Transfer Learning for Cross-Lingual Sentiment Classification with Weakly Shared Deep Neural Networks

Guangyou Zhou1, Zhao Zeng1, Jimmy Xiangji Huang2, and Tingting He1
1 School of Computer, Central China Normal University, Wuhan 430079, China 2 School of Information Technology, York University, Toronto, Canada
{gyzhou, zhaozeng, tthe}@mail.ccnu.edu.cn jhuang@yorku.ca

ABSTRACT
Cross-lingual sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of data in a label-scarce target language by exploiting labeled data from a label-rich language. The fundamental challenge of cross-lingual learning stems from a lack of overlap between the feature spaces of source language data and that of target language data. To address this challenge, previous studies have been performed to make use of the translated resources for sentiment classification in the target language, and the classification performance is far from satisfactory because of the language gap between the source language and the translated target language.
In this paper, to address the above challenge, we present a novel deep neural network structure, called Weakly Shared Deep Neural Networks (WSDNNs), to transfer the crosslingual information from a source language to a target language. To share the sentiment labels between two languages, we build multiple weakly shared layers of features. It allows to represent both shared inter-language features and language-specific ones, making this structure more flexible and powerful in capturing the feature representations of bilingual languages jointly. We conduct a set of experiments with cross-lingual sentiment classification tasks on multilingual Amazon product reviews. The empirical results show that our proposed approach significantly outperforms the stateof-the-art methods for cross-lingual sentiment classification, especially when label data is scarce.
Keywords
Cross-lingual; sentiment classification; auto-encoders
1. INTRODUCTION
With the development of Web 2.0, more and more user generated sentiment data have been shared on the Web. They exist in the form of user reviews on shopping or opinion sites, in posts of blogs or customer feedback in different languages. These labeled user generated sentiment data
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17­21, 2016, Pisa, Italy.
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2911490

are considered as the most valuable resources for sentiment classification. However, such resources in different languages are very imbalanced. Manually labeling each individual language is a time-consuming and labor-intensive job, which makes cross-lingual sentiment classification essential for this application.
Cross-lingual sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of data in a label-scarce target language by exploiting labeled data from a label-rich language. The fundamental challenge of cross-lingual learning stems from a lack of overlap between the feature spaces of source language data and that of target language data. To address this challenge, previous work in the literature mainly relies on machine translation engines or bilingual resources to directly translate labeled data from source language to target language [19, 49, 46, 46, 34, 30, 50]. With the translated resources, one way is to jointly train the bi-view sentiment classifiers on labeled data from source language and their translations in target language via ensemble methods. Another way is to firstly select a subset of pivot features from source language and their translations in target language, and then use these pivot pairs to induce the language-independent features by modeling the corrections between pivot features and non-pivot features in an unsupervised fashion. Though pivot studies have been performed to make use of the translated resources for sentiment classification in target language, the methods are very straightforward by directly employing an inductive classifier, and the classification performance is far from satisfactory because of the language gap between source language and the translated target language.
Recently, many efforts have been initiated on learning feature representations with deep neural networks (DNNs) in the context of cross-lingual sentiment analysis [21, 17, 7, 22, 53, 40, 56, 18], inspired by the success of work on monolingual feature representations. Usually, the paired sentences from parallel corpora are used to learn bilingual feature representations across languages, eliminating the need of machine translation systems. By transferring the feature representations and labeling information from the source language space, we can learn a semantic-intensive target language feature representation, which can greatly improve the performance of target language sentiment classification tasks. In other words, the rich information transferred from the source language can help train the target language DNNs even with little labeled target language data. This is contrary to the popular strategy of trading the representation power of DNNs for better generalization performance in the

245

literature. In this paper, we will present how to use transferred cross-lingual information to train a powerful DNNs without sacrificing linguistic richness, which will yield much better performance for cross-lingual sentiment classification tasks.
To this end, we propose a novel DNNs that hierarchically learns to transfer the semantic knowledge from the source language to the target language, namely Weakly Shared Deep Neural Networks (WSDNNs). Our WSDNNs are trained in a novel way that minimizes the errors incurred by a crosslingual information transfer process. As a hierarchically non-lineal model, WSDNNs differ from the existing shallow cross-lingual information transfer algorithms, such as crosslingual mixture model [26], cross-lingual subspace learning [55], and cross-lingual correspondence learning [34], which learn the cross-lingual feature representations by linear mathematics models. In WSDNNs, we model two DNNs that take a pair of parallel bilingual sentences as input respectively, followed by multiple weakly-shared network layers at the top. The output of the shared layer in WSDNNs yields the translator function that can be used to transfer crosslingual information. To the best of our knowledge, existing DNNs in the context of cross-lingual sentiment classification [7, 22, 53, 56, 18] are representation sharing. In "representation sharing structure", a set of common features are constructed, which usually overestimates the importance of language-specific features. While our weakly parametershared scheme makes our networks more robust of representing shared inter-language features as well as languagespecific ones. To evaluate the effectiveness of the proposed approach, we conduct extensive experiments on multilingual Amazon product reviews for cross-lingual sentiment classification tasks. The empirical results show the proposed approach is effective for cross-lingual sentiment classification, and outperforms the state-of-the-art methods.
Our contribution in this paper is three-fold: (1) we propose a novel architecture of DNNs to transfer the crosslingual information from a source language to a target language, which can adequately mitigate the problem of insufficient training data in the target language by bringing in rich sentiment labels from the source language; (2) the proposed WSDNNs are trained in a novel way that directly minimizes the loss incurred by a label transfer function via back-propagation, which can avoid unbalanced tuning of the source language and the target language DNNs; (3) we show superior results of the proposed WSDNNs on extensive experiments as compared with several strong baselines and the other state-of-the-art methods.
The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents our proposed deep neural network transfer learning framework for cross-lingual sentiment classification. Section 4 presents the experimental results. Finally, we conclude the paper in Section 5.
2. RELATED WORK
Sentiment classification has gained widely interest in information retrieval (IR) and natural language processing (NLP) communities, we point the readers to recent books [31, 24] for an in-depth survey of literature on sentiment classification. Methods in the literature for sentiment classification heavily rely on quality and quantity of the label corpora, which are considered as the most valuable resources in

sentiment classification task. However, such sentiment resources are imbalanced in different languages. To leverage resources in the source language to improve the sentiment classification in the target language, cross-lingual sentiment classification approaches have been investigated.
Cross-lingual sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of data in a label-scarce target language by exploiting labeled data from a label-rich language. The fundamental challenge of cross-lingual learning stems from a lack of overlap between the feature spaces of source language data and that of target language data.
To bridge the language gap, previous work in the literature mainly relies on machine translation engines or bilingual lexicons to directly adapt labeled data from a source language to a target language. Banea et al. [3] employed the machine translation engines to bridge the language gap in different languages for multilingual subjectivity analysis. Wan [46] proposed to use ensemble methods to train Chinese sentiment classification model on English labeled data and their Chinese translations. English labeled data are first translated into Chinese, and then the bi-view sentiment classifiers are trained on English and Chinese labeled data respectively. Pan et al. [30] proposed a bi-view non-negative matrix tri-factorization (BNMTF) model for cross-lingual sentiment classification problem. They employed machine translation engines so that both training and test data are able to have two representations, one in a source language and the other in a target language. The proposed model is derived from the non-negative matrix factorization models in both languages in order to make more accurate prediction. Prettenhofer and Stein [34] proposed a cross-lingual structural correspondence learning (CL-SCL) method to induce language-independent features. Instead of using machine translation engines to translate labeled texts, the authors first selected a subsect of pivot features in the source language to translate them into the target language, and then use these pivot pairs to induce cross-lingual representations by modeling the correlations between pivot features and non-pivot features in an unsupervised fashion. Recently, Xiao and Guo [51] used the similar idea with [34] for crosslingual sentiment classification. Instead of in a fully unsupervised fashion, Xiao and Guo [51] performed representation learning in a semi-supervised manner by directly incorporating discriminative information with respect to the target prediction task. Li et al. [37] selected the samples in the source language that were similar to those in the target language to reduce the gap between two languages. Other similar work includes [48, 25, 1, 52, 13, 6, 12, 41, 27, 8, 23, 2, 11, 36]. All these approaches rely on machine translation or bilingual dictionary to build language connection.
Another group of studies propose to use unlabeled parallel data to fill the gap between two languages. To solve the feature coverage problem, Meng et al. [26] leveraged the unlabeled parallel data to learn unseen sentiment words. Similarly, Popat et al. [33] used the unlabeled parallel data to cluster features in order to reduce the data sparsity problem. Miao and Guo [50] formulated the cross-lingual representation as a matrix completion problem to infer unobserved feature values of the concatenated document-term matrix in the space of unified vocabulary set from the source language and target language by using unlabeled parallel bilingual data. Zhou et al. [55] proposed a subspace learning frame-

246

work by leveraging the partial parallel data for cross-lingual sentiment classification. However, the parallel data is also a scarce resource. Besides, some other studies addressed the cross-lingual knowledge transferring using parallel or comparable corpora [29, 15, 28, 47, 45, 43].
Over the past few years, DNNs have gained a lot of attention from the research community and industry for their ability to automatically learn feature representations for a give task. Most recently, a number of studies leverage DNNs to learn bilingual (or multilingual) feature representations with parallel corpora. Bi-view feature representation has been successfully applied to many IR and NLP tasks, such machine translation [57], cross-lingual sentiment analysis [21, 17, 7, 53, 10, 40, 16, 55, 18, 39], cross-lingual information retrieval [20, 44], question answering [54], etc. The general idea is that they learn bilingual feature representation with aligned sentences throughout two phases: the languagespecific feature representation learning phase and the shared representation learning phase. The key difference is that these existing models are "sharing representations", which usually overestimates the importance of language-specific features. While our proposed WSDNNs are "sharing parameters", which makes our networks are more robust of representing shared inter-language features as well as languagespecific ones.
3. DEEP NEURAL NETWORK TRANSFER LEARNING
3.1 Task Description
Given a labeled data set Ds = {(xsi , yis)}Ni=s1 in source language, in which xsi  Rm is a text data from the source language and yis  {1, 0} is the positive sentiment label or negative sentiment label.1 Our goal is to transfer the labels from the source language to the target language for sentiment classification task. To facilitate the label transfer process, we also have another co-occurrence set of parallel bilingual pairs C = {(x¯sj , x¯tj )}Nj=c1, where x¯sj  Rm and x¯tj  Rn denote a data from the source language and target language respectively. By exploring this parallel bilingual set, we can reveal the alignment between the source language and target language, which will facilitate the sentiment label transfer between these two languages.
In this paper, we will jointly learn the bilingual feature representations to effectively transfer the discriminative information from the source language to the target language. The key idea of the deep neural network transfer learning is an efficient cross-lingual translator which can transfer the sentiment labels from the source language to the target language, even with the challenge of scarcely labeled target language data. By leveraging the learned deep neural network translator, we can solve the target language sentiment classification with extremely insufficient training data.
3.2 Modeling with Deep Neural Networks
An auto-encoder is an unsupervised neural network which is trained to reconstruct a given input vector from its distributed representation [4]. It can be seen as a special neural
1Besides positive and negative sentiments, there are also neural and mixed sentiments in practical applications. In this paper, we only consider binary (positive, negative) sentiment, but it is not hard to extend the proposed framework to address multi-class sentiment classification problems.

Translator Function
... ...
Weakly Shared Layers
... ...

Empirical Loss
... ...
... ... ...

...
Source Language

...
Target Language

Figure 1: Weakly Shared Deep Neural Networks (WSDNNs).

network with three layers: the input layer, the latent layer, and the reconstruction layer. An auto-encoder contains an encoder function h(x) = se(Wx + b) and a counterpart decoder function h¯(x) = sd(W¯ x + b¯) to minimize the reconstruction error of loss function Er(x, h¯(h(x))). se(·) and sd(·) are the non-linear activation function and decoder's activation function respectively. Several auto-encoders can be used as building blocks to form a Stacked Auto-Encoders (SAEs) [4, 42]. Once an auto-encoder has been trained, one can stack another auto-encoder on top of it, by training a second one which sees the latent representation of the first one as input.
Recently, many efforts have been initiated on learning feature representations with DNNs in the context of crosslingual sentiment analysis [21, 17, 7, 22, 53, 40, 56, 18]. First, they pre-train two SAEs for the source language and the target language respectively, which output latent representations of these two languages via the multiple layers of nonlinear encoding. Assume that these two SAEs have L1 layers, where they are structured and built separately. After the first L1 layers, the two SAEs begin to share their structures where L2 shared layers are constructed as shown in Figure 1. These shared layers provide a way to transfer the information across two languages represented by the two SAEs. Therefore, the input into the shared layers is the mixture of outputs of the bottom L1 layers by the two SAEs.
However, we observe that this kind of representation sharing layers tend to over-mix the features learned from two languages. In other words, although there exist many shared features across different languages, it is difficult to completely ignore the language-specific features through the shared layers, since the source language and the target language often contain many elements that cannot be expressed by the same set of the neurons in the shared layers. In this paper, we relax such representation sharing structure, and propose a novel weakly shared deep neural networks (WSDNNs), whose structure is shown in Figure 1. The advantage of our proposed WSDNNs is the flexibility of representing shared inter-language features as well as languagespecific ones, making it more powerful in modeling feature representations of bilingual languages than representation sharing layers in the literature.
Formally, there are L + 1 layers in WSDNNs, where L = L1 + L2. Given a pair of parallel bilingual texts xsj and

247

xtj respectively, we use x(slj)  Rml and x(tjl)  Rnl to denote the latent representation of a hidden layer l for the two SAEs respectively. At the first layer, we set x(s0j) = x(js) and x(tj0) = x(jt) as inputs. For easy of presentation, we drop the subscripts i of x(slj-1) and x(tjl-1) (l = 1, 2, · · · , L) in the following. For l = 1, 2, · · · , L, the layer-wise processing of
these two inputs through the whole networks are defined as
follows

x(sl) = h(sl)(xs) = se(Ws(l)x(sl-1) + b(sl)) x(tl) = h(tl)(xt) = se(Wt(l)x(tl-1) + b(tl))

(1)

where h(sl)(·) and h(tl)(·) denote the l-th layer feature representations in source language and target language SAEs respectively. {Ws(l), b(sl)}Ll=1 and {Wt(l), b(tl)}Ll=1 are the parameters in the source language and target language respec-
tively. The first L1 layers are expected to learn the feature rep-
resentations of a source language and a target language respectively, while the last L2 layers provide shared feature representations. Under weakly-shared assumption, the parameters of the last L2 layers should be set to be close to each other in order to trade off the shared inter-language
features as well as language-specific ones. Inspired by [38],
we propose the following penalty term  to quantify such
trading-off:

L
=

Ws(l) - Wt(l)

2 F

+

b(sl) - b(tl)

2 2

(2)

l=L1 +1

Minimizing this term will minimize the difference of parameters in the last L2 layers of two SAEs networks. It will be added to the proposed objective function in the next Subsection. A positive value of balancing coefficient will be multiplied with it in the objective function, which reflects the above trading-off for the weakly-shared layers.

3.3 Transfer Learning with DNNs
The goal of the proposed cross-lingual transfer learning is to transfer the labels annotated on the source language data set Ds to annotate an arbitrary test data xt in the target language. Following the literature [5, 38], for an arbitrary test data xt and a labeled data xsi in Ds, we define a translator function as (h(sL)(xsi )) Ms,th(tL)(xt) between their weaklyshared layer outputs from the two SAEs, where denotes transpose operation in this paper, and Ms,t is the translator matrix. This translator function is used to transfer the sentiment labels from the source language to the target language as follows:

Ns

f (xt) =

yis h(sL)(xsi ) Ms,th(tL)(xt)

(3)

i

which combines all the labeled data from the source language
weighted by the corresponding translator functions. For the binary sentiment classification task, the distribution f (xt) is the form of [1, 0] for positive and [0, 1] for negative, whose sign predicts the label of the target language data xt.
The parameters can be learned by minimizing the loss
with the sentiment label transfer process, as well as mini-
mizing the inconsistency between a set of parallel bilingual
pairs to capture the cross-lingual alignment information. We
model these two criteria as below:

Empirical loss on the labeled target language data set: Usually, we have a small size of labeled data At = {(xti, yit)}Ni=t1 in the target language, where xti  Rmt is the target space and yit  {1, 0} is the sentiment label. We aim to minimize the training errors incurred by the label transfer function f on the labeled target language data set. The empirical loss on At is as follows:

Nt

arg min = L1 = 

yit · f (xti)

(4)

i=1

where (x) = log(1 + exp(-x)) is a logistic loss function,
which is used to measure the cross-lingual label transfer error. The parameters are  = {Ws(l), b(sl), Wt(l), b(tl), Ms,t}Ll=1.
Empirical loss on the parallel bilingual pairs: Given a set of parallel bilingual pairs C = {(x¯sj , x¯tj )}Nj=c1 in the source language and target language, we wish to maximize
the alignment between each pair of bilingual texts in this
set, yielding a translator function that can well capture the
alignment between these bilingual pairs. Specifically, we
minimize the objective function as follows:

Nc

arg min = L2 = 

h(sL)(x¯sj )

Ms,t - h(tL)(x¯tj )

2 2

(5)

j=1

This loss function can be seen as a measurement of misalignment between parallel bilingual pairs caused by the translator function. Clearly, minimizing this loss function will ensure the consistency of translator function over the parallel bilingual pairs C.

3.4 Learning Algorithm
After the above analysis, we propose the following objective function to learn the parameters of deep semantic translator as input of the top-layers of WSDNNs:

arg

min 

=

L

=

L1

+

L2

+

Er

+

 2



+

 2



(6)

where Ms,t


2 F

= is

L l=1

(

Ws(l)

2 F

+

the regularization

b(sl)

2 2

term.

+

Wt(l)

2 F

+

b(sl)

The parameters ,

2 2

)

,

+ 

and  weigh the importance of different term. In particular,

 is the importance weight on alignment between the parallel

bilingual pairs,  is the importance weight of reconstruction

error,  adjusts the weakly-shared structure, and  weights

the regularization term.

To train the WSDNNs, we first pre-train each layer per

time in a greedy fashion by using the unsupervised data

as in conventional auto-encoder algorithms. The pre-train

WSDNNs set up a good starting point that can fine tuned

according to the objective function by employing the avail-

able supervision information.

We implement a back propagation process starting from

the top output layers down through the whole WSDNNs to

adjust all parameters. Each parameter in  is updated by

stochastic gradient descent in back-propagation algorithm

below:

Ws(l)

=

Ws(l)

-



L  Ws(l)

(7)

b(sl)

=

b(sl)

-



L  b(sl)

(8)

Wt(l)

=

Wt(l)

-



L  Wt(l)

(9)

248

b(tl)

=

b(tl)

-



L  b(tl)

(10)

Ms,t

=

Ms,t

-



L  Ms,t

(11)

where  is the learning rate. These parameters can be computed based on the stochastic gradient optimization. The convergence is guaranteed when the number of iterations reaches the max or the objective function value is smaller than a predefined threshold. The overall complexity of our WSDNNs is similar with an existing SAE [4, 42].
We exploit the supervision information on the labeled target language data set At to directly tune the target language SAE. Similar to [38], we add an additional softmax layer upon the target language SAE that outputs the sentiment labels of the target language data. Then the labeled target language data in At are used to compute the backpropagated errors to tune the parameters in the target language SAE. In this paper, the back-propagated errors only arise from the target language labels that are intended to enhance the tuning of target language SAE. This can avoid unbalanced tuning of source language and target language SAEs when much more labeled data are used in label transfer process.

4. EXPERIMENTS
4.1 Data Sets
We use the multilingual sentiment classification data sets provided by Prettenhofer and Stein [34], which contain Amazon product reviews in four languages (English (E), French (F), German (G) and Japanese (J)) of three categories (Books (B), DVD (D), Music (M)). The English product reviews are sampled from previous cross-domain sentiment classification data sets, while the other three language product reviews are crawled from Amazon by the authors in November. Each category of product reviews contains a balanced training set and test set, each of which consists of 1000 positive and 1000 negative reviews for each of the language. Besides, we also collect a set of parallel bilingual reviews between English and each of the other three languages. Following the literature [50], each review is represented as a unigram bag-of-words vector representation and each entry is computed with tf-idf. Given the four languages from the three categories, we construct 18 cross-lingual sentiment classification tasks (EFB, EFD, EFM, EGB, EGD, EGM, EJB, EJD, EJM, FEB, FED, FEM, GEB, GED, GEM, JEB, JED, JEM) between English and the other three languages. For example, the task EFB uses English Books reivews as the source language and uses French Books reviews as the target language.
4.2 Compared Methods
In our experiments, we compare our proposed WSDNNs with the several strong baselines and state-of-the-art methods in the literature for cross-lingual sentiment classification:
· TB: This is a target bag-of-words baseline method, which trains a supervised monolingual classifier on the labeled training data from the target language without using the unlabeled parallel bilingual pairs and the source language data.

· CL-LSA: This is the cross-lingual learning method described in [15], which first translates each document from the source language into the target language via a bilingual dictionary to produce augmenting features, and then performs latent semantic analysis (LSA) over the augmented bilingual document-term matrix.
· CL-SCL: This is the cross-lingual structural correspondence learning method described in [34], which first selects some pivot features and then automatically induces the cross-lingual correspondences with a bilingual dictionary.
· CL-MT: This is the state-of-the-art machine translation based method described in [46], which first translates the source language to the target language, and then uses the ensembles methods to train sentiment classifiers on labeled data from the source language and their translations in the target language.
· CL-MM: This is the generative cross-lingual mixture model (CL-MM) described in [26], which learns previously unseen sentiment words from the large-scale bilingual parallel data to improve the vocabulary coverage. We implement this method using the 2000 unlabeled parallel reviews.
· CL-OPCA: This is the cross-lingual oriented principal component analysis (OPCA) method described in [32], which first learns cross-lingual representations with all data from both languages by performing OPCA and then trains a monolingual classifier with labeled data from both languages in the induced feature space.
· CL-TS: This is a two-step method described in [50], which formulates the cross-lingual representation as a matrix completion problem to infer unobserved feature values of the concatenated document-term matrix in the space of unified vocabulary set from the source language and target language by using the unlabeled parallel bilingual pairs.2
· CL-SP: This is the state-of-the-art multiview learning method described in [55], which is achieved by jointly learning the document-aligned review data and un-aligned data from the source language and the target language via a non-negative matrix factorization framework.
In all experiments, we train the sentiment classification model on the learned representations using the linear support vector machine (SVM) [9]. For CL-LSA, CL-OPCA and CL-TS, we use the same parameter setting as suggested in the paper [50]: the latent dimension is set to 50. For CLSCL, we use the same parameter setting as suggested in the paper [34]: the number of pivot features is set as 450, the threshold value for selecting pivot features is 30, and the reduced dimensionality after singular value decomposition is 100. For CL-SP, we use the same parameter settings as suggested in the paper [55]: the shared latent dimension is set to 100 and the normalized parameter is set to 10-2. We choose the above parameter values empirically because these
2There is a slight exception: using the same data set and parameter setting, our re-implement systems have slight differences with the results reported in [50].

249

Table 1: Average results (accuracy + standard derivation) for the 18 cross-lingual sentiment classification tasks. The bold formate indicates the best results,  indicates that the difference between our proposed

WSDNNs and stateof-the-art CL-SP is significant with p < 0.05 under a McNemar paired test for labeling disagreements, and  indicates the mildly significant with p < 0.08.

Task
EFB EFD EFM EGB EGD EGM EJB EJD EJM FEB FED FEM GEB GED GEM JEB JED JEM avg.

TB
66.89±0.87 67.42±0.91 67.55±0.50 67.31±0.72 66.54±0.73 67.61±0.46 62.91±0.62 65.33±0.58 67.28±0.67 66.77±0.51 65.98±0.57 65.92±0.55 67.05±0.68 66.30±0.60 66.55±0.46 66.72±0.63 66.32±0.49 66.48±0.55
66.50±0.62

CL-LSA
79.38±0.25 77.69±0.54 75.26±0.43 77.60±0.37 79.16±0.26 73.67±0.52 72.55±0.41 72.51±0.32 73.40±0.47 76.61±0.40 76.39±0.34 76.24±0.35 77.43±0.26 77.55±0.30 77.03±0.42 74.49±0.37 75.17±0.24 72.29±0.45
75.80±0.37

CL-SCL
79.86±0.22 78.80±0.25 75.95±0.31 77.77±0.28 79.93±0.23 73.95±0.30 72.91±0.25 72.82±0.28 73.75±0.35 77.26±0.22 76.57±0.20 76.76±0.25 77.85±0.27 77.83±0.33 77.37±0.34 75.25±0.30 75.34±0.27 73.21±0.33
76.29±0.28

CL-MT
78.01±0.45 77.75±0.68 75.86±0.51 77.02±0.60 79.75±0.58 73.69±0.55 72.20±0.80 72.68±0.56 73.33±0.65 77.43±0.55 76.80±0.52 76.19±0.48 77.50±0.66 77.52±0.54 77.63±0.51 74.41±0.47 75.15±0.49 73.16±0.50
75.89±0.56

CL-MM
69.35±0.46 67.47±0.28 69.12±0.38 70.76±0.33 66.93±0.38 69.58±0.40 65.95±0.35 66.20±0.37 67.89±0.34 69.02±0.36 66.93±0.35 70.44±0.30 71.13±0.31 66.55±0.39 69.12±0.35 68.05±0.40 66.22±0.32 67.55±0.41
68.24±0.36

CL-OPCA
76.47±0.35 70.36±0.43 73.43±0.37 74.65±0.48 74.47±0.56 74.38±0.61 71.17±0.50 71.70±0.45 74.82±0.64 74.29±0.52 72.30±0.57 73.41±0.55 74.66±0.42 74.68±0.54 74.07±0.46 73.38±0.45 75.37±0.48 72.55±0.61
73.68±0.50

CL-TS
81.83±0.25 81.92±0.35 79.06± 0.28 79.30±0.34 81.27±0.26 79.26±0.33 72.40±0.48 76.51±0.37 76.17±0.43 79.29±0.30 77.88±0.34 78.31±0.41 78.45±0.29 79.22±0.28 78.90±0.37 77.11±0.30 78.95±0.46 77.13±0.51
78.50±0.35

CL-SP
82.61± 0.25 82.70± 0.45 80.19± 0.40 79.91± 0.47 81.86± 0.31 79.59± 0.42 73.45± 0.27 77.06± 0.32 76.83± 0.52 80.48± 0.33 78.76± 0.38 79.18± 0.33 78.61± 0.34 80.27± 0.35 79.80± 0.26 77.97± 0.35 80.63± 0.38 77.78± 0.37
79.32± 0.36

WSDNNs
83.45± 0.23 83.61± 0.33 80.97± 0.38 81.32± 0.36 82.40± 0.25 80.65± 0.28 74.51± 0.40 78.26± 0.38 77.52± 0.40
80.06± 0.27 79.84± 0.26 80.14± 0.31 79.23± 0.35 80.95± 0.50
79.68± 0.43 79.10± 0.48 81.89± 0.52 78.22± 0.55
80.10± 0.37

parameter settings have shown superior performance on the same benchmark [50, 34, 55].
4.3 Classification Accuracy
For each of the 18 cross-lingual sentiment classification tasks, we use all labeled data from the source language. For the target language, we use the test set as testing data while randomly choose 100 documents from the training set as labeled data. Thus, for each task, we have 2000 labeled documents from the source language, 100 labeled documents from the target language as auxiliary data ( At = 100) and the rest of target language as test data, as well as a set of parallel bilingual pairs. We run each experiment 10 times with different random selections of 100 labeled training documents from the target language. All parameters in our model are tuned based on a 5-fold cross-validation procedure on the training data, and the parameters are selected when the best performances are achieved. We train our model with 5-layers WSDNNs from bottom up. The last three ones are weakly shared layers. The average sentiment classification accuracies and standard deviations are presented in Table 1.
From Table 1, we can see that our proposed WSDNNs clearly outperforms the several strong baselines on 16 out of the 18 tasks. The target baseline TB performs poorly on all the 18 tasks, which indicates that 100 labeled documents from the target language is far from enough to obtain an accurate and robust sentiment classifier for sentiment classification. All the other seven cross-lingual sentiment classification methods, CL-LSA, CL-SCL, CL-MT, CL-MM, CL-OPCA, CL-TS and CL-SP, consistently outperform the baseline method TB across all the 18 tasks, which demonstrates that the labeled training data from source language is useful for classifying target language data. Among the 18 tasks, WSDNNs outperforms CL-LSA, CL-SCL, CL-MT, CL-MM, CL-OPCA and CL-TS across all the 18 tasks, outperforms CL-SP on 16 out of the 18 tasks and achieves the slight lower performance than CL-SP on the rest two tasks (FEB and GEM).
We also conduct significance tests for our proposed ap-

proach and each of the other methods using a McNemar paired test for labeling disagreements [14]. The results in bold formate indicates the best results, the overall results indicate that they are significant with p < 0.05. All these results demonstrate the efficacy and robustness of the proposed WSDNNs for cross-lingual sentiment classification.
Recently, many efforts have been initiated on learning feature representations with DNNs in the context of crosslingual sentiment classification tasks [21, 17, 7, 53, 10, 40, 16, 18, 39]. However, these existing methods in the literature like bilingual SAEs [53, 55, 18] are representation sharing. While our proposed WSDNNs are weakly parametersharing, which makes our networks more flexible, especially when cross-lingual sentiment classification requires more language specific features are learned. In other words, by sharing parameters, we allow deviation exists between the feature representations of different languages. In contrast, in "representation sharing" structure, a set of common features are constructed, which usually overestimates the importance of language-specific features. Therefore, we also compare with the following representative representation sharing DNNs and state-of-the-art DNNs in the literature for cross-lingual sentiment classification: Chandar et al. [7] proposed a predicative auto-encoder for learning shared representation for cross-lingual tasks. Zhou et al. [53] proposed a two SAEs to learn feature representation for cross-lingual sentiment classification. Hermann and Blunsom [16] proposed to learn compositional distributed semantics for multilingual analysis. Zhou et al. [56] proposed to learn bilingual sentiment word embeddings for cross-lingual language analysis. Jain et al. [18] leveraged the sentence aligned corpora to develop a cross-lingual sentiment analysis tool. In this paper, we reimplement these representation sharing DNNs based on the original papers and train these models with a 5-fold crossvalidation procedure on the training data. The average results are presented in Table 2.
From Table 2, we can see that our proposed WSDNNs significantly outperforms the state-of-the-art representation sharing DNNs in general with p < 0.05. Among the 18 tasks, WSDNNs achieves the best performance on 15 tasks. This

250

Table 2: Average results (accuracy + standard derivation) for the 18 cross-lingual sentiment classification tasks by using DNNs. The bold formate indicates the best results,  indicates that the differences between our proposed WSDNNs and other DNNs are significant with p < 0.05, and  indicates the mildly significant

with p < 0.08.

Task EFB EFD EFM EGB EGD

Chandar et al. [7] 78.75±0.37 78.08±0.54 76.43±0.42 77.94±0.37 80.11±0.41

Zhou et al. [53] 79.68±0.27 78.33±0.41 78.56±0.28 77.87±0.33 78.63±0.52

Hermann and Blunsom [16] 82.47±0.34 81.51±0.52 79.29±0.37 80.33±0.42 81.67±0.29

Zhou et al. [56] 80.37±0.38 79.56±0.41 77.21±0.29 78.94±0.35 80.45±0.31

Jain et al. [18] 81.33± 0.41 80.68± 0.35 79.05± 0.28 79.47± 0.56 81.39± 0.43

WSDNNs
83.45± 0.23 83.61± 0.33 80.97± 0.38 81.32± 0.36 82.40± 0.25

EGM

74.87±0.53

78.25±0.48

80.73±0.36

79.68±0.28

79.86± 0.38

80.65± 0.28

EJB

73.21±0.62

73.08±0.39

74.05±0.45

75.53±0.42

74.70± 0.34

74.51± 0.40

EJD

74.05±0.48

75.37±0.55

77.68±0.37

76.35±0.57

78.43± 0.30 78.26± 0.38

EJM

74.66±0.57

76.44±0.28

77.24±0.40

77.28±0.33

76.91± 0.36 77.52± 0.40

FEB FED FEM

78.73±0.45 77.48±0.51 76.96±0.47

75.58±0.47 77.62±0.50 77.16±0.44

79.63±0.38 78.47±0.46 78.21±0.32

78.15±0.36 76.62±0.37 78.61±0.43

78.57± 0.47 78.35± 0.33 79.28± 0.40

80.06± 0.27 79.84± 0.26 80.14± 0.31

GEB GED GEM JEB JED JEM avg.

77.71±0.62 78.64±0.55 78.02±0.39 75.59±0.44 76.16±0.48 74.83±0.54
76.79±0.49

77.32±0.38 79.05±0.33 77.31±0.51 76.67±0.47 78.73±0.38 76.48±0.56
77.17±0.42

78.37±0.37 79.15±0.44 79.07±0.35 78.27±0.45 81.20±0.39 77.74±0.27
79.17±0.39

79.15±0.32 79.44±0.38 78.87±0.27 78.05±0.35 79.33±0.34 77.58±0.46
78.40±0.37

78.44± 0.51 79.61±0.32 79.14± 0.44 78.20± 0.38 80.93± 0.34 77.65± 0.25
78.99± 0.38

79.23± 0.35 80.95± 0.50
79.68± 0.43 79.10± 0.48 81.89± 0.52 78.22± 0.55
80.10± 0.37

confirms that our proposed weakly shared layers are more suitable to model the DNNs than the existing representation sharing layers.
4.4 The Impact of Number of Labeled Target Language Data
Next, we look into the performance of all eight approaches by varying the number of labeled training documents from the target language. We use the same experimental setting as before, but investigate a range of different numbers, nt = {100, 200, 300, 400, 500}, as the number of labeled training data from the target language. Given a value nt, we randomly select nt documents from the training set of the target language as labeled data for each experiment. We also run the experiments on the same 2000 test data from the target language. Each experiment is repeated 10 times based on different random selection of the labeled training data from the target language. Figure 2 shows the average classification accuracies (%) vs. different numbers of labeled target language data on all the 18 tasks.3
From Figure 2, we can see that when the number of labeled documents from the target language is small, TB performs poorly. By increasing the number of labeled data from the target language, TB can greatly increase the classification accuracy and even outperform the CL-MM method. The CL-MM has a stable performance across the range of different numbers. The CL-LSA method has inconsistent performance across the 18 tasks. Its performance is better than TB when the labeled training data in the target language is very limited and is poor than TB when the labeled target data reaches 300 on most tasks. By using the machine translation resources, the CL-MT method outperforms TB, CL-LSA, CL-SCL and CL-MM. With a more sophisticated representation, the CL-TS, CL-SP and WSDNNs achieve the better performance than other five methods. Our proposed WSDNNs significantly outperforms all the other seven comparison methods across all experiments except on the
3In Figure 2, we do not present the results of CL-OPCA because this method has used all data from both languages in the original paper.

tasks of EJB and GEM. In addition, we also observe that WSDNNs achieves high accuracies even when the number of labeled target language data is small. This is important for transferring the knowledge from a source language to a target language in order to reduce the labeling effort.
4.5 Parameter Analysis
In this subsection, we look into the parameters  and  of objective function in Eq. (6). We choose   {0, 0.5, 1.0, 2.0} and   {0.1, 0.5, 1.0, 2.0} via a cross-validation procedure, respectively. As usual, we set  =  = 1 to equally weigh the three types of loss functions. Here, we study their impacts on the performances in Figure 3. When  = 0, the average accuracy is the lowest. The reason may be that in this case the source language and the target language SAEs are completely independent without any shared layers. This structure fails to jointly model the source language and the target language representations, and is unable of transferring sentiment labels between two languages. The accuracy increases rapidly when  becomes large. On the other hand,  can also improve the accuracy when it is set to a proper value to regularize the model. The best accuracy on 16 cross-lingual tasks (except on the task of FEB and GEM) is achieved when  = 1 and  = 0.5. The accuracies with different values of parameters are not varied very much, which suggests that our proposed WSDNNs are not very sensitive to the parameters.
5. CONCLUSIONS AND FUTURE WORK
In this paper, we propose a novel weakly parameter-shared deep neural networks (WSDNNs) to transfer cross-lingual information from the source language to the target language. To share the sentiment labels between two languages, we build multiple weakly shared layers of features. It allows to represent both shared inter-language features and languagespecific ones, making our networks more flexible and powerful in capturing the feature representations of bilingual languages than the existing representation sharing structure. The proposed WSDNNs are trained in a novel way that directly minimizes the loss incurred by a label transfer func-

251

Accuracy (%)

Accuracy (%)

Accuracy (%)

82 80 78 76 74 72 70 68 66 100
80 78 76 74 72 70 68 66 64 100
76
74
72
70
68
66 100
84 82 80 78 76 74 72 70 68 66 100

EFB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

EGD

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

EJM

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

GEB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

Accuracy (%)

Accuracy (%)

Accuracy (%)

Accuracy (%)

Accuracy (%)

78 76 74 72 70 68 66 64 100
80

EFD

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

EGM

75
70
65 100
84 82 80 78 76 74 72 70 68 61600
84 82 80 78 76 74 72 70 68 66 100
85

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

FEB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

GED

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

JED

80 75 70 100

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

Accuracy (%)

Accuracy (%)

Accuracy (%)

Accuracy (%)

Accuracy (%)

EFM 80

75
70
61500
72 71 70 69 68 67 66 65 64 63 100
84 82 80 78 76 74 72 70 68 66 100
84 82 80 78 76 74 72 70 68 66 100
84 82 80 78 76 74 72 70 68 61600

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

EJB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

FED

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

GEM

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

JEM

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

Accuracy (%)

Accuracy (%)

Accuracy (%)

Accuracy (%)

82 80 78 76 74 72 70 68 61600
76 74 72 70 68 66 64 100
84 82 80 78 76 74 72 70 68 66 100
82 80 78 76 74 72 70 68 61600

EGB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

EJD

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

FEM

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

JEB

TB CL-LSA CL-SCL CL-MT CL-MM CL-TS CL-SP WSDNNs

200

300

400

500

#Labeled target data

Accuracy (%)

Figure 2: Average accuracies (%) vs. different numbers of labeled target language data on all the 18 tasks.

tion. This yields a fine tuning strategy to train WSDNNs from top down with via back-propagation, which can avoid unbalanced tuning of the source language and the target language. We conduct extensive experiments on 18 crosslingual sentiment classification tasks constructed from the Amazon product reviews in four languages. The empirical results show the superior performances as compared with several strong baselines and state-of-the-art methods.
There are three research directions that we are planning to investigate in future. First, a straightforward path of the future research is to use the proposed WSDNNs for other language pairs, and apply to other tasks such as cross-lingual information retrieval [44]. Second, another straightforward extension is to replace the simple feature representations of SAE with more systematic context-aware learning methods,

such as convolutional neural networks (CNNs) or recursive neural networks (RNNs). Third, inspired by the successful application of attention mechanism in multilingual neural machine translation [35], we will try to model the crosslingual sentiment information with a shared attention mechanism.
Acknowledgments
This work was supported by the National Natural Science Foundation of China (No. 61303180, No. 61300144 and No. 61573163), the Fundamental Research Funds for the Central Universities (No. CCNU15ZD003 and No. CCNU16A02024), and also supported by a Discovery grant from the Natural Sciences and Engineering Research Council (NSERC) of

252

Accuracy (%)

Accuracy (%)

84

EFB

84

83

83

Accuracy (%)

82

82

81

81

80

J=0.1

80

J=0.5

79

J=1.0

79

J=2.0

78

78

0

0.5

1

1.5

2

0

E

75

EJB

78

Accuracy (%)

76

74 70

J=0.1

72

J=0.5

J=1.0

70

J=2.0

650

0.5

E1

1.5

2

0

80

GEB

80

78

Accuracy (%)

78

76

76

74

J=0.1

74

72

J=0.5

J=1.0 J=2.0

72

700

0.5

1

1.5

2

0

E

EFD

0.5

1

E

EJD

0.5

1

E

GED

0.5

1

E

81

80

79

Accuracy (%)

78

77

76 J=0.1

J=0.5

75

J=1.0

74

J=2.0

73

1.5

2

0

78

Accuracy (%)

76

74

J=0.1

72

J=0.5

J=1.0

J=2.0

70

1.5

2

0

80

Accuracy (%)

78

76

J=0.1

74

J=0.5

J=1.0 J=2.0

72

1.5

2

0

EFM

0.5

1

E

EJM

0.5

1

E

GEM

0.5

1

E

82

81

80

Accuracy (%)

79

78

J=0.1

77

J=0.5

J=1.0

76

J=2.0

75

1.5

2

0

80

78

Accuracy (%)

76

J=0.1

74

J=0.5

J=1.0

72

J=2.0

1.5

2

700

80

78

Accuracy (%)

76

74

J=0.1

J=0.5 J=1.0

72

J=2.0

1.5

2

700

EGB

0.5

1

E

83

82

81

Accuracy (%)

80

79

78 J=0.1

J=0.5

77

J=1.0

76

J=2.0

75

1.5

2

0

FEB

0.5

1

E

80

78

Accuracy (%)

76

74

J=0.1

J=0.5

72

J=1.0

J=2.0

70

1.5

2

0

JEB

0.5

1

E

82

81

80

Accuracy (%)

79

78

J=0.1

77

J=0.5

J=1.0

76

J=2.0

1.5

2

750

EGD

0.5

1

E

FED

0.5

1

E

81

80

79

Accuracy (%)

78

77

76 J=0.1

J=0.5

75

J=1.0

74

J=2.0

73

1.5

2

0

80

78

Accuracy (%)

76

J=0.1

74

J=0.5

J=1.0

72

J=2.0

1.5

2

700

JED

0.5

1

E

78

Accuracy (%)

76

74

J=0.1

72

J=0.5

J=1.0 J=2.0

70

1.5

2

0

EGM

0.5

1

E

FEM

J=0.1 J=0.5 J=1.0 J=2.0

1.5

2

0.5

1

E

JEM

J=0.1 J=0.5 J=1.0 J=2.0

1.5

2

J=0.1 J=0.5 J=1.0 J=2.0

0.5

1

1.5

2

E

Figure 3: Average accuracies (%) vs. different values of  and  on all the 18 tasks.

Accuracy (%)

Canada and an NSERC CREATE award. We thank the anonymous reviewers for their insightful comments.
6. REFERENCES
[1] B. A., A. Joshi, and P. Bhattacharyya. Cross-lingual sentiment analysis for Indian languages using linked wordnets. In COLING, pages 73­82, 2012.
[2] S. Artem, J. Laura, H. Felix, and R. Stefan. Boosting cross-language retrieval by learning bilingual phrase associations from relevance rankings. In EMNLP, pages 1688­1699, 2013.
[3] C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. Multilingual subjectivity analysis using machine translation. In EMNLP, pages 127­135, 2008.
[4] Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle, U. D. Montreal, and M. Quebec. Greedy layer-wise training of deep networks. In NIPS, pages 153­160, 2007.
[5] A. Bordes, J. Weston, and N. Usunier. Open question answering with weakly supervised embedding models. In ECML/PKDD, pages 165­180, 2014.
[6] G. Cao, J. Gao, J.-Y. Nie, and J. Bai. Extending query translation to cross-language query expansion with markov chain models. In CIKM, pages 351­360, 2007.
[7] S. Chandar A P, S. Lauly, H. Larochelle, M. Khapra, B. Ravindran, V. C. Raykar, and A. Saha. An autoencoder approach to learning bilingual word representations. In NIPS, pages 1853­1861. 2014.
[8] A. Chen and F. C. Gey. Multilingual information retrieval using machine translation, relevance feedback and decompounding. Inf. Retr., 7(1):149­182, 2004.
[9] R. Fan, K. Chang, C. Hsieh, X. Wang, and C. Lin. Liblinear: A libary for large linear classification. JMLR, 9:1871­1874, 2008.
[10] M. Faruqui and C. Dyer. Improving vector space word representations using multilingual correlation. In EACL, pages 462­471, 2014.

[11] T. Ferhan, L. Jimmy, and D. W. Oard. Combining statistical translation techniques for cross-language information retrieval. In COLING, pages 2685­2702, 2012.
[12] J. Gao, E. Xun, M. Zhou, C. Huang, J.-Y. Nie, and J. Zhang. Improving query translation for cross-language information retrieval using statistical models. In SIGIR, pages 96­104, 2001.
[13] W. Gao, C. Niu, J.-Y. Nie, M. Zhou, J. Hu, K.-F. Wong, and H.-W. Hon. Cross-lingual query suggestion using query logs of different languages. In SIGIR, pages 463­470, 2007.
[14] L. Gillick and S. Cox. Some statistical issues in the comparison of speech recoginition algorithms. In ICASSP, pages 532­535, 1989.
[15] A. Gliozzo and C. Strapparava. Exploiting comparable corpora and bilingual dictionaries for cross-language text categorization. In ACL, pages 553­560, 2006.
[16] K. M. Hermann and P. Blunsom. Multilingual models for compositional distributed semantics. In ACL, pages 58­68, 2014.
[17] J.-T. Huang, J. Li, D. Yu, L. Deng, and Y. Gong. Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers. In ICASSP, pages 137­140, 2013.
[18] S. Jain and S. Batra. Cross lingual sentiment analysis using modified brae. In EMNLP, pages 159­168, 2015.
[19] S. James, G. Gregory, Q. Yan, and E. David. Mining multilingual opinions through classification and translation. 2004.
[20] J. Kim, J. Nam, and I. Gurevych. Learning semantics with deep belief network for cross-language information retrieval. In COLING, pages 579­588, 2012.
[21] A. Klementiev, I. Titov, and B. Bhattarai. Inducing crosslingual distributed representations of words. In COLING, pages 1459­1473, 2012.

253

[22] T. Kocisky´, K. M. Hermann, and P. Blunsom. Learning bilingual word representations by marginalizing alignments. In ACL, pages 224­229, 2014.
[23] W. Kraaij, J.-Y. Nie, and M. Simard. Embedding web-based statistical translation models in cross-language information retrieval. Comput. Linguist., 29(3):381­419, 2003.
[24] B. Liu. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 2012.
[25] B. Lu, C. Tan, C. Cardie, and B. K. Tsou. Joint bilingual sentiment classification with unlabeled parallel corpora. In ACL, pages 320­330, 2011.
[26] X. Meng, F. Wei, X. Liu, M. Zhou, G. Xu, and H. Wang. Cross-lingual mixture model for sentiment classification. In ACL, pages 572­581, 2012.
[27] S.-H. Na and H. T. Ng. Enriching document representation via translation for improved monolingual information retrieval. In SIGIR, pages 853­862, 2011.
[28] X. Ni, J.-T. Sun, J. Hu, and Z. Chen. Cross lingual text classification by mining multilingual topics from wikipedia. In WSDM, pages 375­384, 2011.
[29] J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web. In SIGIR, pages 74­81, 1999.
[30] J. Pan, G.-R. Xue, Y. Yu, and Y. Wang. Cross-lingual sentiment classification via bi-view non-negative matrix tri-factorization. In PAKDD, pages 289­300.
[31] B. Pang and L. Lee. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1­135, 2008.
[32] J. Platt, K. Toutanova, and W. Yih. Translingual document representations from discriminative projects. In EMNLP, pages 251­261, 2010.
[33] K. Popat, B. A.R, P. Bhattacharyya, and G. Haffari. The haves and the have-nots: Leveraging unlabelled corpora for sentiment analysis. In ACL, pages 412­422, 2013.
[34] P. Prettenhofer and B. Stein. Cross-language text classification using structural correspondence learning. In ACL, pages 1118­1127, 2010.
[35] I. V. Serban, A. Sordoni, Y. Bengio, A. C. Courville, and J. Pineau. Building end-to-end dialogue systems using generative hierarchical neural network models. In AAAI, pages 3776­3784, 2016.
[36] S. Shigehiko, H. Felix, S. Artem, and R. Stefan. Learning translational and knowledge-based similarities from relevance rankings for cross-language retrieval. In ACL, pages 488­494, 2014.
[37] L. Shouhan, W. Rong, L. Huanhuan, and H. Churen. Active learning for cross-lingual sentiment classification. In NLPCC, pages 236­246, 2013.
[38] X. Shu, G. Qi, J. Tang, and J. Wang. Weakly-shared deep transfer networks for hetergeneous-domain knowledge propagation. In MM, pages 35­44, 2015.
[39] G. Stephan, B. Yoshua, and C. Greg. Bilbowa: Fast bilingual distributed representations without word alignments. In ICML, pages 1­10, 2015.
[40] X. Tang and X. Wan. Learning bilingual embedding

model for cross-language sentiment classification. In WI, pages 134­141, 2014.
[41] D. Trieschnigg, D. Hiemstra, F. de Jong, and W. Kraaij. A crosslingual framework for monolingual biomedical information retrieval. In CIKM, pages 169­178, 2010.
[42] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, pages 1096­1103, 2008.
[43] I. Vuli´c and M.-F. Moens. A unified framework for monolingual and cross-lingual relevance modeling based on probabilistic topic models. In ECIR, pages 98­109, 2013.
[44] I. Vuli´c and M.-F. Moens. Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings. In SIGIR, pages 363­372, 2015.
[45] I. Vuli´c, W. Smet, and M.-F. Moens. Cross-language information retrieval models based on latent topic models trained with document-aligned comparable corpora. Inf. Retr., 16(3):331­368, 2013.
[46] X. Wan. Co-training for cross-lingual sentiment classification. In ACL, pages 235­243, 2009.
[47] Z. Wang, Z. Li, J. Li, J. Tang, and J. Z. Pan. Transfer learning based cross-lingual knowledge extraction for wikipedia. In ACL, pages 641­650, 2013.
[48] B. Wei and C. Pal. Cross lingual adaptation: An experiment on sentiment classifications. In ACL, pages 258­262, 2010.
[49] K. Wu, X. Wang, and B. liang Lu. Cross language text categorization using a bilingual lexicon. In IJCNLP, pages 165­172, 2008.
[50] M. Xiao and Y. Guo. A novel two-step method for cross language representation learning. In NIPS, 2013.
[51] M. Xiao and Y. Guo. Semi-supervised representation learning for cross-lingual text classification. In EMNLP, pages 1465­1475, 2013.
[52] Z. Ye, X. Huang, B. He, and H. Lin. Mining a multilingual association dictionary from wikipedia for cross-language information retrieval. JASIST, 63(12):2474­2487, 2012.
[53] G. Zhou, T. He, and J. Zhao. Bridging the language gap: Learning distributed semantics for cross-lingual sentiment classification. In NLPCC, pages 138­149, 2014.
[54] G. Zhou, T. He, J. Zhao, and P. Hu. Learning continuous word embedding with metadata for question retrieval in community question answering. In ACL, pages 250­259, 2015.
[55] G. Zhou, T. He, J. Zhao, and W. Wu. A subspace learning framework for cross-lingual sentiment classification with partial parallel data. In IJCAI, pages 1426­1432, 2015.
[56] H. Zhou, L. Chen, F. Shi, and D. Huang. Learning bilingual sentiment word embeddings for cross-language sentiment classification. In ACL, pages 430­440, 2015.
[57] W. Y. Zou, R. Socher, D. M. Cer, and C. D. Manning. Bilingual word embeddings for phrase-based machine translation. In EMNLP, pages 1393­1398, 2013.

254

