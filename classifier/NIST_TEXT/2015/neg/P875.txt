Predicting User Behavior in Display Advertising via Dynamic Collective Matrix Factorization

Sheng Li
Northeastern University Boston, MA, USA
shengli@ece.neu.edu

Jaya Kawale
Adobe Research San Jose, CA, USA
kawale@adobe.com

Yun Fu
Northeastern University Boston, MA, USA
yunfu@ece.neu.edu

ABSTRACT
Conversion prediction and click prediction are two important and intertwined problems in display advertising, but existing approaches usually look at them in isolation. In this paper, we aim to predict the conversion response of users by jointly examining the past purchase behavior and the click response behavior. Additionally, we model the temporal dynamics between the click response and purchase activity into a unified framework. In particular, a novel matrix factorization approach named dynamic collective matrix factorization (DCMF) is proposed to address this problem. Our model considers temporal dynamics of post-click conversions and also takes advantages of the side information of users, advertisements, and items. Experiments on a realworld marketing dataset show that our model achieves significant improvements over several baselines.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information filtering
Keywords
Conversion prediction; matrix factorization; temporal dynamic
1. INTRODUCTION
With the proliferation of the Internet and online shopping websites, digital marketing has become an effective way to reach out to consumers. Typically consumers can be influenced via targeted advertisements (ads) on the web to make purchases. Display advertising is a popularly used medium for targeting users and allows advertisers to place graphical ads on the publishers' web pages. Most of the ads aim to create an impulse leading to a sale. Traditionally, the
This work was completed during Sheng Li's internship at Adobe Research.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. SIGIR'15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767781.

click-through rate (CTR) has been used as a central measure for evaluating the performance of a direct response ad campaign. An alternate strategy that has gained attention in the recent past is to maximize the conversion rate (CVR) instead of just ad-clicks, as many advertisers would prefer not to pay for an ad impression unless it leads to a conversion. The conversion could either imply revenue generated via buying a product or could mean account creation. In both strategies it is critical to understand the user behavior and predict the response so as to have better targeting of the ads and as a result higher conversions.
So far, the problem of click prediction and conversion prediction has mainly been studied in isolation. Researchers have successfully applied novel strategies for click prediction and there has been significant work in the area [1]. Recently the problem of conversion prediction has been studied by [2] to analyze the ad campaigns. However, the objectives of the two problems are often intertwined together and there is a need to study the two problems in conjunction with each other. With the notable exception of [3], there is not much work analyzing the two objectives together to understand the user purchase behavior better. Jointly studying the two problems can help us understand the pathway leading to conversion and can provide answers to several questions. For example, What ads should be shown to a particular user so that he generates revenue? and Will a given user generate revenue?
In this paper, we propose a novel approach called as dynamic collective matrix factorization (DCMF) to jointly examine the user click behavior and the purchase activity. The DCMF model is a substantial extension of the collective matrix factorization model used to jointly factorize multiple matrices [4]. Apart from considering the two matrices of click and purchase behavior together as in a CMF model, our model also takes into account the temporal influence of an ad impression/click on conversion. We model the time dependency into the matrix factorization framework to account for the decay in the influence of an ad. An efficient optimization algorithm is devised to solve the problem. Our approach is well suited for an interactive setting where the user preferences and behavior change over time.
Our key contributions can be summarized as follows:
· We propose a dynamic collective matrix factorization (DCMF) approach for conversion prediction, which jointly models the temporal relationships between click events and purchase events in display advertising. It also incorporates the side information of users, ads and items via regression.

875

A d Feature Ads

Item Feature Items

User Feature

Users

Click

Response

Vt-1



Conversion

Response

Pt-1



   (t-1)

 Share 

Item Feature Items

A d Feature
Ads

User Feature Users Click Response
Ct
Conversion Response

   (t)
Timeline

Training
 Vt
Share
 Pt

Prediction Conversion Response

(t+1)

Figure 1: Framework of DCMF approach.

· Our framework is based upon examining the data in time slices to account for the decayed influence of an ad and we use stochastic gradient descent for optimization. This makes the framework well suited for interactive settings as well as large datasets.
· We evaluate the conversion prediction performance of our approach on real-world datasets and show that our model performs better as compared to the several baseline methods.
2. RELATED WORK
Response Prediction. Response prediction in digital marketing has been widely studied in recent years. Most of the prior work focuses on predicting the click-through-rate (CTR) of online ads or other contents [1]. The ultimate goal of display advertising is conversion. However, there are only a few works that investigate the conversion prediction problem [2]. For example, Lee et al. estimated the conversion rate by using the past performance observations along with user, publisher and advertiser data hierarchies [2]. Unlike the existing conversion prediction methods, our approach takes advantage of the click response and side information via the collective matrix factorization technique. The most relevant method in the literature is the hierarchical multitask learning algorithm presented in [3]. It jointly models the conversion, click and unattributed-conversion problems. There are significant differences between [3] and our work. First, we make use of the explicit temporal relationship between click and purchase events, which is ignored in [3]. Second, unlike the multi-task learning model used in [3], we develop a matrix factorization approach.
Temporal Prediction Models. The prediction model considering temporal dynamics was first developed for collaborative filtering in [5]. The idea of using temporal dynamics has been explored in online advertising. Barajas et al. proposed a time series approach for evaluating the effectiveness of display advertising [6]. Most recently, Oentaryo et al. designed a hierarchical importance-aware factorization machine (HIFM) for click response prediction in mobile advertising [7]. It is able to handle the temporal ad response data. Unlike HIFM, our approach aims to tackle the conversion prediction problem, and to model the temporal relationships between click and purchase events.
3. APPROACH
3.1 Modeling Temporal Dynamics
We deal with the conversion prediction problem using the collaborative filtering (CF) technique. The fundamental intuition behind CF is that the "similar" users will have "sim-

ilar" preferences. There has been work on applying the CF technique to conversion prediction [8], but it models the interactions between pages and ads. In our paper, we directly model the relationships between users and ads/items, which enables us to predict the user behaviors. The intuition is that "similar" users are very likely to click "similar" ads and purchase "similar" items. Figure 1 shows our framework.
First, we want to jointly analyze the relational data, i.e., the click response and purchase activities of users. Inspired by the collective matrix factorization (CMF) [4], we factorize the click response matrix (UserAds) and the purchase activity matrix (UserItem) simultaneously.
Secondly, we aim to model the temporal information, which is critical in attributing the conversions to the ad clicks. A key observation is that, the behavior of users may change over time. For example, if a user has already purchased an item in the previous week, it is unlikely that he/she will purchase the same item again in the next week. Therefore, we incorporate temporal information into CMF.
Thirdly, we need to ensure that the latent features of users do not dramatically change in a short period of time, as in reality the user preferences would evolve smoothly. To address this concern, we leverage the latent features of the users learned in time t - 1.
Given T pre-defined time slices t  {1, 2, · · · , T }, we use Ct  RNu×Na and Dt  RNu×Np to denote the click responses and purchase activities from Nu users to Na ads (or Np items) in the time slice t, respectively. By exploiting the temporal relationships between click response and purchase events, we notice that the purchase events in time t + 1 are mainly related to the click events in time t and hence our model needs to account for that. The objective function is:

arg min U t,V t, P t,M

f (U t, V t, P t, M ) =  W Ct

(Ct - U tV tT)

2 F

+(1 - ) W Dt

(Dt - U tP tT)

2 F

+1

U t - U t-1M

2 F

+2(

Ut

2 F

+

Vt

2 F

+

Pt

2 F

+

M

2F),

(1)

where W Ct and W Dt are boolean matrices that indicate the

training samples in Ct and Dt, respectively. U t, V t and P t

are latent factors; M is a transition matrix; denotes the

entry-wise product; , 1 and 2 are trade-off parameters. The first two terms in (1) denote the approximation errors,

and the last four terms are regularizations used to prevent

overfitting. In (1), the smooth transition of user latent

factors are modeled based on the assumption:

U t  U t-1M,

(2)

where U t-1 is the latent features of users learned from the previous time slice t - 1. We assume that the latent features in time t are closely related to the feature in time t-1, which is reasonable in real applications. M is a transition matrix of users' behavior, which tries to capture the mappings between users' behavior in two successive time slices. The intuition is that users' intention on purchasing items should be smoothly transited over time.

3.2 Modeling Side Information
So far, we have seen that the model in (1) is not aware of side information, i.e., the features of users, ads, and items. We can further exploit the additional information to improve the prediction performance. The side information are also particularly useful as the data in conversion and click

876

prediction problems are generally sparse. For example, we do not have any click responses or conversion responses of

where

gradient

is

f M

= -1U (t-1)T(U t - U t-1M ) + 2M .

The above process is repeated until convergence.

some new users, which lead to the cold-start problem. In

this case, the latent features of new users estimated by (1) are not reliable anymore. However, side information provide useful cues from another perspective, and make it possible to learn robust latent features in the cold-start scenario. In

4. EXPERIMENTS
In this section, we evaluate the performance of our approach and baselines on a marketing dataset.

this section, we incorporate the side information into (1), and present the DCMF method.
Let X, Y and Z denote the feature matrices for users, ads and items, respectively. We assume that the click response and purchase activity are generated by the inner product of latent factors, and the side information via linear regression. Thus, the matrix approximation can be written as:

4.1 Data and Settings
To evaluate the performance on conversion prediction, we examine a subset of the marketing data from Oct. 1, 2013  Nov. 30, 2013. The dataset constitutes of behavioral characteristics of 448,158 number of users and 737 ads. Along with the impression records, we also have click and purchase activity information for all the users. We empirically choose

Ct  U tV tT + U^ tY T + XV^ tT, Dt  U tP tT + U^ tZT + XP^tT,

one week as the time window t in our model. To construct

(3)

the binary response tables, we denote the click events and

purchase events as positive responses, and the impressions

where U^ t, V^ t and P^t are regression coefficients on user fea-
tures, ad features and item features, respectively. We treat the three terms used to approximate Ct (or Dt) equally for
simplicity. The performance can be enhanced by assigning

(without any following events) as negative responses. All the other entries are treated as missing values. As the click and purchase are rare events in reality, our data set is extremely sparse. To collect the side information, we select

different weights for them.

some features of users, ads and items, respectively. For each

By replacing the matrix approximations in (1) with (3),

user, we encode the demographic information (e.g., country,

we can then rewrite the objective function as:

state, domain) into a binary valued vector. The attributes

arg

min  W C

U t,V t,P t,M,

(Ct - U tV tT - U^ tY T - XV^ tT)

2 F

U^ t,V^ tP^t
+(1 - ) W D

(Dt - U tP tT - U^ tZT - XP^tT)

2 F

+1 U t - U t-1M

2 F

+

2(

Ut

2 F

+

Vt

2 F

+

Pt

2 F

+

U^ t

2 F

+

V^ t

2 F

+

P^t

2 F

+

M

2F).

(4)

With the learned latent factors, we can predict the con-

version score of user m for item n at time t + 1 as:

of ads (e.g., advertiser, ad size) and items (e.g., type, price) are also encoded into binary vectors, respectively. To conduct fair comparisons, we set up 5 different training/test cases along the timeline. Each training set consists of a click events table and a purchase events table. Each test set only contains a table of purchase events, as our goal is to predict the conversions.
We compare our approach with the following baselines: PMF [9], LIBMF [10], SVDFeature [11], HBMFSI [12], and CMF [4]. For PMF, LIBMF, SVDFeature and HBMFSI, we

Score(m, n, t + 1) = utmptnT + u^tmznT + xmp^tnT, (5) where utm and u^tm are the m-th row of U t and U^ t, ptn and p^tn are the n-th row of P t and P^t, respectively.

only use the purchase data for training, due to the intrinsic limitation of these methods. For CMF and our approach, we use both the click data and purchase data for training. In particular, we use the click events and purchase events

3.3 Optimization

at time t to predict the purchase events in time t + 1 (i.e., Dt+1). Following [3], we use the ROC curve and the area

As the stochastic gradient descent (SGD) algorithm is ef-

under ROC (AUC-ROC) as our evaluation metrics.

ficient in practice, we utilize SGD to solve (4).

For SGD based matrix factorization methods (e.g., PMF,

First, we fix M , and update other variables, U t = {ut1, · · · , utr}, LIBMF, SVDFeature and CMF), the major parameters are

V t = {v1t , · · · , vrt }, P t = {pt1, · · · , ptr}, U^ t = {u^t1, · · · , u^tr},

the learning rate  and the trade-off parameter  for regu-

V^ t = {v^1t , · · · , v^rt }, and P^t = {p^t1, · · · , p^tr}. For simplicity,

larization terms. For Bayesian method HBMFSI, we follow

we use f to denote the objective in (4). After selecting a

the settings in [12]. We sample a validation set from the

pair of random training points Citj and Ditk, we only need to update uti, vjt, ptk, u^ti, v^jt and p^tk using:

training data, and tune these parameters empirically. The parameters , 1 and 2 are set to 0.003, 0.001 and 0.02, respectively. In CMF and our approach, another important

uti

=

uti

-



  uti

f

,

vjt

=

vjt

-



  vjt

f, ptk

=

ptk

-



  ptk

f

,

u^ti

=

u^ti

-



  u^ti

f

,

v^jt

=

v^jt

-



  v^jt

f, p^tk

=

p^tk

-



 p^tk

f

,

(6)

parameter is . To understand its sensitivity, we observe the AUC-ROC of CMF and DCMF approach with various choices of . Figure 2(a) shows the AUC-ROC values in

Case-3. We can observe that our approach is not sensitive

where  is the learning rate. The detailed gradients for each

to the values of . We achieve better performance when 

variable are omitted here due to the space limit.

falls into the range [0.5, 0.8]. In the following experiments,

Next, we fix all the other variables, and update M . By

 is set to 0.6. In addition, the dimension of latent features

ignoring all the irrelevant terms with respect to M , the ob-

is set to 20 for each method. To initialize our approach in

jective (4) reduces to:

Case-1, we borrow the latent factors of CMF learned from

arg min f (M ) = 1 M

U t - U t-1M

2 F

+

2

M

2 F

.

(7)

Oct. 1Oct. 7 as the input U t-1.
4.2 Results and Discussions

We can then update M using:

We evaluate the performance of each compared method

M

=

M

-



 M

f

(M

),

(8)

in 5 training/test splits. Figure 2(b) shows the ROC in

877

0.9

0.8

AUCíROC

0.7

0.6

True Positive Rate (TPR)

0.5

CMF

DCMF

0.4 0.1
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

(a)

PMF [9] LIBMF [10] SVDFeature [11] HBMFSI [12] CMF [4] DCMF (Ours)

0.2

0.4

0.6

0.8

1

False Positive Rate (FPR)

(b)

Figure 2: (a): AUC-ROC of CMF and DCMF in Case-3 with different . (b): ROC curves in Case-1.

Table 1: AUC-ROC of each methods on marketing data.

Method

Case 1 Case 2 Case 3 Case 4 Case 5

PMF [9]

0.729 0.718 0.645 0.712 0.714

LIBMF [10]

0.731 0.719 0.653 0.726 0.723

SVDFeature [11] 0.742 0.729 0.661 0.731 0.732

HBMFSI [12]

0.750 0.737 0.669 0.739 0.741

CMF [4]

0.751 0.746 0.668 0.736 0.737

DCMF (Ours) 0.850 0.851 0.841 0.832 0.837

Case-1, and Table 1 lists the AUC-ROC of all cases. Form Figure 2 and Table 1, we make the following observations: (1) Incorporating side information improves the prediction results significantly. SVDFeature and HBMFSI employ the features of users and items, they achieve much better performance than PMF and LIBMF, which do not utilize any side information. Similarly, our DCMF approach performs very well by virtue of the side information. (2) Modeling click response is helpful in predicting purchase events. CMF and our approach take advantages of the click response information, and they outperform PMF and LIBMF in each case. (3) Temporal dynamics is critical in conversion prediction. Our approach obtains better results than CMF, indicating that the latent features learned from previous time slice are very useful. (4) Our DCMF approach achieves the best results in each case, compared to the baselines. It demonstrates that the side information and temporal information could be complementary to each other in predicting user behaviors such as conversion.

5. CONCLUSIONS
In this paper, we presented a novel matrix factorization approach DCMF for conversion prediction in display advertising. DCMF jointly examines the click events and purchase events in an online learning fashion by leveraging the temporal information and side information. Extensive experimental results on a real-world marketing dataset demonstrate the superiority of our approach over existing methods.
Acknowledgements
This research is supported in part by the NSF CNS award 1314484, ONR award N00014-12-1-1028, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office Young Investigator Award W911NF-14-1-0218.
6. REFERENCES
[1] Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. Laser: a scalable response prediction platform for online advertising. In WSDM, pages 173­182, 2014.
[2] Kuang chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. Estimating conversion rate in display advertising from past performance data. In KDD, pages 768­776, 2012.
[3] Amr Ahmed, Abhimanyu Das, and Alexander J. Smola. Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising. In WSDM, pages 153­162, 2014.
[4] Ajit Paul Singh and Geoffrey J. Gordon. Relational learning via collective matrix factorization. In KDD, pages 650­658, 2008.
[5] Yehuda Koren. Collaborative filtering with temporal dynamics. In KDD, pages 447­456, 2009.
[6] Joel Barajas, Ram Akella, Marius Holtan, Jaimie Kwon, and Brad Null. Measuring the effectiveness of display advertising: a time series approach. In WWW (Companion Volume), pages 7­8, 2011.
[7] Richard Jayadi Oentaryo, Ee-Peng Lim, Jia-Wei Low, David Lo, and Michael Finegold. Predicting response in mobile advertising with hierarchical importance-aware factorization machine. In WSDM, pages 123­132, 2014.
[8] Aditya Krishna Menon, Krishna Prasad Chitrapura, Sachin Garg, Deepak Agarwal, and Nagaraj Kota. Response prediction using collaborative filtering with hierarchies and side-information. In KDD, pages 141­149, 2011.
[9] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In NIPS, 2007.
[10] Yong Zhuang, Wei-Sheng Chin, Yu-Chin Juan, and Chih-Jen Lin. A fast parallel sgd for matrix factorization in shared memory systems. In RecSys, pages 249­256, 2013.
[11] Tianqi Chen, Weinan Zhang, Qiuxia Lu, Kailong Chen, Zhao Zheng, and Yong Yu. Svdfeature: a toolkit for feature-based collaborative filtering. Journal of Machine Learning Research, 13:3619­3622, 2012.
[12] Sunho Park, Yong-Deok Kim, and Seungjin Choi. Hierarchical bayesian matrix factorization with side information. In IJCAI, 2013.

878

