High Quality Graph-Based Similarity Search
Weiren Yu, Julie A. McCann
Imperial College London, United Kingdom
{weiren.yu, j.mccann}@imperial.ac.uk

ABSTRACT
SimRank is an influential link-based similarity measure that has been used in many fields of Web search and sociometry. The best-of-breed method by Kusumoto et al. [7], however, does not always deliver high-quality results, since it fails to accurately obtain its diagonal correction matrix D. Besides, SimRank is also limited by an unwanted "connectivity trait": increasing the number of paths between nodes a and b often incurs a decrease in score s(a, b). The best-known solution, SimRank++ [1], cannot resolve this problem, since a revised score will be zero if a and b have no common in-neighbors.
In this paper, we consider high-quality similarity search. Our scheme, SR#, is efficient and semantically meaningful: (1) We first formulate the exact D, and devise a "varied-D" method to accurately compute SimRank in linear memory. Moreover, by grouping computation, we also reduce the time of [7] from quadratic to linear in the number of iterations. (2) We design a "kernel-based" model to improve the quality of SimRank, and circumvent the "connectivity trait" issue. (3) We give mathematical insights to the semantic difference between SimRank and its variant, and correct an argument in [7]: "if D is replaced by a scaled identity matrix (1 - )I, top-K rankings will not be affected much". The experiments confirm that SR# can accurately extract high-quality scores, and is much faster than the state-of-the-art competitors.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval
Keywords
Link Analysis; Graph-Based Similarity; High Quality Search
1. INTRODUCTION
The Web today is a huge, self-organized, and hyperlinked network. These salient features bring striking challenges to data management, and call for new search abilities to extract meaningful knowledge automatically from the gigantic Web. Link-based similarity search is a modern means to quantify
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. SIGIR'15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767720.

node-to-node relationships based on graph topologies, with a wide range of successful applications, e.g., link prediction, collaborative filtering, and co-citation analysis.
SimRank, conceived by Jeh and Widom [5], is one of the most influential similarity measures. The central idea underpinning SimRank is a simple recursion that "two nodes are assessed as similar if they are in-linked from similar nodes". For a digraph G = (V, E) with |V | nodes and |E| edges, let Na = {x  V |(x, a)  E} be the in-neighbor set of node a. Then, SimRank score between nodes a and b is defined by1

1

(a = b)

s(a, b) =

·

(i,j)Na ×Nb s(i,j) |Na ||Nb|

(a = b)

(1)

where   (0, 1) is a decay factor. Generally,  = 0.6 [12] or 0.8 [5], which penalizes long paths relative to short ones.
In contrast with other similarity measures, SimRank has the following prominent features: (a) It takes a concise form that captures both direct and indirect neighbors recursively, unlike Bibliographic Coupling and Co-citation that focus only on direct neighbors. (b) It considers structural equivalence of two nodes, whereas Personalized PageRank focuses on reachability from every node to a query. Therefore, SimRank has attracted increasing attention in recent years [3, 4, 12].

1.1 The Quality of SimRank Search
Despite much effort devoted to fast SimRank computation (e.g., [2, 7, 8, 12, 13]), the quality of SimRank search is still less desirable, due to the following two reasons:
(1) Superfluous Diagonal Correction Error diag. The best-of-breed SimRank method by Kusumoto et al. [7] is based on the following "linearized SimRank formula":

s(a, b) = ea Deb + (P ea)D(P eb) + 2(P 2ea)D(P 2eb) + · · · (2)

where D is a precomputed diagonal correction matrix, ea is a unit vector with a 1 in the a-th entry, and P is the column

normalized adjacency matrix, with Pa,b =

1/|Nb|, if (a,b)E; 0, if (a,b)/E.

According to [7], before Eq.(2) is computed, D requires

to be determined in advance. However, it is too difficult to

compute the exact D (not to mention within linear memory)

since SimRank results have a recursive impact on D. Note

that even Kusumoto et al. [7] have not obtained the exact D,

but simply approximated D by D~ := (1-)I. Consequently,

the diagonal correction error is produced:

diag := |s(a, b) - sD~ (a, b)|,

(3)

1To avoid division by 0 in Eq.(1), s(a, b) = 0 if |Na||Nb| = 0.

83

11

12 7

s(1, 2) s(4, 5) s(2, 8) s(8, 10) s(3, 9) SR 0.24 0.30 0.12 0.18 0.30

SR++ 0.20 0.23

0

0

0.15

RS 0.34 0.24 0.05 0.07 0.12

SR# 0.38 0.24 0.14

0.10

0.17

4

6

359

1

2 8 10

SR SR++ RS SR#
s(1, 2) > s(4, 5)     s(2, 8) > s(8, 10)     s(4, 5) > s(3, 9)    

Figure 1: SimRank++ (SR++) and RoleSim (RS) may not resolve the "connectivity trait" problem of SimRank (SR)

where sD~ (a, b) is the estimated similarity when D is replaced by D~ in Eq.(2). After D is estimated, [7] uses an iterative method that sums up only the first k terms of series sD~ (a, b), denoted as s(D~k)(a, b). This yields the iterative error :

iter

:=

|sD~ (a, b) - sD(~k)(a, b)|



. k+1
1-

Hence, the total error in a nutshell, consists

for of

approximating s(a, b) two ingredients: diag

abnyds(D~kit)e(ra. ,

b),

We argue diag is far more serious than iter, because iter

is guaranteed to converge by [7], and can be minimized by

increasing the number of iterations. This increase, however,

cannot minimize diag. Worse still, there is no bound on

diag for Eq.(3). The only argument about diag in [7] is that "estimating D as D~ := (1 - )I does not much affect the

top-K rankings of sD~ (, ) and s(, )", but this, as will be shown in Section 4.1, bears a blemish.

This motivates us to design an accurate and fast approach

that has no diag and can avoid computing the exact D.

(2) "Connectivity Trait" Problem. Another factor that plagues the quality of SimRank is the "connectivity trait": increasing the number of paths between nodes a and b often incurs a contrary decrease in s(a, b). However, a paucity of existing works [1, 2, 11] only noticed a special case (1hop neighbor) of the above phenomenon: "increasing the number of common in-neighbors between nodes a and b will decrease s(a, b)." The best-known treatment is due to Antonellis et al. who proposed SimRank++ [1] that replaces  in Eq.(1) with the following "evidence factor":

~ := (1 - e-|NaNb|)

or

~ := 

|NaNb| 1

i=1

2i

(4)

These revised "evidence factors" have a good property: ~ is

increasing with respect to |Na Nb|. Hence, a larger ~ means that there are more common direct in-neighbors (i.e., more

paths of length 2) between a and b.

However, we observe a weakness of SimRank++ [1]: Sim-

Rank++ score s~(a, b) is always zero if nodes a and b have no

common (direct) in-neighbors. This is because, by the defini-

tion in Eq.(4), if Na Nb = , then ~ = 0. Thus, s~(a, b) = 0, regardless of how many common l-hop in-neighbors (l > 2) exist between a and b.

Other pioneering works (e.g., RoleSim [6], PSimRank [2],

and MatchSim [11]) to quantify s(a, b) also resort to common

direct in-neighbors between a and b, all of which can resolve

the special case (1-hop) of the SimRank "connectivity trait" problem (see related work in Section 1.3.2 for more details).

However, increasing the number of paths with length > 2

between a and b may still lead to a decrease in s(a, b).

Example 1. Consider a real Web graph G in Figure 1. We evaluate the similarity of each node-pair by 4 measures: (a) SR (Jeh and Widom's SimRank [5]); (b) SR++ (SimRank++ [1]); (c) RS (RoleSim [6]); (d) SR# (our method).

The results are partly depicted in the table. We notice that SR++ and RS do not well resolve the SR "connectivity trait".
For example, most people may agree s(1, 2) > s(4, 5) since node-pair (1, 2) has 3 common in-neighbors {4, 6, 3} whereas (4, 5) has only 2 in common {11, 12}. However, although SR++ narrows the gap between s(1, 2) and s(4, 5), it gives the same counter-intuitive answer s(1, 2) < s(4, 5) as SR.
Another example is the comparison of s(2, 8) and s(8, 10). For SR++, s(2, 8) = s(8, 10) = 0. This is because (2, 8) has no common direct in-neighbors, N2  N8 = ; neither has (8, 10). Thereby, their "evidence factors" ~ = 0. However, there are 4 indirect path-pairs in-linked from (2, 8):
2  4  11  5  8, 2  3  11  5  8
2  4  12  5  8, 2  3  12  5  8
as opposed to only 1 from (8, 10): 8  5  12  9  10. Thus, node-pair (2, 8) has a higher connectivity than (8, 10), but this connectivity trait is ignored by SR++. Regarding RS, since it is a "role" similarity measure, it emphasizes more on similar node degrees than high connectivities. Thus, RS can only partially resolve the SR "connectivity trait" problem.
Example 1 suggests that the state-of-the-art methods (e.g., SimRank++ [1] and RoleSim [6]) cannot solidly circumvent the "connectivity trait" problem of SimRank. Unfortunately, as illustrated by our statistical experiments in Section 5.2, there are many node-pairs suffering from this problem (e.g., 62.3% in social networks, 82.7% in Web graphs, and 56.4% in citation graphs), which has adversely affected the quality of similarity search. This highlights our need for a high-quality model to resolve the "connectivity trait" problem.
1.2 Our Contributions
Our main contributions are summarized as follows:
· We formulate the exact diagonal correction matrix D, and propose a "varied-D" method to accurately compute SimRank with no diag and in linear memory. Moreover, by grouping computation, we also optimize the algorithm [7] from quadratic to linear time w.r.t. k. (Section 2)
· We observe a "connectivity trait" problem for SimRank, which SimRank++ [1] cannot resolve in a recursive style. To circumvent this problem, we design a "kernel-based" model and improve the search quality. (Section 3)
· We give mathematical insights to the semantic difference between Jeh and Widom's model [5] and its variant [9], and correct an argument [7]: if D is replaced by (1 - )I, top-K rankings will not be affected much. (Section 4)
The comprehensive experiments verify that our methods (1) improve an accuracy of average NDCG200 by 30% over SimRank on various real networks, and (2) are 10x faster than the state-of-the-art competitors on large datasets with 65.8M links for 1000 queries.
1.3 Related Work
1.3.1 SimRank Computation
Recent years have witnessed a surge of efficient methods to compute SimRank. They can be categorized as follows:
· Single-source SimRank [3, 7, 8]. Compute all s(i, ).
· All-pairs SimRank [9, 12, 13, 16]. Compute all s(, ).
· Single-pair SimRank [2, 7, 10]. Compute s(i, j).

84

Type single source
all pairs

Algorithm Proposed
Kusumoto et al. [7]
Fujiwara et al. [3] Lee et al. [8] Proposed
Kusumoto et al. [7]
Yu et al. [13] Lizorkin et al. [12] Yu et al. [16] Li et al. [9] Jeh et al. [5]

Error

 k+1

k+1 1-

+ diag

rank-r + diag  k+1

 k+1
k+1
1-
 k+1  k+1

+ diag

rank-r + diag

rank-r + diag  k+1

Time
O(k|E|)
O(k2 |E |) O(r|V |2) O(d2k )
O(k|V ||E|)
O(k2|V ||E|) O(kd|V |2) O(k|V ||E|) O(r|V |2) O(r4|V |2) O(k|E|2)

Memory O(|E| + k|V |)
O(|E| + |V |) O(r|V |2) O(d2k + |V |) O(|E| + k|V |)
O(|E| + |V |) O(|V |2) O(|V |2) O(|V |2) O(r2|V |2) O(|V |2)

Table 1: A comparison with previous deterministic methods

(with

low-rank

r



|V |,

degree

d

=

|E| |V |

,

and

d



d)

In Table 1, we briefly summarize the accuracy, time, and memory of previous works for each type of SimRank search.
Compared with the best-known method [7], our techniques not only well preserve the scalability of [7], but also achieve high accuracy and fast computational time. Furthermore, for high accuracy, our methods not only remove superfluous error diag but also attain a better bound on iter than [7].

1.3.2 SimRank "Connectivity Trait"

Fogaras et al. [2] is the first to notice one special case of the

SimRank "connectivity trait" problem: "if two nodes a and

b have  common (direct) in-neighbors, then s(a, b)  1/."

To address this problem, they employed an unwieldy method

that divides the entire search space into three probabilities:

, |Na Nb |
|Na Nb|

, |Na -Nb |
|Na Nb|

and

. |Nb -Na |
|Na Nb |

However, this complicates

the revised SimRank equation, which is rather tedious.

Recently, Antonellis et al. [1] gave an excellent revision,

called SimRank++, by introducing the "evidence factor" ~.

Unfortunately, ~ can only, in part, alleviate a special case

of the "connectivity trait" problem, since, if |Na  Nb| = 0,

then ~ = 0 has no recursive impact on SimRank any more.

Jin et al. [6] also gave an excellent exposition on "role

similarity". Their proposed model, namely RoleSim, has the

advantage of utilizing "automorphic equivalence" to improve

the quality of similarity search in "role" based applications.

Their initial intention, however, was not to deal with the

SimRank "connectivity trait" problem.

There is also a SimRank-like "connectivity trait" prob-

lem in other SimRank variant models, such as MatchSim,

SimRank*, SimFusion+ [15]. Our proposed methods for

SimRank are also extensible to SimRank*. Due to space

limitation, we omit it in this paper.

1.3.3 Semantics between SimRank and Its Variant
There are some interesting works (e.g., [3, 4, 9, 14, 17]), based on the following model, to evaluate similarity S~:

S~ = P S~P + (1 - )I.

(5)

[7] argued that "the top-K rankings of S~ in Eq.(5) and S in Eq.(1) are not affected much". However, we correct this argument, and provide new mathematical insights into the subtle difference of S~ and S from a semantic perspective.

2. ACCURATE AND FAST SIMRANK
We first show the sensitivity of diagonal correction matrix D to SimRank matrix S, and formulate the exact D. Then, we devise an accurate fast "varied-D" model to compute S.

2.1 Sensitivity of Diagonal Correction Matrix
In matrix forms, SimRank in Eq.(1) can be rewritten as

S = max{P SP, I},

(6)

where max{} denotes the matrix entry-wise maximum, i.e.,
(max{A, B})i,j = max{Ai,j , Bi,j }. Kusumoto et al. [7] have showed that there exists a unique
diagonal matrix D such that Eq.(6) can be converted to

S = P SP + D,

(7)

where D is called the diagonal correction matrix, which needs

to be determined beforehand.

However, [7] did not mention how to accurately compute

the exact D, but simply approximated D by D~ = (1 - )I.

In fact, D is very sensitive to the resulting S. Even small

errors in D may lead to large changes in SimRank scores S

by

a

factor

of

up

to

1 1-

,

as

shown

in

Lemma

1.

Lemma 1. Let S be the solution to Eq.(7), and SD~ be the solution to the equation:

SD~ = P SD~ P + D~ ,

(8)

and let D := D - D~ and S := S - SD~ . Then,

S

max



1 1-

D max. 2

(9)

Proof. The recursion of SD~ in Eq.(8) naturally leads to the following series:

SD~ = D~ + P D~ P + 2(P )2D~ P 2 + · · · ,

(10)

We subtract Eq.(10) from Eq.(2), and then take  max

norms on both sides:

 D max

S max  D max +

 i=1

i

(P )iD(P i) max

 (1 +  + 2 + · · · )

D

max

=

1 1-

D

max .

2.2 Formulating Diagonal Correction Matrix
We next derive an exact explicit formulation of D in Eq.(7). For ease of exposition, the following notations are adopted.

Definition 1 (Entry-Wise Product). For matrices X and Y , their entry-wise product X  Y is defined as
(X  Y )i,j = Xi,j Yi,j .

Let diag(Z) be a diagonal matrix whose diagonal entries
are those of Z, i.e., (diag(Z))i,i = Zi,i. Using this notation, Eq.(6) can be represented as

S = P SP + I - diag(P SP ).

(11)

Due to D uniqueness, Eqs.(7) and (11) imply that

D = I - diag(P SP ).

(12)

To formulate the exact D in Eq.(12) only in terms of P , we introduce the following lemma.
Lemma 2. Let -d-iag(Z) be a column vector of the diagonal entries of Z, i.e., (-d-iag(Z))i = Zi,i. For two n × n matrices X and Y , and an n × n diagonal matrix Z, we have
-d-iag(XZY ) = (X  Y )-d-iag(Z).

2  max returns the maximum element of a matrix.

85

Combining Lemma 2 with Eq.(12), we next formulate D.

Theorem 1. The diagonal correction matrix D in Eq.(7) can be explicitly formulated as

-d-iag(D) =

+ k=0

k(P k



P k)

-1,

(13)

where 1 is a |V | × 1 vector of all 1s, and ()- := (())-1. Proof. Taking -d-iag() on both sides of Eq.(2) produces

-d-iag(S) = -d-iag(D) + -d-iag(P DP ) + 2-d-iag((P )2DP 2) + · · · (14)

By

SimRank

definition --

Eq.(6),

we

have

Si,i

=

1

(i



V

),

which implies that diag(S) = 1.

Applying Lemma 2 to the right-hand side of Eq.(14) yields

1 = I + (P  P ) + 2(P 2  P 2) + · · · -d-iag(D), (15)

Since 0  (P  P )i,j  Pi,j  1, one can readily show that (I + (P  P ) + 2(P 2  P 2) + · · · ) is diagonally dominant.
Multiplying both sides by its inverse produces Eq.(13).

Theorem 1 characterizes the exact D as an infinite series. Hence, prior to computing S, it is too difficult to obtain the exact D in only a finite number of iterations. This tells us that using the method of [7] will innately produce diag.
Theorem 1 also implies that the estimation D  (1-)I in [7] is not appropriate for accurately computing S in Eq.(7). This is because replacing (P k  P k) by P k in Eq.(13) yields

-d-iag(D) 

+ k=0

kP

k

-1 = (I - P )1 = (1 - )1,

which suggests that the approximation D  (1 - )I in [7] is equivalent to the approximation P kP k  P k. Clearly, most people will not agree that ((P k)i,j )2  (P k)i,j is reasonable. In Section 4.2, we will further discuss D  (1 - )I from the viewpoint of semantics.
One benefit of Theorem 1 is that it narrows the boundaries for the range of D in [7], based on the following corollary.

Corollary 1. (1 - )I  D  I - diag(P P ) 3

Proof. Since 0  Pi,j  1, we can readily show that (P  P )k  (P k  P k)  P k.

Applying this to Eq.(13) yields

+ k=0

kP

k

-1  -d-iag(D) 

+ k=0



k

(P

 P )k

-1.

Since -d-iag(D)

+ k=0

X

k

=

 I - (P

(I - X)-1, it follows that  P ) 1. Then, applying

I - P Lemma

1  2 on

both sides, we obtain the results.

In comparison, the best-known bounds for the range of D in Proposition 2 of [7] (i.e., (1 - )I  D  I) are loose, and independent of P , which is isolated from graph structures.
2.3 A "Varied-D" Iterative Model
Another important consequence of Theorem 1 is to derive an accurate SimRank algorithm without diag.
Instead of determining the exact D in advance, our method is to iteratively update D and S at the same time. Precisely, we leverage the "varied-D" SimRank model as follows:
S(k) := Dk + P Dk-1P + · · · + k(P )kD0P k, (16)
3For matrices A and B, A  B refers to Ai,j  Bi,j , i, j.

where {Dk} is a diagonal matrix sequence (convergent to D), which can be iteratively obtained while S is being iterated.
Different from the model Eq.(2) by Kusumoto et al. [7], our "varied-D" model Eq.(16) replaces all Ds by a convergent sequence {Dk}. The main advantage of our replacement is that Eq.(16) can avoid determining the exact D beforehand, and thereby, will not produce the superfluous error diag.
The correctness of our "varied-D" model can be verified by taking limits k   on both sides of Eq.(16). As k  , Dk  D and S(k)  S.4 Thus, Eq.(16) converges to Eq.(2).

2.3.1 Finding Dk in "Varied-D" Model
The challenging problem in our "varied-D" Eq.(16) is to determine the diagonal matrix Dk. Our main idea is based on two observations: (a) S(k) in Eq.(16) can be iterated as

S(l) = P S(l-1)P + Dl with S(0) = D0.

(17)

(b) To ensure diag(S(l)) = I, Dl in Eq.(17) must satisfy

Dl = I - diag(P S(l-1)P ).

(18)

Coupling these observations, we can compute Dk in Eq.(16).

Theorem 2. The diagonal correction matrices in Eq.(16) can be iteratively obtained as follows:

(Dk)i,i = 1 -

k l=1

(hl



hl)-d-iag(Dk-l)

with

D0 = I,

(19)

where the auxiliary vectors h1, · · · , hk are derived from

h0 hl

= =

ei

P

hl-1

(l = 1, 2, · · · , k)

(20)

Proof. First, we derive a complete matrix formula of Dk. By Lemma 2, Eq.(19) can be converted to

(Dk)i,i = 1 -

k l=1

hl



Dk-l

hl

(21)

Successive substitution applied to Eq.(20) yields hl = lP lei. Then, substituting this back into Eq.(21) produces

Dk = I -

k l=1

ldiag

(P l)Dk-l(P l)

(22)

Next, we show that Dk in Eq.(22) satisfies Eqs.(16)­(18). It follows from Eq.(16) that

diag(P S(k-1)P ) = diag( = diag(

k-1 l=0

 l+1 (P

l+1 ) Dk-1-l P

l+1)

k l=1

l(P

l)Dk-lP

l).

Thus, the above equation implies that

I - diag(P S(k-1)P ) = I -

k l=1

ldiag

(P l)Dk-l(P l)

Applying Eq.(22) to the right-hand side yields Eq.(18).

Theorem 2 provides a simple efficient way to compute Dk.

Algorithm 1: Compute Diagonal Matrix Dk

1 initialize t := 0, h0 := ei, D0 := I ;

2 3
4

for l := 1, 2, compute
update t

:·h=·l·:t=, +kd(holPhhl-l)1;-d-iag(Dk-l)

;

5 return (Dk)i,i := 1 - t ;

The correctness of Algorithm 1 is verified by Theorem 2. Regarding complexity, we have the following result.
4The convergence of S(k) will be proved in Section 2.3.2.

86

Theorem 3. Given the total iteration number k = 1, 2, · · · , Algorithm 1 is in O(k|V |) memory and O(k(|E|+|V |)) time.

In contrast to the linear-memory SimRank method in [7], Theorem 3 implies that our "varied-D" method to compute Dk will not compromise the scalability of [7] for high quality search, since Dk can be computed in linear memory as well.

2.3.2 Fast Convergence of "Varied-D" Model
Besides no diag and no need to precompute the exact D, our "varied-D" model Eq.(16) also converges faster than [7].

Theorem 4. Let S(k) and S be the k-th iterative and the exact SimRank in Eqs.(16) and (7), respectively. Then,

S(k) - S max  k+1.

(23)

Proof. We subtract Eq.(7) from Eq.(17) to obtain, k,

S(k) - S = P (S(k-1) - S)P + (D(k) - D).

(24)

We notice from Eq.(18) that (S(k))i,i = Si,i = 1, i  V . Thus, when i = j, it follows from Eq.(24) that, i, j  V ,

(S(k) - S)i,j = (P )i,(S(k-1) - S)P,j .

(25)

  S(k-1) - S max  · · ·  k I - S max

By Eq.(1), I - S max  . Thus, Eq.(23) holds.

In comparison to the bound

k+1 1-

(see Eq.(10) of [7]),

Theorem 4 shows that our "varied-D" model not only elim-

inates diag, but also has a better bound on iter than [7].

Thus, our "varied-D" model achieves both high-quality and

fast convergence rate at the same time.

2.4 Efficiently Computing S(k)
Having determined Dk in our "varied-D" model Eq.(16), we next propose our method to efficiently compute S(k).
The method [7] requires O(k2|E|) and O(k2|V ||E|) time, respectively, to compute single-source and all-pairs SimRank. If we merely apply the method [7] and replace D with Dk, then our "varied-D" Eq.(16) to compute S(k) will retain the same complexity as [7] except with no diag, as follows:

Procedure 2: Single-Source "Varied-D" SimRank(i)

1 initialize h := 0, x := ei ;

2 for l := 0, 1, · · · , k do

3

update h := h + l(P )l(Dk-l)x, x := P x ;

4 return (S(k))i, := h ;

However, we observe that there exist many duplicate products in [7]. Precisely, to obtain the result of the sums

(S(k))i, = Dkx0 + P Dk-1x1 + · · · + k(P )kD0xk, (26)

the method [7] separately computes every l(P )l(Dk-l)xl

and then adds them together. Its main limitation is that,

to compute any power of (P ), [7] has to go through all of

the previous powers from scratch. As a result, there are l

matrix-vector products to compute each h in Line 3, leading

to

k l=1

l

=

O(k2)

products

for

k

iterations

in

total.

We now propose an efficient method for Procedure 2, which

reduces O(k2|E|) to O(k|E|) time, with no loss of accuracy.

Our key observation is that "doing each matrix-vector mul-

tiplication separately is equivalent to multiplying a matrix

x1

xn

... ...

...

a

b

Figure 2: SimRank "Connectivity Trait" Problem

by a group of the resulting vectors added together". Hence, we rearrange the computation of Eq.(26) as follows:

(S(k))i, = Dkx0 + P (Dk-1x1 + P (Dk-2x2 + · · · · · · + P (D1xk-1 + P (D0xk)))) (27)

and obtain the result by starting with the innermost brackets and working outwards. In contrast with the method [7], Eq.(27) has only O(k) matrix-vector products in k brackets, as opposed to O(k2) products in Procedure 2.
Based on Eq.(27), we give an efficient way of Procedure 2.

Algorithm 3: Optimized Single-Source SimRank(i)

1 initialize x0 := ei ; 2 for l := 1, 2, · · · , k do

3

update xl := P xl-1 ;

-- 4 initialize y0 := diag(D0)  xk ;

5 6

for

l := 1, 2, · update yl

:·=· ,-dk-iadgo(Dl

)



xk-l

+

P yl-1

;

7 return (S(k))i, := yk ;

Algorithm 3 can reduce not only the time of single-source SimRank from O(k2|E|) [7] to O(k|E|), but also the time of all-pairs SimRank from O(k2|V ||E|) [7] to O(k|V ||E|), since all-pairs SimRank runs |V | times of single-source SimRank.

3. ENHANCING SIMRANK QUALITY
After the superfluous diag is avoided, we next focus on the "connectivity trait" problem of SimRank.

3.1 The "Connectivity Trait" Problem

We observe that the root cause of the "connectivity trait"

problem

is

that

the

order

of

the

normalized

factor

1 |Na ||Nb |

in the SimRank definition Eq.(1) is too high. To clarify this,

let us consider the following situation in Figure 2:

Let  be the number of paths {a  x  b} to be inserted

between nodes a and b. By SimRank definition Eq.(1), after

insertions, s(a, b) will become a function of :

s(a, b) =  ·

|Na Nb |+ (|Na |+)(|Nb |+)

·

 2

 0.

(  ) (28)

This

suggests

that,

for

large

,

s(a, b)

behaves

like

(

·

1 

),

which is eventually decreasing w.r.t. .

3.2 Our Kernel-Based SimRank Model

To avoid the order inconsistency between denominator

and numerator in Eq.(28), our goal is to judiciously adjust

the

order

of

1 |Na ||Nb|

while

normalizing

s(a, b)

correctly.

Definition 2. Let A be an adjacency matrix. The "cosinebased" SimRank S^a,b between a and b is defined by


S^a,b = (1 - ) k
k=0

ea (Ak)Akeb Akea 2 Akeb

2

,

(29)

where x 2 :=

i |xi|2 denotes the L2-norm of vector x.

87

To prevent division by zero in Eq.(29), we define the k-th
term of the sums to be 0 if (Ak),a or (Ak),b = 0. Our cosine-based SimRank S^a,b integrates weighted cosine
similarities between a's and b's multi-hop in-neighbor sets.
This can be seen more clearly when we rewrite Eq.(29) as

S^a,b = (1 - )  k(Akea, Akeb)
k=0

with (x, y) :=

. x y
x2 y 2

(30)

We call (x, y) a kernel similarity function. In Definition 2,
we take (x, y) as the well-known cosine similarity function. The vector Akea (resp. Akeb) in Eq.(30) collects the information about k-hop in-neighbors of node a (resp. b). Hence, the term (Akea, Akeb) in Eq.(30) evaluates how similar node a's and b's k-hop in-neighbor sets are likely to be in terms of
the number of length-k paths in-linked from both a and b. The factor k penalizes connections made with distant k-hop in-neighbors, and (1 - ) normalizes S^a,b into [0, 1]. Thus, S^a,b not only distills the self-referentiality of SimRank, but also extends a one-step cosine similarity to a multi-step one.

Theorem 5. The cosine-based SimRank model in Eq.(29) can circumvent the SimRank "connectivity trait" problem.
Proof. Let hopk(x) = {i  V |(Akex)i > 0} be the k-hop in-neighbor set of node x. Then, we have

ea (Ak)Akeb = |hopk(a)  hopk(b)|, Akea 2 = ea (Ak)Akea = |hopk(a)|.

Plugging these into Eq.(29) produces


S^a,b = (1 - ) k
k=0

|hopk(a)  hopk(b)| . |hopk(a)| · |hopk(b)|

(31)

When inserting the following  paths between a and b:

a    · · ·        · · ·    b (32)

k1 edges

k2 edges

we notice that, only for k1 = k2, the k1-th term of the series Eq.(31) will be changed to a function of :

f () = k1  |hopk1 (a)hopk1 (b)|+

.

(|hopk1 (a)|+)·(|hopk1 (b)|+)

( > 0)

To show f () increases w.r.t. , we take log() on both sides, and then use implicit differentiation w.r.t.  on both sides:

f () = f ()

- - 1
|hopk1 (a)hopk1 (b)|+

1 2(|hopk1 (a)|+)

1 2(|hopk1 (b)|+)

.

Since f () |hopk1 (b)| 

> 0 and |hopk1 (a)|  |hopk1 (a)  hopk1 (b)|,

|whoepcka1n(ao)btahionpkf1

(b)| ()

and > 0.

Thus, f () increases w.r.t. , which implies that paths (32)

insertion will not decrease S^a,b.

Indeed, by using P eb = Aeb/ Aeb 1 5 to the original SimRank Eq.(2), we notice that both Eqs.(2) and (29) tally the

same paths in-linked from a and b. The difference is norms

 2 and  1 used by Eq.(29) and Eq.(2)6, respectively.

Since the SimRank "connectivity trait" problem is due to

the

high

order

of

1 |Na ||Nb |

in

Eq.(1),

it

is

reasonable

for

us

to prevent its high order by replacing  1 with  2 since

x 2  x 1. Moreover, by using  2, S^a,b can be correctly

normalized into [0, 1]. This is because (, )  [0, 1], which

indicates that 0  S^a,b  (1 - )

 k=0

k



1

in

Eq.(30).

5 6

x1 P is

:= i |xi| associated

denotes the L1-norm

with

1 |Na ||Nb |

(=

P ea

of
1 1

vector

P eb

)
1

x. in

Eq.(1).

Example 2. Recall the  paths {a  x  b} to be added into G in Figure 2. After insertion, S^a,b() in Eq.(29) can
circumvent the "connectivity trait" problem. This is because

Aea = (1, 1, · · · , 1, 0, 0, · · · 0, 1, 1, · · · , 1)

|Na |

|Nb-Na |



Aeb = (0, 0, · · · 0, 1, 1, · · · , 1, 1, 1, · · · , 1)

|Na -Nb|

|Nb |



Then, we have (Aea)Aeb = |Na  Nb| +  and

Aea 2 = 12 + · · · + 12 + 12 + · · · + 12 = |Na| + ,

|Na |



Therefore, it follows from Eq.(29) that

Aeb 2 = |Nb| + 

S^a,b()

=

(1 - )

·

 |NaNb|+
|Na |+ |Nb|+



(1 - )

(  ) (33)

Comparing this with Eq.(28), S^a,b() is not eventually decreasing w.r.t. , which is due to norm  2 used in Eq.(29).

In contrast to SimRank++ [1] and PSimRank [2] whose
revised weight factors rely only on common Na and Nb, our method Eq.(29), even if Na  Nb = , can evaluate s(a, b) from common multi-hops neighbors hopk(a)  hopk(b).
To compute the cosine-based SimRank score S^a,b, if a = b, Eq.(29) implies S^a,b = 1. If a = b, we compute S^a,b as

S^a(k,b) = S^a(k,b-1) + (1 - )k(u(k))v(k) with S^a(0,b) = 0 (34)

where the auxiliary vectors u(k) and v(k) are obtained by

u(0) = ea

u = (k)

Au(k-1)

Au(k-1) 2

v(0) = eb

v = (k)

Av(k-1)

Av(k-1) 2

(35)

Eqs.(34)­(35) provide an algorithm to compute S^a(k,b), which is in O(k|E|) time and O(|E|+k|V |) memory for k iterations.

4. SEMANTIC DIFFERENCE
Apart from Jeh and Widom's SimRank model [5]:

S = max{P SP, I},

(36)

recent years have witnessed many studies (e.g., [3, 4, 9, 14]) to compute similarity, based on Li et al.'s model [9]:

S~ = P S~P + (1 - )I.

(37)

In this section, we explore their relationship from a semantic perspective, and correct two arguments in [9] and [7].

4.1 A Fly in the Ointment of [7, 9]
There are only two works [7, 9] that have mentioned the relationship between S~ and S. (a) Li et al. [9] argued that "S~ affects only the absolute similarity value of S, but not the relative similarity ranking of S." (b) The recent work by Kusumoto et al. [7] states that "S~ does not much affect the top-K ranking of S. 7" However, either of them implies a limitation, as disproved by the following counterexample.

Example 3. Consider graph G in Figure 3, for  = 0.6, the top-10 similarity rankings by S and S~ are shown in part:

node pairs (3, 3) (6, 6) . . . (1, 2) (7, 8)

rank by S 1

1 ... 9

9

rank by S~ 4

3 . . . 10

9

7In essence, S  S~ is equivalent to D  (1 - )I.

88

1

7

4

3

6

5

2

8

Figure 3: A Citation Graph (A Counterexample)

From the table, we can discern the following: (a) S~ does not preserve the relative similarity rankings of S; (b) At least 4 out of top-10 rankings of S are affected by S~.
Thus, neither of the statements by [7, 9] is correct.

4.2 Semantic Relationship Between S and S~
To "rekindle" the semantic relationship between S and S~, let us first introduce the following notation:

Definition 3 (Off-diagonal Operator). For square matrix X, let ()off be a matrix operator defined by
(X)off := X - diag(X).
This notation is introduced to bring new insights into S.

Theorem 6. The similarity S in Jeh and Widom's model Eq.(36) can be characterized as follows:
S =I + (P P )off + 2(P (P P )offP )off + · · · + + k (P  · · · (P (P P )offP )off · · · P )off + · · · (38)
k nested ()off

Proof. Applying ()off, Eq.(36) can be iterated as

Sk = (P Sk-1P )off + I.

(39)

We now construct the iterations: starting with R0 = I, Rk = k (P  · · · (P (P P )offP )off · · · P )off +Rk-1. (40)

k nested ()off

Using induction on k, we next show that Sk = Rk (k). Clearly, S0 = I = R0. Assume Sk = Rk holds, we consider

Sk+1 = (P SkP )off + I

(using the hypothsis Sk = Rk)

= k+1 P (P  · · · (P P )off · · · P )offP off + (P Rk-1P )off + I

k nested ()off

={using Eq.(39)}

= k+1 P (P  · · · (P P )off · · · P )offP off +Rk = Rk+1.

(k+1) nested ()off

By Theorem 6, S in Eq.(36) is the weighted sums of

(P  · · · (P (P P )offP )off · · · P )off

k = 1, 2, · · · (41)

k nested ()off

In contrast, S~ in Eq.(37) is the weighted sums of the terms

(P  · · · (P (P P )P ) · · · P ) k = 1, 2, · · · (42)

k nested brackets
To find out the semantic difference between S and S~, we merely need to compare the paths tallied by (41) and (42):

Theorem 7. Given a graph G, the terms in Eq.(41) tally the following paths in G:

x0  x1  · · ·  xk-1  xk  xk+1  · · ·  x2k-1  x2k (43)

k edges

k edges

k=0

k=1

k=2

...

Li et al.'s SimRank
Variation S~k



  

... i (j) i j i (j) i j i j i (j) i (j)

Jeh and

Widom's

SimRank Sk

i (j)

ij

... ij

Figure 4: Different Paths Tallied by S and S~

where x0, · · · , x2k can be any nodes, but with no repetition of nodes xi and x2k-i allowed, i  {0, 1, · · · , 2k} - {k}.
In comparison, the terms in Eq.(42) tally the paths of (43) in G without having such a constraint on nodes xi and x2k-i.
Proof. By the power property of the adjacency matrix, (P k)P k i,j tallies the paths of (43) between i and j.
To show the terms in Eq.(41) tally the paths of (43) with the additional constraint, we use induction on k as follows.
When k = 1, ((P P )off)i,j = (P P )i,j for i = j, and 0 for i = j. Thus, ((P P )off)i,j tallies i  x  j with i = j.
Assume that, for the fixed k, the term
Ek := (P  · · · (P (P P )offP )off · · · P )off

k nested ()off
tallies the length-2k paths (43) with no repetition of nodes xl and x2k-l (l). We now consider the term Ek+1 for k + 1. Due to (Ek+1)i,j = (P )i,Ek(P ),j if i = j, and 0 if i = j, (Ek+1)i,j tallies the length-(2k + 2) paths concatenated by i  x0, paths (43), and x2k  j, which is

i  x0  x1  · · ·  xk-1  xk  xk+1  · · ·  x2k-1  x2k  j

k edges

k edges

with no repetition of nodes xi and x2k-i and i = j.

Example 4. Recall the graph in Figure 3. By Theorem 7,
the path 7  6  5  3  4  6  8 is tallied by the term (P 3)P 3 , but not by (P (P (P P )offP )offP )off.
Indeed, regarding the term (P (P (P P )offP )offP )off, the innermost ()off disallows paths with repetition of nodes 5 and 4; the second nested ()off disallows the repetition of nodes 6 and 6 (which the considered path violates); the outermost ()off disallows the repetition of nodes 7 and 8.

In light of Theorem 7, the semantic relationship between S and S~ is evident: S~ often aggregates more paths than S, and S excludes the paths with self-intersecting nodes that are considered by S~. Figure 4 depicts an illustrative comparison of the paths tallied by (Sk)i,j and (S~k)i,j for k = 0, 1, 2.
For verification, let us apply ()off definition to expand, e.g., the term (P (P P )offP )off as follows:
(P (P P )offP )off i,j = (P 2)P 2 i,j - P diag(P P )P i,j -







- diag((P 2)P 2) i,j + diag(P diag(P P )P ) i,j





where a circled number beneath each term is associated with

a path numbered in the upper-left corner of Figure 4.



  







=

-

-

+

ij

i j i j i (j) i (j)

i j i (j)

i (j) i (j)

i (j)

89

The following result shows the specific types of paths that are tallied by S~ but not by S.
Corollary 2. Let P(S) and P(S~) be the sets of paths tallied by S and S~, respectively. Then, P(S~)  P(S), and P(S~) - P(S) is the set of "special" cycles of length 2k (k = 1, 2, · · · ), with first k contiguous edges oriented in one direction, and next k contiguous edges in the opposite direction.

5. EXPERIMENTAL STUDIES

5.1 Experimental Setting

(1) Real Data. The details are described below:

Dataset

|V |

|E| |E|/|V |

Type

WikiV

7,115

103,689 14.57

Directed

CaD

15,683

55,064

5.31 Undirected

CitH

34,546

421,578 12.20

Directed

WebN 325,729 1,497,134

4.59

Directed

ComY 1,134,890 2,987,624

2.63 Undirected

SocL 4,847,571 68,993,773

14.23

Directed

(a) WikiV, a Wikipedia who-votes-on-whom graph8, where
nodes are users, and an edge i  j means user i voted on j. (b) CaD, a collaboration graph, where each node is an
author, and edges co-authorships. The graph is derived from 6-year publications (2006­2011) in seven major conferences.
(c) CitH, a citation graph from arXiv high energy physics

theory, where each node is a paper labeled with meta information (e.g., title, authors, abstract) and an edge a citation.
(d) WebN, a web graph from University of Notre Dame,

where a node is a page (from nd.edu) and an edge a link. (e) ComY, an undirected Youtube social graph, where a
node is a user and an edge a friendship. (f) SocL, a friendship graph of a LiveJournal community,

where i  j is a recommendation of user j from user i. (2) Synthetic Data. To produce SYN, we adopt a scalefree graph generator based on the Barabasi-Albert model9. This generator takes as input two parameters: (|V |, |E|).

(3) Query Generator. (i) To evaluate all-pairs s(, ), we

generate the query-pair set (A, B), by using two criteria:

(a) Importance coverage is to ensure the selected (A, B) to

comprehensively contain a broad range of any possible pairs.

To this end, we first sort all nodes in V in descending order

by PageRank (PR), and split them into 10 buckets: nodes

with PR  [0.9, 1] are in the first bucket; nodes with PR 

[0.8, 0.9)

the

second,

etc.

We

next

randomly

select



1 10

|A|

(resp.



1 10

|B|)

nodes from each bucket to A (resp.

B).

Thus,

(A, B) has both important and non-important pairs.

(b) Overlapping coverage is to ensure that (A, B) contains

node-pairs with many multi-hop in-neighbors overlapped.

To achieve this, we first sort node-pair (a, b) in descending

order via a scoring function:10 fa,b :=

. 5 |hopk(a)hopk(b)|
k=1 |hopk(a)hopk(b)|

We then split all pairs into 5 buckets: pairs with fa,b  [4, 5]

are in the first bucket; pairs with fa,b  [3, 4) the second, etc.

For each bucket, we next sort node-pair (a, b) in descending

order based on the value of ga,b :=

5 k=1

|hopk

(a)



hopk

(b)|,

and

select

top



1 5

|A||B|

node-pairs

from

each

bucket.

Hence,

(A, B) covers node-pairs with many multi-hop in-neighbors

in common. (ii) Similarly, to evaluate single-source s(, q),

the query set for q can be sampled as "importance coverage".

8http://snap.stanford.edu/data/index.html 9http://graphstream-project.org/doc/Generators/ 10All paths of length up to 10 between a and b can be tallied
by our queries, ensuring results accurate to 2 decimal places.

(4) Algorithms. We implement the following, all in VC++.

Name SR# MSR OIP PSUM SMAT JSR
LSR SR++ RS RWR COS

Description
our scheme ("cosine" kernel + computation sharing) the state-of-the-art SimRank [7] all-pairs SimRank (fine-grained clustering) [13] all-pairs SimRank (partial sums memoization) [12] single-source SimRank (matrix decomposition) [3] Jeh and Widom's SimRank [5] Li et al.'s SimRank [9]
SimRank++ (revised "evidence factor") [1] RoleSim (automorphism equivalence) [6] Random Walk with Restart classic cosine similarity

(5) Parameters. We set (a)  = 0.6, as suggested in [12]. (b) k = 10, guaranteeing S(k) accurate to 2 decimal places.

(6) Evaluation Metrics. To evaluate the semantic quality

of the similarity search, we consider four metrics:

(a) Normalized Discounted Cumulative Gain at position p:

NDCGp

:=

1 IDCGp

p i=1

, 2reli -1
log2 (1+i)

where

reli

is

the

graded

relevance at position i, and IDCGp is the ideal DCG ranking.

(b)

Spearman's

:=

1-

6

n i=1

d2i

n(n2 -1)

,

where

di

is

the

difference

of two ranks at position i, and n is the number of elements.

(c) Kendall's  :

=

(#

of

concordant

pairs)-(# of 0.5n(n-1)

discordant

pairs) .

(d) Query coverage is the queries from our query sample.

(7) Ground Truth. (a) To label ground truth for similar

users on WikiV, a manual evaluation is carried out by 50

professional members who have accumulated a long history

of activity on Wikipedia. Each pair of users is considered by

an evaluator, and is assigned a score on a scale from 1 to 4,

with 1 meaning irrelevant, 4 meaning completely relevant,

and 2 and 3 meaning "somewhere in between". The judge-

ment is based on evaluator's knowledge and public votes on

promotion of individuals to adminship. (b) To mark ground

truth labels for similar authors on CaD, 30 members from 5

database groups are invited. Each pair of authors is given a

score based on the collaboration distance between authors.

The judgement relies on evaluator's knowledge and "sepa-

rations" of Co-Author Path in Microsoft Academic Search.11

(c) To establish the ground truth of similar articles on CitH,

28 research associates from the School of Physics are hired.

Each pair of articles is assigned a score based on evaluator's knowledge on paper abstracts and citation relations.
All experiments are run with an Intel Core(TM) i7-4700MQ CPU @ 2.40GHz CPU and 32GB RAM, on Windows 7.

5.2 Experimental Results

5.2.1 Semantic Quality
We first evaluate the high semantic quality of SR# against SR++, JSR, LSR12, RS, COS, RWR on real WikiV, CitH, CaD. For each dataset, we randomly issue 300 queries for s(, q) and s(, ) via importance coverage criterion, and use 3 metrics (NDCG, Kendall, Spearman) to evaluate each method, respectively. Fig. 5a shows the average quantitative results. (1) In all cases, SR# exhibits higher semantic quality than the other methods. This is because SR# can avoid "connectivity trait" issue by utilizing a "cosine" kernel recursively in a SimRank-like style, whereas COS considers only direct overlapped in-neighbors, and JSR and LSR both have a "connectivity trait" problem. (2) In several cases, the NDCG200 of SR++ (on CitH) and RS (on CaD) may even worse than that of JSR and LSR. This is because, for SR++, its evi-
11http://academic.research.microsoft.com/VisualExplorer 12For semantics evaluation, MSR produces the same similarity values as LSR, since [7] approximates D by (1 - )I.

90

Ave. NDCG200

SR# 1 0.9 0.8 0.7 0.6 0.5
WikiV CitH

LSR (MSR) CaD

Ave. Spearman's 

JSR 1 0.8 0.6 0.4 0.2
WikiV

SR++

RS

CitH

CaD

Ave. Kendall's 

COS 1 0.8 0.6 0.4 0.2
WikiV

RWR CitH

CaD

Query Coverage (%)

1 300 Sample Queries
0.8

0.6

WikiV

CitH

0.4

CaD

SR# LSR JSR SR++ RS COS RWR

(a) Semantics on Real Data (Measured by NDCG, Spearman's , Kendall's  )

(b) Query Coverage

Memory (MB) Elapsed Time (Sec)

% of Common Multi-hops In-neighbors Coverage s

SR#

LSR (MSR)

JSR

1

0.8

300 Sample

Queries

0.6

0.4

0.2

0 WikiV CitH CaD

% of Sample Queries s

SR++

RS

COS

RWR

1

0.8

0.6

0.4

0.2

300 Sample Queries

0 4-5

3-5

2-5

1-5

# of Hops of In-neighbors (Depths)

SR#

MSR

PSUM

104

# of Iterations

k = 10

101

0.01

×
WebN

×
SocL

×
ComY WikiV

CaD

×
CitH

Elapsed Time (Sec)

OIP

SR

SMAT

105

# of Iterations

k = 10

103

101 ×××
WebN SocL ComY WikiV CaD
(50000 (1000 (10000 cols) cols) cols)

CitH

Elapsed Time (sec)

(c) Overlapping Coverage

4K

SR#

3K

MSR

2K

1K

0 5 10 15 20 25 30 # of Iterations k

Elapsed Time (sec)

(d) Depth Coverage

300

SR#

200

MSR

100

|V | = 1M k = 10

0 2 5 10 15 20 25 Graph Density (|E|/|V |)

Memory (GB)

(e) Time for Single Source

(f) Time for All Pairs

SR#

MSR

PSUM

OIP

SR

104

k = 10

102

1.5 SR#
MSR 1

100 ×
WebN
(50000 cols)

× SocL
(1000 cols)

× ComY
(10000 cols)

WikiV

CaD

CitH

0.5
5 10 15 20 25 # of Iterations k

Kendall's 

(g) Time vs. k on SocL

(h) Time vs.

|E| |V |

on

SYN

(i) Memory for Single Source/All Pairs

(j) Memory vs. k on SocL

1

0.9

0.8

top 50

0.7

top 200

top 500

0.6
WebN SocL ComY WikiV CaD

CitH

/655D QN

 . .



 
     


 .



.

. .



-655DQN 

Error

0.4

0.3

0.2

MSR

SR#

0.1

Est. Bound k+1

01 3 5 7 9 11 13 15 # of Iterations k

% of Node Pairs with "Connectivity Trait"
Problem

1

82.7%
0.8

78.1%

62.3%
0.6

56.4%

44.4% 41.5%

0.4

0.2

0
WebN SocL ComY WikiV CaD CitH

(k) LSR and JSR Relative Ordering (l) Ranking on WikiV (m) (diag + iter) vs. k (n) % of "Connectivity Trait" Issues

Figure 5: Performance Evaluations on Real and Synthetic Datasets

dence factor will be 0 whenever there are no common direct in-neighbors; for RS, automorphism equivalence has priority over connectivity in similarity assessment. Thereby, SR++ and RS may not resolve the "connectivity trait" problem.
Fig. 5b compares the percentage of queries from the 300 queries sample (based on importance coverage criterion) that SR#, SR++, JSR, LSR, RS, COS, RWR provide similarities for on real WikiV, CitH, CaD, respectively. For each dataset, SR# substantially improves the coverage of JSR/LSR (0.73) and SR++/RS (0.81) to 0.95. This can be considered as expected, since (a) the "connectivity trait" problem of JSR and LSR will downgrade similarities of node-pairs with high connectivity, and (b) SR++ can only partially fix the "connectivity trait" issue within 1-hop in-neighborhood.
Fig. 5c depicts the percentage of queries with overlapped multi-hop in-neighbors from the 300 queries sample (via overlapping coverage criterion) that SR#, SR++, JSR, LSR, RS, COS, RWR are able to identify on real WikiV, CitH, CaD, respectively. (1) For each dataset, SR# significantly achieves 0.95 coverage of common multi-hop in-neighbors, much superior to JSR/LSR (0.20), SR++(0.51) and COS(0.41). The reason is that our "cosine" kernel provides an appropriate normalization factor  2 that can recursively fix the "connectivity trait" problem. In contrast, the  1 normalization factor of JSR/LSR excessively squeezes the range of similarity [0, 1]. (2) Under overlapping coverage criterion, COS (0.41) outperforms JSR/LSR (0.20) since COS is not limited by the "connectivity trait" problem.

To further evaluate the search depth of SR#, SR++, JSR, LSR, RS, COS, RWR, we first apply overlapping coverage criterion to generate 2,000 queries, and then generate 300 queries via importance coverage criterion, and classify them into 4 groups, e.g., "4-5" collects queries (a, b) whose path length between a and b is 8­10. Fig. 5d depicts the search depth of all the methods on WikiV. (1) For each group, SR++ and COS have the lowest quality of depth search among all the methods, since they cannot capture the paths of length > 2 between nodes. (2) SR# achieves the highest quality, and its superiority is more pronounced in the groups that have longer paths. This tells us that the "connectivity trait" issue has a large influence on node-pairs with long paths.
5.2.2 Time Efficiency
Fig. 5e illustrates the running time of SR#, MSR, PSUM, OIP, SR, SMAT for single-source s(, q) on 6 real datasets. (1) In all cases, SR# always substantially outperforms the other methods. This is because SR# can eliminate duplicate computations for maximal sharing, whereas MSR computes each term separately. (2) PSUM, OIP, SR, SMAT will crash on large WebN, SocL, ComY, due to the memory allocation. On WikiV and CaD, they are 3-4 orders of magnitude slower than SR#, since their iterative models to compute s(, q) rely on all-pairs outputs of the previous iteration.
Fig. 5f shows the time of SR#, MSR, PSUM, OIP, SR for all-pairs s(, ) on 6 real datasets. (1) Only SR#, MSR survive on all datasets, whereas PSUM, OIP, SR fail on large

91

WebN, SocL, ComY, due to the memory allocation. (2) MSR is slower than others as it sacrifices speed for scalability. In contrast, SR# not only scales well on large graphs, but also has comparable speed to those of PSUM, OIP, SR.
Fig. 5g presents the impact of the iteration number k on the time of SR# and MSR. When k grows from 5 to 30, the time of SR# does not increase significantly (just from 42s to 301s), as opposed to the time of MSR growing from 152s to 3744s. The reason is that MSR contains many duplicate computations among different iterations, whereas SR# can merge these results after rearranging the computation order. It is consistent with our analysis in Subsection 2.4.
Fig. 5h demonstrates the impact of network density on the computational time of SR# and MSR on synthetic data. Fixing |V | = 1, 000, 000 and k = 10, we generate a synthetic dataset by increasing the graph density from 2 to 25. (1) When the density increases, the time of both algorithms will increase. (2) For dense graphs, the speedup for SR# is significantly higher than MSR, due to the number of iterations with a huge influence on MSR compared with SR#. This is in agreement with the complexity of SR# and MSR.
5.2.3 Memory Efficiency
Fig. 5i shows the memory of SR#, MSR, PSUM, OIP, SR on six real datasets. (1) For large WebN, SocL and ComY, only SR# and MSR survive, highlighting their scalability. (2) For each dataset, SR# requires slightly more memory than MSR because it requires to store Dk.
Fig. 5j reports the impact of the iteration number k on the memory of SR# and MSR on SocL. (1) When k varies from 5 to 25, the memory requirements of SR# and MSR increase, since they need to memorize the k intermediate vectors from previous iterations, as expected. (2) The disparity in the memory between SR# and MSR is due to storing Dk.
5.2.4 Relative Order
Fig. 5k compares the relative order between LSR and JSR for the top K results on 6 real datasets (K = 50, 200, 500). The order gap is measured by Kendall's  . (1) For different graphs, the quality of the relative order is irrelevant to top K size. For instance, on SocL, top 500 (0.94) is better preserved than top 200 (0.91) and top 50 (0.9), whereas on CaD, top 500 (0.84) is worse than both top 200 (0.9) and top 50 (0.92). (2) On each dataset, the average Kendall's  for top 50 is 0.77­0.92, which indicates that LSR does not maintain the relative rank of JSR, even for top 50. Thus, approximating D by (1 - )I would adversely affect the top K ranking.
Further, a qualitative result on WikiV is depicted in Fig. 5l, where x (y) axis is the ranking by JSR (LSR). Other datasets also statistically exhibit similar phenomena. (1) Many points below the diagonal imply that low-ranked node-pairs by JSR have greater likelihood to get promoted to a high rank of LSR. This association does not imply a (near) linear relationship between the rankings of JSR and LSR. (2) For high top-K ranking (e.g., K = 15), the top 15 of JSR may be inconsistent with those of LSR. Hence, the relative order preservation of JSR and LSR hinges on network structure.
Fig. 5m tests (diag + iter) of MSR and SR# w.r.t. k. (1) When k increases from 1 to 15, the error of each algorithm decreases. While the error of SR# approaches 0, MSR levels off at 0.28. The large disparity between their convergent solutions is due to the approximation of D by (1 - )I in MSR; our "varied-D" iterative model can guarantee the error

to be 0 when k increases. (2) The SR# curve is always below the Est. Bound curve, showing the correctness of Theorem 4.
Fig. 5n statistically shows the percentage of node-pairs with the "connectivity trait" problem over all real datasets. From the results, we see that the percentages are all high (e.g., 82.7% on WebN, 62.3% on SocL, 78.1% on ComY), showing the seriousness of this problem in real scenarios.
6. CONCLUSIONS
We consider the problem of high-quality similarity search. Observing that (1) the best-of-breed SimRank [7] produces diagonal correction error diag and (2) SimRank++ [1] does not well resolve the "connectivity trait" problem, we proposed our scheme, SR#. First, we characterize the exact D, and devise a "varied-D" model to compute SimRank with no diag in linear memory. We also speed up the computational time from quadric [7] to linear in terms of k. Next, we devise a "kernel-based" model to circumvent the "connectivity trait" problem. Finally, we give new insights into the semantic difference between Jeh and Widom's SimRank and its variant, and correct an argument in [7]. We empirically show that SR# (1) improves an accuracy of average NDCG200 by 30% on real graphs, and (2) can be 10x faster than [7] on SocL with 65.8M links for 1000 queries.
Acknowledgment. This work forms part of the Big Data Technology for Smart Water Network research project funded by NEC Corporation, Japan.
7. REFERENCES
[1] I. Antonellis, H. G. Molina, and C. Chang. SimRank++: Query rewriting through link analysis of the click graph. PVLDB, 1(1), 2008.
[2] D. Fogaras and B. R´acz. Scaling link-based similarity search. In WWW, 2005.
[3] Y. Fujiwara, M. Nakatsuji, H. Shiokawa, and M. Onizuka. Efficient search algorithm for SimRank. In ICDE, 2013.
[4] G. He, H. Feng, C. Li, and H. Chen. Parallel SimRank computation on large graphs with iterative aggregation. In KDD, 2010.
[5] G. Jeh and J. Widom. SimRank: A measure of structural-context similarity. In KDD, 2002.
[6] R. Jin, V. E. Lee, and H. Hong. Axiomatic ranking of network role similarity. In KDD, 2011.
[7] M. Kusumoto, T. Maehara, and K. Kawarabayashi. Scalable similarity search for SimRank. In SIGMOD, 2014.
[8] P. Lee, L. V. S. Lakshmanan, and J. X. Yu. On top-k structural similarity search. In ICDE, 2012.
[9] C. Li, J. Han, G. He, X. Jin, Y. Sun, Y. Yu, and T. Wu. Fast computation of SimRank for static and dynamic information networks. In EDBT, 2010.
[10] P. Li, H. Liu, J. X. Yu, J. He, and X. Du. Fast single-pair SimRank computation. In SDM, 2010.
[11] Z. Lin, M. R. Lyu, and I. King. MatchSim: A novel similarity measure based on maximum neighborhood matching. Knowl. Inf. Syst., 32(1), 2012.
[12] D. Lizorkin, P. Velikhov, M. N. Grinev, and D. Turdakov. Accuracy estimate and optimization techniques for SimRank computation. VLDB J., 19(1), 2010.
[13] W. Yu, X. Lin, and W. Zhang. Towards efficient SimRank computation on large networks. In ICDE, 2013.
[14] W. Yu, X. Lin, and W. Zhang. Fast incremental simrank on link-evolving graphs. In ICDE, pages 304­315, 2014.
[15] W. Yu, X. Lin, W. Zhang, Y. Zhang, and J. Le. SimFusion+: Extending SimFusion towards efficient estimation on large and dynamic networks. In SIGIR, 2012.
[16] W. Yu and J. A. McCann. Sig-SR: SimRank search over singular graphs. In SIGIR, 2014.
[17] W. Yu and J. A. McCann. Efficient partial-pairs SimRank search for large networks. PVLDB, 8(5):569­580, 2015.

92

