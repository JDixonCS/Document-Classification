Short Research Papers 1B: Recommendation and Evaluation

SIGIR '19, July 21≠25, 2019, Paris, France

On Topic Diiculty in IR Evaluation: The Eect of Systems, Corpora, and System Components

Fabio Zampieri
University of Udine Udine, Italy
zampieri.fabio@spes. uniud.it

Kevin Roitero
University of Udine Udine, Italy
roitero.kevin@spes. uniud.it

J. Shane Culpepper Oren Kurland

RMIT University

Technion

Melbourne, Australia

Haifa, Israel

shane.culpepper@ kurland@ie.technion.

rmit.edu.au

ac.il

Stefano Mizzaro
University of Udine Udine, Italy
mizzaro@uniud.it

ABSTRACT
In a test collection setting, topic diculty can be dened as the average eectiveness of a set of systems for a topic. In this paper we study the eects on the topic diculty of: (i) the set of retrieval systems; (ii) the underlying document corpus; and (iii) the system components. By generalizing methods recently proposed to study system component factor analysis, we perform a comprehensive analysis on topic diculty and the relative eects of systems, corpora, and component interactions. Our ndings show that corpora have the most signicant eect on topic diculty.
ACM Reference Format: Fabio Zampieri, Kevin Roitero, J. Shane Culpepper, Oren Kurland, and Stefano Mizzaro. 2019. On Topic Diculty in IR Evaluation: The Eect of Systems, Corpora, and System Components. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19). ACM, New York, NY, USA, 4 pages. https: //doi.org/10.1145/3331184.3331279
1 INTRODUCTION
Topic diculty, dened as the average eectiveness of a set of systems on a topic [9, 10], is a well-studied problem in the IR literature. It is loosely related to the problem of Query Performance Prediction (QPP), which aims to estimate the eectiveness of a system for a given query when no relevance judgments are available [2]. In classical QPP, however, the aim is to predict the performance of a specic system for a specic query; in this paper we study topic diculty for a set of systems. This is a dierent problem that can be justied by the aim of understanding the "general" diculty of a topic [7≠10]. It also leads naturally to the research issue of nding representative sets of systems, i.e., sets for which diculty would generalize to other sets. Our overall goal is to understand the eect of three factors (the set of systems, the document corpus, and the system components) on topic diculty. To the best of our knowledge, this problem has only been investigated from a system eectiveness perspective. We achieve this goal by extending factor analysis methods recently proposed to study the eect of system components on eectiveness of systems [4≠6]. We address four research questions:

RQ1. Given a collection, what is the eect of choosing a dierent set of systems on the diculty of topics?
RQ2. Given a set of systems, what is the eect of the corpus of documents (or sub-corpora of a corpus) on topic diculty?
RQ3. What is the eect of system components on topic diculty? RQ4. What is the relative eect of choosing dierent systems, cor-
pora, and system components on topic diculty?
2 RELATED WORK
A body of related work focuses on studying factors that aect system eectiveness, such as topic composition, collection, and system components. Sanderson et al. [11] investigated the eect of splitting a TREC collection into sub-collections based on system eectiveness, and identied several interesting sub-collection effects induced by the splits. Banks et al. [1] provided an overview of methods that can be applied to analyze the performance of IR systems on TREC collections and its relation to topics, collections and other factors. One common statistical tool used for this problem is the Analysis of Variance (ANOVA), which was recently used by Ferro and Silvello [5] to compare combinations of collections, metrics, and systems. They showed that stop lists, IR models, and component interactions have a signicant but small eect on overall system eectiveness. The same approach was adopted by Ferro and Sanderson [4] and Ferro et al. [3], whose experiments show the existence of a signicant sub-corpus eect relative to system eectiveness; however, the eect is smaller than both system and topic eects, with topic eect being the most signicant. Similar experiments using the sub-corpora of a single collection showed that the system eect is smaller than the topic eect [4]. However, none of these studies specically addresses the eect of factors on topic diculty which we study here. Moreover, all of them compare sub-corpora of the same collection, which has some drawbacks. TREC corpora are built with a "working assumption" that they are somehow complete, and working on sub-corpora can sometimes negate this assumption. In this paper, we do not only analyze what happens on incomplete sub-corpora, but we are also able to compare across dierent corpora.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee. Request permissions from permissions@acm.org.
SIGIR '19, July 21≠25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331279

3 EXPERIMENTS
3.1 Experimental Setting
Datasets. Table 1 summarizes the datasets used for our experiments. We focus on ve TREC (Text REtrieval Conference) collections. Our datasets are purposefully chosen to include overlapping sets of topics, systems, and corpora. The set of R04 topics includes TREC6 topics (301-350), TREC7 topics (351-400), TREC8 topics (401450), half of the Robust03 topics (601-650), and 50 additional topics

909

Short Research Papers 1B: Recommendation and Evaluation

SIGIR '19, July 21≠25, 2019, Paris, France

Table 1: Datasets used in our experiments.

Acronym
TREC6 TREC7 TREC8 R04 C17

Track
Ad Hoc Ad Hoc Ad Hoc Robust Common Core

Year
1997 1998 1999 2004 2017

Topics
50 50 50 249 50

Ocial
74 103 129 110 75

Unocial
158 158 158 158 158

Table 2: The number of common topics between collections.

R04 C17 TREC6 TREC7 TREC8

C17

50 50

TREC6 50 11

50

TREC7 50 17

0

50

TREC8 50 16

0

0

50

Table 3: Corpora of documents used in the datasets.

Acronym Corpus name

TREC6-8 R04 C17

FT

The Financial Times

x

x

FR

Federal Register

x

x

CR

Congressional Record

x

FBIS

FBI Service

x

x

NYT

The New York Times

x

that were specically introduced in R04. C17 has 50 topics, which were also originally included in the R04 set of topics; C17 has a few topics that overlap with TREC6-8 (see Table 2). Table 3 shows the document corpora used in each collection: R04 and TREC6-8 share, apart from C17, the same corpora; C17 is based only on NYT.
For each of the TREC collections we use the ocially-submitted runs. We also supplement available runs using several open source search engines in order to produce system congurations that are directly comparable across collections: Terrier, Atire, and Indri (www.terrier.org, www.atire.org, www.lemurproject.org). The 158 system variants are generated by systematically alternating and combining the ranker, stemmer, and stopword congurations, but xing congurations to be identical across all test collections. Henceforth we distinguish between ocial systems/runs (O) from TREC, and unocial system congurations (U) generated by us. Both O and U systems produce ranked lists of 1000 documents. Metrics. We use Average Precision (AP) as an eectiveness measure. Given a system si and a topic tj , we denote the corresponding score which is a real number between 0 and 1 as AP(si , tj ). By averaging athme eAaPsuvraeluoefstoopviecrdeiachcutlotypi[c9, ,w1e0]o: bAtAaiPn(ttjh)e=Avm1er’agmie=1AAPP((AsiA, tPj )),. A high AAP value indicates that the topic is easy, and a low AAP indicates that the topic is dicult for a specic collection and set of system runs. We use Kendall's as the primary correlation coecient in this work, as it is well-suited to compute partial correlations in fully-ranked data [1].
3.2 Results
RQ1: System Eects. We rst illustrate and discuss how topic diculty changes when we select a dierent set of systems. In Figure 1, scatter plots of AAP values for R04 and C17 topics are shown; the other collections, not shown due to space limits, exhibit similar trends. Columns correspond to subsets of systems, each containing 30 elements (with the exception of the rst column, which represents the set of all systems), while rows correspond

aOO systems

best systems woUst systems Uandom systems

0.8  0.8

0.8  0.63

0.8  0.81

0.8  0.84

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

8

8

0.8  0.7

0.8  0.6

0.8  0.72

0.8  0.65

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00

0.25 0.50
2

0.75

0.00.00

0.25 0.50
2

0.75

0.00.00

0.25 0.50
2

0.75

0.00.00

0.25 0.50
2

0.75

Figure 1: Scatterplots of AAP values for C17 (rst row) and R04 (second row), computed over dierent sets of systems (y-axis: U = Unocial; x-axis: O = Ocial).

2

8

aOO systems
0.8  0.48
0.6 0.4

best systems woUst systems Uandom systems

0.8  0.51

0.8  0.43

0.8  0.46

0.6

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.8  0.38
0.6 0.4

0.8  0.36
0.6 0.4

0.8  0.4
0.6 0.4

0.8  0.37
0.6 0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.8  0.84
0.6

0.8  0.76
0.6

0.8  0.76
0.6

0.8  0.75
0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.8  0.95
0.6

0.8  0.87
0.6

0.8  0.92
0.6

0.8  0.94
0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

2

8

Figure 2: Scatterplots of AAP values computed over R04 vs. C17 (rst two rows), and R04 vs. TREC6 (3rd and 4th rows), using either the ocial (O) runs (1st and 3rd row) or the unocial (U) ones.

to collections. For each plot, a point is dened by the AAP value computed over the set of ocial systems (on the x axis) and the AAP value computed over the set of unocial systems (on the y axis). High correlations are observed in almost every case. Selecting a particular group of systems does not seem to aect the correlation, even though a signicant overall drop can be seen when values are computed using only the best systems (i.e., the 30 best ocial and the 30 best unocial). Therefore, for a given corpus, topic diculty seems quite stable and does not appear to change much across dierent sets of systems, although they heavily dier in terms of implementation and components. The correlation values drop, however, when relying only on the most eective systems.

910

Short Research Papers 1B: Recommendation and Evaluation

SIGIR '19, July 21≠25, 2019, Paris, France

all systems
0.8  0.27

best systems woUst systems Uandom systems

0.8  0.3

0.8  0.23

0.8  0.26

0.6

0.6

0.6

0.6

8

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.8  0.39

0.8  0.4

0.8  0.38

0.8  0.39

0.6

0.6

0.6

0.6

8

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

0.00.00 0.25 0.50 0.75

Figure 3: Scatterplots of AAP values computed over R04 subcollections: FT vs FR (1st row) and FT vs. FBIS (2nd row).

RQ2: Corpora Eects. We now turn to the eect of document corpora on topic diculty. In Figure 2, we see that the correlation between AAP values of R04 and C17 is 0.48 for ocial systems (1st row, 1st column), and 0.38 for unocial ones (2nd row, 1st column). It is somewhat higher for ocial systems, although they dier across collections whereas the unocial congurations are identical. Similar results are observed when selecting a particular subset of systems (columns 2-4). In contrast, the correlations between R04 and TREC6 are very high: 0.84 when computed over ocial systems (3rd row, 1st column), and 0.95 when computed over unocial systems (4th row, 1st column). Also in this case, selecting a subset of systems does not seem to aect correlations. We obtained the same results for TREC7-8 (not shown here).
As R04 and C17 include dierent document corpora (see Table 3), these results suggest that topic diculty is indeed quite sensitive to the document corpus. When comparing these results to previous work [3, 4], we observe two dierences: only sub-corpora were used, not dierent corpora as we do here, and system eectiveness was studied, not topic diculty as we do here.
Figure 3 provides also evidence to sub-corpora eects over R04. It shows how topic diculty changes across the sub-corpora of R04 (shown in Table 3). Here again, the correlation of AAP values computed over dierent sub-collections is very low: the highest correlation is between AAP values computed over FT and FBIS (2nd row), while other values do not exceed 0.3.
To summarize: (i) we nd very low correlations when changing signicantly the corpus (R04 vs. C17), thereby generalizing the nding about low correlations on dierent sub-corpora also to the case of dierent complete corpora; (ii) in one case (R04 vs. C17), we nd the strange result that computing AAP using the same unocial system set leads to lower correlation than when using the ocial--and dierent--system set; but this is not conrmed on other datasets; nally (iii) if the changes to the corpus are small (R04 vs. TREC6) then correlations are high. RQ3: System Component Eects. We now turn to our third research question, which focuses on the impact of system components on topic diculty; in particular, we consider stemming and query expansion. Since these are quite dramatic changes to the systems, we expect quite signicant changes to AAP values, and probably low correlations. Figure 4 shows, for each topic in the R04 and C17 collections, the dierence of AAP values computed over the baselines (i.e., systems without stemmer and query expansion) and

R04

.rRvetz  = 0.76
0.8 0.6 0.4 0.2 0.0

 = 0.72
0.8

PRrter

0.6

0.4

0.2

0.0

 = 0.76
0.8

 = 0.74
0.8

0.6

0.6

C17

0.4

0.4

0.2

0.2

0.0

0.0

Figure 4: Dierences between AAP values computed over baselines (i.e., systems without stemmer and query expansion) and those computed over systems using stemmers.

 = 0.78 0.8
0.6
0.4

R04

 = 0.77 0.8

C17

0.6

0.4

0.2

0.2

0.0

0.0

Figure 5: Dierences in AAP computed over baselines and over systems using query expansion.

when using two common stemmers (Krovetz and Porter). Due to space limitations, we do not show the results for the all stemmer and collection combinations. For many of the topics, stemming leads to little or no signicant improvement in terms of AAP. In a few cases, however, there are signicant increases and decreases in AAP, which occur for the same topics across dierent stemmers. The highest dierences in AAP was observed for the R04 topics (see the 1st row), which appear to be quite sensitive to the stemmer used.
Figure 5 shows the AAP dierences between the baselines and systems using query expansion for R04 and C17. For R04 (1st column), we see frequent increases in AAP and infrequent decreases. However, for C17 (2nd column) decreases in AAP are negligible (the same is also true for TREC6-8, not shown).
The results show that system components can have variable eects on topic diculty. In particular, we see that, for a xed subset of topics in a given collection, topic diculty can considerably change if we add a stemming or query expansion to the set of

911

Short Research Papers 1B: Recommendation and Evaluation

SIGIR '19, July 21≠25, 2019, Paris, France

Table 4: ANOVA table for the model described by Eq. 1.

Factor

SS

DF F

p-value 2

corpus

1.5537 2 140.299 < 1e-6

system

48.4639 168 52.0968 < 1e-6

topic

3045.68 248 2217.86 < 1e-6

corpus:topic 1120.13 496 407.84 < 1e-6

corpus:system 6.4594 336 3.4718 < 1e-6

0.0003 0.0103 0.6603 0.2423 0.0009

systems. However, the correlations, shown in Figures 4 and 5, are quite high: somehow unexpectedly, relative topic diculty remains quite stable despite the changes to the systems (stemming or query expansion) are quite signicant. RQ4: Comparing relative eects with ANOVA. In an attempt to provide a more principled and, at the same time, concise analysis, we investigate the eects of systems, corpora, and system components using ANOVA as part of our nal research question. In particular, we dene two ANOVA models (see Equations (1) and (2)), which are described below. Tables 4 and 5 show the outcome of each ANOVA test. For each factor, we report the Sum of Squares (SS), the Degrees of Freedom (DF), the F statistics, the p-value, and the eect-size ( 2) which quanties the proportional variance of each factor [4≠6]. The rst model decomposes the eectiveness (measured by AP) into system, topic, and corpus eects:

AP (i, j) = µ + si + tj + cz + czsi + cztj + i j

(1)

where terms identify AP(i, j) of i-th system and j-th topic, grand mean (µ), z-th corpus (cz ), corpus-system (czsi ) and corpus-topic (cztj ) interactions, and model error ( ij ). Table 4 shows the results of the ANOVA analysis for Eq. (1). All eects are statistically signicant. Systems have a small eect (0.0103), while topics have the greatest eect (0.6603). The interaction eect between corpus and topic is also large but, perhaps surprisingly, both the relative eect of the corpus, and the interaction between corpus and system is negligible. The second model focuses on system components:

AP(i, j) = µ + si + tj + moq + stk + qe + cz + czsi + cztj + i j (2)

where terms identify IR model (moq ), stemmer (stk ), query expansion (qe ), corpus-system (czsi ) and corpus-topic (cztj ) interactions. The results of the ANOVA test for Eq. (2) are shown in Table 5. All eects are statistically signicant, and the topic eect is the largest (0.8157); the system eect is signicant but small. Again, somewhat surprisingly, the corpus interactions have a negligible eect on AP scores. All other eects are not signicant. In summary, the ANOVA analyses show that AP scores are aected mostly by topics and systems, with the greatest eects being attributable to the topic eect; furthermore, system components, corpus, and the interaction between corpus and systems have very little eect on AP. Nevertheless, the impact of topics on AP clearly varies based on the corpus.

4 CONCLUSIONS AND FUTURE WORK
This is the rst study that specically addresses topic diculty in a systematic way: we use dierent corpora, not just sub-corpora; we run the same set of systems across dierent datasets; and we rely on datasets featuring common topics. To do so, we exploit the topic overlap between C17 and R04 with previous collections, and we supplement our analysis using a comprehensive set of unocial but reproducible systems.

Table 5: ANOVA table for the model described by Eq. 2.

Factor

SS

DF F

p-value 2

corpus

15.7907 2 1133.24 < 1e-6

topic

2528.42 248 1463.35 < 1e-6

system

52.6792 168 45.007 < 1e-6

ir_model

2.8554 22 18.6294 < 1e-6

qe

2.0049 1 287.777 < 1e-6

stemmer

0.3708 6 8.8723 < 1e-6

corpus:system 5.9907 336 2.5591 < 1e-6

corpus:qe

0.2012 2 14.4394 < 1e-6

0.0050 0.8157 0.0166 0.0008 0.0006 0.0001 0.0011 6.045e-05

We nd that topic diculty is aected by the document corpora
of collections: there is a signicant corpus-eect on topic diculty
in all of the collections tested. Also, there is a signicant system-
eect, although not so large. Finally, we see a smaller eect of
system components on topic diculty, with the exception of a
few limited cases. Although the standard ANOVA analysis shows a
strong variance across topics and system eects that are higher than
the corpus eects, we alsof nd that topic diculty is reasonably
stable across system sets and system components, thus conrming
that it is a reasonable and measurable concept. We found only
two exceptions with low correlations: the comparison across the
dierent corpora of R04 and C17 and the comparison across R04 sub-
corpora (Figures 2 and 3). Although the latter might be due to the
incomplete nature of sub-corpora, the former conrms that topic
diculty is mostly aected by the underlying document collection.
In the future we plan to extend the analysis to more collections,
to ne-tune the parameters of the unocial systems to each dataset,
and to study more system and topic components. Acknowledgements. This work was partially supported by the Israel Science Foundation (grant no. 1136/17), the Australian Research Council's Discovery Projects Scheme (DP170102231), a Google Faculty Award, and an Amazon Research Award.
REFERENCES
[1] David Banks, Paul Over, and Nien-Fan Zhang. 1999. Blind men and elephants: Six approaches to TREC data. Information Retrieval 1, 1 (1999), 7≠34.
[2] David Carmel and Elad Yom-Tov. 2010. Estimating the query diculty for information retrieval. Synthesis Lectures on Information Concepts, Retrieval, and Services 2, 1 (2010), 1≠89.
[3] Nicola Ferro, Yubin Kim, and Mark Sanderson. 2019. Using Collection Shards to Study Retrieval Performance Eect Sizes. ACM TOIS 5, 44 (2019), 59.
[4] Nicola Ferro and Mark Sanderson. 2017. Sub-corpora impact on system eectiveness. In Proceedings of the 40th ACM SIGIR. ACM, 901≠904.
[5] Nicola Ferro and Gianmaria Silvello. 2016. A general linear mixed models approach to study system component eects. In 39th ACM SIGIR. 25≠34.
[6] Nicola Ferro and Gianmaria Silvello. 2018. Toward an anatomy of IR system component performances. JASIST 69, 2 (2018), 187≠200.
[7] Donna Harman and Chris Buckley. 2009. Overview of the reliable information access workshop. Information Retrieval 12, 6 (2009), 615≠641.
[8] Stefano Mizzaro, Josiane Mothe, Kevin Roitero, and Md Zia Ullah. 2018. Query Performance Prediction and Eectiveness Evaluation Without Relevance Judgments: Two Sides of the Same Coin. In The 41st ACM SIGIR (SIGIR '18). 1233≠1236.
[9] Stefano Mizzaro and Stephen Robertson. 2007. Hits Hits TREC: Exploring IR Evaluation Results with Network Analysis. In Proceedings 30th SIGIR. 479≠486.
[10] Kevin Roitero, Eddy Maddalena, and Stefano Mizzaro. [n. d.]. Do Easy Topics Predict Eectiveness Better Than Dicult Topics?. In ECIR2017. 605≠611.
[11] Mark Sanderson, Andrew Turpin, Ying Zhang, and Falk Scholer. 2012. Dierences in eectiveness across sub-collections. In Proc. of the 21st ACM CIKM. 1965≠1969.

912

