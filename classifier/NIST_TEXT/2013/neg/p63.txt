Learning Latent Friendship Propagation Networks with Interest Awareness for Link Prediction

Jun Zhang1,2,3,4 Chaokun Wang2,3,4 Philip S. Yu5 Jianmin Wang2,3,4
1 Department of Computer Science and Technology, Tsinghua University 2 School of Software, Tsinghua University
3 Tsinghua National Laboratory for Information Science and Technology 4 Key Laboratory for Information System Security, Ministry of Education, P. R. China
5 Department of Computer Science, University of Illinois at Chicago
zhang-jun10@mails.thu.edu.cn, chaokun@tsinghua.edu.cn, psyu@uic.edu, jimwang@tsinghua.edu.cn

ABSTRACT
It's well known that the transitivity of friendship is a popular sociological principle in social networks. However, it's still unknown that to what extent people's friend-making behaviors follow this principle and to what extent it can benefit the link prediction task.
In this paper, we try to adopt this sociological principle to explain the evolution of networks and study the latent friendship propagation. Unlike traditional link prediction approaches, we model link formation as results of individuals' friend-making behaviors combined with personal interests. We propose the Latent Friendship Propagation Network (LFPN), which depicts the evolution progress of one's egocentric network and reveals future growth potentials driven by the transitivity of friendship based on personal interests. We model individuals' social behaviors using the Latent Friendship Propagation Model (LFPM), a probabilistic generative model from which the LFPN can be learned effectively. To evaluate the power of the friendship propagation in link prediction, we design LFPN-RW which models the friend-making behavior as a random walk upon the LFPN naturally and captures the co-influence effect of the friend circles as well as personal interests to provide more accurate prediction.
Experimental results on real-world datasets show that LFPN-RW outperforms the state-of-the-art approaches. This convinces that the transitivity of friendship actually plays important roles in the evolution of social networks.
Categories and Subject Descriptors
H.2.8 [DATABASE MANAGEMENT]: Database Applications-- Data mining; J.4 [SOCIAL AND BEHAVIORAL SCIENCES]: Sociology
Keywords
Link Prediction; Social Networks; Transitivity of Friendship; Friendship Propagation; Interest Awareness
Corresponding authors: Chaokun Wang and Jianmin Wang.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

1. INTRODUCTION
The evolution of social networks has attracted considerable attention recently. Since the seminal work of Liben-Nowell and Kleinberg [18], it has been formulated as the link prediction task which studies the formation and variation of the links in the network. Both unsupervised and supervised approaches have been proposed, based on the current observations of the network, utilizing the structural or vertex-intrinsic features [19][9][20][1]. Most approaches treat the network as an evolving graph and each individual as a general vertex in the graph, while ignoring the initiative of individuals as active participants in the evolution of the social network.
From another point of view, people's social behaviors have been studied by sociologists long ago [28]. They have found many interesting and popular phenomena [23][21][26][8], which are also verified in online social networks by computer scientists [12][5][24] [11][27]. Among these phenomena is triadic closure [26][8], which states that two persons with common friends will likely become friends in the future. The sociological principle under this phenomenon is the transitivity of friendship [26][15]. Although researchers have found that most of new links close an open triangle [16], not all open triangles will be closed with equal probabilities. It's still unknown how this principle works in real world, and to what extent it can promote the evolution of social networks and furthermore benefit the link prediction task.
In this paper, we study the evolution of social network based on one of the well-known sociological principles, i.e. the transitivity of friendship. We address the above problems by positing that there is some underlying unknown network over which friendships propagate, and the evolution of social networks can be regarded as results of the friendship propagation based on common user interests. We formulate such network as the Latent Friendship Propagation Network (LFPN), which depicts the growth process of one's ego-centric social network driven by the friendship propagation via the co-influence effect of the friend circles with common user interests, and also captures the trend of friendship propagation on the whole network. In LFPN, we assume one, denoted by the ego, expands her social circles mainly via her existing friends, who act as intermediaries and introduce new friends to the ego explicitly or implicitly based on common interests.
We demonstrate the proposed LFPN with a toy example. Fig. 1(a) shows an egocentric network with a as the ego, which we mark as purple. The blue vertices are a's friends; the green ones show the friends of a's friends. The connections among the blue and green vertices are omitted for brevity. Given the plain structure of an egocentric network, we can hardly observe the implicit intrinsic

63

Ego

Ego

Ego

a

Local Layer

Local Layer

Local Layer

Global Layer

(a) Egocentric network of a

(b) a's partial view of the LFPN

(c) More complete view of the LFPN

Figure 1: An LFPN is composed of three layers: the ego layers, the local layers for each ego, and the global layer for the whole network. In this figure, the purple vertex a is the ego, the blue vertices are the friends of the ego and the green ones show other individuals in the network.

structures and relations within it. The LFPN shows a 3-layer hierarchical network for the original network. Fig. 1(b) shows the partial view of the ego a. While the first layer is the ego herself, the second layer, the local layer, consists of all her current friends and the directed edges as representation of the friendship propagation traces along which a created relationships with each one. In this figure we can see that a made friends with b directly, and via b she became friends of e, and furthermore she created friendship with d via b and e. Through the local layer as intermediaries a can make more new friends in the global layer in which the edges among individuals represent the potential friendship propagation directions in the whole network. While the local layer is defined for each ego and visualizes the growth of one's friend circles by showing the intermediaries for each of her friends, the global layer is inferred based upon all the local layers and defined for the whole network. A more complete LFPN with multiple egos is shown in Fig. 1(c).
However, learning the LFPN is challenging because the network over which friendship propagation takes place is usually unknown and unobserved. Thus, the first challenge is, how we can leverage one's social behaviors to infer all the potential intermediaries and furthermore learn the structure of the friendship propagation network?
While traditional approaches for link prediction are usually based on the topological features, LFPN provides a hierarchical view of one's friend circles from which we can observe the evolution of networks from the perspective of the ego, who drives this evolution progress. This leaves us the second challenge: to what extent the transitivity of friendship influences the network evolution, whether there is a co-influence effect of the friend circle, and how they can be utilized to predict future shapes of the network?
Along with the transitivity of friendship, another factor which affects one's social behaviors is the personal interests. In this study, we're also interested in the challenge that how the personal interests, along with the friendship propagation, affect the creation of friendships?
1.1 Contributions
To address these challenges we study how the LFPN can be inferred based on behavior modeling, and further utilized for predicting or recommending new links. To the best of our knowledge, this is the first time that the transitivity of friendship is deeply investigated and the link formation is studied based on the behavior modeling. The main contributions of this paper can be summarized as follows.
Firstly, we formulate the LFPN, which depicts the evolution traces of one's egocentric social network and potential friendship propagation traces on the whole network based on the transitivity of friendship with interest awareness.

We design LFPM (Latent Friendship Propagation Model), a probabilistic generative model for the friend-making behaviors of individuals in social networks. LFPM models the interest-aware friendship propagation driven by the transitivity of friendship. Given the time-stamped individuals' social behavior histories, we can learn the hidden LFPN based on LFPM effectively. It should be noted that both the friendship propagation and personal interests are inferred from the social behaviors only, and no other evidences are included.
Furthermore, we put forward a new method for link prediction utilizing the transitivity of friendship and personal interests based on the LFPN. We simulate the link creation using a random walk of an ego on the two layers of the LFPN. Firstly, she seeks for a preferred intermediary in her local layer of the LFPN, and via this intermediary she goes to the global layer where she makes new friends. We name this process as LFPN-RW (Random Walk upon LFPN), in which the random walk is guided by the friendship propagation based on the co-influence effect of friend circles and personal interests.
We conduct extensive experiments on real-world datasets. Experimental results show that the inferred LFPN actually contains important knowledge about the network evolution and can benefit the link prediction significantly.
1.2 Roadmap
The rest of this paper is organized as follows. We formulate the LFPN in Section 2. Methods for inferring the LFPN are developed in Section 3. Afterwards we present LFPN-RW, the new approach for link prediction upon LFPN in Section 4. In Section 5, we discuss the experimental results. We review related work in Section 6 and conclude this study in Section 7.
2. LFPN DEFINITION
In this section, we introduce the concepts related to LFPN. As shown in Fig. 1(c), the LFPN G is composed of three layers: the ego, the local layer and the global layer. In the following we first define the local layer and global layer respectively, and then give the definition of the LFPN.
Let G = {G1, G2, · · · , GT } denote an evolving social network where Gt = (Vt, Et) is a directed graph denoting the snapshot of the network at time t. Each vertex in Vt represents an individual in the network, and the edges in Et indicate the friendships among them. Gt denotes the new vertices and edges appearing during the period t (i.e. the time from t - 1 to t), and thus we have Gt = Gt-1  Gt. We'll use G to denote any snapshot of the evolving G for simplicity. Furthermore, for each snapshot Gt we have a corresponding interaction set Xt  Vt × Vt which denotes

64

the interactions among individuals in t. The interactions include co-authoring a paper in scholar collaboration network, leaving a message on Facebook, etc.
It should be noted that although the network G is directed here, the problem discussed in this paper is also applicable to undirected networks which can be transformed to directed networks.
In this paper, we study how E grows in social networks, i.e. the formation of friendships. Based on the transitivity of friendship, when two individuals become friends, we assume their common friends act as the role of "intermediaries".

Definition 1. Latent Friendship Propagation Triple (LFP Triple). For three vertices u, z and v in G, (u, z, v) is named as an LFP Triple if u makes friends with v via z. u is called the initiator of this tuple and z is the intermediary.

Each LFP Triple (u, z, v) is associated with an intermediation probability p(z| u, v ) which denotes the probability that z has
acted as the intermediary for u to makes friends with v. We use Ft(u) to denote the set of friends of u at time t, and
Ft(u, v) to denote the set of common friends of u and v at time t. As each common friend in Ft(u, v) may act as the intermediary, the intermediation probability satisfies:

p(z| u, v ) = 1.

(1)

zFt(u,v)

If u doesn't have any common friends with v, we assume u makes friends with v directly.

Definition 2. The local layer of ego u on an LFPN G, denoted as GL(u), consists of all the friends of u. For each LFP Triple (u, z, v) initiated by u there is a corresponding local LFP edge z, v in GL(u), whose weight wzL,(vu) = p(z| u, v ).
The local layer of the LFPN is defined for each ego u. Each friend of the ego u  GL(u) can play the role of intermediary for u to make more new friends. We use the intermediary preference probability p(u z) to measure u's preference for each friend z as the intermediary.
We define the cross-layer edges from the ego to the local layer as intermediary preference edges.
Definition 3. For each friend z  GL(u), there's an intermediary preference edge u, z pointing from the ego u to z in the local layer, whose weight wuE,z = p(u z).

Definition 4. Each LFP Triple (u, z, v) derives an LFP Pattern z v, indicating that one's friendship with z is likely to propagate to v.

Each LFP Pattern is associated with a friendship propagation probability p(z v) which denotes the extent to which z is willing to recommend v to her friends and the friends of z are likely to make friends with v in the future.
Definition 5. The global layer of an LFPN G, denoted as GG, consists of all the individuals of the given social network. For each LFP Pattern z v there's a corresponding global LFP edge z, v in GG, whose weight wzG,v = p(z v).

The global layer is defined for the whole network based on the LFP Patterns. It can be interpreted as the aggregation of all the local layers. Each vertex has its direct projection on the global layer so we don't define the cross-layer from the local to global layer again.
Now we can give the definition of LFPN.

U, K Nu, Vu F (u) Y (u) X (u)
u u u c zu,y , , ,  (cciz,z)i (cciy,y)i
(uuic,c)i (uuiz,z)i (zzi y,y)i (uuiv,y)i

Table 1: The notations for the LFPM # of individuals and topics # of new friends and interactions of u The current friend set of individual u The new friend set of individual u The interaction collection of individual u The intermediary preference distribution of u The friendship strength distribution of u The interest preference distribution of u The reputation distribution of topic c The intermediary assignment of the friendship u  y The prior parameters for , , , , respectively
# that zi has acted an intermediary in topic ci
# that yi has been recommended and accepted as a new friend in topic ci
# that ui has selected friends in topic ci
# that ui has selected zi as an intermediary
# that zi has recommend yi for others
# that ui has interacted with yi

Definition 6. The Latent Friendship Propagation Network (LFPN) G for a given social network G is a weighted 3-layer network consisting the ego layers {u}, the local layers for each ego {GL(u)}, and the global layer GG.
The local layer shows the inferred traces for the evolution history of one's current egocentric network, while the global layer indicates the possible traces for the friendship propagation on the whole social network in the future. The global layer can also be regarded as a friend-recommendation network, as in some sense it's the recommendation among people that promotes the friendship propagation.
3. LFPN INFERENCE
In this section, we develop effective algorithms for the inference of LFPN for the given social network. Before proceeding, we formulate our problem as follows:
LFPN Inference Problem. Given an evolving social network G = {G1, G2, · · · , Gt} and the associated interaction sets X = {X1, X2, · · · , Xt}, the LFPN inference problem is to infer the LFPNs G1, G2, · · · , Gt, where Gt is the LFPN for Gt.
As each snapshot is a subgraph of any of later snapshots, each LFPN also contains the structures of the LFPN inferred from the earlier snapshots. However, the weights of the same edges are not necessarily equal because the network is evolving and the propagation patterns are also varying.
In the remainder of this section, we first introduce the LFPM model for learning the LFPN on a single snapshot, and then present the inference framework for LFPM. We discuss the inference of LFPN on an evolving network at last.
3.1 The LFPM Model
Each LFP Triple (u, z, v) implies the assumption that the friendmaking behavior is a 2-step process: u selects z as an intermediary first and then via z she makes friends with v. Meanwhile this process is inevitably influenced by the interests of u. LFP Patterns are the aggregation of LFP Triples, and both of them are the basic elements for LFPN. Thus the preliminary problem for the LFPN inference is to find all the LFP Triples. In other words, given each friendship between u and v, we need to infer the intermediary z.

65

















 




  





 

 



Figure 2: The graphical representation of LFPM

To model this process and infer the intermediaries of each friendship, we propose the Latent Friendship Propagation Model (LFPM), a probabilistic generative model for the social behaviors in social networks. In this paper we only consider the social behaviors like friend-making and interactions. LFPM models the generative process for individuals' social behaviors as follows:
1. Sample the number of individuals U  Poisson ( ). 2. For each of the K interest areas c, sample its reputation dis-
tribution c  Dir() 3. For each individual u:
(a) Sample her friendship strength distribution u  Dir(u). (b) Sample the number of her interactions, Vu  Poisson(). (c) For each of the Vu interactions:
i. Sample one of her existing friends, x  u, as another participant of the interaction
4. For each individual u: (a) Sample her interest preference distribution u  Dir(). (b) Sample her intermediary preference distribution u  Dir(u). (c) Sample the number of her new friends, Nu  Poisson(). (d) For each of the Nu new friends: i. Sample an interest area c  u ii. Sample an intermediary z  u · c iii. Sample a new friend y  z · c
We draw the graphical representation of LFPM in Fig. 2. In LFPM, each interest area is modelled as a distribution over individuals. Each ego is modelled as a distribution of her intermediaries, i.e. the individuals that may make recommendations to her, and each intermediary as a distribution over the friends of this intermediary. Thus, the set of new friends of an ego can be modelled as the mixture of her intermediaries and interest areas. Specifically, the intermediary preference distribution  describes through whom an ego prefers to make new friends, and friendship strength distribution  models the closeness of an ego with each of her friends. Such closeness can be reflected by both the frequency of their interactions and the willingness of the ego to recommend her friends to others. We use the interest preference distribution  to model one's interest preference in friend-making behaviors, and regard the reputation distribution  as a global reputation ranking of all individuals in each interest area. It's natural to assume that one prefers to make friends with someone with higher reputation in her preferred area. It should be noted that the interests here are learned only from the social behavior histories, rather than external profiles.
To improve the inference performance, we adopt heuristic pruning by constraining that for each individual her intermediary preference distribution and friendship strength distribution are only defined over her current friends, based on the assumption that only the

current friends of ego u may act as u's intermediaries, and that an intermediary z can only recommend and interact with the current friends of z. This is different from traditional topic models like LDA[2], which defines the distributions over the whole space. Thus
in our model, each individual maintains a unique sampling space
for herself. Correspondingly, the prior distributions for  and  are also required to be defined on the corresponding pruned space for
each individual. That's why the priors  and  need to be defined for each individual u and are placed within the big box labelled U in the graphical model shown in Fig. 2.
LFPM applies to a snapshot Gt and tries to infer the friendship propagation in the expansion of one's egocentric network in peri-
od t. For the social behaviors that happen in period t, the hidden distributions  and  of LFPM can be naturally interpreted as the intermediary preference probabilities wE of each ego and friendship propagation probabilities wG in the LFPN in period t, respectively. Each possible intermediary assignment for each friendship
is an LFP Triple and the sampling probability can be regarded as the intermediation probabilities wL. With the inferred LFP Triples and the weights wE, wL and wG we can construct the LFPN Gt.

3.2 Inference Framework for LFPM

Exact inference for LFPM is generally intractable. In this sub-

section we present the framework for LFPM inference using Gibbs

sampling, a special case of Markov-Chain Monte Carlo (MCMC)

simulation, which can emulate high-dimensional probability distri-

butions by the stationary behavior of a Markov chain.

Firstly, the joint probability of all observed and unobserved data

can be stated as follows (with the distributions integrated out): P (C, Z, X, Y ; , , , )

=

U
(
u=1

B

((uuz) + B((u)

(u)) )

K
)(
k=1

B((kcz) + (kcy) B()

+

) )

·

U
(
u=1

B((uuv) + (uzy) B(u())

+

u())

U
)(
u=1

B((uuc) + B()

)

),(2)

where B(·) is the multinomial Beta function. For the details of

other notations please refer to Table 1.

We infer the model by updating the estimation for unobserved

variables c and z iteratively. In each iteration, we sample c and z

for each new friendship i according to the conditional probability

p(ci|C-i, Z, X, Y ; , , , ) and p(zi|C, Z-i, X, Y ; , , , ).

Y and X are the new friendship and the interaction data, respec-

tively. C and Z are estimations for the interest area and intermedi-

ary for each friendship, respectively. C-i is the current estimations except ci and Z-i is that except zi.

The sampling probabilities can be estimated by

p(ci|C-i, Z, X, Y

; , , , )=

P (C, Z, X, Y ) P (C-i, Z, X, Y )



((cciz,z)i + (cciy,y)i + ci,zi - 1) vF (ui)((cciz,v) + (cciy,v) + ci,v) - 1

·

(uuic,c)i + ui,ci - K k=1((uuic,k) + ui,k

1 -

1)

,

(3)

p(zi|C, Z-i, X, Y ; , , , )=

P (C, Z, X, Y ) P (C, Z-i, X, Y )



(uuiz,z)i + (ui),zi - 1 vF (ui)((uuiz,v) + (ui),v ) - 1

·

(zui,vy)i + (zzi,yy)i + z(i,)yi - 1 vF (ui)((zui,vv) + (zziy,v) + z(i,)v ) - 1

·

(cciz,z)i + (cciy,z)i + ci,zi - 1 vF (ui)((cciz,v) + (cciy,v) + ci,v )

-

1

.

(4)

66

Algorithm 1 LFPM Inference using Gibbs Sampling

Require:

The snapshot network Gt-1 at time t - 1 The increment of the network in period t, Gt

The interaction set in period t, Xt

Ensure:

The hidden distributions , , ,  The sampling distributions P c, P z

1: Initialize F, Y using Gt-1, Gt, respectively

2: Assign interest areas for each new friendship randomly

3: Assign intermediaries for each new friendship randomly

4: while not finished do

5: for each individual u who has new friends do

6:

for each new friend v  Y (u) do

7:

Sample interest area using Eq. 3

8:

Sample intermediary using Eq. 4

9: end for

10: end for

11: end while

12: Update distributions , , ,  using Eq. 5 ­ 8

13: Record all the sampling distributions for topics and intermedi-
aries in the last iteration with P c and P z 14: return , , , , P c, P z

Given the estimations for all unobserved data, we can estimate

the hiddenduiis,ztriib=utionvs: F((uuuiiz,)z)(i+(uuiz,v)(u+i),zi (ui),v) ,

(5)

zi,yi =

(zui ,vy)i

+

(zzi

y) ,yi

+

z(i ,)yi

vF (ui)((zui,vv) + (zziy,v) + z(i,)v )

,

(6)

ui,ci =

(uuic,c)i + ui,ci

K k=1

((uuic,k)

+

ui ,k )

,

(7)

ci,ui =

(cciz,u)i + (cciy,u)i + ci,ui

U u=1

((cciz,u)

+

(cciy,u)

+

ci ,u )

.

(8)

Algorithm 1 presents the inference framework. Firstly, it initial-

izes the friends set F before period t, and the new friendships Y

that emerge in t. The interest area and intermediary for each new

friendship are initialized randomly before the iteration. Next in

Line 4­11 the interest and intermediary are updated for each new

friendship using Eq. 3 and 4, iteratively. The iteration is repeated

until converge or the count of iterations reaches a given threshold.

The hidden distributions can be estimated using Eq. 5 - 8.

3.3 Learning Evolving LFPN in Cascade
In LFPM all behaviors are assumed to be independent with each other, and the correlation among the behaviors is ignored, which will lead to the loss of knowledge carried by the temporal behavior sequence. To minimizing this loss, we can split the evolving social network G into fine-grained snapshots G1, G2, · · · , Gt and infer the LFPM model on each snapshot, and thus we can build the corresponding LFPN G1, G2, · · · , Gt respectively. However, each Gt is also a snapshot of the evolving G and only carries the information of the behaviors in t, but ignores the knowledge of the previous behavior history. For learning the complete evolving LFPN, we apply the LFPM in cascade, during which the later models can inherit the knowledge learned from the previous models.
The knowledge accumulation in cascade LFPM is achieved by the prior parameters, which can significantly influence the behaviour of the model by bringing important priori knowledge[10]. Via the priors, the knowledge in the previous period can be transferred in-

Algorithm 2 Building Evolving LFPN

Require:

The evolving network G

Ensure:

The evolving LFPNs {Gt} for G 1: Split G into T subgraphs by discrete periods

2: for each period t  T do

3: Initialize the priors for t using the previous model according

to Eq. 9 ­ 12

4: Infer the LFPM on Gt 5: Initialize LFPN Gt using the structure of Gt-1

6: {In the following we omit the subscript t of weights and

distributions for brevity}

7: for each ego u  Gt do

8:

Add new friends of u in t to GtL(u)

9:

for each friend z  GtL(u) do

10:

Add cross-layer edge u, z and set wuE,z  u,z

11: end for

12: for each LFP Triple (u, z, v) initiated by u do

13:

Add local LFP edge z, v to GtL(u)

14:

Set wzL,(vu)  p(z| u, v )

15: end for

16: end for

17: Add new individuals to GtG

18: for each LFP Pattern (z, v) derived from the LFP Triples do

19:

Add global LFP edge z, v to GtG

20:

Set wzG,v  z,v

21: end for

22: end for

23: return G1, G2, · · · , Gt

to the next period successively. We define the priors of the LFPM at time t as the linear combination of the accumulated knowledge from previous models encoded by the priors and the new knowledge encoded by the statistics in the last period t - 1 as follows:

tu,z =  · tu-,z1 + (uu,z,z)(t-1) ut ,y =  · ut-,y1 + (uu,y,v)(t-1) + (uz,,yy)(t-1) ut ,c =  · ut-,c1 + (uu,c,c)(t-1) ct,u =  · ct,-u1 + (cc,u,y)(t-1)

(9) (10) (11) (12)

where  is a cascade damping factor. A higher  means to inherit more priori information from the earlier models. For the first model the priors are initialized with the default values 0, 0, 0, 0.
While cascade LFPM allows knowledge accumulation in the model inference on the sequential snapshots, the LFPN can also inherit the structures from previous periods. By adding the new structures and updating the weights learned from the LFPM for each period, we can always get the up-to-date evolving LFPN for the evolving social network. The details are given in Algorithm 2.

4. LFPN-BASED LINK PREDICTION
LFPN adopts the transitivity of friendship to explain the evolution of social networks and shows the potential friendship propagation in the network. An interesting problem is, to what extent the LFPN can model the hidden power which drives the growth of social networks. We study this by applying LFPN in the traditional link prediction problem in social networks. We formulate the problem as follows:
LFPN based Link Prediction Problem. Given an LFPN Gt inferred from a snapshot Gt of the evolving social network G at

67

Table 2: The statistics of the datasets. V, E: number of existing nodes and edges in each dataset, S: number of egos for prediction, D:

total number of candidate friends for the egos, R: total number of candidate friendships for prediction, E/V: average degree of each

node, R/S: average candidate friendships of each ego.

Dataset

V

E

S

D

R

E/V

R/S

cond-mat 27,348 72,119 465 21,266 274,817 2.637 1,182.009

hep-ex 5,667 60,425 45 3,476 85,447 10.663 3,797.644

hep-lat 3,804 13,331 216 3,059 74,189 3.504 686.935

hep-ph 17,615 78,932 601 14,943 529,623 4.481 1,762.473

hep-th 14,751 27,299 113 11,608 100,717 1.851 1,782.603

nucl-ex 4,425 59,769 167 3,396 132,803 13.507 1,590.455

time t, our problem is to predict the new friendships in period t + 1, i.e. Et+1.
Here we don't consider the new-coming vertices in the network. Random Walk (RW) provides an effective node proximity measure for predicting new links [31][1]. However, traditional RW regards the social network as a plain graph while ignoring the motivation of individuals. Unlike them, we predict new links based on behavior modeling. We design a new random walk upon the LFPN, LFPNRW. In LFPN-RW, we treat the creation of new friendship as the result of friendship propagation in the network. In this way, LFPNRW captures the co-influence effect of the friend circles on one's friend-making behaviors, rather than considering them as independent events. Furthermore, the personal interests are also taken into consideration by being incorporated within the weights of edges.
To predict the new friends of u, consider a random walker who starts the LFPN-RW from the ego u. Then LFPN-RW operates on the local and global layer of the LFPN successively, modeling the 2-step friend-making process. The walk on local layer allows one to find an intermediary first, and to make new friends via this intermediary on the global layer next. The basic assumption for the random walk on the local layer is that one should prefer the intermediary whom she knows via her preferred intermediaries; and that for the random walk on the global layer is that one should be likely to make friends with those recommended by important people.
We introduce the process of LFPN-RW for u as follows. Firstly, the walker goes to any vertex z  GL(u) with the intermediary preference probability wuE,z, and walks in GL(u) randomly. At each vertex, the walker can go to next vertex along any local LFP edge with probability 1 - , or go back to the ego u with probability  and then restart the walk.
When the walker stops at some vertex z  GL(u), before jumping to the ego u, she jumps to the projection of z in the global layer GG, and starts the random walk on GG to find a new friend. Arriving at any vertex in GG, the walker may go to any of its neighbors along the global LFP edges with probability 1-, or just stop there with probability  and then jump back to the ego u directly.
Before proceeding, we revise the weight definition of the edges in LFPN to combine the global propagation probabilities and personal interests in the random walk from u:

wzL,(vu) = z,v · p(z| u, v ),

wvG,(yu) = v,y ·

(u,c · c,y),

cC

(13) (14)

where C is the collection of interest areas. Eq. 13 biases the local
layer using global propagation probabilities. Meanwhile, Eq. 14
biases the global layer by incorporating the personal interests, and
thus ensures that the friendship is more likely to propagate to those
with higher reputation in u's preferred interest areas in the random walk of u.
Let rL(u)(z) and rG(u)(v) denote the steady-state probabilities of the random walk initialized from the ego u in GL(u) and GG(u),

respectively. They satisfy: (assuming all the weights in LFPN are

normalized)

rL(u)(z) = (1 - ) ·

wzL(,uz) · rL(u)(z ) +  · wuE,(zu)

z F (u,z)

(15)

rG(u)(v) = (1 - ) ·

wvG(,uv) · rG(u)(v ) +  · rL(u)(v)

v F (v)

(16)

where  is the restart probability in the walk. rL(u)(z) can be regarded as the probability that u will select z as the intermediary in a friend-making behavior, and rG(u)(v) as the probability that u decides to make friends with v finally. This can be used to predict or recommend new friends for u.

5. EXPERIMENTAL EVALUATION
In this section, we demonstrate the effectiveness of our model through comprehensive experiments on multiple real-world datasets. We introduce our experimental settings in the first two subsections, and afterwards present and discuss the details of the experimental results.
5.1 Datasets
We construct 6 real-world datasets from Arxiv1, an archive for electronic preprints of scientific papers in the fields of mathematics, physics, etc. The datasets include cond-mat (Condensed Matter), hep-ex (High Energy Physics - Experiment), hep-lat (High Energy Physics - Lattice), hep-ph (High Energy Physics - Phenomenology), hep-th (High Energy Physics - Theory) and nucl-ex (Nuclear Experiment). For each dataset, we use the network evolution history in 1998­2000 as the training set and predict the new links emerging in 2001­2003. Here we only make predictions for the egos who have been in the network up to 1998. And then for each ego, we select her/his 2-hop neighbors as candidate friends for prediction, because it's found that most of the new links connect two individuals with common friends[16][1]. The statistics of the datasets are shown in Table 2.
5.2 Baselines and Evaluation Methodology
Baselines. We compare our method with other 9 popular link prediction methods, which can be classified into 5 sorts.
· Local neighbourhood based measures, including Jaccard Coefficient and Adamic / Adar, two best measures reported in [19].
· Variants of random walk based on global network structures, including Random Walk with Restarts (RWR) [25] , SimRank [13] and Maximum Entropy Random Walk (MERW) [4]. RWR measures the proximity between two nodes by the probability that one arrives at another in a random walk. SimRank
1Arxiv: http://arxiv.org/

68

Dataset cond-mat
hep-ex hep-lat hep-ph hep-th nucl-ex

Metric MAP P@10 AUC MAP P@10 AUC MAP P@10 AUC MAP P@10 AUC MAP P@10 AUC MAP P@10 AUC

Table 3: The performance of various link prediction methods on the six datasets.

AdamicAdar Jaccard LaFT-Proximity SimRank MF MF-BL RWR MERW SRW

0.20119

0.1743

0.20796

0.12685 0.09929 0.09266 0.25933 0.2165 0.26378

0.08782 0.07815

0.07438

0.05363 0.04761 0.04524 0.1089 0.10901 0.10428

0.69089 0.62261

0.70027

0.5658 0.53794 0.50567 0.74899 0.59948 0.75552

0.23527 0.23922

0.23388

0.20722 0.10362 0.12034 0.26752 0.20549 0.21131

0.10001 0.11556

0.07667

0.12222 0.06444 0.06667 0.08667 0.05111 0.08889

0.65977

0.6738

0.67723

0.66678 0.47561 0.47822 0.6697 0.64236 0.66543

0.19878 0.15381

0.20324

0.10139 0.06187 0.08202 0.25117 0.19337 0.25893

0.11574 0.08287

0.09083

0.05046 0.02685 0.04352 0.14444 0.08093 0.09028

0.73988 0.67935

0.74152

0.61405 0.51185 0.48524 0.78936 0.61661 0.80564

0.17418 0.16228

0.17627

0.09455 0.07149 0.07835 0.24014 0.1994 0.22646

0.08587 0.07056

0.05775

0.03729 0.04344 0.06837 0.11566 0.09274 0.11141

0.71379 0.66339

0.72125

0.59292 0.53282 0.61038 0.76727 0.6312 0.75767

0.19384 0.16609

0.11209

0.09864 0.08205 0.11605 0.25992 0.21746 0.23688

0.06903 0.06814

0.07918

0.03717 0.02655 0.03982 0.10088 0.10133 0.09425

0.68021 0.63403

0.69231

0.53306 0.51608 0.51852 0.74719 0.60993 0.72813

0.18049 0.17826

0.22870

0.1858 0.09074 0.09723 0.28525 0.29525 0.25826

0.12216 0.10599

0.12994

0.11018 0.0521 0.06527 0.16826 0.16581 0.18497

0.71581 0.67474

0.75488

0.68996 0.49876 0.53021 0.76803 0.72169 0.76481

LFPN-RW 0.24867 0.11191 0.76101 0.26608 0.09778 0.67919 0.27711 0.16019 0.83025 0.27212 0.12830 0.81268 0.25668 0.11239 0.78204 0.31502 0.22515 0.79627

estimates how soon two random walkers will meet each other in the graph. While both assume the graph is unweighted, MERW assigns the propagation probabilities proportional to the eigenvector centrality of nodes [17]. · A state-of-the-art supervised link prediction approach, Supervised Random Walk (SRW) [1], which performs random walk on a weighted graph with the weights learned as a function of features. · Matrix Factorization methods, including the basic MF [30] which considers the hidden features as the recommendation of intermediaries, and an improved method, denoted as MFBL here, which tries to overcome the imbalance problem [22]. · LaFT-Proximity, a proximity measure based on the LaFTTree, our previous work which studies the transitivity of friendship in social networks[32]. All of the above methods are based on link structures while SRW utilizes more external features. Evaluation Metrics. We evaluate the prediction performance of the above algorithms using 3 metrics: MAP (Mean Average Precision), P@10 and AUC (Area Under the ROC Curve). Generally, MAP measures how well the algorithm ranks positive instances above negative instances, P@10 measures the precision of the top 10 predictions given by the algorithm, and AUC measures how well the algorithm distinguishes positive instances from negative instances. Parameter Settings. For LFPM, we set the default priors 0 = 0 = 1, 0 = 0 = 0.1, and the number of interest areas K = 10, as they are shown appropriate in our experiments. For each LFPM, we run Gibbs sampling for 20 iterations at most. The cascade damping factor for LFPM  = 0.5. In LFPN-RW, RWR, MERW and SRW, we set the restart probability  = 0.15, and the number of iterations of random walk is limited to 100. For SimRank, we set the decay factor C = 0.8 and the maximum number of iterations as 6, as in [13]. For MF and MF-BL, we set the number of hidden features as 20. For SRW, we select the Wilcoxon-Mann-Whitney (WMW) loss function and logical edge strength function, as reported the best in [1]. We select the two-hop neighbors of each ego as the negative instances for that in our settings only the two-hop neighbors are considered as the candidate friends for prediction. We apply the gradient descent method to solve the optimization problem and the iteration is executed at most 20 times. The features for SRW include number of friends of the two individuals, number of their common friends, Jaccard coefficient and Adamic/Adar score.

5.3 Performance Comparison
We present the evaluation results in Table 3. As highlighted in bold, LFPN-RW consistently outperforms other methods on most datasets and most metrics.
LaFT-Proximity is a proximity measure based on the LaFT-Tree, another work which tries to explain link formation using the transitivity of friendship. Though LaFT-Proximity shows better performance than other local neighbourhood based measures, including Jaccard and Adamic/Adar, it fails when compared with more complex algorithms which can utilize more global network information. LaFT-Proximity is always worse than our LFPN-RW, demonstrating the importance and effectiveness of modeling interests in LFPM and capturing the co-influence of friend circles in LFPN-RW.
By utilizing the global network topological structure for proximity measure, random walk based methods, including RWR, MERW and SRW, show better performance than other baselines. In most occasions their performance exceeds Adamic/Adar and Jaccard, the two best local measures reported in [19]. However, the variants of RWR, MERW and SRW, are not always better than RWR as expected. SRW outperforms the RWR on cond-mat and hep-lat on MAP and AUC, but becomes worse on hep-ph. MERW fails to improve the performance of RWR on most of our datasets. Both MERW and SRW try to weight the edges in the graph based on the topological features; on the contrary, LFPN-RW weights the edges by modeling the behaviors of individuals and capturing the co-influence of friend circles based on the common user interests, and thus achieves better improvement over RWR than MERW and SRW. On hep-lat, hep-ph and nucl-ex, LFPN-RW achieves on average 0.04 higher AUC and 0.03 higher MAP as compared to RWR. Furthermore, we notice that LFPN-RW is not only accurate but also more stable than others. This convinces us that the LFPN can capture the important information about the network growth and people's friend-making behaviors.
It is important to note that, unlike SRW which requires feature extraction from both positive and negative instances, LFPN estimates the weighted network from only the "positive instances", and no other features are considered.
The performance of LFPN-RW far exceeds that of MF which tries to capture the effect of intermediary by matrix factorization, and that of its improved version MF-BL. While in matrix factorization we can explain the latent feature space as the intermediation effect, these methods cannot utilize the internal relations among individuals' friend-making behaviors and thus the intermediation effect cannot be modelled well.

69

MAP

MAPVS.#TRAININGCASCADES heplat nuclex
0.34
0.32
0.3
0.28
0.26
0.24 012345678 #TRAININGCASCADES

AUC

AUCVS.#TRAININGCASCADES heplat nuclex
0.86
0.84
0.82
0.8
0.78
0.76 012345678 #TRAININGCASCADES

Figure 3: The effect of knowledge accumulation in Cascade LFPM on the link prediction performance of LFPN-RW.

AUC

AUCOFYEARLYLINKPREDICTION

RWR

LFPNRW

0.9

0.85

0.8

0.75

0.7

0.65

0.6

0.55

0.5 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002
YEAR

AUC

AUCOFYEARLYLINKPREDICTION

RWR

LFPNRW

0.9

0.85

0.8

0.75

0.7

0.65

0.6

0.55

0.5 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004
YEAR

(a) hep-lat

(b) nucl-ex

Figure 4: The performance of dynamic link prediction for each year.

MAPVS. heplat nuclex 0.36

0.845

AUCVS.

heplat

nuclex

0.34

0.84

0.32

0.835

MAP AUC

0.3

0.83

0.28

0.825

0.26

0.82

0.24

0.1

0.3

0.5

0.7

0.9



0.815

0.1

0.3

0.5

0.7

0.9



Figure 5: The variance of link prediction performance of LFPN-RW with different damping factor  in Cascade LFPM.

5.4 Effect of Knowledge Accumulation
In this subsection, we study to what extent the knowledge accumulation in Cascade LFPM can influence the learned LFPN and the link prediction performance based on LFPN. We conduct this study by three questions: (1) Does a longer training time mean more accumulated knowledge and thus promise better performance in link prediction? (2) As time goes by, with more knowledge accumulated in cascades, will the prediction performance increase continuously? (3) How should we control the amount of the accumulated knowledge that be passed from one period to the next?
We answer the first question by examining the performance variance of LFPN-RW on the LFPNs with different length of training time. Longer training time means more earlier knowledge is learned and accumulated, and afterwards reflected in the final LFPN. Fig. 3 shows the experimental results. Here we split the training data into multiple cascades by year and each cascade corresponds to one year. For the sake of readability we only show the results on hep-lat and nucl-ex, and similar results are observed on other datasets. When the number of training cascades is 0, our LFPN-RW decays to RWR. LFPN-RW with one training cascade only utilizes

MAP AUC

MAPVS. heplat nuclex 0.35

0.33

0.31

0.29

0.27

0.25

0.1

0.3

0.5

0.7

0.9



AUCVS. heplat nuclex 0.85

0.83

0.81

0.79

0.77

0.75

0.1

0.3

0.5

0.7

0.9



Figure 6: The variance of link prediction performance of LFPN-RW with different  in LFPN-RW.

the knowledge of the current period and outperforms that with no training cascade, i.e. RWR, on both datasets and both metrics. The AUC of LFPN-RW increases with the number of training cascades in the beginning, and then tends to be stable after 4 training cascades. This indicates that the accumulated knowledge in the recent time can really improve the performance; however, the knowledge too far in the past has little effect because people's behaviors and interests are changing with time. This finding proves that our approach is more feasible as when only little training data are given it can still show promising performance.
To answer the second question, we conduct dynamic link prediction tasks on the datasets. For fixed individuals in the first year in each dataset, we make yearly link prediction which predicts the new links for the next year given the network in each year, and study how the performance will vary. As time goes by and the number of friends of each individual keeps growing, there will be more candidate friendships than new emerging friendships in each year, so it's difficult to compare the performance on a sequential basis. Thus we compare LFPN-RW with RWR in each year. The results are presented in Fig. 4. The curves of RWR and LFPN-RW are quite similar on both datasets. We observe that LFPN-RW is not only always better than RWR, but also more stable, as shown in the more smooth curve. RWR will perform worse if there exist outliers in the network; however, LFPN becomes increasingly robust with continuous knowledge accumulation. Furthermore, in nucl-ex and later time of hep-lat, we see the improvement of LFPN-RW over RWR increases with time.
Finally, we study how we can control the extent of knowledge accumulation by the cascade damping factor  in LFPM inference for better link prediction performance. The choice of  faces the trade-off between the knowledge learned in the new period and that accumulated from previous models. Just think of the extreme cases. When  = 0, each LFPM is trained in each period independently, without the accumulated knowledge; however, when  = 1, all previous knowledge is passed to the next model, with equal importance as the new knowledge. Typically, we set a higher  when less data is observed in the specific period. Otherwise, if we observe sufficient data for the current model, we can lower the influence of the previous models on the current one by setting a smaller . When evaluating on real data we observe that  plays an important role in the cascade inference procedure. For the sake of readability, we only show some representative curves in Fig. 5. We can see  in the range from 0.3 to 0.5 seems to be most appropriate.
5.5 Effect of Co-influence of Friend Circles
In LFPN-RW, we treat the creation of a new friendship as a result of friendship propagation in the network and model the link prediction as a random walk upon the LFPN, taking the co-influence ef-

70

MAPONEACHDATASET WithInterestAwareness WithoutInterestAwareness 0.35

AUCONEACHDATASET WithInterestAwareness WithoutInterestAwareness 0.85

0.3

0.8

MAP AUC

0.25

0.75

0.2

0.7

0.15 condmat hepex

heplat hepph DATASET

hepth

nuclex

0.65 condmat hepex

heplat hepph DATASET

hepth

nuclex

Figure 7: Comparison of link prediction performance of LFPNRW with/without interest awareness.

fect of the friend circles on one's friend-making behaviors into consideration naturally. In this subsection we study how we can benefit from the co-influence effect. In the LFPN-RW, the restart probability  controls how "far" the walker wanders on the network; a smaller value allows the walker to walk farther and increases the co-influence of the friend circles on one's friend-making behaviors, and a larger value enhances the direct influence of one's current friends. As shown in Fig. 6, in our evaluations we see the lower value of  tends to achieve better performance. This demonstrates the importance of the co-influence captured in our LFPN-RW. Furthermore, the performance will decrease if  < 0.3 because the direct influence from the current friends is reduced too much. To achieve better performance, one needs to make trade-off between the influence from current friends and the co-influence of friend circles in specific networks.
5.6 Effect of Interest Awareness
In LFPM and LFPN-RW, we assume that the creation of friendship is the result of friendship propagation, which would be influenced by both the transitivity of friendship and the personal interests. In this subsection, we investigate how personal interests will influence the link prediction performance. We remove the interest factors, including  and , from LFPM and LFPN-RW, and get a new algorithm denoted by LFPN-RW without Interest Awareness. Correspondingly, our original algorithm can be denoted by LFPNRW with Interest Awareness. We compare the performance of the new algorithm with our original algorithm on all the datasets and the results are shown in Fig. 7. We can see the latter outperforms the former on most datasets. It should be noted that we don't introduce external personal profiles to learn the personal interests. This convinces us that the personal interests can be well captured from the social behaviors of the individuals and the topological structure of the network, and furthermore can benefit the link prediction using LFPN-RW, i.e. the LFPN-RW with Interest Awareness here, which models the friendship propagation with interest awareness.
5.7 Convergence Analysis
In this subsection we study the convergence speed of our LFPM inference and LFPN-RW.
In Fig. 8 we investigate how the performance of LFPN-RW varies with the number of iterations of LFPM. From the two representative curves on hep-lat and nucl-ex, we see the performance increases quickly, and then LFPM converges in nearly 15 iterations.
Fig. 9 shows the performance variance with the number of iterations in LFPN-RW. Experimental results on hep-lat and nucl-ex demonstrate the LFPN-RW converges in about 30 iterations.
6. RELATED WORK
Link prediction is a classical problem which attracts many at-

MAP AUC

MAPVS.#ITERATIONS INLFPM heplat nuclex
0.46 0.44 0.42
0.4 0.38 0.36 0.34 0.32
0.3 2 4 6 8 10 12 14 16 18 20 #ITERATIONS

AUCVS.#ITERATIONSINLFPM heplat nuclex
0.9
0.88
0.86
0.84
0.82
0.8
0.78 2 4 6 8 10 12 14 16 18 20 #ITERATIONS

Figure 8: The variance of link prediction performance of LFPN-RW with increasing number of iterations in LFPM.

MAP AUC

MAPVS.#ITERATIONSINLAFTRW heplat nuclex
0.33

0.32

0.31

0.3

0.29

0.28

0.27

0.26

0.25

5 10 15 20 25 30 35 40 45 50 #ITERATIONS

AUCVS.#ITERATIONSINLAFTRW heplat nuclex
0.85

0.845

0.84

0.835

0.83

0.825

0.82

0.815

0.81

5 10 15 20 25 30 35 40 45 50 #ITERATIONS

Figure 9: The variance of link prediction performance of LFPN-RW with increasing number of iterations in LFPN-RW.

tentions. The general approach for link prediction is based on the proximity measuring in the network. One branch of this method is based on the local neighbourhood structures, such as common neighbors, Jaccard coefficient and Adamic/Adar, all of which were surveyed by Liben-Nowell and Kleinberg [19]. Another popular approach utilizes the random walk to measure the node proximity on the whole network, including Random Walk with Restarts (RWR) [25], SimRank [13] and Katz [14]. Approaches have also been proposed to improve the traditional random walk by adjusting the transition probabilities , including randomized shortest-path (RSP) dissimilarity [29] and Maximum Entropy Random Walk(MERW) [4][17]. Supervised Random Walk(SRW) was proposed to learn the transition probabilities with a supervised method [1]. However, supervised methods face the imbalance problem [20][22] and require elaborate feature extraction; on the contrary, our LFPN-RW models personal behaviors depending only on the positive instances. Furthermore, we identify personal interests from their social relations only, without other node-specific attributes.
It's also interesting to study how the network evolves [16] and how people make friends [12]. Researchers have found many interesting patterns, such as preferential attachment [23], triadic closure [27], reciprocity[24][11] and homophily [5]. The transitivity of friendship has been noticed long ago [26][28] and used to explain the phenomenon of triadic closure in social networks [15]. Recently, the role of triadic closure in the link formation in social networks was further verified [7][27][3][6]. However, it hasn't been studied that how the triadic closure and the transitivity of friendship drive the microscopic evolution of social networks. Yin et al. proposed a matrix factorization approach for link prediction by considering the hidden features as the recommendation of intermediaries [30]. Their work is a bit similar with ours; however, they ignore the sequential relationship among the social behaviors and cannot model the actual contribution of each intermediary on the link formation.
Our previous work [32] primarily focuses on how to capture the expansion traces of one's social network. It does not explore the

71

dimension of personal interest and model its impact on network expansion. Neither does it utilize the concept of friend circles to capture the co-influence effect of one's friends based on interest awareness as in our paper.
7. CONCLUSION
Modeling people's social behaviors and furthermore understanding their motivations are important for us to know how the social network emerges, evolves and vanishes eventually, as the people are the dominant players in social networks. In this paper, we model people's friend-making behaviors using the LFPM, a generative model driven by the famous sociological principle of the transitivity of friendship and personal interests. The inferred LFPN incorporates rich knowledge about the patterns of individuals's behaviors and the growth potentials of the social network, with the co-influence of friend circles and personal interest well modeled. Furthermore, we propose LFPN-RW, which treats the link prediction task as a random walk on the LFPN, guided by the interestaware friendship propagation. Our approach achieves promising performance in experimental studies, which leads us to draw the conclusion that the transitivity of friendship really plays important roles in the evolution of social networks and can be utilized to analyze the network evolution if well modeled with interest awareness.
8. ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their valuable comments and suggestions to improve this paper. This work is supported in part by the National Natural Science Foundation of China (No. 61170064, No. 61073005, No. 61133002), the National High Technology Research and Development Program of China (No. 2012AA011002), US NSF through grants IIS-0905215, CNS-1115234, IIS-0914934, DBI-0960443, and OISE-1129076, and Huawei grant.
9. REFERENCES
[1] L. Backstrom and J. Leskovec. Supervised random walks: predicting and recommending links in social networks. In WSDM '11, pages 635­644, 2011.
[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993­1022, Mar. 2003.
[3] M. J. Brzozowski and D. M. Romero. Who should I follow? recommending people in directed social networks. In ICWSM'11, 2011.
[4] Z. Burda, J. Duda, J. M. Luck, and B. Waclaw. Localization of the maximal entropy random walk. Phys Rev Lett, 102(16):160602, 2009.
[5] M. De Choudhury. Tie formation on twitter: Homophily and structure of egocentric networks. In SocialCom/PASSAT '11, pages 465 ­470, 2011.
[6] M. Doroud, P. Bhattacharyya, S. F. Wu, and D. Felmlee. The evolution of ego-centric triads: A microscopic approach toward predicting macroscopic network properties. In SocialCom/PASSAT '11, pages 172 ­179, 2011.
[7] S. A. Golder and S. Yardi. Structural predictors of tie formation in twitter: Transitivity and mutuality. In SocialCom/PASSAT '10, pages 88­95, 2010.
[8] M. S. Granovetter. The Strength of Weak Ties. The American Journal of Sociology, 78(6):1360­1380, 1973.
[9] M. A. Hasan, V. Chaoji, S. Salem, and M. Zaki. Link prediction using supervised learning. In SDM '06 workshop on Link Analysis, Counterterrorism and Security, 2006.

[10] G. Heinrich. Parameter estimation for text analysis. Version 2.9, Fraunhofer IGD, 2009.
[11] J. Hopcroft, T. Lou, and J. Tang. Who will follow you back?: reciprocal relationship prediction. In CIKM '11, 2011.
[12] H. Hu and X. Wang. How people make friends in social networking sites - a microscopic perspective. Physica A: Statistical Mechanics and its Applications, 391(4):1877 ­ 1886, 2012.
[13] G. Jeh and J. Widom. Simrank: a measure of structural-context similarity. In KDD '02, 2002.
[14] L. Katz. A new status index derived from sociometric analysis. Psychometrika, 18:39­43, 1953.
[15] D. Krackhardt and M. S. Handcock. Heider vs simmel: emergent features in dynamic structures. In ICML'06, 2006.
[16] J. Leskovec, L. Backstrom, R. Kumar, and A. Tomkins. Microscopic evolution of social networks. In KDD '08, 2008.
[17] R.-H. Li, J. X. Yu, and J. Liu. Link prediction: the power of maximal entropy random walk. In CIKM '11, 2011.
[18] D. Liben-Nowell and J. Kleinberg. The link prediction problem for social networks. In CIKM '03, 2003.
[19] D. Liben-Nowell and J. Kleinberg. The link-prediction problem for social networks. J. Am. Soc. Inf. Sci. Technol., 58(7), 2007.
[20] R. N. Lichtenwalter, J. T. Lussier, and N. V. Chawla. New perspectives and methods in link prediction. In KDD '10, 2010.
[21] M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds of a feather: Homophily in social networks. ANNUAL REVIEW OF SOCIOLOGY, 27:415­444, 2001.
[22] A. K. Menon and C. Elkan. Link prediction via matrix factorization. In ECML PKDD'11, 2011.
[23] M. E. J. Newman. Clustering and preferential attachment in growing networks. PHYS.REV.E, 64:025102, 2001.
[24] V.-A. Nguyen, E.-P. Lim, H.-H. Tan, J. Jiang, and A. Sun. Do you trust to get trust? a study of trust reciprocity behaviors and reciprocal trust prediction. In SDM '10, 2010.
[25] J.-Y. Pan, H.-J. Yang, C. Faloutsos, and P. Duygulu. Automatic multimedia cross-modal correlation discovery. In KDD '04, pages 653­658, 2004.
[26] A. Rapoport. Spread of information through a population with socio-structural bias: I. assumption of transitivity. Bulletin of Mathematical Biology, 15:523­533, 1953.
[27] D. M. Romero and J. Kleinberg. The directed closure process in hybrid social-information networks, with an analysis of link formation on twitter. In ICWSM '10, 2010.
[28] G. Simmel and K. H. Wolff. The Sociology of Georg Simmel. Free Press, 1964.
[29] L. Yen, M. Saerens, A. Mantrach, and M. Shimbo. A family of dissimilarity measures between nodes generalizing both the shortest-path and the commute-time distances. In KDD '08, 2008.
[30] D. Yin, L. Hong, and B. D. Davison. Structural link analysis and prediction in microblogs. In CIKM '11, 2011.
[31] Z. Yin, M. Gupta, T. Weninger, and J. Han. A unified framework for link recommendation using random walks. In ASONAM '10, pages 152­159, 2010.
[32] J. Zhang, C. Wang, J. Wang, and P. S. Yu. LaFT-Tree: Perceiving the expansion trace of one's circle of friends in online social networks. In WSDM '13, 2013.

72

