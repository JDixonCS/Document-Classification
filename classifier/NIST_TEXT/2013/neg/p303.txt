Opportunity Models for E-commerce Recommendation: Right Product, Right Time

Jian Wang, Yi Zhang
School of Engineering University of California, Santa Cruz
Santa Cruz, CA 95060 USA
{jwang30, yiz}@soe.ucsc.edu

ABSTRACT
Most of existing e-commerce recommender systems aim to recommend the right product to a user, based on whether the user is likely to purchase or like a product. On the other hand, the effectiveness of recommendations also depends on the time of the recommendation. Let us take a user who just purchased a laptop as an example. She may purchase a replacement battery in 2 years (assuming that the laptop's original battery often fails to work around that time) and purchase a new laptop in another 2 years. In this case, it is not a good idea to recommend a new laptop or a replacement battery right after the user purchased the new laptop. It could hurt the user's satisfaction of the recommender system if she receives a potentially right product recommendation at the wrong time. We argue that a system should not only recommend the most relevant item, but also recommend at the right time.
This paper studies the new problem: how to recommend the right product at the right time? We adapt the proportional hazards modeling approach in survival analysis to the recommendation research field and propose a new opportunity model to explicitly incorporate time in an e-commerce recommender system. The new model estimates the joint probability of a user making a follow-up purchase of a particular product at a particular time. This joint purchase probability can be leveraged by recommender systems in various scenarios, including the zero-query pull-based recommendation scenario (e.g. recommendation on an e-commerce web site) and a proactive push-based promotion scenario (e.g. email or text message based marketing). We evaluate the opportunity modeling approach with multiple metrics. Experimental results on a data collected by a real-world e-commerce website(shop.com) show that it can predict a user's follow-up purchase behavior at a particular time with descent accuracy. In addition, the opportunity model significantly improves the conversion rate in pull-based systems and the user satisfaction/utility in push-based systems.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval
General Terms
Algorithms, Design, Experimentation
Keywords
Recommender System; Opportunity Model; E-commerce
1. INTRODUCTION
As online shopping becomes popular, e-commerce recommendation is an increasingly important business tool for promoting sales. Researchers and industry practitioners are looking for all possible approaches to improve the recommendation performance. Even a minor improvement could lead to a big business return.
Traditional recommender systems focus on finding the right item to recommend. Major approaches include contentbased methods, collaborative filtering methods and hybrid methods. For example, if a user viewed or purchased some camera(s) in the website, the system recommends more similar items (e.g. similar cameras) to the user. Recent research [19] proposed that recommender systems should recommend items that maximize the users' marginal utility, instead of only items that a user likes. As the marginal utility of a camera decreases immediately after a user purchased a camera, a system's follow-up recommendation should include camera accessories instead of similar cameras.
On the other hand, the user satisfaction/utility depends on both the relevance and the time of the recommendation. While an irrelevant recommendation results in a negative utility, the opportunity cost of recommending a relevant item at the wrong time could also be high, as we wasted the space while giving the user a negative impression. This is especially a problem for email or message based recommendations, as it wastes a user's time and effort to receive product recommendation emails/messages that are full of products she does not need to purchase at the time. In the long term, the user may have negative impression about the company, unsubscribe from the marketing email list, label the emails as spams, or uninstall the message application.
To address these issues, recommender systems need to answer the following question: when is the right time for the system to make recommendations of the right product(s)? For example, after a user purchased a camera, whether and

303

when should the system recommend related accessories including camera lenses, batteries, digital photo frames, etc.?
Multiple heuristic approaches [18, 24] have been proposed to tackle this problem. In this paper, we propose a theoretical model to learn the probability of a user making a followup purchase at a particular time. The model is inspired by the hazards model in survival analysis in statistics. The purchase time would be influenced by multiple factors, such as the user's characteristics, the user's purchase history, the product promotion information, the global environment and so on. Thus we propose to leverage the proportional hazards modeling approach which incorporates related factors as covariates(i.e., features). We further extend the model with the hierarchical Bayesian framework to handle the data sparsity issue. The new model is denoted as the Opportunity Model in this paper. It predicts the joint purchase probability, i.e., the probability of a user purchasing a product at a particular time. It helps to promote a right item at the right time which further enhances the user satisfaction. Experimental results are performed with a dataset from a realworld e-commerce website. Detailed analysis shows that the opportunity model could help to significantly improve the conversion rate and the user satisfaction.
The major contribution of this paper includes:
· We propose a new research problem in recommender systems: When is the right time to make recommendation of the right product in the e-commerce domain?
· To solve this problem, we propose a principled approach, (i.e. theopportunity model), to predict the joint probability of purchasing a product and the time of the event. We extend the proportional hazards model in statistics with the hierarchical Bayesian framework as part of the solution, and derive detailed inference steps based on the variational Bayesian algorithm.
· We leverage the joint probability in both the zeroquery pull-based recommendation scenario and the proactive push-based email/message promotion scenario 1. In particular, the probability enables a proactive recommendation agent to decide whether to send recommendations of certain items to a user at a particular time based on a solid utility optimization framework. Experimental results show that the opportunity modeling approach significantly improve the user satisfaction and the conversion rate of the system.
2. RELATED WORK
To provide recommendations to a user, recommendation systems usually predict a user's ratings for each item or probability of purchasing, then rank all items in the descending order. There are two major recommendation approaches: content-based filtering and collaborative filtering. Content-based filtering [12]assumes that descriptive features of an item indicate a user's preferences. Thus a recommender system estimates the score of each item based on descriptive features of other items the user likes or dislikes. Usually, the system recommends items that are similar to what the user liked before. On the other hand, collaborative filtering [7, 18, 13, 5] assumes that users with similar
1In the pull-based scenario, a user comes to the website and views some recommendation. In the push-based scenario, a system sends promotion emails or messages to the user.

tastes on some items may also have similar preferences on other items. Thus the main idea is to use the behavior history from other like-minded users to provide the current user with good recommendations. Research on collaborative filtering algorithms reached a peak due to the 1 million dollar Netflix movie recommendation competition. Factorizationbased collaborative filtering approaches [3, 9, 19, 17], such as the regularized Singular Value Decomposition, performed well on this competition. A common characteristic of these models is the introduction of user latent factors and/or item latent factors to solve the data sparsity issue. In the field of recommender systems, the effect of time [10, 18, 24] has received some research attention recently. One focus is about the drift of the user's preference over time [10, 23, 15]. Koren [10] revamped two popular collaborative filtering methods by modeling the time drifting factor of user preferences. Rendel et al. [15] proposed a factorized personalized model that subsumes both a common Markov chain and the normal matrix factorization model.
Recommendation in the e-commerce domain is a topic that has been studied in the IR community [8, 20]. Several methods have been tried in this domain, including neighborhoodbased method, graph models [6], MDP-based methods [16], multi attribute utility theory based methods [11] and so on. In general, most of these existing methods, directly or indirectly, only estimate whether a user would like an item or purchase an item. Some recent work studied modeling the time interval between purchase orders in the e-commerce domain [18, 24]. Wang et al. [18] discovered different postpurchase behavior in different time windows after purchasing. Zhao et al. [24] used the purchasing time interval to improve the temporal diversity of recommendations [15]. The time interval and the corresponding purchase probability is modeled inside the framework of a utility-based recommender system [19]. The hybrid system takes the time interval into consideration when ranking all candidate items. Compared to the prior work about time, our work explicitly models the joint probability of purchasing the product at the time based on a solid theoretical foundation. We explicitly model the conditional probability as a white box by leveraging Weibull distribution with various covariates to estimate the time-based probabilistic density. These covariates enable us to capture various time-dependent patterns such as local changes, cyclic behavior, seasonable pattern, general trend of follow-up purchase behaviors, which are not captured by the prior work. Besides, the joint probability of product and time enables us to improve the recommendation accuracy.
3. OPPORTUNITY MODEL IN E-COMMERCE
To recommend the right product at the right time, we exam each candidate product for each user at a particular decision time. We propose to build an opportunity model to estimate the probability of a user purchasing the product at a particular time interval (i.e. (y, y + t]). That is the joint probability P (p product, T  (y, y + t]), where T is the purchasing time. Let P (p product) represent the probability of the user purchasing the product, and P (T  (y, y + t]|p product) represent the conditional probability of the user purchasing the product at a particular time period conditioned on that the user will purchase the product.

304

Based on the chain rule, we have the joint probability:

P (p product, T  (y, y + t]) = P (T  (y, y + t]|p product)P (p product) (1)

We propose to adapt hazards models in survival analysis to estimate P (T  (y, y + t]|p product), and adapt existing recommendation algorithms to estimate P (p product).

3.1 Hazards Model in Survival Analysis

Survival analysis is a heavily studied topic in statistics,

which is named as duration modeling in economics or reli-

ability analysis in engineering. One major part of survival

analysis is to estimate the time of an event, such as when a

machine fails to work or when a patient fails to survive. In

the e-commerce domain, we can view the task of conditional

opportunity model as predicting the time of the follow-up

purchase event of the product. Follow-up purchases may in-

clude repurchases that happen regularly or new purchases

that are triggered by the previous purchase. Given the sim-

ilar nature of survival analysis and our e-task, we propose

to use the hazards model in survival analysis to estimate

p(y|p product) in this paper.

Let us review basic hazards models in survival analysis.

Let p(y) denote the density function of the time distribution

of an event. Let y be a value of time and T be a random

variable representing the event time. The cumulative distri-

bution function is denoted as P (y) = P r(T  y) and sur-

vival function is denoted as S(y) = P r(T > y) = 1 - P (y).

The hazards function is h(y) =

p(y) S(y)

.

It indicates the in-

stantaneous potential per unit time for the event to occur

at time y given that the event has not occurred up to time

y.

The survival analysis further extends the model with co-

variates. Covariates are features that would affect the sur-

vival time. For example, if a product is on promotion, it

might shorten the time before a user waits to purchase it.

The covariates could include different types of features, in-

cluding time independent variables (user age, gender, house-

hold income, product brand etc.), time dependent internal

variables (time since last purchase of the same product, re-

cent user search queries or clicks etc.) and time dependent

external variables (global economy, seasonal index, day of

the week, etc.). There are two common approaches to in-

corporate covariates x(a vector of features) in a hazards

model. The first approach is the Cox proportional hazards

model [14]. It assumes that covariates are multiplicatively

related to the hazards. The second approach is the Accel-

erated life model [22]. It assumes that covariates are multi-

plicatively related to the survival time. Research in statistics

discovered that the Weibull distribution satisfies assump-

tions in both directions. The density function of the basic

Weibull distribution is shown in Equation 2 [21].

p(y) =y-1exp{-y }

(2)

where  is sometimes called the shape parameter and held fixed. If  = 1, the Weibull model reduces to the exponential model and the hazard is constant. If  > 1, the hazard increases as time increases. If  < 1, the hazard decreases over time.  is the scale parameter and can be re-parameterized based on a regression parameter  and covariates x as follows:

p(y) =exp{T x}y-1exp{-exp{T x}y }

(3)


  





  








 

Figure 1: Illustration of the relationship of variables. The user first makes a series of product purchases before timestamp tm. Then the user makes a purchase of item jm in category m at timestamp tm. This follow-up purchase in category m is the ith observation in category m. Suppose that the purchase of jm is triggered by item js at timestamp ts. Purchase time ym,i = tm - ts is the time gap between tm and ts. An observation i is associated with two major variables: 1) purchase time ym,i and 2) covariates xm,i (which is not shown in the figure).
where exp{T x} represents the new scale parameter  . This density function represents the basic proportional hazards model that models the event time with associated covariates. The corresponding hazards function is simply h(y) =  y-1.
3.2 Notations
Here we describe notations in the e-commerce domain in this paper. The relationship between different variables is shown in Figure 1.
· u = 1, 2, ..., U : the index of users.
· m = 1, 2, ..., M : the index of item categories. In the ecommerce domain, it is the category of the product, such as Apparel & Accessories|Swimwear, Baby|Car Seats, Sports and Fitness|Football, etc.
· jm = 1m, 2m, ..., Jm: the index of items in category m. In this paper, an item is a product.
· tm: the purchase timestamp of item jm.
· t: the window size of the purchase time in consideration (such as 3 days or 1 hour)
· D: The observed data of all follow-up purchases from all users. Each category m has Nm follow-up purchase observation from all users. Each follow-up purchase observation i = 1, ..., Nm in category m is associated with the purchase time ym,i and covariates xm,i.
· ym,i: the purchase time of the ith observation in category m. ym,i = tm - ts is the time distance between

305

the user's purchase timestamp tm of item jm and the user's purchase timestamp ts of the triggering item js.

· xm,i: the k-dimensional vector of covariates associated with the ith observation in category m. Covariates could be associated with user u who makes the purchase, the user's purchase history j1, ..., jm-1, the purchase item jm, the global environment, etc.

· P (p product = yes): the probability of a user purchasing the product. The probability is calculated for each user-product pair.

· Opportunity model : density function/model to predict the joint purchase probability p(y, p product), i.e., the probability of a user purchasing of the product at the particular time.

· Conditional opportunity model : density function/model to predict the conditional time probability p(y|p product), i.e., the probability of a user purchasing the product at the particular time, given that the user will purchase the product.

3.3 Conditional Opportunity Model
In this paper we propose to adapt the Cox proportional hazards model to the e-commerce domain and use it to estimate P (T  (y, y + t]|p product). To do that, we learn the conditional opportunity model p(y|p product), which is the density function/model of the purchasing time. We can either learn one model per product or one model per product category. Without loss of generality, we describe the model by assuming one model per category in this paper.
In the real world, a small number of categories are often purchased while most categories have few purchases. To solve the data sparsity issue, we follow a common practice and extend the conditional opportunity model with a hierarchical Bayesian framework as illustrated in Figure 2. This framework helps the category with few observations by borrowing information from other categories through a common prior for parameters of all proportional hazards models.
For each category m, m is sampled from a Gaussian distribution: m  N (, ) and m is sampled from the Gamma distribution: m  Gamma(a , b ). We denote  = (, , a , b ). For each ith observation in category m with its observed covariates xm,i, its purchase time ym,i is sampled from the conditional opportunity model

p(ym,i|m, m)

(4)

= mexp{m T xm,i}ym m,i-1exp{-exp{m T xm,i}ym m,i}

Consider that data D consists of a series of observations from
all categories. Purchase times in the observations are generated by using a set of hidden variables  = {1, 2..., M } (m = {m, m}). The likelihood can be written as a function of  = (, , a , b ). We use ym to represent {ym,1, ..., ym,i, ..., ym,Nm }, i.e., observation times in category m.

M

M

p(D|) = p(ym|) =

p(m, ym|)dm (5)

m=1

m=1

data category
Figure 2: Illustration of dependencies of variables in the hierarchical conditional opportunity model. It shows the ith observation of category m. ym,i is the purchase time which is dependent on the conditional opportunity model m = {m, m} of category m, as wells the observed covariates xm,i of this purchase. Each category m has its own parameters of the conditional opportunity model m, m. Models of each category share information through the prior,  = (, , a , b ).

3.4 Parameter Inference with Variational Bayesian
There is no closed-form solution for the estimation of the model parameters. We follow the variational Bayesian method[1] for constrained (approximate) optimization to derive an iterative process to find the approximate solution. Maximizing the likelihood in Equation 5 is equivalent to maximizing the log likelihood L().

M

M

L() = ln p(D|) = ln p(ym|) = ln

m=1

m=1

p(m, ym|)dm

We can simplify the problem by introducing an auxiliary distribution q(m) for each hidden variable m [1]. In the variational approach, we constrain q(m) to be a particular tractable form for computational efficiency. In particular, we assume that q(m) = N (m , m ) and q(m) = Gamma(am , bm ). The process to infer parameters is to iterate between the following E-step and M-step until convergence.

3.4.1 E-Step
In the E-step, we infer the posterior distributions over hidden variables m given the current parameter setting . There is no closed-form solution. Instead, we find a tractable approximation of the posterior distribution of m given  (i.e, q(m) that maximizes L()).

306

We can combine the above derivations with Equation 8,

M
L() = ln
m=1

q(m

)

p(m, ym q(m)

|)

dm

then find q(m) using the conjugate gradient descent method.
3.4.2 M-Step

M

m=1

q(m)

ln

p(m, ym|) q(m)

dm

In the M-step, the goal is to maximize F (q(1), ..., q(M ), ) in Equation 6 with respect to  given all m. It is same as to maximize the following quantity:

M

M

=

q(m) ln p(ym|)dm -

m=1

m=1

F (q(1), ..., q(M ), )

q(m)

ln

q(m) p(m|ym,

)

dm

(6)

M
(t+1)  arg max  m=1

q(m) ln p(ym|)dm

(10)

To maximize L(), it is the same as minimize the following

The optimal  at this step can be estimated with the following closed form:

equation to find each distribution q(m):

q(m)(t) = arg min q(m )

q(m)

ln

q(m) p(m|ym,

) dm

(7)

Given

that

p(m|ym, )

=

, p(ym |m )p(m |) p(ym |)

we

have:

q(m) = arg min KL[q(m)||p(m|)] -
q(m )

q(m) ln p(ym|m)dm (8)

The first part in Equation 8 is the KL-divergence between

 =

M m

m

M

 =

M m

[m

+

(m

-

 )(m

-

 )T ]

M

a = -1(ln b +

M m

(am )

-

ln(bm )

)

M

b =

M a
M am m bm

the posterior distribution q(m) and the prior distribution

where -1() is the inverse digamma function.

p(m|).

KL[q(m)||p(m|)] = KL[q(m)||p(m|)] + KL[q(m)||p(m|)] 3.5 Joint Purchase Probability

The KL-divergence between two Gaussian distributions is

At a time y, we can decide whether to recommendation a particular product in category m to a particular user or not

K L[q (m )||p(m |)]

based on the following estimation: whether a user is likely to

=

1 2

[tr(- 1

m

)

+

(

- m )T - 1(

- m )

purchase the product in the near future (i.e. between time y and time y + t), given that the user has not purchased

- ln( det m ) - k] det 
The KL-divergence between two gamma distributions is

the product since a triggering time point. To do so, we need to estimate P (p product = yes, T  (y, y + t]) = P (p product = yes)P (y < T  y + t|T > y, p product = yes), where

K L[q (m )||p(m |)]

= (am - a )(am ) - log (am ) + log (a )

+

a (log

bm

-

log b )

+

am

b

- bm bm

P (y < T  y + t|T > y, p product = yes) = P (T  y + t) - P (T  y)
1 - P (T  y)

where () is the digamma function.

(11)

The second part in Equation 8 is to maximize the data likelihood of ym = {ym,1, ..., ym,i, ..., ym,Nm } with the cur-

where:

rent m = {m, m}.

P (T  y)

(12)

Nm

q(m) ln p(ym,i|m)dm

(9)

i=1

Nm
=
i=1

q(m)q(m)ln p(ym,i|m, m)dmdm

Nm
= [E(ln m) + E(m)T xm,i + (E(m) - 1) ln ym,i
i=1
- E(exp(m T xm,i))E(ym m,i)]

The expectations in the above equation are

E(ln m) =(am ) - ln(bm )

E(m) =m

E(m)

=

am bm

E(exp(m T xm,i))

=exp{Tm xm,i

+

1 2

xm,i

T

m

xm,i

}

E (ym m,i )

= (bm

bam m - ln ym,i)am

= 1 - Em,m [exp{-ym exp{m T xi}}]

 1 - exp{Em,m [-ym exp{m T xi}]}

= 1 - exp{Em [-ym ]Em [exp{m T xi}]}

=

1

-

exp{- (bm

bam m - ln y)am

exp{Tm xi

+

1 2

xTi

m

xi

}}

The approximation is used because there is no closed-form solution of the integration for calculating the expectation.
To estimate P (p product = yes), i.e., the probability of the user purchasing the product, we can use any existing recommender systems through the logistic regression model:

1 P (p product = yes) = 1 + e-fT x

where x is a vector of features that are associated with the purchasing, which includes the score/output of the existing recommender system(such as SVD), as well as other features that might help to predict the user's purchase probability. f is a vector of coefficients that can be learnt by maximizing the likelihood of the training data.

307

3.6 Implementation Details

The purchase time ym is determined by the purchase timestamp of product jm and that of the triggering product js. The triggering product is not necessarily the product in the most recent purchase. There are multiple heuristic approaches to find the triggering item js in the user's purchase history. Here we leverage the transition probability P (js, jm) in Equation 13.

P (ja, jb) =

# (ja, jb) +  # (ja, ) + J · 

(13)

where # (ja, jb) is the number of follow-up purchases of jb that happened after ja. # (ja, ) is the number of followup purchases after ja. J is the number of products and  is the smoothing factor, which is set as 0.1.
We first rank all items {j1, ..., js, ..., jm-1} that happened less than kt days before jm and have P (js, jm) > T hrestran. Then we use the top one as the triggering item. Other approaches can be explored in the future work. Although other purchases {j1, ..., js-1, js+1, ..., jm-1} in the user history are not treated as the triggering item, they are incorporated into the opportunity model as covariates xm,i.
In this paper, we use the following covariates for each purchase of product jm made by user u at timestamp tm: whether user u purchased any product in category m in time bin tb1, ..., tbk; how many times the user u purchased any product in category m in time bin tb1, ..., tbk; whether the user purchased the product jm in time bin tb1, ..., tbk; how many times the user u purchased the product jm in time bin tb1, ..., tbk; which season tm is in, whether tm is in the holiday season, etc. Time bins tb1, ..., tbk are set as one day, one week, one month, two months, three months, six months, one year, etc. We choose these covariates to show the effect of incorporating covariates in the conditional opportunity model. These covariates capture the change of the time distribution with the user's purchase history, the seasonal change, the cyclic pattern, etc. All covariates are normalized in the scale of [0, 1].

4. EVALUATION METHODOLOGY
As we are studying a new problem of recommending the right product at the right time, there is no standard evaluation methodology. We design various experiments to evaluate the performance of the opportunity model. Major research questions that we aim to answer are:
Predictability of the conditional opportunity model How accurate is the conditional time probability that is predicted by the conditional opportunity model? How accurate is the predicted purchase time, compared to the actual purchase time? Are covariates useful?

Predictability of the opportunity model Is the joint purchase probability a good signal of making recommendations? Does it generate a better ranking in traditional zero-query pull-based recommendation systems? Can it help to improve the user satisfaction/utility in proactive push-based recommendation systems?

4.1 Evaluation of Conditional Opportunity Model

4.1.1 Metrics

It is a relatively new research topic to predict the purchase time and evaluate the performance of such model. We introduce the following two metrics to evaluate the performance of the conditional opportunity model.
The first metric is the perplexity of the model. It is motivated by the perplexity metric used to evaluate language models and speech recognition [2]. The perplexity measures how well a model predicts the testing data. It is defined as follows:

M Nm

1

perplexity =

P (T  (y, y + t]|p product)

m=1 i=1

1

M m=1

Nm

(14)

= 2-

M m=1

Nm i=1

1 M m=1

Nm

log2P (T (y,y+t]|p

product)

where P (T  (y, y+t]|p product) is defined in Equation 11,

and i is the index for a testing data point. A better model

tend to give a higher data likelihood to the actual follow-

up purchase time in the testing data, thus they have lower

perplexity, which means they are less surprised by the test-

ing data.

The second metric focuses on the difference between the

estimated time ym,i and the actual time y^m,i. After a model predicts the distribution p(ym,i|p purchase) of the purchase

time, we use the median of the distribution as the esti-

mated purchase time y^m,i. The median of the distribu-

tion

is

exp(mxm,i)-

1 rm

(ln

2)

1 rm

.

The

error

across

all

test-

ing data can then be used to analyze and compare. The

smaller the error, the better the model. Here we use three

types of errors: mean absolute error(MAE), mean squared

error(MSE) and mean absolute percentage error(MAPE =

1

M m=1

Nm

M m=1

). Nm |y^m,i-ym,i|

i=1

ym,i

4.1.2 Conditional Opportunity Models to Compare

In our experiments, we compare the following four conditional opportunity models.

Uniform assigns a uniform distribution to all time. p(ym,i

|p

purchase) =

1 Tunif orm

where Tuniform

is the max-

imum time in consideration. We set Tuniform = 500,

i.e., 500 days, arbitrarily in this paper.

O-One is a conditional opportunity model that fits a single set of parameters with no covariates (i.e., a basic Weibull distribution) to the purchase data. All follow-up purchases in different category m use the same model.

O-Dest is a hierarchical conditional opportunity model that fits one Weibull distribution per product category, with no covariates.

O-DestCov further incorporates covariates into O-Dest. In this case, the probability density function changes for each user and product as values of the associated covariates change over time.

All models smooth the conditional probability estimation P (T  (y, y + t]|p product) = max(P (minThres, T  (y,

308

Table 1: The utility set of the recommender sys-

tem. There are four types of utilities, depending

on whether the system recommends the item to the

user and whether the user purchases the item.

show:Y show:N

accept:Y uT P accept:N uF P

uF N uT N

y + t]|p product)) to avoid having a probability that is too low (such as when there is no triggering item before the purchase). minThres is set as 0.001. t in Equation 11 is set as 7 (i.e., 7 days) for all models during the prediction step. The threshold for the transition probability to consider the an item js as the triggering item is set as 0.01.
4.2 Evaluation of Opportunity Model
4.2.1 Metrics
Here we evaluate the predictability of the opportunity model with the joint purchase probability in two scenarios.
1) [Zero-query pull-based scenario] assumes the user comes to the site to look for products to purchase without issuing any search query. In this scenario, the goal is to discover products that the user would purchase and recommend them to the user proactively. The system ranks all products by their joint purchase probability and recommends top K products to the user.
The evaluation metric in this scenario is the conversion rate which reflects whether a user receives at least one good recommendation. Each testing time corresponds to the time when a user comes to the site and makes purchases. Let Spurchased contain all unique products in the order. Let Cpurchased contain all unique categories in the order. Let SK,recommended contain top K unique product recommendations. Let CK,recommended top K unique category recommendations. CRproduct is the conversion rate at the product level and CRcategory is the conversion rate at the category level. Significance level of 0.05 with the paired two-tailed t-test is used to compare two models.

CRproduct@K =

1 0

Spurchased  SK,recommended =  otherwise

CRcategory @K =

1 0

Cpurchased  CK,recommended =  otherwise

2) [Push-based email promotion scenario] assumes that recommender systems send email/message proactively to a user regularly regardless of whether the user comes to the site or not.
The evaluation metric in this scenario is the average utility/user satisfaction. The utility for each type of recommendations is shown in Table 1. The utilityg for each email of recommendations is calculated by Equation 15.

utilityg = (uT P Ishow,accept + uF P Ishow,acc¯ept
+ uF N Ish¯ow,accept + uT N Ish¯ow,acc¯ept) (15)
I is the indicator function where I = 1 if  is true. Unlike traditional metrics such as conversion rate@K, the utility metric considers both the positive effect for good recommendations and the negative effect for bad recommendations. The higher the utility, the better the model.

To achieve a better utility, the system with a filtering

component should send emails only if the expected utility

of adding the product is higher than zero (i.e. the joint

probability is higher than the threshold). The recommenda-

tion threshold is automatically determined by the following

equation [4]:

. uF P -uT N
uF P -uT N +uF N -uT P

We don't have a real push-based email promotion system

for a user study. Instead, we create an evaluation dataset

with the purchase data from a pull-based e-commerce web-

site. The goal is to evaluate each model's predictability of

discovering the "real opportunity" and avoiding the "fake op-

portunity" in the email marketing. For each purchase at time

t in the testing dataset, we let each model consider two op-

portunities: sending a recommendation email the weekend

right before t and sending an email on some other random

weekend before t. Since existing models can not tell whether

to send an email or not, they always send an email with top

K recommendations for each opportunity. The opportunity

model with a filtering component will add a product to the

email if the expected utility of adding the product is higher

than zero. If no product is added to the email, the opportu-

nity model would skip this opportunity and do not send an

email. Recommendations in the email are compared with

actual products that the user purchases in the week after

the email is sent. Assume that there are G opportunities

to send recommendation emails in the testing period. The

average utility/user satisfaction utility can be calculated as

following: utility =

. G
g=1

utilityg

G

4.2.2 Recommendation Models to Compare

We choose the following recommendation models to compare:

TopPop recommends most popular products to the user.

SVD is a widely-used recommendation algorithm with a decent performance on the well-known Netflix competition. It is the basis of several recommendation algorithms based on latent factors.

SVD.util is the state-of-art recommendation algorithm in the e-commerce domain without time consideration. It modifies SVD with the marginal net utility framework [19].

Regression.Model is an alternative new approach to predict the probability of a user purchasing a product at a particular time using a logistic regression model, with various important time-dependent features. This model contains features such as the SVD score of the product, whether the product/category has been purchased t days ago, how many time the product/category has been purchased t days ago, etc.

Conditional.Opportunity.Model recommends products based on P (T  (y, y + t]), which is estimated by the hierarchical conditional opportunity model with covariates.

Opportunity.Model recommends products based on the joint probability of a user making a purchase of a product in the near future(P (p product, T  (y, y + t])).

Opportunity.Model.Filtering adds a filtering component to Opportunity.M odel. In the push-based email scenario, it adds a product to the promotion email only

309

if the expected utility of adding the product is higher than zero.
4.3 Dataset
The purchase history from 2004-01-01 to 2009-03-08 collected on a real-world e-commerce website, shop.com, is used for our experiments. We use all purchases that have category information of the product. Tail users that made less than 5 product purchases are filtered out in the training data, which follows the similar pre-processing in related work [19, 24]. In addition, 10 possible spam users that made more than 200 product purchases are filtered out as well. The remaining data contains 11,351 users and 67,291 products. There are 105,550 unique (user, product) pairs. This userproduct matrix is quite sparse, with only 0.014% density. There are 380 categories in total.
To evaluate the conditional opportunity model as in Section 4.1, 10-fold cross validation is used. To evaluate the opportunity model with the joint purchase probability as in Section 4.2, we sort all purchase history by time. The first 90% is used as the training data (data before 200811-24) and the last 10% is used as the testing data (data after 2008-11-24). There are 7,014 testing cases in total. At the product level, there are 1,143 repurchase cases(16.29%) and 6,269 new purchase cases(89.37%). At the categorical level, there are 2,850 repurchase cases(i.e. 40.63% cases with purchase from the same category) and 4,850 new purchase cases(i.e. 69.14% cases with purchase from a new category).
To train the regression model with SVD as one of the features, the first half training data is used to train the SVD model and the second half training data is used to learn coefficients in the regression model. The number of latent factors for all SVD-related models is set to 50. In the recommendation step, all models recommend top K (K=5) products to the user. To save the computation time, Regression.M odel, Conditional.Opportunity.M odel and Opportunity.M odel rank among top N recommendations from SVD and selects top K to recommend, where N = 100 and K = 5.
The time density plots of some common transitions from products in the Baby|Feeding category to the target item jm are shown in Figure 3. This supports our motivation of identifying triggering items in the user history. For example, users who purchased from Baby|Feeding would purchase items in other Baby related categories in the future. The purchase time of the follow-up purchase does follow different distributions for different products or different covariates (take the triggering product as a covariate). For example, users who purchased from the Baby|Feeding category would purchase products from this category again in one month. Later on when the baby grows up, they would purchase products from Toys|Board, Card&Dice Games.
5. EXPERIMENTAL RESULTS
5.1 Analysis of Conditional Opportunity Model
The perplexity of all conditional opportunity models in Section 4.1.2 are compared in Table 2. All conditional opportunity models have lower perplexity than the baseline model Uniform. This demonstrates that conditional opportunity models have better predictability of the time-based purchase probability in the data. Among all conditional op-

0.010

follow-up purchases
Baby|Feeding->Baby|Feeding Baby|Feeding->Baby|Bathing Baby|Feeding->Apparel_&_Accessories|Bras Baby|Feeding->Baby|Safety Baby|Feeding->Toys|Board,_Card_&_Dice_Games

0.008

0.006

prob of time

0.004

0.002

0.000

0

100

200

300

400

500

days

Figure 3: Density plot of the purchase time between different follow-up purchases from Baby|Feeding

Table 2: Perplexity of different conditional oppor-

tunity models in 10-fold cross validation.

Data

Uniform O-One O-Dest O-DestCov

All purchases repurchases new purchases

46.95 58.99 44.25

23.75 16.68 26.04

22.45 14.80 25.01

18.95 9.75 22.48

portunity models, O-DestCov achieves the lowest perplexity, followed by O-Dest, and O-One. O-DestCov incorporates related covariates in addition to fitting parameters of a conditional opportunity model for each category m. It shows the importance of considering covariates when modeling the purchase time of a follow-up purchase.
To further analyze the effect of covariates, we compare the perplexity of all models in the repurchase data and the new purchase data in Table 2. As expected, the major gain is in reducing the perplexity of repurchases. More feature exploration would be useful to improve the prediction of new purchases in the future.
Now we compare the estimated purchase time with the actual time of a follow-up purchase in Table 3. All conditional opportunity models perform better than the baseline model U nif orm. O-DestCov gives the most accurate estimation of the purchase time, followed by O-Dest, and O-One. According to MAE, the estimated purchase time from O-DestCov

Table 3: Error between the estimated purchase time

and the actual purchase time. MAE stands for mean

absolute error. MSE stands for mean squared error.

MAPE stands for mean absolute percentage error.

Data All Purchases

Error rate MAE MSE MAPE

Uniform 159.74 30859.346 16.592

O-One 105.279 23322.373
3.796

O-Dest 102.617 21920.462
3.763

O-DestCov 77.695
14335.505 2.434

Repurchases

MAE MSE MAPE

183.337 37728.853
27.895

63.7 9406.591
6.165

62.119 8799.832
5.631

34.536 4456.393
0.658

New Purchases

MAE MSE MAPE

154.244 114.956 112.042 87.736

29260.204 26560.746 24973.753 16634.239

13.964

3.246

3.329

2.847

310

Table 4: Conversion rate of recommendation models in the zero-query pull-based scenario. Numbers in bold are significantly better than the corresponding value in baseline models.

Product level

Model TopPop
SVD SVD.util Regression.Model Conditional.Opportunity.Model Opportunity.Model

All purchases CR@1 CR@5
0.0 0.0155 0.0134 0.0344 0.0287 0.0369 0.0339 0.0525 0.0160 0.0282 0.0289 0.0452

Repurchases CR@1 CR@5
0.0 0.0936 0.0822 0.2073 0.1750 0.2248 0.2082 0.3202 0.0962 0.1706 0.1750 0.2712

New purchases CR@1 CR@5
0.0 0.0003 0.0 0.0011 0.0002 0.0003 0.0 0.0003 0.0003 0.0006 0.0005 0.0011

Category level

Model TopPop
SVD SVD.util Regression.Model Conditional.Opportunity.Model Opportunity.Model

All purchases CR@1 CR@5 0.0204 0.0848 0.0577 0.1688 0.0751 0.1344 0.0999 0.1792 0.1102 0.2154 0.1313 0.2345

Repurchases CR@1 CR@5 0.0130 0.1382 0.1309 0.3267 0.1779 0.2453 0.2330 0.3646 0.2467 0.3856 0.3091 0.4495

New purchases CR@1 CR@5 0.0219 0.0435 0.0066 0.0540 0.0041 0.0511 0.0076 0.0472 0.0144 0.0907 0.0082 0.0816

is 77 days away(higher or lower) from the actual time. It is a decent performance given that the total time range is 500 days. Further analysis shows that O-DestCov predicts more accurately in both the repurchase and the new purchase data.
5.2 Analysis of Opportunity Model
5.2.1 Pull-based Scenario
Now we evaluate the performance of the opportunity model with the joint purchase probability. The conversion rate of different recommendation models in the zero-query pullbased scenario is compared in Table 4.
The opportunity model achieves higher conversion rate at both the product level and the category level. Further analysis shows that the contribution of the conditional opportunity model is mainly at the category level. It is not surprising because the model is designed at the category level. Product-level models can be explored in the future. The key challenge is to solve the sparsity and scalability issues.
We further analyze the performance of the conversion rate in different purchase scenarios. In Table 4, we show the conversion rate of repurchases and new purchases. It is clear that the major contribution of the opportunity model is in the repurchase scenario. The observation is consistent with the evaluation of the conditional opportunity model in Section 5.1: the conditional opportunity model predicts more accurately in repurchases.
5.2.2 Push-Based Scenario
Now we evaluate all models in the push-based scenario. In the Opportunity.M odel.F iltering model, a product is recommended only if its joint purchase probability is higher than the threshold. We evaluate the model with three sets of utility at both the product level (i.e. true positive means that the user purchased the exact product) and the category level (i.e. a true positive means that the user purchased a product in same category as the recommendation). The results are shown in Table 5. There are 3,014 email opportunities in the testing period. 55% of them have follow-up

Table 5: Average utility of email recommendations

in the push-based scenario. Coverage is the percent-

age of emails that are sent among all possible oppor-

tunities. Rec count is the average number of unique

recommendations in a email when the email is sent.
utility set 1 uT P = 3, uF N = 0 uF P = -1, uT N = 0 Threshold = 0.25
Product level

Model
Utility Coverage Rec count

TopPop
-4.994 1 5

SVD
-4.862 1 5

SVD.util Opportunity.Model

-4.768

-4.810

1

1

5

5

category level

Opportunity.Model Filtering -0.048 0.023 2.432

Model
Utility Coverage Rec count

TopPop
-4.823 1 5

SVD
-4.515 1 5

SVD.util Opportunity.Model

-4.570

-4.255

1

1

5

5

utility set 2

uT P = 10, uF N = 0 uF P = -1, uT N = 0 Threshold = 0.09

Opportunity.Model Filtering 0.006 0.023 1.081

Model
Utility Coverage Rec count

TopPop
-4.983 1 5

SVD
-4.621 1 5

Product level SVD.util Opportunity.Model

-4.363 1 5

-4.477 1 5

Opportunity.Model Filtering -0.399 0.180 3.007

Model
Utility Coverage Rec count

TopPop
-4.514 1 5

SVD
-3.667 1 5

Category level SVD.util Opportunity.Model

-3.819 1 5

-2.951 1 5

Opportunity.Model Filtering 0.282 0.180 1.880

Model

TopPop

SVD

utility set 3 uT P = 3, uF N = -1 uF P = -1, uT N = 0 Threshold = 0.20
Product level SVD.util Opportunity.Model

Opportunity.Model Filtering

Utility Coverage Rec count
Model

-4.992 1 5
TopPop

-4.828 1 5
SVD

-4.710

-4.762

1

1

5

5

Category level

SVD.util Opportunity.Model

-0.066 0.033 2.356
Opportunity.Model Filtering

Utility Coverage Rec count

-4.779 1 5

-4.394 1 5

-4.463 1 5

-4.069 1 5

0.015 0.033 1.115

purchases in the following week. Among those with followup purchases, the average number of purchases is 2.227.
In the first utility set, the utility uT P for a good recommendation that the user purchases is set to 3. When the system shows a product and the user does not purchase it, the utility uF P is -1. The resulting filtering threshold is 0.25. In this case, Opportunity.M odel.F iltering has a better utility than other models by filtering out many false alarms. The average utility at the category level is higher, which is expected. It rewards a recommendation if it matches the user's purchase at the category level, which is an easier task. In general, the model with higher conversion rate in the pullbased scenario has high utility in the push-based scenario.
In the second utility set, the utility uT P is set to 10, indicating that the user is more tolerant to bad recommendations. Thus the threshold is lower, being 0.09. The coverage of Opportunity.M odel.F iltering increases while the average utility drops. There is a tradeoff between the utility and the recommendation coverage, which can be tuned in a real-world application by a user or the system designer.
In the third utility set, uF N is set to -1. It is the penalty for not recommending a product that would be purchased

311

by the user in the following week. Thus the coverage of Opportunity.M odel.F iltering is higher to avoid missing good recommendations with the threshold being 0.02. It still achieves the highest utility among all models.
6. CONCLUSION AND FUTURE WORK
In this paper, we propose to develop the opportunity model to predict the probability of a user purchasing a product at a particular time. This is achieved by modeling the joint probability of time and product, which can be calculated by combining a proportional hazards model and a logistic regression model. The joint probability guides the system to make the right product recommendation at the right time.
This is just the first step to tackle the research problem of capturing the time-based recommendation opportunity. Besides Weibull distribution, other distributions such as Exponential, Log-logistic, Lognormal, Generalized gamma, can be explored. Further improvements could be achieved with better covariates. More systematic approaches of discovering the triggering item could be explored. It would be helpful to carry out experiments with a real push-based system to evaluate the effectiveness of the opportunity model in a real user study. Due to the limited number of research data available and our own computational limits, we only learn the category-level conditional opportunity model, which clearly work well at the category level prediction. Another followup work is to evaluate this approach on a large-scale system to learn the product-level models, which might lead to better prediction at the product level.
Acknowledgments
We would like to thank shop.com for sharing the data. This work was funded by National Science Foundation IIS-0713111 and IIS-0953908. Any opinions, findings, conclusions or recommendations expressed in this paper are the authors, and do not necessarily reflect those of the sponsors.
7. REFERENCES
[1] M. Beal. Variational algorithms for approximate Bayesian inference. PhD thesis, University of London, 2003.
[2] S. Chen, D. Beeferman, and R. Rosenfeld. Evaluation metrics for language models. In DARPA Broadcast News Transcription and Understanding Workshop (BNTUW), Lansdowne, Virginia, USA, Feb. 1998.
[3] P. Cremonesi, Y. Koren, and R. Turrin. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the 4th ACM Recommender systems, pages 39­46, 2010.
[4] C. Elkan. The foundations of cost-sensitive learning. In Proceedings of the 17th international joint conference on Artificial intelligence - Volume 2, IJCAI'01, pages 973­978, 2001.
[5] N. Golbandi, Y. Koren, and R. Lempel. Adaptive bootstrapping of recommender systems using decision trees. In Proceedings of the fourth ACM WSDM'11.
[6] Z. Huang, W. Chung, and H. Chen. A graph model for e-commerce recommender systems. J. Am. Soc. Inf. Sci. Technol., 55:259­274, February 2004.
[7] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative filtering with decoupled models for preferences and

ratings. In Proceedings of the twelfth CIKM, pages 309­316, New York, NY, USA, 2003. ACM.
[8] Y. S. Kim, B.-J. Yum, J. Song, and S. M. Kim. Development of a recommender system based on navigational and behavioral patterns of customers in e-commerce sites. Expert Syst. Appl., 28:381­393, February 2005.
[9] Y. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceeding of the 14th ACM SIGKDD KDD'08.
[10] Y. Koren. Collaborative filtering with temporal dynamics. In KDD, 2009.
[11] S. li Huang. Designing utility-based recommender systems for e-commerce: Evaluation of preference-elicitation methods. Electronic Commerce Research and Applications.
[12] R. J. Mooney and L. Roy. Content-based book recommending using learning for text categorization. In DL '00, pages 195­204, 2000.
[13] D. Parra-Santander and P. Brusilovsky. Improving collaborative filtering in social tagging systems for the recommendation of scientific articles. Web Intelligence and Intelligent Agent Technology, 1:136­142, 2010.
[14] C. D. R. Regression models and life tables. Journal of the Royal Statistic Society, B(34):187­202, 1972.
[15] S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th WWW.
[16] G. Shani, D. Heckerman, and R. I. Brafman. An mdp-based recommender system. J. Mach. Learn. Res., 6:1265­1295, 2005.
[17] E. Shmueli, A. Kagian, Y. Koren, and R. Lempel. Care to comment?: recommendations for commenting on news stories. In Proceedings of the 21st international conference on World Wide Web, WWW '12, pages 429­438, New York, NY, USA, 2012. ACM.
[18] J. Wang, B. Sarwar, and N. Sundaresan. Utilizing related products for post-purchase recommendation in e-commerce. In Proceedings of the 5th ACM Recommender systems.
[19] J. Wang and Y. Zhang. Utilizing marginal net utility for recommendation in e-commerce. In Proceedings of the 34th ACM SIGIR'11, pages 1003­1012, 2011.
[20] J. Wang, Y. Zhang, and T. Chen. Unified recommendation and search in e-commerce. In Information Retrieval Technology, pages 296­305. Springer Berlin Heidelberg, 2012.
[21] J. Wang, Y. Zhang, C. Posse, and A. Bhasin. Is it time for a career switch? Proceedings of the 22nd International World Wide Web Conference, 2013.
[22] L. J. Wei. The accelerated failure time model: A useful alternative to the cox regression model in survival analysis. Statistics in Medicine, 11(14-15):1871­1879, 1992.
[23] L. Xiang, Q. Yuan, S. Zhao, L. Chen, X. Zhang, Q. Yang, and J. Sun. Temporal recommendation on graphs via long- and short-term preference fusion. In Proceedings of the 16th ACM SIGKDD KDD'10.
[24] G. Zhao, M. L. Lee, W. Hsu, and W. Chen. Increasing temporal diversity with purchase intervals. In Proceedings of the 35th ACM SIGIR.

312

