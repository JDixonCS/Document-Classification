An Adaptive Teleportation Random Walk Model for Learning Social Tag Relevance
Xiaofei Zhu, Wolfgang Nejdl, Mihai Georgescu
L3S Research Center, Leibniz Universität Hannover, Hannover, Germany {zhu, nejdl, georgescu}@L3S.de

ABSTRACT
Social tags are known to be a valuable source of information for image retrieval and organization. However, contrary to the conventional document retrieval, rich tag frequency information in social sharing systems, such as Flickr, is not available, thus we cannot directly use the tag frequency (analogous to the term frequency in a document) to represent the relevance of tags. Many heuristic approaches have been proposed to address this problem, among which the well-known neighbor voting based approaches are the most effective methods. The basic assumption of these methods is that a tag is considered as relevant to the visual content of a target image if this tag is also used to annotate the visual neighbor images of the target image by lots of different users. The main limitation of these approaches is that they treat the voting power of each neighbor image either equally or simply based on its visual similarity. In this paper, we cast the social tag relevance learning problem as an adaptive teleportation random walk process on the voting graph. In particular, we model the relationships among images by constructing a voting graph, and then propose an adaptive teleportation random walk, in which a confidence factor is introduced to control the teleportation probability, on the voting graph. Through this process, direct and indirect relationships among images can be explored to cooperatively estimate the tag relevance. To quantify the performance of our approach, we compare it with state-of-the-art methods on two publicly available datasets (NUS-WIDE and MIR Flickr). The results indicate that our method achieves substantial performance gains on these datasets.
Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval
Keywords
Social Tag Relevance, Neighbor Voting, Random Walk
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609556 .

1. INTRODUCTION
With the advance of social media sharing platforms, such as Flickr, users are allowed to upload personalized photos and annotate these photos with freely chosen tags. These user contributed tags bring a new way to retrieve and organize the huge volume of photos available online, and recently have attracted increasing attention among the research and commercial communities. However, tags contributed by common users are known to be ambiguous, incomplete, and personalized [23, 13], which makes it an obstacle to utilize tag information for image retrieval and organization. Moreover, another obstacle is the lack of relevance information in the tag list of images. For example, on the Flickr website, the tag frequency information is not available, and the order of the tags of an image does not reflect any relevance level information (e.g., a tag in the top positions does not indicate its relevance is higher than the relevance of a tag in the bottom positions). Thus a fundamental problem is how to accurately and efficiently learn the relevance of a tag with respect to the visual content the tag is describing1. To be precise, a tag is considered as relevant to an image if the tag accurately describes objective aspects of the visual content [13].
Over the years, many approaches have been dedicated to cope with the tag relevance learning issue. In [14], Liu et al. proposed an approach to automatically learn relevance score of each tag for an image. This method first leveraged the Kernel Density Estimation to estimate the initial tag relevance and then a random walk was performed to refine tag relevance by further exploring the relationships between tags through a tag graph. The learnt relevance scores are used for ranking tags of the target image. The work in [25] proposed to learn tag relevance by taking into account three kinds of correlations: tag co-occurrence, tag visual correlation, and image conditioned tag correlation. Specifically, they adopted the Rankboost [5] to learn an optimal combination of these multi-modality correlations, and generated a ranking function for tag recommendation.
The most related work to ours are [13, 12, 22], which employ different neighbor voting strategies for learning tag relevance for tag-based image retrieval. Li et al.[13, 12] proposed to learn tag relevance by accumulating the neighbor votes received from these visually similar images of the target image. The learnt tag relevance scores are then embedded into the classical OKAPI-BM25 model for tag-based image re-
1For simplicity, hereafter we use `the tag relevance' to denote `the relevance of tag with respect to the images that the tag is describing'.

223

animal buildings dog flowers horses sky sports sunset tower window
animal 0.66
buildings 0.64

dog

0.62

flowers

0.6

horses

0.58

0.56 sky

0.54 sports
0.52 sunset
0.5
tower 0.48

window

0.46

Figure 1: The relationship between intra-class similarity (diagonal blocks) and inter-class similarity (non-diagonal blocks). Warmer colors indicate higher visual similarities and colder colors indicate lower visual similarities.

trieval. The main limitation of this method is that it treats the voting power of each visual neighbor equally. Due to the existence of noisy or less relevant tags in images, this will inevitably hurt the learning performance. In order to tackle this problem, a variant method [22] is proposed by Truong et al. In [22], they claim that different visual neighbors should have different voting weights, and they exploit four content and contextual features (i.e., image similarity, tag matching, tag influence, and refined tag relevance) for estimating the voting weights. Experimental results show that significant improvements are achieved only based on the content feature, while other three features have not shown to have beneficial effects on the performance.
Although these neighbor voting methods (e.g., weighted and unweighted) are simple and have achieved encouraging results, directly using visual similarity as the voting weights will inevitably be affected by the semantic gap(the gap between the low-level features and high-level image semantic concept [20]). Specifically, visual similarity can not effectively reflect the semantic relationship between images. To illustrate this problem, we randomly sample 10,000 images from 10 different classes (e.g., animal, buildings, dog, flowers, horses, sky, sports, sunset, tower, window) with 1,000 images per each class, and compute their intra-class similarities (i.e., average image similarity within the same class) and inter-class similarities (i.e., average image similarity between different classes). Figure 1 illustrates the relationship between intra-class similarity (diagonal blocks) and interclass similarity (non-diagonal blocks). From Figure 1 we can see that many intra-class similarities are smaller than some of the corresponding inter-class similarities, e.g., the intra-class similarity of the concept `flower' is much smaller than its corresponding inter-class similarity with the concept 'horse'.
In this paper, we propose a unified voting framework which can seamlessly integrate the relationship information among images into the general neighbor voting schemes through a novel random walk process. To this end, we first exploit the relationship information among images by constructing a novel graph, called voting graph. In the voting graph, we

consider these tagged visual neighbors2 as the nodes. Moreover, there is a direct edge from node i to node j if and only if node i appears in the k visual nearest neighbors of node j. The k visual nearest neighbor set of node j is calculated for the entire image set, which means it can contain both tagged and untagged images. This can be interpreted in that image i will compete with all other images in the image set, including both tagged and untagged images, and there is a direct edge from node i to j only when i can win a position in the k visual nearest neighbor set of node j (More details about the construction of voting graph are given in Secion 3). Furthermore, we propose a novel random walk model, called adaptive telepotartion random walk model, to learn relevance scores based on the voting graph. In existing random walk models, such as time-homogenous random walk (e.g., PageRank [18], Personalized PageRank [8]) or time-variant random walk (e.g., DivRank[16]), each node has the same fixed teleportation probability(e.g., 1 - ) to randomly transit its scores to an arbitrary node. However, our new model considers involving a new factor, called confidence factor (see Section 4.1), where a node with a larger confidence factor will assign a relative high proportion of its score to vote the corresponding neighbors, otherwise it will assign a high proportion of its score to do teleportation in order to reduce the risk of incorrect voting.
We conduct extensive experiments on two publicly available image datasets: NUS-WIDE [3] and MIR Flickr [7], which consists of 269,648 and 25,000 images, respectively. Experimental evaluations demonstrate that by further exploiting the relationships among all visual neighbors through the voting graph, the proposed method can significantly improve the effectiveness of tag-based image retrieval.
Overall, the main contributions of this work includes:
· exploiting the relationship information among all visual neighbors for learning the tag relevance; for this purpose a novel graph (i.e., voting graph) is proposed.
· introducing a new confidence factor into the standard random walk model to adjust the teleportation probability for simulating user' typical voting behaviors, and then proposing a novel random walk model, i.e., adaptive teleportation random walk, to learn the tag relevance through propagating the voting scores on the voting graph.
· giving a theoretical analysis of the convergence property of the novel model. We prove the model has a convergence property, and also give an intuitive interpretation.
The rest of the paper is organized as follows. In Section 2, we give a brief review of related works. Section 3 describes the construction of the voting graph. Our adaptive teleportation random walk algorithm is introduced in Section 4. Section 5 shows the experimental results of our empirical studies, and finally conclusions are made in Section 6.
2. RELATED WORK
2For convenience, we call all the visual neighbors which have been annotated by the given tag as tagged visual neighbors, and the remaining visual neighbors as untagged visual neighbors.

224

In this section, we briefly review two research topics which are closely related to our work: social image tag relevance learning and random walk.
Social Image Tag Relevance Learning. Over the years, due to the increasing amount of tag information available online, social image tag relevance learning has received a considerable attention in the research community.
Li et al. [13, 12] proposed to learn tag relevance by employing a neighbor voting strategy (i.e., accumulating votes from visual similar neighbor images). The assumption of this method is that a tag is considered as relevant to its annotated image if it is also adopted by different persons to annotate other visually similar images. In this approach, for a given image d (called target image), its k-nearest neighbors, denoted by Nk(d), are first obtained based on some visual similarity measurements (e.g., Euclidean similarity). Then for each tag t in image d's tag list, denoted by Td, the relevance of t is measured by the number of neighbor images in Nk(d) which are also annotated by the tag t. The experimental results demonstrate that the neighbor voting algorithm is a good measure for both image ranking and tag ranking. In [21], Sun et al. also compared three tag relevance formulations, namely, unit relatedness, tag position, and neighbor voting. Their experimental results demonstrate that neighbor voting achieves the best performance for singe-tag queries in the image search task, while obtaining comparable performance to other two formulations for multi-tag queries.
In [22], a variant of the neighbor voting algorithm is proposed. In this work, Truong et al. suggested to exploit a content-based feature (image visual similarity) and three context-based features (tag matching, refined tag relevance, and tag influence) of social images, and incorporate these features in the neighbor voting framework. Based on these features, different neighbor voting schemes are investigated and the results show that only the content-based feature can significantly improve the accuracy in tag relevance learning for tag-based image retrieval. To be precise, the contentbased feature was used to measure the voting weights of the visual neighbors. We call this method weighted neighbor voting. The main limitation of this method is that using the visual similarity as the neighbor voting weights may suffer from the semantic gap problem (i.e., gap between low-level images features and high-level semantic concepts).
In existing neighbor voting schemes, the voting power from neighbor images are either treated equally [13, 12] or simply weighted based on their visual similarity [22], thus they have not effectively exploited the relationship among these visual neighbors. Our model differs from these neighbor voting methods in that we formulate the learning tag relevance problem as an adaptive teleportation random walk process on the voting graph. The basic idea of our approach is that we attempt to boost the structure information of these visual neighbors for better estimating tag relevance.
Random Walk. Random walk has been successfully adopted in a broad range of applications, such as web search [18, 6], community detection[9, 19], recommender system[11, 17], and so on. A random walk on a given (either directed or undirected) graph G is a Markov process, where each node represents a state and a walk transiting from the state i to the state j is based on a transition probability matrix P .
Since the graph G may not be strongly connected, the convergence of the Markov process is not guaranteed. In

[18], L. Page et al. proposed the well-known PageRank algorithm. In PageRank, at each step, the surfer either jumps to an arbitrary node or follows one of the out-going edges of the current node. Formally, the random walk process of PageRank can be defined as

rt = P T rt-1 + (1 - )v,

(1)

where P is a transition matrix, rt is the importance score vector of all pages at step t, and  is a damping factor (also called teleportation probability) which controls how often the surfer jumps to an arbitrary node, v is a uniform distribution , with elements 1/N , where N is the number of nodes in the graph. We can also substitute the uniform distribution v in Eq. 1 with other distributions by incorporating the prior preference of visiting certain kinds of nodes. In this case, the random walk process then yields the famous Personalized PageRank[6, 8].
Recently, there are some works oriented towards using a random walk for estimating tag relevance. For example, in [14], Liu et al. proposed to construct a tag graph in order to take into account the relationship among tags. In the tag graph, the nodes are the tags of the image and the edges are weighted by pairwise tag similarity. Then a random walk is performed over the tag graph for learning the tag relevance. Some other works [4, 10] are proposed to model the relationship among images through constructing an image graph, and then performing random walk based methods on the graph. For example, Craswell et al. [4] constructed a click graph, where the nodes are queries or images, and edges indicate clicks. Jing et al. [10] also constructed a similarity graph, where nodes are the images (e.g., the top 1,000 search result images from search engines), and edges are weighted based on their pairwise visual similarity. The limitation of these methods is that they either depend on some external resources (e.g., [14]), or the generated graph is very dense and may contain noisy information (e.g., [4, 10]), thus needing more computational effort and possibly being inaccurate.
In our work, we do not depend on any external resource. Besides, our voting graph is a sparse graph which only considers tagged images of the query tag as the nodes, and can be computational effective. At last, contrasting to the existing random walk and its variants [6, 8, 16], which use a same fixed teleportation probability across all nodes in the graph, we introduce an adaptive teleportation random walk process. We will illustrate in Section 4 the rationality of our proposed models in dealing with the task of learning tag relevance.

3. VOTING GRAPH
In this section, we formally define the notations and introduce the concept of voting graph.
Given a tag t, let X = {x1, x2, · · · , xn} be the set of feature vectors for all images annotated by the tag t, where xi  Rd represents the feature vector of the i-th image in X and n is the number of images annotated by t. Let Nk(i) denote the k nearest neighbor set of image i based on metrics such as the Euclidean distance or cosine distance. It is worth noting that for computing Nk(i) we consider not only images annotated by t, but also account for images which are not annotated by t. That is, we take into consideration the entire image set for finding the k nearest neighbor set Nk(i) for an image i.

225

Definition 1. (Voting Graph). A voting graph G = (V, E) is a directed graph where nodes are images in X, i.e., images annotated by a given tag t. There is an edge e = (i, j)  E if and only if image i appears in Nk(j).

Both our voting graph and the typical k-NN graph [24] compute the k nearest neighbor set Nk(i) from all images without considering whether these images are annotated by the given tag t or not. However, these two graphs use different set of images as the nodes, e.g., in existing k-NN graph models, nodes are all the available images, while our voting graph uses only images annotated by the given tag t as nodes3.
The construction of the voting graph can be summarized as follows:

1. For the given tag t, we gather all the images annotated by the tag t, and use them as the nodes of the graph.

2. For each image j in X, we get its k nearest neighbors Nk(j) throughout the whole image dataset. If any image i in X appears in Nk(j), then there is a directed edge going from vertex i to vertex j.

3. Set the edge weight wij based on the visual similarity between i and j. In our work, we compute the visual similarity between two images using a Gaussian kernel function with a radius parameter :

wij = exp(-

xi - xj 2

2
2 ),

(2)

where · 2 denotes the 2-norm.

Figure 2 illustrates how a voting graph is constructed. For a given tag, `car' in this example, there are 6 images associated with it in the dataset. In each row, the image on the left side of the vertical dashed line is the tagged image, and the images on the right side are its k (k = 5 in this case) nearest neighbors. Notice that the images on the right side may contain both tagged images (marked with red frame) and untagged images. A solid arrow represents a directed edge from a neighbor image on the right side to the tagged image on the left side . Figure 2(b) corresponds to the resulting voting graph where each node represents a tagged image (i.e., the image annotated by the given tag `car'), and each directed edge from node i to node j represents that image i appears in the k nearest visual neighbor of image j.
After we construct the voting graph, the next step is to measure the tag relevance. There are many methods that can be adopted to compute the relevance based on the constructed voting graph. For example, we can directly consider using the in-degree, denoted as d-i , of each node i in the voting graph as the tag relevance measurement, which is equivalent to adopting the standard neighbor voting approach as mentioned in [12, 13]. Moreover, if we further take into account the weight of the edges when we aggregate the in-degree as the tag relevance measurement, then we get a variant of the standard neighbor voting model. This model is equivalent to the weighted neighbor voting algorithm proposed in [22] which was proved to have best performance in the empirically evaluation 20 different neighbor voting schemes. The limitations of these methods have been discussed in Section 2. In the next section, we will introduce
3Here our purpose is to learn these user contributed tags with respect to the visual content of their annotated images.

our approach, which performs an adaptive random walk on the voting graph in order to learn the tag relevance.

4. OUR METHOD
In this section we first introduce the concept of confidence factor, and then seamlessly encode it into the standard random walk process in a unified way. Finally, we theoretically analyse the mathematical property of our model, and prove that the novel model still holds a convergence property.

4.1 Confidence Factor
In the scenario of learning tag relevance, the link from one image to another image is strictly constrained by their visual similarity, in contrast to the Web link graph scenario where links can be freely added by the content owners. Furthermore, while in the web page search scenario the nodes of the graph probably come from different concepts, in our case, since all the images in the voting graph are the images annotated by general users for describing a specified concept, they can be seen as the exemplars of the concept. If an image has many out-link neighbors in the graph (i.e., it frequently appears in the neighbor image set of other exemplar images), then it indicates that the image is similar to the exemplar images of the concept, and should be more related to the concept represented by the exemplars.
In this work, we make use of the above property and introduce a novel factor, called confidence factor, into the standard random walk process. The confidence factor reflects what proportion of the score of a node is used for voting its out-link neighbors. To be precise, nodes with a large number of out-link neighbors will comparably devote larger scores for voting on their out-link neighbors than those nodes with less out-link neighbors. In summary, the confidence factor of node i is formulated as follows,

ci

=

(d+i ) maxj (d+j )

,

(3)

where d+i is the number of out-link neighbors of node i.  is introduced to control the degree of the impact of the number of out-link neighbors. When  = 1, ci is proportional to the number of out-link neighbors of i. When  = 0, our model will regress to PageRank, where all nodes have the uniform confidence, i.e., ci = 1. If 0 <  < 1, then nodes with a small number of out-link neighbors will be boosted to have relatively higher confidence values. If  > 1, then nodes with a large number of out-link neighbors will be boosted to have relatively higher confidence values.
In our experiments,  is empirically set to 1.0. In Section 5.6, we will give a detailed discussion on the impact of parameter .

4.2 Adapative Teleportation Random Walk Model
Whereas in previous random walk methods, walkers can either follow out-links with probability  or teleport to a random node with probability 1-, in our model, each node will have an adaptive teleportation probability. Specifically, the teleportation probability is determined not only by the probability 1 -  (1 -  is the typical setting in previous random walk algorithms), but also by the confidence factor ci(i = 1, 2, · · · , n). Formally, the teleportation probability of a node i is equal to (1 - ) + (1 - ci) × , where the first

226

Tagged Images

k Nearest Neighbors (k=5)



 







 










(a)

 







(b)

Figure 2: An illustration of a voting graph construction. (a) The k (k = 5 in this case) nearest neighbors of each tagged image. Images on the left side of the vertical dashed line are tagged images (i.e., images annotated with the given tag `car'), and images on the right side of the vertical dashed line corresponds to their k nearest neighbors based on their visual similarity (tagged images on the right side are marked with red frame). (b) The resulting voting graph. Each node indicates a tagged image; the presence of a directed edge from node i to node j shows that image i appears in Nk(j).

item can be considered as the prior teleportation probability which is identical for all nodes, and the second term can be considered as the observed teleportation probability which relies on the confidence factor ci of the node i. Thus the combined teleportation probability can be seen as a posterior probability.
Intuitively, the adaptive teleportation process can be explained as follows: when the current node has a high confidence factor, then walkers will follow the out-links with a higher probability and contribute most of the voting impact to its out-link neighbors. Otherwise, walkers will more likely teleport to a random node, and devote less voting impact to out-link neighbors in order to reduce the risk of incorrect voting. Let us denote by P an n-by-n transition matrix, where an element pij indicates the probability of transition from node i to node j and it is computed as

pij =

wij

,

kNk(i) wik

(4)

where wij denotes the visual similarity between node i and j (see Eq. 2). For a given voting graph G =< V, E > with n nodes, let rt be a vector whose i-th element rt(i) indicates the relevance score of node i at step t. The novel adaptive telepotation random walk process is then formulated as follow:

rt(j) = ciPij rt-1(i) + vj (1 - ci)rt-1(i)

i

i

+ (1 - )vj,

(5)

where vj is the initial probabilistic relevance score of tag tj, and ci is the confidence factor defined in Eq. 3.

4.3 Mathematical Property
It is worth noting that the new random walk process still converges to a stationary distribution. Let  denote the di-

agonal matrix with diagonal elements equal to (c1, c2, · · · , cn). Let e = (1, 1, · · · , 1)T denote the vector of all ones, where the superscript T denotes the transpose. Let I denote the n × n identity matrix, and let v = (v1, v2, · · · , vn)T . Hereafter, we will prove the convergence property of the iteration of Eq. 5.
Lemma 1. For all P, , , and v, (I - (PT  + veT (I - ))) is invertible.
Proof. Let Q = PT +veT (I-), then we should prove that (I - Q) is invertible. It is equivalent to prove that its transpose (I - QT ) is invertible. For this purpose, we need prove that (I - QT )x = 0 only has a trivial solution x = 0.
(I - QT )x = 0 x = QT x
xi =  Qjixj
j
=  (ciPij + (1 - ci)vj )xj
j
Note that 0  ciPij +(1-ci)vj  1i, j (since min{Pij, vj}  ciPij + (1 - ci)vj  max{Pij , vj }), and j (ciPij + (1 - ci)vj ) = ci j Pij +(1-ci) j vj = 1j. Let m = arg max{xi}, xm =  j (cmPmj + (1 - cm)vj )xj   j (cmPmj + (1 - cm)vj)xm = xm. Thus, (1 - )xm  0 and xm  0. Similarly, let M = arg max{xi}, we also have (1 - )xM  0 and xm  0. Thus xi = 0i.
Theorem 2. The iteration of Eq.5 converges to
r = (1 - )(I - (PT  + veT (I - )))-1v (6)

227

Proof. Eq.5 can be rewritten in the matrix form

rt = PT rt-1 + eT (I - )rt-1v + (1 - )v (7)

= PT rt-1 + veT (I - )rt-1 + (1 - )v (8)

= (PT  + veT (I - ))rt-1 + (1 - )v

(9)

Let Q = PT  + veT (I - ), then we have

rt = Qrt-1 + (1 - )v,

(10)

and thus we have

n
r = lim (Q)nr0 + (1 - )( (Q)i-1)v
n i=1

(11)

Note that transition matrix P has been row normalized to
1, and v is the probabilistic relevance score (i.e., i vi = 1). For 0 <  < 1, there exists  < 1, such that  < , and we
can derive that

(Q)nij =
i
=
=
=

(Q)ik (Q)nkj-1
ik

(Q)nkj-1 (Q)ik

k

i

(Q)nkj-1 (ckPki + (1 - ck)vi)

k

i

(Q)nkj-1(ck Pki + (1 - ck)

k

i

i

(12) (13) (14) vi) (15)

= (Q)nkj-1()
k
 (Q)nkj-1()
k
 n

(16) (17) (18)

Thus the column sums of (Q)n converges to zero. Then according to Eq. 11 and Lemma 1 we have

r = (1 - )(I - Q)-1v

(19)

= (1 - )(I - (PT  + veT (I - )))-1v

(20)

which is the unique stationary distribution. Although the closed-form solution is derived, in practice,
the iterative process (See Eq. 5) is more preferable.

4.4 Tag-based Image Retrieval
For a given query tag, we first construct a voting graph for all images annotated by the tag. Then we perform the adaptive teleportation random walk algorithm over the voting graph in order to learn the relevance score of each tagged image (i.e., the relevance of the query tag with respect to the visual content of that tagged image.). Finally, all images are ranked according to their relevance scores.
We propose two versions of our method according to whether the visual similarity is used as an edge weight in the voting graph or not. The first method is running the adaptive teleportation random walk over the unweighted voting graph, where all edges in the voting graph have the same weight wij = 1, and the second method is performing over the weighted voting graph, where edges in the voting graph are weighted based on their visual similarity as defined in

Eq. 2. For simplicity, let us call the method over the unweighted voting graph Graph Voting (GV), and the one over the weighted voting graph Weighted Graph Voting (GV-W).
4.5 Discussion
It is natural to perform a standard random walk, such as PageRank, on the voting graph, and use the estimated node importance scores as the tag relevance. Although random walk models have achieved great success, directly adopting random walk for social tag relevance learning on the voting graph is problematic. In Figure 3, we illustrate the problem of performing a random walk on our voting graph for tag relevance learning and compare its performance with our proposed method. Intuitively, a good tag relevance learning method should satisfy the following two voting assumptions.
Assumption 1: The voting impact from a highly relevant voting node4 should be higher than the voting impact from a less relevant voting node.
Assumption 2: The voting impact from many voting nodes should usually be higher than the voting impact from fewer voting nodes.
As we can see from Figure 3(a), the importance scores learned by a standard random walk do not fulfill the assumption 1 for learning tag relevance. For example, it is reasonable that node 5 should have a higher score than node 9, since node 5 has a more relevant voting node (node 3) than the voting node (node 4) of node 9. While the results of standard random walk method show that node 9 receives a much higher score (0.160) than the node 5 (0.107). Figure 3(b) shows the results of our proposed method. Compared with the results of standard random walk in Figure 3(a), our method has a more reasonable results. For example, in our method node 5 receives a relatively higher score (0.117) as compared with the score (0.113) of node 9.
In Figure 3(a), we also observe that the assumption 2 has not been satisfied by performing a standard random walk. For example, the score (0.160) of node 9 is nearly close to that (0.164) of node 3, and much higher than the score (0.103) of voting node 4. While in our model, the score (0.113) of node 9 become close to the score (0.109) of its voting node 4, and much more small than the score (0.128) of node 3 which has two voting nodes (node 1 and node 2).
These observations can be attributed to the fact that in the standard random walk (e.g., PageRank), as defined in Eq. 1, all nodes share the same fixed teleportation probability, determined by the parameter . In other words, the walker will jump to the neighbor nodes with probability , and jump to an arbitrary node with probability 1 - . By considering the jump probability as a type of voting impact from one node to its out-link neighbors, nodes with large out-degree will consequently have a slight voting impact to each of its neighbors. For example, in the voting graph in Figure 3 (a), node 3 has 4 out-link neighobrs, thus the contributed voting power to each of its neighbor is only 1/4 of the total impact of node 3. In contrast, node 4 can contribute all of its impact to the sole out-link neighbor, since it merely has one out-link neighbor (node 9) .
In the typical Web link graph scenario, a standard random walk is reasonable, since authors of the Web pages can freely add links to other web pages. Therefore, for nodes with many out-links, the impact to their out-link neighbors
4We call all the nodes with a directed edge towards node i as the voting nodes of node i.

228

0.072
1

0.072
2

0.164
3

0.107
5
0.107
6
0.107
7
0.107
8

0.090
1
0.090
2

0.128
3

0.117
5
0.117
6
0.117
7
0.117
8

0.103
4
(a)

0.160
9

0.109
4
(b)

0.113
9

Figure 3: An explanatory comparison between the standard random walk model and our proposed model. (a) results of standard random walk model. (b) results of our adaptive teleportation random walk model.

should be penalized (i.e., discounted by the number of outlink neighbors as in the standard random walk). However this property does not satisfy the requirements in the scenario of learning tag relevance through the voting graph.
5. EXPERIMENTS
In this section we present a set of extensive experiments to evaluate the performance of our proposed method on two publicly available datasets, including NUS-WIDE [3] and MIR Flickr [7]. The experimental results demonstrate that our method outperforms state-of-the-art methods for tagbased image retrieval.
5.1 Datasets
The NUS-WIDE dataset [3] collected from Flickr5 contains 269,648 web images with their associated tags. In NUS-WIDE, both global features (such as color histogram, edge direction histogram, and wavelet texture) and local features (such as bag-of-visual words features) are available. In this work, we measure the visual similarity between two images based on 265-D global features, including 64-D color histogram, 73-D edge direction histogram, and 128-D wavelet texture. Furthermore, since the owner information of images has not been released in NUS-WIDE, we crawled this information for 239,891 images6. In NUS-WIDE, 81 concepts with manual ground-truth labels are provided and will be used for evaluating the performance of our method.
The MIR Flickr collection [7] consists of 250,00 images, and the original tag data contributed by users. For each image in this dataset, we use Lire [15] to extract 305-D global features, including the 192-D Fuzzy Color and Texture Histogram [2], 33-D MPEG-7 Color layout [1], and 80-D MPEG-7 Edge Histogram [1]. All features are normalized to a zero mean and unit variance. For the evaluation, 17 potential concepts [7], which have more than 100 tagged images,
5http://www.flickr.com/ 6Due to link failure, the owner ID of some images are unavailable. Here we also release our crawled owner ID on http://www.l3s.de/zhu/NUS-WIDE OwnerInfo.txt for easily reproducing the experiments.

Table 1: Statistics of the two publicly available datasets: NUS-WIDE and MIR Flickr. (The number of unique owners and the average number of images per owner in NUS-WIDE are calculated based on our crawled owner information.)

Statistics # of images # of unique tags # of unique owners avg # of tags per image avg # of owner's tagged images

NUS-WIDE 269,648 425,059 47,721 19.31 5.03

MIR Flickr 25,000 80,997 9,862 8.94 2.53

are selected as the ground-truth concepts. Table 1 shows basic statistics for both datasets.

5.2 Evaluation Metrics

To evaluate the performance of each approach, we use

both Precision@K and MAP as the performance evaluation

measures.

Precision@K (P @K). P @K is a localized evaluation

criterion, which measures the ranking quality of the top re-

sults. For a given query, it is calculated as the fraction

of relevant images of the top-K retrieved results, formally,

P @K =

K i=1

rel(i) K

,

where

rel(i)

is

a

binary

function

on

the

relevance of the i-th instance, rel(i) = 1 if the i-th instance

is relevant and 0 otherwise. Similar to [22], we choose to re-

port P @100 only. For each method, the reported P @100 is

the macro-average of P @100 values of all evaluated queries.

Mean Average Precision (MAP). Average Precision

(AP) measures the ranking quality of the entire list. For a

given query, the AP value is calculated as

AP = 1 N Ri rel(i),

(21)

Ri

i=1

where R is the number of relevant instances, N is the number of retrieval instances, Ri is the number of relevant images in the top i ranking list. To evaluate the overall performance, we get the Mean Average Precision (MAP) by averaging the AP values over all the queries.

5.3 Baseline Methods
To evaluate the performance of our methods for tag-based image ranking, we compare them against (a) Neighbor Voting (NV) [12, 13], (b) Weighted Neighbor Voting (NV-W) [22], (c) Random Walk(RW), and (d) Weighted Random Walk (RW-W). NV uses the frequency of a tag in the visual neighbors of the target image as the tag's relevance to that image. NV-W further take into account the visual similarities between the visual neighbors and the target image as the voting weights in a neighbor voting framework. In order to gain in-depth insights into the effects of importing the adaptive teleportation in the random work process, we also compare our methods with two random walk based methods: RW and RW-W. RW is a method which performs a standard random walk over the unweighted voting graph for learning the tag relevance, and RW-W performs a standard random walk on the weighted voting graph.

5.4 Comparisons with Other Methods
For a fair comparison of the different methods, the number of nearest neighbors k are set to the same value (e.g., k =

229

Table 2: Performance of different methods on the metric MAP and P@100. The  () indicates statistical significance at p-value<0.05 using the Student's t-test with regard to the baseline NV (NV-W). The underline indicates the best performance.

Method

NUS-WIDE

MAP

P@100

MIR Flickr MAP P@100

NV NV-W RW RW-W GV GV-W

0.3766 0.3778 0.3526 0.3531 0.3788   0.3790  

0.7406 0.7480 0.6336 0.6359 0.7453  0.7501  

0.2918 0.2921 0.2869 0.2871 0.2921 0.2923

0.8906 0.8935 0.8571 0.8559 0.8918 0.8965 

100) for all methods. A detailed discussion of the impact of parameter k to our methods is given in Section 5.6. For NV-W, RW-W, and GV-W, the radius parameter  in Eq. 2 is set to the average Euclidean distance of all images (i.e.,  = 6.7 in NUS-WIDE and  = 22.48 in MIR Flickr). The parameters  and  are set to their optimal values (e.g.,  = 0.85 and  = 1.0).
The evaluation results on both NUS-WIDE and MIR Flickr datasets are shown in Table 2. For each method, we report the MAP and P@100. For each column in Table 2, we have underlined the best performer. The statistical significance of improvement was assessed using the Student's paired ttest, and p-values less than 0.05 were used to reject the null hypothesis.
As can be seen from the results, in the NUS-WIDE dataset, our method GV-W significantly (p - value < 0.05 ) outperforms all the four baselines on both metrics MAP and P@100. The reason is because GV-W simultaneously takes into account both the relationship information among neighbor images and their visual similarity for learning tag relevance.
Generally, the weighted methods (e.g., NV-W, RW-W, and GV-W) are better than the unweighted methods (e.g., NV, RW, and GV) on MAP and P@100. Moreover, among all three unweighted methods (NV,RW, and GV), our method GV is significantly (p - value < 0.05 ) better than the other two baselines NV and RW, which is due to the fact that tag relevance can be estimated more accurately by further considering the structure information among neighbor images. It is worth noting that the random walk based voting methods (i.e., RW and RW-W) have the worst performance. As we explained in Section 4.5, directly using existing random walk methods may hurt the voting since these methods share a fixed teleportation probability for all nodes in the random walk process. This is the main motivation for introducing an adaptive teleportation process into the standard random walk for better voting. In the MIR Flickr dataset, similar results are observed.
5.5 Analysis on different categories
In this section, we further analyse the performance of our methods over different categories of images. To this end, we group the 81 concepts in the dataset NUS-WIDE into 6 categories7: events (e.g., dancing), program (e.g., sports), scene (e.g., sky), people (e.g., police), objects(e.g., horses),
7We use the the concept taxonomy provided in [3] to group the concepts.

Table 3: Group Analysis on NUS-WIDE based on the metric MAP. The underline indicates the best performance.

Category NV NV-W RV RV-W GV GV-W

Events Scene People Objects

0.332 0.344 0.391 0.438

0.333 0.347 0.394 0.438

0.285 0.317 0.376 0.403

0.286 0.317 0.377 0.403

0.337 0.345 0.395 0.440

0.335 0.347 0.396 0.439

and graphics(e.g., map). Since the categories program and graphics have solely 1 concept each, we report here only the other 4 categories: events, scene, people, and objects, which have 9, 33, 4 and 33 concepts, respectively.
The evaluation results for all methods on the NUS-WIDE dataset in terms of MAP are shown in Table 3. We can notice that the random walk based methods (RW and RW-W) have the worst performance over all 4 categories. Neighbor voting based methods (NV and NV-W) perform better than the two random walk based methods (RW and RW-W). Moreover, our proposed methods (GV and GV-W) are consistently outperforming both neighbor voting based methods and random walk based methods on all categories.
This observation confirms that our proposed methods (GV and GV-W) can achieve better performance than all baselines for different categories of concepts.
5.6 Impact of Parameters
In this section, we conduct experiments to analyze the sensitivity of our methods with respect to the parameters: k, ,  and .
5.6.1 Impact of Parameter k
The parameter k represents the number of nearest neighbors considered, and controls the density of the voting graph. When k is small, less edges are generated for building the voting graph. However, when k becomes large, the constructed voting graph will have more edges and become denser.
For this set of experiments, we fix the other parameters to the following values:  = 1.0,  = 0.85, and  is set to 6.7 in NUS-WIDE and 22.48 in MIR Flickr. We use MAP as the performance measure. Figure 4 shows the change in performance when k is varied in the range from 100 to 1000 with a step length of 100. We can observe that on the NUS-WIDE dataset, the MAP gradually increases as k increases, and the increasing rate becomes small after k > 400. On the MIR Flickr dataset, the MAP first increases when the k varies from 100 to 200, and start to decrease as k > 200. This happens because when given more nearest neighbors, more useful relationship information can be used for constructing the voting graph. On the other hand, when k becomes too large, noisy relationships would be introduced into the voting graph and hurt the performance. It is also worth noting that for the concepts in the MIR Flickr dataset, the average number tagged images is much smaller than that in NUS-WIDE, thus it suffers an early drop in performance on the MIR Flickr dataset.
5.6.2 Impact of Parameter 
The parameter  in Eq. 3 controls how the number of out-link neighbors affects the confidence value. In our ex-

230

MAP

MAP

GV GV-W 0.39 0.388 0.386 0.384 0.382 0.38 0.378 0.376 0.374
100 200 300 400 500 600 700 800 900 1000 k
GV GV-W 0.294
0.2935
0.293
0.2925
0.292
0.2915
0.291 100 200 300 400 500 600 700 800 900 1000 k
Figure 4: The impact of number of nearest neighbors k to our proposed methods GV and GV-W on NUS-WIDE (Above) and MIR Flickr (Below)

MAP

0.385

GV GV-W

0.38

0.375

0.37

0.365

0.36

0.355

0.35

0.345

0.34

0.335 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 

0.293

GV GV-W

0.292

0.291

0.29

0.289

0.288

0.287

0.286

0.285

0.284 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 

MAP

Figure 5: The impact of parameter  to our proposed methods GV and GV-W on NUS-WIDE (Above) and MIR Flickr (Below)

periments, we vary  in the range 0 to 2 with a step size of 0.2, and use MAP as the performance measure. The results are shown in Figure 5. We can see that on both datasets the performance increases as  increases until  = 1.0; when  > 1.0, there is a slight decrease of the performance. This is because with a small  value, the adaptive teleportation random walk model will have nearly the same teleportation probabilities for all nodes, and regress to the standard random walk model. While  gets too large, the useful information from these nodes with less number of out-link neighbors will be omitted. The best setting is  = 1.0, which indicates that the confidence value of each node should be linearly proportional to the number of its out-link neighbors.
5.6.3 Impact of other parameters
We also conduct experiments to analyse the impact of the parameters  and . Due to space limitations, here we directly report the results.
The parameter  in Eq. 5 can be considered as a parameter which controls the prior teleportation probability. We vary  from 0.1 to 1.0 with step size 0.1, and observe that our methods are not very sensitive to  as compared with the case of standard random walk based methods. This is because in the random walk based methods the teleportation probability is exclusively determined by , while in our methods this probability will be characterized by both parameters  and .
The parameter  in Eq 2 will affect the sensitivity of the similarity measure. When  is small, neighbor images which are very close to the target image will have a larger similarity, thus have more voting power in the weighted version method, i.e., GV-W. On the contrary, when  is large, al-

most all neighbor images will have similar voting powers. At the extreme,  can be set to infinity which will result in all neighbor images having equal voting power, in this case GV-W will regress to GV. We varied the value of  from 2 to 100 with step size 2, and find the optimal value is around the average Euclidean distance of all images in each dataset.
6. CONCLUSIONS
In this paper, we have presented a novel framework for learning social tag relevance. We show that the relationships among visual neighbors may embed rich information which can be further exploited to boost the neighbor voting performance. In particular, these previous neighbor voting methods can be considered as a flat voting, which heavily rely on the visual similarity between images while neglect the structure information among images. While our proposed methods can be considered as a structured voting, where the relationships among images are further exploited. To this end, we introduce an adaptive teleportation random walk model and prove theoretically that the proposed model can converge to a stationary distribution and also give its closed-form solution. Experimental results show that our method outperforms existing tag relevance learning algorithms for the tag-based image retrieval.
For future work, we would like to apply the proposed method in other applications, such as web search, query recommendation. By further considering each node's confidence information, our adaptive teleportation strategy may help to improve the performance in these applications. Besides, we will also investigate using the textual information to reduce the noise propagation in the voting graph since there still exists some incorrect relationships in the graph.

231

Acknowledgments
This research work was partially funded by the European Commission FP7 under Grant No. 287704 (CUbRIK).
7. REFERENCES
[1] S. F. Chang, T. Sikora, and A. Puri. Overview of the MPEG-7 standard. IEEE Trans. Circuits and Systems for Video Technology, 11(6):688­695, June 2001.
[2] S. A. Chatzichristofis and Y. S. Boutalis. Fcth: Fuzzy color and texture histogram - a low level feature for accurate image retrieval. In Proceedings of the 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services, WIAMIS '08, pages 191­196, Washington, DC, USA, 2008. IEEE Computer Society.
[3] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '09, pages 48:1­48:9, 2009.
[4] N. Craswell and M. Szummer. Random walks on the click graph. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '07, pages 239­246, New York, NY, USA, 2007. ACM.
[5] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efficient boosting algorithm for combining preferences. J. Mach. Learn. Res., 4:933­969, Dec. 2003.
[6] T. H. Haveliwala. Topic-sensitive pagerank. In Proceedings of the 11th international conference on World Wide Web, WWW '02, pages 517­526, New York, NY, USA, 2002. ACM.
[7] M. J. Huiskes and M. S. Lew. The mir flickr retrieval evaluation. In Proceedings of the 1st ACM international conference on Multimedia information retrieval, MIR '08, pages 39­43, New York, NY, USA, 2008. ACM.
[8] G. Jeh and J. Widom. Scaling personalized web search. In Proceedings of the 12th international conference on World Wide Web, WWW '03, pages 271­279, New York, NY, USA, 2003. ACM.
[9] D. Jin, D. Liu, B. Yang, C. Baquero, and D. He. Ant colony optimization with markov random walk for community detection in graphs. In Proceedings of the 15th Pacific-Asia conference on Advances in knowledge discovery and data mining - Volume Part II, PAKDD'11, pages 123­134, Berlin, Heidelberg, 2011. Springer-Verlag.
[10] Y. Jing and S. Baluja. Pagerank for product image search. In Proceedings of the 17th international conference on World Wide Web, WWW '08, pages 307­316, New York, NY, USA, 2008. ACM.
[11] M. Li, B. M. Dias, I. Jarman, W. El-Deredy, and P. J. Lisboa. Grocery shopping recommendations based on basket-sensitive random walk. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '09, pages 1215­1224, New York, NY, USA, 2009. ACM.
[12] X. Li, C. G. Snoek, and M. Worring. Learning tag relevance by neighbor voting for social image retrieval. In Proceedings of the 1st ACM international

conference on Multimedia information retrieval, MIR '08, pages 180­187, New York, NY, USA, 2008. ACM.
[13] X. Li, C. G. M. Snoek, and M. Worring. Learning social tag relevance by neighbor voting. Trans. Multi., 11(7):1310­1322, Nov. 2009.
[14] D. Liu, X.-S. Hua, L. Yang, M. Wang, and H.-J. Zhang. Tag ranking. In Proceedings of the 18th international conference on World wide web, WWW '09, pages 351­360, New York, NY, USA, 2009. ACM.
[15] M. Lux and S. A. Chatzichristofis. Lire: lucene image retrieval: an extensible java cbir library. In Proceedings of the 16th ACM international conference on Multimedia, MM '08, pages 1085­1088, New York, NY, USA, 2008. ACM.
[16] Q. Mei, J. Guo, and D. Radev. Divrank: The interplay of prestige and diversity in information networks. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '10, pages 1009­1018, New York, NY, USA, 2010. ACM.
[17] K. Onuma, H. Tong, and C. Faloutsos. Tangent: A novel, 'surprise me', recommendation algorithm. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '09, pages 657­666, New York, NY, USA, 2009. ACM.
[18] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. In Proceedings of the 7th International World Wide Web Conference, pages 161­172, 1998.
[19] P. Pons and M. Latapy. Computing communities in large networks using random walks. In Proceedings of the 20th International Conference on Computer and Information Sciences, ISCIS'05, pages 284­293, Berlin, Heidelberg, 2005. Springer-Verlag.
[20] A. W. M. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Trans. Pattern Anal. Mach. Intell., 22(12):1349­1380, Dec. 2000.
[21] A. Sun, S. S. Bhowmick, K. T. Nam Nguyen, and G. Bai. Tag-based social image retrieval: An empirical evaluation. J. Am. Soc. Inf. Sci. Technol., 62(12):2364­2381, Dec. 2011.
[22] B. Q. Truong, A. Sun, and S. S. Bhowmick. Content is still king: the effect of neighbor voting schemes on tag relevance for social image retrieval. In Proceedings of the 2nd ACM International Conference on Multimedia Retrieval, ICMR '12, pages 9:1­9:8, New York, NY, USA, 2012. ACM.
[23] C. Wang, F. Jing, L. Zhang, and H.-j. Zhang. Scalable search-based image annotation. Multimedia Systems, 14(4):205­220, 2007.
[24] J. Wang, J. Wang, G. Zeng, Z. Tu, R. Gan, and S. Li. Scalable k-nn graph construction for visual descriptors. In Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), CVPR '12, pages 1106­1113, 2012.
[25] L. Wu, L. Yang, N. Yu, and X.-S. Hua. Learning to tag. In Proceedings of the 18th International Conference on World Wide Web, WWW '09, pages 361­370, New York, NY, USA, 2009. ACM.

232

