Modeling Evolution of a Social Network using Temporal Graph Kernels

Akash Anil
Department of CSE Indian Institute of Technology
Guwahati Guwahati, Assam-781039,
India
a.anil@iitg.ernet.in

Niladri Sett
Department of CSE Indian Institute of Technology
Guwahati Guwahati, Assam-781039,
India
niladri@iitg.ernet.in

Sanasam Ranbir Singh
Department of CSE Indian Institute of Technology
Guwahati Guwahati, Assam-781039,
India
ranbir@iitg.ernet.in

ABSTRACT
Majority of the studies on modeling the evolution of a social network using spectral graph kernels do not consider temporal effects while estimating the kernel parameters. As a result, such kernels fail to capture structural properties of the evolution over the time. In this paper, we propose temporal spectral graph kernels of four popular graph kernels namely path counting, triangle closing, exponential and neumann. Their responses in predicting future growth of the network have been investigated in detail, using two large datasets namely Facebook and DBLP. It is evident from various experimental setups that the proposed temporal spectral graph kernels outperform all of their non-temporal counterparts in predicting future growth of the networks.
1. INTRODUCTION
Given a non-empty set of objects X , a kernel k : X × X  R is a measure of similarity between two objects x  X and y  X satisfying two properties; (i) symmetry i.e., k(x, y) = k(y, x) and (ii) positive semi definite i.e.,
cxcyk(x, y)  0
x,yX
where cx, cy  R. For a finite set X , a kernel can be uniquely represented by a matrix K of order |X | × |X | where K[x][y] relates to k(x, y). For graph kernels, x and y are either nodes in the graph or the graph itself quantifying how similar two nodes in a graphs are or how similar two graphs are? [1, 2, 3, 4]. In recent studies, graph kernels (in both forms) have been applied in various social network analysis problems such as link prediction [4, 5, 6, 7], network evolution [8, 9], community detection [10]. Social networks evolve over time and solution to above problems can be greatly affected by temporal parameters of the evolution [11, 12]. However, majority of the above studies do not consider temporal parameters. This paper revisits the study [8] of modeling net-
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. Include the http://DOI string/url which is specific for your submission and included in the ACM rightsreview confirmation email upon completing your ACM form.

work growth using spectral graph kernels (spectral transformation of the graph kernels). It proposes temporal version of the spectral graph kernels by incorporating the temporal effects. Given a sequence of snapshots of an evolutionary social network graph taken at different instance in time i.e., G1, G2, G3, ..., Gm (Gi represents a snapshot at time i), the task is to predict Gt for some t > m. This paper focuses on four popular spectral kernels on graphs namely triangle closing [13], exponential [2], path counting [14] and neumann [2], and makes the following contributions.
· Devise temporal versions of the spectral graph kernels.
· Estimate temporal kernel parameters using regression.
· Compare performance of predicting future growth of a network between different kernels (proposed temporal and existing non-temporal) using two large datasets namely Facebook and DBLP.

2. SPECTRAL KERNEL OF GRAPH
Spectral graph theory is a popular method to study graph properties [15, 16], which exploits matrix decomposition of the adjacency or Laplacian matrix of a graph. Considering an adjacency matrix A of a graph, eigenvalue decomposition(EVD) can be used to decompose A as follows:

A = UUT

(1)

where U is an n × r orthogonal matrix such that the ith column vector corresponds to ith eigenvector of A, and  is a r×r diagonal matrix with eigenvalues as diagonal elements (set of eigenvalues represents the spectrum of the matrix and they are arranged in descending order of their values) and r is the rank of the matrix. Considering equation 1, spectral transformation of a graph kernel K(A) is defined as

K(A) = K(UUT ) = UF ()UT

(2)

for some function F (). Like in [8], this paper also assumes the eigenvectors U to be time invariant. The function F () is defined by a set of real valued function f () where s are the eigenvalues of adjacency matrix. The spectral transformation of the four kernels are discussed in Table 1. If  is an eigenvalue of a source graph, f () defines the future growth of the same eigenvalue. The formulation of f () for each kernel is briefly discussed in the 2nd and 3rd columns of the table 1 (details of which can be found in [15, 8]).

1051

Table 1: Different spectral kernels on graph and their spectral transformation

Kernel

Kernel Function

Spectral Kernel Transformation

LSS error for learning parameters

Path Counting

K(A) = Ak = UkUT

r

K(A) = UF (k)UT where F (k) is E(e) = (vi - (a + bi + c2i ))2

defined by f () = k and  > 0.

i=1

Triangle Closing

K(A) = A2 = U2UT

K(A) = UF (2)UT where F (2)

E(e) =

r i=1

[vi

-

(a

+

b2i )]2

is defined by f () = 2 and  > 0.

Exponential kernel Neumann kernel

K(A) = exp(A) =

 i=0

i i!

Ai

=

eUUT

K(A) = (I-UUT)-1 where -1 > 1

K(eA) = UF (e)UT where F (e) is defined by f () = e.

K(A) = [UF (I - )UT )]-1where

f () =

1 1-

defines

the

kernel.

r
E(e) = (log vi - (log a + bi))2
i=1

r

E(e)

=

(vi
i=1

-

(a

+

b

1 1-i

))2

3. PROPOSED METHODS
Let As and At be the adjacency matrices of the source graph and target graph respectively. The predicted target graph At can be defined using spectral graph kernel as At = UF (s)UT where U is constant over time.

3.1 Learning kernel parameter
Kernel parameters can be learnt using two different approaches; (i) learn the parameter individually for all eigenvalues or (ii) learn a common parameter for all the eigenvalues that minimizes the average prediction error. This paper uses the second approach and estimates the parameters using a polynomial based regression. For learning the kernel parameters, we use a reference dataset. This study uses a validation graph as a reference dataset to estimate the parameters, which is a snapshot of the evolving network taken at a particular time between the source and target snapshots. Considering As, Av and the At as the adjacency matrices of the source, the validation and the target networks respectively, the validation network Av satisfy the following inequality.

As < Av < At

A matrix X < Y iff X[i][j]  Y [i][j]. For learning parameters, we define an absolute square error using reference dataset as follows:

e = (Av-Av)2 = [U(v-F())UT]2 = U(v-F())2UT (3)
Since U is assumed to be time invariant, the square error sum is defined as follows:

r

E(e) = [vi - f (i)]2

(4)

i=1

where i is the ith eigenvalue and r is the rank of the matrix As and vi is the ith eigenvalue of the matrix Av. Now the task is to find the kernel's parameters that minimize the above square error sum E(e) using regression. Table 1 (4th
column) shows the criteria error functions of applying re-
gression for all the kernels. The parameters a, b and c are
learnt using the reference dataset Av and respective regression function f (.).

3.2 Temporal Kernels on Graphs
If we consider a sequence of snapshots taken at different time stamps, we can estimate a sequence of kernel parameters defining the evolution of the network between subsequent snapshots. The plots in figure 1 show the changing

Table 2: Characteristics of datasets.

DBLP

Facebook

Nodes

3,61,032

63,729

Edges (s) 13,93,802

14,09,084

Edges (t) 14,57,489

15,19,684

Periods 2001 to 2010

5/9/2006 - 21/1/2009

Snapshots 1st five years for first Till 21/9/2007 as 1st

snapshot and succes- snapshot and succes-

sive years for succes- sive months for suc-

sive snapshots

cessive snapshots

pattern of the kernel parameters over time. It clearly shows that parameters follows a pattern which can be defined suitably using a polynomial curve fitting. Let {a1, a2, a3, ..} be the values of parameter a at different instance in time, the value of a at some future time t i.e., a(t) is defined using a polynomial a(t) = z0 + z1t + z2t2 where z0, z1 and z2 are the coefficients of the polynomial. We repeat the same procedure for all the other kernel parameters. Considering the temporal dimension into account, we finally define the temporal graph kernel as follows:

f (i, t) = a(t) + b(t)i + c(t)2i

(5)

where a(t), b(t) and c(t) define the estimate of the tempo-

ral parameters. Depending on the type of underlying ker-

nel, equation 5 is customized accordingly. Temporal triangle closing kernel is formally formulated as f (, t) = a(t)+b(t)2

where a(t) and b(t) are estimated using polynomial curve fitting with degree two 1. Similarly, temporal path counting kernel is formulated as f (, t) = a(t) + b(t) + c(t)2, tem-

poral exponential kernel as f (, t) = a(t)eb(t) and temporal

neumann

kernel

as

f (, t)

=

a(t)

+

b(t)

1 1-

.

We

have de-

termined the value of  in temporal neumann kernel using

gradient descent (the  that returns the local minimal er-

ror).

4. EXPERIMENTAL ANALYSIS
All the experimental results reported in this section use two large datasets namely DBLP co-authorship [17] and Facebook friendship [18] undirected unweighted networks. The characteristics of the datasets are shown in Table 2. Performance of different kernels are evaluated using the fol-
1We observe that experiments return minimum error with degree two.

1052

Exponential Intercept Evolution 5
FB DBLP
4.5

4

3.5

3

1

2

3

4

5

6

7

Snapshots

(a) Exponent intercept

0.02 0.018

FB DBLP

Exponential Slope Evolution

0.016

0.014

0.012

0.01

0.008

0.006

1

2

3

4

5

6

7

Snapshots

(b) Exponent slope

Neumann Intercept Evolution

40000 FB
20000 DBLP

0

-20000

-40000

-60000

-80000

-100000

-120000

-140000

1

2

3

4

5

6

7

Snapshots

(c)Neumann Intercept

Figure 1: Evolution of kernel parameters with the evolution of the network over time. Only three plots are shown in the figure. All other kernels also follow a regular pattern fitting polynomial curve.

Table 3: Absolute average prediction error for fixed source and target networks and variable validation. TC:

triangle closing, Exp:Exponential, Neu:Neumann and PCE-2: Path Counting kernel with path length 2.

Dataset As Av At

TC

Non-temporal Exp Neu PCE-2

TC

Temporal

Exp

Neu

PCE-2

129 41.45 41.37 41.45 41.45

NA

NA

NA

NA

139 39.31 39.23 39.31 39.31 26.49(+33%) 24.52(+37%) 23.412(+40%) 23.39(+40%)

149 37.00 36.93 37.00 37.00 22.68(+39%) 24.09(+35%) 12.53(+66%) 13.09(+65%)

Facebook

159

28.28 28.20 28.28 28.28 20.07(+29%) 19.83(+30%) 15.25(+46%) 20.52(+27%)

169 20.91 20.83 20.91 20.91 14.38(+31%) 14.09(+32%) 12.28(+41%) 12.18(+42%)

179 12.97 12.96 12.97 12.97 8.48(+35%) 8.95(+30%) 6.43(+50%) 6.55(+50%)

189

6.46 6.82 4.86 4.85 5.82(+10%) 5.84(+14%) 2.97(+39%) 2.61(+46%)

126

3.98 4.90 3.50 3.50

NA

NA

NA

NA

DBLP

136 146

3.62 4.37 2.93 2.94 3.16 3.50 1.99 1.99

3.27(+10%) 3.01(+4%)

3.73(+15%) 3.24(+7%)

1.83(+38%) 1.76(+40%) 1.53(+23%) 1.53(+23%)

156

2.81 2.87 1.23 1.24 2.80(+0.32%) 2.87(+0.31%) 1.22(+0.73%) 1.23(+1%)

lowing absolute error.

SE = 1 r

r

|ti - f (si )|

i=1

where si and ti are the actual ith eigenvalues of the source and target network graphs and r is the rank of the matrix. In this paper, performance of non-temporal and temporal graph kernels have been investigated using two experimental setups. In the first setup, the source and target graphs are fixed and validation graph changes. It allows us to investigate the effect of validation graph in modeling the evolution of the graph. Table 3 compares the performance between different kernels. For all kernels (both temporal and non-temporal), performance increases (error decreases) as we move the validation graph closer to the target graph. It indicates that validation graphs closer to source graph are underspecified and do not capture much information of the target graph. This observation is true for both Facebook and DBLP networks and also for both temporal and nontemporal kernels.
In the second setup, validation and target graphs are fixed and source graph changes. It allows us to investigate the effect of time gap between source and target graph in modeling the evolution. Since we get the best performance when validation set is closest to the target (in first setup), we therefore fix the validation graph to be closest snapshot (8th for Facebook and 5th for DBLP). Table 4 compares the performance between different kernels. Since validation graph is close to target, variation in prediction error is small. Still

error decreases as the source graph moves closer to target for almost all cases. From the above two experiments, we can infer the following two points. Graph kernels predict the evolution of the network well, if (i) partial graph captures significantly large amount of target information (validation graph is close to the target graph) and (ii) source graph is close to the target graph.
For non-temporal graph kernels, the above two points lead us to the following issues.
· Availability of the validation graph close to target graph is not feasible in practice.
· One may often like to predict the growth of the network with longer time gap.
· Growth of a network after a longer time gap may be modeled as a sequence of short gap growth prediction in incremental fashion. For example, from As, predict As+; from As+, predict As+2 and so on. However, this approach will be computational intensive. Further, it may also have the effect of accumulated error from successive prediction.
· Since we do not use the intermediate snapshots between source and validation graphs, the pattern of underlying structural growth of the kernel is lost.
The above problems can be addressed using the proposed temporal spectral graph kernels. For temporal graph ker-

1053

Table 4: Absolute average prediction error for fixed validation and target networks and variable source. TC:

triangle closing, Exp:Exponential, Neu:Neumann and PCE-2: Path Counting kernel with path length 2.

Dataset

As  Av  At

TC

Non-temporal Exp Neu PCE-2

TC

Temporal

Exp

Neu

PCE-2

189

6.46 6.82 4.86 4.85 5.82(+10%) 5.84(+14%) 2.97(+39%) 2.61(+46%)

289

6.46 6.82 4.90 4.89 5.71(+12%) 5.74(+16%) 2.91(+40%) 2.73(+44%)

389

6.48 6.84 4.91 4.90 6.00(+7%) 6.17(+10%) 3.48(+29%) 4.15(+15%)

Facebook

489

6.59 7.01 4.94 4.89 6.64(-0.62%) 7.09(-1%) 5.05(-2.2%) 2.76(+43%)

589

6.27 6.61 4.86 4.86 6.25(+0.2%) 6.58(+0.4%) 4.86(+0.04%) 3.74(+23%)

689

6.00 6.30 4.77 4.77

6:00

6.30

4.77

4.77

789

5.79 6.11 4.67 4.67

NA

NA

NA

NA

156

2.81 2.87 1.24 1.24 2.80(+0.3%) 2.86(+0.3%) 1.22(+1.5%) 1.23(+1%)

DBLP

256 356

2.82 2.93 1.07 1.05 2.82(+0.14%) 2.91(+0.5%) 1.03(+3.5%) 1.04(+0.47%)

2.78 2.86 0.94 0.94

2.78

2.86

0.94

0.94

456

2.78 2.93 0.94 0.95

NA

NA

NA

NA

nels, the absolute spectral error is modified as follows:

1 SE =

r

|i - f (, t)|

r

i=1

From the Tables 3 and 4, it is evident that temporal kernels outperform almost all of its non-temporal counterparts. With proposed model, an improvement of upto 66% over Facebook dataset and upto 40% over DBLP dataset can be achieved. Temporal kernels also predict future evolution better (referring to the experimental cases where validation is closer to source and farther from target in Table 3). Further among all the kernels, path counting spectral graph kernel outperforms all other kernels for both temporal and non-temporal over both the Facebook and DBLP datasets.

5. CONCLUSIONS
This paper proposes temporal graph kernels for four spectral graph kernels namely path counting, triangle closing, exponential kernel,neumann kernel and compares their performances using two large datasets namely Facebook and DBLP. From various experimental setups, it can be inferred that non-temporal kernels fail to capture structural growth of the network. In almost all the experimental cases, temporal kernels outperform their non-temporal counterparts.

6. REFERENCES
[1] S. V. N. Vishwanathan, N. N. Schraudolph, R. Kondor, and K. M. Borgwardt. Graph kernels. J. Mach. Learn. Res., 11:1201­1242, Aug. 2010.
[2] R. I. Kondor and J. D. Lafferty. Diffusion kernels on graphs and other discrete input spaces. In Proc. of the Nineteenth International Conference on Machine Learning, ICML '02, pages 315­322, San Francisco, CA, USA, 2002.
[3] A. Smola and R. Kondor. Kernels and regularization on graphs. In Proc. Conf. on Learning Theory and Kernel Machines, pages 144­158, 2003.
[4] F. Fouss, L. Yen, A. Pirotte, and M. Saerens. An experimental investigation of graph kernels on a collaborative recommendation task. In Proc. Int. Conf. on Data Mining, pages 863­868, 2006.
[5] D. Liben-Nowell and J. Kleinberg. The link-prediction problem for social networks. J. Am. Soc. Inf. Sci. Technol., 58(7):1019­1031, May 2007.

[6] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. T. Riedl. Application of dimensionality reduction in recommender system ­ a case study. In IN ACM WEBKDD WORKSHOP, 2000.
[7] A. K. Menon and C. Elkan. Link prediction via matrix factorization. In Proc. of the 2011 European conference on Machine learning and knowledge discovery in databases - Volume Part II, ECML PKDD'11, pages 437­452, Berlin, Heidelberg, 2011.
[8] J. Kunegis, D. Fay, and C. Bauckhage. Network growth and the spectral evolution model. In Proc. of the 19th ACM international conference on Information and knowledge management, CIKM '10, pages 739­748, New York, NY, USA, 2010. ACM.
[9] T. Thorne and M. P. H. Stumpf. Graph spectral analysis of protein interaction network evolution. Journal of The Royal Society Interface, May 2012.
[10] S. Sarkar and A. Dong. Community detection in graphs using singular value decomposition. Phys. Rev. E, 83:046114, Apr 2011.
[11] S. G. Matus Medo, Giulio Cimini. Temporal effects in the growth of networks. Physical Review Letters, 2011.
[12] D. M. Dunlavy, T. G. Kolda, and E. Acar. Temporal link prediction using matrix and tensor factorizations. ACM Trans. Knowl. Discov. Data, 5(2):10:1­10:27, Feb. 2011.
[13] J. Leskovec, L. Backstrom, R. Kumar, and A. Tomkins. Microscopic evolution of social networks. In Proc. of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '08, pages 462­470, New York, NY, USA, 2008. ACM.
[14] L. Lu¨, C. Jin, and T. Zhou. Similarity index based on local paths for link prediction of complex networks. Physical Review E, 80(4):046122, 2009.
[15] F. Chung. Spectral Graph Theory. American Math. Society, 1997.
[16] P. R. Dragos Cvetkovic and S. Simic. Eigenspaces of Graphs. Cambridge University Press, 1997.
[17] Dblp dataset, 2012. http://dblp.uni-trier.de/.
[18] A. Mislove, M. Cha, B. Viswanath, and K. P.Gummadi. On the evolution of user interaction in facebook. In Proc. of the 2nd ACM workshop on Online social networks,Aug.2009

1054

