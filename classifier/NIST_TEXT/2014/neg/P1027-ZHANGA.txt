Do Users Rate or Review? Boost Phrase-level Sentiment Labeling with Review-level Sentiment Classification
Yongfeng Zhang, Haochen Zhang, Min Zhang, Yiqun Liu, Shaoping Ma
State Key Laboratory of Intelligent Technology and Systems Department of Computer Science & Technology, Tsinghua University, Beijing, 100084, China
{zhangyf07,rukyzhc}@gmail.com, {z-m,yiqunliu,msp}@tsinghua.edu.cn

ABSTRACT
Current approaches for contextual sentiment lexicon construction in phrase-level sentiment analysis assume that the numerical star rating of a review represents the overall sentiment orientation of the review text. Although widely adopted, we find through user rating analysis that this is not necessarily true. In this paper, we attempt to bridge the gap between phrase-level and review/document-level sentiment analysis by leveraging the results given by review-level sentiment classification to boost phrase-level sentiment polarity labeling in contextual sentiment lexicon construction tasks, using a novel constrained convex optimization framework. Experimental results on both English and Chinese reviews show that our framework improves the precision of sentiment polarity labeling by up to 5.6%, which is a significant improvement from current approaches.
Categories and Subject Descriptors
I.2.7 [Artificial Intelligence]: Natural Language Processing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - Classification
Keywords
Sentiment Analysis; Sentiment Classification; Sentiment Lexicon Construction; Optimization
1. INTRODUCTION
The construction of a sentiment lexicon is of key importance in phrase-level sentiment analysis [7] and many other tasks such as recommender systems [10], where each entry in the lexicon is a Feature-Opinion (F-O) word pair together with the corresponding Sentiment polarity (S), represented by (F,O,S) [5]. For example, the entries (service, excellent, positive) and (phone quality, perfect, positive) could be extracted from the textual review of Figure 1.
However, current phrase-level sentiment lexicon construction approaches may only give sentiment polarity labeling
This work was supported by Natural Science Foundation (60903107, 61073071) and National High Technology Research and Development (863) Program (2011AA01A205).
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609501.

(assigning the S for an F-O pair) precisions of around 70%  80% [4]. We find through large-scale user behavior analysis that one of the basic assumptions in current approaches, i.e., the overall numerical rating of a review represents the overall sentiment of the review text, is not necessarily true.
To avoid the biased assumption, we propose to boost the performance of phrase-level sentiment polarity labeling in a reverse way, which is to use unsupervised review-level sentiment classification results instead of the numerical ratings as a heuristic for phrase-level polarity labeling. State-of-theart review-level sentiment classification techniques, even the unsupervised approaches, can give pretty good precisions of above 90% [9, 6], which could be reliable to boost the performance of phrase-level sentiment polarity labeling.
In general the framework is two-stage. In the first stage, the overall sentiment orientations of the product reviews are labeled using a review-level sentiment classifier. In the second stage, we extract feature-opinion pairs from the corpus [5, 8], then use the overall sentiment orientations of the reviews as constraints to learn the sentiment polarities of these pairs automatically, using a novel optimization framework.
Experimental results on both English and Chinese review datasets show that our framework improves the precision of phrase-level sentiment polarity labeling significantly, which means that the original assumption might be infeasible, and that it might be promising to leverage sentence- or reviewlevel sentiment analysis techniques to boost the performance of phrase-level sentiment analysis tasks.
2. THE FRAMEWORK
The first stage of the framework determines the overall sentiment of each piece of review by conducting reviewlevel sentiment classification, and the second stage leverages the results for sentiment lexicon construction. We use x = [x1, x2]T (xi  0) to represent a sentiment vector, where x1 and x2 are the positive and negative degrees, respectively, and use X = [x1x2 · · · xm]T as the sentiment matrix for a set of m reviews or feature-opinion pairs.
2.1 Review-Level Sentiment Classification
Two possible sentiment vector candidates are used in this stage. If a review is classified as positive by a sentiment classification algorithm, then its sentient vector is assigned
Figure 1: A sample user review from Amazon.com

1027

as x = [1, 0]T , otherwise, the corresponding sentiment vector is x = [0, 1]T . Based on the classification results, a sentiment matrix X~ = [x1x2 · · · xm]T is constructed, which will be used as a constraint in the next stage.
We use the sentence orientation prediction approach in [1] for English reviews, and the automatic seed word selection scheme in [9] for Chinese reviews. Both of them are stateof-the-art approaches on the corresponding language.

2.2 Sentiment Lexicon Construction

We consider four kinds of constraints to learn the senti-

ment lexicon X: 1) Review-level sentiment orientation, 2)

General sentiment lexicon, 3) Linguistic heuristics, and 4)

Sentential sentiment consistency.

1) Review-level Sentiment Orientation captures the

overall sentiment of a review given by the review-level sen-

timent classification algorithm in the previous stage. We

construct a matrix A to indicate the frequency of each F-O

pair in each review: Aij is the frequency of F-O

= Iinjeg · pair j in

Freq(i,j)
k Freq(i,k)
review i.

, where Freq(i, j) The matrix Ineg

is an indication matrix that allows us to take the "negation rules" into consideration. Iinjeg = -1 if the F-O pair j is
modified by a negation word, e.g. "no", "not", "hardly", etc. Otherwise, Iinjeg = 1.
The sentiments of all the F-O pairs are aggregated to ap-

proximate the review-level sentiment polarity, which gives

the following objective function: R1 =

AX - X~

2 F

.

2) General Sentiment Lexicon captures the sentiment

of some context-irrelevant opinion words, like excellent, good

and bad. We construct the general sentiment lexicon X0 by

labeling the polarities of the F-O pairs in X according to the public sentiment corpora MPQA1 on English, and HowNet2 on Chinese. An F-O pair is labeled as [1, 0]T or [0, 1]T if the

opinion word is included in the positive or negative word set, correspondingly. Otherwise, we use [0, 0]T .

We expect the sentiment polarities of the context-irrelevant

words in X to be close to those in the general sentiment lex-

icon X0, which corresponds to the objective function R2 =

G(X - X0)

2 F

,

where

G

is

a

diagonal

matrix

indicating

which F-O pairs in X are "fixed" by the general sentiment

lexicon X0. Namely, Gii = 1 if the i-th F-O pair has a fixed

sentiment, and Gii = 0 otherwise.

3) Linguistic Heuristic captures the linguistic "and"

and "but" relationship. It is intuitional that those F-O pairs

frequently concatenated with "and" might have similar sen-

timents, while those frequently connected by "but" tend to

have opposite sentiments. To formalize the intuition, we define two n × n matrices Wa and Wb for the "and" and "but" linguistic heuristics, respectively. We set Waij = Waji = 1 or Wbij = Wbji = 1 if pair i andj are concatenated by "and"
or "but" for a minimal number of times, correspondingly,

otherwise, we set Waij = Waji = 0. The objective function regarding both "and" and "but" linguistic heuristic is:

R3 = tr(XT DaX - XT WaX) + tr(XT DbX - XT WbXE) = tr(XT DX - XT WaX - XT WbXE)

where tr(·) is the trace of a matrix, Da, Db  Rn×n are diag-

onal matrices where Daii =

n j=1

Waij ,

and

Dbii

=

n j=1

Wbij

.

E

=

[

0 1

1 0

]

is

an

anti-diagonal

matrix

that

serves

as

a

col-

1http://mpqa.cs.pitt.edu/corpora/ 2http://www.keenage.com/

umn permutation function to reverse the columns of X, and D = Da+Db. The underlying intuition is that the sentiment vectors of two pairs should be similar if they are frequently linked by "and" and opposite if by "but", or a penalty would be introduced to the loss function.
4) Sentential Sentiment Consistency captures the sentiment consistency in sentences [3], i.e., similar opinion orientations are usually expressed in consecutive sentences.
To formalize the heuristic, a sentential similarity matrix Ws  Rn×n is introduced, which leverages the sentential distance between F-O pairs in corpus to estimate their sentential similarities. For example, consider two pairs i and j, if they co-occur in the same piece of review in the corpus, then we calculate their sentential similarity in this review, and the final similarity between i and j is the average of all their intra-review similarities. More formally, suppose pair i and pair j co-occur in the same review for Nij times, and the k-th co-occurrence happens in review tik , then Wsij and Wsji are defined as:

 0, 

if

Nij

=0

or

Waij

=0

or

Wbij

=0

Wsij = Wsji =

Nij 1

 

Nij

k=1

1-

dist(i,j) length(rik )

, else

where the length of a review length(rik ) is the number of words (punctuations excluded) in the review, and the dis-

tance dist(i, j) of pair i and j in the review is the number of

words between the two feature words of the pair. The corre-

sponding objective function is R4 = tr(XT DsX-XT WsX),

where Ds is also a diagonal matrix, and Dsii =

n j=1

Wsij .

2.3 The Unified Model for Polarity Labeling

With the above constraints from different information sources and aspects, we adopt the following objective function to learn the contextual sentiment lexicon X:

min R = 1

AX - X~

2 F

+ 2

G(X - X0)

2 F

X0

+ 3 tr(XT DX - XT WaX - XT WbXE) (1)

+ 4 tr(XT DsX - XT WsX)

where 1, 2, 3 and 4 are positive weighing parameters that control the contributions of each information source in
the learning process. An important property of the objec-
tive function (1) is its convexity, which makes it possible to search for the global optimal solution X. We give the updating rule for learning X directly here, as shown in (2).
The proof of the updating rule as well as its convergence is
similar to the KKT condition approach in [2].

Xij  Xij

[1AT X~ + 2GX0 + 3WaX + 3WbXE + 4WsX]ij [1AT AX + 2GX + 3DX + 4DsX]ij (2)

In this work, we choose the function s(xi) = xi1 - xi2 to

calculate the final sentiment polarity. Pair i is labeled as

positive if s(xi)  0, and negative if s(xi) < 0.

3. EXPERIMENTS
We use the MP3 player reviews crawled from Amazon for the experiment on English, which is publicly available3. For the Chinese language, we use the restaurant reviews crawled from Dianping4, which is a famous restaurant rating website
3http://sifaka.cs.uiuc.edu/~wang296/Data/ 4http://www.dianping.com/

1028

Percentage  % Percentage  of  4  and  5  stars  

in China. Each of the reviews of the two datasets consists of a piece of review text and an overall numerical rating raging from 1 to 5 stars. Some statistical information about these two datasets is shown in Table 1.

Table 1: Statistics of the two datasets #Users #Items #Reviews

MP3 Player 26,113

796

Restaurant 11,857 89,462

55,740 510,551

An important property of our restaurant review dataset is that, each review is accompanied with three sub-aspect ratings except for the overall rating. They are users' ratings made on the flavour, environment and service of restaurants, respectively, which makes it possible for us to conduct much detailed user rating analysis on this dataset. The range of the sub-aspect ratings are also from 1 to 5.

3.1 User Rating Analysis
The ratings on three sub-aspects allow us to investigate a user's "true" feelings on more specific aspects of a restaurant beyond the overall rating. For the overall rating and each sub-aspect rating, we calculate the percentage that each of the 5 star ratings takes in the total number of ratings, shown in Figure 2. The x-axis represents 1 star through 5 stars, and the y-axis is the percentage of each star rating.

50%  

40%  

30%  

20%  

10%  

0%  
Overall   Flavor   Environ.   Service  

1   1.24%   2.15%   2.56%   3.36%  

2   3.89%   25.84%   40.51%   38.21%  

3   37.06%   46.70%   40.91%   41.99%  

4   49.23%   20.77%   13.05%   13.05%  

5   8.58%   4.53%   2.97%   3.39%  

Figure 2: Percentage of each star of overall rating, flavour, environment and service.

We see that user ratings tend to center around 4 stars on overall rating, while they tend to center around 23 stars on the sub-aspect ratings. This implies that the overall rating might not serve as a real reflection of the users' feelings, and users tend to "tell the truth" in much detailed sub-aspects. In order to examine the statistical significance, we calculate the average rating µ and coefficient of variation cv = /µ for the overall rating and the three sub-aspect ratings, where  is the standard deviation. Table 2 shows the results. We see that users tend to give higher scores on overall rating, and the scores on overall rating are more concentrated.
More intuitionally, we conduct per user analysis. For each user and each kind of rating (overall, flavour, environment and service), we calculate the percentage of 4 or 5 stars that the user made. Then we sort these percentages of the users in descending order, which is shown in Figure 3.
It is clear that user rating behaviours on overall and subaspect ratings are different. More than a half of the users

Table 2: Average ratings and coefficient of variation Overall Flavour Environment Service

µ 3.6432 3.1547 cv 0.1977 0.2522

2.8934 2.8510 0.2697 0.2816

100%  
Overall  

80%  

Flavor  

Service  

Environ.  
60%  

40%  

20%  

0%  
Sorted  UserIDs  
Figure 3: Percentage of  4 stars made by each user on each kind of rating, sorted in descending order of percentages.
made 50% or more 4+ ratings in terms of overall rating, while less than 5% users did so on sub-aspect ratings.
This analysis partly shows that it might not be appropriate to use overall ratings as groundtruth to label the sentiment orientations of review texts, as users tend to act differently when making overall ratings and expressing their true feelings on detailed product features/aspects.
3.2 Phrase-Level Polarity Labeling
We choose the frequently used measures precision, recall and F-measure to evaluate the performance of polarity labeling, and experiment with the following methods:
· General: Predict by querying the polarity of the opinion word in general sentiment opinion word sets. Also, we use MPQA for English and HowNet for Chinese.
· Optimize: The optimization approach in [5], which reduces the problem of polarity labeling to the problem of constrained linear programming.
· Overall: Use our framework except that the reviewlevel sentiment orientation is determined using the corresponding overall rating.
· Subaspect: Use our framework except that sentiment orientations of reviews are determined by averaging the corresponding sub-aspect ratings.
· Boost: Use our complete framework, where unsupervised sentiment classification is conducted on reviews to boost phrase-level sentiment polarity labeling.
We use 1 = 2 = 3 = 4 = 1 in this experiment, and the results on the two datasets are shown in Table 3. We did not perform the "Subaspect" method on mp3 player reviews as the sub-aspect ratings are absent.
We see that labeling the polarities by querying the general opinion word sets gives the best precision on both of the two datasets. However, the recall of this method is rather low. This implies that there are many "contextual dependent" opinion words which are absent from these word sets.
The "Optimize" method and our "Overall" method are similar in that both of them leverage overall numerical ratings as the groundtruth of review-level sentiment orientations. Though the Optimize method achieves slightly better recall, their overall performance are comparable. Further more, by taking advantage of the sub-aspect ratings in the "Subaspect" method, both precision and recall are improved from "Optimize" and "Overall" methods, which implies that the detailed sub-aspect ratings could be more reliable.
Finally, our "Boost" method achieves the best performance in terms of recall and F-measure, on both of the two datasets.

1029

Table 3: Performance of polarity labeling Precision Recall F-measure

MP3 Player Data General Optimize Overall Boost

0.9238 0.8269 0.8288 0.8504

0.4201 0.7626 0.7525 0.7683

0.5776 0.7934 0.7888 0.8073

Restaurant Review General Optimize Overall Subaspect Boost

0.9017 0.8405 0.8473 0.8675 0.8879

0.3571 0.7760 0.7468 0.7561 0.7818

0.5115 0.8069 0.7938 0.8079 0.8315

Besides, it also achieves the best precision without regard to the "General" method. This further verifies the effect of leveraging review-level sentiment classification in boosting the process of phrase-level polarity labeling.

3.3 Parameter Analysis
In this subsection, we attempt to study the effect of different constraints in our framework by analyzing the four main parameters 1  4 in objective function (1).
We first conduct "Knock Out One Term" experiment on these parameters, to see whether all these constraints contribute to the performance of phrase-level polarity labeling. We set one of the four parameters to 0 at a time, and evaluate the F-measure. The results are shown in Table 4.
The experimental result shows that knocking out any of the four parameters decreases the performance of polarity labeling. Besides, removing the constraint on review-level sentiment orientation (1) or general sentiment lexicon (2) decreases the performance to a great extent, which implies that these two information sources are of great importance in constructing the sentiment lexicon.
We further investigate the effect of different constraints by fixing three parameters to 1 and weighing the remaining parameter. The results on restaurant are shown in Figure 4, and the observations on mp3 player dataset are similar.

0.9  

0.85  

F--Measure  

0.8  

0.75  

1  

2   0.7  
3  

0.65  

4  

0.6  

0   0.25   0.5  

1  

2  

4  

8  

Parameter  values    

Figure 4: Tune one of the four parameters.

The experimental result shows that giving more weights to the constraints of review-level sentiment orientation and general sentiment lexicon could further improve the performance, which means that these two information sources might be more reliable. However, weighting the constraint on sentential sentiment consistency too much would decrease the performance, this implies that noise could be introduced by this heuristic and it is not as reliable as the linguistic heuristic of "and" and "but".

Table 4: F-measure by knocking out one constraint

1 2 3 4 MP3 Player Restaurant

Default 1 1 1 1

0.8073

0.8315

Knock 0 1 1 1

out

1011

one

1101

term

1110

0.6783 0.6332 0.7461 0.7756

0.6476 0.6728 0.7352 0.7504

We tuned the parameters carefully to get the optimal performance. Finally, the optimal result on mp3 player dataset was achieved when using the parameters (4, 2, 1, 0.25), with an F-measure of 0.8237, and on restaurant review dataset (3, 2, 2, 0.5) is used, which gives the F-measure of 0.8584.

4. CONCLUSIONS AND FUTURE WORK
In this paper, we investigated the inconsistency between overall numerical ratings and the sentiment orientations of textual user reviews in real-world datasets, which is an unvalidated assumption but frequently used in previous work. We propose to leverage review-level sentiment classification techniques to boost the performance of phase-level sentiment polarity labeling. Besides, we formalize the phraselevel sentiment polarity labeling problem in a simple convex optimization framework, and designed iterative updating algorithms for model learning. Experimental results on both English and Chinese datasets show that our framework helps to improve the performance in contextual sentiment lexicon construction tasks.
This work is a first step towards bridging the gap between phrase-level and sentence/review-level sentiment analysis. Except for the four kinds of heuristics investigated in this paper, the framework can also integrate various other information sources. Besides, review-level analysis could also be promising to help extract feature or opinion words in phrase-level analysis, except for the polarity labeling task in this work. Additional insights about the bidirectional relationship of phrase- and review-level analysis may also yield more effective heuristics and algorithms for both tasks.

5. REFERENCES
[1] M. Hu and B. Liu. Mining and Summarizing Customer Reviews. KDD, pages 168­177, 2004.
[2] X. Hu, J. Tang, H. Gao, and H. Liu. Unsupervised Sentiment Analysis with Emotional Signals. WWW, 2013.
[3] H. Kanayama and T. Nasukawa. Fully Automatic Lexicon Expansion for Domain-oriented Sentiment Analysis. EMNLP, pages 355­363, 2006.
[4] B. Liu and L. Zhang. A Survey of Opinion Mining and Sentiment Analysis. Jour. Mining Text Data, 2012.
[5] Y. Lu, M. Castellanos, U. Dayal, and C. Zhai. Automatic Construction of a Context-Aware Sentiment Lexicon: An Optimization Approach. WWW, 2011.
[6] L. Qiu, W. Zhang, C. Hu, and K. Zhao. Selc: A self supervised model for sentiment classification. CIKM, 2009.
[7] M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and M. Stede. Lexicon-Based Methods for Sentiment Analysis. Computational Linguastics, 37(2), 2011.
[8] Y. Tan, Y. Zhang, M. Zhang, Y. Liu, and S. Ma. A Unified Framework for Emotional Elements Extraction based on Finite State Matching Machine. NLPCC, 400:60­71, 2013.
[9] T. Zagibalov and J. Carroll. Automatic Seed Word Selection for Unsupervised Sentiment Classification of Chinese Text. Coling, pages 1073­1080, 2008.
[10] Y. Zhang, G. Lai, M. Zhang, Y. Zhang, Y. Liu, and S. Ma. Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis. SIGIR, 2014.

1030

