Detection of Abnormal Profiles on Group Attacks in Recommender Systems

Wei Zhou
Chongqing University Chongqing, China
zhouwei@cqu.edu.cn

Yun Sing Koh
University of Auckland New Zealand
ykoh@cs.auckland.ac.nz

Junhao Wen
Chongqing University Chongqing, China
jhwen@cqu.edu.cn

Shafiq Burki

Gillian Dobbie

University of Auckland

University of Auckland

New Zealand

New Zealand

sala038@aucklanduni.ac.nz gill@cs.auckland.ac.nz

ABSTRACT
Recommender systems using Collaborative Filtering techniques are capable of make personalized predictions. However, these systems are highly vulnerable to profile injection attacks. Group attacks are attacks that target a group of items instead of one, and there are common attributes among these items. Such profiles will have a good probability of being similar to a large number of user profiles, making them hard to detect. We propose a novel technique for identifying group attack profiles which uses an improved metric based on Degree of Similarity with Top Neighbors (DegSim) and Rating Deviation from Mean Agreement (RDMA). We also extend our work with a detailed analysis of target item rating patterns. Experiments show that the combined methods can improve detection rates in user-based recommender systems.
Categories and Subject Descriptors
H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval; K.4 [Computers and Society]: K.4.4 Electronic Commerce--Security
Keywords
Recommender Systems, Group Attack, Attack Detection
1. INTRODUCTION
Recently, recommender systems have become an effective tool for information retrieval, and has played an important role in many popular web services, such as Amazon, YouTube, Netflix, Yahoo! etc. However, due to the open nature of CF (Collaborative Filtering) recommender systems, they suffer significant vulnerabilities from being attacked by
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609483.

malicious raters that inject profiles consisting of biased ratings. These attacks are carried out in order to influence the system's behavior and have been termed "shilling" or "profile injection" attacks. Shilling attacks can be divided into push and nuke attacks to make a target item more or less likely to be recommended respectively. Since attackers try to make their profiles look similar to genuine ones, it is a difficult task to correctly identify shilling attacks. Attacks can cause different losses to unprotected systems depending on the purpose of the attackers. They can push or nuke some specified items by injecting some profiles into the system; in some ways, they can ruin the system by injecting a large number of profiles, which lead to a breakdown of the system. Lam [1] analysed the influence of different types of attacks on prediction shift in recommender systems.
Many attack profiles are based on random and average attack models which were introduced originally in Lam and Reidl [1]. Both of these attack models involve the generation of attack profiles using randomly assigned ratings to the filler items in the profiles. In a random attack the assigned ratings are based on the overall distribution of user ratings in the database, while in an average attack the rating for each filler item is computed based on its average rating for all users. In addition to these standard attack models, several more sophisticated models have been studied. In this work we have evaluated group attack models, including segment and bandwagon attack models [2]. There are four parts in a group attack profile, including target item, selected set, filler set and unrated set. Selected items in malicious profiles are a set of items that make the profile look normal and makes them harder to detect. There are common attributes in a selected set, for example, items that are most rated, those with common topics, those with special interests, and so on. A target item is an item that attackers want to promote. Since items in a select set are rated with the same score as the target item, we see target item as an element in the select set. Unrated items are items that are not rated. The more attack profiles that are statistically identical to genuine profiles, the harder they are to detect. We generated the filler ratings in the same way as the average attack model in this paper.
The main contribution of this paper is an unsupervised approach to attack detection that does not rely on profile classification, called Target Item Analysis (DeR-TIA). The

955

other contribution of this research is that we propose a novel metric DegSim to detect group attacks. The rest of the paper is organized as follows. In the next section, we examine previous work in the area of attack detection in recommender systems. Section 3 introduces the background work on which our approach is based. Section 4 introduces the detailed formulation of our approach. Our experimental results are presented in Section 5. Finally we summarize our research contributions in Section 6.

2. RELATED WORK
The word "shilling" was first termed in 2004 [1]. There have been some recent research efforts aimed at detecting and reducing the effects of profile injection attacks [3, 4]. These attacks consist of a set of attack profiles, each containing biased rating data associated with a fictitious user identity. Since "shilling" profiles look similar to authentic profiles, it is difficult to identify them. A lot of research has been undertaken to employ supervised learning for shilling attack detection such as [5]. Three classification algorithms [6], k NN-based, C4.5-based and SVM -based, are used to improve the robustness of the recommender system. These supervised algorithms need a large number of labeled users to enhance the accuracy. Classification-based methods require balanced numbers of attack and normal profiles to train the classifiers. Work by Zhang et al. [7] has shown singular value decomposition (SVD) techniques can also help reduce the effects of attacks. It is obvious that unsupervised learning based detectors do not make use of the labeled data which indeed exists and is significant for detection. An unsupervised shilling attack detection algorithm using principal component analysis (PCA) is proposed in [8]. Hurley et al. [9] utilize Neyman-Pearson theory to construct both supervised and unsupervised detectors. Statistical detection techniques [10] are also used to detect shilling attacks.

3. BACKGROUND
There are item-based CF systems and user-based CF systems, in this paper, we consider only user-based CF algorithms. A kNN -based algorithm is the most popular CF algorithm. Rating data is represented as a user × item Matrix R, with R(u, i) representing the rating given by user u for item i, if there exists a rating on item i, or otherwise there will be a null value. Similarity between users is then computed using the Pearson correlation:

Wuv =

iI (Rui - Ru)(Rvi - Rv)

(1)

iI (Rui - Ru)2(Rvi - Rv)2

where I is the set of items that users u and v both rated, Rui is the rating user u gave to item i, and Ru is the average rating of user u.
It is impractical to apply a supervised learning approach to the raw data because of its sparsity. As a result, some researchers focused on profile analytics data and attribute reduction techniques to lower the dimensionality of the data. In [11] some generic detection attributes and model-specific detection attributes are proposed. In this paper, we use two generic attributes to detect group shilling attacks.
As researchers have hypothesized attack profiles are likely to have a higher similarity with their top 25 closest neighbors than real users [11]. The DegSim attribute is based

on the average Pearson Correlation of the profile's k nearest neighbours and is calculated in Equation 2:

DegSim =

k u=1

Wuv

(2)

k

where Wuv is the Pearson correlation between user u and user v, and k is the number of neighbours.
RDMA measures the deviation of agreement from other users on a set of target items, combined with the inverse rating frequency for these items. RDMA can be calculated in the following way:

Nu |ru,i-ri|

RDM Au =

i=0 N Ri
Nu

(3)

where Nu is the number of items user u rated, ru,i is the rating given by user u to item i, N Ri is the overall number of ratings in the system given to item i.

4. OUR APPROACH
There are different metrics that have been proposed to measure the features of profiles. In [12] a number of algorithm independent qualitative factors are used in analyzing the influence of a user on a recommender system. Chirita [11] proposed several metrics for analyzing rating patterns of malicious users and evaluate their potential for detection. Considering the fact that attackers should have a high influence in the system in order to effectively promote the target items, we use the metrics RDMA and DegSim to reveal distinctive features in the rating patterns. Overall attackers should have a high influence in the system in order to promote the target items effectively. There are three different features in attack profiles, which enable us to differentiate between genuine and attack profiles. Firstly in group attack profiles, filler items are randomly chosen thus the similarity based on these filler items between attack and genuine profiles should be lower. Secondly, since shilling attacks usually try to push items with low ratings, the users mounting such an attack will assign a rating that deviates from the average rating value assigned by the genuine profiles. Last but not least, all target items are assigned a highest or lowest value, the count number of this value should be greater than other values among items. Attackers should therefore have relatively high values for RDMA, as well as low values in DegSim. Based on these reasons, RDMA and DegSim are used to reveal these distinctive features in the rating patterns. This metric are suitable to detect random and average attacks, but is ineffective in group attacks because the select set in attack profiles can make them more similar with the genuine profiles. So we propose a new metric called DegSim that calculates the similarity of ratings independently. DegSim can be calculated using Equation 4:

DegSim = DegSimr - DegSimr

(4)

rR

R is the rating scale of the rating database and r is a rating score. DegSimr is the mean value of DegSimr. When calculating DegSimr, all ratings not equal to r are replaced with 0. DegSimr is then calculated with Equation 2 using the new transform rating matrix. There maybe no difference between attack profiles and genuine profiles in DegSim, but there would be differences in DegSim . Using this method DegSim of attack profiles will be relatively greater than

956

genuine profiles, as long as there are differences in each rating scale.
There are two phases in DeR-TIA. In the first phase, we extract profile attributes using Equation (3) and Equation (4); use k -means(with k equals to 2) to split each group of attributes; choose the two greater parts, and we consider the intersection between the two parts as the output of Phase 1. From this process, we get a pool of suspicious profiles. The pseudocode is in Algorithm 1.
Algorithm 1 DeR-TIA Phase 1: Find suspicious profiles
Input: Rating Matrix M; Output: Suspected profiles, SU SRD; 1: RDM Au  Calculate RDM A(M ); 2: DegSim u  Calculate DegSim (M ); 3: {R1, R2}  kmeans(RDM Au); 4: {D1, D2}  kmeans(DegSimu); 5: D = max(D1,D2), R = max(R1,R2); 6: SU SRD  {SU SRD |D  R }; 7: return suspected profiles SU SRD.
In the second phase, genuine profiles are filtered out in SU SRD using target item analysis. An item is considered a target item, when it is rated proportionally higher than the rest. For example, if 80% of the profiles in the suspicious pool rated an item with the highest possible rating, we consider that item as a target item. We then move all the profiles that rated the suspected target item with the highest (or lowest) rating into the DetectedResult Set. These profiles are considered to be attackers. The intuition behind this is that we believe the attackers will target one specific item many times if they want to push the item to the recommendation list. To detect the proportion, we use an absolute count threshold . Attack profiles should occur at least 20 times for a considerable prediction shift [4]. On the other side, there will be more false positives if  is too small. Considering these factors, we don't consider attacks that number less than 6 and set  equals 6. If the count (highest rating r) for an item is greater than 6, then itemi is regarded as a target item. Profiles that rated itemi with the highest rating r are considered as attackers, and moved to the DetectedResult pool. The pseudocode is in Algorithm 2.
Algorithm 2 DeR-TIA Phase 2, Filter out genuine profiles.
Input: The set of suspected profiles SU SRD; highest rating r; item set I;
Output: Final detect result set DetectedResult; 1: DetectedResult = ; 2: i  I, counti  number of ratings in itemi equal r; 3: while max(count) >  do 4: itemt  {itemi |counti = max(count) }; 5: p  SU SRD, P  p rate itemt with r; 6: DetectedResult  P  DetectedResult; 7: SU SRD  SU SRD - P ; 8: end while 9: return DetectedResult.
5. EXPERIMENTS
In this section, we conduct extensive experiments on different datasets and a benchmark detection method.

Table 1: Datasets used in the experiments

Dataset

ML100K ML1M

Netflix Eachmovie

#Users

943

6,040

4,334

2,000

#Movies

1,682

3,952

3,558

1,623

#Ratings

80,000

1,000,209 552,054 137,425

Sparseness 94.96% 95.81%

94.42% 95.77%

Rating scale 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 6

5.1 Experimental setup

We now describe datasets we have used in the experiments, and the metrics we have used to evaluate attributes, followed by experimental results. We use four publiclyavailable datasets, including MovieLens 100K Dataset, MovieLens 1M Dataset, subset of Netflix Dataset and subset of Eachmovie Dataset. Information of the four datasets is as Table 1.
To evaluate the performance of our technique we used two metrics: Detection Rate and False Positive rate, which are used in similar experiments [13]. Detection rate is defined as the number of detected attacks divided by the number of attacks.

Detection

Rate

=

#Detection #Attacks

(5)

False positive rate is the number of genuine profiles that are predicted as attacks divided by the number of genuine profiles.

F alse P ositive Rate = #F alse P ositives

(6)

#Genuine P rof iles

5.2 Experiment results
Three tests were done, all of them were push attacks. In the first test, we evaluate our technique in four datasets. Attack profiles are generated as follow: in select set, 1% of the most rated items in the datasets are chosen, these items are rated as maximum rating; the ratings for filler items are distributed around the average rating for each item.

Figure 1: Detection rate and false positive rate in different datasets when the attack size is 5% and filler size varies.
Figure 1 shows the detection and false positive rates of the proposed method while facing group attacks on different datasets. Figure 1(A) is the detection rate when the

957

Figure 2: Detection rate of single target attack when attack size and filler size varies.
Figure 3: Detection rate of group attack when the attack size and filler size varies.
attack size is 5% and filler size varies. Figure 1(B) shows the false positive rate of the detection. We find that the detection rates increase very fast along with an increase in filler size. The detection rates reach close to 100% when filler size reaches 4%. The false positive rates, on the other hand, consistently stay below 0.5% when the filler size is greater than 2%, regardless of attack size.
In the second test, we compare our method with the stateof-art unsupervised -based method [13] using ML100k Dataset when the select set is zero, that is, there is only one target item in an attack profile, and the filler size is 5% and the attack size varies from 1%, 3%, 5%, 7% and 9%. Figure 2 shows the detection rates of -based method (A) and our method (B) when facing single target push attack. In our method (B), detection rate reaches almost 100% when the filler size is greater than 4%. The false positive rates are relatively low.
In the third test, we compare -based method and our method using ML100k Dataset when the select set varies from 2 to 10. Figure 3 shows the detection rates of -based method (A) and our method (B) when facing group Push

attacks. In our method, the detection rate reaches almost 100%. The false positive rates are below 0.5%, which is low.
6. CONCLUSIONS
In this paper, we propose an unsupervised group detection method De-TIA. We improved a metric of profiles called DegSim , which measures the difference in similarity between genuine profiles and attack profiles better. Tests show that a detection method using the new metric can improve the performance of detection. As for future work, we will further study attack detection methods on more complicated attack models using the new metric DegSim .
7. ACKNOWLEDGMENTS
This research work was funded by the National Natural Science Foundation of China under Grant No. 61379158, the Ph.D. Programs Foundation of Ministry of Education of China No. 20120191110028.
8. REFERENCES [1] Shyong K Lam and John Riedl. Shilling recommender systems for fun and profit. In Proceedings of the 13th international conference on World Wide Web, pages 393­402. ACM, 2004. [2] Chad Williams and Bamshad Mobasher. Profile injection attack detection for securing collaborative recommender systems. Technical report, Technical report, DePaul University, 2006. [3] Bhaskar Mehta, Thomas Hofmann, and Wolfgang Nejdl. Robust collaborative filtering. In Proceedings of the 2007 ACM conference on Recommender systems, pages 49­56. ACM, 2007. [4] Bhaskar Mehta and Wolfgang Nejdl. Attack resistant collaborative filtering. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 75­82. ACM, 2008. [5] Robin Burke, Bamshad Mobasher, Chad Williams, and Runa Bhaumik. Classification features for attack detection in collaborative recommender systems. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 542­547. ACM, 2006. [6] Chad A Williams, Bamshad Mobasher, and Robin Burke. Defending recommender systems: detection of profile injection attacks. Service Oriented Computing and Applications, 1(3):157­170, 2007. [7] Sheng Zhang, Yi Ouyang, James Ford, and Fillia Makedon. Analysis of a low-dimensional linear model under recommendation attacks. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 517­524. ACM, 2006. [8] Bhaskar Mehta and Wolfgang Nejdl. Unsupervised strategies for shilling detection and robust collaborative filtering. User Modeling and User-Adapted Interaction, 19(1-2):65­97, 2009. [9] Neil Hurley, Zunping Cheng, and Mi Zhang. Statistical attack detection. In Proceedings of the third ACM conference on Recommender systems, pages 149­156. ACM, 2009. [10] Runa Bhaumik, Chad Williams, Bamshad Mobasher, and
Robin Burke. Securing collaborative filtering against malicious attacks through anomaly detection. In Proceedings of the 4th workshop on intelligent techniques for web personalization (ITWP'06), 2006. [11] Paul-Alexandru Chirita, Wolfgang Nejdl, and Cristian Zamfir. Preventing shilling attacks in online recommender systems. In Proceedings of the 7th annual ACM international workshop on Web information and data management, pages 67­74. ACM, 2005. [12] George Karypis Al Mamunur Rashid and John Riedl. Influence in ratings-based recommender systems: An algorithm-independent approach. In Proc. of the SIAM International Conference on Data Mining. SIAM, 2005. [13] Chen-Yao Chung, Ping-Yu Hsu, and Shih-Hsiang Huang. p: A novel approach to filter out malicious rating profiles from recommender systems. Decision Support Systems, pages 314­325, 2013.

958

