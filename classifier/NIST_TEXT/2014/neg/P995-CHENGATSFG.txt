Group Latent Factor Model for Recommendation with Multiple User Behaviors

Jian Cheng, Ting Yuan, Jinqiao Wang, Hanqing Lu
National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences
Beijing, China
{jcheng, tyuan, jqwang, luhq}@nlpr.ia.ac.cn

ABSTRACT
Recently, some recommendation methods try to relieve the data sparsity problem of Collaborative Filtering by exploiting data from users' multiple types of behaviors. However, most of the exist methods mainly consider to model the correlation between different behaviors and ignore the heterogeneity of them, which may make improper information transferred and harm the recommendation results. To address this problem, we propose a novel recommendation model, named Group Latent Factor Model (GLFM), which attempts to learn a factorization of latent factor space into subspaces that are shared across multiple behaviors and subspaces that are specific to each type of behaviors. Thus, the correlation and heterogeneity of multiple behaviors can be modeled by these shared and specific latent factors. Experiments on the real-world dataset demonstrate that our model can integrate users' multiple types of behaviors into recommendation better.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information filtering
Keywords
Recommender Systems; Matrix Factorization
1. INTRODUCTION
In the past decade, Collaborative Filtering (CF) has become one of the most popular techniques for recommender systems, which makes predictions by mining users' historical behaviors on items. In particular, Matrix Factorization (MF) models [6, 2] have become dominant in current CF methods. MF methods learn low-dimensional latent factor vectors of users and items to represent their characteristics, and predictions are made by the inner product of them. Traditionally, CF methods are designed to deal with single type of user behavior at a time. However, the behavioral data
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.

is typically very sparse, that is, most users have interacted with a very few items. It is indeed hard for CF methods including MF to make accurate recommendations with such insufficient data.
To address the data sparsity problems, some works have been proposed to exploit users' multiple types of behaviors for recommendation [1, 7, 4]. As we know, with the prevalence of massive web applications, users often have various types of behaviors on the web, varying from rating movies, listening music, to making friends. Considering simultaneously multiple behaviors of a user offers us more information to model the user's taste better. The most widely used method addressing this issue is Collective Matrix Factorization (CMF) [7], which decomposes the rating matrices for different types of user behaviors jointly by sharing the same user latent factor matrix across different behaviors. That is, in CMF a user is characterized by the same latent factor vector across different behaviors. Through these shared user latent factors, CMF aims to transfer information between different behaviors to improve the recommendation results. Inspired by the idea of CMF, some following works [5, 8, 3] have demonstrated that better predictions can be achieved by sharing the same user latent factors across multiple types of behaviors.
However, the CMF ignores the heterogeneity of different behaviors. When characterizing a user by the same latent factor vector across different behaviors, the underlying assumption is that user's taste should be the same when she/he conducts different behaviors. This is too strict to be realistic. For example, a user's taste on music may be quite different from her/his taste on movie. When users conduct different types of behaviors, there should exist some correlations between behaviors as well as some specific characteristics for each type of behaviors. Nevertheless, traditional methods like CMF mainly consider to model the correlation of different behaviors but neglect the heterogeneity of them, which could not effectively model the characteristics of a user on various behaviors and may make improper information transferred to harm the recommendation results.
In this paper, we propose to integrate multiple types of user behaviors into recommendation effectively by modeling both the correlation and heterogeneity of them. Particularly, we present a novel recommendation model, named Group Latent Factor Model (GLFM), which attempts to learn a factorization of the latent factor space into subspaces that are shared across multiple behaviors and subspaces that are specific to each type of behaviors. In GLFM, when user conducts different types of behaviors, she/he is character-

995

ized by different latent factor vectors, among which, some dimensions are shared by multiple types of behaviors while the others are specific for certain behavior. Thus, the correlation and heterogeneity of multiple behaviors can be modeled by these shared and specific latent factors. Experiments show that our method can achieve better recommendation results than other state-of-the-art methods.
2. THE PROPOSED METHOD
2.1 Problem Statement
Suppose that we have a set of n users U = {u1, · · · , un} and their B types of behavior records. Each type of user behavior demonstrating her/his opinions on a kind of items can be regarded as ratings (binary or real values), thus we have B rating matrices for different behaviors, denoted as {R1, · · · , RB}, where Rb = [Ribj ]n×mb denotes the rating matrix for the b-th type of behavior. Ribj denotes the rating of ui on item vjb, vjb denotes the j-th item in the b-th type of behavior, mb is the number of items belong to the bth type. Our goal is to predict the missing values in each behavior matrix Rb (b = 1, · · · , B) by effectively exploiting the observed data from users' multiple types of behaviors.
2.2 Group Latent Factor Model
We formulate our problem on the basis of Matrix Factorization [6], which learns latent factors of the users and the items to characterize them. In our cases, for each user we have her/his multiple types of behavior records, leading to multiple rating matrices with the same user dimension. To correctly account for the correlation and heterogeneity of different behaviors, we cast the problem as finding a factorization of the latent factor space into subspaces that are shared across multiple behaviors and subspaces that are specific to each type of behaviors.
Let U0  RKs×n denote the user latent factor matrix shared among different behaviors, with each column Ui0 representing the shared latent factor vector for user ui. Ks is the number of the shared factors. For the b-th type of behaviors, let Ub  RKb×n denote the behavior-specific user latent factor matrix, with each column Uib representing the behavior-specific latent factor vector for user ui. Kb is the number of the specific factors for the b-th type of behaviors. As shown in Figure 1, when user ui conducts the b-th behaviors, she/he is modeled by U~ib = [Ui0; Uib]  R(Ks+Kb)×1, which consists of both the shared and the behavior-specific latent factors. We denote U~ b  R(Ks+Kb)×n to be the b-th user latent factor matrix with each column as U~ib, thus we have U~ b = [U0; Ub].
For items belong to the b-th type, we let Vb  R(Ks+Kb)×mb denote the item latent factor matrix, with each column Vjb representing the latent factor vector for item vjb. We denote Vjb = [Djb; Pjb], where Djb  RKs×1 corresponds to the shared latent factor space of Ui0 and Pjb  RKb×1 corresponds to the behavior-specific latent factor space of Uib. Thus, the ratings of user ui on item vjb can be predicted as:
R^ibj = (U~ib)T Vjb = [Ui0; Uib]T Vjb = (Ui0)T Djb + (Uib)T Pjb (1)
Thus, given users' B types of behavior records {R1, · · · , RB}, we learn {U~ b}Bb=1 and {Vb}Bb=1 by minimizing the following objective function:

Behavior 1
user (Ui1)T (Ui0)T (Ui1)T

Behavior 2 (Ui2)T (Ui0)T (Ui2)T

Behavior 3 (Ui3)T (Ui0)T (Ui3)T

item (Vj1)T (D1j )T (Pj1)T

(Vj2)T (D2j )T (Pj2)T

(Vj3)T (D3j )T (Pj3)T

Figure 1: In GLFM, user ui is modeled by U~ib = [Ui0; Uib] when she/he conducts the b-th behavior, where Ui0 is shared across multiple behaviors and Uib is specific for the b-th behavior. vjb, the j-th item belongs to the b-th type, is modeled by Vjb = [Djb; Pjb], where Djb corresponds to the latent factor space of Ui0 and Pjb corresponds to that of Uib.

L({U~ b}Bb=1, {Vb}Bb=1)

(

)

 B n  mb

=

Iibj (Ribj - (U~ib)T Vjb)2 + (U~ b2F + Vb2F )

b=1 i=1 j=1

 B n =

 mb Iibj

( Ribj

-

(Ui0)T Djb

-

(Uib)T Pjb)2

b=1 i=1 j=1

n

 B n

 B  mb

+ (B Ui02F +

Uib2F +

Vjb2F )

i=1

b=1 i=1

b=1 j=1

(2)

In Eq.(2), the first term measures the quality of the approx-

imation of the predicted ratings to the observed ratings in multiple types of user behaviors by squared error, where Iibj is the indicator function which is equal to 1 if the user ui rated the item vjb and is 0 otherwise. In the second term,  · F is the Frobenius regularization norm which is used to
avoid over-fitting. Parameter  controls the strength of the

regularization term.

Notice that, traditional MF can be viewed as a special

case of our model by restricting the number of shared latent

factors Ks = 0; CMF can be viewed as a special case of our model by restricting the number of behavior-specific latent

factors Kb = 0.

2.3 Optimization Algorithm
Eq.(2) is convex with respect to one of the variables U0, U1, · · · , UB, V1, · · · , VB when the others are fixed. Thus,
we apply an alternating optimization to solve the problem, which update U0, {Ub}Bb=1, and {Vb}Bb=1 iteratively and alternatingly.
Optimizing U0, when {Ub}Bb=1 and {Vb}Bb=1 fixed: U0 can be obtained by solving following optimization problem,

min L(U0)
U0

=

 B  n  mb
b=1 i=1 j=1

Iibj

( Ribj

-

(Ui0 )T

Djb

-

(Uib )T

Pjb )2

(3)

 n

+ B Ui02F

i=1

solving

 L(U0 )  Ui0

= 0,

we

have:

  B  mb

-1

Ui0 = BE0 +

Iibj Djb(Djb)T 

b=1 j=1





(4)

 B  mb

×

Iibj (Ribj - (Uib)T Pjb)Djb

b=1 j=1

where E0 is a Ks × Ks identity matrix.

996

Algorithm 1 Optimization Algorithm for GLFM

Require: {Rb}Bb=1, Parameters Ks, Kb,  Ensure: U0, {Ub}Bb=1 and {Vb}Bb=1

1: Initialize U0, {Ub}Bb=1 and {Vb}Bb=1; 2: Repeat

3: Update Ui0, 1  i  n with Eq. (4) 4: for b = 1 to B do

5:

Update Uib, 1  i  n with Eq. (6)

6: end for

7: for b = 1 to B do

8:

Update Vjb, 1  j  mb with Eq. (8);

9: end for

10: Until convergence

11: Return U0, {Ub}Bb=1 and {Vb}Bb=1

out users who have rated less than 10 books, or 10 movie, or 10 music, and then removed users without social relationships with others. Retrieving all items rated by the selected users, we have a dataset containing 5,916 users with their ratings on 14,155 books, 15,492 music and 7,845 movie, as well as their social relations between each other. The ratings are real values in the range [1,5], while the social relations are binary, indicating whether or not a social relation exists. The detailed statistics are showed in Table 1.

Table 1: Statistics of the Datasets Behavior Type #Items Sparsity #Ratings per User

Book

14,155 99.85%

22

Music

15,492 99.75%

38

Movie

7,845 98.87%

88

Social Relation 5,916 99.72%

17

Optimizing {Ub}Bb=1, given U0 and {Vb}Bb=1: When U0 and {Vb}Bb=1 are fixed, the constraints are independent on each Ub (b = 1, · · · , B), suggesting that we can optimize each Ub separately. Ub can be obtained by solving following

Performance Metric: We focus on the task of rating prediction in recommendation to evaluate our models' quality. The most popular metric, Root Mean Square Error (RMSE) is used to measure the prediction quality.

problem,

 n  mb

min L(Ub) =

Ub

i=1 j=1

solving

 L(Ub )  Uib

= 0,

( Iibj Ribj - we have:

(Ui0 )T

Djb

-

(Uib )T

Pjb )2

+



 n Uib 2F
i=1
(5)

RM SE =

1 T

 (Rij

- R^ij )2

(9)

i,j

where Rij and R^ij denote the true and predicted ratings respectively, and T denotes the number of tested ratings. The smaller RSME value means a better performance.

  mb

-1

  mb



Baseline Methods: For comparison, we consider following related methods: (1)PMF [6], the state-of-the-art tra-

Uib = Eb +

Iibj Pjb(Pjb)T   Iibj (Ribj - (Ui0)T Djb)Pjb

ditional MF method, which learns latent factors for each

j=1

j=1

type of behaviors separately with no information transferred;

(6)
where Eb is a Kb × Kb identity matrix. Optimizing {Vb}Bb=1, given U0 and {Ub}Bb=1: We can also
optimize each Vb separately by solving following problem:

(2)NCDCF U and NCDCF I [1], the early multi-behavior based methods which integrate multiple types of behaviors into recommendation by the user-based and item-based neighborhood method, respectively; (3)CMF [7], the state-of-the-

min
Vb

L(Vb)

=

 n
i=1

 mb Iibj
j=1

( Ribj

-

(U~ib)T

Vjb )2

+



 mb Vjb 2F
j=1

(7)

solving

 L(Vb )  Vjb

= 0,

we

have:

art multi-behavior based MF method as discussed before. To perform comprehensive comparison, we conducted ex-
periments on different training sets (80%, 60% and 40%) to test the models' performance under different sparsity cases. For example, for training data 80%, we randomly select 80% of the data from each types of the behaviors for training and

(

 n

)-1 ( n

)

Vjb = Esb + Iibj U~ib(U~ib)T

Iibj Ribj U~ib

(8)

the rest for testing. The random selection was carried out 5 times independently, and we report the average results.

i=1

i=1

3.2 Experimental Results

where Esb is a (Ks + Kb) × (Ks + Kb) identity matrix. The detailed optimization algorithm is described in Al-
gorithm 1. Note that, the number of behavior-specific latent factors Kb can be different for different behaviors. In order to reduce the model complexity, we set all the Kb (b = 1, · · · , B) the same in our experiments.

Performance Comparison. We evaluate the rating prediction performance for book, music and movie using the above constructed training/testing sets. Since the social relation prediction belongs to the task of link prediction, which is different from rating prediction task and unsuitable to be evaluated by RMSE, here we use social relations as a kind of

auxiliary behavior and do not do the social relation predic-

3. EXPERIMENTS

tion task. The experimental results using 10 dimensions to

represent the latent factors are shown in Table 2. The pa-

3.1 Experiment Settings
Datasets: To evaluate our model's recommendation quality, we crawled the dataset from the publicly available website Douban1, where users can provide their ratings for movie, books and music, as well as establish social relations with others. Thus, we have four types of user behaviors here. To have sufficient observations to be split in various proportions of training and testing data for our evaluation, we filtered
1http://www.douban.com

rameter values of our GLFM are:  = 0.2, Ks = 6, Kb=4, which are determined by cross-validation.
From Table 2, we can observe that the multi-behavior based MF methods, CMF, is consistently better than the PMF, which demonstrates that integrating information from multiple types of user behaviors is useful for recommendation. However, the two multi-behavior based neighborhood methods, NCDCF U and NCDCF I, do not get consistently better results, which may because that our dataset is very sparse and the neighborhood based methods usually fail to

997

Table 2: Performance Comparison on different sparsity cases Behavior Training PMF NCDCF U NCDCF I CMF GLFM

Book

80% 0.8150 0.8355 60% 0.8329 0.8367 40% 0.8500 0.8394

0.7976 0.8026 0.8143

0.7849 0.7684 0.8011 0.7878 0.8181 0.8061

Music

80% 0.7309 0.7826 60% 0.7326 0.7812 40% 0.7639 0.7859

0.7367 0.7376 0.7465

0.7112 0.6922 0.7187 0.6943 0.7411 0.7111

Movie

80% 0.7577 0.8941 60% 0.7671 0.8954 40% 0.7955 0.8971

1.0866 1.0920 1.1060

0.7452 0.7288 0.7581 0.7374 0.7790 0.7542

0.77

0.8

0.85

80% training data

80% training data

80% training data

0.84

60% training data

0.76

60% training data

0.79

60% training data

40% training data

40% training data

40% training data

0.83

0.75

0.78

0.82

0.74

0.77

0.81

0.73

0.76

0.8

0.72

0.75

0.79

0.71

0.78

0.74

0.7

0.77

0.73

0.69

0.76

0

2

4

6

8

10

0.72

0

2

4

6

8

10

0

2

4

6

8

10

Ks (Kb=10- Ks)

Ks (Kb=10- Ks)

Ks (Kb=10- Ks)

(a) Book

(b) Music

(c) Movie

Figure 2: Impact of Parameter Ks (Kb)

RMSE RMSE RMSE

find similar neighbors under such sparse data. It is obvious that our GLFM model consistently outperforms other approaches in all sparsity cases, especially achieving significant improvement over CMF, which illustrates that the by modeling the shared and behavior-specific latent factors among behaviors, GLFM can integrate users' multiple types of behaviors into recommendation more effectively.
Impact of Parameter Ks and Kb. In GLFM, the shared latent factors model the correlation between multiple behaviors and the behavior-specific latent factors model the heterogeneity of them. Hence, we investigate the effects of the important parameter in GLFM: the number of shared latent factors Ks and the number of behavior-specific latent factors Kb. In the extreme cases, if Ks = 0, it degenerates to PMF, which will not share any information between behaviors; if Kb = 0, it degenerates to CMF, which will not model the specific characteristics of different behaviors. Fixing the total number of latent factors (Kb + Ks) as 10, Figure 2 shows the performance of GLFM on different training sets with different values of Ks (Kb is also different for Kb = 10 - Ks). We can see that, in all cases the RMSE results decrease (prediction accuracy increases) at first with Ks increasing, which demonstrates that sharing information between users' multiple types of behaviors is useful for recommendation; however, when Ks goes greater than a threshold the RMSE increase (prediction accuracy decreases) with Ks increasing (Kb decreasing), which may because that improper information is transferred to harm the recommendation results for lack of modeling the specific characteristics of different behaviors.
4. CONCLUSION
In this paper, we propose a novel recommendation model, GLFM, to integrate multiple types of user behaviors effectively by modeling the correlation and heterogeneity of

them. To achieve this goal, GLFM attempts to find a factorization of latent factor space into subspaces that are shared across multiple behaviors and subspaces that are specific to each type of behaviors. Experiment on real-world dataset demonstrate that the proposed method can achieve better recommendation results than other competitors.
5. ACKNOWLEDGEMENTS
This work was supported in part by 973 Program (Grant No. 2010CB327905), National Natural Science Foundation of China (Grant No. 61170127, 61332016).
6. REFERENCES
[1] S. Berkovsky, T. Kuflik, and F. Ricci. Cross-domain mediation in collaborative filtering. In User Modeling. 2007.
[2] Y. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In KDD, 2008.
[3] A. Krohn-Grimberghe, L. Drumond, C. Freudenthaler, and L. Schmidt-Thieme. Multi-relational matrix factorization using bayesian personalized ranking for social network data. In WSDM, 2012.
[4] B. Li, Q. Yang, and X. Xue. Can movies and books collaborate? cross-domain collaborative filtering for sparsity reduction. In IJCAI, 2009.
[5] H. Ma, H. Yang, M. R. Lyu, and I. King. Sorec: social recommendation using probabilistic matrix factorization. In CIKM, 2008.
[6] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In NIPS, 2008.
[7] A. P. Singh and G. J. Gordon. Relational learning via collective matrix factorization. In KDD, 2008.
[8] S.-H. Yang, B. Long, A. Smola, N. Sadagopan, Z. Zheng, and H. Zha. Like like alike: joint friendship and interest propagation in social networks. In WWW, 2011.

998

