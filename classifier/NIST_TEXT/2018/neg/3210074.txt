Short Research Papers II

SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA

Robust Asymmetric Recommendation via Min-Max Optimization

Peng Yang, Peilin Zhao, Vincent W. Zheng, Lizhong Ding, Xin Gao

KAUST, Saudi Arabia;SCUT, China;Advanced Digital Sciences Center, Singapore {peng.yang.2,lizhong.ding,xin.gao}@kaust.edu.sa;peilinzhao@hotmail.com;vincent.zheng@adsc.com.sg

ABSTRACT
Recommender systems with implicit feedback (e.g. clicks and purchases) suffer from two critical limitations: 1) imbalanced labels may mislead the learning process of the conventional models that assign balanced weights to the classes; and 2) outliers with large reconstruction errors may dominate the objective function by the conventional L2-norm loss. To address these issues, we propose a robust asymmetric recommendation model. It integrates costsensitive learning with capped unilateral loss into a joint objective function, which can be optimized by an iteratively weighted approach. To reduce the computational cost of low-rank approximation, we exploit the dual characterization of the nuclear norm to derive a min-max optimization problem and design a subgradient algorithm without performing full SVD. Finally, promising empirical results demonstrate the effectiveness of our algorithm on benchmark recommendation datasets.
CCS CONCEPTS
· Information systems  Collaborative filtering; · Theory of computation  Semi-supervised learning;
KEYWORDS
Robust Asymmetric Learning; Concave-Convex Optimization
ACM Reference Format: Peng Yang, Peilin Zhao, Vincent W. Zheng , Lizhong Ding, Xin Gao. 2018. Robust Asymmetric Recommendation via Min-Max Optimization. In SIGIR '18: The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval, July 8­12, 2018, Ann Arbor, MI, USA. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3209978.3210074
1 INTRODUCTION
Recommender systems are attractive for content providers, through which they can increase sales or views. The user-item matrix, i.e., Y  Rn×m , encodes the individual preference of users for items. In this work, we assume m  n. Most often user preference is not explicitly but implicitly expressed with binary (0 or 1) values. In the implicit feedback setting, the observed feedbacks marked as 1's
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00 https://doi.org/10.1145/3209978.3210074

are positive instances, indicating that a user viewed or purchased an item, while the others annotated as 0's are a mixture of negatives and missing values. However, imbalanced labels and outliers often occur in the implicit feedback datasets. To tackle these problems, a large number of studies have been conducted, among which one-class collaborative filtering (CF) model [5, 8] treated all unlabeled values as negatives, which is biased in estimation since some missing values are positives. Rendle et al. [14] sampled a subset of negative instances from unlabeled values, which often decreases the predictive power of the model due to insufficient data coverage. To address the outlier issue, robust matrix decomposition [9][17] employed a sparse matrix to capture the noise so that the low-rank structure can be recovered. However, the proposed L2-norm loss function may be easily misled by the outliers and noisy data.
Although these methods are effective, they mainly rely on nuclear norm for the low-rank approximation. The optimization for nuclear norm minimization can be solved by first-order optimization methods such as subgradient descent [10] and proximal gradient descent [11]. Although these methods are guaranteed to converge, they are inefficient because a singular value decomposition (SVD) step, which takes O(m2n) time, is required at each iteration. To reduce the computational complexity, one efficient way is to replace the full SVD with an approximate SVD [3]. However, those approaches require the loss function to be smooth [7]. The alternative way relies on the bilinear factorization, which utilizes alternating direction methods to iteratively optimize the decomposed variables. However, these approaches break the convexity of the original problem, which results in no global convergence [8].
In this paper, we propose a robust asymmetric recommendation method via min-max optimization. To reduce the negative impact of imbalanced and noisy labels, we propose a capped Lp -norm asymmetric learning model. It derives an iteratively weighted algorithm to minimize the objective function. By leveraging the capped-norm and cost-sensitive learning, our model seamlessly integrates them into a joint framework, where the result of one task reinforces the other one. To reduce the computational cost of low-rank approximation, we develop an SVD-free optimization algorithm. Based on the dual characterization of the nuclear norm, we reformulate the problem with a min-max optimization problem and solve it by a subgradient method. In each iteration, we only need to compute the largest singular vector instead of a full SVD, thus reducing the time complexity from O(m2n) to O(mn). Finally, the promising experimental results demonstrate the effectiveness of our algorithm on several benchmark recommendation datasets.

1077

Short Research Papers II

SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA

2 ALGORITHM

We assume that a 0-1 rating matrix Y  {0, 1}n×m with a bounded

nuclear norm Y  , where n and m are the numbers of items

and users, respectively. Generally, only a subset of 1's of Y are

observed. Let the observations  be a subset of positive entries

sampled from {(i, j)|Yij = 1}. We define the observation matrix as A where Aij = 1 if (i, j)  , and Aij = 0 otherwise. Our objective

is that, given the observation matrix A, we aim to find a low-rank

matrix X to minimize the loss between X and A:

nm

min
X Rn ×m

i =1

j =1

(Xi j , Ai j )

+

rank(X),

(1)

where   0 is a trade-off parameter, (X, A) is a loss function between the matrices X and A, and rank(X) constrains X into a

low-rank matrix.

2.1 Framework for Class Imbalance and Outlier

We introduce a framework to tackle class imbalance and outliers. Class-Imbalance Learning: In the 0-1 rating matrix, a small por-

tion of positives is observed, which may result in biased estimation

by the conventional models that treat each class equally. To address

this issue, we assume that the cost of missing a positive target

is much higher than that of having a false-positive, and study an appropriate performance metric: weighted cost,

cost = cp × Mp + cn × Mn,

(2)

where Mp and Mn are the numbers of false negatives and false positives, cp and cn  [0, 1] (cp + cn = 1) denote the predefined
costs of false negatives and false positives, respectively. The lower

the cost value, the better the performance.

Lemma 1. Minimizing the weighted cost in Eq. (2) is equivalent to minimizing the following objective:

 I(Xi j <q) +

I(Xi j q),

(3)

Ai j =+1

Ai j =0

where 

=

cp cn

is a biased coefficient, q



(0, 1) is a threshold and I

is the indicator function that outputs 1 if  holds and 0 otherwise.

Lemma 1 gives the explicit objective for optimization, but the indicator function in Eq. (3) is not convex. Thus, we replace the indicator function by its convex surrogate,

 (Xi j ) =  I(Aij =1) + I(Aij =0) ^(Xi j ),

(4)

and ^(·) is a convex unilateral loss for the 0-1 classes,

^(Xi j ) =

[1 - Xi j ]2+, Ai j = 1

[Xi j ]2+,

Ai j = 0

where [·]+ = max(·, 0) is the hinge loss. We assume that 0  cn  cp , since we would prefer to improve the accuracy of the positive class. Fig. 1(a) illustrates the loss  (Xij ) for Aij = 1 with  = 2. We observe that for  (Xij ), the slope of the loss function changes

for the positive class, leading to more "aggressive" updating. The

cost-sensitive learning has been widely studied in [15]. Different

from previous techniques, we derive a cost-sensitive unilateral loss

for binary classification with 0-1 label feedback. Capped LP -norm Loss: A large squared loss occurs in Eq. (4) if the data point is not correctly classified. Outliers may result in such

Loss Value Loss Value

Figure 1: Illustration of robust cost-sensitive loss

(a) Cost-sensitive unilateral loss

8 Weighted L2-norm loss

7

L2-norm loss

6

Hinge loss

5

4

3

2

1

-01

0

1

2

3

X

(b) Capped Cost-Sensitive Loss

1.5

error cost on positives

error cost on unlabels

1

0.5

0

-0.5

0

0.5

1

1.5

X

issues and mislead the learning process. To be resistant to outliers, we propose a robust cost-sensitive loss for 0 < p < 2:
p
h( (Xi j )) =  I(Aij =1) + I(Aij =0) min(^(Xi j ) 2 ,  ), (5)

where h( (x)) enforces a capped Lp -norm over the loss ^(x) with an upper bound  > 0. As shown in Fig. 1(b) ( = 2, p = 1 and  = 0.5), no matter how misclassified the data point is, the loss h( (x)) is capped by  . This makes the loss function robust to
outliers since their effect to the model is fixed. However, optimizing
Eq. (5) is difficult since h( (x)) is a concave non-smooth function in the domain of  (x). Motivated by concave duality [19], Lemma 2
provides an iteratively weighted function to solve it.

Lemma 2. Eq. (5) can be relaxed to iteratively minimizing a weighted L2-norm formulation:

Xt +1 = argmin ~itj ^(Xi j )( I(Aij =1) + I(Aij =0)),

(6)

X i,j

where ~ = uh(u)|u=^(x) denotes the supergradient of the concave function h(u) at point u = ^(x) for p  (0, 2):

~itj =

p 2

^(X

t ij

)

p -2 2

,

^(Xitj

)

p 2

  ;

0,

otherwise.

(7)

p
Proof. Let u = ^(x) and h(u) = min(u 2 ,  ). As ^(x) is convex in the domain of x, h(u) can be rewritten:

p
min(u 2 ,  )

=

inf [~u

- h(~)],

(8)

~ 0

where h(~) is the concave dual of h(u) given below:

h(~)

=

inf [~u
u

-

h(u)]

(=8)

inf [~u
u

-

min(u

p 2

,



)]

  = 

p -2 p

(

p 2

)

2 2-p

(

1 ~

)

p 2-p

,

2

  

~

p


-  ,

p
if u 2 < 
p
if u 2   .

Equipped h(~) into Eq. (8), ~ can be solved as in Eq. (7).

From the updating rule (7), we observe that the misclassified points
p
^(x) 2 >  are considered as outliers, and ignored, which is ex-
pected for robustly learning a model. Remark: The sequence {Xt } generated by Eq. (6) iteratively minimizes the upper bound of the concave problem ij h( (Xij )) + rank(X). Since h( (x)) is a concave function, for any x,
h( (x))  h( (xt )) + ~t ,  (x) -  (xt )F ,

1078

Short Research Papers II

SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA

Algorithm 1: ROMA: RObust asyMmetric recommendA-

tion

1 Input: A  Rn×m ; 2 Initialize: X0 = U0 = 0  Rn×m , 0 and 0 ;

3 for t = 1, . . . ,T - 1 do

4

~itj =

p 2

^(X

t ij

)

p -2 2

,

0,

^(X

t ij

)

p 2

 

otherwise

as Eq. (7);

5 Xt +1 = Xt - t ~t   (Xt ) + Ut ;

6 Ut +1 = Ut + t (Xt - [U2 - 1]+) ;

7 end

8 Output: X^ T =

T t =1

Xt /T

;

where ~t = uh(u)|u=^(xt ). Thus we obtain an upper bound of ij h( (Xij )) + rank(X) via a linear approximation at  (Xt ):

X  Rn×m : rank(X) + h( (X))

 rank(X) + h( (Xt )) + ~t ,  (X) -  (Xt )F .

(9)

Since  (Xt ) is constant w.r.t. X, we have

Xt +1 = arg min rank(X) + h( (Xt )) + ~t ,  (X) -  (Xt )F
X
= arg min rank(X) + ~t ,  (X)F ,
X

which obtains an iterative solution to minimize the upper bound of

the concave objective function.

2.2 SVD-free Min-Max Optimization
The objective, rank(X) + ~t ,  (X)F , is a nonconvex function and computationally intractable [1]. To address the issue, we relax rank(X) to its convex norm,

Xt +1 = arg min ~t ,  (X)F + X,

(10)

X

where X = i i (X) is the nuclear norm and i (X) is a singular value. The nuclear norm minimization can be solved by subgra-

dient descent (GD) [12] or proximal gradient descent (PGD) [11].

Although GD and PGD are guaranteed to converge, they have to perform SVD of Xt or Xt - t  (Xt ) in each iteration [2], which takes a high computational cost of O(m2n). To reduce the computa-
tional complexity, we propose an SVD-free min-max optimization

algorithm. According to the dual form of the nuclear norm [16],

X

=

max
U Rn ×m

tr(UX)

s.t. U2  1,

where  · 2 represents the spectral norm, we can cast Eq. (10) to a

concave-convex optimization problem,

min max ~t ,  (X)F + tr(UX) s.t. U2  1.
XU

Due to the spectral norm constraint, we have to project the in-

termediate solution onto the unit spectral norm ball, which again

requires a full SVD operation. To address this issue, we replace the constraint U2  1 with a regularization term in the objective function to control the spectral norm of U:

min max~t ,  (X)F + tr(UX) - [U2 - 1]+,
XU

where  > 0 is a parameter and [·]+ = max(·, 0). Since the above optimization problem is convex-concave, we can apply the above standard subgradient method to solve it, which iterates as follows:
Xt +1 = Xt - t ~t   (Xt ) + Ut , Ut +1 = Ut + t (Xt - [U2 - 1]+) . Note that the subgradient [U2 - 1]+ can be computed efficiently. We denote 1 as the leading singular value of U, p1 and q1 as the corresponding left and right singular vectors. Then we have
p1q1 I(1 >1)  [U2 - 1]+.
In each iteration, we only need to compute the leading singular vector of Ut with O(mn) time. In contrast, a full SVD takes O(m2n) time. The entire procedure is summarized in Algorithm 1.
3 EXPERIMENTAL RESULTS
We start with experimental data and benchmark setup, and then present the comparison results.
3.1 Experimental Settings
Datasets: The experiments were conducted on three real datasets: MovieLens-100K [4], MovieLens-1M, and EachMovie1. Table 1 summarizes the details of the three datasets. These datasets are classimbalanced due to a small portion of observations. To simulate the implicit setting on the datasets, we followed previous studies [13] by treating the ratings larger than 3 as observed positive feedbacks. Evaluation Metrics: Each dataset was randomly partitioned into two non-overlapping sets for training and testing: for each user, 80% of its observed feedbacks were randomly chosen as the training data and the remaining 20% were used for testing. For the sake of fair comparison, we repeated the random partition for five times. At each time, we computed the results for each user, then reported the averaged results over all users. We measured the performance with two widely-used evaluation metrics: 1) NDCG@N, the normalized discounted cumulative gain in the ranking; 2) F1@N, the weighted harmonic mean of precision and recall. We chose the top-N ranked items for evaluation with N = {5, 15}. Specifically, the higher these measures, the better the performance is. Baselines: We compared our algorithm with four state-of-the-art baselines: 1) BPRMF is a one-class CF approach, which assigns each example with a heuristic prior [14]. 2) RMF-MM solves the L1-norm based low-rank matrix factorization problem via majorization minimization [9]. 3) SPMF employs a self-paced learning to resist outliers and noise [20]. 4) MCShift is a cost-sensitive method for matrix completion [6]. All parameters of the baselines were tuned according to their recommended instructions. For bilinear factorization methods, the number of latent factors was tuned from {10, 20, . . . , 50}. For ROMA, we fixed p = 1,  = 10 and  = 1. We let  = 10 for ML-100K and  = 100 for ML-1M and EachMovie. We tunedthe parameters 0 and 0 from {10-3, . . . , 102}, and set t = 0/ t, t = 0/ t according to [16].
3.2 Comparison Results
The comparison results, in terms of NDCG and F1, are summarized in Table 2. It shows that ROMA always outperforms state-ofthe-art robust MF methods, SPMF and RMF-MM, over all metrics.
1
http://www.grouplens.org/

1079

Short Research Papers II

SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA

Objective Value Objective Value
NDGC@15 NDGC@15

Table 1: Description of Datasets

Datasets ML-100K ML-1M Each-MV

#Users 943 6,039
72,916

#Items 1,682 3,628 1,628

#Ratings 100,000 1,000,209 2,811,983

Data Density 6.30% 4.47% 1.91%

Figure 2: Objective value versus the CPU time

7 x 104 6.8 6.6 6.4

ML-100K
ROMA-MM ROMA-PSD ROMA-SD

4 x 105 3.5
3

ML-1M

ROMA-MM ROMA-PSD ROMA-SD

6.2 6 20

2.5

40

60

80

CPU time

100 120

500 1000 1500 2000 2500 CPU time

Table 2: Mean and Standard Deviation of Evaluation Metrics

Algorithm
BPRMF SPMF RMF-MM MCShift ROMA
BPRMF SPMF RMF-MM MCShift ROMA
BPRMF SPMF RMF-MM MCShift ROMA

F1@5
19.53±0.46 18.74±0.53 18.80±0.77 19.12±0.54 21.32±0.53
15.81±0.48 16.63±0.46 16.71±0.51 16.52±0.42 17.13±0.42
31.91±0.46 31.10±0.53 31.14±0.46 31.31±0.38 32.22±0.38

F1@15 NDCG@5
ML-100K
27.93±0.34 69.37±0.88 27.72±0.26 68.02±0.51 27.88±0.42 68.13±0.73 29.00±0.29 70.16±0.54 31.15±0.31 72.45±0.57
ML-1M
23.64±0.35 62.44±1.01 23.42±0.44 62.03±0.62 23.81±0.41 62.19±0.78 24.25±0.31 63.07±0.60 25.92±0.33 64.67±0.46
Each-MV
28.30±0.20 60.36±1.02 27.77±0.34 59.65±0.55 27.59±0.36 59.78±0.86 27.32±0.30 59.65±0.51 29.07±0.30 61.68±0.54

NDCG@15
68.73±0.62 68.17±0.46 69.39±0.56 71.33±0.49 72.93±0.41
63.47±0.62 64.05±0.46 64.09±0.72 64.03±0.47 65.32±0.39
60.92±0.66 60.58±0.47 60.73±0.75 60.67±0.45 62.11±0.48

These MF methods treat imbalanced labels equally, which result in biased estimation of classification. In addition, ROMA outperforms the cost-sensitive methods, MCShift and BPRMF, over all the datasets. Although these methods exploit prior weights on imbalanced classes, their performance is degraded due to outliers [18].
To show the efficiency of the proposed min-max (MM) optimization, we compared our method with two classical methods: subgradient descent (SD) and proximal subgradient descent (PSD). The same step t = 0/ t is used for SD and PSD. We plotted the objective value along the running time in Fig. 2. As can be seen, MM decreases much faster than SD and PSD. This is as expected, because MM is SVD-free and time-efficient, taking much less time in each iteration than the other two methods.
We also studied the impact of the parameter  to show how cost-sensitive weight improves the results. The results in Fig. 3 show that a small value of  would degrade the performance due to the equal weights on the imbalanced classes. However, increasing the value of  can reduce the negative impact of imbalanced classes via more "aggressive" update for the positive class.

Figure 3: Parameter sensitivity analysis of 

0.78 0.76 0.74 0.72
0.7 0.68 0.66
100

ML-100K ROMA MCShift BPRMF
101 Parameter 

102

0.68 0.67 0.66 0.65 0.64 0.63 0.62 0.61
0.6 100

ML-1M ROMA MCShift BPRMF
101 Parameter 

102

4 CONCLUSION
We proposed a robust asymmetric recommendation via efficient
low-rank approximation. Our proposed model ROMA can well leverage both cost sensitive learning and capped Lp -norm to solve the problem. It novelly formulates the objective as an iteratively
weighted convex function, which can be efficiently solved with a
tight bound. To reduce the computational cost of low-rank approx-
imation, we proposed a min-max optimization without performing
full SVD. Finally, we validated the efficiency and effectiveness of
our algorithm in the promising empirical results.
REFERENCES
[1] Edoardo Amaldi and Viggo Kann. 1998. On the approximability of minimizing nonzero variables or unsatisfied relations in linear systems. Theoretical Computer Science 209, 1-2 (1998), 237­260.
[2] JianFeng Cai, Emmanuel J Candes, and Zuowei Shen. 2010. A singular value thresholding algorithm for matrix completion. SIAM Journal on Optimization 20, 4 (2010), 1956­1982.
[3] Lizhong Ding and Shizhong Liao. 2017. An approximate approach to automatic kernel selection. IEEE Transactions on Cybernetics 47, 3 (2017), 554­565.
[4] F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History and context. TIIS 5, 4 (2016), 19.
[5] Xiangnan He and Hanwang Zhang. 2016. Fast matrix factorization for online recommendation with implicit feedback. In SIGIR. ACM, 549­558.
[6] Cho-Jui Hsieh, Nagarajan Natarajan, and Inderjit S Dhillon. 2015. PU learning for matrix completion. In ICML. 2445­2453.
[7] Cho-Jui Hsieh and Peder Olsen. 2014. Nuclear norm minimization via active subspace selection. In ICML. 575­583.
[8] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In ICDM. Ieee, 263­272.
[9] Zhouchen Lin, Chen Xu, and Hongbin Zha. 2017. Robust Matrix Factorization by Majorization Minimization. PAMI (2017).
[10] Yurii Nesterov. 2004. Introductory lectures on convex optimization. Vol. 87. Springer Science & Business Media.
[11] Yu Nesterov. 2013. Gradient methods for minimizing composite functions. Mathematical Programming 140, 1 (2013), 125­161.
[12] Yurii Nesterov. 2013. Introductory lectures on convex optimization: A basic course. Vol. 87. Springer Science & Business Media.
[13] Weike Pan and Li Chen. 2013. GBPR: group preference based Bayesian personalized ranking for one-class collaborative filtering. In IJCAI. 2691­2697.
[14] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In UAI. AUAI, 452­461.
[15] Clayton Scott. 2011. Surrogate losses and regret bounds for cost-sensitive classification with example-dependent costs. In ICML-11. 153­160.
[16] Yichi Xiao, Zhe Li, Tianbao Yang, and Lijun Zhang. 2017. SVD-free convexconcave approaches for nuclear norm regularization. In IJCAI. 3126­3132.
[17] Peng Yang, Peilin Zhao, and Xin Gao. 2017. Robust online multi-task learning with correlative and personalized structures. IEEE Transactions on Knowledge and Data Engineering 29, 11 (2017), 2510­2521.
[18] Peng Yang, Peilin Zhao, Xin Gao, and Yong Liu. 2017. Robust Cost-Sensitive Learning for Recommendation with Implicit Feedback. arXiv preprint arXiv:1707.00536 (2017).
[19] Tong Zhang. 2010. Analysis of multi-stage convex relaxation for sparse regularization. JMLR 11 (2010), 1081­1107.
[20] Qian Zhao, Deyu Meng, Lu Jiang, Qi Xie, Zongben Xu, and Alexander G Hauptmann. 2015. Self-Paced Learning for Matrix Factorization.. In AAAI. 3196­3202.

1080

