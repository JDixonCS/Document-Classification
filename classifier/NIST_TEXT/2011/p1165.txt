Location Disambiguation for Geo-tagged Images
Zhu Zhu, Lidan Shou, Kuang Mao, Gang Chen
Department of Computer Science, Zhejiang University, Hangzhou, China
{04jsjzz,should,mbill,cg}@zju.edu.cn

ABSTRACT
In this poster, we address the problem of location disambiguation for geotagged Web photo resources. We propose an approach for analyzing and partitioning large geotagged photo collections using geographic and semantic information. By organizing the dataset in a structural scheme, we resolve the location ambiguity and clutter problem yield by massive volume of geotagged photos.
Categories and Subject Descriptors
H.3.3 [Information Systems]: Information Retrieval
General Terms
Algorithms, Design
Keywords
Location Disambiguation, Geotagged Images
1. INTRODUCTION
The popularity of mapping mashup applications has enabled millions of users with GPS-equipped gadgets to upload, tag, and share diverse media resources by their geographic locations. The need to manipulate and retrieve such massive geotagged Web resources is faced by a serious ambiguity problem.
The geotags of a photo indicate its relevance to a certain location, while the textual tags describe the photo's content or user's interests in it. We define the location designated by the geotags of an image as its Physical Location. The physical location is in the form of longitude and latitude coordinates and typically indicates the place where the photo is taken. Then we define the location that the content of the image refers to as its Semantic Location, assuming this would be implied in the title or textual tags of the item. Thus, a Geographic Semantic Gap between the physical location and semantic location can be observed for many images, as photos taken at the same place may capture different semantic objects. Conversely, photos targeting at the same object may have different physical locations too.
A keyword search for "Big Ben" in the well-known Panoramio geo-image search engine exemplifies this ambiguity problem.
Copyright is held by the author/owner(s). SIGIR'11, July 24­28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

The search results displayed on a 2D map contains many pictures of the Big Ben scattering around a certain area. All these items have coordinates close to the bell and a common tag "Big Ben" in their tags. However, in the midst of these photos there are ones about other landmarks too, such as London Eye and Thames River, which are located elsewhere. The ambiguity problem will subject the dataset in a clutter, leading to unpleasant geotag-based retrieval experiences.
In this work, we try to analyze the spatial and semantic aspects of geotagged photos in a systematic way. Our approach is based on two observations, which motivate the approach to an organization of image collections. On one hand, geotagged photos inherently reveal geographic relations between each other; on the other hand, the semantic content contained in textual tags provides effective information for location disambiguation within a limited geographic region. Thus we propose a two-level clustering scheme combining structural analysis on the geotags with content analysis on the textual tags to resolve the ambiguity problem. Such combination leads us to know the underlying correlation among image semantics. We believe this would be particularly useful in supporting keyword-based search for geotagged images. In addition, our work can also be utilized to discover interesting non-landmarks.
Prior work in [3] and [2] also use clustering methods to organize geo-photo collections by combining geotags with visual features, rather than textual tags. Therefore, our approach is expectedly more efficient when handling massive photos.
2. SOLUTION
In our solution, the physical and semantic aspects are considered to resolve location ambiguity. Our data model handles geotagged photo collections about landmarks. Each photo p in the dataset P is represented by a three-tuple (p, lp, Tp), where p is the unique photo ID, lp is the physical location marking the place where it was taken, and Tp denotes the tag set. We assume every image has some georelated tags such as place name. This "place semantics" are treated as the semantic location of the photo.
Our solution mainly consists of two clustering phases, namely a geo-clustering phase and a semantic clustering phase. In the geo-clustering phase, we employ a density based method OPTICS [1] to roughly segment the image collection into a set of compact geo-clusters. For the semantic clustering step, a spectral clustering algorithm is performed on each geo-cluster generated previously. Since each

1165

geo-cluster has limited size, the computational cost for exploring its semantic meanings becomes reasonable. Besides, We also employ an intermediate semantic enhancement process to produce more precise results for semantic clustering. This process can not only capture the underlying surrounding context of images, but also eliminate the negative effects caused by some ill-formed tags. Another advantage of our solution is its ability to adapt to the granularity of geoclustering, which make sense for location-skewed data. Step 1. Geo-clustering
We perform OPTICS clustering in metric space (P, dG), dG is the geographic distance between any two points on a flat Earth surface. As a density-based algorithm, OPTICS does not impose any restriction to the shape of the resulting clusters. As well, it can discover clusters of varying density, which favors for multi-level 2D visualization of the clustered results. Step 2. Semantic Enhancement
Since the textual tags provided by users are often brief and noisy, we cannot simply rely on the document proximity measure to calculate the similarity between tags. We leverage additional Web resources to enhance the image semantics. Treating the tag set as a query to the Google search engine, we take the snippets of search results, then select the words with high term frequency to form an enhanced semantic vector Vp for each photo. Step 3. Semantic Clustering
The semantic clustering procedure is iteratively applied for each geo-cluster produced in step 1. We compute the tfidf matrix with enhanced semantic context, and construct an undirected weighted graph whose weight is calculated by cosine similarity measure. Finally, we use spectral clustering algorithm to partition the graph into k subsets using the Kmeans algorithm.
To determine parameter k, we address a novel method to automatically estimate the value k. This method can adapt to the granularity of the previous geo-clustering. The intuitions behind our method is:
· The error bound of location ambiguity is limited, because a camera can only capture scenes within a certain distance.
· We assume each cluster generated in geo-clustering represent a meaningful landmark, since it corresponds to a dense area with a burst in number of photos.
Thus for each geo-cluster, we expand its margin with a certain error bound. The area will become larger in the map so that it may overlap with adjacent geo-clusters. We define the number of geo-clusters overlapping the expanded area as the semantic uncertain degree, denoted by du. This degree indicates the photos in this area might have du additional semantic locations, so the intended number of clusters is given by k = du + 1. Obviously, the value of du will increase as the granularity of geo-clustering refines, since the number of the overlapping clusters may increase as well, which is the way semantic clustering automatically adapt to the granularity of geo-clustering.
3. EXPERIMENTS
Our dataset contains more than 120,000 images crawled from Panoramio, covering several states of USA. We consider three location granularities during the geo-clustering

phase. Each corresponds to different density neighborhood

threshold. For semantic enhancement, we retrieve the top-20

search results and top-30 frequent-occurring words to form

the enhanced semantic vector. During the semantic cluster-

ing,

L

=

1
L2

DL-

1 2

is

used for eigendecomposition

of Lapla-

cian matrix.

Preliminary results of the two clustering phases is pre-

sented below. Figure 1(a) shows part of the geo-clustering

results. Here geo-clusters are plotted in different colors.

(a) Results of geo-clustering (b) Results of semantic clustering of 2 geo-clusters
Figure 1: Results of geo-clustering and semantic clustering.
Figure 1(b) illustrates the further semantic partitioning for two geo-clusters in the upper-left quadrant of Figure 1(a). The two geo-clusters (blue and pink) locate around Ellis Island in Jersey city. Different symbols are used to denote the subsequent semantic clusters generated from each geocluster.
4. CONCLUSION
In this poster, we address the problem of location disambiguation for geotagged photo collections. A two-level clustering scheme that exploits both the geographic and semantic features of photos has been proposed. We also propose a semantic enhancement technique and a method to determine the parameters for the semantic clustering phase. Our work provides a new standpoint for organization and manipulation of massive geotagged photos. Preliminary experiments confirm the effectiveness of our approach. We plan to conduct a comprehensive performance study on the proposed approach.
5. ACKNOWLEDGMENTS
This work is supported in part by the National Science Foundation of China (NSFC Grant No. 60803003, 60970124).
6. REFERENCES
[1] M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. Optics: Ordering points to identify the clustering structure. In SIGMOD Conference, pages 49­60, 1999.
[2] Y. S. Avrithis, Y. Kalantidis, G. Tolias, and E. Spyrou. Retrieving landmark and non-landmark images from community photo collections. In ACM Multimedia, pages 153­162, 2010.
[3] D. J. Crandall, L. Backstrom, D. P. Huttenlocher, and J. M. Kleinberg. Mapping the world's photos. In WWW, pages 761­770, 2009.

1166

