Learning for Graphs with Annotated Edges
Fan Li
Yahoo! Labs
hustlfhustlf@gmail.com

ABSTRACT
Automatic classification with graphs containing annotated edges is an interesting problem and has many potential applications. We present a risk minimization formulation that exploits the annotated edges for classification tasks. One major advantage of our approach compared to other methods is that the weight of each edge in the graph structures in our model , including both positive and negative weights, can be learned automatically from training data based on edge features. The empirical results show that our approach can lead to significantly improved classification performance compared to several baseline approaches.
Categories and Subject Descriptors
H.4 [Information Systems Applications]: Miscellaneous
General Terms
Algorithms
Keywords
graph regularization, webpage categorization
1. INTRODUCTION
Automatic classification with graphs containing annotated edges is an interesting problem and has many potential applications. For example, in webpage categorization, the hyperlink structures among web-pages are very useful resources. The hyper-links can be thought as edges annotated by their associated anchor text and can be used to improve web-page classification performance. Many researcher have studied the problem of classification with graph structures. For example, [1] has exploited the web links using pagerank scores and combines these scores with local text features for webpage categorization tasks. [2] and [3] developed semisupervised learning methods to take advantage of graph structures in classification tasks.
While the above works successfully improved the classification performance using graph structures, they did not exploit the annotation information associated with the edges in the graph. For example, in [2], it is assumed that all the edges in hyperlink structures have the same positive weight. However, this assumption may not always yield the best
Copyright is held by the author/owner(s). SIGIR'11, July 24­28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

result from a classification standpoint. The importance of these edges could be very different in terms of classification, depending on their associated anchor text. Furthermore, sometimes the edges in hyperlink structures may have negative weights. For example, in the catalog and product webpage classification task, the catalog pages often connect to product pages but seldom connect to other catalog pages.
One simple way to use annotation information is to pass edge annotations to node features. That is to treat the annotations of an edge as additional features of the two node connected by this edge. However, by doing this, we have merged the edge features into node features and lost part of the useful information. In this paper, we propose a novel objective function in the graph regularization framework to exploit the annotations on the edges. The general idea used in the paper is to create regularization for the graph with the assumption that the likelihood of two nodes to be in the same class can be estimated using annotations of the edge linking the two nodes.
There are other discriminative models that could learn edge weights in the graph automatically from the training data. For example, conditional random field (CRF) has been widely used for classification tasks on chain graphs. However, when the graph topology becomes more complex (which is always the case in hyper-link structures), the accurate solutions of such models will be very difficult to get. Our approach does not have such a problem.
2. METHOD
Consider the problem of predicting unknown labels for the testing examples based on their input vectors. In this paper, we are interested in the setting where we observe a training set (xi, yi) for i = 1, ..., n and a test set (xj) for j = n + 1, ..., m. Here xi is the input vector of the ith example and scalar yi  {-1, 1} is the class label of the ith example. The true labels yj for the test set (xj) are unknown and to be predicted. We are interested in the case that in addition to the input vectors, a graph is also observed on the whole dataset (including both the training and the testing set). Each node in the graph corresponds to an example and each edge in the graph corresponds to some relationship between the two connected examples.

1259

The objective function we proposed is listed as formula 1,

n
f^ = argminf, Loss(fi, yi) + f T K-1f
i=1

+

(fifj - cij )2

(i,j)E

and set cij = aij

(1)

Here Loss() represents the loss function we defined on the
training data. In our work, we will use the the least square loss function thus loss(f, y) = (f - y)2. K is the m × m kernel matrix that is constructed only from the local text features.  and  are regularization parameters that are
treated as constants here. Notice that formula 1 will reduce to a standard ridge regression classifier when  is set to be zero. cij are the edge weights to be learned from the anchor text features. Vector aij = (aij1, . . . , aijp) represents the values of the p anchor text features associated with the hyperlink connecting web-page i and web-page j. Vector  = (1, . . . , p)T consists of the parameters that represent the weights of anchor text features. Notice that we are using a least square loss function as Loss(fi, yi) so that the values of fifj are encouraged to be similar to ±1.
The intuition of formula 1 is clear. If we consider regularization of the form (fifj - cij)2 with unknown annotation dependent parameter cij, then the proposed method seems the best way to use annotation information to optimize parameter cij because cij = E(fifj |aij ). This has the desirable effect that if given the annotations, fi and fj are likely to have the same sign, then our objective function will strengthen this trend. When fi and fj are likely to have different signs given the annotations, formula 1 works in a similar pattern. In formula 1, each edge weight cij = aij is assumed to be the sum of anchor text weights appeared in this hyperlink. Note that the fi values for the training examples are encouraged to be close to yi (either 1 or -1) by the first term of the above formula.
[2] has presented an efficient algorithm to solve the ob-
jective function with graph regularizers. In this paper, a
similar algorithm with slight modifications is used to solve
the objective function in formula 1.
Notice that formula 1 can be re-written as

f^ = argminf,,v,w

n

Loss(fi,

yi)

+

 (||w||2 2

i=1

+||v||2) + 

(fifj - aij )2

(i,j)E



s.t. fk = wxk + vk u (k = 1, ..., m)

(2)

Here u plays the role as a stabilizing parameter and we

set it to adding a

fbeaetuaresmaulltocoenascthanspt e0c.i1fi.c

It can be regarded as node. By reformulating

the objective function as formula 2, the construction of the

dense kernel matrix K is avoided. We can then solve the

problem iteratively using the gradient descent algorithm. In

each iteration, we first fix  and solve v and w. Then we

fix v and w and solve . This process is iterated until the

algorithm converges. The initial values of these parameters

are all set to be zero.

Table 1: The micor-F1 performance (mean ± std-

dev %)

Baseline Baseline with anchor text Our approach

Yahoo Directory Data 57.9 ± 0.5 60.5 ± 0.4 64.8 ± 0.4

Webkb Data 86.5 ± 0.3 87.6 ± 0.6 89.0 ± 0.5

Table 2: The macor-F1 performance (mean ± std-

dev %
Baseline Baseline with anchortext Our approach

Yahoo Directory Data 57.9 ± 0.4 60.8 ±0.4 65.1 ±0.5

Webkb Data 77.2 ± 0.3 82.6 ± 0.5 82.7 ± 0.3

3. EXPERIMENT
The two real hyperlinked collections used in our paper are WebKB data (http://www.cs.cmu.edu/webkb/) and Yahoo! Directory data (http://www.yahoo.com/). We constructed co-citation graphs on these two collections, in which two pages are connected by an undirected edge if both pages are linked to by a third page.
The WebKB dataset consists of 8275 web-pages crawled from university web sites. The vocabulary consists of 20000 most frequent words. Its co-citation graph has 1143716 edges. The Yahoo! Directory dataset consists of 22969 web pages. Each page of this collection belongs to one of the 13 top level topical directory categories (for example, arts, business and education). The vocabulary consists of 50000 most frequent words. The number of edges in its co-citation graph is 1170029. We randomly split the labeled data into two parts: 50 percent for training and another 50 percent for testing. We draw five runs and report test set averages and standard deviations.
The micro-F1 and macro-F1 performance of different approaches on multiple datasets with co-citation graphs are listed in table 1 and table 2. We use the graph regularization approach in [2] as our baseline approach and call it "Baseline" in the two tables. In order to be fair, we have also tried an extension of the baseline approach by putting the anchor text features associated with each edge into the body text of the two pages connected by this edge. We call this extension "Baseline with anchor text" in the following tables. The performance of our approach is shown in the last raw of the two tables. We can see that our approach has achieved significant improvement compared with the other two approaches.
4. CONCLUSION
This paper presents a novel risk minimization formulation for classification tasks with graphs containing annotated edges. The empirical results show that our approach can lead to improved classification performance, compared to several baseline approaches.
5. REFERENCES
[1] Z. Gyongyi, H. Garcia-Molina, and J. Pedersen. Web content categorization using link information. Technical Report, standford University, 2006.
[2] T. Zhang, A. Popescul, and B. Dom. Linear prediction models with graph regularization for web-page categorization. In SIGKDD 2006, 2006.
[3] X. Zhu, Z. Ghahramani, and J.Lafferty. Semi-supervised learning using gaussian fields and harmonic functions. In ICML 2003, 2003.

1260

