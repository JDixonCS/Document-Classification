A Unified Framework for Recommendations Based on Quaternary Semantic Analysis

Wei Chen

Wynne Hsu

Mong Li Lee

School of Computing, National University of Singapore, Singapore
{weichen,whsu,leeml}@comp.nus.edu.sg

ABSTRACT
Social network systems such as FaceBook and YouTube have played a significant role in capturing both explicit and implicit user preferences for different items in the form of ratings and tags. This forms a quaternary relationship among users, items, tags and ratings. Existing systems have utilized only ternary relationships such as users-items-ratings, or users-items-tags to derive their recommendations. In this paper, we show that ternary relationships are insufficient to provide accurate recommendations. Instead, we model the quaternary relationship among users, items, tags and ratings as a 4-order tensor and cast the recommendation problem as a multi-way latent semantic analysis problem. A unified framework for user recommendation, item recommendation, tag recommendation and item rating prediction is proposed. The results of extensive experiments performed on a real world dataset demonstrate that our unified framework outperforms the state-of-the-art techniques in all the four recommendation tasks.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: [information filtering]
General Terms
Algorithms, Experimentation, Measurement, Performance
Keywords
Tensor factorization, Recommendation, Social tags, Personalization, Collaborative Tagging
1. INTRODUCTION
The amount of information on the Web is increasing at a lightning pace. In order to adequately cope with this information overload, recommendation systems are needed to
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'11, July 24­28, 2011, Beijing, China. Copyright 2011 ACM 978-1-4503-0757-4/11/07 ...$10.00.

bring the relevant resources to the attention of the users automatically. Recommendation systems are typically classified according to the type of tasks they are intended for, which include:
1. User recommendation - Here the task is to identify users with common interests so as to extend the connection among users with similar interests (e.g., Amazon 1 and Facebook 2). Existing user recommendation systems (e.g., Amazon) determine users with common interests either through the fact that these users often give the same rating to similar resources, or they use similar tags to describe the resources.
2. Item recommendation - Instead of stopping at identifying users with common interests, this task goes one step further. Based on the identified set of users with common interests, the items that this set of users are interested in become the candidates for recommending to the target user (e.g., Amazon and YouTube 3).
3. Tag recommendation - This task has emerged recently due to the popularity of social tagging activity. Users typically use an ubiquitous vocabulary as tags to reflect the semantics of the items from his/her point of view. In order to improve the selection of vocabulary to be used as tags, tag recommendation is now a hot research area which aims to provide users with a good set of tags to describe items (e.g., Amazon, Facebook and Flickr 4). Most tag recommendation systems rely on identifying similar users and recommending the tags used by these similar users on similar resources.
4. Item rating prediction - Here, the task goes beyond just determining whether an item should be recommended to a user. Instead, the recommendation systems need to predict the degree of preference a user is likely to exhibit for an item (e.g., Netflix 5).
Till now, most, if not all, recommendation systems utilize only ternary relationships in generating their recommendations. The collaborative filtering-based recommendation systems [8, 1, 12, 18] typically make use of the users-ratingitems relationship to group users based on their ratings on
1http://www.amazon.com 2http://www.facebook.com 3http://www.youtube.com 4http://www.flickr.com 5http://www.netflix.com

1023

items, whereas the tag-based recommendation systems utilize the users-tags-items relationship to perform the various tasks [20, 19, 15]. We argue that recommendations based on ternary relationships are not accurate as they would have missed out important associations.

Table 1: Ternary relations among user, rating and item

User
U1 U1 U2 U2 U2 U3 U4 U4 U4 U5 U5

Rating
like like like like like like like dislike dislike dislike dislike

Item
Forrest Gump Beautiful Mind Forrest Gump Groundhog Day Groundhog Day Forrest Gump Forrest Gump
Toy Story Toy Story Forrest Gump Groundhog Day

Let us consider the ternary relationship users-rating-items in Table 1. From this table, we conclude that users U1, U2, U4 have common interests with U3 since they all like the movie "F orrest Gump". Hence, these users will be highlighted to U3 and the movies "Beautif ulM ind" and "Groundhog Day" will be recommended to U3 because U1 and U2 also like "Beautif ul M ind" and "Groundhog Day". Note that "T oy Story" is not recommended to U3 since U4 dislikes the movie.

Table 2: Ternary relations among user, tags, and item

User
U1 U1 U2 U2 U2 U3 U4 U4 U4 U5 U5

Tag
psychology psychology
comedy excellent comedy comedy comedy overrated comedy comedy overrated

Item
Forrest Gump Beautiful Mind Forrest Gump Groundhog Day Groundhog Day Forrest Gump Forrest Gump
Toy Story Toy Story Forrest Gump Groundhog Day

Table 2 shows the ternary relationship users-tags-items. The users U2, U4 and U5 are said to have common interests with U3 because they all tag the movie "F orrest Gump" as "comedy". Thus, U2, U4 and U5 will be highlighted to U3. At the same time, the movies "Groundhog Day" and "T oy story" will be recommended to U3 since U2 and U4 also tag "Groundhog Day" and "T oy story" as "comedy". In addition, suppose U3 wants to tag the item "Groundhog Day", the set of tags {"comedy", "excellent", "over rated"} will be recommended to him/her as they have been used to tag "Groundhog Day" previously.
Now, instead of the two ternary relationships, we have the quaternary relationships among users, tags, ratings, and items as shown in Table 3. We note that only users U2

Table 3: Quaternary relations among users, tags, ratings and items

User
U1 U1 U2 U2 U2 U3 U4 U4 U4 U5 U5

Tag
psychology psychology
comedy excellent comedy comedy comedy overrated comedy comedy overrated

Rating
like like like like like like like dislike dislike dislike dislike

Item
Forrest Gump Beautiful Mind Forrest Gump Groundhog Day Groundhog Day Forrest Gump Forrest Gump
Toy Story Toy Story Forrest Gump Groundhog Day

and U4 would be highlighted to U3 and the only movie recommended to U3 is "Groundhog Day". This is because even though U1 is highlighted under the ternary relationship users-ratings-items, we realize from the quaternary relationship that U1 likes "F orrest Gump" as a psychology movie, whereas U3 likes the movie "F orrest Gump" as a comedy. Hence, U1 does not share a common interest with U3. As a result, U1's item "Beautif ul M ind" is also not recommended to U3.
Similarly, under the ternary relationship users-tags-items, U5 is highlighted to U3 and the movie "T oy Story" is recommended to U3. However, the quaternary relationship in Table 3 shows that U5 dislikes the movie "F orrest Gump" although he/she tags it with "comedy". Since U3 and U5 have different opinions on "F orrestGump" even though they both use the tag "comedy", U5 should not be considered as having common interests with U3. At the same time, we observe that although U4 tags "T oy Story" as "comedy", he/she does not like it. Hence "T oy Story" should not be recommended to U3.
For tag recommendation, suppose U3 wants to tag "Groundhog Day", a system based on the quaternary relationship would recommend the set of tags {"comedy", "excellent"}. Note that the tag ``overrated", which is one of the tags recommended based on the ternary relationship users-tagsitems, will not be recommended to U3. This is because we are able to infer from the quaternary relationship that U3 likes the movie "Groundhog Day" as it is a comedy. Since the tag "overrated" is associated with the rating "dislike", it is not a good tag to recommend for U3.
The above examples clearly illustrates the need to consider the quaternary relationship among users, tags, ratings, and items together. The quaternary relationships can reveal semantics that cannot be obtained otherwise. This is reinforced by the following observations:
1. Users may use the same tag for an item but have different ratings for it. For example, users U2 and U4 both use the same tag "comedy" on item "F orrestGump". However, user U2 likes the movie but U4 does not. Hence using tag information alone is insufficient.
2. Items may have multiple tags indicating their different facets. This could give rise to varied ratings, depending on the facet considered by the user. For example, "F orrestGump" is tagged as a "psychology" movie by

1024

user U1 and a "comedy" by U4. However, the movie may be not a good comedy movie as U4 dislike it. Yet this movie could be an interesting psychology movie since user U1 like it. In other words, rating information alone is insufficient.
3. Some tags may carry implicit semantics that can reveal the users' preferences. For example, user U2 tags movie "GroundhogDay" with the tag "excellent" implying that U2 likes the movie. Similarly, the tag "overrated" which is tagged by the user U4 will imply that U4 dislikes the movie "Toy Story". This observation tells us that the combination of tag and rating information gives extra insights into the users' preferences.
In order to capture the quaternary relationship among users, items, tags and ratings, we propose a model based on the 4-order tensor. We apply the Higher-Order Singular Value Decomposition (HOSVD) [11] in the 4-order tensor to reveal the latent semantic associations among users, items, tags and rating. With this model, we design a unified framework to perform item rating prediction as well as user, item and tag recommendations. We carry out experments on a real world dataset to demonstrate the effectiveness of our proposed approach. To the best of our knowledge, this is a first work to explore the use of the quaternary relationship among user, items, tags and ratings for recommendation tasks.
The rest of this paper is organized as follows. Section 2 provides the background on tensor operation and approximation. Section 3 presents the algorithm for quaternary semantic analysis. Section 4 describes the unified framework for user, item and tag recommendations as well as item rating prediction. Section 5 presents the experimental results. Related work is given in Section 6, and we conclude the paper in Section 7.
2. BACKGROUND
Tensor algebra and multilinear analysis have been applied successfully in many domains [9, 11]. In this section, we review the concepts and terminologies used in the paper.
A tensor is a multidimensional array. An N-order tensor A is denoted as A  RI1×···×IN with elements ai1...in and dimensions I1,I2, · · · IN .
For example, the corresponding 3-order tensor A for the example dataset in Table 4 is:
1 0 0 A(:, :, 1) =  0 0 0 
100
0 1 0 A(:, :, 2) =  0 0 0 
000
0 0 0 A(:, :, 3) =  0 0 1 
000
Definition 1. The matrix unfolding of an N-order tensor A = RI1×···×IN along the dimension d are vectors ob-

Table 4: Example dataset of a 3-order tensor

I1 I2 I3 element value

111

1

122

1

233

1

311

1

tained by keeping the index d fixed while varying the other indices.
The unfolding of our example 3-order tensor A along each dimension is:
1 0 0 0 1 0 0 0 0 A(1) =  0 0 0 0 0 0 0 0 1 
100000000

1 0 1 0 0 0 0 0 0
A(2) =  0 0 0 1 0 0 0 0 0  000000010

1 0 0 0 0 0 1 0 0
A(3) =  0 1 0 0 0 0 0 0 0  000001000

Note that the definition of the matrix unfolding involves the tensor dimensions I1, I2, I3 in a cyclic way. Hence, for the unfolding of dimension Ic × IaIb, the index Ib varies more slowly than Ia.

Definition 2. The n-mode product of a tensor A = RI1×···×IN by a matrix U = RJn×In , denoted by A ×n U , is a (I1 × I2 · · · In-1 × Jn × In+1 · · · × IN )-tensor where the entries are given by

(A ×n U )i1i2i3···in-1jn in+1···iN

=

a · u i1i2i3···in-1inin+1···iN

jn in

in

For example, the 1-mode product of a tensor A = R2×3×4 by a matrix U = R5×2, denoted as A ×1 U is an 5 × 3 × 4 tensor in which the entries are given by

2

(A ×1 U )ji2i3 =

aki2i3 · ujk

k=1

1j5

The Higher-Order Singular Value Decomposition (HOSVD) is a generalization of the Singular Value Decomposition (SVD) to higher-order tensors [11] and can be written as n-mode product:

A = S ×1 U (1) ×2 U (2) · · · ×N U (N)

where U (n) contain the orthonormal vectors (or n-mode singular vectors) spanning the column space of the A(n) (nmode matrix unfolding of A). S is the core tensor and has the property of all orthogonality.
Consider our example tensor A and its matrix unfolding A(1). We perform SVD on A(1) and obtain the resultant left singular matrix:

1025

 -0.85 0 0.53  U (1) =  0 -1 0 
-0.53 0 -0.85
1 0 0 U (2) =  0 1 0 
001

We can now construct the approximate core tensor S^  R2×3×3 using S = A ×1 (U^ (1))T ×2 (U^ (2))T ×3 (U^ (3))T :

S^(:, :, 1) =

-1.38 0 0 0 10

S^(:, :, 2) =

0 -0.85 0 000

1 0 0 U (3) =  0 1 0 
001
With this, the core tensor S  R3×3×3 can be constructed as described in [11]. We have S = A×1(U (1))T ×2(U (2))T ×3 (U (3))T where
 -1.38 0 0  S(:, :, 1) =  0 1 0 
-0.32 0 0

S^(:, :, 3) =

00 0 0 0 -1

Finally, we obtain the RANK-(2,3,3) approximation A^ = S^ ×1 U^ (1) ×2 U^ (2) ×3 U^ (3):
 1.2 0 0  A^(:, :, 1) =  0 1 0 
0.72 0 0

 0 -0.85 0  S(:, :, 2) =  0 0 0 
0 -0.53 0

 0 0.72 0  A^(:, :, 2) =  0 0 0 
0 0.45 0

0 0 0  S(:, :, 3) =  0 0 -1 
00 0

0 0 0 A^(:, :, 3) =  0 0 1 
000

Definition 3. The n-rank of tensor denoted by RN =

where ||A - A^||2F =0.618 which is minimized.

rankn(A), is the dimension of the vector space spanned

by the n-mode matrix We denote the rank of tensor A as rank(A) = (rank1(A) · · · , rankn(A))

3. QUATENARY SEMANTIC ANALYSIS

The main idea behind the quaternary semantic analy-

Definition 4. Given a tensor A = RI1×···×IN , the RAN K- (R1 · · · , RN ) approximation A^ is defined as minBS ||A - B||2F ,

sis is to capture the underlying relationships among userstags-items-ratings. Suppose we have a list of quadruples

S = {B||rank(B)  (R1 · · · , RN )} where ||A - B||2F is the

<u,t,r,v > denoting that a user u will provide tag t to a

least-square cost.6

movie v and give the rating r if he has watched v before.

We first model this list of quadruples as a 4-order tensor

Suppose we want to get the RANK-(2,3,3) approximation,

A  U × T × R × V , where U is the set of all users, V

we first retain the first ci column of matrix U (i) at mode i

the set of all items/resources, T the set of all tags and R

(1  i  3) as follows:

the set of ratings. An entry A(u, t, r, v) has a value 1 if the

 -0.85 0  U^ (1) =  0 -1 
-0.53 0

quadruple <u,t,r,v> exists, otherwise it has a value of 0. We reduce the rank of the original tensor to minimze
the effect of noise on the underlying population and reduce spareness. This is achieved by approximating the tensor A

1 0 0 U^ (2) =  0 1 0 
001

to a lower rank tensor. Given the dimensions of users, tags, ratings and items, namely, c1, c2, c3, c4, we want to obtain the RANK-(c1, c2, c3, c4) approximation of A^ such that the square frobenius norm defined as:

1 0 0 U^ (3) =  0 1 0 
001

I1

IN

||A^||2F =

···

A^(i1, · · · , iN )2

i1 =1 iN =1

6the square frobenius norm is defined as ||A||2F =

R1 i1 =1

·

·

·

RN iN =1

A(i1

·

··

, iN )2

is minimized. In our experiments, we set c1, c2, c3, c4 to preserve 70%,
90%, 80%, 90% of the original tensor information in each dimension respectively (see Section 5.6).

1026

3.1 Tensor Approximation Algorithm
Algorithm 1 shows the details for approximating a tensor. We first apply SVD on the four matrix unfoldings A(1), A(2), A(3), and A(4). Note that:

A(i) = U^ (i) · S (i) · (V^ (i))T ,

1i4

(1)

In order to obtain the left matrix of the SVD, we first define a matrix C i as follows:

C i = Ai · ATi ,

1  i  4,

(2)

Since each U^ (i) and V^ (i) are orthogonal and each S (i) is diagonal, we substitute (1) into (2):

C i = AiATi = (U^ (i) · S (i) · (V^ (i))T ) · (U^ (i) · S(i) · (V^ (i))T )T
= U^ (i)(S (i))2(U^ (i))T

Therefore, each required U (i) can be computed by diagonalizing each C i and taking its eigenvectors (Lines 3-4).

Algorithm 1 Quaternary Semantic Analysis
Input: List of quadruples < users, tags, rating, items>; Dimensions of users, tags, ratings and items c1, c2, c3, c4;
Output: Approximate Tensor A^;
1: Initialization: From the quadruple (users, items tag and rating), we construct tensor A  R|U|×|T |×|R|×|V |, where |U |, |V |, |T | and |R| are the number of users, items and tags and rating respectively
2: Calculate the matrix unfolding A(1), A(2), A(3), and A(4) from tensor A.
3: Construct the variance matrix C i = A(i)AT(i) for each mode 1  i  4
4: Compute U (i) by diagonalizing C i, 1  i  4
5: Remove the least significant rows |U |-c1, |V |-c2, |T |-c3 and |R| - c4 from U (1), U (2), U (3), and U (4), respectively. Denote the result as U^ (1), U^ (2), U^ (3), and U^ (4).
6: Calculate the approximate core tensor S^ as follows:
S^ = A ×1 (U^ (1))T ×2 (U^ (2))T ×3 (U^ (3))T ×4 (U^ (4))T

7: Approximate the original tensor by: A^ = S^ ×1 U^ (1) ×2 U^ (2) ×3 U^ (3) ×4 U^ (4)

Consider our example quaternary relations in Table 3. We initialize the the weights of the quadruples to 1, as shown in Table 5. A 4-order tensor A  R5×4×4×2 can be constructed from this table. For example, the first quadruple < U1, psychology, like, F orrestGump > will correspond to the entry A(1, 1, 1, 1)=1.
For each matrix unfolding A(i), 1  i  4, we compute U (i) as follows:

Table 5: Data of the tensor A

User

Tag

Rating

Item

Val

U1 psychology like

Forest Gump 1

U1 psychology like Beautiful Mind 1

U2

comedy

like

Forest Gump 1

U2 excellent

like Groundhog Day 1

U2

comedy

like Groundhog Day 1

U3

comedy

like

Forest Gump 1

U4

comedy

like

Forest Gump 1

U4

comedy dislike

Toy story

1

U4 overrated dislike

Toy story

1

U5

comedy dislike Forest Gump 1

U5 overrated dislike Groundhog Day 1

 -0.24 0.49 0 -0.82 0.15 

-0.48 -0.72 0 -0.36 -0.27





U (1) =  -0.29 -0.21 0 0.12 0.92 





 -0.79 0.38 0 0.42 -0.22 

0

010

0

 -0.25 0.95 -0.16 -0.11 

U (2)

=

 -0.93

 

-0.16

-0.19 -0.11

0.20 0.25

0.24 

-0.95

 

-0.20 -0.24 0.93 -0.19

 -0.95 0.25 0 0.20 

U (3)

=

 -0.17

 

-0.27

0.14 -0.96

0 0

-0.97 

-0.09

 

0

010

U (4) =

10 01

We maintain only a subset of the original dimensions in
each of the four modes (Line 5). Here, we choose c1 = 4, c2 = 4, c3 = 4, c4 = 2. The resulting U^ (i) are shown as follows:

 -0.24 0.49 0 -0.82 

-0.48 -0.72 0 -0.36

U^ (1)

=

  -0.29

-0.21

0

 0.12 





 -0.79 0.38 0 0.42 

0

010

 -0.25 0.95 -0.16 -0.11 

U^ (2)

=

 -0.93

 

-0.16

-0.19 -0.11

0.20 0.25

0.24 

-0.95

 

-0.20 -0.24 0.93 -0.19

 -0.95 0.25 0 0.20 

U^ (3)

=

 -0.17

 

-0.27

0.14 -0.96

0 0

-0.97 

-0.09

 

0

010

U^ (4) =

10 01

Lines 6-7 computes the approximate tensor A^. The final

1027

weights of the quadruples are shown in Table 6. We observe that the algorithm has added the following four quadruples:
<U3, comedy, like, Groundhog Day> <U3, excellent, like, Groundhog Day> <U3, comedy, dislike, Toy story> <U3, overrated, dislike, Toy story>
Note that user U3 has not used the tag "excellent" previously, and there is no indication on which item should be recommend to U3 based on the tags "comedy" and "excellent" in the original table (recall Table 5). However, the newly added quadruples indicate that the movie "Groundhog Day" is associated with user U3 and tags "comedy" and "excellent" with a weight of 0.25. Hence, the movie "Groundhog Day" will be recommended to U3.

Table 6: Output of the approximate tensor A^

User

Tag

Rating

Item

Val

U1 psychology like

Forest Gump 1.01

U1 psychology like Beautiful Mind 0.98

U2

comedy

like

Forest Gump 1.1

U2 excellent

like Groundhog Day 0.92

U2

comedy

like Groundhog Day 0.92

U3

comedy

like

Forest Gump 0.60

U4

comedy

like

Forest Gump 1.1

U4

comedy dislike

Toy story

0.95

U4 overrated dislike

Toy story

0.95

U5

comedy dislike Forest Gump

1

U5 overrated dislike Groundhog Day 1

U3

comedy

like Groundhog Day 0.25

U3 excellent

like Groundhog Day 0.25

U3

comedy dislike

Toy story

0.21

U3 overrated dislike

Toy story

0.21

We observe that latent associations such as the newly added quadruples in Table 6 may not be found if the tensor data is sparse, that is, most of the entries are 0. This problem is particularly acute as we are working with the quaternary relationship. We overcome this problem by applying a smoothing technique to Line 1 in Algorithm 1. The smoothing method is based on the similarity between items. For each user < u, r, t > in the tensor, let S1 be the set of items that are rated and tagged by user u, and S2 = V - S1 where V is the set of all items/resources. We assign < u, r, t, vj > with the overall similarly between item vj  S2 and the items in S1.
The overall similarity between item vj  S2 and the items in S1 can be calculated as follows:

SIM (vj , S1) =

viS1 sim(vi, vj ) |S1|

(3)

where sim(vi, vj ) is the cosine similarity between items vi and vj , assuming the items are represented by vectors of word weights.
The most time consuming steps in Algorithm 1 are the diagonalization of the unfolding matrices and the computation of the approximate core tensor. For real world applications involving large tensors, the work in [9] utilizes parallel architectures to optimize memory usage and reduce computation time. Note that the approximate tensor needs to be updated when we have new users, items, or tags. We adopt

the methods described in [20] to incrementally update the approximate tensor.
4. FRAMEWORK FOR RECOMMENDATION AND PREDICTION
In this section, we describe how the proposed quaternary semantic analysis can provide a unified framework for the 4 common tasks: item recommendation, item rating prediction, user recommendation and tag recommendation.
· User Recommendation.
This is achieved in the proposed framework as follows: We first initialize the set Q to be empty. For each quadruple < u, r, t, i > involving the target user u, we find the set of quadruples that have the same r, t, and i values and add them to Q. Next, we group the quadruples in Q according to the user and aggregate the weights for each user. The top N users with the highest weights are recommended to u.
· Item Recommendation.
Here, we assume that a user likes a movie if he/she has given a 5-star rating to the movie [10]. Let Tu be the set of tags that a user u has used to tag movies which s/he likes. For each item i in V , we compute its total weight
wi = A^(u, t, r, i)
tTu
Then we sort the items according to their wi and return the top N items with the highest weights.
· Tag Recommendation.
In our framework, the task of tag recommendation is reduced to examining the weights of the quadruples in the approximate tensor A^ which indicate how likely a user u would use the tag t for an item i if he has given the rating r before. Hence, we sort the quadruples involving u, r and i according to their weights and return the top N tags.
· Item Rating Prediction. We use the approximate tensor A^ to predict the item rating as follows. Let the rating scale be [1, Rmax]. Let Tu be the set of tags that a user u has used to tag movies. The rating that a user u will give to an item i such as ru,i (1  ru,i  5) is given by:

ru,i =

Rmax j=1

tTu j · A^(u, t, j, i)

Rmax j=1

tTu A^(u, t, j, i)

5. PERFORMANCE STUDY
We conduct experiments to evaluate the effectiveness of our proposed framework for item recommendation, item rating prediction and tag recommendation. We implemented our framework in MATLAB and run the experiments on a 2.33Ghz Intel Core 2 CPU with 4GB RAM, running Windows 7-64 bit.

1028

5.1 Experimental Dataset
We use the publicly available MovieLens dataset available at http : //www.grouplens.org/node/73. This dataset comprises of two files. The first file contains users' tags on different movies. The second file contains users' ratings on different movies on a scale of 1 to 5, with 1 being bad and 5 being excellent. By joining these two files over user and movie, we obtain the quadruples < user, movie, tag, rating >. We have a total of 24563 quadruples with 2,026 users, 5,088 movies, and 9,078 tags. We pre-process these quadruples to generate a subset such that each user, movie and tag occur at least 10 times in the dataset. The resulting dataset has 11122 tuples with 201 users, 501 movies, and 404 tags. Table 7 shows the statistics of the users' ratings after preprocessing.

Table 7: Statistics of rating data

Statistics

Users

Movies

Min. # of ratings

5

1

Max. # of ratings

203

58

Mean. # of ratings 32.58 ± 35.61 13.06 ± 8.67

QSA can find more accurate latent associations using quaternary relationships compared to ternary relationships of either users-items-ratings or users-items-tags. UPCC and IPCC find similar users or items (neighbors) by calculating Pearson correlation coefficient. If a user has few ratings for items, then it will be difficult for UPCC and IPCC to find neighbors. The PMF approach suffers from the data sparsity problem and is unable to extract sufficient feature information. On the other hand, TSA captures user's interest (topic) by using tag, but does not judge how much he likes these topics (rating). By utilizing quaternary relations, the proposed QSA overcomes the data sparsity problem and captures both users' opinions and interests with the rating and tagging information.

0.6

UPCC

IPCC

PMF

0.5

TSA

QSA

0.4

0.3

Hit Ratio

5.2 Experiments on Item Recommendation
We first evaluate the effectiveness of the proposed quaternary analysis model (QSA) for item recommendation. We compare our method with the following existing methods:
1. UPCC [16]. This method uses the Pearson's Correlation Coefficient to cluster similar users and recommend items based on these similar users.
2. IPCC [18]. This method uses the Pearson's Correlation Coefficient to cluster similar items for recommendation.
3. Probabilistic Matrix Factorization (PMF) [17]. This is a state-of-the art collaborative filtering algorithm that utilizes the ternary relationship among user, item and ratings.
4. Ternary Semantic Analysis (TSA) [20]. This method recommends items based on the ternary semantic analysis on users-items-tags.
We use the Hit Ratio [8] as the metric to evaluate the effectiveness of the various item recommendation methods. For each user u  U , we randomly choose one item i that has a rating of 5 and withhold the quadruples involving u and i. Then we run the 5 methods to generate the top N items recommended for this user. If the item i is among the top N recommended items, then we say that a hit has occurred. The hit ratio of a method is given by:

H itRatio

=

N umberof hits |U |

Figure 1 shows the hit ratio of the 5 methods as we vary N. We observe that the proposed QSA method has a higher hit ratio compared to the other methods. In particular, QSA outperforms TSA, PMF, IPCC and UPCC by more than 23%, 50%, 60% and 80% respectively. This is because

0.2

0.1

1

5

10

Top N

Figure 1: Hit ratio for Top N item recommendation

5.3 Experiments on User Recommendation
In order to evaluate the effectiveness of QSA in recommending interesting users, we determine the similarity of items among the recommended top N users [20] since users with shared interests are more likely to tag and rate similar items. We compute the item similarity as the average of the cosine similarity of their TF × IDF tag term vector [20] and cosine similarity of the rating vector [18].
Let N Bu be the set of top N users recommended to u. The intra-neighborhood similarity is given by the average cosine similarity of all items for the users in N Bu:

IntraSim(N Bu) =

wNBu iIu,jIw sim(i, j) wNBu |Iu||Iw|

where Iu and Iw are the sets of items tags by users u and w.

Let Randomu be the set of N users randomly chosen from the set of users U - {u}. We can determine the interneighborhood similarity as follows:

InterSim(Randomu) =

wRandomu iIu,jIw sim(i, j) wRandomu |Iv ||Iw|

where Iu and Iw are the sets of items tags by users u and w respectively.

1029

Table 8: Comparison of intra- and inter- similarity between QSA and TSA

Method Intra - similarity Inter - similarity

TSA

0.10

0.08

QSA

0.145

0.065

Table 8 shows the intra-similarity and inter-similarity of QSA and TSA. We observe that the average intra-similarity is consistently higher than the average inter-similarity for both QSA and TSA. In particular, QSA outperforms TSA in intra-similarity indicating that more relevant users are found by QSA. Table 8 shows that the average of intra-similarity for QSA is about 0.15, while the average inter-similarity is only 0.065.
5.4 Experiments on Tag Recommendation
For the task of tag recommendation, we evaluate our algorithm QSA against the two state-of-the-art methods: TSA [20] and RTF [15]. For each user u  U , we randomly choose one item i and remove all quadruples involving u and i from the dataset. Then we run the 3 methods to generate the top N tags recommended for this user.
We use the standard recall and precision measures to evaluate the results:

P recision

=

N umber of N

H its

Recall

=

N umber of |Tu,i|

H its

where Tu,i is the set of tags used by user u on item i.

Figures 2(a) and 2(b) show the precision and recall of the 3 methods for varying values of N. It is clear that QSA is able to achieve a higher recall and precision compared to the other two methods.
5.5 Experiments on Item Rating Prediction
In this set of experiments, we evaluate the predictive performance of QSA for item ratings. We compare QSA with UPCC, IPCC and PMF only because TSA is based on useritem-tag relationship and does not use rating information.
We use the Mean Absolute Error (MAE) and Coverage as the evaluation metrics [1]. Coverage refers to the fraction of items that an algorithm is able to give a predicted rating. The MAE is given by:

MAE =

tT |ru,i - r^u,i| |D|

where ru,i is the rating given by user u for item i, r^u,i is the predicted rating and D is the size of the testing dataset.

We use 80% of the dataset as training set and 20% as the testing set, and compute the MAE and coverage for different methods. The five-fold cross validation results are shown in Table 9. We observe that the coverage is not 100% for UPCC and IPCC, which confirms that these two methods are unable to deal with the problem of data sparsity effectively. On the other hand, QSA alleviates the data sparsity

Precision

0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 1

TSA RTF QSA

5

10

Top N

(a)

Recall

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2
1

TSA RTF QSA

5

10

Top N

(b)

Figure 2: Precision and recall for tag recommendation

problem with the help of tagging information, thus achieving 100% coverage with a lower MAE.
To analyze the statistical significance of the results, we conduct a paired t-test. Let ai, bi, i = 1, 2, · · · , n, be the MAE values obtained using methods A and B respectively. Let di = ai - bi and d¯ be the average value of di, i = 1, 2, · · · , n. We set the null hypothesis as d¯ = 0. The pvalue is computed using the t-statistics:
T = d¯ s/ n
where s is the standard deviation of d. A p-value that is less than 0.01 indicates the existence of statistically significant evidence against the null hypothesis. We compare the results of QSA against UPCC, IPCC and PMF and obtain the p-values of 3.52E-06, 4.02E-06 and 1.70E-03 respectively. These results indicate that the improvement in the MAE values for QSA is statistically significant compared to UPCC, IPCC and PMF.

1030

Table 9: MAE and Coverage

Method UPCC IPCC PMF QSA

M AE 0.7424 0.7458
0.692 0.673

C ov erag e 97.29% 98.05% 100% 100%

5.6 Effect of Tensor Dimensions on Item Recommendation
We also conduct experiments to study the effect of core tensor dimensions c1, c2, c3, and c4 on the performance of our algorithm QSA. We first vary each dimension to find the settings that give the best performance. This occurs when c1 = 45, c2 = 125, c3 = 165, c4 = 4.
For ease of visualization, we vary two of the four dimensions and keep the other two dimensions fixed at their optimal values. The results are shown in Figure 3. Figure 3(a) shows the effect on hit ratio as we vary c1 and c2 while keeping c3 fixed at 165 and c4 fixed at 4. Figure 3(b) shows the effect on hit ratio as we vary c1 and c3 while keeping c2 fixed at 125 and c4 fixed at 4. Figure 3(c) shows that results of varying c2 and c3 while c1 and c4 are fixed at 45 and 4 respectively. From the figures, we observe that a good approximation of the original diagonal can be achieved by preserving 70%, 90%, 80%, 90% of the original tensor information in each dimension respectively, that is, c1 = 45, c2 = 125, c3 = 165, c4 = 4.

6. RELATED WORK
In this section, we review the related work in the various recommendation tasks.
Item recommendation. Existing systems for item recommendation can be roughly divided into two major categories. Content-based systems [2, 14] make use of explicitly stated profiles of users or products to characterize their nature. On the other hand, systems based on collaborative filtering (CF) [18, 17] do not exploit such explicit user profiles. Instead, they infer the user profiles through their past activities, such as their transaction history or product satisfaction expressed in ratings. These systems rely only on the associations between users, ratings, and items. They cannot be easily used to consider the the quaternary relationship among users, items, tags and ratings.
Recent work has focused on using tags to recommend items. The work in [21] proposed a generic method to incorporate tags to CF algorithms. This is done by decomposing the users-tags-items relationship into 3 binary relationships, namely, users-tags, tags-items, and user-items. A fusion method is then applied to perform item recommendation. [19] tries to infer tag preferences and recommend items to users based on their tag preferences. Recently, a ternary semantics analysis approach [20] has been proposed to utilize the ternary relationship users-items-tags for recommendation. None of these works have utilized the associations among users, items, tags and ratings.
User recommendation. Social networking sites have adopted the simple strategy of suggesting friends-of-friends to increase the connectivity among their users. Recently, content-based approaches [7] were proposed to match the

content of user profiles and determine user similarities for recommendation. Research has also been done using known social network structures for recommendations. Groh et al. [4] generated user neighborhood information from known social network structures and demonstrated that collaborative filtering based on such neighborhoods outperforms classic collaborative filtering methods. The work in [20] proposed a ternary semantic analysis unified framework to perform user recommendation.
Tag recommendation. Personalized tag recommendation has attracted significant attention recently. The work in [6] provides a comprehensive evaluation and comparison of several state-of-the-art tag recommendation algorithms in three different real world datasets. Content-based collaborating filtering technique has been proposed in [13] to automate tag assignments to blogs. The works in [5, 20] have shown to generate high quality tag recommendations that outperform baseline methods such as the most-popular models and collaborative filtering [6].
Item rating prediction. There are three approaches to item rating prediction: user-based methods [12], itembased methods [18], and model-based methods [3, 17]. Userbased methods search for similar users and utilize the ratings of these similar users to make prediction, while item-based methods search for similar items and utilize the ratings of these similar items to make prediction. Model-based methods try to learn a model from the data using statistical learning techniques. All these approaches are based on tenary relationships.
7. CONCLUSIONS
In this work, we have shown that quaternary semantic analysis can lead to more accurate recommendation. We have proposed using a 4-order tensor to model the four heterogenous entities: users, items, tags and ratings. We further employed the higher order singular value decomposition to reduce the dimensionality of the 4-order tensor, thereby casting the recommendation problem as a multiway latent semantic analysis problem. Extensive experiments have been conducted on a real world dataset for item recommendation, user recommendation, tag recommendation, and item rating prediction. The results demonstrated that quaternary semantic analysis outperforms state-of-the-art algorithms in all the four tasks.
8. REFERENCES
[1] X. Amatriain, N. Lathia, J. M. Pujol, H. Kwak, and N. Oliver. The wisdom of the few: a collaborative filtering approach based on expert opinions from the web. In SIGIR, pages 532­539. ACM, 2009.
[2] M. Balabanovi´c and Y. Shoham. Fab: content-based, collaborative recommendation. Communications of the ACM, pages 66­72, March 1997.
[3] S. Funk. Netflix update: Try this at home.. sifter.org/simon/journal/20061211.html. 2006.
[4] G. Groh. Recommendations in taste related domains: Collaborative filtering vs. social filtering. In In Proc ACM Group 07, pages 127­136, 2007.
[5] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme. Folkrank: A ranking algorithm for folksonomies. In

1031

Hit Ratio Hit Ratio

0.2

0.18

0.16

0.14

0.12

0.1 130

125

48

46

120

44

42

Item

115 40

User

(a)

Hit Ratio

0.2 0.18 0.16 0.14 0.12
0.1 165

160

Tag

155 115

(c)

0.22

0.2

0.18

0.16

0.14

0.12 165

160 Tag

48

46

44

42

155 40

User

(b)

130 125 120
Item

Figure 3: Effect of core tensor dimensions on hit ratio

University of Hildesheim, Institute of Computer Science, pages 111­114, 2006.
[6] R. J¨aschke, L. Marinho, A. Hotho, S.-T. Lars, and S. Gerd. Tag recommendations in social bookmarking systems. AI Commun., 21:231­247, December 2008.
[7] C. D. M. M. Jilin Chen, Werner Geyer and I. Guy.. Make new friends, but keep the old: recommending people on social networking sites. In SIGCHI '09, pages 201­210, 2009.
[8] G. Karypis. Evaluation of item-based top-n recommendation algorithms. In CIKM, pages 247­254, 2001.
[9] T. G. Kolda and J. Sun. Scalable tensor decompositions for multi-aspect data mining. In ICDM, pages 363­372, 2008.
[10] Y. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In KDD, pages 426­434, 2008.
[11] L. D. Lathauwer, B. D. Moor, and J. Vandewalle. A multilinear singular value decomposition. SIAM J. Matrix Anal. Appl., 21:1253­1278, March 2000.
[12] G. Linden, B. Smith, and J. York. Amazon.com recommendations: item-to-item collaborative filtering. volume 7, pages 76 ­ 80, jan/feb 2003.
[13] G. Mishne. Autotag: a collaborative approach to automated tag assignment for weblog posts. In WWW '06, pages 953­954, 2006.
[14] R. J. Mooney and L. Roy. Content-based book recommending using learning for text categorization.

In In Proceedings Of 5th ACM Conference On Digtal Libraries, pages 195­204. ACM Press, 1999.
[15] S. Rendle, L. Balby Marinho, A. Nanopoulos, and S.-T. Lars. Learning optimal ranking with tensor factorization for tag recommendation. In KDD, pages 727­736, 2009.
[16] P. Resnick, N. Iacovou, M. Sushak, P. Bergstrom, and J. Riedl. Grouplens: An open architecture for collaborative filtering of netnews. In ACM Conference on Computer Supported Collaborative Work Conference, pages 175­186, 1994.
[17] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. Advances in Neural Information Processing Systems, pages 1257­1264, 2008.
[18] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. Item-based collaborative filtering recommendation algorithms. In WWW, pages 285­295, 2001.
[19] S. Sen, J. Vig, and J. Riedl. Tagommenders: connecting users to items through tags. In WWW, pages 671­680, May 2009.
[20] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. A unified framework for providing recommendations in social tagging systems based on ternary semantic analysis. IEEE TKDE, 22:179­192, February 2010.
[21] K. H. L. Tso-Sutter, L. B. Marinho, and L. Schmidt-Thieme. Tag-aware recommender systems by fusion of collaborative filtering algorithms. In SAC, pages 1995­1999, 2008.

1032

