A Toolkit for Knowledge Base Population

Zheng Chen, Suzanne Tamang, Adam Lee, Heng Ji
Computer Science Department Queens College and Graduate Center
City University of New York New York, USA
zchen1@gc.cuny.edu,{suzanne.tamang,duo1123}@gmail.com,hengji@cs.qc.cuny.edu

ABSTRACT
The main goal of knowledge base population (KBP) is to distill entity information (e.g., facts of a person) from multiple unstructured and semi-structured data sources, and incorporate the information into a knowledge base (KB). In this work, we intend to release an open source KBP toolkit that is publicly available for research purposes.
Categories and Subject Descriptors: H.3.4 [Information Storage and Retrieval]: Systems and Software
General Terms: Experimentation
Keywords: knowledge base population, toolkit
1. INTRODUCTION
A knowledge base is a centralized repository for information. Automatic knowledge base population by extracting entity information from large-scale unstructured text data has been shown to be a very challenging task in the recent TAC KBP program1. In KBP2010, 45 teams registered but only 23 submitted results, most probably because some basic analysis components are not available. Therefore, we are distributing a toolkit based on our KBP system which achieved highly-competitive performance in KBP2010. The toolkit is able to not only set up a baseline KBP system for the default task defined in KBP2010 (extracting facts for pre-defined persons or organizations), but also facilitate the development of techniques and customization in distilling diversified new entity or attribute types (e.g., product KB for firms, medicine KB for pharmacies).
2. TOOLKIT OVERVIEW
Our toolkit aims to deal with the following challenges: (1) unstructured information extraction, which requires to distill various entity facts (attribute-value pairs) from multiple unstructured and semi-structured data sources. In KBP2010, we developed three pipelines including pattern matching, supervised classification based Information Extraction (IE) and Question-Answering based [1]. We choose pattern matching as our baseline technique in the toolkit, because it can be easily customized to distill information for new types of entities and attributes. In contrast, the other two pipelines require domain-specific resources and domain
1http://nlp.cs.qc.cuny.edu/kbp/2010/
Copyright is held by the author/owner(s). SIGIR'11, July 24­28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

knowledge, and we provide a general platform which allows developers to add or customize new functionalities.
(2)entity integration, which requires to resolve and merge references to the same real-world entity. There are two main difficulties, one is that entities can be referred to by multiple name variants (e.g., aliases, acronyms), and the other is that names can be ambiguous. For the former difficulty, we implemented a name expansion component which identifies name variants [1]; for the latter, we employed different strategies to disambiguate names.
(3)scalability, which requires easy integration of new components, reasonable processing speed with large-scale corpora. Keeping this in mind, the toolkit is implemented to be modular and configurable. The toolkit itself integrates many other useful IE and Wikipedia analysis tools.

3. APPLICATION
To visualize the information stored in the KB, we demonstrate a web-based application which automatically augments recognized entities in a web page with links. As shown in Figure 1, if the user clicks the link of entity "Aaron Rodgers", a popup window will show the facts retrieved from KB.

ARLINGTON, Tex. -- When the Green Bay Packers watched Aaron

Rodgers sit inAtahroengRreoedngerrosom as he plummeted down the first round

of the 2005 draft, they noted his poise at dealing with his agonizing

plight.

Date of birth: December 2, 1983 (1.0*)

Place of birth: Chico, California (0.8)
The Packers had already done extra

Title: footballer (1.0)
research on Rodgers when they heard

Employer: Green Bay Packers (1.0)
the predraft buzz that he might drop,

* confidence score
and those long moments under the

klieg lights only reassured them that

he might be able to handle what was

to come.

Figure 1: Snapshot of application

4. ACKNOWLEDGMENTS
This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement Number W911NF09-2-0053, the U.S. NSF CAREER Award under Grant IIS0953149, PSC-CUNY Research Program.
5. REFERENCES
[1] Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li, Marissa Passantino, and Heng Ji. Top-down and bottom-up: A combined approach to slot filling. In Proceedings of Asia Information Retrieval Societies Conference (AIRS2010), 2010.

1267

