Collaborative Cyberporn Filtering with Collective Intelligence

Lung-Hao Lee and Hsin-Hsi Chen
Department of Computer Science and Information Engineering National Taiwan University Taipei, Taiwan
{d98922011, hhchen}@ntu.edu.tw

ABSTRACT
This paper presents a user intent method to generate blacklists for collaborative cyberporn filtering. A novel porn detection framework that finds new pornographic web pages by mining user search behaviors is proposed. It employs users' clicks in search query logs to select the suspected web pages without extra human efforts to label data for training, and determines their categories with the help of URL host name and path information, but without web page content. We adopt an MSN porn data set to explore the effectiveness of our method. This user intent approach achieves high precision, while maintaining favorably low false positive rate. In addition, real-life filtering simulation reveals that our user intent method with its accumulative update strategy achieves 43.36% of blocking rate, while maintaining a steadily less than 7% of over-blocking rate.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information filtering.
General Terms
Experimentation, Human Factors
Keywords
Query log analysis, pornographic blacklists, searches-and-clicks.
1. INTRODUCTION
Filtering the wide spreading objectionable web content, e.g., pornography, violence, drug and gambling, has attracted intensive attention for child protection or anyone else from inappropriate materials. URL blocking relies on a blacklist to reject undesirable requests [2]. Content analysis selects features from text, image, and linking structure for training pornography classifier [1]. The URL-based features were empirically shown as an effective approach for correctly identifying pornographic websites [4]. Moreover, query-URL click pairs were also exploited for clustering the similar pornographic images [3].
Different from web content and structure mining in the past work, we only exploit implicit collective intelligence from query logs for web usage mining. Filtering cyberporn is challenging due to its variability. Traditional filtering techniques regard this problem as categorization with statically crawled data sets. Since it is difficult to know the actual changing trail of objectionable web content, we attempt to explore those successfully accessed in search query logs to keep up with the change of the web approximately. Our user intent model can capture the newlyappearing objectionable web content or the variants of the original
Copyright is held by the author/owner(s). SIGIR'11, July 24­28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

ones for avoiding being filtered, if someone has visited them via searches-and-clicks.
2. USER INTENT MODEL
Submitting queries to search engines and clicking search results, two common operations in daily life, provide implicit tagging on web pages. We employ click data in search query logs to classify web pages and generate a pornographic blacklist based on user intents. The algorithm is composed of 3 stages: (1) query identification, (2) majority voting, and (3) category recognition.
In query identification stage, the user intent model identifies suspected queries along with their clicked URLs from search query logs with a lexicon. The lexicon is constructed automatically as follows. We first select terms from the catalog of pornographic web sites as seed queries, and then regard any five seeds as a combination for term expansion by Google Sets. In total, there are 410 expanded terms and seeds in the lexicon for suspected query identification.
In majority voting stage, we count the clicks of a page for the same queries issued within a time period, e.g., one month, and identify the URL candidates which satisfy either one of the majority rules proposed as follows. (1) Absolute majority rule: A URL is selected if its total number of clicks is more than a half of total issues of a query. The physical meaning of this rule is: users' clicks on a URL show that the URL has similar intents in more than a half of query submissions. (2) Relative majority rule: A URL is selected if its total number of clicks is more than the average number of clicks among all URLs. The physical meaning of this rule is: a URL with higher tendency to be clicked than other URLs will be more related to the query.
In category recognition stage, we use words in hostname and path to tell out different intents. A candidate whose URL contains at least one categorical keyword will be proposed. A categorical keyword set is formulated automatically as follows. We first employ the blacklist released publicly in URLBlacklist.com to collect categorical keywords common used in URLs of pornographic web pages, then remove "http://" and "/" from URLs, further segment the remaining part of host name and path into all possible n-grams, and finally compose a 172-categoricalkeyword set by consulting a pornographic dictionary.
Besides, we also propose an accumulative update strategy, i.e., to use all query logs up to now, to explore the change of collective intelligence and update the blacklist. The accumulative time periods imply that the same query can be issued at different time and different search results may be clicked by users with similar intents. The newborn objectionable web pages or the variants of

1153

the original ones for avoiding being filtered can be included in the updated blacklist if users have accessed them with similar intent.

3. EXPERIMENTS
3.1 Data Sets
The data set comes from the MSN 2006 RFP data. It consists of an MSN search query log excerpt with 15 million queries from US users during May 2006. Data made available include the issued queries, the clicked URLs and the time-stamps. We randomly selected 1% of MSN search query logs and removed those queries issued only once. After sampling, we manually labeled the pages as ground truth by examining their contents. Those pages which could not be accessed successfully at the labeling time were ignored. The numbers of unique queries issued in our testing data set are 43,198. Total 5,821 and 10,135 unique URLs are annotated in porn and non-porn categories, respectively.

3.2 Experimental Results
To examine the effects of the three stages in user intent model, i.e., (1) query identification, (2) majority voting, and (3) category recognition, we experiment different combinations of stages on the testing data set, where the time period is set to one month. Table 1 shows the experimental results. Strategy (1) achieves the highest recall, but a very bad false positive rate and precision. It reveals the category of queries does not always represent the category of web pages. Comparing Strategies (1)+(2) and (1)+(3), category recognition in URLs performs better than majority voting, due to clear categorical keywords of host names and paths in URLs. The disadvantage of majority voting is that even the same query was issued, different search results were proposed by search engines at different time.

The proposed user intent model, i.e., Strategy (1)+(2)+(3), performs the best. It achieves high precisions of 0.7418, while maintaining favorably low false positive rate 0.0707. We analyze the reason of lower recall, and find that the number of clicks will be distributed among different URLs of the same pornographic content. In such a case, the clicks cannot satisfy any majority voting rules. Because pornographic content is the major target for objectionable web content filtering, the content providers tend to create more hosts and redirections to avoid being filtered.

Table 1. Experimental results of MSN RFP data set

Strategy
(1) (1)+(2) (1)+(3) (1)+(2)+(3)

Precision
0.5669 0.6057 0.6941 0.7418

Recall
0.8505 0.4485 0.6628 0.3539

False Positive Rate
0.3732 0.1677 0.1677 0.0707

Comparing Strategies (1) and (1)+(2)+(3), the former is an aggressive method for achieving a higher recall without concerning false positive rate; and the latter is a conservative method in which false positive rate is an important consideration. The user intent method achieves the lowest false positive rate of all the four methods. Obviously, this method is more proper to incorporate collective intelligence to search engines to mask pornographic search results before they are clicked.

We further evaluate the filtering effects by real-life simulation using query logs. Figure 1 shows the blocking rates of three update strategies when time period is set to one day. The without

update strategy, i.e., query logs of the first time period are used to generate a blacklist, performs the worst. Its blocking rate decreases with the passage of the time. The preceding update strategy, which iteratively updates a blacklist with the query logs of the preceding time period, performs better than the without update strategy because similar search results will be reported for the same query with similar intent in the following day. The accumulative update strategy achieves the macro-averaging blocking rate 43.36%, which is better than 28.44% and 20.56% with the preceding update and the without update strategies, respectively. In addition, its blocking rates vary between 40% and 50% with standard deviation 0.04. The over-blocking rate, which is the proportion of normal accesses incorrectly blocked as pornographic ones, of all the three strategies is less than 7%.
Figure 1. Blocking trend if update frequency is one day.
4. CONCLUSIONS AND FUTURE WORK
This paper proposes a simple but effective intent-based method for cyberporn filtering. Query ambiguity is a challenging issue for intent-based approach. Alternative suspected query identification methods such as considering a porn dictionary as seed queries will be investigated in the future for improving filtering performance.
5. ACKNOWLEDGEMENTS
This research was partially supported by National Science Council, Taiwan under grant NSC99-2221-E-002-167-MY3. We are also grateful to Microsoft Research Asia for the support of MSN Search Query Log excerpt.
6. REFERENCES
[1] Hammami, M., Chahir, Y., and Chen, L. 2006. WebGuard: a web filtering engine combining textual, structural, and visual content-based analysis. IEEE Transactions on Knowledge and Data Engineering, 18(2), 272-284.
[2] Lee, L.-H., and Luh, C.-J. 2008. Generation of pornographic blacklist and its incremental update using an inverse chisquare based method. Information Processing and Management, 44(5), 1698-1706.
[3] Szummer, M. and Craswell, N. 2008. Behavioral classification on the click graph. In Proceedings of the 17th International World Wide Web Conference, 1241-1242.
[4] Zhang, J., Qin, J., and Yan, Q. 2006. The role of URLs in objectionable web content categorization. In Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence, 277-283.

1154

