Integrating Hierarchical Feature Selection and Classifier Training for Multi-Label Image Annotation

Cheng Jin
School of Computer Science Fudan University, P. R. China
jc@fudan.edu.cn

Chunlei Yang
Dept of Computer Science
UNC-Charlotte, NC, USA
cyang36@uncc.edu

ABSTRACT
It is well accepted that using high-dimensional multi-modal visual features for image content representation and classifier training may achieve more sufficient characterization of the diverse visual properties of the images and further result in higher discrimination power of the classifiers. However, training the classifiers in a high-dimensional multi-modal feature space requires a large number of labeled training images, which will further result in the problem of curse of dimensionality. To tackle this problem, a hierarchical feature subset selection algorithm is proposed to enable more accurate image classification, where the processes for feature selection and classifier training are seamlessly integrated in a single framework. First, a feature hierarchy (i.e., concept tree for automatic feature space partition and organization) is used to automatically partition high-dimensional heterogeneous multi-modal visual features into multiple lowdimensional homogeneous single-modal feature subsets according to their certain physical meanings and each of them is used to characterize one certain type of the diverse visual properties of the images. Second, principal component analysis (PCA) is performed on each homogeneous singlemodal feature subset to select the most representative feature dimensions and a weak classifier is learned simultaneously. After the weak classifiers and their representative feature dimensions are available for all these homogeneous single-modal feature subsets, they are combined to generate an ensemble image classifier and achieve hierarchical feature subset selection. Our experiments on a specific domain of natural images have also obtained very positive results.
Categories and Subject Descriptors I.4.8 [Image Processing and Computer Vision]: Scene Analysis-object recognition, H.2.8 [Database Management]: Database Applications - image databases.
General Terms Algorithms, Measurement, Experimentation
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'11, July 24­28, 2011, Beijing, China. Copyright 2011 ACM 978-1-4503-0757-4/11/07 ...$10.00.

Keywords: Feature hierarchy, SVM image classifier, hierarchical feature selection, boosting.
1. INTRODUCTION
When large-scale image collections come into view, automatic detection of object classes and image concepts may provide more effective solutions for image indexing and retrieval [23, 5, 26, 12]. Image classification is one of the potential solutions for automatic detection of object classes and image concepts from large-scale image collections. Thus achieving more accurate training of the image classifiers plays an important role in supporting multi-label image annotation and semantic image retrieval via keywords [8, 14, 30, 11, 17, 35, 34, 1, 29, 32, 7, 3, 16]. However, the performance of the image classifiers largely depends on two inter-related issues: (1) high-dimensional multi-modal visual features for characterizing the diverse visual properties of the images more sufficiently; (2) effective algorithms for achieving more accurate training of the image classifiers and selecting more representative feature subsets automatically.
Many image classification algorithms have been proposed in the literature [8, 14, 30, 11, 17, 35, 34, 1, 29]. Ideally, using more visual features for image content representation and classifier training has more capacity to characterize various visual properties of the images effectively and efficiently. This may further enhance the classifier's ability on detecting different image concepts and object classes and result in higher classification accuracy. However, learning the image classifiers in a high-dimensional multi-modal feature space requires a large number of labeled training images and generally increases exponentially as the feature dimension increases (i.e., curse of dimensionality). When only a limited number of labeled training images are available, there is an urgent need to develop new techniques that are able to achieve accurate training of the image classifiers by using a small number of labeled training images. One promising approach is to select the most representative feature subsets and train the image classifiers simultaneously.
To select the optimal feature subsets for classifier training, many feature selection algorithms have been proposed and they can generally be classified into two categories: filter and wrapper [33, 18, 13, 28, 20, 24]. A filter algorithm separates the procedures for feature selection and classifier training by merely calculating the ranking information for each feature dimension based on its correlation score with the given image concept or object class. On the other hand, a wrapper algorithm wraps the procedure for feature selection with the procedure for classifier training. However, both the fil-

515

ter and wrapper approaches ignore the feature hierarchy and the heterogeneity of high-dimensional multi-modal visual features. They perform feature selection directly in the high-dimensional multi-modal feature space and thus they require a large number of labeled training samples to achieve reliable feature selection. Recently, Viola et al. have developed a new feature selection approach by using AdaBoost to train a cascade of linear classifiers [29], which can be treated as a new wrapper-based approach. Each weak classifier depends on only one-dimensional single-modal Harr feature and thus the correlation among the multi-modal visual features has been ignored completely.
By incorporating the feature hierarchy for automatic feature space partition and organization, our solution is to automatically partition the high-dimensional heterogeneous multi-modal feature space into multiple low-dimensional homogeneous single-modal feature subsets according to their certain physical meanings and perform classifier training in each homogeneous single-modal feature subset simultaneously. The advantages of our proposed framework include:
(a) Partitioning the high-dimensional heterogeneous multimodal feature space into multiple low-dimensional homogeneous single-modal feature subsets according to their certain physical meanings can scale up SVM image classifier training significantly because the number of the labeled training images (that are required for classifier training in a lowdimensional homogeneous single-modal feature subset) is reduced dramatically;
(b) Different homogeneous single-modal feature subsets are used to characterize different principal visual properties of the images, thus the corresponding weak classifiers are diverse, complementary and can be combined to generate an ensemble classifier with higher prediction accuracy;
(c) It can support more effective kernel function selection because the geometric property for the distribution of the images in each homogeneous single-modal feature subset can effectively be approximated by using RBF kernel functions;
(d) It can significantly reduce human efforts on labeling large-scale training images by incorporating unlabeled images and feature hierarchy for SVM classifier training, and it is able to boost the image classifiers significantly and result in higher classification accuracy;
(e) It is able to select the most representative feature subsets for different object classes and image concepts and speed up the process for image classification significantly. It also has good scalability with the sizes of the image concepts (object classes) and the feature dimensions.
The major differences between our new approach and the technique proposed in [29] are: (1) feature correlation is exploited to enable more accurate classifier training; (2) ensemble classifier is learned by boosting both the labeled training images and the multi-modal visual features.
This paper is organized as follows: Section 2 introduces our feature extraction framework; Section 3 presents our new framework for joint classifier training and feature selection; Section 4 gives our extensive experimental results on multilabel image annotation; We conclude this paper in Section 5.
2. AUTOMATIC FEATURE EXTRACTION
There are three widely accepted image patterns for image content representation and feature extraction [23]: (a) region-based approach by using homogeneous image regions

for feature extraction; (b) scene-based approach by treating whole image as single visual pattern for feature extraction; (c) object-based approach by using image objects for feature extraction.
The major problem for the region-based approach is that there is no accurate correspondence between the image semantics and the homogeneous image regions, and thus the region-based visual features may not be able to detect various image concepts accurately. On the other hand, one single image may consist of multiple object classes, thus the image-based global visual features may not be able to detect the object classes accurately. Using the semantic objects for feature extraction is able to improve the quality of the visual features significantly and result in the image classifiers with higher discrimination power. The major problem for the object-based approach is that automatic object extraction is generally difficult because homogeneous image regions in color or texture do not correspond to the semantic objects directly.
Based on these observations, we believe that it is very important to develop a middle-level framework for achieving semantic-sensitive image content representation, which is able to enhance the quality of the low-level visual features and the discrimination power of the image classifiers. In addition, this middle-level framework should be able to reduce the cost for object extraction and feature extraction. Based on this understanding, we use image Blobs for image content representation and feature extraction. The image blobs are defined as the groups of the neighboring image regions which may have similar color or texture [5].
To detect the image blobs automatically, we use an automatic image segmentation technique that is developed by Deng and Majunanth [6]. The neighboring homogeneous image regions with similar colors or textures are then merged as semantic-sensitive image blobs for image content representation and feature extraction.
After the image blobs are formed, we extract 83-dimensional multi-modal visual features to characterize their multi-modal visual properties of the images. These 83-dimensional heterogeneous multi-modal visual features include: 7-dimensional R,G,B average colors and their variances, 7-dimensional L,U,V average colors and their variances, 62-dimensional texture feature from Gabor filter banks and 7-dimensional Tamura texture. It is worth noting that all these 83-dimensional heterogeneous multi-modal visual features can be organized more effectively by using a feature hierarchy, i.e., multiple homogeneous single-modal feature subsets with certain physical meanings and each feature sunset consists of multiple feature dimensions. To reduce the number of labeled training images that are required for achieving accurate SVM classifier training, all these 83-dimensional heterogeneous multi-modal visual features are automatically partitioned into multiple low-dimensional homogeneous singlemodal feature subsets according to their certain physical meanings. The feature dimensions in the same homogeneous single-modal feature subset share the same physical meaning, and each homogeneous single-modal feature subset is used to characterize one certain type of the diverse visual properties of the images. Obviously, different image concepts and object classes may have different representative feature subsets. Thus it is very important to develop new techniques that are able to select the most representa-

516

tive feature subsets for different image concepts and object classes.

Table 1: The optimal parameter pairs (C¯, ¯) of the SVM classifiers for some object classes.

In our experiments, all these 83-dimensional heterogeneous multi-modal feature space are automatically parti-

object classes C¯

grass 10

purple flower 6

red flower 32

tioned into 9 homogeneous single-modal feature subsets ac-

¯

1.0

0.5

0.125

cording to their certain physical meanings: 3-dimensional object classes

rock

sand field

sky

R,G,B average color; 4-dimensional R,G,B color variances; 3-dimensional L,U,V average color; 4-dimensional L,U,V color variances; 2-dimensional average & standard deviation of Gabor filter bank channel energy; 30-dimensional Gabor average channel energy; 30-dimensional Gabor channel energy deviation; 2-dimensional Tamura texture features (coarse &

C¯ ¯
object classes C¯ ¯

32 2
snow 512
0.03125

8 2
water 2
0.5

8192 0.03125
sunset 8
0.5

contrast), and 5-dimensional angel histogram derived from

Tamura texture. Thus the heterogeneous multi-modal visual

features are organized effectively by using two-level feature hierarchy: (a) multiple homogeneous single-modal feature

cj = {Xl, Yl|l = 1, · · · , NL} and the negative images. Each labeled training image is represented by (Xl, Yl), where Xl

subsets with certain physical meanings; (b) multiple visual

stands for 83-dimensional blob-based multi-modal visual fea-

features for each homogeneous single-modal feature subset

tures , and Yl, the semantic label. The unlabeled images are

that share the same physical meaning.

denoted as Omegacj . The weak classifier for each homogeneous single-modal

3.

FEATURE

SUBSET

SELECTION

AND

feature subset is first learned by using
CLAS-pairs in cj , a pair of transformation

only cj . For parameters W

each and

SIFIER TRAINING

b exists that satisfies f (Xl) = Yl(W · (Xl) + b)  +1,

In order to reduce the number of labeled training images that are required for achieving accurate classifier training, we propose a new framework to enable hierarchical feature subset selection, where a weak classifier is learned for each homogeneous single-modal feature subset. Because the dimensions for each homogeneous single-modal feature subset are relatively low, we can use a smaller number of labeled training images to learn the weak classifier accurately. The weak classifiers, which are learned from different homogeneous single-modal feature subsets, are then combined to generate an ensemble classifier for achieving more accurate image classification.
By incorporating the feature hierarchy for automatic feature space partition and organization, our lab developed a novel hierarchical algorithm to seamlessly integrate classifier

where (Xl) maps Xl into higher-dimensional space. The kernel function is defined as (Xi, Xj) = (Xi)T (Xj).

The radial basis function (RBF) is selected, (Xi, Xj) = exp(-||Xi - Xj||2),  > 0. These two supporting planes have a margin of 2/||W ||2. The weak SVM classifier is

then designed to maximize the margin with the constraints

f (Xl) = Yl(W · (Xl) + b)  +1 for the positive images

(Yl = +1) and negative ones (Yl = -1).

The margin maximization procedure can be done by the

following optimization task with the set of cj :

{

}

min

1 2

W

2

+

C

 NL

l

(1)

l=1

subject to:

training and hierarchical feature selection in a single framework [11]: (a) The weak classifiers for all these 9 homoge-

Nl=L1 : Yl(W · (Xl) + b)  1 - l

neous single-modal feature subsets are learned simultaneously and principal component analysis (PCA) is used to exploit the feature correlation and select the most representative feature components for each homogeneous single-modal feature subset (i.e., in-set feature selection); (b) The weak classifiers are combined to boost an ensemble classifier, and feature subset selection is achieved by selecting the most effective weak classifiers and the corresponding homogeneous single-modal feature subsets (i.e., inter-set feature selection). Different from [11], which focuses on Grid representation of the feature set, we select features using its self-proved robustness.
Support vector machine (SVM) is used to learn weak classifiers [27, 21, 15, 2], while Adaboost is used to learn the ensemble classifier from combination of weak classifiers [10, 9]. Bagging proposed by Breiman [4] is also a candidate for ensemble classifier learning. Some experiments have shown that AdaBoost sometimes outperforms Bagging. Thus, we use AdaBoost for weak classifier combination.
3.1 Weak Classifier Training

where l  0 is the training error rate, C > 0, the penalty

parameter In order

and

1 2

W

2

,

to determine

the regularization the optimal model

term. parameters

(C¯

,

¯)

for the weak SVM classifiers, an algorithm was designed as

follows: (a) Images in cj are partitioned into  groups in equal size, -1 groups for classifier training, the residual one

for validation. (b) The visual features for each homogeneous

single-modal feature subset are firstly normalized to avoid

numerical problem. (c) The numeric ranges for C and  are

coarsely partitioned into small pieces with M pairs.  - 1

groups are used to train the classifier for each pair. When

the M classifier models are available, the underlying optimal

parameter pair (C, ) is determined via cross-validation. (d)

When (C, ) at the coarse level is available, a fine partition

of the search space around it is used to determine more accurate parameter pair (C¯, ¯) in a hierarchical way. (e) With the optimal parameter pair (C¯, ¯), the final model for

the weak SVM classifier is trained again by using the whole

set of training images. Table 1 and 2 shows the optimal parameter pairs (C¯, ¯) for some object classes and semantic

concepts.

For a given image concept or object class Cj, we use

To select the most representative feature components for

one-against-all rule to label the positive training images

weak classifier training, for a given homogeneous single-modal

517

Table 2: The optimal parameter pairs (C¯, ¯) of the SVM classifiers for some image concepts.

semantic concepts C¯
¯

mountain view 512
0.0078

beach 32
0.125

garden 312
0.03125

semantic concepts C¯
¯

sailing 56
0.625

skiing 128 4

desert 8 2

feature subset Sj, PCA is used to exploit the feature correlation and enable in-set feature selection as follows: (1) PCA is used to determine its feature components, which are ranked based on the values of their Eigenvalues. (2) The unrepresentative feature components with small Eigenvalues are sequentially removed from Sj, and the residual ones are used for learning a new weak classifier, which is then tested on the validation image set, and the relevant loss function LSj (Xn, Yn) = |f (Xn)-Yn| is also calculated. (3) the goodness for Sj is defined as:

1  N

G(Sj) = 1 - N

LSj (Xn, Yn)

(2)

n=1

(4) The above procedure is performed repeatedly until the goodness of Sj is below a pre-defined threshold. (5) The results will be used as the inputs for ensemble classifier training.

3.2 Classifier Training using Unlabeled Images

In order to achieve accurate image classifiers, it is some-

times too expensive to manually label large amounts of train-

ing images. When this is concerned, semi-supervised classi-

fier training becomes a promising solution to take advantage

of unlabeled images [15, 2, 19, 25, 31].

To incorporate the unlabeled images cj for semi-supervised training of the weak SVM classifiers, an incremental frame-

work was developed to predict labels for images in cj . A hyperplane < W, b > is then estimated by the framework,

which separates cj and cj with maximum margin [27, 21]. Thus the semi-supervised training of SVM classifier

can be formulated as:

M in

{

1 2

||W

||2

+

C

 NL

i

+

C

 Nu

} j

(3)

i=1

j=1

subject to:

{ Ni=L1 : Yi[W · (Xi) + b]  1 - i, i > 0 Nj=u1 : Yj[W · (Xj) + b]  1 - j, j > 0

(4)

When the number of unlabeled images is small, the training work can be solved simply by trying all possible label assignments for images in cj . However, this will become too expensive and the outlying unlabeled images may mislead the classifiers when the number gets larger.
In order to solve this, an incremental framework was developed for semi-supervised training of the SVM classifiers, which takes the following major steps: (1) For a given image concept or object class, a weak SVM classifier is first learned from cj as introduced in Section 3.1. (2) the classifier is then used to predict the labels for images in cj , while the confidence score for the label of the unlabeled

Figure 1: The SVM boundaries that are obtained by a batch-based training approach when all training samples are available at the batch.

image Xj is calculated by applying an additional sigmoid function [21]:

P (Xj)

=

1 1 + ef (Xj)+

(5)

where f (Xj) is the output of the weak SVM classifier for Xj,  and  can be determined by minimizing the negative log-likelihood (NLL) function on the validation image set. The value of P (Xj) is used to determine whether or not the unlabeled image Xj will be removed from the set through a pre-defined threshold. (3) A new SVM classifier can then be learned incrementally with all the remaining high-confident unlabeled images . (4) Considering the small shift of the hyperplane from previous step, the new SVM classifier is used to predict new labels for these high-confident unlabeled images. Images with inconsistent predicted labels are restored as the unlabeled images. (5) By integrating unlabeled images with consistent predicted labels for incremental classifier training, our incremental algorithm is performed repeatedly until it converges.
A two-dimensional synthetic data set is used to visualize and show the convergence of our incremental framework for semi-supervised SVM classifier training. As discussed in [22], this synthetic data set has two classes with two attributes, each class has a bimodal distribution which is formed by equal mixture of two normal distributions, and two normal distributions share the same covariance matrix. By treating this synthetic data set as an example, we have experimentally obtained the convergence of our incremental framework for semi-supervised SVM classifier training as shown in Fig. 1 and Fig. 2. From our experimental results, one can observe that our incremental framework for semi-supervised SVM classifier training finally converges to the same decision boundaries that are obtained by the batch-based training approach. The theoretical proof of the convergence for incremental SVM classifier training can be found at [27].

3.3 Two-Level Feature Selection and Ensemble Classifier Training
AdaBoost is used for weak classifier combination too enable both a two level feature selection and ensemble classifier training. Feature selection is performed at two different levels simultaneously and accurate image classifiers are learned by using a small number of labeled images. At the first level,

518

Figure 2: The SVM boundaries that are obtained by our incremental framework for SVM classifier training after it converges.

each visual feature dimension can be treated as a selection

unit. PCA is used to select the most representative feature

components. At the second level, each homogeneous single-

modal feature subset is treated as an individual selection

unit, whose goodness is measured by estimating the perfor-

mance of the relevant weak classifier on the cross-validation

image set. Thus, the most effective weak classifiers and

their corresponding homogeneous single-modal feature sub-

sets form the inter-set feature selection at the second

level.

The process for inter-set feature selection at the second

level can be treated as a process for ensemble classifier train-

ing, where AdaBoost can be used to boost the relevant weak

classifiers:

{

}

9  T

9  T

H(X) = sign

tj ftj (X) ,

jt = 1 (6)

j=1 t=1

j=1 t=1

where ftj(X) is the weak classifier for the jth homogeneous single-modal feature subset Sj at the tth iteration, and T is the total number of iterations. Higher prediction accuracy can be expected since the ensemble classifier combines the predictions of the weak classifiers and boosts the results. The homogeneous single-modal feature subsets corresponds to the most effective weak classifiers are then selected for image classification.
Compared with previous works, the advantages of our proposed work include: (a) Incorporating the feature hierarchy and feature subset selection for SVM classifier training can speed up SVM classifier training significantly because the number of the labeled training images is reduced dramatically for each low-dimensional homogeneous single-modal feature subset; (b) Partitioning the heterogeneous multimodal feature space into multiple homogeneous single-modal feature subsets automatically can support more effective kernel function selection because the geometric property of the distribution of the images in each homogeneous single-modal feature subset can be effectively approximated by using RBF functions; (c) Incorporating the unlabeled images for semisupervised SVM classifier training can significantly reduce human efforts on labeling large-scale training images while achieving higher classification accuracy; (d) Our boosting algorithm is able to simultaneously boost both the training images and the feature subsets, thus higher classification accuracy can be obtained; (e) Our proposed classifier training

framework is able to select both the most suitable feature subsets for characterizing various visual properties of different image concepts and object classes accurately; (f) Our proposed classifier training framework is scalable with the image concepts (object classes) and the feature dimensions effectively.
4. AUTOMATIC OBJECT DETECTION AND IMAGE CLASSIFICATION
Given a certain test image, its image blobs and the relevant 83-dimensional multi-modal visual features are detected automatically, which are then classified into the most relevant object classes. The neighboring image blobs belongs to the same class are merged into a single region. Based on these object classes, the whole image is then classified into the most relevant image concept and multi-label image annotation can be achieved accurately.
The task of this paper is to detect 19 object classes and 15 image concepts. After an unlabeled test image is classified, the text keywords for interpreting the object classes and image concepts provide the annotations of the images at the content and concept level respectively. As shown through Fig. 3 to Fig. 6, our multi-label image annotation framework can support more expressive interpretations of the image semantics, and is very attractive to enable multimodal image retrieval via keywords such that the naive users will have more flexibility to specify their query concepts via various keywords at different semantic levels.
5. ALGORITHM EVALUATION
We evaluate our algorithm on two databases: image database from the Google image search engine with about 30,000 pictures, and Corel image database with more than 3,800 pictures consisting of different image concepts and object classes. For each object class and image concept, only 50 images are labeled for classifier training.
Figure 3: Multi-label image annotation results for the image concept "garden" and the relevant object classes.
With the same number of training images, four sets of comparison experiments are performed to evaluate the effect of our proposed framework for joint feature selection and classifier training using different conditions: (a) Learning the optimal ensemble classifier by using all the weak classifiers and the corresponding homogeneous feature subsets. (b) Performing only the second level of feature selection. (c)

519

Figure 4: Multi-label image annotation results for the image concept "ocean view" and the relevant object classes.

Figure 7: The relationship between the ensemble classifier's performance and the number of weak classifiers for boosting.

Figure 5: Multi-label image annotation results for the image concept "beach" and the relevant object classes.
Figure 6: Multi-label image annotation results for the image concept "mountain view" and the relevant object classes. Performing both the first level (PCA) and the second level of feature selection. (d) Comparing the performance difference between our approach, AdaBoost, and FeatureBoost.
There are 9 homogeneous single-modal feature subsets and the total number of iterations for AdaBoost is T = 50. Thus we have obtained 9 × 50 = 450 weak SVM classifiers. All

Figure 8: The relationship between the goodness of the ensemble classifier and the number of the selected homogeneous feature subsets.
these weak SVM classifiers can be used to boost the ensemble classifier. Ideally, integrating more weak SVM classifiers for ensemble classifier training may improve the classifier's performance sequentially. For a given object class "sea water", the relationship is obtained between the ensemble classifier's performance and the number of weak SVM classifiers used for ensemble classifier training. As shown in Fig. 7, although adding more weak SVM classifiers may improve accuracy, it is not able to achieve significant improvement after some iterations. This also proves that selecting the most effective weak classifiers and the corresponding homogeneous single-modal feature subsets for image classification can achieve acceptable accuracy. For the same object class "sea water", we have also obtained the optimal number of homogeneous single-modal feature subsets for ensemble classifier training as shown in Fig. 8. It's obvious that only the top 3 homogeneous single-modal feature subsets may boost the classifier's performance significantly.
The performance difference of our ensemble classifier is also evaluated by performing only the second-level feature selection against both levels. As shown in Fig. 9 and Fig. 10, the latter is able to exploit the feature correlation effectively and improve the accuracy of the ensemble classifier significantly.

520

Table 3: The performance of our classifiers (i.e., precision/recall) for some object classes.

object classes

grass

purple flower red flower

83.8% /84.2% 76.9% /75.8% 78.5% /80.2%

object classes

rock

sand field

sky

75.1% /74.8% 83.2% /78.9% 81.2% /82.6%

object classes

snow

water

sunset

72.8% /70.2% 80.5% /83.6% 80.2% /81.5%

Figure 11: The performance comparison (i.e., 100) for some image concepts and object classes by using different approaches for classifier boosting.

Figure 9: The performance differences of our ensemble classifier (i.e., 100) under different situations.
The performance differences of multiple approaches for ensemble classifier training is shown in Fig. 11 and Fig. 12. With the advantages of both AdaBoost and FeatureBoost, higher classification accuracy can be expected. Results show that our approach can outperform AdaBoost and FeatureBoost. The average performance of our classifiers for some object classes and image concepts are given in Table 3 and Table 4.
The performance of our classifiers is also evaluated with different sizes of unlabeled images for classifier training. Results are shown through Fig. 13 to Fig. 16. It can be observed that if the training set is small, the unlabeled images can improve the classifier's performance significantly. The reasons are: (a) The certain unlabeled images, originated from the existing image context classes for concept interpretation, are able to improve the underlying SVM decision boundaries. (b) The informative unlabeled images, originated from the unknown image context classes, have the capability to provide additional context knowledge for updating the underlying SVM decision boundaries, which

Figure 12: The performance comparison (i.e., 100) for some image concepts and object classes by using different approaches for classifier boosting.

Figure 13: The classification accuracy (i.e., precision )

of

image

concept "beach" with

different

ratio



=

Nu NL

between the labeled images and the unlabeled images.

Figure 10: The performance differences of our ensemble classifier (i.e., 100) under different situations.

Figure 14: The classification accuracy (i.e., precision )

of

image

concept "garden" with

different

ratio



=

Nu NL

between the labeled images and the unlabeled images.

521

Table 4: The comparison of our classifiers (i.e., precision/recall) for some image concepts.

concepts mountain view

beach

garden

75.2% /77.2% 85.6% /83.4% 74.6% /72.8%

concepts

sailing

skiing

desert

70.9% /70.4% 75.3% /75.4% 73.3% /75.2%

concepts ocean view

waterway

prairie

71.2% /70.8% 77.8% /74.9% 74.2% /73.6%

Figure 15: The classification accuracy (i.e., precision )

of image concept "mountain view" with different ratio

 =

Nu NL

between

the labeled

images and the

unlabeled

images.

will in turn influence the prediction accuracy of the SVM classifiers learned incrementally. (c) The outlying unlabeled images, originated from outliers, can be predicted accurately, while misleading effects on classifier training can be eliminated by determining an optimal value of the penalty term C automatically.
When a limited number of labeled images are available and more unlabeled images are involved for semi-supervised classifier training, the classifier's performance will decrease, which is also foreseeable, since large-scale outliers may mislead it.
By using the same number of training samples for classifier training, we have also compared the performance differences between out approach and simply training the classifier directly from the 83-dimensional heterogeneous multi-modal feature space, shown in Fig. 17. It also shows that our approach can obtain higher classification accuracy when labeled training samples are limited.

6. CONCLUSIONS AND FUTURE WORKS
By incorporating the feature hierarchy for ensemble im-

Figure 16: The classification accuracy (i.e., precision )

of

image

concept

"skiing" with

different

ratio



=

Nu NL

between the labeled images and the unlabeled images.

Figure 17: The performance comparison results between our approach and one simple approach for image classifier training.
age classifier training, we have proposed a novel approach to enabling hierarchical feature subset selection. By selecting the most effective weak classifiers and the corresponding homogeneous single-modal feature subsets to boost the ensemble image classifier, our proposed framework is able to achieve higher prediction accuracy for image classification and object detection. In addition, our proposed framework has also supported a novel solution for multi-label image annotation and image retrieval via keywords. Our experiments on a specific domain of natural images have also obtained very positive results. Obviously, our proposed algorithm for joint classifier training and feature subset selection can also be applied to other data domains.
The main problem for image classification is the large range of possible variations within the same image concept or object class because of various viewing and illumination conditions. Thus it is also very important to develop new techniques that are able to handle the changes of viewing and illumination conditions effectively. By treating various viewing conditions or illumination conditions as the additional selection units, we will label the training images to learn the relevant classifiers under various view or illumination conditions, and our proposed image classifier training technique can be used to combine these classifiers effectively for final prediction and thus it is able to generalize across different viewing and illumination conditions.
7. ACKNOWLEDGMENTS
The authors wish to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Program (2010CB327906), Shanghai Leading Academic Discipline Project (B114), Doctoral Fund of Ministry of Education of China (20100071120033), and Shanghai Municipal R&D Foundation (08dz1500109).
8. REFERENCES
[1] K. Barnard and D. Forsyth. Learning the semantics of words and pictures. ICCV, pages 408­415, 2001.
[2] K. Bennet and A. Demiriz. Semi-supervised support vector machines. NIPS, pages 368­374, 1998.
[3] D. Blei and M. Jordan. Modeling annotated data. ACM SIGIR, pages 127­134, 2003.

522

[4] L. Breiman. Bagging predictors. Machine Learning, 24:123­140, 1996.
[5] C. Carson, S. Belongie, H. Greenspan, and J. Malik. Blobworld: Image segmentation using expectation maximization and its application to image querying. IEEE Trans. on PAMI, 24:1026­1038, 2002.
[6] Y. Deng and M. Manjunath. Unsupervised segmentation for color-texture regions in images and video. IEEE Trans. on PAMI, 23:800­810, 2001.
[7] P. Duygulu, K. Barnard, J. Freitas, and D. Forsyth. Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary. ECCV, pages 97­112, 2002.
[8] J. Fan, Y. Gao, and H. Luo. Multi-level annotation of natural scenes using dominant image components and semantic image concepts. ACM Multimedia, pages 540­547, 2004.
[9] W. Fan, S. Stolfo, J. Zhang, and P. Chan. Adacost: Misclassification cost-sensitive boosting. ICML, pages 99­105, 1999.
[10] Y. Freund and R. Schapire. Experiments with a new boosting algorithm. ICML, pages 148­156, 1996.
[11] Y. Gao, J. Fan, H. Luo, X. Xue, and R. Jain. Automatic image annotation by incorporating feature hierarchy and boosting to scale-up svm classifiers. ACM Multimedia, pages 901­910, 2006.
[12] K. Ghahremani, C. Shahabi, S. Yao, and R. Zimmermann. Yima: real-time multimedia storage and retrieval. ACM Multimedia, pages 668­669, 2002.
[13] J. Jeon, V. Lavrenko, and R. Manmatha. Automatic image annotation and retrieval using cross-media relevance models. ACM SIGIR, pages 119­126, 2003.
[14] Y. Jin, L. Khan, L. Wang, and M. Awad. Image annotations by combining multiple evidence and wordnet. ACM Multimedia, pages 706­715, 2005.
[15] T. Joachims. Transductive inference for text classification using support vector machines. ICML, pages 200­209, 1999.
[16] V. Lavrenko, R. Manmatha, and J. Jeon. A model for learning the semantics of pictures. NIPS, pages 553­560, 2003.
[17] A. Makadia, V. Pavlovic, and S. Kumar. A new baseline for image annotation. ECCV, pages 316­329, 2008.
[18] D. Modha and W. S. Spangler. Feature weighting in k-means clustering. Machine Learning, 52:217­237, 2003.
[19] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell. Text classification from labeled and unlabeled documents using em. Machine Learning, pages 103­134, 2000.

[20] J. O'Sullivan, J. Langford, R. Caruana, and A. Blum. Featureboost: A meta learning algorithm that improves model robustness. ICML, pages 703­710, 2000.
[21] J. Platt. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. Adavances in Large Margin Classifiers, MIT Press, 1999.
[22] B. Ripley. Neural network and related methods for classification. Journal of the Royal Statistical Society, Series B, 56:409­456, 1994.
[23] A. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Trans. on PAMI, 22:1349­1380, 2000.
[24] C. Sutton, M. Sindelar, and A. McCallum. Feature boosting: Preventing weight undertraining in structured discriminative learning. CIIR TR-IR-402 University of Masschusetts, 2005.
[25] M. Szummer and T. Jaakkola. Information regularization with partially labeled data. NIPS, pages 1025­1032, 2002.
[26] A. Torralba and A. Oliva. Semantic organization of scenes using discriminant structural templates. ICCV, pages 1253­1258, 1999.
[27] V. Vapnik. Statistical learning theory. 1998. [28] N. Vasconcelos and M. Vasconcelos. Scalable
discriminant feature selection for image retrieval and recognition. CVPR, pages 770­775, 2004. [29] P. Viola and M. Jones. Robust real-time face detection. Intl. J. Computer Vision, 57:137­154, 2004. [30] X.-J. Wang, W.-Y. Ma, L. Zhang, and X. Li. Iteratively clustering web images based on link and attribute reinforcements. ACM Multimedia, pages 122­131, 2005. [31] M. Weber, M. Welling, and P. Perona. Unsupervised learning of models for recognition. ECCV, pages 18­32, 2000. [32] C. Yang, M. Dong, and J. Hua. Region-based image annotation using asymmetrical support vector machine-based multiple-instance learning. CVPR, pages 2057­2063, 2006. [33] L. Yu and H. Liu. Feature selection for high-dimensional data: A fast correlation-based filter solution. ICML, pages 856­863, 2003. [34] R. Zhang, Z. Zhang, M. Li, W.-Y. Ma, and H. Zhang. A probabilistic semantic model for image annotation and multi-modal image retrieva. ICCV, pages 846­851, 2005. [35] S. Zhang, J. Huang, Y. Huang, Y. Yu, H. Li, and D. Metaxas. Automatic image annotation using group sparsity. CVPR, pages 3312­3319, 2010.

523

