Utilizing Marginal Net Utility for Recommendation in E-commerce

Jian Wang and Yi Zhang
Department of Computer Science University of California, Santa Cruz
Santa Cruz, CA 95060 USA
{jwang30, yiz}@soe.ucsc.edu

ABSTRACT
Traditional recommendation algorithms often select products with the highest predicted ratings to recommend. However, earlier research in economics and marketing indicates that a consumer usually makes purchase decision(s) based on the product's marginal net utility (i.e., the marginal utility minus the product price). Utility is defined as the satisfaction or pleasure user u gets when purchasing the corresponding product. A rational consumer chooses the product to purchase in order to maximize the total net utility. In contrast to the predicted rating, the marginal utility of a product depends on the user's purchase history and changes over time. According to the Law of Diminishing Marginal Utility, many products have the decreasing marginal utility with the increase of purchase count, such as cell phones, computers, and so on. Users are not likely to purchase the same or similar product again in a short time if they already purchased it before. On the other hand, some products, such as pet food, baby diapers, would be purchased again and again.
To better match users' purchase decisions in the real world, this paper explores how to recommend products with the highest marginal net utility in e-commerce sites. Inspired by the Cobb-Douglas utility function in consumer behavior theory, we propose a novel utility-based recommendation framework. The framework can be utilized to revamp a family of existing recommendation algorithms. To demonstrate the idea, we use Singular Value Decomposition (SVD) as an example and revamp it with the framework. We evaluate the proposed algorithm on an e-commerce (shop.com) data set. The new algorithm significantly improves the base algorithm, largely due to its ability to recommend both products that are new to the user and products that the user is likely to re-purchase.
Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'11, July 24­28, 2011, Beijing, China. Copyright 2011 ACM 978-1-4503-0757-4/11/07 ...$10.00.

General Terms
Algorithms, Design, Experimentation
Keywords
Recommender System, E-commerce, Consumer Utility Function
1. INTRODUCTION
With ever increasing e-commerce websites and online shoppers, the recommender system is becoming popular among internet users. It helps consumers to make purchase decisions, mainly by gathering information from other users. In the short term, it saves users' time and effort to find what they are looking for. In the long term, it helps to increase users' satisfaction rate and loyalty to the site.
In the literature, the satisfaction or pleasure a user gets when purchasing/consuming a product is called the marginal utility. According to consumer behavior theory, a rational consumer chooses the product with the highest marginal net utility, i.e., a product's marginal utility minus the price. A product's marginal utility is dependent on the user's previous purchase history. A product with the higher marginal net utility is more likely to be purchased. Some products have the diminishing marginal utility. For example, the utility of purchasing a second computer is less than that of purchasing the first computer. For these products, users are not likely to purchase them again and again in a short time period. This is called the Law of Diminishing Marginal Utility in economics. On the other hand, some products (pet food, baby diapers, etc.) are likely to be purchased again and again. We call it the "re-purchase" behavior in this paper.
In order to match users' purchase decision(s), the recommender system should choose products with the highest marginal net utilities to recommend. Such a system is able to capture characteristics of both types of products and makes recommendations accordingly. Unfortunately, most of existing recommendation algorithms are not based on the marginal net utility optimization and cannot model the above two different products well. Most existing algorithms select products with the highest predicted ratings to recommend, assuming that the value/utility of a product for a user does not change over time.
This paper introduces the concept of marginal net utility to develop recommendation algorithms. Inspired by the Cobb-Douglas function in consumer behavior theory, we propose a utility function for the recommender system in ecommerce sites. The new function contains a factor to con-

1003

trol the product's marginal utility diminishing rate. Assuming that a user's purchasing decision depends on the marginal net utility, the rate can be learned from the purchase history of all users. The function can be applied on a family of existing recommender algorithms, which we call base algorithms. In this work, we choose SVD as our base algorithm. Applying our utility function to SVD leads to a new utility function SV Dutil in this paper.
We evaluate our algorithm on the purchase history from an e-commerce website shop.com. The experimental results show that our approach can improve the base algorithm significantly with better precision, recall and conversion rates. If the user purchased what he/she purchased before, the product is denoted as a re-purchase product. Otherwise, if the user purchased a product that he/she never purchased before, the product is denoted as a new product. The recommended list generated by our proposed algorithm contains both new products and re-purchase products. Or we can add a filter on top of the recommender system to recommend only re-purchase products or only new products for specific recommendation tasks.
The major contributions of this paper include the following:
· Introduce the idea of utilizing the marginal net utility in the recommender system of e-commerce sites. Adapt the utility function from the Cobb-Douglas function to apply in a general framework.
· Apply the new utility function on SVD algorithm, denoted as SV Dutil. The new algorithm achieves significant improvement in precision, recall and conversion rates.
· The new algorithm SV Du0.t7il performs significantly better in the re-purchase product recommendation task, the new product recommendation task, and the longtail product recommendation task.
The rest of this paper is organized as follows: Section 2 discusses the related work. Section 3 introduces basic utility functions in economics and marketing research. Then we propose a new utility-based recommendation framework, motivated by these basic utility functions. Section 4 applies the new framework to revamp the well-known SVD algorithm. Section 5 first introduces the experimental design to evaluate and understand the new algorithm. Then it presents experimental results and further analysis. In the end, Section 6 concludes the work and discusses some future work.
2. RELATED WORK
A major task of the recommender system is to present recommendations to the user. The task is usually conducted by first predicting a user's ratings (or probability of purchasing) for each item and then ranking all items in descending order. There are different information sources to find the relevant recommendation, including item's content, user's behavior history, user's demographical information, so on and so forth. There are two major recommendation approaches: content-based filtering and collaborative filtering.
The content-based recommendation is based on the assumption that descriptive features of an item (meta data, words in description, price, tags, etc.) tell much about a

user's preferences to the item. Thus a recommender system makes a decision for a user based on the descriptive features of other items the user likes or dislikes. Usually, the system recommends items that are similar to what the user likes before. A user profile contains his/her previous transaction history, such as what he/she viewed or purchased before. How to determine the similarity between a product and the profile is the key challenge. Cosine similarity with TF.IDF term weights, the language modeling approach, Bayesian classifiers, clustering, etc., have been proposed [23, 24]. Largely influenced by the TREC filtering track, most of the early research on content-based filtering is about filtering text documents. In e-commerce systems, products usually have very limited description (title, user reviews, etc.). The effectiveness of content-based approaches is limited. Thus a content-based approach is usually not used by itself in e-commerce sites. It is used as part of a hybrid recommendation strategy [6]. In this work, we do not assume that a user likes things similar to what he/she likes before. Instead, we utilize the product's metadata to find similar products in order to determine the product's marginal net utility. As a result, a user may like or dislike an item that is similar to what he/she purchased in our model.
In the collaborative filtering approach, user behavior history is utilized to make recommendations. This approach is based on the assumption that users with similar tastes on some items may also have similar preferences on other items. Thus the main idea is to utilize the behavior history from other like-minded users to provide the current user with good recommendations. This approach usually operates on a user-item matrix, in which each row is a user vector and each column is an item vector. User-based methods find similar users to the current user, and fall into the category of memory-based approach in the literature [26, 5, 12]. However, these methods suffer from the poor quality and scalability issues. Item-based methods directly find items that are similar to the items a user has rated/purchased [25, 10]. Various similarity measures, such as cosine similarity, Pearson correlation coefficient, conditional probability-based similarity, have been proposed to find all neighbors. In addition, a group of model-based approaches have been developed in recent years. Model-based approaches use the collection of user behavior (ratings, purchases, etc.) to learn a model, and make predictions based on the learned model. Examples are Probabilistic Latent Semantic Indexing (PLSI) [14], Flexible Mixture Models [30], Decoupled Models [16], Multiple Multiplicative Factor Model [21], etc.
Research on collaborative filtering algorithms has reached a peak due to the 1 million dollar Netflix movie recommendation competition [4]. Factorization-based collaborative filtering approaches, such as the regularized Singular Value Decomposition, perform well on this competition, significantly better than the Netflix own well-tuned Pearson correlation coefficient (nearest neighbors) algorithm. A common characteristic of these models is to introduce user latent factors or/and product latent factors to solve the data sparsity issue. In this paper, we use SVD as our base algorithm, since it represents a family of factorization-based methods that work well on the Netflix dataset [4]. There are many extensions (AsySVD, SVD++, etc.) to the basic SVD in the literature [9, 18]. The approach proposed in this work can be applied to all these methods in the future.
In contrast to our work, most of the existing collabora-

1004

tive filtering methods assume that the utility of a product for a user does not change over time. Utility is typically represented by the rating. Although some work captures the temporal variations of a user's ratings [19], they cannot capture the economic behavior behind products' diminishing return and re-purchase characteristic.
Besides content based filtering and collaborative filtering approaches, other approaches such as Graph-based methods [1], Bayesian network [5], association rules [22], and MDP-based methods (Markov decision process) [29] were developed. Though it is not straightforward to use our proposed technique to revamp these filtering approaches, the basic idea of considering the marginal net utility, the diminishing return and the re-purchase behavior could be used to further improve these algorithms in the future.
Recommendation in the e-commerce domain is a topic that has been studied in the IR community [26, 28, 17, 11]. Several methods have been studied in this domain, including neighborhood-based method [26], graph models [15], MDPbased methods [29], multi attribute utility theory based methods [20] and so on. Existing research in economics and marketing can also be applied to model user behavior in ecommerce sites. This paper focuses on modeling users' purchase decisions based on the marginal net utility of products.
3. ALGORITHM DESIGN
In this section, we first define some basic notations to be used in the rest of this paper. Then we review two representative consumer utility functions. After proposing a new utility function for our problem, we describe how it can be used in a general framework to revamp some existing recommendation algorithms.
3.1 Notations
The following notations are used in the problem definition and analysis.
u = 1, ..., M : the index of a user. M is the number of unique users in the system.
i or j = 1, ..., N : the index of a product. N is the number of unique products in the system.
t: time.
ci: the price of product i. We assume that this value is given. Making this value time dependent (i.e., replacing it with ci,t) won't affect any analysis in the rest of this paper.
PM×N : user-product matrix. Depending on the context, each entry Pu,i could be user u's rating of product i, user u's purchase count of product i, or a unary/binary value indicating whether user u has purchased product i or not.
The goal of our system is to provide a ranked list of personalized recommendations to user u. In this paper, each user's budget is not taken into consideration. The optimal purchase rule [3] indicates that a rational consumer purchases the product to maximize the marginal net utility. Accordingly the algorithm should choose the product with the maximum marginal net utility at each recommendation time point. Since the product price is given, the core problem of a recommender system is to determine the marginal utility for each product.

3.2 Marginal Utility
The utility of a product for a user depends on the user's purchase history. Marginal utility is used in economics and marketing research to represent the additional utility the consumer gets when consuming an additional unit of a product. The Law Of Diminishing Marginal Utility states that the marginal utility of a product drops while the consumption of the product increases. For example, for user u, the utility of consuming the first "iPhone 4" might be 10, the utility of consuming the second one might be 5, while the utility of consuming a third one might be only 1.
It is worth mentioning that the standard definition of the Law Of Diminishing Marginal Utility assumes continuity. It means that all units of a product are purchased one after another, without time gaps between any two purchases. However this assumption might not hold in an ecommerce site, where there are time gaps and purchases of other products between most re-purchases. For example, the user might purchase some pet food on Friday evening, then some books on the following Monday morning, and some pet food again after two weeks. Although the continuity assumption no longer holds in our e-commerce domain, we can still use the concept of marginal utility. Utility functions in economics can be adapted to our problem. This enables us to make recommendations based on the different diminishing return rate of different products.

3.2.1 Linear Utility Function
Linear utility function is one of the simplest functions in consumer behavior theory, as shown in Equation 1.

U (X) = j xj

(1)

j

where X is the set of products the user consumed, and xj is the consumption quantity of product j. j is the basic utility of product j, indicating the purchasing intention for product j. U (X) is the utility of the entire purchase list X.
We can calculate the marginal utility U (X, i) of purchasing one additional unit of product i in the following equation.

U (X, i) = U (X, i) - U (X) = i

where U (X, i) = j:j=i j xj+ixi is the utility of the entire purchase list with one additional product i. xi = xi + 1 is the updated quantity of product i.
The linear utility does not capture the diminishing return characteristic. From the deduction, we can see that the previous purchase count xi of product i does not affect the marginal utility of purchasing one additional unit of product i. If product i's basic utility i is high, the system will recommend it regardless of previous purchase(s) of the same product.
In most existing recommender systems, products with the highest predicted values are recommended to the users. If these products include both re-purchase ones and new products, the approach follows the linear utility assumption. If only products that were never purchased are recommended, the following utility function is used:

U (X) = j

(2)

j

However, both of these two underlying utility functions do

1005

not match how users make purchase decisions in the real world.
3.2.2 Cobb-Douglas Utility Function
Another representative utility function is the Cobb-Douglas utility function [8]. This function is widely used due to its attractive mathematical characteristic: the ability of modeling the diminishing marginal return. The functional form is:

U (X) = j log(xj)

(3)

j

where the definitions of xj and j are the same as before. The marginal utility of purchasing one additional unit of product i is:

U (X, i) = U (X, i) - U (X) = i(log(xi) - log(xi)) (4) = i(log(xi + 1) - log(xi))

The above equation shows that the marginal utility of product i decreases as the consumption quantity of product i increases. The diminishing return rate is log(xi+1)-log(xi).

3.3 New Marginal Utility Function for E-Commerce Sites
Diminishing marginal utility is a widely recognized consumer behavior which we intend to model in the design of a recommender system for e-commerce sites. This motivates us to utilize the Cobb-Douglas utility function in our algorithm design.
However, Equation 4 shows two major drawbacks of the Cobb-Douglas utility function. First, the marginal utility of different products has the same diminishing return rate log(xi + 1) - log(xi). It does not differentiate two types of products: products that the user would not purchase many times vs. products that the user would purchase again and again. Second, the basic utility i of a product i does not depend on the particular user, which contradicts with the goal of a personalized recommender system.
A real-world e-commerce system could collect a large amount of consumer purchase data. This enables us to handle these drawbacks of the Cobb-Douglas utility function. We can learn the product-specific diminishing return rate and the user-specific basic utility from the data. Now we describe how to modify the Cobb-Douglas utility function to achieve this goal.
We propose a new marginal utility function as follows:

Uu,t(X, i) = u,i((xu,i,t + 1)i - xui,i,t)

(5)

where xu,i,t is user u's consumption quantity of product j by time t.
There are four major differences between Equation 5 and Equation 4. First, we substitute log(xj) with xj for the mathematical convenience. This simplification is motivated by the well-known Constant elasticity of substitution (CES) utility function in Equation 6 [31]:

U (X) = jxj

(6)

j

Second, xi is substituted by xu,i,t, so that it depends on the product, the user and the time. Third, i is substituted by u,i, so that it is personalized to each individual

user. Fourth, we introduce i as a parameter to capture the diminishing return rate of product i.
One important question is how to determine xu,i,t. The original definition of xu,i,t is user u's purchase count of product i by time t. We make two major modifications while calculating xu,i,t in the e-commerce domain. First, we define the purchase count as the number of purchase orders the current user made. Each order is counted once for the same product, regardless of the product quantity in the order. For example, if the user purchases 4 window panels in one order, the purchase count of window panel is 1. Second, we assume that the marginal utility is affected not only by previous purchase(s) of the same product, but also by previous purchase(s) of similar products. For example, the previous purchase of "iPhone 3" has effect on the marginal utility of the current purchase of "iPhone 4". We first find products that are similar to product i based on the metadata, such as the product title. Then let xu,i,t be the total similarity between these similar products and the current product i for user u at time t.

xu,i,t =

Cu,j,t × sim(i, j)

j:sim(i,j)

where Cu,j,t is user u's purchase count of product j by time t, and sim(i, j) is the similarity between product i and product j.  is a similarity threshold, which will be estimated by the cross-validation in our experiments.
It is worth mentioning that the utility over a sequence of purchases can be calculated based on the definition of the above marginal utility (Equation 5). However, the utility of an unordered set of products is not defined. The only exception is when  = 1, in which case only the same product will influence the marginal utility. Under such circumstance, the utility over a sequence is independent of the sequential order of products. Then the utility can be used for an unordered set of products. With some derivation, we can get the definition of a user u's utility over an unordered set of products X at time t in this special case as follows:

Uu,t(X) =

u,j xuj,j,t

(7)

j

It is similar to the Constant Elasticity of Substitution utility function in Equation 6. However, the meaning of i in Equation 7 is different from  in Equation 6.  is the parameter to tune the elasticity of substitution 1 and is the same for different products. In our new utility function (Equation 7), i is a parameter to tune the diminishing return rate. It is product-specific and can be learned based on the purchase history of each product. Linear and Cobb-Douglas utilities can be viewed as special cases of our utility function. That is, in the limit as all i approach 1, we get the linear utility; as all i approach 0, we get the Cobb-Douglas utility.

3.4 Revamp Existing Algorithms with the New Marginal Utility Function
In most cases, we can view an existing recommendation algorithm as a function f (u, i) to estimate the value of product i for user u without considering the diminishing return or the cost of a product. To reflect a user's true decision

1More information of CES utility function can be found in the reference [31].

1006

behavior in reality, we model vu,i,t, the marginal net utility of product i for user u at time t, as follows:

vu,i,t = f (u, i)[(xu,i,t + 1)i - (xu,i,t)i ] - ci

(8)

Whether product i is likely to be purchased is dependent on the product's basic utility, its diminishing return rate, as well as the product's price. Comparing Equation 8 and Equation 5, we notice that u,i is replaced by f (u, i). In other words, we propose to use an existing recommendation algorithm f (u, i) to estimate u,i, the basic utility of product i for user u.
At each decision point t, a higher marginal net utility vu,i,t indicates that user u is more likely to purchase product i. The following logistic function can be used to capture this intuition and model the conditional probability of making the purchase.

P r(ru,i,t|vu,i,t)

=

1 1 + e-vu,i,t·ru,i,t

(9)

where ru,i,t = 1 if user u purchases i at time t. Otherwise ru,i,t = -1.
Assume that the cost ci of product i is given, the parameters of the above model include i and parameters of function f . To learn these parameters, we can order the entire user purchase history by the purchase time. At each time point t, user u's purchase decision of product i is considered as a training point. If user u purchased the product, it is a positive training point with ru,i,t = 1. Otherwise, it is a negative training point with ru,i,t = -1.
When a new recommended list is needed, the system can estimate each product's marginal net utility based on Equation 8 and rank them accordingly. For email-based or messagebased marketing/recommendation applications, the system can predict how likely a user will purchase an item using Equation 9 and decide whether to recommend an item to the user accordingly (as in TREC adaptive filtering tasks).

4. APPLY NEW MARGINAL UTILITY FUNCTION ON SVD

In this section, we choose a popular recommendation algorithm SVD as an example. The algorithm in Section 3.4 is used to revamp it. This leads to a new recommendation algorithm, which we call SV Dutil.

4.1 SVD

In this work, we choose SVD as an example because it is a popular recommendation algorithm with a decent performance. It is the basis of several recommendation algorithms based on latent factors, which have been proven to work well on benchmark recommendation datasets including the Netflix dataset [4].
Following [9, 18], we represent SVD as a matrix factorization approach. The basic SVD algorithm operates over a user-product matrix PM×N . It assumes that each entry Pu,i in the matrix P can be estimated using the following form:

P^u,i = qiT pu

(10)

where qi and pu are vectors, which are the hidden representation of product i and user u. These vectors can be estimated based on all given entries in PM×N .
The value of Pu,i in the observed matrix PM×N is determined by the user purchase history. In the e-commerce do-

main, Pu,i is usually set to be a unary value that indicates whether user u purchased product i or not [13]. Existing work finds that unary value is more suitable than numerical value, i.e., the number of times the user purchased the product [27]. Our piloting experiment compares these two types of values and reaches the same conclusion.
When a recommender system ranks all products by their estimated P^u,i values and selects the top ones to recommend, it is equivalent to maximizing the linear utility.

4.2 SVDutil: Revamp SVD
In this section, we apply the technique in Section 3.4 to revamp SVD. To do so, we set the basic utility u,i = f (u, i) = qiT pu. Based on Equation 8, the marginal net utility is:

vu,i,t = qiT pu[(xu,i,t + 1)i - (xu,i,t)i ] - ci

(11)

For simplicity and as commonly done in the literature, we assume that prior distributions of user vector pu and item vector qi are Gaussian distributions. P r(pu) and P r(qi) have mean zero and variance 1/1 . We assume that the prior distribution of i is a Gaussian distribution with mean 0 and variance 1/2. We treat each purchase order made by a user as a decision point. The purchase history of all users can be viewed as the training data D = (ru,i,t, ci, u, t). The joint probability (likelihood) of all parameters and the training data is:

L = P r(pu) P r(qi) P r(i) P r(ru,i,t|vu,i,t)

u

i

i

u,i,t

(12)

4.3 Parameter Estimation
The model parameters can be found by maximizing the joint probability of all parameters and the training data. According to Equation 12 and Equation 9, this is equivalent to minimizing the negative log likelihood of the data as follows:

(pu, qi, i) = argmin [-logL]

1 =argmin 2 1

||pu||2

+

1 2 1

||qi ||2

+

1 2 2

(i - 0)2

u

i

i

+

log(1 + e-vu,i,t·ru,i,t )

u,i,t

 can also be viewed as regularization factors to avoid the overfitting problem.
The first order derivatives are:

(-logL) qi

=

1 qi

+

gu,i,t

·

[pu

·

du,i,t ]

(-logL) pu

=

1pu

+

gu,i,t

·

[qi

·

du,i,t ]

(-logL) i

=

2i

+

gu,i,t

·

[qiT pu

·

((xu,i,t

+

1)i

· log(xu,i,t + 1) - (xu,i,t)i · log(xu,i,t))]

1007

where

du,i,t = [(xu,i,t + 1)i - (xu,i,t)i ]

vu,i,t = qiT pudu,i,t - ci

(log(1 + e-vu,i,t·ru,i,t ))

gu,i,t =

 vu,i,t

=

e-vu,i,t ·ru,i,t 1 + e-vu,i,t·ru,i,t

· (-ru,i,t)

Based on the above derivation, we can use the stochastic gradient descent method to find the optimal parameters. Following the standard stochastic gradient descent method, update rules at each iteration are shown in the following equations. The algorithm stops when the change in an iteration is small enough.

pu

=

pu

-

1

·

(-logL) pu

qi

=

qi

-

1

·

(-logL) qi

i

=

i

-

2

·

(-logL) i

where  controls the learning rate at each iteration.  and  can be set by the cross-validation.

5. EXPERIMENTAL DESIGN AND RESULT
Since this paper focuses on the recommendation in ecommerce sites, we collect a dataset from a typical e-commerce website, shop.com, for our experiments. This dataset contains the purchase history from 2004-01-01 to 2009-03-08. Since our algorithm is dependent on users' previous purchase history, we sort all history by the purchase time. The first 90% of data is the training data, and the last 10% is the testing data. Tail users that made less than 5 unique product purchases are filtered out in the training data. The remaining training data contains 10,399 users and 65,551 products. There are 102,915 unique (user, product) pairs. As we can see, the user-product matrix for SVD is quite sparse, with only 0.015% density. There are 55,539 unique (user u, order time t) pairs and 119,322 unique (user u, product i, order time t) tuples. All products are kept in the training process. In the evaluation step, usern>0 are returning users with at least one purchase in the training data. productn>0 are products with at least one purchase in the training data. In following sections, we report the performance for returning users that purchased from: 1) all products and 2) productn>0.
We first split the training data, using the last 10% of the training data as the validation data to set (, , 0, ). We have 1 = 0.015, 2 = 0.035, 1 = 0.05, 2 = 0.01 for positive training points, 2 = 0.001 for negative training points, 0 = 1, and  = 0.7. Instead of using all negative training points, we randomly sampled 1% from missing entries as negative training points in SV Dutil. The sample percentage is determined by cross-validation. Both positive and negative training datas are used to learn model parameters. Finally the model is used to generate the recommendation list in the testing stage. For every decision point t in the testing data, all products are ranked by the marginal net utility vu,i,t (Equation 11). The top ranked products are recommended to the user.

We set the dimension of the user vector and the product vector to be 50. Product titles are used to calculate products' similarity. All stop words are removed. 2
Some researchers have tried to fit SVD model parameters to the entire matrix P by replacing the missing entries with a base value such as 0. They found that such methods perform better for ranking metrics, such as recall and precision [9]. Their experiment results are performed on the movie data (Movielens and Netflix) with matrix density being 4.26% and 1.18% respectively. The matrix density on an e-commerce data set is usually much lower [13] (0.015% in our dataset). To train SVD, we randomly sample 0.1% missing entries and set them to 0, where percentage is determined by the cross-validation. The method is denoted as SV Dmatrix.
5.1 Evaluation Metrics
There are several metrics to evaluate recommender algorithms in the literature [13]. Considering the usage scenario in a typical e-commerce web site, the ranking of all recommendations is more important than the rating prediction. Instead of using some common rating prediction accuracy measures (Root Mean Square Error, etc.), we evaluate all algorithms in the context of a ranking task [9].

· Each order Du,t corresponds to a testing point, which is uniquely identified by a (user, order time) pair. Let Spurchased be the set that contains all products in this purchase order.
· Rank all products according to their predicted marginal net utility for user u at time t. Let SK,recommended be the set that contains the top K products.

Then we have:

recall@K

=

|Spurchased  SK,recommended| |Spur chased |

precision@K = |Spurchased  SK,recommended| K

(13) (14)

Conversion rate, a commonly-used metric in e-commerce, is used as an additional evaluation metric in our experiments. If the user purchased at least one product from the recommended top K list, we consider that the user has converted from a browser into a buyer. The calculation of conversion rate for one testing point is shown in the following equation.

conversion rate@K =

1 0

Spurchased  SK,recommended =  otherwise

(15)

Conversion rate reflects whether a user receives at least one good recommendation. The average value of all testing points will be used to compare among different algorithms. Statistical significant tests are used when comparing two methods.

5.2 General Analysis
In this section, we intend to answer the following questions with the general analysis:
2Other metadata information, such as user's review to the product, product's limited description, can be used in the future.

1008

600

500

400

Table 1: Conversion rate performance for the gen-

eral recommendation task. Value* is significantly

better than the baseline SV Dmatrix and TopPop.

Method

K=1 K=2 K=3 K=4 K=5

for usern>0 and all products

TopPop 0.0002 0.0004 0.0006 0.0006 0.0011

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0102 0.0194 0.0287 0.0363 0.0266* 0.0425* 0.0542* 0.0575*
0.0190* 0.0324* 0.0432* 0.0499* for usern>0 and productn>0

0.0438 0.0607* 0.0536*

TopPop 0.0005 0.0010 0.0015 0.0015 0.0025

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0238 0.0456 0.0673 0.0851 0.1028 0.0623* 0.0997* 0.1271* 0.1347* 0.1423* 0.0446* 0.0759* 0.1013* 0.1170* 0.1256*

300

Frequency

200

100

· How does SV Dutil perform? We compare it with SV Dmatrix and a naive method T opP op. The T opP op method recommends the most popular products. It is a simple non-personalized recommendation algorithm that is commonly used in real world applications. Prior research has shown that it outperforms some common recommendation approaches and almost matches the accuracy of sophisticated algorithms in top-N recommendation task [9].
· Does considering similar products help the performance compared to using the exact same product? We compare SV Dutil with different similarity thresholds:  = 0.7 vs.  = 1.0. When  = 1.0, only the purchase(s) of the same product influences the diminishing return. When  = 0.7, the purchase(s) of similar products also influences the diminishing return. In the analysis, we represent the model with  = 0.7 as SV Du0.t7il, and the model with  = 1.0 as SV Dusatiml e.
The conversion rate performance of all methods is shown in Table 1. It is clear that all personalized methods are significantly better than the non-personalized method T opP op. Although the precision and recall are not reported here, we have similar observations when evaluating with these two metrics.
Comparing SV Du0.t7il and SV Dusatiml e with SV Dmatrix, we can see that our proposed marginal utility function helps. Both SV Du0.t7il and SV Dusatiml e are significantly better than SV Dmatrix for all evaluation metrics.
Between two methods with the new utility function, the performance of SV Dusatiml e is significantly better than SV Du0.t7il. The method SV Dusatiml e only utilizes the same product to learn the diminishing return rate and estimate the marginal utility. Thus it might catch re-purchase behavior with the higher accuracy. This will be further analyzed in the next section.
5.3 Further Analysis: Re-purchase Product Recommendation and New Product Recommendation
In the previous section, we generate a recommended list by ranking all products, including both re-purchase products and new products. Besides the general recommendation task, there are more specific tasks in e-commerce sites. Now we perform further analysis to compare these recommendation algorithms in two different recommendation tasks.
One task is to recommend products for a user to re-purchase. In the testing data, 13.79% of the purchase orders from returning users contain re-purchase products, i.e., products

0

0

5

10

15

20

25

30

35

previous purchase count of re-purchase products

Figure 1: Histogram of the previous purchase count in the training data of all re-purchase products. If a product in the testing data was purchased before, it is a re-purchase product.

that were purchased by the user before. To successfully recommend products for the user to re-purchase could save a consumer much time and effort, and might be able to increase sales.3 The challenge is how to rank products the user has purchased before. For all re-purchase products in the testing data, we plot the the histogram of their previous purchase count (Figure 1). We observe that the majority of re-purchase products were purchased only once or twice in the training data. Thus it is hard to use the previous purchase count to rank. In Section 5.3.1, we compare all methods' performance in ranking products that were purchased before. Only re-purchase products in each testing order are used to evaluate all methods' performance.
A second task is to recommend new products that a user has never purchased before. In the testing data, 90.64% in the dataset of all purchase orders from returning users contain new products. The new product recommendation task is much harder and more interesting than the re-purchase recommendation task. The recommendation candidates include all products that were not purchased by the current user before. Only new products in each testing order are used to evaluate all methods' performance.
In this section, we intend to answer the following questions:
· How does SV Dutil perform in the re-purchase product recommendation task?
The methods in general recommendation task, including T opP op, SV Dmatrix, SV Du0.t7il and SV Dusatiml e, recommend both new products and re-purchase products. We add a filter on top of them, so that only products that were purchased before are recommended. The method with filter is denoted as method.P revious. For testing, we use only orders that contain product(s) that the user has purchased.
3This is why amazon.com is providing subscribing service with discount to encourage re-purchase.

1009

Table 2: Conversion rate@K for the re-purchase rec-

ommendation task. Value* is significantly better

than the baseline SV Dmatrix and TopPop.

Method

K=1 K=2 K=3 K=4 K=5

for usern>0 and all products

(13.79% orders contain repurchase purchase)

TopPop

0.0 0.0013 0.0013 0.0013 0.0026

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0609 0.1179 0.1735 0.2199 0.1629* 0.2609* 0.3325* 0.3523* 0.1126* 0.1934* 0.2543* 0.2954*

for usern>0 and productsn>0

(31.69% orders contain repurchase purchase)

0.2662 0.3709* 0.3179*

TopPop

0.0 0.0016 0.0016 0.0016 0.0032

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0735 0.1422 0.2093 0.2652 0.3211 0.1965* 0.3147* 0.4010* 0.4249* 0.4473* 0.1358* 0.2332* 0.3067* 0.3562* 0.3834*

TopPop.Previous 0.1390 0.2476 0.3498 0.4249 0.4840

SV Dmatrix.P revious SV Dusatiml e.P revious SV Du0.t7il.P revious

0.1230 0.2252 0.3243 0.3866 0.1981* 0.3243* 0.4201* 0.4553* 0.2061* 0.3658* 0.4840* 0.5591*

0.4553 0.4952* 0.6342*

Table 3: Product 2426's purchase history in the

training data. The table is used in Section 5.3.1.

userID order time

u1916 u2694 u2613 u2857 u2863

12/14/06 6:44 12/16/07 19:34 6/10/08 16:11
8/6/08 20:11 8/23/08 8:58

Table 4: Product title of Product 2426 and two sim-

ilar products. The table is used in Section 5.3.1.

ProductID

Product Title

2426

Obsession by Calvin Klein TESTER

for Women Eau de Parfum Spray 3.4 oz

2365

Eternity by Calvin Klein

for Women Eau de Parfum Spray 1.7 oz

1329

Eternity by Calvin Klein

for Women Eau de Parfum Spray 3.4 oz

5.3.2 New Product Recommendation Task

· How does SV Dutil perform in the new product recommendation task?

Table 5 compares the conversion rate of all methods in recommending new products.

Similarly, we add a filter to recommend only new prod-

Before using the filter, SV Du0.t7il achieves better perfor-

ucts. The method with the filter is denoted as method.N ew. mance than the baseline SV Dmatrix and TopPop. On the

For testing, we use only orders that contain product(s) that the user has never purchased.

other hand, SV Dusatiml e does not help recommending new products. In this task, SV Du0.t7il performs better than SV Dusatiml e

since it learns from similar products' purchase behavior with

5.3.1 Re-purchase Product Recommendation Task

 < 1. Recommending good and new products makes SV Du0.t7il

The conversion rate for the re-purchase product recom-

more attractive in e-commerce sites since it adds more serendip-

mendation task is shown in Table 2. Before the filter is applied, SV Du0.t7il and SV Dusatiml e per-
form significantly better than baseline methods. This is as

ity to the user. To better understand how the proposed method works,
Table 6 shows user u3007's order and Table 7 shows the cor-

expected, since the new algorithm is expected to capture the

responding recommended lists generated by different meth-

re-purchase behavior. SV Dusatiml e is better than SV Du0.t7il before adding the filter,
probably because using similar products introduces some
noise into the model. However, it is worth mentioning that SV Du0.t7il is able to catch some re-purchase behavior ignored by SV Dusatiml e. Some product was not purchased again and again in the training data, yet it is similar to the user's pre-

ods.
User u3007 purchased product 915 in the training data. In the SV Dusatiml e method, only the marginal (net) utility of the exact same product 915 will be changed. Since product
915 was purchased by the other user(s) for many times, it is recommended to user u3007 by SV Dusatiml e. In the SV Du0.t7il method, the marginal (net) utility of similar products will

vious purchase. If such product is purchased in the test-

also be changed, including product 914. Its estimation shows

ing data, the re-purchase behavior can only be captured by SV Du0.t7il yet not SV Dusatiml e. For methods with filter, SV Du0.t7il.P revious performs the best.
Here is one example. Table 3 shows product 2426's entire

that product 914 has a higher marginal net utility. Thus it appears in the top position of SV Du0.t7il recommended list,
which was actually purchased by the user in the testing

order history in the training data. Table 4 shows the prod-

uct title of product 2426 and some of its similar products.
2426 was purchased only once by each of the five users. In this case, SV Dusatiml e cannot learn that it is a potential repurchase product. Yet user u2613 purchased two products
(2365 and 1329) before, which are similar to product 2426. With this information, SV Du0.t7il learns that product 2426 is likely to be purchased again after a user purchases a similar product or itself. In the testing data, SV Du0.t7il recommends product 2426 to user u2857 at timestamp 12/1/08,17:52. It
was purchased by user u2857 at that time, which is a re-
purchase behavior.

Table 5: Conversion rate@K for the new product

recommendation task. Value* is significantly better

than the baseline SV Dmatrix and TopPop.

Method

K=1 K=2 K=3 K=4 K=5

for usern>0 and all products

(90.64% orders contain new purchase)

TopPop

0.0002 0.0002 0.0005 0.0005 0.0007

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0002 0
0.0007

0.0002 0
0.001

0.0007 0
0.0024

0.0007 0
0.0026

for usern>0 and productsn>0

(76.20% orders contain new purchase)

0.0010 0.0002 0.0026

TopPop

0.0007 0.0007 0.0013 0.0013 0.0020

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0007 0
0.0020

0.0007 0
0.0027

0.0020 0.0020 0.0027

0

0

0.0007

0.0066* 0.0073* 0.0073*

TopPop.Previous 0.0007 0.0007 0.0013 0.0013 0.0020

SV Dmatrix.N ew SV Dusatiml e.N ew SV Du0.t7il.N ew

0.0020 0.0020 0.0027 0.0027 0.0027 0.0007 0.0020 0.0020 0.0020 0.0027 0.0047 0.0073* 0.0086* 0.0100* 0.0113*

1010

Table 6: user u3007's purchase order

times

productID

product title

In the training data

915

Frontline Top Spot DOG up to 22lb (3 pack)

9/28/08 0:20

1049

Pet Bio Guard Shampoo

1033

Frontline Top Spot DOG 89-132lb. (3 pack)

10/23/08 8:37

In the testing data

914

Frontline Top Spot DOG 45-88lb. (3 pack)

293

Frontline PLUS - Dog (23 to 44 Lbs) 3-Pack

150

Figure 2: Popularity (purchase count) of all products in the training data

100

purchase count

Table 7: Top 5 recommendation for user u3007 at time 10/23/08 8:37

Method TopPop

ProductID 165 166 322 1611 1924

Product title Frontline PLUS - Dog (45-88 Lbs)
Frontline PLUS - Cat 3-Pack Pet Solid Compressed Rawhide Bone - 5" Frontline PLUS - Dog up to 88 lbs. (6-Pack) 9" x 12" Colorations Heavyweight Construction Paper

SV Dmatrix

165 1611 166 1593 2028

Frontline PLUS - Dog (45-88 Lbs) Frontline PLUS - Dog up to 88 lbs. (6-Pack)
Frontline PLUS - Cat 3-Pack Frontline PLUS - For Cats (6-Pack) Colorations Simply Washable Tempera Paint

SV Dusatiml e

915 1033 1049 2978 2678

Frontline Top Spot DOG up to 22lb (3 pack) Frontline Top Spot DOG 89-132lb. (3 pack)
Pet Bio Guard Shampoo Nasal Aspirator
Brother LC51BK Compatible Black Ink Cartridge

SV Du0.t7il

914 1033 1610 915
30

Frontline Top Spot DOG 45-88lb. (3 pack) Frontline Top Spot DOG 89-132lb. (3 pack) Frontline Top Spot DOG up to 22lb (6 pack) Frontline Top Spot DOG up to 22lb (3 pack) Frontline Top Spot CAT (3 pack)

data. With these examples in the data, we discover that it is worthwhile to model the purchase decision based on the product's marginal net utility. The utility function can capture much information from consumer behavior.
After a filter is applied, SV Du0.t7il.N ew performs better than the baseline SV Dmatrix and the difference is significant.
5.4 Long-tail Product Recommendation Task
It is well known that the number of rated items follows a long-tail distribution, i.e., a small fraction of the most popular ones receive the majority of ratings (or purchase counts) [2]. Figure 2 plots the popularity (purchase count) of all products, reflecting that the majority of products were purchased by a few times ( 5). The 80:20 rule [7] is commonly used to divide between long-tail products and popular ones. In shop.com dataset, the short-head (20%) involves 0.814% of popular products. All the rest are long-tail products.
As mentioned in [9], to recommend popular products is easier yet more trivial. On the other hand, to recommend long-tail products adds more novelty yet it is also a harder task, due to the data sparsity issue. Though our algorithm is not targeted for recommending long-tail products, we would like to see how SV Du0.t7il and SV Dusatiml e perform from this perspective. 96.09% of purchase orders in the testing data contain long-tail products. Only long-tail products in these testing orders are used to evaluate all methods' performance.
Table 8 shows the conversion rate of all methods for longtail products. As expected, T opP op cannot recommend any long-tail products. By maximizing the marginal net utility, SV Du0.t7il and SV Dusatiml e can improve the baseline significantly. As long as the marginal net utility factor can be learned, the improvement is achieved for long-tail products.

50

0

200

400

600

800

1000

top 1000 products in decreasing order of popularity

Table 8: Conversion rate@K for the long-tail

product recommendation task(96.09% of all testing

points). Value* is significantly better than the base-

line SV Dmatrix and TopPop.

Method

K=1 K=2 K=3 K=4

for usern>0 and all products

K=5

TopPop

0

0

0

0

0

SV Dmatrix SV Dusatiml e SV Du0.t7il

0.0052 0.0108 0.0187 0.0225 0.0292 0.0148* 0.0267* 0.0364* 0.0396* 0.0416* 0.0108* 0.0200* 0.0272* 0.0335* 0.0360*

6. CONCLUSION AND FUTURE WORK
Inspired by the utility function in consumer behavior theory, we design a general framework to revamp existing recommendation algorithms for e-commerce sites. We apply it to SVD, which leads to a new algorithm SV Dutil. We evaluate two special cases of the new algorithm: SV Du0.t7il and SV Dusatiml e. The former one utilizes similar products in estimating the marginal utility while the latter one utilizes only the same product. These two methods use each purchase decision point in the data sequentially for the parameter estimation. On shop.com data, the new methods perform significantly better than baselines because they can better capture the re-purchase behavior as well as the diminishing return of the marginal utility. When comparing between these two cases, we found that SV Dusatiml e performs better in the re-purchase product recommendation task. SV Du0.t7il is more useful in recommending new products, which is a harder task and generates more interesting result to the user.
This is just the first step towards revamping recommendation algorithms based on the concept of marginal net utility. In this work, the marginal utility diminishing rate only depends on each product. In the future, we plan to do more research to explore its dependency on each user, different time, or other features. Besides, the latent vectors and products' diminishing return rate are not updated online in the current work. In the future, online updating and online testing would be implemented to reflect real-world scenario. In addition, the rich implicit data can also be utilized to train our model better.

1011

Acknowledgments
We would like to thank shop.com for sharing the data. This work was funded by National Science Foundation IIS-0713111 and IIS-0953908. Any opinions, findings, conclusions or recommendations expressed in this paper are the authors, and do not necessarily reflect those of the sponsors.
7. REFERENCES
[1] C. C. Aggarwal, J. L. Wolf, K. lung Wu, and P. S. Yu. Horting hatches an egg: A new graph-theoretic approach to collaborative filtering. In Proceedings of the Fifth ACM SIGKDD, 1999.
[2] C. Anderson. The Long Tail: Why the Future of Business Is Selling Less of More. Hyperion, 2006.
[3] W. J. Baumol and A. S. Blinder. Microeconomics: Principles and Policy. South-Western College Pub, 11 edition, July 2008.
[4] J. Bennett and S. Lanning. The netflix prize. 2007. [5] J. S. Breese, D. Heckerman, and C. Kadie. Empirical
analysis of predictive algorithms for collaborative filtering. pages 43­52. Morgan Kaufmann, 1998. [6] R. Burke. Hybrid recommender systems: Survey and experiments. User Modeling and User-Adapted Interaction, 12:331­370, 2002. [7] Y. Chen, P. P. Chong, and Y. Tong. Theoretical foundation of the 80/20 rule. Scientometrics, 28(2):183­204, October 1993. [8] C. Cobb and P. Douglas. A theory of production. American Economic Review, 18:139 ­ 165, 1928. [9] P. Cremonesi, Y. Koren, and R. Turrin. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the fourth ACM conference on Recommender systems, pages 39­46, New York, NY, USA, 2010. ACM. [10] M. Deshpande and G. Karypis. Item-based top-n recommendation algorithms. ACM Trans. Inf. Syst., 22(1):143­177, 2004. [11] D. Fleder and K. Hosanagar. Blockbuster culture's next rise or fall: The impact of recommender systems on sales diversity. Manage. Sci., 55:697­712, May 2009. [12] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In Proceedings of the 22nd annual international ACM SIGIR, pages 230­237, New York, NY, USA, 1999. ACM. [13] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. Evaluating collaborative filtering recommender systems. ACM Trans. Inf. Syst., 22:5­53, January 2004. [14] T. Hofmann. Latent semantic models for collaborative filtering. ACM Trans. Inf. Syst., 22(1):89­115, 2004. [15] Z. Huang, W. Chung, and H. Chen. A graph model for e-commerce recommender systems. J. Am. Soc. Inf. Sci. Technol., 55:259­274, February 2004. [16] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative filtering with decoupled models for preferences and ratings. In Proceedings of the twelfth CIKM, pages 309­316, New York, NY, USA, 2003. ACM. [17] Y. S. Kim, B.-J. Yum, J. Song, and S. M. Kim. Development of a recommender system based on

navigational and behavioral patterns of customers in e-commerce sites. Expert Syst. Appl., 28:381­393, February 2005.
[18] Y. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '08, pages 426­434, New York, NY, USA, 2008. ACM.
[19] Y. Koren. Collaborative filtering with temporal dynamics. In KDD '09: Proceedings of the 15th ACM, pages 447­456, New York, NY, USA, 2009. ACM.
[20] S. li Huang. Designing utility-based recommender systems for e-commerce: Evaluation of preference-elicitation methods. Electronic Commerce Research and Applications, In Press, Corrected Proof:­, 2010.
[21] B. Marlin and R. S. Zemel. The multiple multiplicative factor model for collaborative filtering. In ICML '04: Proceedings of the twenty-first international conference on Machine learning, page 73, New York, NY, USA, 2004. ACM.
[22] B. Mobasher, R. Cooley, and J. Srivastava. Automatic personalization based on web usage mining. Commun. ACM, 43(8):142­151, 2000.
[23] R. J. Mooney and L. Roy. Content-based book recommending using learning for text categorization. In DL '00, pages 195­204, New York, NY, USA, 2000. ACM.
[24] M. Pazzani, D. Billsus, S. Michalski, and J. Wnek. Learning and revising user profiles: The identification of interesting web sites. In Machine Learning, pages 313­331, 1997.
[25] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th WWW conference, pages 285­295, New York, NY, USA, 2001. ACM.
[26] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Analysis of recommendation algorithms for e-commerce. In Proceedings of the 2nd ACM conference on Electronic commerce, pages 158­167, New York, NY, USA, 2000. ACM.
[27] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. T. Riedl. Application of dimensionality reduction in recommender system ­ a case study. In IN ACM WEBKDD WORKSHOP, 2000.
[28] J. B. Schafer, J. A. Konstan, and J. Riedl. E-commerce recommendation applications. Data Min. Knowl. Discov., 5:115­153, January 2001.
[29] G. Shani, D. Heckerman, and R. I. Brafman. An mdp-based recommender system. J. Mach. Learn. Res., 6:1265­1295, 2005.
[30] L. Si and R. Jin. Flexible mixture model for collaborative filtering. In Proc. of ICML, pages 704­711. AAAI Press, 2003.
[31] H. Uzawa. Production functions with constant elasticities of substituion. Review of Economic Studies, 29(4):291­299, Oct 1962.

1012

