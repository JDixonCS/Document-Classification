Learning Features through Feedback for Blog Distillation

Dehong Gao, Renxian Zhang, Wenjie Li, Yiu Keung Lau, Kam Fai Wong
Department of Computing, The Hong Kong Polytechnic University, Hong Kong City University of Hong Kong, Hong Kong, The Chinese University of Hong Kong, Hong Kong
{csdgao, csrzhang, cswjli}@comp.polyu.edu.hk, raylau@cityu.edu.hk, kfwong@se.cuhk.edu.hk

Abstract
The paper is focused on blogosphere research based on the TREC blog distillation task, and aims to explore unbiased and significant features automatically and efficiently. Feedback from faceted feeds is introduced to harvest relevant features and information gain is used to select discriminative features. The evaluation result shows that the selected feedback features can greatly improve the performance and adapt well to the terabyte data.
Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Search Process
General Terms
Design, Experimentation
Keywords
Blog Distillation, Faceted Distillation, Feedback
1. Introduction
With the accelerated growth of social network, both organizations and individuals have shown great interest in conveying or exchanging ideas and opinions. The blogosphere provides an ideal platform for communication. According to the statistics of Blogpulse (blogpulse.com) in Jan. 2011, more than 152 million blogs have been published (more than 47,000 blog posts per day). One interesting issue related to the massive blogs is to automatically explore authors' behaviors from their blog posts.
Focusing on this issue, TREC introduces the blog distillation track in 2009 with two subtasks: baseline distillation and faceted distillation. The purpose of the former is to retrieve all the relevant feeds corresponding to given topics without any consideration of facets. The latter aims to rerank the baseline feeds according to specific facets [1].
At present, most published work deals with the two subtasks in sequence. Retrieving the relevant feeds according to given queries is regarded as a common IR task. For faceted distillation, several methods have been attempted. In [3], SVM and ME classifiers are introduced to predict the faceted inclinations of each feed according to pre-trained models. In [2], feed faceted scores are heuristically given to re-rank feeds. For classification as well as re-ranking, the challenge is to select the features related to each inclination. Most work above focuses on exploring heuristic features like permalink numbers or comment numbers. However, we observe that for some facets these features are far from enough. In view of this, we first discover more (non-heuristic) feature candidates with faceted feedback information. Then, a feature selection approach is employed to select discriminative features. Furthermore, we take some flexible processing to adapt to the massive dataset. In a word, we believe this can help us to explore
Copyright is held by the author/owner(s). SIGIR11, July 24-28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

the significant features automatically and efficiently. In the remainder of this paper, more details of our approach are given in Section 2; then the evaluation of baseline and faceted distillations is presented in Section 3; Section 4 concludes the whole paper.
2. Blog Distillation
Since the faceted blog distillation is based on the baseline distillation, we briefly introduce the latter first. To enhance efficiency in the face of the huge and noisy raw data (2.3TB), we implemented a distributed system and adopted the Indri tool (www.lemurproject.org) for our purpose, with its default language model and related toolkits. With the help of these tools, the top related feeds can be retrieved according to given topics in the baseline distillation.
Based on the ranking of the baseline distillation, we then focus on the faceted blog distillation subtask. The TREC 2010 task specifies three inclination pairs: opinionated vs. factual, personal vs. official, and in-depth vs. shallow, for operational simplicity [1]. According to those inclinations, the baseline feeds are to be reranked. The key issue is to discover the relevant and discriminative features for each faceted inclination, and determine the weight of each feature.
To solve the issue above, our approach explores features from three orientations: heuristic features, available lexicons, and corpora. Heuristic features, which have been used in some existing work, include Average Permalink/Sentence Length, Comment number, Organization Numbers, Opinion Rule, etc, which can be helpful for distinguishing some inclinations. In our method, besides these heuristic features we also use the statistics of the presence of Cyber Words and Cyber Emoticons (like `LOL' and `') in feeds, which provides clues to personal and official feeds. To discover the lexicon features, the SentiWordNet (sentiwordnet.isti.cnr.it) and Wilson Lexicon are used to manually select about 1500 opinion words as our own opinion lexicon. These two lexicons are vital in identifying the opinionated inclination feeds. However, most of these features suit the opinionated inclination and may not work well in other inclinations, and may introduce noise for other inclinations, especially for the factual and shallow inclinations. Thus, in order to discover more relevant features, we take the effort to explore some useful features from corpora.
Here, we propose a feature expansion approach by learning more feature candidates through feedback information of faceted feeds. Since TREC has released some faceted feeds for each topic, we can select some faceted-related word unigrams in the top ranking faceted feeds as new feature candidates according to the official release. These features are mainly opinion-independent words and unbiased for particular inclinations, resulting in more balanced feature structure.
A byproduct of feature expansion is that the unprocessed feature candidates contain too much useless information, which not only wastes computing resources but also harms the performance.

1085

Therefore, we need to select the top discriminative features with feature selection methods. For fast and efficient handling of large and noisy data, the filter approach, rather than wrapper approaches is adopted [4].

With lexicon-based features and feedback features, an unanswered question is how to determine the weight of both features. Though each opinion word has a polarity weight and a feature selection measure is assigned to each feedback term, these weights are not in the same scale. To unitize the weights of selected features, for each inclination we conduct a SVM classifier with a linear kernel and calculate the weight of a support vector from the trained model that corresponds to a feature. The feeds are re-ranked with the summation of the products of the feature values and their weights.

3. Evaluation
Our experiment is conducted on the blog08 collection crawled over 14 weeks. It contains permalinks, feeds, and related information. The size of the blog08 collection is up to 2.3TB. In order to efficiently handle the terabyte dataset and reduce noise, the raw dataset is first cleaned and filtered by several regular expression rules, which reduce the size to 30%. Then, Indri is used to index the cleaned blog08 collection, and fetch the top 2000 related blog posts according to the 50 topics provided in TREC2009. Since feeds are what the task is concerned with, we rank the feeds by summing the relevance scores of retrieved blog posts corresponding to the same feed number. The top 100 relevant feeds are obtained and evaluated in table 1, and TREC provides four measures: the mean average precision (MAP), RPrecision (rPrec), binary Preference (bPref) and Precision at 10 documents (P@10), among which MAP is the primary measure for evaluating the retrieval performance [1].
Table 1: Evaluation of baseline distillation and comparison with official best, median and worst

Baseline Distillation MAP R-Prec P@10 B-Pref

Language model 0.2494 0.3047 0.3590 0.2611

Official best

0.2756 0.2767 0.3206 0.3821

Official median 0.1752 0.1986 0.2447 0.3282

Official worst 0.0624 0.0742 0.0980 0.1410

As shown in table 1, our Indri-based language model run ranks

competitively against official submissions. Based on our baseline

feed ranking, we conduct the faceted distillation.

We first collect the lexicon features and the feedback features

from the top ranking five feeds as feature candidates for feature

selection. There are several commonly used feature selection

approaches, and according to [4], information gain (IG) selects

some negative features, but also has a bias for positive features.

Thus, in our experiment IG is used to select features, and the

formula is as follows:

,

|

where Ex is the set of all training examples; H(x) represents the

entropy;

, the set of all attributes. Instead of using all

instances in the official released answers, we calculate H(Ex|a)

using the top five feeds in our experiment. The change can

greatly reduce the complexity of computing and make our

approach more adaptable for the massive data collection. The top

five feeds are a good surrogate for the whole feed set as they are

statistically found to contain an approximately equal number of

faceted and non-faceted feeds. More importantly, this "shortcut

approach" adapts very well to the large dataset. We select the top

2,000 features (about 10% features in all feature candidates). To

determine the weights of these features, an SVM classifier is

conducted with these features for each inclination. We use the

same strategy to randomly divide the top five feeds into training

and testing datasets (ratio 4:1). Then, the weights of support vectors are calculated from trained models as the weights of these features for facet re-ranking. With selected features and their weights, feeds are re-ranked according to each inclination, and for comparison, ranking without feedback features (W/O Feedback) are evaluated as well.
Table 2: Evaluation against each inclination

Faced Distillation

MAP All Opin Fact Pers Offi Indp Shal

Best 09 0.1261 0.1259 0.1350 0.1855 0.1965 0.1489 0.1298 W/O Feedback 0.1022 0.1340 0.0222 0.1754 0.1143 0.1859 0.0701

Feedback+IG 0.1521 0.1596 0.1275 0.2360 0.1702 0.2159 0.0554
From the evaluation (Table 2), compared with re-ranking without feedback features (W/O Feedback), re-ranking with feedback features (Feedback+IG) achieves a significant improvement, and outperforms the best of official runs. From the evaluation against each inclination, we can find that great improvements are observed for factual, personal and official identification. It is thus plausible that those inclinations may be more amenable to the usage of words rather than some heuristic features. One exception is the degradation of the shallow inclination performance, which may suggest that information gain is not suitable for selecting discriminative features and thus introduces noise for shallow inclination.

In the last experiment, comparisons are made to investigate the influence of different numbers of features selected.

Figure 1: Re-ranking with different number of features Figure 1 shows that the with-feedback (W/I feedback) and without-feedback (W/O feedback) approaches peak at 500 features and 50 features, respectively. The flat tail of withoutfeedback approach can be explained by the fact that only about 750 out of the 1500 features (shown by the points in the circle) are present in the features. The bottom line shown in this figure is that re-ranking with feedback feature outperforms the performance of that without feedback. Thus, this proves that feedback features are obviously efficient in faceted blog distillation.
4. Conclusion
To sum up, feedback feature expansion coupled with feature selection is effective and efficient for faceted blog distillation and adapts well to the terabyte dataset. It helps to automatically discover relevant and discriminative features. In the future, besides expanding features with unigrams, a possible extension is to learn some term combinations from unigrams.
Acknowledgements
The work presented in this paper is supported by a Hong Kong RGC project (No. PolyU 5230/08E).
5. References
[1] http://ir.dcs.gla.ac.uk/wiki/TREC-BLOG.
[2] Mostafa Keikha, Mark Carman, et al 2009. University of Lugano at
TREC2009 Blog Track. Proceeding of TREC09. Lugano, Swiss.
[3] Richard McCreadie, Craig Macdonald, Iadh Ounis, et al 2009.
University of Glasgow at TREC2009: Experiments with Terrier. Proceeding of TREC2009. Glasgow, Scotland, UK.
[4] Hua Liu, Hiroshi Motoda 2007. Computational Methods of Feature
Selection. Chapman&Hall/CRC, P257-268, London.

1086

