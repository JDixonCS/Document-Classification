Optimizing Multimodal Reranking for Web Image Search

Hao Li

Meng Wang

Zhisheng Li

Inst. of Computing Technology National Univ. of Singapore National Univ. of Singapore

Chinese Academy of Sciences eric.mengwang@gmail.com lizs@comp.nus.edu.sg

lihao@ict.ac.cn

Zheng-Jun Zha

Jialie Shen

National Univ. of Singapore Singapore Management Univ.

zhazj@comp.nus.edu.sg jlshen@smu.edu.sg

ABSTRACT
In this poster, we introduce a web image search reranking approach with exploring multiple modalities. Different from the conventional methods that build graph with one feature set for reranking, our approach integrates multiple feature sets that describe visual content from different aspects. We simultaneously integrate the learning of relevance scores, the weighting of different feature sets, the distance metric and the scaling for each feature set into a unified scheme. Experimental results on a large data set that contains more than 1,100 queries and 1 million images demonstrate the effectiveness of our approach.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Retrieval models
General Terms
Algorithms, Experimentation, Performance
Keywords
Image Search; Reranking; Graph-based Learning
1. INTRODUCTION
Commercial image search engines, such as Google, Yahoo and Bing, usually index web images using textual information, such as images' titles and ALT text and the surrounding texts on web pages. However, frequently the text information does not describe the content of images, and it can severely degrade the web image search performance. Reranking is an approach to boosting image search performance by adjusting search results based on images' visual information [1][2][4][5][6]. Typically, image search reranking is based on two assumptions: (1) the results after reranking should not change too much from the initial ranking list; and (2) visually similar images should be close in ranking lists. These two assumption usually can be formulated as a graph-based learning scheme, where vertices are images and edges indicate the pairwise similarities [1][2][5].
Although many different reranking algorithms have been proposed, existing results show that reranking is not guaran-
Copyright is held by the author/owner(s). SIGIR'11, July 24­28, 2011, Beijing, China. ACM 978-1-4503-0757-4/11/07.

teed to improve performance. In fact, in several cases search performance may even degrade after reranking. One reason is that the second assumption does not hold for the employed feature space. Actually the effective features should vary across queries.
In this work, we propose a web image search reranking approach with multiple modalities. Here a modality is regarded as a description of images, i.e., a feature set. Our proposed scheme integrates multiple modalities in a graphbased learning framework. It simultaneously learns the relevance scores, the weighting of different modalities, the distance metric and the scaling for each modality. The effects of different modalities can be adaptively modulated for each query. Although multiple modalities are involved, there are only two parameters in our algorithm.

2. MULTIMODAL RERANKING

2.1 Formulation

Generally, graph-based reranking can be formulated as a regularization framework as follows

r = min Q(r, ¯r, X) = min R(r, X) + L(r, ¯r) (1)

r

r

where r = [r1, r2, . . . , rN ]T is the ranking scores corresponding to a sample set X = [x1, x2, . . . , xN ]T . Here the term R(.) is the regularization term that models the assumption
that visually similar images should be close, and the term
L(.) is a loss term that estimates the difference between r and ¯r. For the first term, it is usually formulated as

R(r, X) = wi,j
i,j

ri - rj 2 dii djj

(2)

where W is a similarity matrix in which wij indicates the visually similarity of xi and xj, and dii indicates the sum of the i-th row of W.
Now we extend the scheme to obtain our algorithm. First, considering using one modality, we use Mahalanobis distance metric instead of the Euclidean distance metric
wij = exp(-(xi - xj )T M(xi - xj )) = exp(-||A(xi - xj )||2) (3)
Then we consider there are K modalities. Here we linearly combine the regularizer terms, i.e.,

K

R(r, A1, . . . , AK , ) =

k wk,ij

k=1 i,j

ri - rj 2 dk,ii dk,jj
(4)

1119

where wk,ij = exp(- Ak(xi-xj ) 2) and k is the weight for

k-th modality that satisfies 0  k  1 and

K k=1

k

=

1.

As previously mentioned, we integrate the learning of the

weights into our regularization framework in order to adap-

tively modulate the impacts of different modalities. There-

fore, the regularizer term turns to

K

R(r, A1, . . . , AK , )=

k wk,ij

k=1 i,j

ri - rj dk,ii dk,jj

2
+||||2

(5)

For the loss term, usually it estimates the difference be-

tween two ranking lists. Here we directly use the square loss.

Therefore, our algorithm can be formulated as the following

optimization problem

K

min

k wk,ij

r,A1

,...,AK

, k=1

i,j

ri - rj

2
+||r-¯r||2+  2

dk,ii dk,jj

K

s.t. 0  k  1, k = 1

(6)

k=1

We can see that this optimization framework involves the following variables: (1) r, the ranking scores to be estimated; (2) , the weights for combining K modalities; and (3) Ak, (1  k  K), the transform matrices for K modalities.

2.2 Solution

We adopt alternating optimization to solve the problem. First, we consider  and Ak(k = 1, 2, ..., K) are fixed, then r can be solved with a closed-form solution. Second, we consider r, , and A1, . . . , Ak-1, Ak+1, . . . , AK are fixed, then we derive the derivative of Q with respect to Ak. It can be derived that

 Ak Q(r, , A1, . . . , AK )

=k

i,j

(h2ij

 wk,ij Ak

-wkT,ij hij (

ri dk,ii - d3k,ii Ak

rj dk,jj )) d3k,jj Ak

where

hij

=

ri dk,ii

-

rj dk,jj

,

= dk,ij
Ak

, N Wk,ij
j=1 Ak

 wk,ij Ak

=-2wk,ij Ak(xi(k)-xj(k))T

(xi(k)-x(jk))

Thus,

Ak

can

be

optimized with gradient descent method.

Finally, considering r and Ak(k = 1, 2, . . . , K) are fixed,

then Eq.6 becomes:

K
min
 k=1

i,j

ak

wk,ij

||

ri dk,ii

-

rj ||2 dk,jj

+



2

(7)

K
s.t. 0  k  1, k = 1
k=1

We can employ coordinate descent method to solve Eq.7. We can iterate the optimization of r, A1, A2, . . . , AK and . Since each step decreases the objective in Eq.6 and the value of the objective function is lower bounded by 0, the whole process is guaranteed to converge.

3. EXPERIMENTS AND CONCLUSION
We evaluate our approach with several existing methods on the large-scale image search dataset, MSRA-MM Version 2.0[3], that contains the search results (1,011,738 images in total) of 1,165 queries from Microsoft Bing image search

Table 1: Average NDCG@100 comparison for each cat-

egory of different reranking methods and the original

search results. Here Ver1, Animal, Cartoon, Event, Per-

son, Object, People, Scene, Time08 and Misc are the 10

query categories in MSRA-MM dataset.

Baseline Bayesian Concatenation Multimodal

Ver1

0.544

0.542

0.556

0.568

Animal 0.734

0.775

0.758

0.791

Cartoon 0.807

0.859

0.842

0.865

Event

0.788

0.779

0.797

0.811

Person 0.908

0.916

0.926

0.940

Object 0.703

0.723

0.722

0.745

People 0.714

0.703

0.718

0.742

Scene

0.702

0.766

0.735

0.792

Time08 0.830

0.844

0.863

0.870

Misc

0.736

0.760

0.771

0.790

Mean

0.747

0.770

0.773

0.795

engine. In [3], the queries are manually classified into 10 categories, and each image is labeled with 3 relevance levels (0, 1, and 2). There are 7 feature sets are extracted. We compare the following methods:
(1) Bayesian rerankingBayesianReranking[5]. We concatenate all features into a long vector and then perform the preference strength based method in [5].
(2) Graph-based reranking with concatenated features. That is, we concatenate all the features into a long vector and then perform graph-based reranking.
(3) Proposed multimodal reranking algorithm. For the initial relevance score of i-th ranking position, we estimate it by averaging the ground truth scores at the i-th position of all 1,165 queries.
The methods are denoted as "Bayesian", "Concatenation" and "Multimodal", respectively. For all the involved parameters, we tune them to their optimal values on the 68 queries in of Ver1 with the performance evaluation metric of average NDCG@100, and then these parameters are fixed in the processing of all queries.
Table 1 illustrates the average NDCG@100 measurements of the queries in each category after reranking. We also demonstrate the performance of original search results without reranking. From the table we can see that, in average, all the reranking methods can improve the original search results. Our method performs the best for all categories. Its superiority over the "Concatenation" method demonstrates the effectiveness of our approach of integrating multiple modalities. All the experimental results clearly demonstrate the effectiveness of our approach.
4. REFERENCES
[1] W. H. Hsu, L. S. Kennedy, and S.-F. Chang. Video search reranking through random walk over document-level context graph. In ACM MM, 2007.
[2] M. Wang, K. Yang, X.-S. Hua, and H.-J. Zhang. Towards Relevant and Diverse Search of Social Images. IEEE Trans. on Multimedia, vol. 12, no. 8, 2010.
[3] H. Li, M. Wang, and X.-S. Hua. Msra-mm 2.0: A large-scale web multimedia dataset. In IEEE ICDM Workshops, 2009.
[4] M. Wang, X.-S. Hua, J. Tang,and R. Hong. Beyond Distance Measurement: Constructing Neighborhood Similarity for Video Annotation. In IEEE Trans. on Multimedia, vol. 11, no. 3, 2009.
[5] X. Tian, L. Yang, J. Wang, Y. Yang, X. Wu, and X.-S. Hua. Bayesian video search reranking. In ACM MM, 2008.
[6] M. Wang, X.-S. Hua, R. Hong, J. Tang, G.-J. Qi and Y. Song. Unified Video Annotation Via Multi-Graph Learning. In Trans. on CSVT, vol. 19, no. 5, 2009.

1120

