Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Stacking Bagged and Boosted Forests for E ective Automated Classification

Raphael Campos, Se´rgio Canuto, iago Salles, Clebson C. A. de Sa´ and Marcos Andre´ Gon¸calves
Federal University of Minas Gerais Computer Science Department Av. Anto^nio Carlos 6627 - ICEx Belo Horizonte, Brazil
{rcampos,sergiodaniel,tsalles,clebsonc,mgoncalv}@dcc.ufmg.br

ABSTRACT
Random Forest (RF) is one of the most successful strategies for automated classi cation tasks. Motivated by the RF success, recently proposed RF-based classi cation approaches leverage the central RF idea of aggregating a large number of low-correlated trees, which are inherently parallelizable and provide exceptional generalization capabilities. In this context, this work brings several new contributions to this line of research. First, we propose a new RF-based strategy (BERT) that applies the boosting technique in bags of extremely randomized trees. Second, we empirically demonstrate that this new strategy, as well as the recently proposed BROOF and LazyNN RF classi ers do complement each other, motivating us to stack them to produce an even more e ective classi er. Up to our knowledge, this is the rst strategy to e ectively combine the three main ensemble strategies: stacking, bagging (the cornerstone of RFs) and boosting. Finally, we exploit the e cient and unbiased stacking strategy based on out-of-bag (OOB) samples to considerably speedup the very costly training process of the stacking procedure. Our experiments in several datasets covering two highdimensional and noisy domains of topic and sentiment classi cation provide strong evidence in favor of the bene ts of our RF-based solutions. We show that BERT is among the top performers in the vast majority of analyzed cases, while retaining the unique bene ts of RF classi ers (explainability, parallelization, easiness of parameterization). We also show that stacking only the recently proposed RF-based classi ers and BERT using our OOB-based strategy is not only signi cantly faster than recently proposed stacking strategies (up to six times) but also much more e ective, with gains up to 21% and 17% on MacroF1 and MicroF1, respectively, over the best base method, and of 5% and 6% over a stacking of traditional methods, performing no worse than a complete stacking of methods at a much lower computational e ort.
 is work was partially funded by projects InWeb (grant MCT/CNPq 573871/20086) and MASWeb (grant FAPEMIG/PRONEX APQ-01400-14), and by the authors' individual grants from CNPq, FAPEMIG, Capes and Google Inc.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080815

KEYWORDS
Classi cation; Ensemble; Bagging; Boosting; Stacking
1 INTRODUCTION
Since the advent of the Web, the amount of data available has grown unprecedentedly. us, organizing and extracting useful information from this enormous amount of data has become an important (if not vital) task for industry and society. By using machine learning techniques to automatically associate documents with classes, Automatic Text Classi cation (ATC) provides means to organize information, allowing be er comprehension and interpretation of the data [1]. Many important applications, such as topic categorization, sentiment analysis, spam ltering, language identi cation, recommender systems, among others, can be e ectively and e ciently solved by automatic textual classi ers. Despite the wide applicability of ATC, text classi cation brings its own challenges, such as high dimensionality and the presence of noise [14]. Properly handling these issues is of great importance to guarantee high classi cation e ectiveness. is is the central topic of this work.
Several machine learning techniques aimed at tackling the challenging ATC problem have been proposed. In particular, ensembles of classi ers have been shown to excel in this situation [4, 6, 23], enjoying high e ectiveness in this domain. In particular, Random Forest (RF) is one of the most successful classi er ensembles in a wide variety of classi cation tasks [8]. Despite being a classi er with great generalization power, it has been shown that RF models may su er from over ing issues [24], having their e ectiveness degraded in the presence of many irrelevant or noisy a ributes--a characteristic of textual classi cation tasks. Recently, some RFbased classi ers were shown to achieve state-of-the-art results in text classi cation by exploiting distinct strategies to mitigate the over ing issue faced by RF, namely, a lazy RF version called LazyNN RF [22], and a boosted RF strategy named BROOF [23]. Both methods learn classi cation models focusing on speci c subregions of the input space, hoping to lter out irrelevant a ributes and data--the primary factors that contribute to RF's over ing.
In this work, we advance the state-of-the-art in text classi cation by proposing a novel derivation of the RF classi er. More speci cally, we propose a new boosted version of the RF classi-
er, based on some ideas explored by the BROOF classi er: the so-called Boosted Extremely Randomized Trees (BERT) classi er. While BROOF is able to mitigate the over ing issue faced by the RF classi er when applied to high-dimensional noisy data, by avoiding the generation of overly complex trees, it o ers limited capability

105

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

of bias reduction (through the so-called selective out-of-bag based weight update strategy). us, bias may still pose as an important factor to contribute to the error rate. To tackle this potential issue, we here propose to introduce another source of randomization in the boosted strategy proposed in [23] in order to be er control the learner's bias, by applying the BROOF-like strategies into the Extremely Randomized Trees (Extra-Trees) classi er [10]. is novel strategy has the following motivations: (i) we expect to avoid overly complex models (and thus mitigate over ing) through the application of the BROOF-like strategies; (ii) to provide more control over the learner's bias through the additional randomization o ered by the Extra-Trees classi er; and, nally, (iii) to exploit the fact that the Extremely Randomized was shown to be more robust to noise than the RF classi er. As we shall see, our proposed classi er outperforms the analyzed state-of-the-art classi ers, including SVM, kNN, Na¨ive Bayes, BROOF, and LazyNN RF, o en by large margins.
is is the rst main contribution of this work. Moreover, motivated by the fact that distinct learning methods may complement each other, uncovering speci c structures that underlie the input/output relationship of the data at hand, in this work we also propose to exploit the complementary characteristics of the recently proposed RF-based approaches and ours, by stacking them in order to learn an even more e ective meta-classi er. As we shall see later, their level of disagreement is high, which motivates our idea. Up to our knowledge, this is the rst a empt to combine the three main ensemble strategies: bagging, boosting and stacking. According to our experiments, the meta-classi er that exploits only RF-based techniques is able to achieve gains of up to 21% and 17% in MicroF1 and MacroF1, respectively, over the best base method, and of 5% and 6% over a stacking of traditional method, being the top performer in all analyzed cases. is is the second main contribution of this work. Finally, when stacking classi ers, one usually relies on k fold cross-validation procedures to estimate the a posteriori class probabilities for each example, to serve as input for the meta-classi er. Based on these predicted a posteriori class distribution estimates, the meta-classi er induces a relationship between these predictions and the true class. However, such estimation strategy may be very costly and sometimes ine ective, since it depends on learning k di erent models to estimate the probability distributions that serve as input for the stacking procedure. In order to cope with this problem, we here propose to exploit the e cient and unbiased outof-bag (OOB) error estimate, an out-of-the-box estimate naturally produced by the bootstrap procedure used in each RF-based learner. us, we avoid additional computation e orts to learn a stacked classi er. According to our ndings, this strategy considerably speeds up the training process of stacking while preserving its high e ectiveness. is is our third main contribution. In summary, the main contributions of this work are: (i) the proposal of a novel RF-based classi er, named BERT, that is able to outperform state-of-the-art classi ers; (ii) the proposal of a new stacking classi er that exploits the complementary characteristics of BROOF, LazyNN RF and BERT that is able to outperform all analyzed classi cation algorithms, including a stacking of traditional methods, o en by large margins; (iii) the proposal of a new estimation strategy based on the exploitation of OOB for generating the input for the stacked meta-classi er that substantially reduces the

computational e ort/runtime of the stacking strategy while retaining its predictive power; and (iv) an extensive experimentation with 15 datasets in two domains ­ topic categorization and sentiment analysis; ­ against several baselines including traditional classi ers (to compare with BERT), several stacking combinations (to compare with the stacking of Forests) and several state-of-the-art stackers (to compare with our OOB-based approach).
Roadmap. Section 2 reviews some relevant literature related to this work. In Section 3 we detail our proposed BERT classi er, providing its motivations, learning strategy details, and extensive experimental evaluation. Section 4 details our proposed method to e ciently stack RF-based methods as well as its experimental evaluation and analysis. Finally, in Section 5 we conclude the paper, pointing out some possible directions for further investigation.
2 RELATED WORK
Ensembles of classi ers are an extensively studied machine learning technique [21]. Among several learning methods used in practice, ensembles are one of the most e ective in several applications and can be divided into two groups: ensembles of homogeneous and heterogeneous classi ers. e former relies on learning many versions of the same classi cation technique, each one built by somehow disturbing the training set. en, usually one averages the predictions in order to come up with nal decisions with higher generalization capabilities. e la er combines a set of distinct learning methods trained with the same training set and then producing the nal decisions according to the predictions made by these classi ers.
Regarding the text classi cation realm, in [7], the authors use what they call Moderated Asymmetric Na¨ive Bayes (MANB) as a base learner in their homogeneous ensemble con guration. Several homogeneous ensemble methods are contrasted, such as k-fold partitioning, bagging and boosting, as well as a heterogeneous ensemble method which combines SVM and NB learning algorithms. In [23], the authors combine two well-known homogeneous ensemble techniques, bagging and boosting, by exploiting Random Forests (RF) as "weak learners" in the boosting framework. e combination is achieved by means of "smoothly" updating the weights of only the out-of-bag instances. is combination mitigates the over ing issue faced by RF models in textual classi cation tasks and leverages its generalization power. Recently, in [19] the authors empirically evaluate the e ectiveness of ensemble learning methods on textual documents represented by keywords. ey apply di erent keyword extraction strategies on the dataset. e authors evaluate ve di erent homogeneous ensemble methods that use four di erent base classi ers. In [2, 4, 20], ensembles of heterogeneous classi ers are proposed, by combining classical text classi cation methods (e.g., SVM, kNN, NB and Rocchio). In all analyzed cases, signi cant improvements were observed when compared to the traditional classi ers. Furthermore, a combination of several distinct polarity classi ers for Twi er sentiment analysis is proposed in [13]. Unlike these works, we here aim at combining homogeneous and heterogeneous classi ers by stacking di erent RF-based methods in an original manner.
ere are two common techniques to combine predictions of distinct classi ers, namely, xed combining methods and trainable combining methods [18]. An advantage of applying xed

106

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

methods for ensemble systems is that there are no need to train a

meta-classi er since they do not take into consideration the label

information in the meta-level training set when combining the

learners. us, they are less time-consuming than their counter-

parts. Many xed combining methods can be found in literature,

such as Sum, Product, Vote, and Average.

On the other hand, trainable combining methods work on meta-

level data, in order to learn the prediction model. Although ex-

ploiting metal-level data to extract knowledge usually enhances

classi cation e ectiveness, it comes at the price of additional com-

putational e ort [18]. Perhaps, the most relevant studies about trainable combining

methods are based on Stacking (a.k.a. Blending), which was orig-

inally conceived as "Stacked Generalization" by Wolpert [27]. In

this case, a meta-level training set Dmeta is generated by applying

a cross-validation procedure, in which the original training set

Dtr ain is divided into T equally sized disjoint sets. Each base-level

classi er is learned by considering Dtr ain \ Ft as training set and

reserving Ft for testing. Formally, i = 1, ..., K : t = 1, ...,T :

Cit = Li (Dtr ain \ Ft ). Subsequently, each learned classi er Cit pro-

duces a estimation for the posterior observation xj belongs to a class cm ; (pit (c1 |xj ), pit (c2 |xj ), ..., pit (cM |xj )).

prxojbabFiltit:yCpitit((xcjm)

|x =

j ) that pit (xj )

an =

e obtained meta-level train-

ing set Dmeta is thus:

 p1( 1 |x1) . . . p1( M |x1) . . . pK ( 1 |x1) . . . pK ( M |x1) 

 p1( 1 |x2) 

...

p1( M |x2)

...

pK ( 1 |x2)

...

pK ( M |x2)

 

   

...

...

...

...

...

...

...

   

 

p1( 1 |xN )

...

p1( M |xN )

...

pK ( 1 |xN )

...

pK ( M |xN )

 

Finally, a combining classi er is trained on the meta-level training set and used to produce the nal prediction.
Several methods have been designed to exploit label information in the meta-level training set. In one strategy, the predictions of classi ers are grouped according to the given classes and then a template associated with each label is built. ree methods using that strategy are Multiple Response Linear Regression (MLR) [25], Decision Template (DT) [15] and the recently proposed VIG [18]. MLR assumes that each classi er weights di erently each class. In this case, the combining algorithm is based on the M linear combinations of the posterior class probabilities and the associated class weights. e predicted class is then decided by selecting the maximum value among these combinations. e Decision Template strategy [15] groups the meta-level training set according to the classes of each instance. en, Decision Templates are built by averaging the meta-level instances observed in each class (forming centroids). Subsequently, the predicted class is decided by selecting the class label of the Decision Template that is more similar to the meta-data unlabeled observation. To this end, the authors propose eleven similarity functions based on fuzzy logic. Due to its simple computation, this method has low computational cost in both training and testing. In [17] a combination of Stacking, Correspondence Analysis (CA) and K-Nearest Neighbor (KNN) is proposed, in the form of a single learning algorithm called SCANN.
e goal of such algorithm is to nd the underlying relationship between the learning observations and the predictions of the base classi ers, by applying CA to an indicator matrix formed by the learned meta-level instances and their corresponding true labels.
en, a kNN procedure is employed to classify the unseen data

in the new scaled space. Recently, Nguyen et al. [18] proposed a combining classi er based on the variational inference which is based on the assumption that instances belonging to a given class of the meta-level training set are drawn from a multivariate Gaussian distribution. us, M distributions are estimated by using Bayesian variational inference on the instances belonging to each class. e predicted class for a new unseen observation is given by selecting the label associated with maximum posterior probabilities computed by the M multivariate Gaussian models. All aforementioned methods are used as baselines in our stacking experiments.
Moreover, all those methods rely on the meta-level training sets obtained by costly procedures, such as cross-validation while combining bagging-based methods. In contrast, we here propose to take advantage of the out-of-bag (OOB) samples, naturally available by the bagging procedure, to yield an unbiased meta-level training set. is allows our solution to stack bagging-based methods with any other learning method without additional computational cost while using any combining methodology. In fact, some works a empt to improve the bagging procedure by utilizing stacking to combine the base classi ers [25, 26]. For instance, in [25] the authors propose a variant of bagging, where stacking rather than uniform majority voting is used to achieve the combination. e meta-level training set is obtained by the predictions of the each base learner over the original training set, which can lead the metaclassi er to over t. In contrast to [25], in [26] the authors propose a linear combination in which the coe cients are estimated by the OOB error, thus generating a less biased combination. ose methods di er from ours since here we construct the meta-level data for bagging-based methods in a distinct manner, while also treating them as black-boxes when combining them with any other learning method.

3 THE BERT CLASSIFIER
In this section, we detail BERT, a boosted version of the RF classi er that aims at taking the advantages of BROOF while avoiding its potential bias tendency. As we detail in the following, BERT introduces an additional source of randomization to reduce bias, while, at the same time, exploiting the advantages of the boosting strategy, in order to achieve superior generalization. We start our discussion with a brief overview of the BROOF strategy. en, we describe the key building block for the BERT strategy, namely, Extremely Randomized Trees. Finally, we describe BERT.

3.1 BROOF

Proposed in [23], the BROOF classi er combines boosting and bag-

ging by exploiting RF as "weak learners" in a boosting framework.

Boosting is a sequential meta-algorithm which trains several "weak

learners" (that is, classi ers capable of yielding predictions be er

than random guessing) in order to generate a more precise model. For each iteration i of the boosting algorithm, let i be a probability

distribution over the training set of size M.

When i

=

0, 0(j) =

1 M

,

j |jM=1. At iteration i > 0, for all examples in the training set xj , if xj

is misclassi ed, its weight is incremented so that, in the succeeding iteration, an updated distribution i+1 is considered, which empha-

sizes the misclassi ed instances (e.g, the hardest to classify ones).

In contrast to AdaBoost [9], the update rule in BROOF uses the

107

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

out-of-bag (OOB) samples, promptly generated by the RF classi er at training time, as an unbiased error estimate to drive the boosting iterations and "smoothly" reweights just the OOB instances.
In [23] the authors show that restricting the in uence of training data to the hard-to-classify sub-regions of the input space, by means of a smooth combination of random forests and boosting, can mitigate the over ing issue observed when learning decision trees composing the ensemble classi er, thus leveraging classi cation e ectiveness on new unseen data. Also, the selective weight update strategy slows down boosting's tendency to focus on just a few hard-to-classify samples, thus o ering some bias reduction capabilities. ese ideias were even extended and generalized to realm of learning-to-rank (L2R) tasks [5].
However, although BROOF was shown to provide competitive results in text classi cation and L2R tasks, this can be mainly a ributed to variance reduction, since its limited bias reduction capability may not be enough to fully mitigate its tendency to overly emphasize hard-to-classify examples, mainly in noisy environments. is has to do with the underlying boosting strategy adopted by BROOF and may compromise classi cation e ectiveness. We here propose to tackle the potentially high bias faced by BROOF by means of an additional source of randomization, through the use of the so-called extremely randomized trees, described in the following.
3.2 Extremely Randomized Trees
Extremely Randomized Trees (a.k.a., Extra-Trees) [10] is an ensemble of trees similar to the RF. Unlike RFs, Extra-Trees do not bootstrap the training data when learning its composing trees. Instead, it uses the entire training set for doing so, relying on another more aggressive source of randomization to learn decorrelated trees. More speci cally, while RF builds its trees by using bootstrapped samples from the training set, de ning the decision nodes in order to optimize some information theoretic statistic (such as Information Gain, Chi Squared or Gini Index), the Extra-Trees classi er de nes the decision nodes in a purely random fashion, thus guaranteeing reduced tree correlation in the ensemble.
e Extra-Trees classi er has some bene ts when compared to RF classi ers. Besides yielding be er classi cation e ectiveness, it has been shown that Extra-Trees is more robust to noise than RFs. In this work, we take advantage of BROOF-like techniques and ExtraTrees, by proposing what we call BERT, a smooth combination of both, as detailed next.
3.3 Boosted Extremely Randomized Trees
Recall that boosting algorithms tend to overly emphasize hard-toclassify examples, mainly when applied to noisy data. erefore, the undesired bias towards these hard-to-classify examples is minimized by BROOF by updating only the probabilities i related to out-of-bag samples as proposed in [23], hoping to decrease the misclassi cation rate when the "weak learner" is focused on hardto-classify regions. Hence, by using a "weak learner" more robust to noisy data than Random Forests such as Extra-Trees [10], it is expected to achieve be er performance when focused on hard-toclassify regions, thus, producing a model with higher generalization power. In fact, as we shall see, BERT is among the top performer

classi ers in all tested datasets, outperforming the original BROOF in several cases
BERT combines boosting and Extra-Trees, by exploiting the following BROOF-like strategies: (i) to use the out-of-bag (OOB) error estimate as a less biased error estimation to drive the boosting algorithm; and (ii) to only update the weights of the out-of-bag instances during the boosting iterations. In order to smoothly combine these ideas to the Extremely Randomized Trees framework, we propose to introduce the bagging procedure into its training procedure, in order to allow proper OOB error estimation.
We argue that exploring these strategies through this novel classi cation framework brings two bene ts: (i) it enables us to minimize variance (mitigating the over ing problem faced by the trees composing the ensemble) and (ii) provide means to minimize bias, through the additional randomization source, leveraging the framework ability to avoid being stuck on a few hard-to-classify examples. We summarize the proposed method in Algorithm 1.

Algorithm 1 BERT Pseudo Code

1: function T (Dtr ain = {(Xi , i )|iN=1}, M, ntr ees )

2:

L   ; w1



1 |Dtrain |

3: for each m  {1, .., M } do

4:

(hmXT , (x, , ^)oi ob )  ExtraT rees(Dtr ain, ntr ees , wm )

5: 6:

OO m

Bwe r 

rlog( 1-OOiOOOBiBwewrewOmirr wrI [)mi

^] , where O = (x,

, ^)oi ob

7:

wmi +1



wmi  m I [ Z

^]
, where Z is a normalizing con-

stant

8:

L  L  {(hmXT , m )}

9: end for

10: return L

11: end function

3.4 Experimental Evaluation
We now report and discuss the conducted experimental evaluation regarding the proposed BERT classi er considering a set of datasets on topic categorization and sentiment analysis. We rst detail the explored datasets and the experimental setup. en, we discuss the obtained experimental results, comparing our proposal to state-ofthe-art classi ers.
3.4.1 Experimental Setup and Parameterization. In order to evaluate the BERT classi er considering the textual classi cation domain, we consider ve real-world topic categorization data sets as well as ten sentiment analysis ones, related to computer science articles (ACM), news (REUT), web pages (4UNI), medicine (MEDLINE), items reviews (Amazon), posts on social networks (Twi er, Debate), user comments (Youtube) and snippets of opinion news (NYT). Due to space restrictions, a detailed description of each dataset can be found in an online appendix1. In all cases, we performed a traditional preprocessing task that consists of removing stopwords (using the standard SMART list) and applying a simple feature selection procedure, removing terms with low "document
1 homepages.dcc.ufmg.br/rcampos/papers/sigir2017/appendix.pdf

108

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

frequency (DF)"2. Regarding term weighting, we tested TF, TF-IDF and L2 normalization schemes, choosing the best strategy for each classi cation approach. Particularly, we use TF for all classi ers based on RF and Naive Bayes, and TF-IDF with L2 normalization for both SVM and kNN. e explored classi ers were compared using two standard information retrieval measures: micro averaged F1 (MicroF1) and macro averaged F1 (MacroF1). While the MicroF1 measures the classi cation e ectiveness overall decisions (i.e., the pooled contingency tables of all classes), the MacroF1 measures the classi cation e ectiveness for each individual class and averages them. To compare the average results of our 5-fold cross-validation experiments, we assess their statistical signi cance by applying a paired two-tailed t-test with 95% con dence and Bonferroni correction to account for multiple comparisons. is test assures that the best results, marked in bold, are statistically superior to others (up to the chosen con dence level).
We evaluate ten distinct learning algorithms. We use the scikitlearn implementation3 of linear SVM, k-Nearest Neighbors (kNN), Multinomial Na¨ive Bayes (NB), Random Forests (RF) and Extremely Randomized Trees (Extra-Trees). We use our own implementation of the RF-based methods, namely, BROOF, the lazy version of the RF classi er (LAZY) and the lazy version of extra-trees (LXT), since there is no freely available implementation for these classi ers.
e free parameters of these classi ers include the cost C (for SVM), neighborhood size k (for KNN and LAZY) and the number of features considered in the split of a node on the RF-based approaches. ese free parameters were set using 5-fold crossvalidation within the training set. For the RF-based approaches, each tree is grown without pruning, as suggested in [12], and since the results obtained with 200, 300 and 500 trees are statistically tied (with 95% con dence), we adopted 200 trees due to the lower cost. Concerning the BROOF classi er, we use 8 weak learners, se ing the maximum number of iterations to 200, as suggested in [23]. We use the same parameters for the proposed BERT method.
We would like to point out that some of the results obtained in some datasets may di er from the ones reported in other works for the same datasets. Such discrepancies may be due to several factors such as di erences in dataset preparation4, the use of different splits of the datasets (e.g., some datasets have "default splits" such as REUT and 20NG5). We would like to stress that we ran all alternatives under the same conditions in all datasets, using the best traditional feature weighting scheme, using standardized and well-accepted cross-validation procedures that optimize parameters for each of alternatives, and applying the proper statistical tools for the analysis of the results. Our datasets are available (for result replication and testing of new con gurations) under request.
3.4.2 Results and Discussions. We now turn our a ention to the obtained results regarding the described classi ers. We start by considering the e ectiveness of each classi er in the topic categorization task (see Table 1). In this case, BERT presents statistically tied results with SVM on most datasets despite their fundamentally
2We removed all terms that occur in less than six documents (i.e., DF<6). 3Available in h p://scikit-learn.org/ 4For instance, some works do exploit complex feature weighting schemes or feature selection mechanisms that do favor some algorithms in detriment to others. 5We believe that running experiments only in the default splits is not the best experimental procedure as it does not allow a proper statistical treatment of the results.

di erent classi cation paradigms. While BERT and other RF-based approaches are based on extracting speci c association rules that relate di erent features, SVM measures the complexity of hypotheses based on the margin with which they separate the data, which is independent of the number of features. is characteristic makes the SVM as one of the best-known classi cation strategies to exploit discriminative evidence from high dimensional and sparse textual data. Even considering the speci cities of each feature, BERT is capable of combining small pieces of evidence to build a general model with the same generalization power of SVM in scenarios which SVM traditionally works the best.
Despite SVM and BERT obtain statistically tied results in most datasets, BERT shows signi cantly superior results to SVM in the SPAM dataset. For this particular dataset, the BERT capability of identifying speci c non-trivial relationships between individual words to the spam category grants superior e ectiveness for BERT. On the other hand, the same SVM mechanism that captures good general pa erns limits such classi er in nding speci c pieces of evidence that relate individual features in more complex ways.
BERT is also superior to other RF-based approaches in most datasets, which provides evidence towards the bene ts of the proposed strategy in mitigating the RF over ing problem. Speci cally, BERT presented signi cant improvements over RF on all datasets, with gains up to 7% and 30% on MicroF1 and MacroF1, respectively.
Other strategies designed to overcome the RF limitations also presented inferior results to BERT. e LAZY method is always inferior to BERT in terms of MacroF1, indicating that LAZY has a hard time on discriminating minor classes. We argue that by trying to nd discriminative pa erns based on the neighborhood of documents, LAZY can bias its model towards the larger classes, since their documents are most likely to appear in the neighborhood of an arbitrary test document.
Another strategy aimed at improving RFs is the BROOF classi er. Our experimental results show that the proposed combination of boosting with extremly randomized trees can achieve be er results than combining boosting with the original RFs. Although very competitive to BERT, BROOF is no match to our proposal in both the 20NG and ACM datasets.
Now we turn our a ention to the classi cation results of the sentiment analysis task, presented in Table 2. e experimental results show that, overall, BERT outperforms or ties with the best classi-
cation method for each dataset. Speci cally, BERT and BROOF achieved the best (and statistically tied) results in almost all datasets, which provides additional evidence towards the bene ts of reducing the over ing issues of RF-based methods using boosting. In the sentiment analysis context, both methods take advantage of being able to identify the presence of individual words that are highly correlated to a positive or negative sentiment. eir generalization capabilities of identifying noisy or irrelevant information provide improvements over the original RF, with 14% and 5% on MacroF1 and MicroF1, respectively.
In the sentiment analysis scenario, SVM is not always among the best approaches, since it does not have the ability to discriminate the
ne-grained discriminative evidence present in individual words and non-linear relationships between words. Moreover, there is no clear winner between SVM and the simple NB classi er. In this scenario, NB has the advantage of learning how each word relates to

109

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

BERT SVM BROOF XGBOOST LAZY NB KNN Extra-Trees LXT RF

microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1

20NG
89.45 ± 0.46 89.13 ± 0.58 90.06 ± 0.43 89.93 ± 0.43 87.96 ± 0.24 87.44 ± 0.28 81.88 ± 0.65 81.38 ± 0.68 87.96 ± 0.37 87.39 ± 0.37 88.99 ± 0.54 88.68 ± 0.55 87.53 ± 0.69 87.22 ± 0.66 87.03 ± 0.41 86.65 ± 0.56 88.39 ± 0.51 88.05 ± 0.44 83.64 ± 0.29 83.08 ± 0.35

4UNI
84.61 ± 0.98 73.61 ± 1.85 83.48 ± 1.08 73.39 ± 2.17 84.41 ± 1.07 73.23 ± 1.10 85.52 ± 0.88 74.44 ± 1.28 82.34 ± 0.61 68.33 ± 1.6 62.63 ± 1.7 51.38 ± 3.19 75.63 ± 0.94 60.34 ± 1.36 82.87 ± 1.00 68.54 ± 2.60 81.24 ± 0.71 66.89 ± 1.23 81.52 ± 1 65.44 ± 1.91

ACM
74.8 ± 0.59 62.1 ± 0.99 75.4 ± 0.66 63.84 ± 0.55 73.35 ± 0.79 60.76 ± 0.8 73.78 ± 0.51 62.79 ± 1.38 74.02 ± 0.79 59.46 ± 1.35 73.54 ± 0.71 58.03 ± 0.85 70.99 ± 0.96 55.85 ± 0.97 73.08 ± 0.55 58.71 ± 0.89 69.63 ± 0.91 57.33 ± 1.48 71.05 ± 0.31 56.56 ± 0.45

REUT90
67.33 ± 0.72 29.24 ± 1.40 68.19 ± 1.15 31.95 ± 2.59 66.79 ± 0.97 28.48 ± 2.17 65.21 ± 0.84 29.06 ± 2.46 66.3 ± 1.07 26.61 ± 2.12 65.32 ± 1.13 27.86 ± 0.79 68.07 ± 1.07 29.93 ± 2.48 64.87 ± 0.81 26.18 ± 2.55 65.92 ± 0.82 26.71 ± 2.53 63.92 ± 0.81 24.36 ± 1.98

SPAM
96.11 ± 0.52 95.93 ± 0.55 92.55 ± 0.8 92.12 ± 0.87 96.09 ± 0.84 95.9 ± 0.88 95.08 ± 0.52 94.84 ± 0.54 92.91 ± 0.68 92.54 ± 0.71 79.27 ± 0.81 78.18 ± 0.83 83.31 ± 0.98 82.91 ± 0.93 95.74 ± 0.55 95.52 ± 0.58 92.42 ± 0.78 92.05 ± 0.82 95.46 ± 0.74 95.22 ± 0.79

MED
83.68 ± 0.32 74.25 ± 0.37 86.19 ± 0.05 78.46 ± 0.42 83.05 ± 0.05 73.25 ± 0.42 84.19 ± 0.05 76.81 ± 0.21 84.88 ± 0.08 72.90 ± 0.08 82.92 ± 0.14 63.8 ± 0.43 82.16 ± 0.08 68.00 ± 0.34 82.49 ± 0.07 71.15 ± 0.31 83.84 ± 0.11 71.02 ± 0.23 81.61 ± 0.05 70.41 ± 0.36

Table 1: Topic categorization - Obtained results for base classi ers.

BERT BROOF
NB XT SVM RF XGBOOST LXT LAZY KNN

AMAZON BBC DEBATE DIGG MYSPACE NYT TWEETS TWITTER

microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1

75.76 74.16 74.52 73.02 74.68 73.32 73.88
72.1
74.24
72.84
73.8
71.76
71.49
69.98
72.22

86.04 53.78 86.17
55.04 86.84 46.48
86.58 52.35 86.43
50.34
86.84 52.4 86.16 52.39 87.11

79.38 77.24 79.23 77.07
76
73.7
79.33 76.93 78.58 76.2 78.53 75.79 75.89
73.01
78.07

75.7 63.03 76.34 65.56 76.09 64.38 76.85 60.84 75.58 60.96 75.31 57.04
74.29
57.46 74.93

86.46 67.35 86.57 67.93 85.5 60.39
85.64 65.24 86.23 67.94 85.74 60.7
85.38 63.57
85.26

68.14 67.01 68.01 66.85 67.1 66.06 67.43 66.03 66.34
65.48 67.43 65.41
61.06
60.08
64.41

88.3 85.49 88.11 85.36 86.82 84.4 86.46
83
86.87 84.1 84.63
79.54
84.24
80.11
82.36

76.15 74.71 75.01 73.73 74.88 73.89 75.19 73.26 74.53 73.15 73.83
71.21
72.47
69.01
71.91

macroF1 microF1

69.24 72.3

49.36 87.37

74.98 76.35

56.91 76.21

55.64 85.14

61.5 64.64

75.35 80.86

68.51 70.86

macroF1

69

50.19 72.89 58.9

55.55 61.61 73.53

microF1

69.86

86.44 74.03

74.8

85.49

60.61 77.34

67.49 67.02

macroF1 67.64 46.36 72.25 52.77 56.07 54.92 68.14

64.08

Table 2: Sentiment analysis - Obtained results for base classi ers.

YELP 94.26 94.26 93.58 93.58 90.44 90.44 91.74 91.73 92.94 92.94 90.76 90.75 90.84 90.83 90.82 90.82 90.18 90.17 74.5 73.83

YOUTUBE 79.85 76.47 79.69 76.18 83.43 80.3 79.65 76.22 82.24 77.99 79.89 76.29 74.74 68.13 77.22 67.56 76.48 66.4 75.74 67.27

a positive or negative sentiment, and they combine these pieces of evidence to determine the sentiment of a text document. However, unlike RF-based methods, there is no mechanism to identify noise or irrelevant words, which may a ect its e ectiveness results.
e methods KNN, LAZY, and LXT are usually associated with the worse results for the sentiment analysis task. Instead of focusing on individual words, these methods exploit the distribution of training examples among neighbors of a test example. is analysis of the neighborhood can be a potential source of noise since similar text documents can be associated with di erent sentiment labels.
Overall, according to the reported experimental results, the BERT classi er is the only approach consistently among the best results in both topic categorization and sentiment analysis. ese results provide empirical evidence towards the bene ts of improving the generalization power of random forests by using elaborated strategies to reduce over ing.
Finally, for both sentiment analysis and topic classi cation, BERT is one of the most e ective classi cation methods that combines discriminative pieces of evidence derived from exploring the complex sub-regions of the input space. Other classi cation approaches provide completely di erent strategies to exploit discriminative pa erns, which motivates us to stack these di erent classi cation

approaches to combine the potentially complementary information captured by each of them (see Section 4).
3.4.3 E ects of Extra-Trees as weak-learner. An important aspect to be further analyzed is the in uence of the additional randomization enjoyed by BERT through the use of Extra-Trees (instead of traditional RFs, as done in BROOF). To this end, we analyze the e ect of gradually increasing the number of Extra-Trees in the BROOF process over MicroF1 and MacroF1. Here, the number of iterations and trees were xed to 200 and 8, respectively. Figure 2 shows the obtained results, where the x-axis represents the proportion of Extra-Trees composing the ensemble (0% means the absence of Extra-Trees, which degenerates to BROOF, and 100% represents the BERT classi er, composed entirely by Extra-Trees). ere is a clear tendency of growth in MicroF1 and MacroF1 as we increase the proportion of Extra-Trees composing the ensemble. us, the additional randomization procedure employed in BERT plays an important role in improving the BROOF algorithm.
4 STACKING RF-BASED LEARNERS
Based upon the results reported in Section 3.4, one aspect should be clear by now: the analyzed RF-based classi ers do excel in both the explored text classi cation tasks. One question that naturally

110

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Disin,ojrm BROOF LAZY SVM NB KNN

BERT 0.12 0.29 0.30 0.32 0.33

BROOF - 0.29 0.32 0.32 0.33

LAZY

-

- 0.31 0.32 0.19

SVM

-

- - 0.27 0.30

NB

-

- - - 0.33

(a) 4UNI

Disin,ojrm BROOF LAZY SVM NB KNN

BERT 0.07

BROOF -

LAZY

-

SVM

-

NB

-

0.18 0.23 0.32 0.25 0.20 0.23 0.35 0.29
- 0.25 0.32 0.23 - - 0.29 0.25 - - - 0.29

(b) ACM

Table 3: Normalized Degree of Disagreement

Disin,ojrm BROOF LAZY SVM NB KNN

BERT 0.15 0.23 0.28 0.39 0.35

BROOF - 0.26 0.24 0.41 0.42

LAZY -

- 0.29 0.43 0.38

SVM

-

- - 0.37 0.36

NB

-

- - - 0.39

(c) 20NG

(a) 20NG

(b) ACM

Figure 2: E ect of Extra-Trees as weak-learner.

arises is: can we explore these methods somehow in order to learn an even more e ective classi er? is is what we pursue in this section.

In order to combine RF-based classi ers, these classi ers should

exhibit some degree of complementarity. In fact, each RF based

classi er explore di erent learning strategies to come up with more

e ective predictions. However, it is still important to assess whether

these distinct strategies do produce complementary information

that could be explored to leverage classi cation e ectiveness. To

this end, we quantify such complementarity degree by means of the

Degree of Disagreement [16] observed for a pair of classi ers. Let

hi and hj be two classi ers, applied to examples from a validation

set Dvalid (e.g., a fold). Also, let D00 be the examples misclassi ed by both hi and hj (n00 = |D00|), D01 be the examples correctly classi ed just by hi ((n01 = |D01|)) and D10 be the examples correctly classi ed just by hj ((n10 = |D10|)). Finally, let D11 be the examples correctly classi ed by both learners ((n11 = |D11|)). e Degree of
Disagreement Disi, j between hi and hj is given by:

Disi, j

=

n00

n01 + n01

+ n10 + n10

+ n11

(1)

is is a symmetric statistic that captures to what extent two classi-

ers disagree in terms of prediction. Classi ers with low disagree-

ment degree tend to have similar behavior in terms of correctly or

incorrectly classifying unseen examples and thus have low com-

plementarity. In order to o er a more appropriate measure of

disagreement degree between classi ers, however, one should also

take into account their prediction capabilities. at way we guaran-

tee a proper comparison between their behavior. For this purpose,

we propose a normalized degree of disagreement metric. Recall

that, in order to have minimal degree of disagreement, we must

have D01  D10 or D10  D01. Also, we have that hi accuracy can

be expressed as Ri =

n 01 +n 11 a,b 0, 1 na,b

,

with

Rj

expressed

analogously.

It is straightforward to show that Disim, jin = Ri + Rj - 2 min(Ri , Rj ).

Similarly, we maximize the degree of disagreement when n00 and

n11 tend to 0. In that case, with some algebraic manipulation, one

can show that Disim, jax = 2 - Ri - Rj . With such derivations in place,

the normalized degree of disagreement metric is de ned as

norm
Disi, j

=

Disi, j - Disim, jin . Disim, jax - Disim, jin

(2)

e Degree of Disagreement values computed for the exempli ed cases can be found on Table 3. is gives us some evidence that the explored learning methods, such as BROOF, LazyNN RF and BERT do have some complementary information that can potentially be explored in order to come up with more e ective learners. is is the main motivation to what we propose here: a novel strategy to stack RF based classi ers that, besides producing highly e ective meta-learners, it also enjoys a signi cantly reduced runtime, guaranteeing its applicability on large classi cation problems.
We now introduce an e cient way of stacking bagging-based classi ers. Recall that bagging-based methods, such as Random Forests, typically yield models with higher generalization capabilities by controlling variance with the bootstrap procedure [3]. We rely on the out-of-bag samples produced by the bootstrap technique performed by these classi ers in order to estimate the a posteriori probability distributions for the training samples, thus producing the meta a ributes to be fed to the stacked classi er. Since this information is promptly generated at training time by bagged classi ers, the meta learner can thus be built with negligible additional computational e ort.
In details, recall that the bootstrap procedure (random sampling with replacement) generates samples Dboot comprising of approximately 1 - e-1  63% of the original training set Dtrain, with the remaining 36% samples being the so-called out-of-bag samples [12]. We here propose to use Doob = Dtrain \ Dboot to estimate the class probability distribution at a point x  Doob to be used as meta a ributes to train a stacked classi er. is comes at a very low cost, since the meta a ributes can be e ciently computed during the

111

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

training stage of bagged learners, without the needs to perform

costly estimation strategies, such as cross-validation. Let M be the number of bootstrap iterations, Diboot|iM=1 be the bootstrap samples and hi |iM=1 the classi ers trained with the corresponding bootstrap samples. We compute the probability distribution estimates poob (x)
for each instance x  Dtrain as follows:

M

poob (x)

=

1 M

phj (x)I [x
j =1



j
Doob

],

(3)

where I denotes the indicator function, phj (x) = (phj (c1|x), phj (c2|x), · · · , phj (cK |x)), {c1, ...cK } is the set of possible classes and phj (ck |x) denotes the probability of x to belong to class ck , according to learner hj .
e estimated a posteriori probability poob (x) can be naturally

used in the traditional stacking framework as meta-features, along

side the meta-features obtained by traditional means, in order to

train any meta-learner as discussed in the Section 2. By doing so,

one can stack bagged-based models e ciently either with bagged

and non-bagged ones, thus, making feasible the applicability of

such stacking systems in real world problems.

4.1 Experimental Evaluation
We now report our experimental evaluation of the proposed stacking model. To this end, we consider all the previously explored datasets regarding topic categorization and sentiment analysis (see Section 3.4.1). We contrast the proposed RF-based stacked classi er against traditional stacking of classical state-of-the-art methods in text categorization (e.g. SVM, kNN, Na¨ive Bayes). en, we analyze our proposal in terms of runtime.
4.1.1 Results and Discussion. As we detail in the following, stacking RF-based classi ers brings substantial improvements in classi cation e ectiveness over traditional methods and their combinations in both analyzed text classi cation tasks. e proposed RF-based stacking is even able to produce as good results as the combination of all evaluated classi ers in most analyzed datasets, at a much lower runtime, guaranteeing its applicability in text classi cation tasks.
e results regarding the topic categorization task can be found in Table 4. First, note that the combination of RF-based approaches BERT + BROOF + LXT + LAZY achieves be er results over the two best base classi ers (BERT and SVM) in most datasets, with substantial gains of up to 17% and 21% in MacroF1 and MicroF1, respectively. In fact, stacking RF-based approaches clearly produces superior results when compared to the top-notch SVM and BERT classi ers. e combination BERT + BROOF + LXT + LAZY is also superior to the combination of classi ers SV M +N B +KN N in 4UNI and SPAM. ese results provide evidence to our claim that stacking RF-based methods for text classi cation is a strong alternative to the stacking of traditional text classi cation approaches, since besides e ective they are highly parallelizable, easily parameterized and e ciently combined by our OOB stacking proposal.
Furthermore, stacking RF-based methods also performs as well as the combination of all classi cation approaches (i.e., Allstack ) in all but 20NG and MED datasets. is indicates that traditional classi cation methods may provide supplementary discriminative

information for RF-based methods, which is the expected since they
follow completely di erent classi cation paradigms.
Considering the sentiment analysis datasets, one can observe
that most of the results regarding stacking di erent classi ers are
statistically tied, as shown in Table 5. Moreover, BERT is not sub-
stantially improved when stacked with other classi ers. In fact, BERT ties with BROOF + LAZY + BERT + LXT in all datasets. Also, BERT also ties with Allstack in all datasets but one, YOUTUBE (in fact, due to the presence of the NB classi er in the Allstack ensemble). ese results show that, despite the potential bene ts of stacking various methods, the proposed BERT classi er remains as one of the top performers when detecting the sentiment of textual
documents, being a strong candidate for consideration.
4.1.2 E ectiveness vs. diversity tradeo . In the following, we perform an analysis of the Pareto's frontier of the generated ensem-
bles. With this, we want to con rm that the RF-based methods are
important to generate ensembles of classi ers with high general-
ization power and complementarity/diversity. Figure 3 exhibits a sca er plot for several datasets, in which each
point represents a stacking ensemble out of the possible ensembles generated by the combination of the nine base classi ers (number of classi ers composing the ensemble varies from 2 to 9). e x-axis represents the diversity metric Double-Fault, which was chosen because it is the pairwise metric that best represents the relationship between accuracy and diversity of an ensemble system[16]. e metric was originally used by [11] to form a pairwise diversity matrix for a classi er pool and subsequently to select classi ers that are least related. e metric estimates the likelihood of both classi ers incorrectly classifying the same sample (the smaller the value of the metric, the higher the diversity/complementarity). e y-axis is the e ectiveness metric MacroF1. For those points, we calculate the Pareto's frontier which maximizes the e ectiveness metric and minimizes the Double-Fault metric (maximizes diversity), which are desirable characteristics of any ensemble method (highly diverse and e ective). e ensembles in the frontier showed in Figures 3 (a), (b), and (c) are the following:
· (LXT , N B), (LAZ Y, N B), (SV M, K N N ), (LXT , SV M, N B), (LAZ Y, SV M, N B), (LXT , SV M, N B, K N N ), (LXT , SV M, N B, K N N , XT ), (LAZ Y, BERT , LXT , SV M, N B, K N N ), (LAZ Y, LXT , SV M, N B, K N N , F A)
· (BERT , SV M ), (BERT , LXT , SV M ), (BROO F, BERT , SV M, K N N ), (BERT , SV M, N B)
· (SV M, N B), (LAZ Y, SV M, N B), (BERT , SV M, N B), (LAZ Y, BERT , SV M, N B), (LAZ Y, BERT , LXT , SV M, N B), (LAZ Y, BERT , SV M, N B, K N N ), (BROO F, LAZ Y, SV M, N B, K N N ), (BERT , LXT , SV M, N B, AEA), (BROO F, BERT , LXT , SV M, N B, K N N )
One can notice that as we go from le to right on the Pareto's frontier both, e ectiveness and diversity6 decreases. is implies
that not necessarily a highly diverse combination will result in more
accurate classi ers, but that there is a tradeo between e ectiveness
and diversity of the base classi ers of the ensemble. By analyzing
the Pareto's frontier, one can clearly notice that the RF extensions
play an important role in providing a balance between diversity
and generalization power in the most e ective ensembles. It is also
possible to note that the loss in diversity brought by the insertion
of more similar methods into the ensemble (e.g., RF-based ones) is
compensated by the high generalization power of those methods.
ese results along with the e ectiveness analysis corroborate
our hypothesis: by using RF-based algorithms in multi-classi er
systems, it is possible to achieve higher e ectiveness.
6In this Section, we will use the terms diversity and complementarity interchangeably.

112

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Al lst ack BROOF+LAZY+BERT+LXT SVM+NB+KNN SVM+BERT BERT SVM

microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1

20NG
92.21 ± 0.44 92.01 ± 0.42 90.63 ± 0.57 90.4 ± 0.57 90.65 ± 0.45 90.42 ± 0.44 90.85 ± 0.50 90.68 ± 0.50 89.45 ± 0.46 89.13 ± 0.58 90.06 ± 0.43 89.93 ± 0.43

4UNI
86.85 ± 1.17 79.43 ± 2.23 86.79 ± 0.86 79.63 ± 1.91 84.95 ± 1.15 75.86 ± 1.48 86.65 ± 1.05 80.13 ± 2.49 84.61 ± 0.98 73.61 ± 1.85 83.48 ± 1.08 73.39 ± 2.17

ACM
79.02 ± 0.72 66.25 ± 1.01 77.83 ± 0.80 63.42 ± 0.92 77.78 ± 0.73 65.08 ± 1.71 77.25 ± 0.60 66.29 ± 0.97 74.8 ± 0.59 62.1 ± 0.99 75.4 ± 0.66 63.84 ± 0.55

REUT90
80.76 ± 1.24 39.28 ± 1.14 80 ± 1.60 38.66 ± 2.85 78.53 ± 1.09 37.10 ± 1.41 78.43 ± 1.33 36.8 ± 2.45 67.33 ± 0.72 29.24 ± 1.40 68.19 ± 1.15 31.95 ± 2.59

SPAM
96.06 ± 0.78 95.87 ± 0.82 96.13 ± 0.86 95.94 ± 0.90 93.67 ± 0.34 93.37 ± 0.34 95.91 ± 0.79 95.72 ± 0.82 96.11 ± 0.52 95.93 ± 0.55 92.55 ± 0.8 92.12 ± 0.87

MED
88.76 ± 0.11 81.62 ± 0.34 87.10 ± 0.07 79.36 ± 0.59 87.96 ± 0.05 80.33 ± 0.57 87.65 ± 0.03 80.55 ± 0.52 83.68 ± 0.32 74.25 ± 0.37 86.19 ± 0.05 78.46 ± 0.42

Table 4: Topic categorization - Obtained results for stacking and top-performer base classi ers.

AMAZON BBC DEBATE DIGG MYSPACE NYT TWEETS TWITTER YELP YOUTUBE

Al lst ack BROOF+LAZY+BERT+LXT SVM+NB+KNN SVM+BERT BERT NB

microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1 microF1 macroF1

75.6 74.44 75.6 74.44 75.37 74.14 75.96 74.85 75.76 74.16
74.68
73.32

86.84 51.56 86.84 50.03
86.7 46.44
86.7 47.34
86.04 53.78 86.84 46.48

80.14 77.86 79.89 77.41 78.83 76.71 79.99 77.88 79.38 77.24
76
73.7

76.47 65.8 75.96 62.71 77.5 64.84 76.46 63.05 75.7 63.03 76.09 64.38

86.1 68.27 86.94 68.88 86.09 65.98 86.11 67.14 86.46 67.35
85.5
60.39

68.1 67.35 67.79 66.87 67.41 66.53 67.73 66.92 68.14 67.01 67.1
66.06

89.16 87.08 89.01 86.63 88.35 86.07 88.25 85.81 88.3 85.49
86.82
84.4

75.71 74.83 76.23 75.26 75.32 74.24 75.89 74.79 76.15 74.71 74.88 73.89

94.82 94.82 94.22 94.22 93.84
93.84
94.64 94.64 94.26 94.26 90.44
90.44

83.93 81.11 81.5
77.63 84.13 81.05 81.42
77.85
79.85
76.47 83.43 80.3

Table 5: Sentiment analysis - Obtained results for stacking and top-performer base classi ers

(a) 20NG

(b) 4UNI

(c) ACM

Figure 3: MacroF1 vs. Double-Fault - each point represents a stacking out of all possible combination of the 9 base classi ers. e line connecting the highlighted points is the Pareto's frontier.

4.1.3 Computational Time and E ectiveness to Stack Baggingbased Methods. Table 6 shows the average time to combine all nine base learning algorithms using ours and the baseline stacking approaches, which generate the meta-level data by means of 5fold cross-validation. We also contrast our proposed method with a xed combination method (simple voting), which is the fastest possible combing strategy since it does not require training. As can be seen in Table 6, the stacking using our strategy based on Out-ofBag (OOB) samples combined with RF as meta-level learner shows signi cant speedups in relation to all other stacking strategies, without degrading its predictive performance. Speci cally, in the MEDLINE dataset, the stacking approaches using cross-validation were not able to handle the dataset in a suitable time. Moreover, one can notice that our approach is competitive regarding execution time when compared to a simple voting algorithm while excelling in e ectiveness.

20NG 4UNI ACM REUT90 MEDLINE

OOB-RF 7244 2413 6762 13163 458013

RF

20479 7358 17194 29256 -

MLR

21455 7334 17170 29131 -

DT

20448 7327 17163 27124 -

SCANN 21651 7330 17166 29007 -

VIG

20620 7499 17335 30296 -

Voting 2921 1046 2451 4017

375297

Table 6: Avg. time in seconds to combine (training + testing

time) all 9 base learning algorithms with di erent stacking

strategies. In the cases that a method was not able to handle

a dataset, we marked the corresponding table cell with `-'.

Table 7 shows the e ectiveness of di erent combination strategies, such as MLR, DT, SCANN and the recently proposed VIG in the largest datasets7. e results of these strategies are never superior to the use of RF as a meta-level combiner. Despite not being designed as a meta-level combiner, RF is capable of achieving
7 is excludes the small SPAM dataset.

113

Session 1C: Document Representation and Content Analysis 1

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

the best e ectiveness results due to its capabilities of automatically identifying discriminative pa erns on the relationship among classi er results. Moreover, the proposed usage of OOB can provide the same discriminative evidence as the output of the RF-based obtained by means of cross-validation, which eliminates the need for costly procedures to stack RF-based methods.

20NG 4UNI ACM REUT90 MED

OOB-RF RF

microF1 macroF1 microF1 macroF1

92.24 92.04 92.21 92.01

86.87 79.35 86.85 79.43

78.99 65.75 79.02 66.25

80.25 40.8 80.76 39.28

88.76 81.62 -
-

microF1 91.36 85.34 77.99 76.33 MLR
macroF1 91.14 76.62 68.26 35.64

microF1 91.44 83.82 77.53 68.19 DT
macroF1 91.23 76.11 65.07 32.43 -

microF1 91.55 84.27 77.7 66.71 VOTING
macroF1 91.29 72.2 64.31 28.89

86.91 77.41

microF1 90.87 85.31 76.84 71.14 SCANN
macroF1 90.55 73.88 63.08 29.25 -

microF1 90.13 82.14 75.11 19.4

-

VIG

macroF1 89.65 74.33 65.49 3.17

-

Table 7: Obtained results for di erent stacking strategies. In

the cases that a method was not able to handle a dataset, we

marked the corresponding table cell with `-'

5 CONCLUSIONS AND FUTURE WORK
In this work, we propose a boosted version of the extremely randomized trees classi er, named BERT, in order to leverage the learner's capability to minimize bias while maintaining high predictive power by properly reducing variance. As our experimental analysis reveal, our proposal enjoys top-notch classi cation e ectiveness, being among the top performers in the vast majority of cases covering two challenging text classi cation tasks, namely, topic categorization and sentiment analysis. We also propose to stack the explored RF-based classi ers in order to exploit the complementarities observed among those classi ers. Unlike traditional stacking, that makes use of cross-validation procedures to learn the meta-features to be fed to the stacking procedure, we here rely on the out-of-bag samples obtained through bootstrapping the training set when learning the forests. More speci cally, the out-of-bag samples are used to estimate the a posteriori class distributions used by the stacking procedure to learn the underlying input/output relationships. We show that such novel stacking approach is not only able to provide state-of-the-art classi cation e ectiveness, but also at a signi cantly lower runtime.
Clearly, there is still room for improvements. For example, we plan to investigate if non-bagging strategies, such as the traditional kNN, Na¨ive Bayes and SVM classi er, could bene t from the bootstrap procedure in order to come up with a uniform stacking strategy that generalizes to any other classi er. Also, in the same vein of exploring the out-of-bag samples to estimate the a posteriori class distributions in our stacking approach, we could explore the out-of-bag error estimates in order to select the candidate features for decision nodes in order to improve both e ectiveness and e ciency of the RF based classi ers, such as BERT, BROOF, LazyNN RF, LXT and the traditional RF.
REFERENCES
[1] Ricardo A. Baeza-Yates and Berthier A. Ribeiro-Neto. 1999. Modern Information Retrieval. ACM Press / Addison-Wesley.

[2] Yaxin Bi, David Bell, Hui Wang, Gongde Guo, and Jiwen Guan. 2007. COMBIN-
ING MULTIPLE CLASSIFIERS USING DEMPSTER'S RULE FOR TEXT CATEGORIZATION. Appl. Artif. Intell. 21, 3 (March 2007), 211­239. [3] Leo Breiman. 1996. Bagging Predictors. Mach. Learn. 24, 2 (Aug. 1996), 123­140. [4] A. Danesh, B. Moshiri, and O. Fatemi. 2007. Improve text classi cation accuracy based on classi er fusion methods. In Information Fusion, 2007 10th International Conference on. IEEE, 1­6. [5] Clebson C. A. de Sa´, Marcos Andre´ Gon¸calves, Daniel Xavier de Sousa, and
iago Salles. 2016. Generalized BROOF-L2R: A General Framework for Learning to Rank Based on Boosting and Random Forests. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy, July 17-21, 2016. 95­104. [6] Yan-Shi Dong and Ke-Song Han. 2004. A comparison of several ensemble methods for text categorization. In Services Computing, 2004. (SCC 2004). Proceedings. 2004 IEEE International Conference on. IEEE, 419­422. [7] Yan-Shi Dong and Ke-Song Han. 2004. A Comparison of Several Ensemble Methods for Text Categorization. In IEEE International Conference on Services Computing. IEEE. [8] Manuel Ferna´ndez-Delgado, Eva Cernadas, Sene´n Barro, and Dinani Amorim.
2014. Do We Need Hundreds of Classi ers to Solve Real World Classi cation Problems? J. Mach. Learn. Res. 15, 1 (Jan. 2014), 3133­3181. [9] Yoav Freund and Robert E Schapire. 1997. A Decision- eoretic Generalization of On-Line Learning and an Application to Boosting. J. Comput. Syst. Sci. 55, 1 (Aug. 1997), 119­139.
[10] Pierre Geurts, Damien Ernst, and Louis Wehenkel. 2006. Extremely randomized trees. Machine Learning 63, 1 (2006), 3­42.
[11] Giorgio Giancinto and Fabio Roli. 2001. Design of E ective Neural Network Ensembles for Image Classi cation Purposes. IMAGE VISION AND COMPUTING JOURNAL 19 (2001), 699­707.
[12] T. Hastie, R. Tibshirani, and J. H. Friedman. 2009. e Elements of Statistical Learning. Springer.
[13] Monisha Kanakaraj and Ram Mohana Reddy Guddeti. 2015. Performance analysis
of Ensemble methods on Twi er sentiment analysis using NLP techniques. In IEEE International Conference on Semantic Computing (ICSC). IEEE. [14] Aurangzeb Khan, Baharum Baharudin, Lam Hong Lee, Khairullah Khan, and
Universiti Teknologi Petronas Tronoh. 2010. A Review of Machine Learning Algorithms for Text-Documents Classi cation. In Journal of Advances In Information Technology. Academy Publisher. [15] Ludmila I. Kuncheva, James C. Bezdek, and Robert P. W. Duin. 2001. Decision templates for multiple classi er fusion: an experimental comparison. Pa ern Recognition 34 (2001), 299­314. [16] Ludmila I. Kuncheva and Christopher J. Whitaker. 2003. Measures of Diversity in Classi er Ensembles and eir Relationship with the Ensemble Accuracy. Mach. Learn. 51, 2 (May 2003), 181­207. [17] Christopher J. Merz. 1999. Using Correspondence Analysis to Combine Classi ers. Mach. Learn. 36, 1-2 (July 1999), 33­58. [18] Tien anh Nguyen, i u uy Nguyen, Xuan Cuong Pham, and Alan Wee-
Chung Liew. 2016. A Novel Combining Classi er Method Based on Variational Inference. Pa ern Recogn. 49, C (Jan. 2016), 198­212. [19] Aytug Onan, Serdar Korukoglu, and Hasan Bulut. 2016. Ensemble of Keyword Extraction Methods and Classi ers in Text Classi cation. Expert Syst. Appl. 57, C (Sept. 2016), 232­247.
[20] Gabriel Pui, Cheong Fung, Je rey Xu Yu, Haixun Wang, David W. Cheung, and
Huan Liu. 2006. A Balanced Ensemble Approach to Weighting Classi ers for Text Classi cation. In ICDM '06. Sixth International Conference on Data Mining. IEEE.
[21] Lior Rokach. 2009. Taxonomy for characterizing ensemble methods in classi cation tasks: A review and annotated bibliography. In Computational Statistics Data Analysis, In Press, Corrected Proof.
[22] iago Salles, Marcos Gon¸calves, and Leonardo Rocha. 2017. PhD Dissertation:
Random Forest based Classi ers for Classi cation Tasks with Noisy Data. (2017).
Federal University of Minas Gerais.
[23] iago Salles, Marcos Gon¸calves, Victor Rodrigues, and Leonardo Rocha. 2015.
BROOF: Exploiting Out-of-Bag Errors, Boosting and Random Forests for E ective Automated Classi cation. In Proc. of the 38th International ACM SIGIR Conference on Inf. Retrieval. ACM, 353­362. [24] M. R. Segal. 2004. Machine Learning Benchmarks and Random Forest Regression. Technical Report. University of California.
[25] Kai Ming Ting and Ian H. Wi en. 1997. Stacking Bagged and Dagged Models. In Proceedings of the Fourteenth International Conference on Machine Learning (ICML '97). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 367­375.
[26] David Wolpert and William G. Macready. 1996. Combining Stacking With Bagging To Improve A Learning Algorithm. Technical Report.
[27] David H. Wolpert. 1992. Stacked Generalization. Neural Networks 5 (1992), 241­259.

114

