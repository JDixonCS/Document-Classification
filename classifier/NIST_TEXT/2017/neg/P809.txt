Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Counter Deanonymization Query: H-index Based k-Anonymization Privacy Protection for Social Networks

Jianliang Gao
College of Information Science and Engineering, Central South University Changsha, China 410083

Bo Song
College of Computing & Informatics, Drexel University
Philadelphia, PA 19104

Zheng Chen
College of Computing & Informatics, Drexel University
Philadelphia, PA 19104

Weimao Ke
College of Computing & Informatics, Drexel University
Philadelphia, PA 19104

Wanying Ding
College of Computing & Informatics, Drexel University
Philadelphia, PA 19104

Xiaohua Hu
College of Computing & Informatics, Drexel University
Philadelphia, PA 19104

ABSTRACT
In this paper, we propose a novel k-anonymization scheme to counter deanonymization queries on social networks. With this scheme, all entities are protected by k-anonymization, which means the attackers cannot re-identify a target with confidence higher than 1/k. The proposed scheme minimizes the modification on original networks, and accordingly maximizes the utility preservation of published data while achieving k-anonymization privacy protection. Extensive experiments on real data sets demonstrate the effectiveness of the proposed scheme, where the efficacy of the k-anonymized networks is verified with the distributions of pagerank, betweenness, and their Kolmogorov-Smirnov (K-S) test.
KEYWORDS
Privacy protection; Deanonymization query; H-index
1 INTRODUCTION
Nowadays, how to deal with the privacy risks is a challenging problem in information retrieval (IR) area [1], especially for social media data. Recent research driven data mining and querying has been developed on social network data, which is published to the third party users [2]. Before publishing these data, the identifications of social entities are usually removed in case of privacy leakage. Such anonymization approach may be effective for relational data, but could not for social network data, where social relationships are modeled in graphs, with vertices representing individual social entities and edges indicating relationships between them. Consequently, it is possible for the attackers to destruct the
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: 10.1145/3077136.3080649

individual privacies by querying the graph structures even if the identifications are removed. For example, 86.9%-95.5% of Google+ users are deanonymizable, which indicates structure based deanonymization is powerful in practice [3].
Hence, it still faces privacy risks if only the identities of entities are removed when social network data is published [4]. The approach of neighborhood attack is first proposed in [5], where an attacker may be able to successfully query the privacy of the victim according to the features of its 1neighborhood graph, which is a subgraph including the target vertex, its neighbor vertices and the edges between them. Further, Wang et al. proposed a stronger assumption that attackers know the target's 1-neighborhood graph and all degrees of neighbor vertices, termed as 1*-neighborhood attack [6]. Recently, a weighted 1*-neighborhood attack was proposed in [7] which requires the attacker acquiring the knowledge of weights on all edges. These strong assumptions about the background knowledge cause very high cost for the purpose of anonymization. For example, more than 20% edges on Facebook data set are modified in the k-anonymizaiton method of [7] when k = 25. If a published social network is modified too much, the utility of the anonymized networks will decrease or even get lost completely. Furthermore, it is more practical for attackers to obtain the knowledge about the distribution of neighbors' degrees such as h-index [8], instead of knowing the exact degrees of all neighbors.
In this paper, we identify a novel attack model of h-index based deanonymization query, which is more realistic in social network domain without demanding the complete knowledge of exact neighbor degrees. To counter such query attack, we propose a k-anonymization privacy protection scheme, which protects privacy of all entities in social networks with significant advantages of achieving effective protections and high network utility preservations simultaneously.
The rest of the paper is organized as follows: Section 2 presents the problem formulation. The proposed scheme is introduced in Section 3. Experimental results are provided in Section 4. Finally, Section 5 concludes the paper.

809

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

2 PROBLEM FORMULATION
Before launching a deanonymization query, attackers are assumed to have some background knowledge of the targets. In this paper, we identify a novel model of deanonymization query where the attackers could feasibly acquire the h-indexes of the targets. The h-index is defined as following:

Definition 2.1. H-index. Given a graph of social network G= (V (G), E(G), L(V )), the h-index of vertex u  V (G) is:

H(u) = maxmin (f (u, i), i) ,

(1)

i

where V (G) is the set of entities in social networks whose identities have been removed; E(G)  V × V is the set of relationships between entities; L(V ) is the set of the information associated to entities; and f (u, i) is a function that satisfies f (u, i) = |{v|v  N (u)  D(v)  i}|, N (u) = {v|(u, v)  E(G)} and D(u) returns u's degree.

Definition 2.2. Deanonymization query. Given a graph of anonymized social network G = (V (G), E(G), L(V )), attackers could re-identify the target entities according to certain background knowledge such as h-index. This kind of attack is a deanonymization query.

Although the identities of entities have already been removed from the anonymized network, deanonymization query is still able to destruct the protection of privacy information. In this paper,we focus on the attack of h-index based deanonymization query and propose a k-anonymization scheme to avoid privacy leakage. K-anonymization is defined as:

Definition 2.3. K-anonymization. A vertex is said to be k-anonymous if there exist at least (k - 1) other vertices whose feature such as h-index are the same. If all vertices of a social network are k-anonymous, the social network is protected by k-anonymization.

In a k-anonymization social network, the results of a h-
index based deanonymization query include at least k ver-
tices. Therefore, attackers cannot re-identify the target with
confidence higher than 1/k. To achieve k-anonymization, we
formulate the problem as:
Problem formulation: Given a graph of social net-
work G = (V (G), E(G), L(V )), the problem is to get a kanonymization graph G = (V (G), E(G), L(V )), which satisfies: (1) V (G) = V (G); (2) for u  V (G), there are at least k - 1 other vertices {v|v  V (G)  H(v) = H(u)}; (3) maximizing the utility of G preserved from G.

3 THE PROPOSED SCHEME OF K -ANONIMYZATION
In the proposed scheme, the vertices are first divided into different groups, and then k-anonymization is achieved in each group by modifying the original networks.

3.1 Merging Bins for Groups
According to the definition of problem in Section 2, the number of vertices in a group must be larger than or equals a

given k. we introduce bin as a container in grouping the vertices. Each bin corresponds to a h-index, and the vertices that have the same h-index are assigned to the corresponding bin.
The k-anonymization process is shown in Algorithm 1. Lines 1-3 of Algorithm 1 are the initiation process of bins. Firstly, h-indexes of all vertices are put into the set . Then, the elements of  are assigned to different bins according to the h-indexes. In the third line, B is the set of bins and hist is a function that assigns vertices into [1, 2, ..., max(H(u))] bins according to their h-indexes. The bins are sorted in ascending order of h-index. Lines 6 to Line 15 demonstrate the iterative process of merging bins and approaching the vertices to the same h-index in each group. In the process,  is the variable to record the number of vertices in a group, and   k is the condition to end a merging process. C is the set of processed bins, and whose sizes, i.e., the number of vertices belonging to the bins, are not permitted to change to the value less than k.

Algorithm 1: H-index based k-anonymization

Input: G = (V (G), E(G), L(V )), k Output: G = (V (G), E(G), L(V )) 1 Initiate G=G ;
2  = {H(u)|u  V (G)} ;

3 B = hist(); B = sort(B, ascend) ;

4 C = N U LL ; Group = N U LL ;

5 =0;

6 foreach B  B do

7  =  + |B| ;

8 Group = Group  B ;

9 if   k then

10

G=UnifyHindex(G, Group, C) ;

11

C = C  Group ;

12

 =0 ;

13

Group = N U LL ;

14 end

15 end 16 return G;

When a group is formed, the next step is to unify the h-indexes in the group. If there are more than one bin in a group, vertices belonging to the group have multiple hindexes since each bin corresponds to one h-index. Therefore, a goal h-index is required for each group, and we present the following metric to determine the goal h-index :



 = argmin

(h(v) + h(v))

(2)

h BGroup vB

where h(v) and h(v) are the numbers of added edges and deleted edges in changing v's h-index to h. Then, the various h-indexes of the vertices in a group will be modified to approach to the goal h-index by the approaching method.

810

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

3.2 Unifying H-indexes in Groups
In this section, we show the detail method of unifying hindex in a group (Line 10 of Algorithm 1). If the corresponding h-index of a bin is not the same as the goal h-index of the group, every vertex in the bin increases or decreases its h-indexes to the goal h-index. Either increasing or decreasing h-index results in degree modifications and consequently changes of h-indexes of the current vertex and its neighbor vertices. Therefore, it is very crucial to decide how to modify the graph to achieve k-anonymization. Without loss of generality, we approach the h-index of a vertex u to a goal h-index  in the following two cases.

3.2.1 Case 1: H(u) < . If u's h-index H(u) is less than the goal h-index , we need to increase u's h-index to achieve k-anonymization. There are two ways to increase a vertex's h-index: First, connecting u to other vertices with larger degrees; Second, increasing the degrees of u's neighbor vertices.
Firstly, we derive two conditions of h-index from Definition 2.1. One is, among u's neighbors, at least H(u) vertices whose degrees are not less than H(u), and the other is the number of neighbors with larger degrees than H(u) can not exceed H(u)+1. Otherwise, h-index of u will not be H(u). Therefore, we can draw a proposition as follows:

Proposition 3.1. The h-index of u satisfies two condi-

tions:

{

H(u)  f (u, H(u)) H(u) > f (u, H(u) + 1) - 1

(3)

where the function f is the same as defined in Eq. 1, which returns the number of neighbors of first parameter whose degrees are not less than the value given in the second parameter.

Theorem 1. To increase h-index of u to , the least number of added edges is 1(u) if connecting u directly to other
vertices whose degrees are lager than  - 2:

1(u) =  - f (u, ).

(4)

Theorem 1 shows the least edges to be added by the first way to increasing the h-index of u. However not all vertices can be connected to u. Connecting u to other vertices, called as destination vertices, need to meet three conditions: (1) the degrees of destination vertices are larger than  - 2; (2) the processed bins (C in Line 11 of Algorithm 1) still meet the requirement of k size; (3) there is no existing edges between u and destination vertices. If there are not as many as 1(u) vertices that meet these conditions, the second way will be adopted to contribute to u's h-index by increasing the degrees of u's neighbors whose degrees are less than the goal h-index .

Theorem 2. To increase vertex u's h-index to  by adding edges to u's neighbors whose degrees are less than , the number of added edges is:

 -h

2(u)) = ( - D(vi)), vi  N(u),

(5)

i=1

Table 1: The percentage of modified edges.

K

5

10

15

20

25

Facebook 0.13% 0.38% 0.53% 0.87% 0.99%

Wiki 0.53% 0.64% 1.02% 1.13% 1.47%

where N(u) is a sub-set of N (u), N(u) = {v|v  N (u)  D(v) < }. Theorem 2 shows the other way to increase h-index. To minimize the modification, those vertices with larger degrees in N(u) are preferred to be selected.

3.2.2 Case 2: H(u) > . If u's h-index H(u) is larger than the goal h-index , we need to decrease u's h-index to , and there are two ways to accomplish: deleting the edges between u and its neighbors whose degrees are not less than ; or decreasing the degrees of u's neighbors whose degrees are not less than than .

Theorem 3. To decrease u's h-index and approach to  by deleting edges of u connecting to its neighbors whose degrees

are not less than , the number of deleted edges satisfies:

1(u)  f (u, ) - .

(6)

The second way of decreasing u's h-index is to reduce the degrees of neighbor vertices, which is shown in the following:

Theorem 4. To decrease u's h-index to  by reducing the degrees of u's neighbors whose degrees are not less than , the number of deleted edges is:

 -h

2(u) = (D(vi) - ), vi  N(u),

(7)

i=1

Either case needs to be considered whether an edges can be added/deleted, because the change of degrees might lead to the change of h-indexes of not only the current vertex and destination vertices, but also that of the neighbors of the destination vertices. If the changes cause the size of any processed bin less than k, the edge is not permitted to be added/deleted. During the approaching process, for both cases the first ways of modifying direct edges on the current vertex u is adopted primarily. The second way is adopted only when the prior modification still can not achieve the goal h-index.

4 EXPERIMENTAL RESULTS
In this section, we show the changes of edges and the evaluation results of the utility. The evaluations are conducted on two real world data sets 1, where Facebook network data has 4,039 vertices and 88,234 edges, and Wiki network data contains 7,115 vertices and 103,689 edges.

4.1 Modified Edges
In Table. 1, the percentage of modified edges on Facebook and Wiki data sets are recorded. The modification of edges increases with the rise of anonymization strength k. A larger k means stronger protection, but also means larger number
1 http://snap.stanford.edu/data/index.html

811

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Num of vertices Num of vertices Num of vertices Num of vertices

160 140 120 100
80 60 40 20 100-5

original k=5 k=10 k=15 k=20 k=25

10-4

10-3

Pagerank

10-2

(a) Facebook: Pagerank

3000 2500 2000 1500

original k=5 k=10 k=15 k=20 k=25

1000

500

100-5

10-4

10-3

Pagerank

10-2

(b) Wiki: Pagerank

104 103 102

original k=5 k=10 k=15 k=20 k=25

101

1000.0

0.1

0.2

0.3

0.4

0.5

Betweenness

(c) Facebook: Betweenness

104 103 102

original k=5 k=10 k=15 k=20 k=25

101

1000.00

0.02

0.04

Betweenness

0.06

(d) Wiki: Betweenness

Figure 1: Utility evaluation: comparison of Pagerank distribution and Betweenness distribution

Table 2: P-value of K-S test.

K

Pagerank

Facebook Wiki

Betweenness

Facebook Wiki

5 0.99160 0.99995 0.99999 0.99820

10 0.99160 0.99995 0.99999 0.97666

15 0.99993 0.99995 0.99999 0.99024

20 0.99999 0.99995 0.99991 0.96887

25 0.99160 0.99995 0.99952 0.90549

of edges need to be modified. In our experiment, the percentages of modified edges are only 0.99% and 1.47% at most for Facebook network and Wiki network respectively. In addition, we assess the utility of the modified social networks with further evaluations.
4.2 Utility
Utility of published data measures information loss and distortion during the anonymization process. The more information that is lost or distorted, the less useful published data is. We evaluate utility of the anonymized networks with the distributions of pagerank and betweenness.
Fig. 1a-1b and Fig. 1c-1d show the distributions of pagerank and betweenness of the k-anonymized Facebook and Wiki networks for various k. As can be seen, the distributions are very similar for k from 5 to 25. We first converge pagerank and betweeenness using the length 0.00001 and 0.01 respectively. Then, these two samples are verified by K-S test. P-value of K-S test, ranging between 0 and 1, indicates significant-level to reject the null hypothesis. Larger p-value means higher possibility of two samples following the same distribution. In our experiments, as shown in Table 2, p-values for all metrics at different k-levels are larger than 0.9 and most of them are over 0.99, which means that all modifications are considered distorting little of the original networks in terms of the these metrics, by K-S test.
5 CONCLUSION
Privacy protection is a crucial challenge in information retrieval. In this paper, we investigate the problem of privacy protection against deanonymization query on social networks. We identify a very practical deanonymization attack named h-index based query. To counter such query, we propose an effective k-anonymization protection scheme. The proposed scheme achieves k-anonymization protection for all

entities. Experimental results indicate that anonymized social networks using the proposed scheme require a very small fraction of edge modification and conserve considerable utility in terms of related centrality score distributions.
ACKNOWLEDGMENTS
This work was supported in part by the National Science Foundation (No. 1646955), the National Natural Science Foundation of China (No. 61532008) and the International Cooperation Projection of Hubei Province (No. 2014BHE0017).
REFERENCES
[1] H. Yang, I. Soboroff. Privacy-preserving IR 2015: When information retrieval meets privacy and security. In Proc. SIGIR, pp. 1157-1158, 2015.
[2] H. Hsieh, C. Li, R. Yan. I See You: Person-of-Interest Search in Social Networks. In Proc. SIGIR, pp. 839-842, 2015.
[3] S. Ji, W. Li, M. Srivatsa, R. Beyah, Structural data deanonymization: theory and practice, IEEE/ACM Transactions on Networking, 24(6), pp. 3523-3536, 2016.
[4] H. Fu, A. Zhang, X. Xie. Effective Social Graph Deanonymization Based on Graph Structure and Descriptive Information. ACM Trans. Intell. Syst. Technol., 6(4), pp. 49:1­49:29, 2015.
[5] B. Zhou, J. Pei. Preserving Privacy in Social Networks Against Neighborhood Attacks. In Proc. IEEE International Conference on Data Engineering, pp. 506-515, 2008.
[6] G. Wang, Q. Liu, F. Li, S. Yang, and J. Wu, Outsourcing PrivacyPreserving Social Networks to a Cloud, In Proc. IEEE INFOCOM, pp. 2886-2894, 2013.
[7] Q. Liu, G. Wang, F. Li, S. Yang, J. Wu. Preserving privacy with probabilistic indistinguishability in weighted Social networks, IEEE Transactions on Parallel and Distributed Systems, 28(5), pp. 1417-1492, 2017.
[8] L. Lu, T. Zhou, Q. Zhang, H. Stanley. The h-index of a network node and its relation to degree and coreness, Nature Communications, 7:10168, DOI: 10.1038/ncomms10168, 2016.

812

