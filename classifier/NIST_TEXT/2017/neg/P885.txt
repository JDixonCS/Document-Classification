Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

A Poisson Regression Method for Top-N Recommendation

Jiajin Huang, Jian Wang
Beijing University of Technology Beijing, China 100124
{hjj,wj1989}@emails.bjut.edu.cn
ABSTRACT
Top-N recommendation tasks aim to solve the information overload problem for users in the information age. As a user's decision may be affected by correlations among items, we incorporate such correlations with the user and item latent factors to propose a Poisson-regression-based method for top-N recommendation tasks. By placing priori knowledge and using a sparse structure assumption, this method learns the latent factors and the structure of the item-item correlation matrix through the alternating direction method of multipliers (ADMM). The preliminary experimental results on two real-world datasets show the improved performance of our approach.
CCS CONCEPTS
·Information systems Collaborative filtering;
KEYWORDS
Recommender systems; poisson regression; item-item correlations
ACM Reference format: Jiajin Huang, Jian Wang and Ning Zhong. 2017. A Poisson Regression Method for Top-N Recommendation. In Proceedings of SIGIR '17, August 7­11, 2017, Shinjuki, Tokyo, Japan, 4 pages. DOI: http://dx.doi.org/10.1145/3077136.3080670
1 INTRODUCTION
In recent years, recommender systems are used to help users tackle the information overload problem by providing them with what they may like. Many methods are proposed to rank items according to the relevance between the target user and item in descending order [6]. And then, top items in the list are recommended to users. The probabilistic matrix factorization (PMF) [12] method assumes the responses of users on items follow a Gaussian distribution, and then ranks items according to the predicted response. The research result shows that the Gaussian distribution in PMF
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 7­11, 2017, Shinjuki, Tokyo, Japan © 2017 ACM. ISBN 978-1-4503-5022-8/17/08. . . $15.00. DOI: http://dx.doi.org/10.1145/3077136.3080670

Ning Zhong
Maebashi Institute of Technology Maebashi, Japan 371-0816 zhong@maebashi-it.ac.jp
is suitable for modeling rating scores on items which users explicitly tell us.
However, users would be not willing to explicitly tell us their preferences. Fortunately, under the assumption that a user is more interested in the item with her higher visiting frequency than ones with lower frequency, we can represent a user's preference on different items according to how frequently the user visits [11]. In this case, the Poisson factor model (PoiFM) [3, 10, 11] is proposed to model user preferences by assuming the observed user-item frequency matrix follows a Poisson distribution with the parameter generated by the inner product of two low-dimensional factor matrices: user latent matrix and item latent matrix. By extending the PoiFM, Chaney et al. [2] developed a social poisson factorization method for recommendations.
Moreover, the item-item correlation plays an important role in recommender systems [7, 9]. For example, the widely used item-based collaborative filtering assumes that a user may like items similar to what he has bought. Koren et al. [8] used item-item correlations as user-specific weights in the matrix factorization (MF) method. Christakopoulou et al. [5] added a local item-item correlation into the MF method. However, the existing PoiFM ignores that a user's decision on the target item may be affected by what the user visited. We also need to consider correlations among items to improve the recommendation quality of PoiFM.
In this paper, we aim to study how to integrate the itemitem correlation within the framework based on the Poisson regression model for recommendations. Following the PoiFM model, we also model a user preference by the inner product of the user latent factor and item latent factor. The item-item correlation is modeled by a correlation matrix. Then by summing up the user preference and the item-item correlation, we can define the parameters of the Poisson likelihood function corresponding a target user on a target item. Under the assumption that the correlation matrix is sparse, we estimate the correlation matrix by using the alternating direction method of multipliers (ADMM) [1] which can deal with the constraints for the model parameters. At last, we apply the proposed model to top-N recommendation tasks.
2 MODEL
We define the user set U = {u1, u2, · · · , uM } and the item set V = {v1, v2, · · · , vN }. The response (rating, like, or implicit frequency) of a user ui on an item vj is yij. A user ui  U has a response on an item vj  V, written as uiY vj. The relation Y between U and V is a subset of pairs (ui, vj) in the Cartesian product U × V. By projecting Y on a given

885

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

user ui, we have a user-oriented relation

Yui = {vj |(ui, vj )  Y }.

(1)

We use a Poisson distribution to model the likelihood function for yij as

yij  P(µij ) 

ln µij = UiVjT +

sj lnyis

(2)

sYui

where Yui is the set of items which user ui visited, P denotes the Poisson distribution with its probability density function formulated as p(x) = µxexp{-µ}/x!.
According to Eq. (2), lnµij consists of two parts. The first part is the linear function of a user latent vector Ui and an item latent vector Vj, which is identical to the basic PoiMF model. The second part is the contribution of items that a user visited. In the second part, the influence factor is described by the matrix W whose (s, j)th element is sj. The influence between vs and vj can be parameterized by sj and js. Specifically, sj could be described as the nonnegative possibility of a user liking item vj after the user visited vs. By defining ln0 = 0, we can have

 N

ln µij = UiVjT + sj ln yis

(3)

s=1

We add a normal prior on Ui and Vj to avoid over-fitting. And we also place a Laplace prior on non-negative W to make it be sparse. So we have

1

Ui, Vj



N (0,

I) 1

1 sj  L(0, 2 )

Then we can formulate the objective function of the MAP solution as

min
U,V,W
s.t.

 M  N (µij

-

yij

ln µij )

+

1 2

 M ||Ui||22

i=1 j=1

i

+ 1 2

 N

||Vj ||22

+

2



sj

j

s,j

H = W, H  0

(4)

Following the study of [13], the augmented Lagrangian is defined as

 M  N

L(U, V, W, H, ) =

(µij - yij ln µij )

i=1 j=1

+

1 2

 M (

||Ui||22

+

 N

||Vj ||22)

i=1

j=1



+2 sj + tr(T (H - W ))

s,j

 + ||H
2

-

W ||2F

(5)

where T is Lagrange multipliers, tr(·) denotes the trace of a square matrix,  is a penalty parameter and || · ||F denotes the Frobenius norm of a matrix.
To minimize L(U, V, W, H, ) with respect to U , V , and W , we use the gradient method with the gradients computed as

L Ui

=

 N (µij - yij )Vj + 1Ui
j=1

L Vj

=

 M (µij - yij )Ui + 1Vj
i=1

L sj

 M

=

(µij - yij ) ln yis + 2 - sj

i=1

+(sj - hsj )

For H, we can have

min
H

tr(T (H

-

W ))

+

 ||H 2

-

W ||2F

s.t.

H 0

(6)

which has an analytical solution as

1

hsj = max(0, sj -  sj )

(7)

Based on the above notations, the U-ADMM algorithm with the learning rate  is described in Algorithm 1 by extending the ADMM [1] .

Algorithm 1 User-oriented ADMM algorithm (U-ADMM)
01. Initialize U (0), V (0), W (0), and (0); 02. for t = 1 to itermax do 03. U (t)=arg minU L(U, V (t-1), W (t-1), H(t-1), (t-1)); 04. V (t)=arg minV L(U (t-1), V, W (t-1), H(t-1), (t-1)); 03. W (t)=arg minW L(U (t-1), V (t-1), W, H(t-1), (t-1)); 04. H(t)=arg minH L(U (t-1), V (t-1), W (t), H, (t-1)); 05. (t)=(t-1) + (W (t) - H(t)); 06. end

The proposed model predicts the frequency of a user ui visiting an item vj as µij. We make recommendations based on the predicted values. The larger µij means that ui will more likely choose vj.
3 EXPERIMENTS
In this section, we first compare the performance of our model with PMF and PoiFM models. And then, we analyze the impact of the important parameters in our model U-ADMM.
3.1 Datasets and Metrics
Experimental data are from Gowalla website and Brightkite website [4]. The Gowalla dataset includes a total of 6442890 check-in records generated by 196591 users from February 2009 to October 2010; And the Brightkite dataset includes a total of 4747200 check-in records generated by 51406 users over the period of April 2008 - October 2010. We remove

886

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

users and items that occur less than twenty-five times, and extract 159335 check-in records generated in Los Angeles by 1471 users from the Gowalla dataset. At the same time, we remove users and items that occur less than ten times, and extract 257249 check-in records by 1850 users from the Brightkite dataset. Statistics of datasets are given in Table 1.
Table 1: Dataset Statistics

#users #items #check in #density

Gowalla
1471 1539 159335 0.9596

Brightkite
1850 1666 257249 0.9877

We randomly divide each dataset into five parts, and se-

lect four parts as the training set and measure the prediction

performance on the rest testing set. We evaluate the effec-

tiveness of theproposed system by respectively using the

precision P =

, u U |R(u)T (u)|
uU |R(u)|

recall

R

=

, u U |R(u)T (u)|
uU |T (u)|

and

F1

=

2×P ×R P +R

,

where

R(u)

is

the

set

of

the

recommend-

ed items for user u, T (u) is the set of items which user u

preferred in the test set, and | · | is the cardinality of a set.

3.2 Comparison
In this section, we show the preliminary results of U-ADMM model compared with some baseline methods including PMF and PoiFM. In the training datasets, all methods are trained to a relatively optimal state through learning respective parameters. On the Gowalla dataset, we set the number of latent factors K=30 for all methods. For PMF, learning rate =0.0012, 1=0.01. For PoiFM, =0.003, and the requested prior Gamma distribution parameter au=5, bu=0.06, av=3, bv=0.1. For our model U-ADMM, =0.01, 1=0.7, 2=0.07, =0.005. Figure 1 shows the results about the three models with precision and recall on the Gowalla dataset. Then, we turn our attention to the Brightkite dataset. For PMF, K=90, =0.0002, 1=0.007. For PoiFM, K=70, =0.0005, au=3, bu=0.008, av=1, bv=0.01. For U-ADMM, K=10, =0.003, 1=1.2, 2=0.007, =0.0001. The performance on the Bright-kite dataset is shown as Fig. 2. And all the models are evaluated with different number of top items in the recommended list.
As shown in Fig. 1 and 2, with the not very good precision and recall values of PMF, we can observe that it is not easy to predict how many times exactly a user visited an item. However, we can obtain a better result by assuming that the frequency of a user visiting an item follows a Poisson distribution, and the proposed U-ADMM can improve the performance by considering the correlations among items.

3.3 Impact of Parameters
Here we show the impact of the five important parameters in U-ADMM for top 10 recommendation tasks: 1) the number

precision(%) recall(%)

16 12
8 4
5

U-ADMM PoiFM PMF

10

15

20

25

Top

20

U-ADMM

PoiFM

16

PMF

12

8

4

0 5

10

15

20

25

Top

Figure 1: Performance comparison between UADMM and other methods on the Gowalla dataset

precision(%) recall(%)

10 8 6 4 2 0 5

U-ADMM PoiFM PMF

10

15

20

25

Top

30

U-ADMM

25

PoiFM

PMF

20

15

10

5

0 5

10

15

20

25

Top

Figure 2: Performance comparison between UADMM and other methods on the Brightkite dataset

of latent factors K; 2) the learning rate , 3) the 1, 2 and  that control regularization.
To be fair, we investigate the impact of those parameters at a relatively optimal state. By varying one of the parameters and fixing the other, we investigate the impact of those parameters. First, we vary the latent factors K= {5, 10, 30, 50, 70, 90} and evaluate the predicted result with F 1 which considers both precision and recall. As shown in Fig. 3, UADMM performs best when K = 10 on the both datasets.

F1(%) F1(%)

11.85

11.80

11.75

11.70

11.65

5 10 30 50 70 90
K

9.5
9.4
9.3
9.2
9.1
9.0 5 10 30 50 70 90
K

Figure 3: Impact of K in U-ADMM on the Gowalla (a) and Brightkite (b) dataset

Next, we investigate the sensitivity of , 1, 2, and . We also vary one of them and fix the other, and measure the result by F 1. As shown in Fig. 4 and 5, U-ADMM

887

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

model performs better with the parameter values mentioned in Section 3.2. From Fig. 4 and 5, we can also observe that smaller values of the learning rate  and penalty parameter  tend to give better performances on the both datasets. The best ranges of prior parameter 1 and 2 are different on different datasets.

F1(%)

12.5

12.0

12.0

11.8

11.5

11.6

F1(%)

11.0

11.4

10.5

11.2

10.0

11.0

5 10 15 20 25 30 (10-3) 0.0

0.2

0.4

0.6

0.8

1.0


12.0

1
12.0

F1(%)

F1(%)

11.9 11.9
11.8
11.8 11.7

11.7

11.6

0.00 0.02 0.04 0.06 0.08 0.10

0.00 0.02 0.04 0.06 0.08 0.10

2



Figure 4: Impact of Parameter , 1, 2 and  in U-ADMM on the Gowalla dataset

F1(%)

10

9.6

8

9.5

6

9.4

F1(%)

4

9.3

2

9.2

0

9.1

0.03 0.3

3

30 300 (10-2)

0.8

1.0

1.2

1.4

1.6


9.55

1
9.6

9.50

9.4

F1(%)

9.45 9.2
9.40
9.0 9.35

9.30

8.8

9.25

8.6

0

2

4

6

8

10 (10-3)

0.0001 0.001 0.01 0.1

1

2



F1(%)

Figure 5: Impact of Parameter , 1, 2 and  in U-ADMM on the Brightkite dataset

4 CONCLUSIONS
This paper proposes the Poisson regression model U-ADMM for top-N recommendation tasks. The proposed U-ADMM adds correlations among items to revise user preference about a target item by extending the ADMM. The results for topN recommendation tasks show that introducing correlations among items to revise user preference can effectively improve recommendation quality in the poisson factor model. In our future work, we will add the correlations among users to our model to yield further improvements.
ACKNOWLEDGMENTS
We thank Zhaoqiang Li for making a double check of the experimental results. The work is supported by the National Natural Science Foundation of China under Grant No.: 61420106005, 61562009.
REFERENCES
[1] S. Boyd, N.Parikh, E. Chu, B. Peleat, and J. Eckstein. 2011. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Mache Learning 3, 1 (2011), 1­122.
[2] A.J.B. Chaney, D.M. Blei, and Eliassi-Rad. 2015. A probabilistic model for using social networks in personalized item recommendation. In Proceedings of the 2015 ACM Conference on Recommender Systems (RecSys 2015). 43­50.
[3] Y. Chen, D. Pavlov, M. Kapralov, and J.F. Canny. 2009. Factor modeling for advertisement targeting. In Proceedings of the 2009 International Conference on Advances in Neural Information Processing Systems (NIPS 2009). 324­332.
[4] E. Cho, S.A. Myers, and J. Leskovec. 2011. Friendship and mobility: user movement in location-based social networks. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2011). 1082­1090.
[5] E. Christakopoulou and G. Karypis. 2016. Local item-item models for top-N recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems (Recsys 2016). 67­74.
[6] W. Cohen, R.E. Schapire, and Y. Singer. 1999. Learning to order things. Artificial Intelligence Research 10 (1999), 243­270.
[7] L. Guo, J. Ma, Z.M. Chen, and H. Zhong. 2015. Learning to recommend with social contextual information from implicit feedback. Soft Computing 19, 5 (2015), 1351­1362.
[8] Y. Koren. 2010. Factor in the neighbors: Scalable and accurate collaborative filtering. ACM Transactions on Knowledge Discovery from Data 4, 1 (2010), 1:1­1:24.
[9] S. Li, A. Karatzoglou, and C. Gentile. 2016. Collaborative filtering bandits. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR 2016). 539­548.
[10] B. Liu, H. Xiong, S.Papadimitriou, Y.J. Fu, and Z.J. Yao. 2015. A general geographical probabilistic factor model for point of interest recommendation. IEEE Transactions on Knowledge and Data Engineering 27, 5 (2015), 1167­1179.
[11] H. Ma, C. Li, I. King, and M.R. Lyu. 2011. Probabilistic factor models for web site recommendation. In Proceeding of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2011). 265­274.
[12] R. Salakhutdinov and A. Mnih. 2008. Probabilistic matrix factorization. In Proceedings of the 2008 International Conference on Advances in Neural Information Processing Systems (NIPS 2008). 1257­1264.
[13] Y. Zhang, W.K. Cheung, and J.M. Liu. 2015. A unified framework for epidemic prediction based on poisson regression. IEEE Transactions on Knowledge and Data Engineering 27, 11 (2015), 2878­2892.

888

