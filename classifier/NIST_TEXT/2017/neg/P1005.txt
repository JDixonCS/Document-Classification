Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Multitask Learning for Fine-Grained Twi er Sentiment Analysis

Georgios Balikas
Univ. Grenoble Alps, CNRS, Grenoble INP - LIG / Co reo
Georgios.Balikas@imag.fr

Simon Moura
Univ. Grenoble Alps, CNRS, Grenoble INP - LIG
Simon.Moura@imag.fr

Massih-Reza Amini
Univ. Grenoble Alps, CNRS, Grenoble INP - LIG
Massih-Reza.Amini@imag.fr

ABSTRACT
Traditional sentiment analysis approaches tackle problems like ternary (3-category) and ne-grained (5-category) classi cation by learning the tasks separately. We argue that such classi cation tasks are correlated and we propose a multitask approach based on a recurrent neural network that bene ts by jointly learning them. Our study demonstrates the potential of multitask models on this type of problems and improves the state-of-the-art results in the
ne-grained sentiment classi cation problem.
KEYWORDS
Text Mining; Sentiment Analysis; Deep Learning; Multitask Learning, Twitter Analysis; biLSTM; Text classi cation
ACM Reference format: Georgios Balikas, Simon Moura, and Massih-Reza Amini. 2017. Multitask Learning for Fine-Grained Twitter Sentiment Analysis . In Proceedings of SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages. DOI: http://dx.doi.org/10.1145/3077136.3080702
1 INTRODUCTION
Automatic classi cation of sentiment has mainly focused on categorizing tweets in either two (binary sentiment analysis) or three (ternary sentiment analysis) categories [8]. In this work we study the problem of ne-grained sentiment classi cation where tweets are classi ed according to a ve-point scale ranging from VeryNegative to VeryPositive. To illustrate this, Table 1 presents examples of tweets associated with each of these categories. Five-point scales are widely adopted in review sites like Amazon and TripAdvisor, where a user's sentiment is ordered with respect to its intensity. From a sentiment analysis perspective, this de nes a classi cation problem with ve categories. In particular, Sebastiani et al. [17] de ned such classi cation problems whose categories are explicitly ordered to be ordinal classi cation problems. To account for the ordering of the categories, learners are penalized according to how far from the true class their predictions are.
Although considering di erent scales, the various settings of sentiment classi cation are related. First, one may use the same feature extraction and engineering approaches to represent the text spans such as word membership in lexicons, morpho-syntactic statistics like punctuation or elongated word counts [2, 14]. Second, one would expect that knowledge from one task can be transfered to
Publication rights licensed to ACM. ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or a liate of a national government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: http://dx.doi.org/10.1145/3077136.3080702

the others and this would bene t the performance. Knowing that a tweet is "Positive" in the ternary setting narrows the classi cation decision between the VeryPositive and Positive categories in the
ne-grained setting. From a research perspective this raises the question of whether and how one may bene t when tackling such related tasks and how one can transfer knowledge from one task to another during the training phase.
Our focus in this work is to exploit the relation between the sentiment classi cation settings and demonstrate the bene ts stemming from combining them. To this end, we propose to formulate the di erent classi cation problems as a multitask learning problem and jointly learn them. Multitask learning [3] has shown great potential in various domains and its bene ts have been empirically validated [5, 15, 16, 22] using di erent types of data and learning approaches. An important bene t of multitask learning is that it provides an elegant way to access resources developed for similar tasks. By jointly learning correlated tasks, the amount of usable data increases. For instance, while for ternary classi cation one can label data using distant supervision with emoticons [10], there is no straightforward way to do so for the ne-grained problem. However, the latter can bene t indirectly, if the ternary and ne-grained tasks are learned jointly.
The research question that the paper attempts to answer is the following: Can twitter sentiment classi cation problems, and negrained sentiment classi cation in particular, bene t from multitask learning? To answer the question, the paper brings the following two main contributions: (i) we show how jointly learning the ternary and ne-grained sentiment classi cation problems in a multitask setting improves the state-of-the-art performance,1 and (ii) we demonstrate that recurrent neural networks outperform models previously proposed without access to huge corpora while being
exible to incorporate di erent sources of data.
2 MULTITASK LEARNING FOR TWITTER SENTIMENT CLASSIFICATION
In his work, Caruana [3] proposed a multitask approach in which a learner takes advantage of the multiplicity of interdependent tasks while jointly learning them. The intuition is that if the tasks are correlated, the learner can learn a model jointly for them while taking into account the shared information which is expected to improve its generalization ability. People express their opinions online on various subjects (events, products..), on several languages and in several styles (tweets, paragraph-sized reviews..), and it is exactly this variety that motivates the multitask approaches. Speci cally for Twitter for instance, the di erent settings of classi cation like
1An open implementation of the system for research purposes is available at https: //github.com/balikasg/sigir2017.

1005

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

XT

XT -1

X1

LSTM LSTM

LSTM LSTM

X1

X2

LSTM
H1
LSTM biLSTM
XT

Additional Features

HA

Multitask outputs softmax1
HM
softmaxN

...

Figure 1: The neural network architecture for multitask learning. The biLSTM output is transformed by the hidden layers H1, HM and is led to N output layers, one for each of the tasks. The lower part of the network can be
used to incorporate additional information.

Beyond frustrated with my #Xbox360 right now,

VeryNegative and that as of June, @Microsoft doesn't support it.

Gotta nd someone else to x the drive.

@Microsoft Heard you are a software company.

Negative

Why then is most of your software so bad that it

has to be replaced by 3rd party apps?

@ProfessorF @gilwuvsyou @Microsoft

Neutral

@LivioDeLaCruz We already knew the media march in ideological lockstep but it is nice of him

to show it.

PAX Prime Thursday is overloaded for me with

Positive

@Microsoft and Nintendo indie events going

down. Also, cider!!! :p

I traveled to Redmond today. I'm visiting with

VeryPositive @Microsoft @SQLServer engineers tomorrow - at

their invitation. Feeling excited.

Table 1: The example demonstrates the di erent levels of sentiment a tweet may convey. Also, note the Twitter-speci c use of language and symbols.

binary, ternary and ne-grained are correlated since their di erence lies in the sentiment granularity of the classes which increases while moving from binary to ne-grained problems.
There are two main decisions to be made in our approach: the learning algorithm, which learns a decision function, and the data representation. With respect to the former, neural networks are particularly suitable as one can design architectures with di erent properties and arbitrary complexity. Also, as training neural network usually relies on back-propagation of errors, one can have shared parts of the network trained by estimating errors on the joint tasks and others specialized for particular tasks. Concerning the data representation, it strongly depends on the data type available. For the task of sentiment classi cation of tweets with neural networks, distributed embeddings of words have shown great potential. Embeddings are de ned as low-dimensional, dense representations of words that can be obtained in an unsupervised fashion by training on large quantities of text [21].
Concerning the neural network architecture, we focus on Recurrent Neural Networks (RNNs) that are capable of modeling shortrange and long-range dependencies like those exhibited in sequence data of arbitrary length like text. While in the traditional information retrieval paradigm such dependencies are captured using n-grams and skip-grams, RNNs learn to capture them automatically [7]. To circumvent the problems with capturing long-range dependencies and preventing gradients from vanishing, the long short-term memory network (LSTM) was proposed [11]. In this work, we use an extended version of LSTM called bidirectional LSTM (biLSTM). While standard LSTMs access information only from the past (previous words), biLSTMs capture both past and future information e ectively [7, 12]. They consist of two LSTM networks, for propagating text forward and backwards with the goal being to capture the dependencies better. Indeed, previous work on multitask learning showed the e ectiveness of biLSTMs in a variety of problems: [1] tackled sequence prediction, while [22] and [13] used biLSTMs for Named Entity Recognition and dependency parsing respectively.
Figure 1 presents the architecture we use for multitask learning. In the top-left of the gure a biLSTM network (enclosed by the

dashed line) is fed with embeddings {X1, . . . , XT } that correspond to the T words of a tokenized tweet. Notice, as discussed above, the biLSTM consists of two LSTMs that are fed with the word sequence forward and backwards. On top of the biLSTM network one (or more) hidden layers H1 transform its output. The output of H1 is led to the softmax layers for the prediction step. There are N softmax layers and each is used for one of the N tasks of the multitask setting. In tasks such as sentiment classi cation, additional features like membership of words in sentiment lexicons or counts of elongated/capitalized words can be used to enrich the representation of tweets before the classi cation step [14]. The lower part of the network illustrates how such sources of information can be incorporated to the process. A vector "Additional Features" for each tweet is transformed from the hidden layer(s) HA and then is combined by concatenation with the transformed biLSTM output in the HM layer.
3 EXPERIMENTAL SETUP
Our goal is to demonstrate how multitask learning can be successfully applied on the task of sentiment classi cation of tweets. The particularities of tweets are to be short and informal text spans. The common use of abbreviations, creative language etc., makes the sentiment classi cation problem challenging. To validate our hypothesis, that learning the tasks jointly can bene t the performance, we propose an experimental setting where there are data from two di erent twitter sentiment classi cation problems: a ne-grained and a ternary. We consider the ne-grained task to be our primary task as it is more challenging and obtaining bigger datasets, e.g. by distant supervision, is not straightforward and, hence we report the performance achieved for this task.
Ternary and ne-grained sentiment classi cation were part of the SemEval-2016 "Sentiment Analysis in Twitter" task [19]. We use the high-quality datasets the challenge organizers released.2 The dataset for ne-grained classi cation is split in training, development, development_test and test parts. In the rest, we refer to these splits as train, development and test, where train is composed
2The datasets are those of Subtasks A and C, available at http://alt.qcri.org/ semeval2016/task4/.

1006

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

|D | VeryNeg. Neg. Neutr. Pos. VeryPos.

Train 7,292

111

884 2,019 3,726

432

Dev. 1,778

29

204 533 887

125

Test 20,632

138

2,201 10,081 7,830

382

Ternary 5,500

-

785 1,887 2,828

-

Table 2: Cardinality and class distributions of the datasets.

by the training and the development instances. Table 2 presents

an overview of the data. As discussed in [19] and illustrated in the

Table, the ne-grained dataset is highly unbalanced and skewed towards the positive sentiment: only 13.6% of the training examples

are labeled with one of the negative classes.

Feature representation We report results using two di erent fea-

ture sets. The rst one, dubbed nbow, is a neural bag-of-words that

uses text embeddings to generate low-dimensional, dense represen-

tations of the tweets. To construct the nbow representation, given

the word embeddings dictionary where each word is associated

with a vector, we apply the average compositional function that

averages the embeddings of the words that compose a tweet. Sim-

ple compositional functions like average were shown to be robust

and e cient in previous work [18]. Instead of training embeddings

from scratch, we use the pre-trained on tweets GloVe embeddings of [21].3 In terms of resources required, using only nbow is e cient

as it does not require any domain knowledge. However, previous

research on sentiment analysis showed that using extra resources,

like sentiment lexicons, can bene t signi cantly the performance

[2, 14]. To validate this and examine at which extent neural net-

works and multitask learning bene t from such features we evaluate

the models using an augmented version of nbow, dubbed nbow+.

The feature space of the latter, is augmented using 1,368 extra fea-

tures consisting mostly of counts of punctuation symbols ('!?#@'),

emoticons, elongated words and word membership features in sev-

eral sentiment lexicons. Due to space limitations, for a complete

presentation of these features, we refer the interested reader to [2], whose open implementation we used to extract them.4
Evaluation measure To reproduce the setting of the SemEval
challenges [19], we optimize our systems using as primary measure the macro-averaged Mean Absolute Error (MAEM ) given by:

M AEM

=

1 |C |

|C | j =1

1 |Tej |

xi Tej

|h(xi ) -

i|

where |C | is the number of categories, Tej is the set of instances whose true class is cj , i is the true label of the instance xi and h(xi ) the predicted label. The measure penalizes decisions far from
the true ones and is macro-averaged to account for the fact that
the data are unbalanced. Complementary to MAEM , we report the performance achieved on the micro-averaged F1 measure, which is
a commonly used measure for classi cation.

The models To evaluate the multitask learning approach, we

compared it with several other models. Support Vector Machines

(SVMs) are maximum margin classi cation algorithms that have

been shown to achieve competitive performance in several text

classi cation problems [19]. SVMovr stands for an SVM with linear kernel and an one-vs-rest approach for the multi-class problem.

3 urlhttp://nlp.stanford.edu/data/glove.twitter.27B.zip 4 https://github.com/balikasg/SemEval2016- Twitter_Sentiment_Evaluation

Also, SVMcs is an SVM with linear kernel that employs the crammersinger strategy [6] for the multi-class problem. Logistic regression (LR) is another type of linear classi cation method, with probabilistic motivation. Again, we use two types of Logistic Regression depending on the multi-class strategy: LRovr that uses an one-vsrest approach and multinomial Logistic Regression also known as the MaxEnt classi er that uses a multinomial criterion.
Both SVMs and LRs as discussed above treat the problem as a multi-class one, without considering the ordering of the classes. For these four models, we tuned the hyper-parameter C that controls the importance of the L2 regularization part in the optimization problem with grid-search over {10-4, . . . , 104} using 10-fold crossvalidation in the union of the training and development data and then retrained the models with the selected values. Also, to account for the unbalanced classi cation problem we used class weights to penalize more the errors made on the rare classes. These weights were inversely proportional to the frequency of each class. For the four models we used the implementations of Scikit-learn [20].
For multitask learning we use the architecture shown in Figure 1, which we implemented with Keras [4]. The embeddings are initialized with the 50-dimensional GloVe embeddings while the output of the biLSTM network is set to dimension 50. The activation function of the hidden layers is the hyperbolic tangent. The weights of the layers were initialized from a uniform distribution, scaled as described in [9]. We used the Root Mean Square Propagation optimization method. We used dropout for regularizing the network. We trained the network using batches of 128 examples as follows: before selecting the batch, we perform a Bernoulli trial with probability pM to select the task to train for. With probability pM we pick a batch for the ne-grained sentiment classi cation problem, while with probability 1 - pM we pick a batch for the ternary problem. As shown in Figure 1, the error is backpropagated until the embeddings, that we ne-tune during the learning process. Notice also that the weights of the network until the layer HM are shared and therefore a ected by both tasks.
To tune the neural network hyper-parameters we used 5-fold cross validation. We tuned the probability p of dropout after the hidden layers HM , H1, HA and for the biLSTM for p  {0.2, 0.3, 0.4, 0.5}, the size of the hidden layer HM  {20, 30, 40, 50} and the probability pM of the Bernoulli trials from {0.5, 0.6, 0.7, 0.8}.5 During training, we monitor the network's performance on the development set and apply early stopping if the performance on the validation set does not improve for 5 consecutive epochs. Experimental results Table 3 illustrates the performance of the models for the di erent data representations. The upper part of the Table summarizes the performance of the baselines. The entry "Balikas et al." stands for the winning system of the 2016 edition of the challenge [2], which to the best of our knowledge holds the state-of-the-art. Due to the stochasticity of training the biLSTM models, we repeat the experiment 10 times and report the average and the standard deviation of the performance achieved.
Several observations can be made from the table. First notice that, overall, the best performance is achieved by the neural network architecture that uses multitask learning. This entails that
5Overall, we cross-validated 512 combinations of parameters. The best parameters were: 0.2 for all dropout rates, 20 neurons for HM and pM = 0.5.

1007

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

nbow

nbow+

SVMovr SVMcs LRovr MaxEnt
Balikas et al. [2]

0.840 0.946 0.836 0.842
-

0.714 0.723 0.712 0.715 0.719

biLSTM (single task) 0.827±0.017 0.694±0.04 biLSTM+Multitask 0.786±0.025 0.685±0.024
Table 3: The scores on MAEM for the systems. The best (lowest) score is shown in bold and is achieved in the multitask setting with the biLSTM architecture of Figure 1.

0.359

0.445

0.459

0.469

0.481

F1 0.45

0.30 0.251

0.15

SVMcs MaxEnt SVMovr

LRovr

biLSTM biLSTM+ Multitask

Figure 2: F1 scores using the nbow+ representations. The best performance is achieved with the multitask setting.

the system makes use of the available resources e ciently and improves the state-of-the-art performance. In conjunction with the fact that we found the optimal probability pM = 0.5, this highlights the bene ts of multitask learning over single task learning. Furthermore, as described above, the neural network-based models have only access to the training data as the development are hold for early stopping. On the other hand, the baseline systems were retrained on the union of the train and development sets. Hence, even with fewer resources available for training on the ne-grained problem, the neural networks outperform the baselines. We also highlight the positive e ect of the additional features that previous research proposed. Adding the features both in the baselines and in the biLSTM-based architectures improves the MAEM scores by several points.
Lastly, we compare the performance of the baseline systems with the performance of the state-of-the-art system of [2]. While [2] uses n-grams (and character-grams) with n > 1, the baseline systems (SVMs, LRs) used in this work use the nbow+ representation, that relies on unigrams. Although they perform on par, the competitive performance of nbow highlights the potential of distributed representations for short-text classi cation. Further, incorporating structure and distributed representations leads to the gains of the biLSTM network, in the multitask and single task setting.
Similar observations can be drawn from Figure 2 that presents the F1 scores. Again, the biLSTM network with multitask learning achieves the best performance. It is also to be noted that although the two evaluation measures are correlated in the sense that the ranking of the models is the same, small di erences in the MAEM have large e ect on the scores of the F1 measure.
4 CONCLUSION
In this paper, we showed that by jointly learning the tasks of ternary and ne-grained classi cation with a multitask learning model, one can greatly improve the performance on the second. This opens several avenues for future research. Since sentiment is expressed in di erent textual types like tweets and paragraph-sized reviews, in di erent languages (English, German, ..) and in di erent granularity levels (binary, ternary,..) one can imagine multitask approaches that could bene t from combining such resources. Also, while we opted for biLSTM networks here, one could use convolutional neural networks or even try to combine di erent types of networks and tasks to investigate the performance e ect of multitask learning.

Lastly, while our approach mainly relied on the foundations of [3],
the internal mechanisms and the theoretical guarantees of multitask
learning remain to be better understood.
5 ACKNOWLEDGEMENTS
This work is partially supported by the CIFRE N 28/2015.
REFERENCES
[1] Héctor Martínez Alonso and Barbara Plank. 2016. Multitask learning for semantic sequence prediction under varying data conditions. arXiv:1612.02251 (2016).
[2] Georgios Balikas and Massih-Reza Amini. 2016. TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classi cation. In SemEval@NAACL-HLT 2016. 85­91.
[3] Rich Caruana. 1997. Multitask Learning. Machine Learning 28, 1 (1997), 41­75. [4] François Chollet. 2015. Keras. https://github.com/fchollet/keras. (2015). [5] Ronan Collobert and Jason Weston. 2008. A uni ed architecture for natural
language processing: deep neural networks with multitask learning. In ICML. [6] Koby Crammer and Yoram Singer. 2001. On the Algorithmic Implementation of
Multiclass Kernel-based Vector Machines. JMLR 2 (2001), 265­292. [7] Chris Dyer, Miguel Ballesteros, Wang Ling, Austin Matthews, and Noah A.
Smith. 2015. Transition-Based Dependency Parsing with Stack Long Short-Term Memory. In ACL. 334­343. [8] Anastasia Giachanou and Fabio Crestani. 2016. Like It or Not: A Survey of Twitter Sentiment Analysis Methods. ACM Comput. Surv. 49, 2 (2016), 28:1­28:41. [9] Xavier Glorot and Yoshua Bengio. 2010. Understanding the di culty of training deep feedforward neural networks. In AISTATS. 249­256. [10] Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classi cation using distant supervision. CS224N Project Report, Stanford 1 (2009), 12. [11] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735­1780. [12] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF Models for Sequence Tagging. CoRR abs/1508.01991 (2015). [13] Eliyahu Kiperwasser and Yoav Goldberg. 2016. Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations. TACL (2016). [14] Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mohammad. 2014. Sentiment analysis of short informal texts. JAIR (2014), 723­762. [15] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Deep Multi-Task Learning with Shared Memory for Text Classi cation. In EMNLP. 118­127. [16] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent Neural Network for Text Classi cation with Multi-Task Learning. In IJCAI. 2873­2879. [17] Giovanni Da San Martino, Wei Gao, and Fabrizio Sebastiani. 2016. Ordinal Text Quanti cation. In SIGIR. 937­940. [18] Je Mitchell and Mirella Lapata. 2010. Composition in Distributional Models of Semantics. Cognitive Science 34, 8 (2010), 1388­1429. [19] Preslav Nakov, Alan Ritter, Sara Rosenthal, Fabrizio Sebastiani, and Veselin Stoyanov. 2016. SemEval-2016 Task 4: Sentiment Analysis in Twitter. In SemEval@NAACL-HLT. 1­18. [20] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. JMLR 12 (2011), 2825­2830. [21] Je rey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global Vectors for Word Representation. In EMNLP. 1532­1543. [22] Barbara Plank. 2016. Keystroke dynamics as signal for shallow syntactic parsing. In COLING. 609­619.

1008

