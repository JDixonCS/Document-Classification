Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Understanding and Predicting Usefulness Judgment in Web Search

Jiaxin Mao, Yiqun Liu, Huanbo Luan, Min Zhang, Shaoping Ma, Hengliang Luo, Yuntao Zhang
Department of Computer Science & Technology, Tsinghua University, Beijing, China Samsung Beijing R&D Center, Beijing, China yiqunliu@tsinghua.edu.cn

ABSTRACT
Usefulness judgment measures the user-perceived amount of useful information for the search task in the current search context. Understanding and predicting usefulness judgment are crucial for developing user-centric evaluation methods and providing contextualize results according to the search context. With a dataset collected in a laboratory user study, we systematically investigate the e ects of a variety of content, context, and behavior factors on usefulness judgments and nd that while user behavior factors are most important in determining usefulness judgments, content and context factors also have signi cant e ects on it. We further adopt these factors as features to build prediction models for usefulness judgments. An AUC score of 0.909 in binary usefulness classi cation and a Pearson's correlation coe cient of 0.694 in usefulness regression demonstrate the e ectiveness of our models. Our study sheds light on the understanding of the dynamics of the user-perceived usefulness of documents in a search session and provides implications for the evaluation and design of Web search engines.
CCS CONCEPTS
·Information systems  Users and interactive retrieval; Retrieval e ectiveness;
KEYWORDS
Usefulness, User Behavior Analysis, Evaluation
1 INTRODUCTION
Web search engines help people e ectively deal with the information overload by retrieving a small number of highly relevant documents to the user within a second. However, high relevance (especially topical relevance) between the document and query may not necessarily mean the document is useful for the user [10]. It is still very common for the user to encounter
Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 7-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080750

documents with low usefulness and feel frustrated in the search. is gap motivates us to study the dynamic, situational, and
subjective document-level usefulness judgment, which is de ned as the user-perceived amount of useful information in the document, for the search task at hand, in the current search context. From the perspective of search engine evaluation, investigating usefulness judgment can help us be er understand user's search process and develop user-centric evaluation methods. From the perspective of search engine design, usefulness judgments from real users can be used as signals of high-quality results and the prediction of usefulness judgment may guide the system to provide personalized and contextualized results for the user.
In order to study user's usefulness judgment, we conducted a user study in laboratory se ings to collect a dataset that contains
ne-grain search logs for 166 sessions and the corresponding usefulness judgments from users on 1,383 visited documents. Using this dataset, we try to answer the following research questions: RQ1: What factors may a ect users' usefulness judgments? RQ2: Can we estimate or predict usefulness judgments using such factors as features?
To address RQ1, we examine the e ect of content, context, and behavior factors on usefulness judgments. To address RQ2, we use these factors as features to build regression and (binary) classi cation models to estimate and predict usefulness judgments. e prediction performance is promising in that the classi cation model achieves an AUC score of 0.909 and the Pearson's r between actual usefulness judgments and the prediction of the regression model reaches 0.694.
Related Work
Some recent studies have addressed concept and measurement of usefulness in information retrieval.
Belkin et al. [1, 2] proposed to adopt usefulness in evaluating interactive information retrieval systems. Mao et al. [10] found that topical relevance is necessary but not su cient for usefulness and the usefulness judgment correlates be er with user satisfaction than relevance judgment. Kim et al. [7] used an online experiment to collect users' in situ feedback of whether a search result is helpful or not. ey found that the in situ usefulness feedback is di erent from assessors' relevance judgment because the user may have idiosyncratic search intents and the ideal threshold of dwell time for predicting positive in situ feedbacks is much longer than the ideal threshold for predicting positive relevance judgments (87 s vs. 38 s). Jiang et al. [6] analyzed the relationship between contextual usefulness feedback(called ephemeral state of relevance (ESR) in

1169

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

their paper) and other explicit feedbacks such as topical relevance, novelty, e ort, understandability, and reliability.
Compared to these studies, our work focuses on inspecting a variety implicit factors that may a ect usefulness judgment as well as building a prediction model that utilizes these implicit factors to e ectively estimate user's usefulness judgments.
2 DATA COLLECTION
In this section, we describe the se ings of the user study and the dataset we collected.
e procedure of the user study is shown in Figure 1. In the user study, we required each participant complete 6 search tasks1 using an experiment search engine. A total of 30 participants were recruited via email or online social networks. All of them are college students aged from 19 to 22. 22 participants are female, and other 8 participants are male. Each search task is a non-trivial question that can be answered in 100 words such as: What are the most commonly-used treatments for cancer in clinical?. Before carrying out the rst search task, each participant would go through a preexperiment training stage. Because we also recorded participants' eye xation movements using a Tobii X2-30 eye-tracker, in stage II, we calibrated the eye-tracker for each participant.
For each of the six search tasks, the participant was required to go through stage III to stage VII. First, in stage III, the participant would read and remember the task description (i.e. a question) on a web page. We further required the participant re-input the task description on the next web page to make sure he or she actually remember the search task. A er that, in stage IV. pre-task questionnaire we collected participants' expected di culty, interest, and prior domain knowledge level about the search task in 5-point Likert scales. en in stage V, the participant would use an experiment search engine to gather information to answer the question in the task description. e experiment search engine has a similar interface as a common commercial search engine, and the search results are crawled from Bing in real time when receive queries from the participants. We used a Chrome extension to log participants' querying, clicking, tab-switch, scrolling, and mouse movement actions during the search. To collect usefulness judgment, we instructed the participant to use a group of radio bu ons in the right-click menu, which is injected by the Chrome extension, to annotate useful documents in the search trail. e instruction and scale for the usefulness judgment are the following:
Is the document useful for the completion of your search tasks? If it is, please use the right-click menu to annotate the usefulness on the web page in the following scale.
1: not useful at all; 2: somewhat useful 3: fairly useful; 4: very useful
e default option is "1: not useful at all", so the participant only needed to annotate the documents that are at least "2: somewhat useful". A er completing the search task, in stage VI, the participant would answer the question in the task description and the answer would be logged by the experiment system. Finally, in stage VII, the participant would give feedbacks about the perceived
1 e search tasks were selected from our previous work[9].

I.  Pre--experiment Training
II. Eye--tracking Device  Calibration
III. Task Description Reading and Repeating
IV. Pre--task  Questionnaire
V.  Task  Completion  with  the  Experiment  Search  Engine  
VI. Question  Answering
VII.  Post--task  Questionnaire
Figure 1: e procedure of the user study.
di culty, interest, knowledge gain, and satisfaction level in a post-task questionnaire.
A er ltering the search sessions in which the eye-tracker malfunctioned, we collected dataset that contains 166 valid search sessions from 28 unique participants. A total of 1,383 documents were visited. Among these documents, 897 (64.86%) were not annotated or judged as "1: not useful at all", 184 (13.30%) as "2: somewhat useful", 172 (12.44%) as "3: fairly useful", and 130 (9.40%) as "4: very useful". e participant visited 2.93 useful documents (at least "2: somewhat useful") per session and the average usefulness judgment is 1.66.
3 FACTOR ANALYSIS ON USEFULNESS JUDGMENTS
In this section, we examine three groups of factors: content factors, context factors, and behavior factors and investigate their e ects on users' usefulness judgments to answer RQ1.
3.1 Content Factors
e content factors include the page contents' cosine similarities with the corresponding query (content cossim with query), task description (content cossim with task description), and answer (content cossim with answer ) as well as the Okapi BM25 score of the query-document pair (content bm25 with query). We also use the eye-tracking data to infer which term on the page is actually
xated by the participant. erefore, we further compute the cosine similarities and Okapi BM25 scores based on the xated page contents (denoted as x content).
We measure the e ect of each content factor on usefulness judgment by the Pearson's correlation coe cient r between the factor and usefulness judgment. From the results shown in Table 1 we can see that: 1) All the content factors have signi cantly positive e ects on usefulness judgments. 2) Among all the content factors, the cosine similarities with the answer submi ed by the participant have the strongest correlations with usefulness judgments, suggesting that usefulness judgments are largely determined by whether the information on the page is useful for the completion of the search task, which happens to be answering an question in our study. 3) Compare with page contents, the
xated contents have stronger correlations with usefulness judgments.
3.2 Context Factors
e search context is determined by the search task and previous user interactions in the search session. Previous studies show that

1170

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: E ects of content factors on usefulness judgment (*/**/*** indicates the correlation is statistically signi cant at p < 0.05/0.01/0.001)

Factors
content bm25 with query content cossim with answer content cossim with query content cossim with task description
x content bm25 with query x content cossim with answer x content cossim with query x content cossim with task description

Pearson's r
0.180 0.335 0.056 0.169 0.238 0.406 0.181 0.238

p
*** *** 0.038* *** *** *** *** ***

Table 2: E ects of context factors on usefulness judgment (*/**/*** indicates the correlation is statistically signi cant at p < 0.05/0.01/0.001)

Factors
avg cossim with previous page content max cossim with previous page content avg usefulness of previous page total usefulness of previous page max usefulness of previous page num previous doc num previous doc in query num previous query progress time in session task di culty task domain knowledge task interest

Pearson's r
0.020 -0.052 -0.024 -0.206 -0.161 -0.214 -0.163 -0.100 -0.159 -0.079 -0.025 0.082

p
0.467 0.052 0.378 *** *** *** *** *** *** *** 0.348 0.002**

the search context factors can explain why the usefulness judgment of a document is di erent from the relevance of it [3]. We extract context factors based on feedbacks in pre-task questionnaires and user's previous behavior in session and analyze their in uence on usefulness judgments.
We show the e ects of context factors in Table 2. From the results, we nd that the usefulness judgment tends to decrease as the search proceed. A number of context factors such as the number of previously visited documents (num previous doc), the sum of the usefulness judgments of previous documents (total usefulness of previous page), and the time spent in session (progress time in session) have negative correlations with usefulness. We further show the interaction between num previous doc and usefulness in Figure 2a. ese ndings suggest that the usefulness judgment measures the increment of useful information when visiting a document, which is likely to diminish as the progress of searching.
is diminishing return may be caused by the redundancy with previous documents. We use the cosine similarity with previously visited documents to capture the redundancy factor and investigate its relationship with usefulness judgments. A non-monotonous relationship between max cossim with previous page content and usefulness is spo ed. As shown in Figure 2b, the usefulness rst increase with the max cosine similarity and then decrease with it. When a document is not similar to any of previously visited documents, it is likely to be irrelevant to user's current information need. But if it is very similar to one of the visited documents, it will be redundant to the visited one thus not useful for the user.

Avg. Usefulness Avg. Usefulness

2.5

2.0

2.0

1.5

1.5 1.0
1.0

0.5

0.5

0.0 123456 nth bin

0.0 123456 nth bin

(a)

(b)

Figure 2: e e ect of two context factors: (a) the number of visited documents (num previous doc); (b) the max cosine similarity between current document and previous visited documents (max cossim with previous page content). To show these e ects, we put the documents into 6 bins with equal size according to the factor and compute average usefulness for each bin.

Table 3: E ects of user behavior factors on usefulness judgment (*/**/*** indicates the correlation is statistically significant at p < 0.05/0.01/0.001)

Factors
avg eye speed avg mouse movement speed
xation num mouse movement num page dwell time query length query time scroll num session time viewport coverage

Pearson's r
-0.109 -0.098 0.582 0.519 0.568 0.042 0.008 0.430 -0.095 0.144

p
*** *** *** *** *** 0.116 0.756 *** *** ***

3.3 Behavior Factors
We also inspect a variety of behavior factors that characterize user's actions on the document.
From the results in Table 3, we rst nd that, similar to the results reported in existing work [7, 8], the dwell time on page (page dwell time) is strongly correlated with usefulness. Because the user tends to stay longer on useful documents, other measures of user engagement such as the number of eye xations ( xation num), the number of mouse movements (mouse movement num), and the number of scrolling actions (scroll num) also show positive correlations with usefulness judgments. We also nd that the average moving speed of the eye
xation point and mouse cursor is negatively correlated with usefulness judgment. is con rms with Buscher et al. [4]'s
nding that users prefer skimming to reading when accessing irrelevant documents.

4 USEFULNESS PREDICTION
A er inspecting the e ects of content, context, and behavior factors on usefulness judgments, we try to utilize them as features to build prediction models for the user-perceived usefulness.
We adopt two experiment se ings for usefulness prediction: binary usefulness classi cation and usefulness regression. For binary usefulness classi cation, we build a classi cation model to predict a

1171

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 4: Results of usefulness prediction. */** indicates the di erence with the prediction result use all the features (All) is signi cant at p < 0.05/0.01.

content context behavior
content+context content+behavior context+behavior
All

Binary Usefulness Classi cation

AUC

Accuracy

F1

0.753±0.012** 0.698±0.006** 0.545±0.019** 0.718±0.014** 0.682±0.006** 0.494±0.022** 0.905±0.008 0.833±0.004* 0.764±0.014*

0.782±0.012** 0.722±0.006** 0.574±0.019** 0.904±0.008* 0.836±0.004* 0.770±0.014** 0.905±0.008 0.834±0.004 0.763±0.015*

0.909±0.008 0.848±0.003 0.785±0.015

Usefulness Regression

Pearson's r MSE

MAE

0.431±0.024** 0.845±0.031** 0.703±0.015** 0.299±0.026** 0.947±0.038** 0.779±0.017** 0.679±0.020* 0.559±0.026* 0.493±0.015

0.451±0.024** 0.827±0.031** 0.679±0.016** 0.686±0.020* 0.549±0.025* 0.489±0.015 0.692±0.019 0.541±0.024 0.498±0.014

0.694±0.019 0.537±0.024 0.494±0.014

binary variable indicating whether a document is useful or not for the user and use Area-Under-Curve of ROC (AUC), accuracy, and the F1 score for the useful documents to evaluate its performance. Because 64.86% documents are "1: not useful at all", we use them as negative samples (not-useful documents) and other documents that are at least "2: somewhat useful" as positive samples (useful document). For usefulness regression, we build a regression model to predict the actual usefulness judgment scale (a real number ranging from 1 to 4). e evaluation metrics adopted are Pearson's r , Mean Squared Error (MSE), and Mean Absolute Error (MAE).
We adopt Gradient Boosting Tree [5] model in both binary usefulness classi cation and usefulness regression se ings because it can handle heterogeneous features and has a good prediction power.
e results of prediction performance with di erent feature combinations are shown in Table 4. All the evaluation metrics were computed using a 10-fold cross-validation over sessions. From the results we can see that: 1) Using all the features, the Gradient Boosting Tree can e ectively estimate usefulness judgment. e AUC in binary usefulness classi cation reaches 0.909 and the Pearson's r in usefulness regression is 0.694. 2) e behavior features are the most informative features in usefulness prediction. Using only the behavior features, the model can achieve an AUC of 0.905 and a Pearson's r of 0.679. Adding content and context features only slightly improves the prediction performance. 3) Given the content and context features, we can predict usefulness to a moderate extent with an AUC of 0.782 and a Pearson's r of 0.451. Because most of the content and context features can be computed before the user visits the page, this usefulness prediction can be used to identify the documents that are likely to be useful in the current search context.
5 CONCLUSIONS AND DISCUSSIONS
With the dataset collected in a user study, we investigate the e ects of various content, context, and behavior factors on users' usefulness judgments during the search (RQ1), and further use these factors as features to build e ective prediction models for usefulness judgments (RQ2). Our ndings not only enriches the understanding on the dynamic, situational usefulness judgments but also provide some implications for the evaluation and design of Web search engines. For example, the ndings in section 3.1 suggest that, in a user study, we can use the similarity between page contents and submi ed answers to infer usefulness judgments and use them to evaluate the search performance

without explicit feedbacks from users. e ndings in section 3.2 suggest that, in order to avoid returning irrelevant or redundant results to users, the search system should return results that are moderately similar to previously visited documents. And the results of usefulness prediction suggest that: 1) With the behavior features in search logs, we can accurately infer the usefulness judgments. ese judgments can be used as o ine ranking signals and evaluation measures for the system. 2) With the content and context features that can be obtained before the user actually clicks the document, we can predict the usefulness judgment to provide contextualize result ranking for the user.
ACKNOWLEDGMENTS
is work was supported by Natural Science Foundation of China (Grant No. 61622208, 61532011, 61672311), Tsinghua University Initiative Scienti c Research Program(2014Z21032), National Key Basic Research Program (2015CB358700).
REFERENCES
[1] Nicholas J Belkin. 2015. Salton award lecture: people, interacting with information. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 1­2.
[2] Nicholas J Belkin, Michael Cole, and Jingjing Liu. 2009. A model for evaluation of interactive information retrieval. In Proceedings of the SIGIR 2009 Workshop on the Future of IR Evaluation. 7­8.
[3] Alexey Borisov, Ilya Markov, Maarten de Rijke, and Pavel Serdyukov. 2016. A context-aware time model for web search. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 205­214.
[4] Georg Buscher, Andreas Dengel, and Ludger van Elst. 2008. Eye movements as implicit relevance feedback. In CHI'08 extended abstracts on Human factors in computing systems. ACM, 2991­2996.
[5] Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics (2001), 1189­1232.
[6] Jiepu Jiang, Daqing He, Diane Kelly, and James Allan. 2017. Understanding Ephemeral State of Relevance. In CHIIR'17.
[7] Jin Young Kim, Jaime Teevan, and Nick Craswell. 2016. Explicit In Situ User Feedback for Web Search Results. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '16). ACM, New York, NY, USA, 829­832. DOI:h p://dx.doi.org/10.1145/2911451. 2914754
[8] Youngho Kim, Ahmed Hassan, Ryen W White, and Imed Zitouni. 2014. Modeling dwell time to predict click-level satisfaction. In Proceedings of the 7th ACM international conference on Web search and data mining. ACM, 193­202.
[9] Xin Li, Yiqun Liu, Rongjie Cai, and Shaoping Ma. 2017. Investigation of User Search Behavior While Facing Heterogeneous Search Services. In WSDM'17. ACM, 161­170.
[10] Jiaxin Mao, Yiqun Liu, Ke Zhou, Jian-Yun Nie, Jingtao Song, Min Zhang, Shaoping Ma, Jiashen Sun, and Hengliang Luo. 2016. When Does Relevance Mean Usefulness and User Satisfaction in Web Search?. In SIGIR'16. ACM, 463­472.

1172

