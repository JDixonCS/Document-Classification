Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Entity Set Expansion via Knowledge Graphs

Xiangling Zhang
Renmin University of China Beijing, China
zhangxiangling@ruc.edu.cn

Yueguo Chen
Renmin University of China Beijing, China
chenyueguo@ruc.edu.cn

Jun Chen
Renmin University of China Beijing, China
chenjun2013@ruc.edu.cn

Xiaoyong Du
Renmin University of China Beijing, China
duyong@ruc.edu.cn

Ke Wang
Simon Fraser University Burnaby, Canada wangk@cs.sfu.ca

Ji-Rong Wen
Renmin University of China Beijing, China
jrwen@ruc.edu.cn

ABSTRACT
e entity set expansion problem is to expand a small set of seed entities to a more complete set of similar entities. It can be applied in applications such as web search, item recommendation and query expansion. Traditionally, people solve this problem by exploiting the co-occurrence of entities within web pages, where latent semantic correlation among seed entities cannot be revealed. We propose a novel approach to solve the problem using knowledge graphs, by considering the de ciency (e.g., incompleteness) of knowledge graphs. We design an e ective ranking model based on the semantic features of seeds to retrieve the candidate entities. Extensive experiments on public datasets show that the proposed solution signi cantly outperforms the state-of-the-art techniques.
KEYWORDS
Knowledge Graph; Entity Set Expansion; Entity Search
1 INTRODUCTION
e entity set expansion (ESE) problem is to nd similar entities to a given small set of seed entities. For example, given the seed entities Barack Obama, ohn Kenned and Franklin Roose elt, we may expect to nd entities such as Bill Clinton and imm Carter because they are all US presidents from the Democratic Party. It can be widely used in many applications such as web search (search by examples), item recommendation and query expansion [10].
Traditionally, people solve this problem using a web corpus (e.g., SEAL [9] and BBR [2]), by evaluating the similarities between candidate entities and the seeds based on their surrounding contexts within the corpus. Entities that co-occur more frequently with the seeds are likely to have higher similarities. Unfortunately, these methods are time-consuming since both web crawling and entity extraction are costly. Moreover, common features shared by the seeds cannot be revealed by these methods. ere have been a number of path-based similarity measures [7, 8] to evaluate the
Yueguo Chen is the corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07­11, 2017, Shinjuku, Tokyo, Japan. © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080732

similarity between a pair of entities in knowledge graphs (KGs) which can be adopted to solve the ESE problem. Metzger et al. [6] propose a solution to ESE called QBEES based on the common features shared by the seeds. It however ignores the de ciency (incompleteness) of the KGs which a ects the precision. e association rule mining (ARM) algorithm [1] can also be adapted to solve the ESE problem. However, it lacks of an e ective ranking model, which cannot distinguish the importance of the common features shared among seeds.
Knowledge graphs such as DBpedia and Freebase are widely used in the elds of web search and question answering. e facts in KGs are typically represented by triples (< s, p, o >) describing the properties of the subjects as well as the relations among entities. We utilize p- to represent the inverse relation of the predicate p.
e whole KGs can be represented as directed and labeled graphs. Figure 1 shows an example of a KG. Although huge, exsting KGs are still incomplete. For example, 71% of people in Freebase lack place of birth information [4].

Steve_Starkey

Gary_Sinise

Brian_Grazer

Ron_Howard Jonathan_Demme

producer producer starring

producer director

director

Contact

Forrest_Gump

Apollo_13_(film)

Philadelphia_(film) producer

director director

starring starring subject

Robert_Zemeckis

subject

starring Tom_Hanks

subject subject

Edward_Saxon type type type

American_films

Film

Films_directed_by _Robert_Zemeckis

director

starring

subject

subject Cast_Away

producer

type Jack_Rapke

Figure 1: A running example, where a dashed triple < Apollo 13 (f ilm), starrin ,Tom Hanks > is missed.

In this paper, We propose a ranking model to e ectively evaluate the similarity of entities to a small number of given seeds, according to the semantic correlations (called k-relaxed common semantic features) among entities in knowledge graphs. e model is designed to handle the incompleteness of knowledge graphs. We use an example of Figure 1 to give a quick view of the idea. Suppose the user's intention is Tom Hanks movies where he plays a leading role and he issues a query of three seeds, Forrest Gump, Apollo 13 (f ilm), and Philadelphia (f ilm). We may nd that two seeds have the same predicate starrin to the same entity Tom Hanks, which implies that Tom Hanks played a role in them. We therefore can apply the label starrin and the entity Tom Hanks as a 1-relaxed common

1101

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

feature among the given seeds. Based on this common feature, we can nd some other entities (e.g. Cast Awa ) sharing the same common feature as the majority of the seeds, and it therefore can be applied for ranking candidate entities.
2 COMMON SEMMANTIC FEATURE
De nition 2.1 (Semantic Feature). A semantic feature  = ea : P in a KG K is composed of an anchor entity ea , and a sequence of labels P = l1/l2/. . . /ln .
A semantic feature (SF) is used to represent a common feature shared by a set of target entities. For example, to describe the movies where Tom Hanks played a role, we can apply the SF 1=Tom Hanks:starrin -. For another example, if we want to de-
ne people who directed movies where Tom Hanks played a role, the SF can then be wri en as: 2=Tom Hanks:starrin -/director , which has two predicates to de ne the relation. e length of a SF is the number of labels (predicates) in P. It can be larger than one when P is a tandem of several predicates (e.g., 2), although the cases of length one (a direct relation) are used more o en.
If an entity e has a relation P with the anchor entity ea , we say that e is a target entity of  =ea :P, which is denoted as e |=  . e set of target entities of a SF  =ea :P is denoted as E( ) = {e |e |=  }. For a given set of seed entities, we may nd some SFs whose target entities contain all those seed entities. ey are de ned as the common semantic features (shorted as CSFs) of the seeds. We use (Q) to denote the set of CSFs for the seeds in a query Q. For example, for the seed entity set {Forrest Gump, Apollo 13 (f ilm), Philadelphia (f ilm)}, SFs 3=Film:t pe- and 4= American f ilms:subject- are their CSFs.
To overcome the de ciency of KGs, we relax the de nition of CSFs as follows.
De nition 2.2 (k-relaxed CSF). A semantic feature  is a k-relaxed CSF to a set of m entities in Q, if |E( )  Q |  m - k.
A k-relaxed CSF  requires that at least m -k entities of the seeds are target entities of  , i.e., |E( )  Q |  m - k. We use k-CSF to denote a k-relaxed CSF, and k (Q) to represent the set of k-relaxed CSFs of the seed set Q. To solve the ESE problem using KGs, we need to follow two steps to rank entities based on the proposed CSF: 1) compute the set of CSFs (~ (Q)) according to the given query Q; 2) retrieve and rank the candidate entities (target entities excluding the seeds) satisfying the detected CSFs in ~ (Q).
As discussed above, due to the limits of the coverage of KGs, there may be a very small number (or even not any) of CSFs (of length one) shared by all the seeds in Q, we therefore apply the relaxation of CSFs by allowing some seeds not satisfying the CSFs. Moreover, the length of CSFs can be extended to be larger than one, so as to include more CSFs indicating indirect common features. However, the relaxation and extension of CSFs will of course generate more false positives of common features that may not be desired by the user. In addition, more CSFs will reduce the search performance as well. e selection of CSFs for ranking entities, therefore has to be carefully designed.
Let hk (Q) be the set of k-CSFs of Q whose length is no more than h, where k  0 and h  1. In our solution, we apply the union of two sets for ranking entities, i.e., ~ (Q) = k1 (Q) h0 (Q), where k1 (Q) includes k-CSFs of length one, and h0 (Q) includes

CSFs whose length is extended up to h. However, those CSFs longer than one will not be relaxed to avoid generating too many false positive CSFs.

3 RANKING MODEL
e ranking model of entities is designed as follows:

r (e) =

d( )  r ( , Q)

(1)

 ~ (Q )  e |=

It is basically an aggregation of the score of each CSF   ~ (Q) that e satis es, which is further evaluated as the product of two components d( ), and r ( , Q), where d( ) is the discriminability of  , and r ( , Q) is the relevance of  to Q.

3.1 Discriminability of CSFs

It is likely that many CSFs can be found from KGs, although only some of them are useful for nding similar entities of seeds. For example, to characterize the seeds, 1 is more speci c than 3 because |E(1)| |E(3)|. We therefore need a measure to evaluate the discriminability of CSFs on nding similar entities. Intuitively, the discriminability of  is then de ned as:

d( )

=

1 |E( )|

(2)

Larger |E( )| means that entities in E( ) are more loosely correlated in terms of the constraint of  . It therefore has a smaller discriminability of the relevant entities.

3.2 Relevance of CSFs
e relevance of a CSF  to the query Q, is evaluated as:

r ( , Q) = p(e,  )

(3)

e Q

where p(e,  ) is the probability of e satisfying  . For e |=  , p(e,  ) is naturally evaluated as 1. However, for a relaxed k-CSF, there can be at most k seeds that do not satisfy  , which may be caused by the de ciency of the KGs. We therefore need to evaluate p(e,  ) for those seeds that do not satisfy  . Borrowing the idea of collaborative ltering in recommendation systems, we evaluate p(e,  ) by considering the likelihood of e satisfying similar CSFs of  .

  p(e,  ) =    

1
 ( ) I (e,  )w ( ,  )  ( ) w ( ,  )

if e |=  otherwise

where I (e,  ) = 1 if e |=  , otherwise I (e,  ) = 0; w( ,  ) =

|E( )E( |E( )|

)

|

,

which

determines

the weight of 

;

( )

=

{

|

=

ea : Px } { | = ex : P } with  = ea : P and the length of Px is one. Obviously, the set of similar CSFs of  , ( ), is derived by

substituting the anchor entity (from ea to any other ex ) or the path (from P to any other Px of length one) of  = ea : P respectively.

4 EXPERIMENTS
e DBpedia v3.9 is applied as the KGs of our experiments. Two test datasets are used in our study. QALD [5], the estion Answering over Linked Data campaign, aims to answer natural language questions using linked data sources. A er removing the redundant

1102

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: Comparison on the QALD dataset

solution seeds p@5 p@10 p@20 MRR R-pre

SEAL 2 .377 .290 .208 .550 .269

BBR

2 .340 .305 .245 .446 .263

LDSD 2 .147 .122 .100 .264 .113

QBEES 2 .507 .400 .320 .654 .369

ARM

2 .503 .422 .322 .662 .377

ESER SEAL

2 .547· .460· .372· .699· .457· 3 .453 .363 .267 .591 .340

BBR

3 .393 .335 .276 .505 .298

LDSD 3 .170 .143 .127 .270 .131

QBEES 3 .557 .440 .362 .688 .423

ARM ESER SEAL

3 .550 .468 .372 .665 .446 3 .613· .498· .387· .773· .501·
4 .420 .350 .270 .539 .354

BBR

4 .363 .312 .270 .526 .302

LDSD 4 .197 .163 .138 .308 .153

QBEES 4 .557 .453 .362 .668 .452

ARM ESER SEAL

4 .527 .430 .348 .716 .420 4 .613· .502· .392· .801· .525·
5 .410 .317 .247 .535 .352

BBR

5 .350 .323 .273 .515 .304

LDSD 5 .173 .145 .127 .282 .153

QBEES 5 .520 .428 .348 .638 .449

ARM ESER SEAL

5 .503 .418 .342 .665 .426 5 .563· .465· .381· .726· .515·
mix .447 .347 .249 .592 .335

BBR mix .373 .328 .262 .477 .298

LDSD mix .183 .155 .137 .292 .141

QBEES mix .517 .408 .328 .626 .412

ARM ESER

mix .537 .443 .337 .646 .433 mix .633· .510· .403· .799· .559·

topics, we get a dataset of 60 topics from QALD-2, QALD-3 and QALD-4. In INEX-XER 2009 (shorted as INEX with 55 topics) [3], a topic contains a natural language question asking for a list of entities. In addition, it also provides several seed entities as the examples of the desired entities. We use the label ESER (for testID) to indicate that the test is under the default se ing. All signi cant tests are conducted using a one-tailed t-test at a signi cance level of p = 0.05.

4.1 An Overall Comparison
We rst test the performance of the compared solutions using 5 groups of di erent numbers of seeds. Note that the mix group contains topics whose numbers of seeds are between 2 to 5. In general, LDSD [7] performs worse than the others on both datasets, which shows that a simple semantic distance approach on entities of KGs is far from judging e ective semantic correlations among entities. Generally, ESER performs the best on almost all the test cases, with two exceptions beaten by SEAL [9] on the INEX dataset when the query contains only 2 or 3 seeds. SEAL bene ts a lot from the usage of Google search engine. e way of using frequent item sets on predicate-object pairs serves the purpose of nding common features of seeds. However, the lack of an e ective ranking model causes that ARM [1] performs worse than ESER. e notation  denotes signi cant di erence over ARM, the notation · denotes signi cant di erence over QBEES [6] in Table 1, and the notation
denotes signi cant di erence over SEAL in Table 2.

Table 2: Comparison on the INEX dataset

solution seeds p@5 p@10 p@20 MRR R-pre

SEAL

2 .412 .388 .331 .542 .327

BBR

2 .304 .248 .213 .418 .209

LDSD 2 .219 .200 .153 .461 .166

QBEES 2 .392 .338 .288 .556 .282

ARM

2

.319 .287 .231 .496 .244

ESER

2 .400 .383 .287 .551 .304

SEAL

3 .462 .433 .354 .547 .377

BBR

3 .292 .246 .211 .470 .208

LDSD 3 .227 .210 .172 .401 .184

QBEES 3 .362 .317 .255 .532 .256

ARM

3

.281 .260 .216 .435 .224

ESER SEAL

3 .500 .415 .311 .684 .340 4 .423 .383 .319 .530 .339

BBR

4 .277 .235 .210 .447 .213

LDSD 4 .246 .235 .176 .408 .179

QBEES 4 .362 .312 .234 .451 .229

ARM

4

.292 .256 .216 .493 .222

ESER SEAL

4 .504 .446 .341 .633 .376 5 .377 .340 .284 .418 .311

BBR

5 .300 .250 .208 .530 .219

LDSD 5 .300 .292 .203 .535 .208

QBEES 5 .246 .215 .169 .342 .169

ARM

5

.315 .267 .211 .484 .239

ESER SEAL

5 .492 .433 .336 .629 .381 mix .473 .398 .305 .644 .330

BBR mix .323 .277 .221 .504 .251

LDSD mix .262 .227 .164 .496 .204

QBEES mix .423 .371 .276 .591 .299

ARM mix .350 .304 .239 .535 .273

ESER mix .515 .440 .350 .701 .409

When looking into the impact of the number of seeds m on the performance of the di erent solutions, we nd that most solutions perform worst when m = 2, which means that there are not enough seeds to distinguish the common features shared among the seeds. When m is enlarged from 2 to 5, the performance of SEAL and ESER basically increases. However, the growth rate is not signi cant when m > 3. For ESER, it bene ts more from the enlargement of m on the INEX dataset than on the QALD dataset. is is reasonable because more seeds help ESER to discover more CSFs in the INEX dataset which are more implicit than those in QALD.

4.2 E ectiveness of e Ranking Model
Two components of ESER a ect the performance of its ranking model: d( ) and r ( , Q). is experiment is designed to look into the performance of individual components by varying the overall ranking model. When a component is not applied in the ranking model, we simply set it 1. e results of the tests on two datasets are shown in Table 3 and Table 4 respectively. We apply 4 variations of the 2 components, with none of them applied as the baseline (in this case, candidate entities are ranked simply based on the number of kCSFs they satisfy). Note that this experiment is conducted over the mix of QALD and the mix of INEX datasets individually. e results show that the 2 individual components can improve the search performance over the baseline approach (the rst row of the two tables). e best performance is achieved when both components are applied (ESER), which is exactly the proposed ranking model.

1103

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 3: Alternative ranking models on the QALD

testID d ( ) r (, Q ) p@5 p@10 p@20 MRR R-pre

q1

1

1 .493 .403 .326 .695 .399

q2 Eqn. 2 1 .560 .452 .359 .739 .453

q3

1 Eqn. 3 .550 .442 .350 .771 .462

ESER Eqn. 2 Eqn. 3 .633 .510 .403 .799 .559

Table 5: Strategies of picking CSFs on QALD

testID

~ (Q )

p@5 p@10 p@20 MRR R-pre

q5 q6 q7 q8 q9 q10 q11 q12 q13 q14 ESER q16 q17 q18

01(Q ) 11(Q ) 21(Q ) 31(Q ) 01(Q ) 02(Q ) 11(Q ) 02(Q ) 11(Q ) 12(Q ) 21(Q ) 02(Q ) 21(Q ) 12(Q ) 21(Q ) 22(Q ) 31(Q ) 02(Q ) 31(Q ) 12(Q ) 31(Q ) 22(Q ) 31(Q ) 32(Q )

.560 .593 .613 .623 .583 .607 .640 .623 .640 .643 .633 .647 .650 .657

.462 .478 .490 .493 .482 .498 .520 .507 .515 .518 .510 .517 .520 .523

.371 .383 .384 .386 .394 .401 .418 .402 .408 .408 .403 .410 .410 .412

.663 .719 .769 .783 .714 .739 .789 .786 .801 .793 .799 .812 .804 .812

.498 .525 .534 .537 .527 .549 .548 .556 .553 .547 .559 .556 .551 .552

4.3 Impacts of Selecting CSFs
ESER has two parameters that determine the set ~ (Q) of CSFs used for retrieving and ranking entities, and therefore a ect the search performance. One is the parameter k used in discovering k-CSFs. e other is the parameter h used for constraining the length of CSFs. In this experiment, we test the impacts of these two parameters using the mix of QALD and the mix of INEX. e results are shown in Table 5 and Table 6. e signi cant tests are compared with the baselines (q5 and i5) where k = 0 and h = 1. For q5q8 and i5i8, we set h = 1, and enlarge k from 0 to 3. According to the results, the performance basically increases when k is enlarged, showing the e ectiveness of k-relax CSFs for picking CSFs when the length of CSFs is limited to one.
When studying the impacts of relaxing 2-hop CSFs, we nd that it may slightly reduce the search performance (e.g., q13 and q14 v.s. q12) on the QALD dataset. However, for INEX dataset, a small relaxation (k = 1) of 2-hop CSFs is helpful. is is also because INEX has a lower mapping quality and the relaxation does help to retrieve more CSFs. Considering that the relaxation of 2-hop CSFs o en incurs more false positive CSFs, and therefore drops the search performance, we apply 31(Q) 02(Q) as the default se ing of ~ (Q) for picking CSFs.

5 CONCLUSIONS
In this paper, we address the problem of entity set expansion by using KGs. We propose a concept called common semantic feature, to describe the common features shared by the seed entities, as the basis of discovering and ranking candidate entities. rough extensive experimental studies, we nd that the proposed solution is very suitable for ESE topics which have good coverage of entities and predicates (relations) in the KGs. Even for those topics that do not have good information coverage in KGs, our noise-resistant

Table 4: Alternative ranking models on the INEX

testID d ( ) r (, Q ) p@5 p@10 p@20 MRR R-pre

i1

1

1 .435 .350 .271 .661 .309

i2 Eqn. 2 1 .454 .410 .313 .689 .362

i3

1 Eqn. 3 .496 .427 .319 .725 .365

ESER Eqn. 2 Eqn. 3 .515 .440 .350 .701 .409

Table 6: Strategies of picking CSFs on INEX

testID

~ (Q )

p@5 p@10 p@20 MRR R-pre

i5 i6 i7 i8 i9 i10 i11 i12 i13 i14 ESER i16 i17 i18

01(Q ) 11(Q ) 21(Q ) 31(Q ) 01(Q ) 02(Q ) 11(Q ) 02(Q ) 11(Q ) 12(Q ) 21(Q ) 02(Q ) 21(Q ) 12(Q ) 21(Q ) 22(Q ) 31(Q ) 02(Q ) 31(Q ) 12(Q ) 31(Q ) 22(Q ) 31(Q ) 32(Q )

.458 .500 .492 .512 .485 .519 .538 .508 .527 .519 .515 .531 .519 .527

.392 .433 .429 .448 .412 .442 .473 .437 .469 .469 .440 .471 .469 .471

.299 .328 .332 .344 .324 .347 .345 .350 .349 .347 .350 .349 .347 .346

.578 .672 .697 .717 .611 .675 .696 .701 .721 .720 .701 .721 .720 .720

.349 .387 .390 .396 .381 .408 .418 .409 .421 .418 .409 .421 .418 .416

solution may also work by discovering some common semantic features shared by the seeds.

6 ACKNOWLEDGMENTS
is work is supported by the National Science Foundation of China under grant (No. 61472426 and 61432006), 863 key project under grant No. 2015AA015307, the open research program of State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Science (No. CARCH201510), the ECNU-RUC-InfoSys Joint Data Science Lab, and a gi from Tencent.

REFERENCES
[1] Ziawasch Abedjan and Felix Naumann. 2013. Improving RDF Data rough Association Rule Mining. Datenbank-Spektrum 13, 2 (2013), 111­120.
[2] Krisztian Balog, Marc Bron, and Maarten de Rijke. 2011. ery modeling for entity search based on terms, categories, and examples. ACM Trans. Inf. Syst. 29, 4 (2011), 22.
[3] Gianluca Demartini, Tereza Iofciu, and Arjen P. de Vries. 2009. Overview of the INEX 2009 Entity Ranking Track. In INEX. 254­264.
[4] Xin Dong and Evgeniy Gabrilovich et al. 2014. Knowledge vault: a web-scale approach to probabilistic knowledge fusion. In KDD '14, New York, USA, August 24-27, 2014. 601­610.
[5] Vanessa Lopez, Christina Unger, Philipp Cimiano, and Enrico Mo a. 2013. Evaluating question answering over linked data. J. Web Sem. 21 (2013), 3­13.
[6] Ste en Metzger, Ralf Schenkel, and Marcin Sydow. 2014. Aspect-Based Similar Entity Search in Semantic Knowledge Graphs with Diversity-Awareness and Relaxation. In WI and IAT. 60­69.
[7] Alexandre Passant. 2010. dbrec - Music Recommendations Using DBpedia. In ISWC. 209­224.
[8] Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and Tianyi Wu. 2011. PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks. PVLDB 4, 11 (2011), 992­1003.
[9] Richard C. Wang and William W. Cohen. 2009. Automatic Set Instance Extraction using the Web. In ACL. 441­449.
[10] Jinxi Xu and W. Bruce Cro . 1996. ery Expansion Using Local and Global Document Analysis. In SIGIR 1996. 4­11.

1104

