Demonstration Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

ASTERIX: Ambiguity and Missing Element-Aware XML Keyword Search Engine

Ba Quan Truong
Nanyang Technological University Singapore
bqtruong@ntu.edu.sg

Curtis Dyreson
Utah State University USA
curtis.dyreson@usu.edu

ABSTRACT

Despite a decade of research on keyword search ( ), demon-

stration of a high quality system has still eluded the infor-

mation retrieval community. Existing engines primarily suf-

fer from two limitations. First, although the smallest lowest com-

mon ancestor ( ) algorithm (or a variant, e.g., ) is widely

accepted as a meaningful way to identify subtrees containing the

query keywords, typically performs poorly on documents with

missing elements, i.e., (sub)elements that are optional, or appear in

some instances of an element type but not all. Second, since key-

word search can be ambiguous with multiple possible interpreta-

tions, it is desirable for an engine to automatically expand the

original query by providing a classi cation of di erent possible in-

terpretations of the query w.r.t. the original results. However, exist-

ing systems do not support such result-based query expansion.

We demonstrate

, an innovative engine that addresses

these limitations.

1 INTRODUCTION
The lack of expressivity and inherent ambiguity of keyword search ( ) bring in three key challenges in building a superior
engine. First, we need to automatically connect the nodes that match the search keywords in an intuitive, meaningful way. In this context, the notion of smallest lowest common ancestor ( ) [12] is arguably the most popular strategy to address this challenge and has become the building block of many keyword search approaches [2, 7, 8]. A keyword search using the semantics returns nodes in the tree such that each node in the result satis-
es the following two conditions: (a) the subtree rooted at a node contains all of the keywords, and (b) no proper descendant of the node satis es condition (a). The set of returned nodes is referred to as the s of the keyword search query. The second challenge deals with e ective identi cation of the desired return information.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 Association for Computing Machinery. ACM ISBN 978-1-4503-5022-8/17/08. . . $15.00. http://dx.doi.org/10.1145/3077136.3084137

Sourav S Bhowmick
Nanyang Technological University Singapore
assourav@ntu.edu.sg
Hong Jing Khok
Nanyang Technological University Singapore
hjkhok1@e.ntu.edu.sg
Speci cally, it focuses on ltering nodes within these matching subtrees to produce relevant and coherent results. There have been several research e orts toward addressing this challenge [2, 7, 8] such as ltering irrelevant matches under an node by returning only contributors [8]. The third challenge is ranking [2, 6] or clustering [5] these relevant result subtrees according to certain criteria and returning them.
The aforementioned challenges have inspired a large body of research on [2, 7, 8, 12]. Several systems have also been demonstrated in major venues [1, 6]. Hence, at rst glance one may question the need for yet another demonstration. In this paper, we justify the need for such a demonstration by advocating that a high quality system has still eluded the information retrieval research community after all these years!
Despite the admirable e orts of state-of-the-art techniques, they su er from two key drawbacks. First, as shown in our previous work [11], techniques based on and its variants (e.g.,
) perform poorly in the presence of the missing element phenomenon. Due to the "relaxed" structure of data, a subelement may appear in one nested substructure of an document but be missing in another "similar" substructure. Note that in many real-world documents more than 40% of the element labels are missing labels [11]. Hence, it is highly possible for users' searches to involve missing elements. For example, the area element in the
document D1 in Figure 1(a) appears in the rst city substructure but is missing in the last two substructures. A keyword query that contains the label of a missing element lowers the quality of
nodes. For example, consider the query Q1(Provo area) on D1. The node with 0.4 (for brevity, we will use nid to denote a node with id) is selected as the node by [12]. However, n0.4.1 is not a relevant match as it is not Provo's area.
Second, a keyword query can be ambiguous with multiple possible interpretations or be exploratory in nature where the user does not have a speci c search target but would like to navigate among possible relevant answers. For example, the results of a query Q2(alaska) may contain subtrees having multiple interpretations such as the country Alaska and the Alaskan range mountains. Hence, an engine that can automatically expand the original query (e.g., Q2) by providing a classi cation of di erent possible interpretation of the query w.r.t the original result set is desirable. For the above example, Q2 can be expanded to Q2a (alaska,

1317

Demonstration Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

³86$´ 0.0

country 0

D1

name territory

state 0.2

0.1

name area name area name ³*XDP´ ³541´ ³7HQQHVVHH´³109,247´ ³7H[DV´
0.1.0 0.1.1 0.2.0 0.2.1 0.3.0

name ³+RXVWRQ´
0.3.1.0

state 0.3

state 0.4

city 0.3.1

name area

city

³8WDK´ ³219,887´

0.4.0 0.4.1 0.4.2

city 0.4.3

population area

name population name population

³215,146´ ³1,558´ ³6DOW/DNH&LW\´ ³189,899´ ³3URYR´ ³113,000´

0.3.1.1 0.3.1.2

0.4.2.0 0.4.2.1 0.4.3.0 0.4.3.1

(a) XML document

country

name

territory

state

name

area

name

area

city

name

population

area

(b) DataGuide

ASTERIX GUI

Online
FSLCA Computation

Result Subtrees Generator
Heuristic-based Selector

Resultbased Query Expansion

Indexer Offline

DataGuide Generator

Synopsis Graph Builder

XML Repository

(c) ASTERIX architecture

Figure 1: (a) Sample documents D1, (b) its DataGuide, and (c) the architecture of

.

Figure 2: The

GUI.

country) and Q2b (alaska, mountain) that classi es the original result set into two key clusters containing information related

to Alaska and the Alaskan range, respectively. Observe that such

result-based query expansion can guide users to focus on the rele-

vant subset of the original query results when a speci c expanded

query is chosen. Unfortunately, existing systems do not pro-

vide e ective techniques for such result-based query expansion.

In this demonstration, we present a novel system called

(Ambiguity and miSsing elemenT-aware kEyword seaRch

In XML) to address the above limitations.

has two novel

features. First, it produces high-quality nodes, which are iden-

tical to nodes produced by any other -based tech-

nique when the query does not contain missing elements or la-

bels but unlike these existing techniques, avoids irrelevant results

when missing elements are involved. Second, it supports result-

based query expansion that lets users navigate within multiple pos-

sible interpretations of the result set.

2 SYSTEM ARCHITECTURE

Figure 1(c) shows the system architecture of

. We model an

document D as an ordered and node-labeled tree. Each node

n  D is assigned a Dewey number as its identi er (e.g., Figure 1(a))

and is associated with a label (i.e., tag) and text value (if any). Each

node n has a type de ned by its pre x path. The Repository

stores the

les in the disk. The Indexer module traverses D to

generate an inverted list of the keywords and a path index to sup-

port e cient evaluation of keyword search. The DataGuide Gener-

ator module constructs the DataGuide [4] of D. The Synopsis Graph

Builder module uses the DataGuide to build a synopsis graph of D.

Note that these three modules are executed o ine as the outputs

remain invariant unless the document is modi ed. Given a key-

word query Q on D, the

Computation module implements

the two variants of the

algorithm, namely

and

[11], to nd full

( ) nodes in D. Speci cally,

these nodes enable an engine to handle missing elements. The

Heuristic-based Selector module leverages the synopsis graph to fa-

cilitate automatic selection of the correct variant of

for

processing Q without any user intervention. The Result Subtrees

Generator module leverages these

nodes to extract a set of

result subtrees in D that match the query and ranks them. The

Result-based Query Expansion module takes the result subtrees as

input and generates the top-k expanded queries to provide multi-

ple interpretations of the original query (if any). We now elaborate

on these modules.

The GUI Module. Figure 2 depicts the screenshot of

. A user begins formulating a query by choosing an docu-

ment as the query target. Panel 1 allows her to upload a new

document or retrieve an existing document. The left panel

(Panel 2) displays the DataGuide of the target document. Panel

3 depicts the area for formulating keyword queries and to view

the expanded queries based on the original result set. Panel 4 al-

lows a user to choose di erent variants of

. By default,

automatically chooses the correct variant of

by

invoking the Heuristic-based Selector module. However, for demon-

stration purpose we also provide an option to switch to "manual"

mode (by selecting the manual radio button) and choose either the

or

variant from the dropdown list before exe-

cuting the query. Note that Panel 4 is disabled in "live" applications

as the correct variant is chosen automatically. Panel 5 allows us to

choose the query expansion strategy i.e., whether the keywords

added to the original query is selected only from element labels in

the result set or from both element labels and text values. Panel 6

displays the query results.

The DataGuide Generator Module. Given D, this module ex-

tracts its DataGuide in linear time by employing [4]. A DataGuide S

is a pre x tree representing all unique paths in D i.e., each unique

path p in D is represented in S by a node (referred to as schema

node) whose root-to-node path is p. Hence, each schema node in

S corresponds to a type and the hierarchical relationship among

schema nodes represents type relations (e.g., descendant or child

type). For example, Figure 1(b) depicts the DataGuide of document

D1 in which tcit is a descendant (or child) type of tstate . The Indexer Module. This module generates two types of in-

dexes on an document D. (a) An Inverted List where each key-

word is mapped to a list of matches sorted by document order. The

list of matches is also partitioned into two sublists corresponding

1318

Demonstration Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

to value matches and type matches of the keyword. (b) A path index

where each root-to-node path p in the DataGuide tree is mapped

to a list of nodes of path p in D. Each index is a B-tree. In addition,

it generates several statistics of D (e.g., keyword frequency).

The Synopsis Graph Builder Module. This module generates

a synopsis graph of D, which shall be exploited by the Heuristic-

based Selector module (discussed later). The synopsis graph G is a

lightweight version of the XSketch-index [10], which is a directed

acyclic graph synopsis where each synopsis node represents a set

of data nodes with the same labels and each edge ( p , c ) signi es the parent-child relationship between the data nodes of p and c . Each internal (resp. leaf) synopsis node stores the structural (resp.

value) distribution of the child labels (resp. value tokens) among its

data nodes. Speci cally, G is stored with the DataGuide S where

each synopsis node corresponds to exactly one schema node in S.

The FSLCA Computation Module. This module generates the

same nodes as any state-of-the-art approach when the query

does not involve missing elements but avoids irrelevant results

when missing elements are involved. To this end, it implements

two variants of a novel algorithm called

, namely

and

. The reader may refer to [11] for detailed descrip-

tion and performance results of these algorithms. Here, we brie y

describe the key idea.

Since the missing element phenomenon does not occur in an

document without missing elements (called a full document),

existing -based techniques work ne on it. Hence,

logically transforms D to a minimal full document F (D) (i.e., it

does not physically add missing elements), where all missing el-

ements are represented as empty elements, and then employs ef-

cient strategies to identify full

( ) nodes from it. For

example, if we compute the nodes on F (D1) (i.e., minimal full document of D1) for Q1, it would produce n0.4.3 due to the existence of the empty element area as its child. Hence, a full

( ) node of a query Q in a document D is an node of Q

on F (D).

Since a full document F (D) may contain empty nodes that do

not exist in the original document D, each

node can be cate-

gorized as complete (

) or partial (

). In the case of the

former, both the

node and its supporting matches are in the

original document D whereas for the latter the

node is in D

but some of its supporting matches may not be. For example, con-

sider the query Q3 (area, city) on D1. Then the

node n0.3.1

is a

as its subtree includes matches for both city and area.

On the other hand, n0.4.2 is a

node as it does not have any

area element as descendant in D1. This module implements two

algorithms called

and

to e ciently identify

these two categories of

nodes, respectively.

Both variants of the algorithm retrieve multiple document-order-

sorted streams of candidates to nd

nodes.

re-

trieves two streams of candidates, namely L1 and L2, for nodes without value matches and with at least one value match, re-

spectively. First, in the L1 stream it locates the label matches in the DataGuide of D and nds the s of these matches (e.g., city

node in Figure 1(b) for Q3). Next, it retrieves the instances in D corresponding to these DataGuide nodes (e.g., n0.3.1, n0.4.2, and n0.4.3). Second, in the L2 stream, for each value match (anchor

node), it computes the a1 between and the last and next value

match of each keyword (e.g., n0.4.2 for the value match n0.4.2.0 in Figure 1(a)). Then it computes the level  between 's path

and paths of each label keyword using DataGuide ( = 3 for Q3)

and nds ancestor a2 of at level  (e.g., n0.4.2). The

candi-

date of is the descendant between a1 and a2 (e.g., n0.4.2). Hence,

the nal

nodes are n0.3.1, n0.4.2, and n0.4.3.

The

, on the other hand, retrieves three streams of

candidates Ls , L1, and L2, where L1 and L2 are the same as in

and Ls is the stream of candidate nodes. The results

of

are generated only from Ls by ltering nodes using

candidates from L1 and L2. For instance, for the query Q3, the Ls

stream contains the

candidates n0.3.1 and n0.4 in D1. The L1

stream is used to lter any candidate nodes whose paths are pre-

xes of the path country/state/city (e.g., n0.4). Using the L2

stream, for each value match , it compute the

candidate

anchored at (n0.4.2) and lters candidate ancestors of the

node. Hence, the nal

node is n0.3.1.

The Heuristic-based Selector Module. Observe that

ignores result nodes containing missing elements (returns

)

whereas

returns all complete

nodes of

as well as additional results containing missing elements where

these elements are indicated as empty nodes (returns

). Since

a user may not have su cient knowledge to manually choose a

variant for a query Q, it is important to automatically deduce which

variant of

needs to be executed for Q. This module imple-

ments a heuristic-based mechanism to achieve it.

Intuitively, the selection choice is in uenced by the usefulness

of the additional results generated by

. We advocate that

it depends on the number of complete

s as well as the num-

ber of results (denoted by N ) desired by a user. So if an sys-

tem returns more than N

results, then a user may not be

interested in the results with missing elements. Consequently,

is relatively more appropriate for this case. On the other

hand, if there are fewer than N

results, then displaying

additional results with missing elements using

will be

potentially useful.

The challenge here is to estimate the number of

s a pri-

ori. We address it by utilizing the synopsis graph (Synopsis Graph

Builder) [11]. To illustrate the selection process using it, let us re-

consider Q1 and Q3 on D1. For Q1(Provo area), from the syn-

opsis graph we know that all cities have name but only 33% of

name have value Provo. Meanwhile, only 33% of cities have area.

Assuming the distributions are independent, 11% of cities have

both Provo and area. Since there are 3 city elements in D1, the estimated result size is 3× 0.11 = 0.33. Similarly, for Q3(city area), 33% of city elements have area which leads to the estimated re-

sult size of 1. Let N = 1. Since 0.33 < 1,

is used for Q1

but

is used for Q3.

The Result Subtrees Generator Module. This module selects

relevant return nodes within the

subtrees satisfying the query

Q and ranks them based on certain criteria (e.g., subtree size). Since

our

computation and result-based query expansion modules

are orthogonal to it, any state-of-the-art approaches related to rel-

evant information identi cation and result ranking (e.g., [2, 7, 8])

can be used here.

uses the strategy in [2].

1319

Demonstration Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

The Result-based Query Expansion Module. Given the set
of result subtrees of a query Q, this module generates top-k (k = 4 in the current version) expanded queries from the result set. Broadly, it consists of two key phases, keyword gathering and keyword re-
nement. In the keyword gathering phase, for each result tree, the root-to-leaf paths are extracted and node labels in the same level are grouped together. Each level is then associated with a set of distinct keywords. Then, duplicate keywords across di erent subtrees are removed. The intention here is to eventually select some of these keywords for expanding Q. However, since there could be many expanded keywords, the output of this phase needs to be re ned based on certain heuristics.
In the keyword re nement phase, it rst selects the top-m (m = 10) frequent keywords in the above collection. Next, keywords that do not produce any new information when they are added to Q (i.e., produces the same set of subtrees as Q) are pruned. For instance, consider the query Q4(paris). Adding the keyword france to Q4 does not generate any new information as the results of Q4 and the query Q4a (paris, france) are identical. Then, it identi-
es keywords that can be used to disambiguate Q. Intuitively, the goal is to identify keywords that co-occur with Q but appear in different context and have very di erent distributions. For example, consider the query Q2 and keywords country and mountain . Both these keywords co-occur with alaska in Mondial but have di erent context and result distributions. Speci cally, for each keyword w it computes its result distribution and intersection probability (probability of shared subtrees with the results of Q). Next, it computes the information gain due to the addition of w to Q by leveraging -divergence. Hence, each keyword is associated with three measures and the goal is to select top-k keywords when added to Q maximize the result distribution and information gain and minimize intersection probability. We exploit Fagin's Threshold Algorithm ( ) [3] to e ciently generate the top-k expanded queries.

3 RELATED SYSTEMS AND NOVELTY

Several result retrieval techniques have been proposed in the

literature [2, 7] based on matching semantics and its variants

(e.g., ) [12]. However, unlike

these e orts do not ad-

dress the missing element phenomenon e ectively. There has also

been recent research in improving user experience for [1, 2, 5].

However, none of these e orts focus on expanding queries with

multiple interpretations by analyzing the result set. In addition,

since these e orts are grounded on or semantics, they

also su er from the missing element problem. Liu et al. [9] inves-

tigated the problem of query expansion based on clustering Web

search results (i.e., textual content). However, this method cannot

be adopted e ectively in data.

Several systems have been demonstrated in major confer-

ence venues [1, 6]. These systems also su er from the missing el-

ement problem as they leverage the semantics. Nevertheless,

our demonstration is complimentary to them as we focus on the

missing element problem and automatic expansion of ambiguous

queries based on query results.

4 DEMONSTRATION OBJECTIVES

A

is implemented in Java JDK 1.7 on top of Berkeley

4.0.103. Our demonstration will be loaded with a few popular real

datasets (e.g., Mondial, I

,

and Shakespeare) of

sizes up to 1GB. Example queries with or without missing labels

will be presented for formulation. Users can also write their own

ad-hoc queries in Panel 3.

FSLCA computation and result display. One of the key ob-

jectives of the demonstration is to enable the audience to inter-

actively experience the

Computation module that addresses

the missing element problem. Speci cally, we rst set the Panel 4

in manual mode. Then, the user can formulate a query with miss-

ing label (Panel 3), select PartialFSLCA or CompleteFSLCA strat-

egy in Panel 4 to invoke the

or

algorithm,

respectively, and observe the di erences in the result set in Panel

6. Through this experience, users will be able to appreciate the limi-

tation of semantics in tackling the missing element phenome-

non. Note that users can also formulate queries without any miss-

ing label and experience that the results returned by

is

identical to those returned by -based techniques.

Automatic selection of MESSIAH variant. Through the ,

we shall also demonstrate the Heuristic-based Selector module, which

selects the correct variant of

automatically for a given

query. First, we set Panel 4 to automatic mode. Then, the user can

re-execute the above query (or any other query) and observe in

Panel 6 the correctness of the selection of

or

based on the result size estimation technique described earlier. Ad-

ditionally, through the aforementioned experiences users will be

able to appreciate superior performance of these modules, consis-

tent with the results reported in [11].

Result-based query expansion. Lastly, users can experience

the working of the Result-based Query Expansion module by clicking on the search box in Panel 3 after executing a query. They will be able to view top-4 expanded queries generated from the result set. Selecting any of the expanded queries will enable the user to view a subset of the original results that contain these keywords.

REFERENCES
[1] Z. Bao, et al. XReal: an interactive XML keyword searching, In CIKM, 2010. [2] Z. Bao, et al. Towards an e ective XML keyword search, In IEEE TKDE, 22(8),
2010. [3] R. Fagin, et al. Optimal aggregation algorithms for middleware, In PODS, 2001. [4] R. Goldman, J. Widom. Dataguides: Enabling query formulation and optimization
in semistructured databases, In VLDB, 1997. [5] X. Liu, et al. Returning clustered results for keyword search on XML documents,
IEEE TKDE, 23(12), 2011. [6] Z. Liu, et al. Targetsearch: A ranking friendly XML keyword search engine. In
ICDE, 2010. [7] Z. Liu, Y. Chen. Identifying meaningful return information for XML keyword
search, In SIGMOD, 2007. [8] Z. Liu, Y. Chen. Reasoning and identifying relevant matches for XML keyword
search, In PVLDB, 1(1), 2008. [9] Z. Liu, et al. Query expansion based on clustered results, In VLDB, 2011. [10] N. Polyzotis, et al. Selectivity estimation for XML twigs, In ICDE, 2004. [11] B. Q. Truong, et al. MESSIAH: Missing element-conscious SLCA nodes search
in XML data, In SIGMOD, 2013. [12] Y. Xu, Y. Papakonstantinou. E cient keyword search for smallest lcas in XML
databases, In SIGMOD, 2005.

1320

