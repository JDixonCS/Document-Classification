Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Cross-Language estion Re-Ranking

Giovanni Da San Martino, Salvatore Romeo, Alberto Barro´n-Ceden~ o, Sha q Joty, Llu´is Ma`rquez, Alessandro Moschi i, Preslav Nakov
Qatar Computing Research Institute, HBKU HBKU Research Complex. P.O. Box 5825 Doha, Qatar
{gmartino,sromeo,albarron,sjoty,lmarquez,amoschi i,pnakov}@hbku.edu.qa

ABSTRACT
We study how to nd relevant questions in community forums when the language of the new questions is di erent from that of the existing questions in the forum. In particular, we explore the Arabic­English language pair. We compare a kernel-based system with a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual dictionaries, and cross-language word embeddings. We observe that both approaches degrade the performance of the system when working on the translated text, especially the kernel-based system, which depends heavily on a syntactic kernel. We address this issue using a cross-language tree kernel, which compares the original Arabic tree to the English trees of the related questions. We show that this kernel almost closes the performance gap with respect to the monolingual system. On the neural network side, we use the parallel corpus to train cross-language embeddings, which we then use to represent the Arabic input and the English related questions in the same space. e results also improve to close to those of the monolingual neural network. Overall, the kernel system shows a be er performance compared to the neural network in all cases.
CCS CONCEPTS
·Information systems Learning to rank; estion answering; Multilingual and cross-lingual retrieval; Similarity measures;
KEYWORDS
Community estion Answering; Cross-language Approaches; estion Retrieval; Kernel-based Methods; Neural Networks; Dis-
tributed Representations
ACM Reference format: Giovanni Da San Martino, Salvatore Romeo, Alberto Barro´n-Ceden~ o, Sha q Joty, Llu´is Ma`rquez, Alessandro Moschi i, Preslav Nakov. 2017. CrossLanguage estion Re-Ranking. In Proceedings of SIGIR '17, Shinjuku, Tokyo, Japan, August 07-11, 2017, 4 pages. DOI: h p://dx.doi.org/10.1145/3077136.3080743
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080743

1 INTRODUCTION
In this paper, we study the problem of question re-ranking, which is an important task of the more general problem of community
estion Answering (cQA). In particular, we address question reranking in a cross-language (CL) se ing, i.e., where the language of the new question is di erent from the language of the candidate questions. We explore alternative ways to adapt kernel-based systems for English into this se ing, when the query language is Arabic. is is an interesting scenario because state-of-the-art cQA models rely upon relational syntactic/semantic structures, using Tree Kernels (TKs) [9], and these might be di cult to port across translation­based models. We compare the kernel machines to feed-forward neural networks (FNN), which have been known to perform well for cQA [21].
We rst explore a standard approach in CLIR: translating the input questions and applying our monolingual systems on the English-translated text. Our second approach, which is novel, is based on a CL TK --which does not require any translation-- as it is applied directly to pairs of Arabic and English trees. is tree kernel makes use of a statistical bilingual dictionary extracted from a parallel corpus. e FNN system can also make use of the parallel corpus by learning cross-language embeddings, which we further use in order to compare the Arabic and the English input representations directly.
We tested our approaches on the benchmark datasets from the SemEval-2016 task 3 on cQA [22], which we enriched with Arabic new questions. e results show that machine translation does not drastically degrade the ranking performance, probably because of the robustness of our similarity features. Most importantly, the use of the cross-language tree kernels almost lls the gap with respect to the monolingual system.
2 RELATED WORK
estion re-ranking can be approached from several di erent angles. Cao et al. [6] tackled it by comparing representations based on topic term graphs, i.e., by judging topic similarity and question focus. Jeon, Cro , and Lee [15] and Zhou et al. [33] dodged the lexical gap between questions by assessing their similarity on the basis of a (monolingual) translation model. Wang et al. [31] computed a similarity function on the syntactic-tree representations of the questions. A di erent approach using topic modeling for question retrieval was introduced by Ji et al. [16] and Zhang et al. [32], who used LDA topic modeling to learn the latent semantic topics in order to retrieve similar questions. Dos Santos et al. [8] used neural networks for the same purpose.

1145

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Cross-language approaches have mainly focused on estion Answering (QA). is has been fostered by multiple challenges such as the Multilingual QA Challenge at CLEF 2008 [10], NTCIR-8's Advanced Cross-lingual Information Access (ACLIA) [20], and DARPA's Broad Operational Language Technologies (BOLT) IR task [26]. Usually, the full question is translated using an out-of-thebox system in order to address CL-QA [14, 17]. Ture and Boschee [29] proposed supervised models to combine di erent translation se ings. Some approaches translate only keywords [24]. To the best of our knowledge, no research has been carried out on CL question re-ranking before. Regarding cross-language tree kernels, the only previous study relates to mapping natural language to an arti cial language (SQL) [11, 12]. We use a similar cross-language tree kernel along with the new idea of deriving relational links [25] using cross-language dictionaries.

3 TASK AND CORPORA

We experiment with data from the SemEval-2016 Task 3 on Com-

munity estion Answering [22], which we further augment with

translations as described below. We focus on subtask B, which targets question­question similarity (QS). Given a new question qo and the set of ten related questions from the QatarLiving forum q1, q2, . . . , q10, retrieved by a search engine, the goal is to re-rank

the related questions according to their similarity with respect to the

new question. e relationship between qo and qi , i  {1, 2, . . . , 10},

is described with a label: P

M ,R

, and I

. e goal is to rank the questions with the rst two labels higher than those with the la er label. Note that the questions in

this dataset are generally long multi-sentence stories which are

wri en in informal English; full of typos and ungrammaticalities.

e SemEval data has 267 new questions for training, 50 for development, and 70 for testing, and ten times as much qo ­qi pairs: 2,670, 500, and 700, respectively.
Based on this data, we simulated a cross-language cQA setup.

We rst got the 387 new train+dev+test questions translated into Arabic by professional translators.1 en, we used these Arabic

versions of the questions as input with the goal of re-ranking the

ten related English questions.

We also used an Arabic­English parallel corpus, which includes

the publicly available TED and OPUS corpora [28]. We used this

corpus in order to train an in-house phrase-based Arabic-English machine translation (MT) system,2 and also to extract a bilingual

dictionary in order to learn cross-language embeddings, as de-

scribed in Sections 4 and 5 below.

4 A KERNEL-BASED SYSTEM

We address the re-ranking task described in Section 3 by using

the scoring function of a binary ({P

M R

} vs.

I

) classi er based on support vector machines (SVM):

r (qo, qi ) =

n j

j j K ((qo, qi ), (qoj , qij )) in order to rank all the re-

lated questions qi with respect to their corresponding new question

qo . Here K (·) is a kernel function assessing how similar two pairs

of questions are. We use a combination of kernels on tree pairs and

features as described below.

1 e extension of the dataset is available at h p://alt.qcri.org/resources/cqa. 2 e MT system also uses a language model trained with the English Gigaword.

4.1 Tree Kernels

Given a pair of syntactic trees of the questions and a kernel for trees KT , we de ne the following kernel applied to (qo, qi ), (qoj , qij ):

KT (t (qo, qi ), t (qoj , qij )) + KT (t (qi , qo ), t (qij , qoj )),

(1)

where t (x, x ) is a string transformation method that returns the parse tree for the text x, further enriching it with RELational tags computed with respect to the syntactic tree of x . Typically, REL tags are assigned to the matching words between x and x , and they

are propagated to the parent and grand-parent nodes (i.e., up to 2

levels). is kernel in the monolingual se ing is described in [4].
Note that Eq. (1) can be applied to pairs (qo, qi ) in which qo and qi are texts in di erent languages, since in Eq. (1) the new (resp. related ) questions are only compared to new (resp. related ) questions:

this produces the kernel space of tree fragment pairs as shown in

[11, 12], where the pair members are in di erent languages. Moreover, the de nition of t (x, x ) is more complicated in case x and x

are in di erent languages as, in addition to using separate Arabic

and English parsers, we need to de ne methods for matching words

in di erent languages. Given the rich morphology of Arabic, this is

not a trivial task.

Cross-Language Tree Matching. In order to match the lexical items from both trees, we created a word-level Arabic-to-English statistical dictionary using IBM's Model 1 [5] over our bilingual corpus, which we pre-processed using Farasa [7] in order to share the segmentation and diacritization of the Arabic syntactic parser.

4.2 Feature Vectors

We combined the above tree kernels linearly with RBF kernels

applied to the following four feature vectors:

ConvKN features. We used the 21 features proposed in [4] computing similarities between the new and related questions such

as: longest common subsequences, Jaccard coe cient, word containment, cosine similarity. Since such similarities can be only

computed when the two texts are in the same language, we use the English translation to obtain them for the cross-language system.

Embedding features. We used three types of vector-based embed-

dings in order to encode the text of a question: (1) G

:

300-dimensional embedding vectors, pre-trained on Google News

[19]; (2) QL

: we trained domain-speci c vectors using

2 on all available QatarLiving data, both annotated and

raw (as provided for SemEval-2016 Task 3). (3) S : we parsed

the questions using the Stanford neural parser [27], and we used

the nal 25-dimensional vector that is produced internally as a

by-product of parsing. We did not use the embeddings themselves, but the cosines between the embeddings of a new and of a re-

lated question.

MTE features. We used the following MT evaluation metrics, which compare the similarity between the new and a related question

as in [13]: (1) B ; (2) NIST; (3) TER v0.7.25; (4) M

v1.4;

(5) Unigram P

; (6) Unigram R . We further used

various components involved in the computation of B , as features: n-gram precisions, n-gram matches, total number of n-grams (n=1,2,3,4), lengths of the related and of the new questions, length
ratio between them, and B 's brevity penalty.

1146

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Figure 1: Feed-forward neural network for QS.
Task-speci c features. We computed various task-speci c features, most of them introduced in the SemEval-2015 Task 3 on cQA [23].
is includes some question-level features: (1) number of URLs/ images/emails/phone numbers; (2) number of tokens/sentences; (3) average number of tokens; (4) type/token ratio; (5) number of nouns/verbs/adjectives/adverbs/ pronouns; (6) number of positive/negative smileys; (7) number of single/double/triple exclamation/interrogation symbols; (8) number of interrogative sentences (based on parsing); (9) number of words that are not in 2 's Google News vocabulary. Also, some question-question pair features: (10) count ratio in terms of sentences/tokens/nouns/verbs/ adjectives/adverbs/pronouns; (11) count ratio of words that are not in 2 's Google News vocabulary. Finally, we also have one meta feature: (12) reciprocal rank of the related question.
5 A NEURAL NETWORK SYSTEM
Given the small size of the training set, we used a simple Feedforward Neural Network (FNN), depicted in Figure 1. e input is a pair (qo, qi ). We map the input elements to xed-length vectors (zqo , zqi ) using their syntactic and semantic embeddings (described in Section 4.2). e network then models the interactions between the input embeddings by passing them through two nonlinear hidden layers (recti ed linear units, ReLU). Additionally, the network also considers pairwise features  (qo, qi ) between the two input elements that go directly to the output layer, and also through the second hidden layer. In our case,  (qo, qi ) is the concatenation of the MTE and the task-speci c features described in Section 4.2, which are also used by the kernel-based system. e following equations describe the transformation: h1 = f (U [zqo , zqi ]); h2 = f (V [h1,  (qo, qi )]), where U and V are the weight matrices in the rst and in the second hidden layer.
e output layer of the neural network computes a sigmoid on the output layer weights and on the pairwise features in order to determine whether qi is relevant with respect to the new question qo . We train the models by minimizing the cross-entropy between the predicted distributions and the target distributions, i.e., the gold labels.
Cross-language embeddings. Using our parallel Arabic­English corpus, we trained cross-language embeddings using the bivec method by Luong et al. [18], a bilingual extension of word2vec, which has reported excellent results on semantic tasks close to ours [30]. Using these CL embeddings allows us to compare directly representations of the Arabic qo and the English qi input questions. In particular, we trained 200-dimensional word embeddings using the parameters described in [30], with a context window of size
ve and iterating for ve epochs.

system

new question

1. IR rank 2. UH-PRHLT (SemEval) 3. ConvKN (SemEval) 4. SVM + TK 5. FNN

English English English English English

MAP dev. test
71.35 74.75 -- 76.70 -- 76.02
73.02 77.41 72.52 76.26

6. SVM + TKMT 7. SVM

Translated 72.94 76.67 Translated 71.99 76.36

8. FNN

Translated 72.44 75.73

9. SVM + TKCL 10. FNN + CL emb

Arabic Arabic

73.34 77.14 72.27 76.06

Table 1: MAP scores on the development and test datasets.

6 EXPERIMENTS
We consider three scenarios: (i) Original, i.e., the SemEval 2016 setup, (ii) Translated, in which qo are originally in Arabic and machine-translated into English, and (iii) Arabic, in which qo are in Arabic. In all se ings, we apply the tree kernel in Eq. (1). However, we distinguish when the kernel is applied to the original English trees qo (TK), the translated ones (TKMT ), and the Arabic ones (TKCL). In all experiments, we kept the default parameters for the kernels and we selected the C parameter of SVM on the development set, trying {0.01, 0.1, 1, 10}. For the FNN models, we used the development set for early stopping based on MAP as well as for parameter optimization.
Table 1 shows Mean Average Precision (MAP) on the development and on the test datasets. e rst block contains the reference results on the original English test set (rows 1­5). IR rank corresponds to the Google-generated ranking, which is a hard-to-beat baseline. UH-PRHLT and ConvKN are the two best-performing systems at SemEval-2016 Task 3 (see [22] for details). SVM + TK is the kernel-based system presented in this paper, which reproduces ConvKN and adds our extra features (cf. Section 4.2). Finally, FNN is the neural network model presented in this paper.
Our SVM model (row 4) shows a sizable improvement over ConvKN on the test set, which means that our extra features are strong. Actually, the SVM results are also be er than the best system at SemEval-2016 (+0.71 MAP). e FNN model shows also competitive performance, but below the SVM system (-1.15 MAP).
e monolingual result from SVM (77.41 MAP) is the upper bound performance when considering the results in the CL scenario.
e second block (rows 6­8) shows the results of our systems in the "translated" se ing. One concern about applying the TK approach in this se ing was that the translated text might be grammatically broken and the parser could produce low-quality parse trees. Still, the SVM system degrades its performance only to 76.67 MAP when applied a er machine-translating the Arabic new questions (i.e., -0.74 MAP points below the upper bound).
Row 7 shows the result for SVM without TK. Its MAP score is 76.36, which is slightly below the previous score of 76.67 obtained with TK; this shows that the two kernels provide complementary information. Comparatively, the FNN model degrades the performance even less when working with the translated Arabic query (75.73, row 8 vs. 76.26, row 5). is indicates again that the features we use are robust to translation.

1147

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

e last block in the table (rows 9-10) shows the results of the systems using the CL kernels and representations. e SVM system scores 77.14 MAP when using the CL kernel. is is above the results with TKMT . is nal MAP value is very close to the upper bound system (77.41). In conclusion, achieving a similar ranking quality to that of the monolingual se ing is possible by departing from Arabic text and using the novel cross-language tree kernel together with a robust feature set computed on the translated texts. Finally, the FNN system achieves slightly improved results when we add the input representation based on cross-language embeddings (row 10), reaching a MAP score, 76.06, that is very close to the monolingual FNN (76.26).
7 CONCLUSIONS AND FUTURE WORK
We studied the task of cross-language question re-ranking in community question answering. We rst explored the possibility of using MT for translating an Arabic query question and then applying an English monolingual system. e results of two alternative systems for question re-ranking (kernel- and FNN-based) show a relatively small degradation in performance with respect to the monolingual se ing on a well-established SemEval dataset. Furthermore, we showed that the performance gap in the SVM system can be almost closed by using a novel cross-language tree kernel, which compares directly the source and the target language trees. A cross-language input representation can also help the FNN system to close the gap with respect to the monolingual case. Finally, the performance of the SVM system is always superior to that of the FNN system in our se ing. We conjecture that this is due to the relatively small size of the training set, and due to the information provided by the tree kernel (relations between syntactic sub-structures).
Our work enables interesting future research lines, e.g., (i) designing more accurate cross-language TKs using be er Arabic structures and cross-language word matching and embeddings, (ii) combining the SVM and the FNN models, and (iii) exploring how far a system can go without machine translation.
ACKNOWLEDGMENTS
is research was performed by the Arabic Language Technologies group at Qatar Computing Research Institute, HBKU, within the Interactive sYstems for Answer Search project (I ).
REFERENCES
[1] 2008. Evaluating Systems for Multilingual and Multimodal Information Access, 9th Workshop of CLEF 2008, Revised Selected Papers. Aarhus, Denmark.
[2] 2010. Proc. of NTCIR-8 Workshop Meeting. Tokyo, Japan. [3] 2016. Proc. of the 10th SemEval Workshop. San Diego, California, USA. [4] Alberto Barro´n-Ceden~ o, Giovanni Da San Martino, Sha q Joty, Alessandro Mos-
chi i, Fahad Al-Obaidli, Salvatore Romeo, Kateryna Tymoshenko, and Antonio Uva. 2016. ConvKN at SemEval-2016 Task 3: Answer and estion Selection for
estion Answering on Arabic and English Fora, See [3], 896­903. [5] Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vicent J. Della Pietra,
Frederick Jelinek, John D. La erty, Robert L. Mercer, and Paul S. Roossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics 16, 2 (1990), 79­85. [6] Yunbo Cao, Huizhong Duan, Chin-Yew Lin, Yong Yu, and Hsiao-Wuen Hon. 2008. Recommending estions Using the Mdl-based Tree Cut Model. In Proceedings of WWW '08. New York, New York, USA, 81­90. [7] Kareem Darwish and Hamdy Mubarak. 2016. Farasa: A New Fast and Accurate Arabic Word Segmenter. In Proceedings of LREC. Portoroz, Slovenia.

[8] Cicero Dos Santos, Luciano Barbosa, Dasha Bogdanova, and Bianca Zadrozny. 2015. Learning Hybrid Representations to Retrieve Semantically Equivalent estions. In Proceedings of ACL '15. Beijing, China, 694­699.
[9] Simone Filice, Danilo Croce, Alessandro Moschi i, and Roberto Basili. 2016. KeLP at SemEval-2016 Task 3: Learning Semantic Relations between estions and Answers, See [3], 1116­1123.
[10] Pamela Forner, Anselmo Pen~ as, Eneko Agirre, In~ aki Alegria, Corina Forascu, Nicolas Moreau, Petya Osenova, Prokopis Prokopidis, Paulo Rocha, Bogdan Sacaleanu, Richard F. E. Sutcli e, and Erik F. Tjong Kim Sang. 2008. Overview of the CLEF 2008 Multilingual estion Answering Track, See [1], 262­295.
[11] Alessandra Giordani and Alessandro Moschi i. 2010. Semantic Mapping Between Natural Language estions and SQL eries via Syntactic Pairing. In Proceedings of NLDB'09. Saarbru¨cken, Germany, 207­221.
[12] Alessandra Giordani and Alessandro Moschi i. 2012. Translating estions to SQL eries with Generative Parsers Discriminatively Reranked. In Proceedings of COLING '12. Mumbai, India, 401­410.
[13] Francisco Guzma´n, Llu´is Ma`rquez, and Preslav Nakov. 2016. Machine Translation Evaluation Meets Community estion Answering. In Proceedings of ACL '16. Berlin, Germany, 460­466.
[14] Sven Hartrumpf, Ingo Glo¨ckner, and Johannes Leveling. 2008. University of Hagen at QA@CLEF 2008: E cient estion Answering with estion Decomposition and Multiple Answer Streams, See [1], 421­428.
[15] Jiwoon Jeon, W. Bruce Cro , and Joon Ho Lee. Finding Similar estions in Large estion and Answer Archives. In Proceedings of CIKM '05. Bremen, Germany,
84­90. [16] Zongcheng Ji, Fei Xu, Bin Wang, and Ben He. 2012. estion-Answer Topic
Model for estion Retrieval in Community estion Answering. In Proceedings of CIKM '12. Maui, Hawaii, USA, 2471­2474. [17] Chuan-Jie Lin and Yu-Min Kuo. 2010. Description of the NTOU Complex QA System, See [2], 47­54. [18] ang Luong, Hieu Pham, and Christopher D. Manning. 2015. Bilingual Word Representations with Monolingual ality in Mind. In Proceedings of the 1st Workshop on Vector Space Modeling for NLP. Denver, Colorado, USA, 151­159. [19] Tomas Mikolov, Wen-tau Yih, and Geo rey Zweig. 2013. Linguistic Regularities in Continuous Space Word Representations. In Proceedings of NAACL-HLT '13. Atlanta, Georgia, USA, 746­751. [20] Teruko Mitamura, Hideki Shima, Tetsuya Sakai, Noriko Kando, Tatsunori Mori, Koichi Takeda, Ruihua Lin, Chin-Yew Song, Chuan-Jie Lin, and Cheng-Wei Lee. 2010. Overview of the NTCIR-8 ACLIA Tasks: Advanced Cross-Lingual Information Access, See [2], 15­24. [21] Preslav Nakov, Llu´is Ma`rquez, and Francisco Guzma´n. 2016. It Takes ree to Tango: Triangulation Approach to Answer Ranking in Community estion Answering. In Proceedings of EMNLP '16. Austin, Texas, USA, 1586­1597. [22] Preslav Nakov, Llu´is Ma`rquez, Alessandro Moschi i, Walid Magdy, Hamdy Mubarak, abed Alhakim Freihat, Jim Glass, and Bilal Randeree. 2016. SemEval2016 Task 3: Community estion Answering, See [3], 525­545. [23] Massimo Nicosia, Simone Filice, Alberto Barro´n-Ceden~ o, Iman Saleh, Hamdy Mubarak, Wei Gao, Preslav Nakov, Giovanni Da San Martino, Alessandro Moschi i, Kareem Darwish, Llu´is Ma`rquez, Sha q Joty, and Walid Magdy. QCRI: Answer Selection for Community estion Answering - Experiments for Arabic and English. In Proceedings of SemEval '15. Denver, Colorado, USA, 203­209. [24] Han Ren, Donghong Ji, and Jing Wan. 2010. WHU estion Answering System at NTCIR-8 ACLIA Task, See [2], 31­36. [25] Aliaksei Severyn and Alessandro Moschi i. 2012. Structural Relationships for Large-scale Learning of Answer Re-Ranking. In Proceedings of SIGIR '12. Portland, Oregon, USA, 741­750. [26] Ian Soboro , Kira Gri , and Stephanie Strassel. 2016. e BOLT IR Test Collections of Multilingual Passage Retrieval from Discussion Forums. In Proceedings of SIGIR '16. New York, New York, USA, 713­716. [27] Richard Socher, John Bauer, Christopher D. Manning, and Ng Andrew Y. 2013. Parsing with Compositional Vector Grammars. In Proceedings of ACL '13. So a, Bulgaria, 455­465. [28] Jo¨rg Tiedemann. 2012. Parallel Data, Tools and Interfaces in OPUS. In Proceedings of LREC'12. Istanbul, Turkey. [29] Ferhan Ture and Elizabeth Boschee. 2016. Learning to Translate for Multilingual
estion Answering. In Proceedings of EMNLP '16. Austin, Texas, USA, 573­584. [30] Shyam Upadhyay, Manaal Faruqui, Chris Dyer, and Dan Roth. 2016. Cross-
lingual Models of Word Embeddings: An Empirical Comparison. In Proceedings of ACL. Berlin, Germany, 1661­1670. [31] Kai Wang, Zhaoyan Ming, and Tat-Seng Chua. 2009. A Syntactic Tree Matching Approach to Finding Similar estions in Community-based QA Services. In Proceedings of SIGIR '09. Boston, Massachuse s, USA, 187­194. [32] Kai Zhang, Wei Wu, Haocheng Wu, Zhoujun Li, and Ming Zhou. 2014. estion Retrieval with High ality Answers in Community estion Answering. In Proceedings of CIKM '14. Shangai, China, 371­380. [33] Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu. 2011. Phrase-based translation model for question retrieval in community question answer archives. In Proceedings of ACL. Portland, Oregon, USA, 653­662.

1148

