Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Social Media Advertisement Outreach: Learning the Role of

Aesthetics

Avikalp Srivastava
IIT Kharagpur avikalp22@iitkgp.ac.in

Madhav Da
Harvard University madhav da @college.harvard.edu

Jaikrishna Chaparala
IIT Kharagpur jaikrishna.ch@iitkgp.ac.in

Shubham Mangla
IIT Kharagpur shubhammangla@iitkgp.ac.in

Priyadarshi Patnaik
IIT Kharagpur bapi@hss.iitkgp.ernet.in

ABSTRACT
Corporations spend millions of dollars on developing creative imagebased promotional content to advertise to their user-base on platforms like Twi er. Our paper is an initial study, where we propose a novel method to evaluate and improve outreach of promotional images from corporations on Twi er, based purely on their describable aesthetic a ributes. Existing works in aesthetic based image analysis exclusively focus on the a ributes of digital photographs, and are not applicable to advertisements due to the in uences of inherent content and context based biases on outreach.
Our paper identi es broad categories of biases a ecting such images, describes a method for normalizing outreach scores to eliminate e ects of those biases, which enables us to subsequently examine the e ects of certain handcra ed describable aesthetic features on image outreach. Optimizing on the features resulting from this research is a simple method for corporations to complement their existing marketing strategy to gain signi cant improvement in user engagement on social media for promotional images.
1 INTRODUCTION
In an e ort to reach out to their user base, corporations spend millions of dollars developing creative image-based promotional content for social media platforms such as Twi er. e ability of corporations to engage a large portion of their target audience has very direct monetary consequences for them. Because of their focus on sales and brand promotion, these images come with certain inherent content and context based biases beyond just aesthetic a ributes that in uence overall outreach.
Most advertisement outreach research and development is based on data from advertisement quality surveys. Conducting such surveys is an extremely resource intensive task. ere has also been signi cant work in aesthetic image analysis [1, 2, 6, 7] for predicting user ratings of digital photographs. However, these studies cannot be applied to promotional images on social media, because, social media user engagement of an image, unlike user ratings, are in uenced by multiple factors beyond just image aesthetics.
In our paper, we develop an engagement score for images on Twi er, identify such broad "biases" or factors, propose an automated method to identify their presence in images and learn a transformation on scores to eliminate the e ects of such biases. We
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080759

select a set of hand-cra ed describable image aesthetic features and train our system to learn the relative signi cance and in uence of each of these features on engagement. To ensure that the results of our research are actionable by graphic designers, we restrict our work to human understandable/describable features and do not use generic or learned deep features such as the ones used in [6].
We also go on to show that low level features that work for digital photography (not accounting for biases) do not work for social media ad success. We use the model described in [1] for aesthetics of digital photographs as a baseline. Our method performs signi cantly be er (71.8% vs 57.5%) than the baseline on classifying our dataset of 8000 promotional images on Twi er into successful and unsuccessful images.
In the end, we describe the basic function and design of an automated interactive system based on the results obtained from our model. e system takes promotional images from corporations as input and provides human understandable/describable aesthetic a ributes of the image that may be tuned (for example, increasing spatial smoothness of hue property by 14%) by designers to obtain the most signi cant increase in engagement on Twi er.
rough this paper, our key contribution is developing a method to deal with the bias related challenges associated with analyzing effects of aesthetic features on outreach of social media advertisement images. is elimination of bias to give comparable image scores based only on aesthetic a ributes, across di erent images and pages on social media, opens possibilities for research in computational aesthetics around the social media advertising industry.
2 DATA COLLECTION
We build a data set of 8,000 image based promotional tweets by scraping Twi er pro les of 80 di erent corporations. ese corporations are particularly active on Twi er and have between 36,000 (@Toblerone) to 13 million (@Pla Station) followers, and 3,000 (@tictac) to 753,000 (@united) tweets. We select these corporations from across 20 broad categories such as retail, fast food, automobiles etc. to account for the diversity in promotional image representation. We scrape such image based promotional tweets along with their likes count, retweets count, date and time, page followers, page tweets and tweet text from the Twi er API for each corporation page, in proportion to their total number of tweets.
For each such image i  page p, we de ne our engagement evaluation score i , as the sum of image likes and image retweets. Due to inherent industry di erences, and the variances across pages in total followers, we normalize our scores to ensure comparability between scores from di erent pages. We get a Pearson Correlation Coe cient of 0.46 and Spearman Rank Correlation of 0.63, suggesting no linear or monotonic correlation between number of

1193

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Figure 1: From le to right: No bias present, holiday season, animal presence, human presence, discounts, product launch

followers and average engagement scores of a page. is is also

supported by the sampled distribution in Figure 2.

erefore, in order to account for the di erence in image based

tweet engagement between pages of di erent sizes, industries etc. we use the mean and variance of engagement scores (i ) of images

from the page p for normalization. us, we de ne normalized engagement Ni : For image i  p,

Ni

=

i - µp p

where µp and p are mean and standard deviation of image scores from page p.

3 BIAS DRIVEN ENGAGEMENT
Datasets used by previous aesthetic image researches (Photo.Net [1], DPChallenge [2], AVA [7]) only involve digital photographs rated by users purely based on their aesthetic appeal. Image based promotions on Twi er contain certain content and context based biases that signi cantly in uence engagement scores N , for example, advertisements involving a cute cat will, on average, have much greater success and outreach, and consequently higher N scores compared to aesthetically be er images free from any signi cant biases. is makes analyzing the e ects of aesthetic features on engagement an extremely challenging task. To ensure that our scores represent e ects of, and are strongly correlated with visual appeal and aesthetic factors, we detect biases a ecting each image and remove their in uences on the score.
For each Twi er page within our 8000 image dataset, we detect outliers in terms of engagement scores using normalized local outlier factor scores and manually identify 8 broad categories of the most signi cant biases (listed in Table 1). In this paper, we account for and eliminate the e ects of 4 biases - Animal Presence (cats, dogs etc.), Human Presence (babies, celebrities etc.), Special Days (Black Friday, Christmas etc.), and Discounts. Handling the remaining biases is beyond the scope of this paper and can give direction to future research in this area.
Table 1: Signi cant biases a ecting Twitter engagement

Discounts/Give-aways Hashtags/Celebrity Mentions Special Days/Holiday Season Social/Motivational Message

Human Presence Animal Presence Product Launches Brand Popularity

3.1 Bias Identi cation
We use the Viola-Jones face detector to give a binary classi cation detecting the presence of faces (as a proxy for human presence) in promotional images. To detect presence of animals, we train a spatial pyramid matching based SVM classi er described by Lazebnik et al. [5] on 5000 images of cats and dogs (most frequently

Figure 2: Distribution of Variances and Medians of Engagement Scores vs Number of Followers of Twitter Pages
occurring animals) scraped from the web. We manually identify all the 4 above mentioned biases from a sample of 1000 images from our 8000 image dataset, to assess quality of our automated bias identi cation, and obtained 75.5% accuracy for human presence detection and 69.6% accuracy for animal presence detection.
To extract text from the image, we use the Tesseract OCR Engine. In this paper, we de ne tweet text as the OCR extracted text along with the text associated with each image from its tweet. To account for the surge in Twi er engagement in periods leading up to major holidays such as Christmas, Black Friday, Halloween etc. we de ne date ranges around each such holiday (for example 7 days before and a er Christmas). We manually build a list of 20 words commonly associated with holidays (such as Thanksgiving, Hanukkah etc.) We augment this list of words by nding the 20 most linguistically and semantically similar words using GloVe [8], which are then manually validated and ltered, and classify all tweets which occur within a holiday date range containing any of these words as Holiday biased.
To identify tweets a ected by biases caused by discounts/o ers, we repeat the same process as described above using a di erent set of common initial words such as free, discount, sale, offer etc. with GloVe. We also identify tweets that urge users to retweet to get o ers or win as part of some promotion. On our manually labeled 1000 image test set, we obtain 88.3% accuracy on holidaythemed image identi cation and 84.4% accuracy in identi cation of discounts and o ers. While some images contain multiple biases, we restrict our paper to images with at most one bias which constitute a majority of our dataset (923 of our sampled 1000 images).
3.2 Bias Removal
We de ne set of unbiased images U and mutually exclusive sets of identi ed biased images Bj  B, where B = {Images with human presence, Images with animal presence, Holiday-themed images, Images with discounts}.

1194

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Figure 3: Le : Distribution of image scores with holiday bias. Right: Distribution comparison for unbiased, humanpresence and animal-presence biased images. Both estimated via Gaussian curves

Figure 4: 1st row: Images with highest feature values: Average hue for DoF, localized light exposure, average intensity of largest segment. 2nd row: Feature visualizations based on Region Adjacency Graphs

We de ne the discrete probability distribution of scores of images Ni , i  U as P, and that of image scores Nj , j  Bj, for Bj  B, as Q. To eliminate the e ects of the bias, we apply the transformation Q - Q¯ , such that the distribution Q¯ can be used as an approximation of P, while maintaining relative ranking order of image scores of biased images as in their original distribution Q. Since, we transform Q to eliminate the e ects of bias, Q¯ should be distributed similar to P, and transformed image scores Ni T for i  Q¯ are used as if the original images had not been a ected by the bias. To this e ect, we use the Kullback-Leibler divergence DK L(P||Q¯ ) as our objective function for minimization, to capture the loss incurred while using Q¯ to approximate P.
Let Yj be the set of scores for images in Bj, thus the set of transformed scores Y¯ is obtained as follows:
Y¯j = ¯i j | ¯i j =  ( i j )
where the probability distribution of the set Y¯j is de ned as Q¯  . us, we learn the transformation    D, where D is the space
of all transformation functions, such that
  = ar miDn (DK L(P||Q¯  ))

where,

D KL (P | | Q)

=

i Yj

P (i )

log

P (i ) Q (i )

In this paper, we explore the space of polynomial functions Ddp  D, where the parameter d de nes the degree of polynomial for the input features ij ,  ij  Yj . erefore for the space Ddp ,  as parameterized by W = [W0,W1, ..Wd ] on the input ij  Yj is de ned as follows:

W (

i j ) = W0 + W1

i j + W2

2 ij

+

..

+ Wd

d ij

We add another constraint that W  (IR+)(d+1), so that during transformation, the relative ranking order of biased images is maintained and arbitrary transformations that disregard original distribution's ranking information and over t are disallowed. For the bias associated with Yj in consideration, the input to the system is the matrix

X  IR(d+1)×n given by:

 1 1 ... 1 

  1j

2j . . .

 nj

2

    

1j
...

2 2j

...

... . . .

2

nj
...

    

d  1j

d 2j

...

d nj





where n = |Yj |. At each step, the intermediate output transformation is given by

O =WTX

where O

=

[

` 1j

,

` 2j

,

...,

` n

j

],

where

` ij

represent

the

intermediate

approximate values of the transformed score ¯ij . We minimize the

above described divergence or loss function, (W ) = DKL(P||O) to

learn the values for the matrix W . With the learned W , we apply

the transformation  (= W ) to image scores in Y to eliminate

e ects of bias described in Bj. We repeat this process for each set

of biased images in B.

4 AESTHETIC FEATURE LEARNING
Computational assessment of aesthetic image quality is a well tackled problem. Having removed the content and context based biases associated with the scores received by the images in our dataset, we obtain image features strongly related with aesthetic appeal and visual a ractiveness of the image to get the feature vector xi for each image i. We now formulate our feature learning problem with training data set {xi , i }i [1, N ], where i = Ni T , i.e. represents the transformed score of image i a er bias elimination. A function f : X  Y is learned for providing feedback and suggestions for improving user engagement through image feature tuning.

4.1 Feature Selection And Extraction
We select describable/human-understandable image a ributes based on handcra ed features used in previous works, augmenting the list with an additional set of features deemed important to capture the multi-object majority nature identi ed in advertisement images vis-a-vis photographic images. We implement the 56 features de-
ned by Da a et al. [1] in addition to non-overlapping features from Ke et al.[4], compositional a ributes from Dhar et al.[3], along with added features based on Region Adjacency Graphs (RAG) such as threshold and recursive normalized cut information. us, we obtain a total of 74 describable aesthetic features for each image.

1195

Short Research Paper
4.2 Experimental Evaluation
We use a standard support vector regressor with RBF kernel to learn the function f : X  Y where X denotes the 74 feature based vector set and Y denotes the set of normalized and bias-removed engagement scores. is provides a quantitative evaluation of the relation between the feature vector values to the predicted engagement score, necessary for providing feedback on feature tuning for the query image to maximize the outreach through increased aesthetic and visual appeal, given that all other components for that image remain same.
We also show that aesthetic features that work for digital photographs do not necessarily work for promotions/advertisement based images. From our dataset {xi , i }i [1, N ], we sample 20% points to form our test set T. To model our data for the classi cation task, we specify thresholds to partition images with scores in the lowest and highest quartile as "unsuccessful" and "successful" respectively. We rst run a SVM classi er model to learn weights for the 56 features used in [1] on the Photo.net dataset and use this trained model to classify on our test set T. While the accuracy of trained model on test set from Photo.net dataset is 69.12% (close to value reported in [1]), on T this model's accuracy reduces to 57.5%. Our 74 feature model trained on Twi er advertisement training dataset {xi , i }i [1, N ] - T performs with 71.8% accuracy on T, and on inspection we nd that a good proportion of misclassi ed images contained biases we didn't handle in this study, and thus also good motivation for future work. e reduced accuracy achieved when using aesthetic features learned from non-advertisement dataset strongly suggests that it is necessary to capture image features linked with success of advertisement related images di erently from those of purely aesthetically motivated digital photographs.

Table 2: e 5 highest signi cance attributes identi ed using linear kernel SVM for Photo.Net dataset vs. Twitter Advertisement Dataset

Photo.Net Familiarity measure
Brightness measure
Avg. hue in wavelet transformation
3rd largest patch size

Twitter Ads Low DoF hue component
Largest segment avg. intensity
Low DoF saturation
RAG segment count

4.3 Applications and Feedback System
Our paper describes the basic functioning and design of a system, based on our trained SVM regressor, to identify the aesthetic feature tunings that can be applied to image based promotions, in conjugation with other marketing strategies, to maximize user engagement.
Given an input promotional advertisement image i, we apply our system for feature extraction to obtain the feature vector xi . Our system ideally seeks to nd the nearest-neighbor feature vectors for xi that lead to maximum increase in predicted engagement. at is, the system outputs a set of features and percentage changes for each, from our initially chosen human-understandable feature space, to maximize predicted engagement scores for the image. However, from a practical perspective, a graphics designer would be more interested in a tuning that provides changes to small number of features, rather than suggesting small changes to a large number of features, which can be inconvenient. A user may restrict the

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan
Figure 5: On input (a) to system with k=2, t=4% suggestions: Increase features, light exposure by 24%, spatial smoothness of 2nd level of saturation by 16%; (b) nal image with suggestions incorporated
number of features where changes are suggested to at most k, where each feature is not changed by more than a value s. For nding the optimal tuning combination among these k features, a distance of s on either side of the original feature value is traversed in steps of size t. e tuning combination that achieves the highest predicted engagement score from the trained support vector regressor is chosen as the suggestion output, as demonstrated in Figure 5.
5 CONCLUSION AND FUTURE WORK
Our paper proposes a novel method to evaluate and improve outreach of promotional images from corporations on Twi er by identifying inherent biases and transforming scores to eliminate their e ect on engagement in order to discover a ributes that contribute most to advertisement outreach. Our model gives an aestheticfeature based representation with corresponding outreach scores, enabling vector space model based retrieval strategies. It also opens new possibilities for research and applications of computational aesthetic analysis of images in the social media advertisement industry. Exploring and tackling the biases excluded by this study, using generic or deep learned features, computational improvements on the feedback system etc. promise exciting scope for future work.
REFERENCES
[1] Ritendra Da a, Dhiraj Joshi, Jia Li, and James Z Wang. 2006. Studying aesthetics in photographic images using a computational approach. In European Conference on Computer Vision. Springer, 288­301.
[2] Ritendra Da a, Jia Li, and James Z Wang. 2008. Algorithmic inferencing of aesthetics and emotion in natural images: An exposition. In Image Processing, 2008. ICIP 2008. 15th IEEE International Conference on. IEEE, 105­108.
[3] Sagnik Dhar, Vicente Ordonez, and Tamara L Berg. 2011. High level describable a ributes for predicting aesthetics and interestingness. In Computer Vision and Pa ern Recognition (CVPR), 2011 IEEE Conference on. IEEE, 1657­1664.
[4] Yan Ke, Xiaoou Tang, and Feng Jing. 2006. e design of high-level features for photo quality assessment. In Computer Vision and Pa ern Recognition, 2006 IEEE Computer Society Conference on, Vol. 1. IEEE, 419­426.
[5] Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. 2006. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In Computer vision and pa ern recognition, 2006 IEEE computer society conference on, Vol. 2. IEEE, 2169­2178.
[6] Luca Marcheso i, Florent Perronnin, Diane Larlus, and Gabriela Csurka. 2011. Assessing the aesthetic quality of photographs using generic image descriptors. In Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 1784­ 1791.
[7] Naila Murray, Luca Marcheso i, and Florent Perronnin. 2012. AVA: A large-scale database for aesthetic visual analysis. In Computer Vision and Pa ern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2408­2415.
[8] Je rey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Natural Language Processing (EMNLP). 1532­1543. h p://www.aclweb.org/anthology/ D14- 1162

1196

