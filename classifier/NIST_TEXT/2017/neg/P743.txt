Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

What Are You Known For? Learning User Topical Profiles with Implicit and Explicit Footprints

Cheng Cao, Hancheng Ge, Haokai Lu, Xia Hu, and James Caverlee
Department of Computer Science and Engineering Texas A&M University
chengcao@tamu.edu, {hge, hlu, hu, caverlee}@cse.tamu.edu

ABSTRACT
User interests and expertise are valuable but o en hidden resources on social media. For example, Twi er Lists and LinkedIn's Skill Tags provide a partial perspective on what users are known for (by aggregating crowd tagging knowledge), but the vast majority of users are untagged; their interests and expertise are essentially hidden from important applications such as personalized recommendation, community detection, and expert mining. A natural approach to overcome these limitations is to intelligently learn user topical pro les by exploiting information from multiple, heterogeneous footprints: for instance, Twi er users who post similar hashtags may have similar interests, and YouTube users who upvote the same videos may have similar preferences. And yet identifying "similar" users by exploiting similarity in such a footprint space o en provides con icting evidence, leading to poor-quality user pro les. In this paper, we propose a uni ed model for learning user topical pro les that simultaneously considers multiple footprints. We show how these footprints can be embedded in a generalized optimization framework that takes into account pairwise relations among all footprints for robustly learning user pro les. rough extensive experiments, we nd the proposed model is capable of learning high-quality user topical pro les, and leads to a 10-15% improvement in precision and mean average error versus a crosstriadic factorization state-of-the-art baseline.
CCS CONCEPTS
·Information systems  Social tagging systems; Collaborative ltering; Users and interactive retrieval;
KEYWORDS
Social Media; User Pro le; User Behavior
ACM Reference format: Cheng Cao[1], Hancheng Ge[1], Haokai Lu, Xia Hu, and James Caverlee. 2017. What Are You Known For? Learning User Topical Pro les with Implicit and Explicit Footprints. In Proceedings of SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 10 pages. DOI: h p://dx.doi.org/10.1145/3077136.3080820
*Equal contribution
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080820

1 INTRODUCTION
In social media systems, demographic pro les -- o en including name, age, gender, and location -- provide an important rst step toward creating rich user models for information personalization. For example, a user's location can be a signal to surface local content in the Facebook newsfeed. ese demographic pro les typically reveal very li le about a user's topical interests (what she likes) or expertise (what she is known for). Hence, there is great e ort toward building high-quality user topical pro les, toward improving user experience and powering important applications like personalized web search [42], recommendation system [13, 33], expert mining [11], and community detection [53].
Indeed, there are two major approaches to build the topical pro les for social media users. One thread of methods seeks to uncover latent factors that may be descriptive of a user. For example, running Latent Dirichlet Allocation (LDA) over a user's posts in social media can reveal the topics of interest of the user [28, 34, 48]; similarly, matrix factorization approaches have proven popular at capturing user factors, o en for personalization purposes [14, 15, 21, 33, 42, 51, 56]. Aside from such recommendation applications, latent factor models have also been used to nd in uential users, mine communities, and predict review quality [31, 48, 53]. Another thread of methods seeks to encourage social media users to directly assess each other's interests and expertise, providing a partial perspective on user topical pro les. For example, LinkedIn users can choose skill tags for their own pro les and can endorse these tags on the pro les of others. Twi er Lists allow users to organize others according to user-selected keywords, e.g., placing a group of popular chefs on the list "Top Chefs". In this way, some list names can be viewed as a topical tag for list members. In the aggregate, this crowd-contributed tagging knowledge can be viewed as explicit evidence for capturing user interests and expertise [4, 11, 39].
Both approaches, however, face great challenges. Approaches that identify latent topics (o en, as a distribution over features in some lower dimensional space) are typically trained only over content (ignoring other important footprints) and are di cult to directly interpret. Methods that only use crowdsourced tags typically su er from limited coverage; that is, while the hand-curated tags may be of high-quality, very few users actually have descriptive topical tags associated with them. For example, in a random sample of 3.5 million Twi er users, we nd that only 2% have been labeled with a topical tag (more details in Section 5). Moreover, to be er understand user topical interests and expertise, a more comprehensive pro ling framework is necessary. For instance, it is unclear what kind of evidence is useful for user topical pro ling. And how can such potentially heterogeneous evidence be modeled for user topical pro ling?

743

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Hence, in this paper, we propose to exploit heterogeneous footprints (e.g., tags, friends, interests, behavior) for intelligently learning user topical pro les. Based on a small set of explicit user tags, our goal is to extend this known set to the wider space of users who have no explicit tags. e key intuition is to identify "similar" users in terms of their topical pro les by exploiting their similarity in a footprint space. For instance, Twi er users who post similar hashtags may have similar interests, and YouTube users who upvote the same videos may have similar preferences. Such evidence of homophily has been widely studied in the sociological literature [35] and repeatedly observed in online social media, e.g., [5, 7, 26, 46, 49]. But what footprint spaces are appropriate for nding this homophily? What impact do they have on the discovery of user topical pro les? And which footprints are more e ective at uncovering topical pro les?
Toward answering these questions, the rest of this paper makes the following main contributions:
· First, we formulate the problem of learning user topical proles in social media, with a focus on leveraging heterogeneous
footprints.
· Second, we demonstrate how to model di erent footprints (e.g., like interests, social, and behavioral footprints) under this framework, and we present a uni ed 2-D factorization model in which we simultaneously consider all of these footprints (called UTop).
· ird, we then extend this initial approach through a generalized model that integrates the pairwise relations across all potential footprints via a tensor-based model (called UTop+), which provides a more robust framework for user pro le learning.
· Finally, through extensive experiments, we nd the proposed UTop+ model is capable of learning high-quality user topical pro les, and leads to a 10-15% improvement in precision and mean average error versus a state-of-the-art baseline. We nd that behavioral footprints are the single strongest factor, but that intelligent integration of multiple footprints leads to the best overall performance.
2 RELATED WORK
Finding User Interests and Expertise. Finding user interests and expertise has numerous applications, and one of the most popular tasks is personalized search and recommendation. Considerable research [13, 14, 21, 33, 34, 42, 54, 56] has been dedicated to uncover users' latent interests or expertise as their personal preferences for building recommender systems in di erent domains, such as web search [34, 42], web content [56], rating systems [20, 33], and social media [14, 15, 21, 54].
For social media research, the latent factor model is a state-of-theart method for user recommendation. Interpreting the latent factors as topics, approaches based on such a model usually avoid explicitly identifying user interests but instead integrate the factors into a recommendation task. For example, Hong et al. applied matrix factorization on both users and tweets and focused on recommending user's retweeting behavior [15]. Similarly, Jiang et al. presented a probabilistic matrix factorization method to recommend whether a user adopts an item on a social network [21]. Zhong et al. collected

user's webpage views to build a matrix factorization pro le for web content recommendation [56].
Leveraging Footprints. A sequence of research has focused on using various footprints to learn user interests. One of the most traditional approaches is to model text-based footprints to obtain users' latent topical preferences, as in the case of PLSA and LDA [37, 38, 48, 53]. Another popular footprint is social (o en via friendships) [21, 32, 36], with the natural homophily assumption that friends tend to have similar pro les. In addition, behavioral footprints have become a newer factor; for example, Guy et al. used a user's tagging behavior as evidence for content recommendation [13]. Lappas et al. considered user endorsement as a behavioral signal [27]. In [54], Zhao et al. focused on the behaviors of commenting, "+1", and "like" on Google+. Some of the other footprints that have been explored in previous works include user's emotions and sentiment, geo-location, temporal context and linguistic activity. For example, Hu et al. [17, 18] proposed an unsupervised factorization approach for user sentiment analysis through emotional signals. Lu et al. [30] considered user's geographical footpints to discover what people are known-for. Yin et al. [51] proposed a probabilistic graphical method to model user's temporal interest for item recommendation. Hu et al [19] applied a factorization method to infer linguistic properties of user's documents. However, typically, these di erent footprints have been treated separately.
Factorization Models. Technically, it is challenging to embed users' heterogeneous footprints into a factorization model. A handful of studies have adopted a regularization model [29, 31, 33] for personalized recommendation, though typically focusing on only one footprint. In [20], latent spaces are learned separately for each footprint through probablisitc matrix factorization assuming they are not independent. Tensor-based factorization methods [2, 8] have been used in many applications such as behavior modeling, healthcare, and urban planning [22, 47, 55]. A more comprehensive survey of tensor factorization and its applications can be found in [24]. In contrast, we rst propose a factorization model in which we simultaneously consider multiple contexts via linearly weighted regularization. We then extend the model with a generalized tensorbased factorization so that not only di erent types of footprints can be considered together but their multi-linear interactions with each other can be exploited.
Several studies have focused on heterogeneous domains or entities, instead of contexts. Yu et al. put mutiple types of entities into a heterogeneous network and used a Bayesian ranking process to estimate user preferences [52]. Similarly, Hu et al. looked into a traditional user-item recommendation problem, presenting a factorization model across heterogeneous items. However, the network will quickly grow when users and items increase. Singh and Gordon proposed a framework to learn di erent types of relations, where they iteratively do matrix factorization between all pairs of domains [43]. Hu et al. [16] adopted the existing PARAFAC2 factorization algorithm on a tensor model, which is obtained by combining user ratings of di erent merchandises like book, music, and movie. Zhong et al. [56] directly applies a matrix factorization model on Web users and their clicked content items. However, in this work, we focus on learning user topical pro les rather than recommending item ratings for users.

744

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Personalized Tag Recommendation. Another related research line focuses on personalized tag recommendation for users in social tagging systems [9, 25, 40, 41, 45, 50]. For example, Rendle et al. [40, 41] proposed tensor factorization to suggest tags to users for annotation on di erent items. Feng et al. [9] modeled social tagging as a multi-type graph and proposed random walk with restart for tag recommendation. Konstas et al. [25] also proposed a modi ed random walk with restart by exploiting social relationships and tagging for item recommendation. Our work is di erent from personalized tag recommendation in two aspects. e rst is that we use crowdsourced tags to represent user's interests and expertise instead of annotating items in social systems. e second is that our problem is to infer users' topical pro les through tags for unknown users based on their di erent footprints rather than recommend tags based on partial knowledge of a user's pro le.

3 PRELIMINARIES
Explicit Footprints. Let U = {u1, u2, . . . , uN } be a set of users where N is the number of users, and T = {t1, t2, . . . , tM } is a set of M tags each of which is associated with a particular topic. Suppose we have a subset of users S  U where each user ui  S has been labeled with a subset of T , typically based on the collective e orts of the crowd. In this paper, we refer to such labels as explicit footprints. Practical examples of explicit footprints include LinkedIn Skill Tags and Twi er Lists, wherein users can provide a crowdsourced summary of a user's interests and expertise [4, 11, 39]. We denote the explicit footprints as the user-tag matrix P  R|S |×M in which element P(i, j) represents the number of times ui is labeled by tj .
Learning User Topical Pro les. Given a set of users U, a set of tags T , and a subset of users S  U for whom we know their user topical pro les P, the problem of Learning User Topical Pro les is the task of inferring the unknown tags from T for users in U - S.

An Initial Attempt with Explicit Footprints Only. A natural choice for a acking the challenge of learning user topical pro les is

the matrix completion approach, which has been adopted in many
related works [15, 43, 52, 56]. Under a matrix completion approach, we can extend P to a larger matrix X  RN ×M by including all users
of U. en, we can formulate the learning user topical pro les

problem as a matrix completion problem:

min
U ,V

1 2



(X

- UVT )

2 F

,

(1)

s. t. U  0, V  0,

where X is a user-tag matrix, and U  RN ×K and V  RM×K are latent representations of users and tags, respectively. K min(N , M) is the number of latent dimensions. Since the given X is naturally non-negative, we add the same constraints for U and V so that we can be er interpret the values in them.  is a non-negative matrix with the same size of X :

(i, j) = 1 if X (i, j) is observed, 0 if X (i, j) is unobserved.

e basic matrix completion model above learns an optimal set of {U , V } to approximate the original matrix X , estimating for unobserved users through observed user-tag pairs. However,

as in many linear-inverse problems, there may not be su cient information to estimate the original matrix X based only on the partially observed data. e problem of learning user topical pro les is one such case, since most of our target users do not have any partially explicit footprint.
Implicit Footprints. With the scarcity of explicit footprints in mind, we are interested to explore the potential of implicit footprints for learning unknown user topical pro les. Implicit footprints may indirectly re ect user interests or expertise. Typical implicit footprints, for example, could include user behaviors, the social circle of a user, sentiment-based features of a user's posts, the geo-location of a user, emotional cues, and temporal dynamics, among many others [13, 17­19, 21, 27, 30, 32, 36, 51, 54]. e key intuition is to identify "similar" users in terms of their topical pro les by exploiting their similarity via these implicit footprints. Since evidence from these heterogeneous implicit footprints may provide con icting evidence, potentially leading to lower quality user pro les than considering footprints in isolation, we propose a generalized optimization framework that takes into account pairwise relations among all possible implicit footprints for learning user pro les. In this way, the bene ts of each footprint may be intelligently combined to nd the best evidence across multiple implicit footprints for learning high-quality user pro les.
4 LEARNING USER TOPICAL PROFILES
We turn in this section to propose a generalized model for learning user topical pro les. We rst identify multiple implicit footprints and demonstrate how to model them. We then introduce a matrix factorization based approach -- called UTop, before extending this version to a more general tensor-based approach -- called UTop+.
4.1 Modeling Implicit Footprints
We aim to integrate many di erent kinds of implicit footprints into the framework for learning user topical pro les. For the concreteness in our discussion, we focus in this section on three speci c types of implicit footprints that capture three di erent perspectives on user topical pro les. e three footprints are: social, based on the friends (via the social graph) around the user; interest, based on the text posts made by the user; and behavioral, based on the URL sharing activities of the user. e intuition is that these varied implicit footprints can connect related users, such that user topical pro les can be propagated from user to user. But how should we model these kinds of implicit footprints? And how can we integrate them into a matrix completion model? Note that the proposed model can be easily extended to incorporate additional footprints.
Social Footprints. Social footprints -- directly suggested by homophily -- naturally indicate that connected users may share common interests, and hence can be used for inferring user topical pro les [13, 21, 32, 36]. For example, if Carol and David are following each other on Twi er, the social footprint suggests that it is more likely for them to share common interests.
ese social network connections between users can be naturally modeled as a matrix. We denote the matrix as E  RN ×N in which the binary element E(i, j) represents if user ui and user uj have a connection on a social network. We can model this social footprint

745

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

(a) Text-based Interest Footprint

(b) Behavioral Footprint

Figure 1: Examples of Di erent Implicit Footprints on Learning User Topical Pro les

as a regularization term:

L1

=

1 2

E -UUT

2 F

.

Our goal is to optimize the user latent matrix U in order to minimize L1, with the intuition that friends are likely to have similar pro les. Of course, users may form relationships in social media for many diverse reasons, and so these relationships may not be appropriate for inferring similar topical pro les. As one example, family members may be "friends" in a social network but can have distinct topical pro les (e.g., sister vs brother, grandson vs grandfather). Hence, we next consider additional implicit footprints that may serve to mitigate these challenges.

Interest Footprints. e second footprint we consider is based on user interests. Texts posted by users can semantically re ect related subjects associated with their interests or expertise. us, many studies have directly applied LDA on posted texts, assuming the (latent) topics in user's posts are their topical pro les [28, 34, 48]. In Figure 1a, Alice is a basketball fan and she has posted many tweets talking about the upcoming NBA all-star game. We nd Bob's tweets share many of the same words as Alice's. Hence, their posted texts demonstrate their shared interests in basketball, suggesting that Alice's user topical pro le may be similar to Bob's.
We can model this text-based interest footprint like so: let w = {w1, w2, . . . , wL } be the set of words, where L denotes the number of words. A  RN ×L is a user-word matrix in which A(i, j) is the frequency of word wj appearing in user ui 's posts. Similarly, B  RM×L is a tag-word matrix where B(i, j) represents the frequency of word wj posted by all users who have tag ti . We propose to leverage a user's interest footprint as the following loss function:

L2

=

1 2

A -UWT

2 F

+

1 2

B -VWT

2 F

,

where W  RL×K represents word's latent topics. Our goal is to minimize L2 so that two users who are "nearby" in the interest footprint space tend to have similar topical pro les. However, a user's posts are o en short (like on Twi er) and may contain many nonsense or o -topic texts, which can interfere with clearly

revealing user topical pro les. Hence, we next turn to a third footprint for overcoming these issues.

Behavioral Footprints. Finally, we propose to augment the so-

cial and textual footprints with behavioral footprints [13, 27, 54].

According to the homophily evidence in the behavior dimension

[35], for instance, two YouTube users may have close tastes if they

usually "like" or "dislike" the same videos. A retweet on Twi er is a

strong indication of the retweeter's personal endorsement, so two

users can have similar preferences if they o en retweet the same

tweets. Hence, these behavioral footprints may provide strong evi-

dence beyond who users are connected to (social) and what they

post (interests).

In this paper, we adopt URL sharing as a public, observable be-

havior that may serve as a rst step toward improving the learning

of user topical pro les. Other behavioral footprints are possible,

and we anticipate revisiting these in our future work. URL shar-

ing behavior for topical pro les has received some a ention in

social media research. Previous work looked into why and what

content people share via URLs in social media [3, 44]. Some other

work has mentioned the role of URL sharing in social spamming

[10]. rough URL sharing, users can concisely express their view-

points, interests, and professional expertise. For instance, a person

who works in the IT industry may usually post URLs linking to

engadget.com. A user who likes sports may o en share URLs of

espn.com. In Figure 1b, Carol is a political journalist so she regu-

larly posts some URLs linking to hu ngtonpost.com, and we see

David also usually shares the same URLs. In this case we may infer

politics-relevant tags for David.

Concretely, let Z = {z1, z2, . . . , zP } be the set of URLs posted by users. Similar to the interest footprint, we de ne C  RN ×P as a

user-URL matrix where C(i, j) is the frequency of URL zj posted by user ui . Also, D  RM×P is a tag-URL matrix with D(i, j) as
the frequency of URL zj appearing in all posts from users having

tag ti . As a result, we leverage URL sharing via the following loss function:

L3

=

1 2

C - UGT

2 F

+

1 2

D - VGT

2 F

,

746

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

where G  RP×K represents URL's latent topical spaces. Our goal
is to minimize L3, with the idea that users may have similar topical pro les if they behave similarly when posting URLs.

4.2 Learning User Topical Pro les: A 2-D

Model

Since evidence from multiple implicit footprints may provide conicting evidence, potentially leading to lower quality user pro les
than considering footprints in isolation, we turn in this section to developing a uni ed model that can integrate all possible heterogeneous footprints together into a matrix (2-D) completion model. Since all implicit footprints are modeled as regularization terms in Section 4.1, intuitively we can linearly incorporate them into the proposed UTop model. Again, recall that we focus our presentation here on those three speci c footprints (social, interest, behavioral), but the model is designed to generalize to more alternative footprints as well.
Figure 2 gives an overview of UTop. In general, we factorize each of the social, interest, and behavioral footprint matrices, and assume that the objective user-tag matrix shares the same latent user dimensions with them. is is the fundamental assumption in most factorization-based methods for solving matrix completion problems. We also consider explicit footprints. Similarly, we collect each tag's latent representation, and multiply them with each user's latent factor for estimating the objective matrix.
Concretely, we formulate the following optimization problem as following:

min
U ,V ,W ,G

F

=

1 2



(X

- UVT )

2 F

+

 2

(

A -UWT

2 F

+

B -VWT

2 F

)

+

 (
2

C

- UGT

2 F

+

D - VGT

2 F

)

(2)

+

 2

E -UUT

2 F

+

( 2

U

2 F

+

V

2 F

+

W

2 F

+

G

2 F

)

s. t. U  0, V  0,W  0, G  0,

where ,  ,  and  are positive regularization parameters con-

trolling the contributions of di erent implicit footprints.

U

2 F

,

V

2 F

,

W

2 F

and

G

2 F

are

deployed

to

avoid

over

ing. Similar

to Equation 1, we insert the non-negative constraints for U , V , W ,

and G.

e derivation of the objective function in Eq.(2) regarding four

variables U , V , W and G are demonstrated as:

F U

=-



(X - UV T )V - (A - UW T )

-  (C - U GT ) - 2 (E - U U T ) + U ,

F V

= - T

T

(XT - VU T )U - (B - VW T )

-  (D - V GT ) + V ,

(3)

F W

= - (AT - W U T )U - (BT - W V T )V + W ,

F G

= -  (CT

- GU T )U

-  (DT

- GV T )V

+ G.

Tags

Latent Dim.

Latent Dim.

User User Tag

User

Textual

Latent Dim. Latent Dim.

Words User

Social

Latent Dim. Latent Dim.

User User

Behaviors

Latent Dim. Latent Dim.

Tag

Tag

Tag URL

Textual

Latent Dim. Latent Dim.

Tag Words

Behaviors

Latent Dim. Latent Dim.

User

URL User

User

User Information

Tag Information

Figure 2: An Overview of the 2-D Model (UTop)
Based upon these derivations, we then apply stochastic gradient descent to iteratively update each variable by taking a step  along its gradient ascending. e algorithm details are presented in Algorithm 1 in which learning steps u ,  , w and  are chosen based upon the Goldstein Conditions [12]. We implement the nonnegative constraints on U and V through forcing their negative values to 0 in each iteration. As shown, this algorithm considers all three footprints together to estimate the topical pro les for each user.

Algorithm 1: UTop Solver

Input: user-tag matrix X , user-word matrix A, tag-word

matrix B, user-url matrix C, tag-url matrix D, user

friendship matrix E, observation indication matrix 

and parameters {,  , , , }

Output: U , V

1 Initialize U , V , W and G randomly, t = 0

2 while Not Converged do

3

Compute

F U

,

F V

,

F W

and

F G

in Eq.(3)

4

Update

Ut +1



max(Ut

- u

F U

,

0)

5

Update Vt +1  max(Vt - 

F U

,

0)

6

Update Wt +1



max(Wt

- w

F U

,

0)

7

Update Gt +1  max(Gt - 

F U

,

0)

8 t =t +1

9 return U and V

ough unifying all three heterogeneous implicit footprints, this initial UTop approach has two main drawbacks. First, it will become complex if we introduce additional footprints, as we bring in more controlling parameters of new footprints to be tuned. In addition,

747

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

UTop does not take into account the relations between those heterogeneous footprints which could be jointly explored in the latent space. Given these concerns, can we nd a generalized model that can jointly leverage all potential heterogeneous footprints? We turn in the following section to answering this question.
4.3 Learning User Topical Pro les: A
Generalized Model
In this section, we augment UTop with a generalized approach toward jointly exploring the relationships across footprints for more robust user topical pro le learning. First, to relieve the dramatic increase of parameters when introducing more regularization terms, we need to replace the linear combination model in UTop by a more compact factorization model without manually tuning tradeo parameters from di erent new footprints. Second, such a compact factorization model should consider all possible pairwise interactions between footprints to exploit their multi-linear relationships.
erefore, we adopt a tensor factorization model which explicitly takes into account the multi-way structure of data. Moreover, the factorization will only happen once even if we introduce additional heterogeneous footprints.
Figure 3 shows an overview of UTop+. In general, we model all implicit footprints in one tensor via calculating the user similarity in each footprint space. ere can be many options for measuring the user similarity in every footprint space. We test many of them and report the one providing the best performance in Section 5. en, we factorize the tensor and obtain a matrix of latent representations for all users, upon which we extract a user similarity matrix to estimate the original user-tag matrix.

Behaviors Social Textual

Calculate Similarity

User

User

User

User-Tag Matrix

User Similarity Matrix

Latent Dimensions

User

Figure 3: An Overview of the Generalized Model (UTop+)
Concretely, we denote the tensor as C  RN ×N ×R which is a multidimensional array where R is the number of implicit footprints and N is the size of the user set. We can factorize the tensor C to one latent user matrices Q  RN ×K and one latent context matrix Y  RR×K , where K is the number of latent dimensions. e tensor

factorization is to solve the optimization problem de ned below:

min
Q,Y

1 2

C - [[Q, Q, Y ]]

2 F

+

 (
2

Q

2 F

+

Y

2 F

),

(4)

where [[Q, Q, Y ]]  RN ×N ×R is given by

K
[[Q, Q, Y ]] = qk  qk  k .
k =1

Here qk and k are the kth column vectors of Q and Y , respectively. To solve Eq.(4), we adopt the existing CPOPT method [1] -- a ing approach for the CP (Canonical-decomposition / Parallelfactor-analysis (PARAFAC)) model. e latent footprint matrix Y represents the contribution of each type of footprint to latent dimensions.
e next natural question is how to leverage the new latent space Q of all users. e basic idea is that two users tend to have similar topical pro les if they have similar latent representations derived by jointly considering all their implicit footprints. us, we rst calculate the user similarity matrix denoted as  computed from latent features of users Q by the cosine similarity. We can see Q as a "new footprint" and formulate it as the new loss function:



=

1 2

i, j

(i, j)

Ui - Uj

2

= Ui (i, j)UiT - Ui (i, j)UjT

i, j

i, j

= Ui D(i, i)UiT - Ui (i, j)UjT

(5)

i

i, j

= tr(U T (D - )U )

= tr(U T LU ),

where Ui is the ith row of U , tr (· ) denotes the matrix trace, and D is a diagonal matrix in which D(i, i) = j (i, j), and L = D -  is the graph Laplacian of the user similarity matrix .
How can we utilize the new implicit footprint  to learn user topical pro les? Similarly, we are able to use  to regulate latent representations of two similar users to make them as close as possible. Hence, we can build the generalized UTop+ by solving the following optimization problem:

min
U ,V

1 2



(X

- UVT )

2 F

+

 2

tr(U

T

LU

)

+

 2

(

U

2 F

+

V

2 F

),

(6)

s. t. U  0, V  0,

where  is the controlling parameter. is optimization problem can be solved similarly as introduced in Section 4.2. e detailed solver is presented in Algorithm 2.
In summary, we rst present a 2-D model for learning user topical pro les (called UTop) in which each of three heterogeneous implicit footprints is modeled as regularization terms. We provide Algorithm 1 to solve the optimization problem in Equation 2. en we extend UTop to a compact generalized model (called UTop+). Based on a tensor decomposition method, UTop+ can jointly handle relationships across multiple footprints without introducing new

748

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Algorithm 2: UTop+ Solver

Input: user-tag matrix X , user-word matrix A, user-url matrix

C, user friendship matrix E, observation indication

matrix  and parameters {, , u ,  } Output: U , V

1 Calculate the tensor C from A, C and E

2 Calculate [Q, Y ]  CPOPT(C)

3 Calculate the user similarity matrix  based on Q

4 Construct the graph Laplacian matrix L for 

5 Initialize U and V , randomly, t = 0

6 while Not Converged do

7

Compute

F U

= -(

)(X - UV T ))V + LU

8

Compute

F V

= -(T

T )(XT - VU T ))U

9

Update Ut +1



max(Ut

-

u

F U

,

0)

10

Update Vt +1  max(Vt - 

F U

,

0)

11 t = t + 1

12 return U and V

parameters. e complete overview of UTop+ is shown in Figure 3, and we propose Algorithm 2 to solve Equation 6.
5 EXPERIMENTS
In this section, we conduct a series of experiments to answer the following questions: (i) How well do the proposed UTop and UTop+ models work? (ii) Which implicit footprints are most e ective? (iii) How does UTop+ compare with other alternatives? Does it really improve upon the simpler UTop approach? (iv) How do the proposed approaches compare to other variants?; and (v) What impact do the model parameters have on the ultimate performance? We begin by introducing the experimental setup including dataset collection and evaluation method.
5.1 Experiment Setup
In this section, we start with describing the data we collect. Next, we introduce the metrics we use for evaluation. Finally, we provide the details of three baselines, and show the parameter se ings we choose in our proposed models.
Twitter Lists. We adopt Twi er Lists, a large publicly-accessible collection of crowd-contributed tagging knowledge for social media users. Recall that these lists allow one user to annotate another with a list name (or tag), e.g., politics, music, art. Via the public Twi er API, we randomly sample a set of 3.468 million Twi er users, and crawl the list membership information for each of them. We identify 977,000 users who have ever been included in some list, but we nd a huge amount of noise. For instance, nonsense tags (like numbers, unicode characters, single le ers) take up a major proportion. Many tags (e.g., "friend", "love", and "amigo") are not re ective of topical pro les. Also, there exist many near-synonyms and variants such as "writer-author" and "news-noticia". To obtain high-quality tags for our problem, we rank all tags by the number of labeled users, and manually curate the top-500 tags through merging variants and ltering noise.

Implicit Footprints. For interest footprints, we aggregate all terms each user has posted and adopt the standard LDA topic model a er ltering stopwords and stemming. We further measure user similarity by calculating the pairwise Jensen-Shannon divergence. For social footprints, we crawl the friendship connection information for each user. Following a user can be quite casual on Twi er, so we focus on mutual followings as the basis of user similarity in the social footprint space. For behavioral footprints, we aggregate all URLs a user has posted in her tweets and obtain the posting counts. We resolve all crawled URLs (most are shortened) to take care of URL variants, and focus on the URL domain name which conceptually represents a website. For quantifying similar URL sharing pa erns, we test a set of measurements (e.g., intersection, cosine, jaccard) and nd the one in [6] works best.
Users. We collect a set of 72,096 users who have all those three types of implicit footprints and have been labeled by at least one of the candidate tags. Since many of them have sparse tagging information, we rank all users by the number of tags they have. We look into the top 50,000 users, and randomly select 10,000 users for training and evaluation.
In our proposed models, we end up with scores of all candidate tags for each user. Since we should take those most associated tags as user topical pro les, we rank them in descending order and focus on the top-k ranked tags. Our evaluation is based on ten-fold cross validation.
Metrics. We pick several metrics which can cover di erent evaluation aspects. On the one side, we would like to see the ratio of correct inferences for learning user topical pro les. And on the other side, we want to measure the prediction error. us, we adopt precision@k which measures the percentage of correctly estimated top-k tags, and Mean Absolute Error (MAE) which quanti es the prediction quality in terms of errors. Note that a lower MAE means a be er performance.
Furthermore, besides the absolute measurement in accuracy, the relative ranking order is another important perspective, especially in some recommendation scenarios. e rank correlation coef-
cients of both Kendall's  and Spearman's  are two prevalent metrics for measuring rank-based agreement across two lists. We use them both to measure the number of pairs of tags that are correctly ordered from our results. eir values both range from -1 to 1, with the higher the more relevant.
Baselines. We select three baselines as alternatives to the proposed UTop+ approach. To be fair, we incorporate all three proposed footprints and maintain the same experimental setup for all the following approaches:
· Nearest Neighborhood (NN). An intuitive solution is based on the traditional nearest neighborhood model. A user is modeled by a vector extracting from the corresponding row in the context matrix, i.e., A, C, or E. en, for each target user, we separately nd a set of closest seed users in each context, and pick the intersected neighbors from whom we propagate their tags and scores and take the average for each tag.
· Cross-domain Triadic Factorization (CTF) [16]. is stateof-the-art method directly combines user ratings of di erent merchandise (e.g., book, music, movie) into one tensor model,

749

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: e Impact of Di erent Implicit Footprints for Learning User Topical Pro les

Method
NN (T) NN (S) NN (B) UTop (T) UTop (S) UTop (B) UTop (T+S) UTop (T+B) UTop (S+B) UTop (T+S+B)

Precision

Top 5 Top 10 Top 15

0.2113 0.1920 0.2423 0.3438 0.3390 0.3556 0.3494 0.3587 0.3544

0.2356 0.2153 0.2629 0.3791 0.3837 0.3980 0.3847 0.4132 0.4069

0.2673 0.2330 0.3155 0.4668 0.4561 0.4733 0.4657 0.4758 0.4729

0.3616 0.4189 0.4931

Top 5
0.2914 0.3048 0.2650 0.2264 0.2298 0.2275 0.2300 0.2193 0.2238 0.2137

MAE
Top 10
0.2692 0.2791 0.2342 0.2069 0.2093 0.1982 0.2107 0.1894 0.1930 0.1861

Top 15
0.2432 0.2642 0.2110 0.1897 0.1887 0.1699 0.1872 0.1909 0.1852 0.1772

Kendall's 

Top 5 Top 10 Top 15

0.2460 0.2110 0.2826 0.3221 0.3172 0.3286 0.3205 0.3329 0.3272

0.1687 0.1420 0.2044 0.2464 0.2421 0.2557 0.2516 0.2606 0.2588

0.1531 0.1289 0.1834 0.2031 0.2003 0.2067 0.2085 0.2197 0.2185

0.3403 0.2746 0.2267

Spearman's 

Top 5 Top 10 Top 15

0.3054 0.2670 0.3314 0.4163 0.4135 0.4302 0.4189 0.4348 0.4322

0.2262 0.1852 0.2429 0.2987 0.2916 0.3015 0.2970 0.3071 0.3054

0.1784 0.1682 0.2106 0.2409 0.2341 0.2426 0.2378 0.2535 0.2561

0.4414 0.3104 0.2682

in which all the values are user ratings. en, it extends the existing PARAFAC2 model [23] that transforms heterogeneous user-rating matrices of di erent lengths into one cubical tensor and factorizes it. Here in our problem se ing, this approach can also be applied on those heterogeneous user-footprint matrices; the subsequent steps follow Equation 5 in order to solve Equation 6.
· UTop. Introduced in Section 4.2, this model is a basic version that considers each footprint as a regularization term and linearly adds them together.
Parameter Settings. To determine the number of latent dimensions in both UTop and UTop+, we experiment with a sequence of se ings {5, 10, 20, 30, 40, 50, 100} and empirically select 20 for both UTop and UTop+, as a trade-o between accuracy and e ciency. In Algorithm 1, there are ve parameters ,  ,  , , and . e rst four parameters are used to control the contributions of various footprints. e last one is a step along its gradient ascending. As is commonly done, we iteratively employ cross-validation to tune these parameters. Speci cally, we empirically set  = 0.02,  = 0.7,  = 0.1,  = 0.4 and  = 0.05 for general experiments, respectively. In UTop+, we choose 10 for the number of latent dimension in tensor factorization. e step size  is set to 0.05. In addition, two positive parameters  and  in Eq. (6) are involved in the experiments. Concretely, we empirically set  = 0.3 and  = 0.02 via cross-validation.
5.2 e Impact of Di erent Footprints
In general, interest, social, and behavioral footprints have di erent emphases on user topical pro les. Hence, which footprints work be er (or best) is one of the most compelling questions to answer. Hence, we compare di erent combinations of all footprints in both NN and UTop. e reason we do not test them in UTop+ is that the multi-way manner of UTop+ may not clearly tell which footprint contributes more. We show the results in Table 1 in which T is for text-based interest, S is for social, and B is for behavioral.
When individually using each implicit footprint, we nd the behavioral footprint (URL sharing) always performs the best in any se ing. Moreover, combining it with other footprints always bring the biggest improvement in these experiments. For instance, within the NN method, the behavioral footprint has up to 24% larger Spearman correlation than the social footprint. In UTop, the MAE@10

decreases by 8% when the behavioral footprint is added with the interest footprint. ese results indicate the importance of capturing actual user behaviors as a critical step for identifying user topical pro les (in contrast, to relying purely on social connections or on the content of what users post). ese results support the intuition that social footprints may capture spurious user similarities (e.g., linking two very di erent users) and that text-based interest footprints may insert noise into learning user topical pro les. In contrast, behavioral cues provide a clearer perspective on user's interests and expertise.
What if behavioral data is scarce? URL sharing is one of the few publicly-available sources of behavioral information, but sometimes it can still be a scarce resource because not all users will share many URLs on social media. In contrast, social and interest-based footprints are typically more universally available. We see in Table 1 that interest and social footprints can still work well even without access to behavioral footprints. For example, in UTop, the interest footprint is only 5% behind behavioral in precision@10, and the social footprint has just 1% larger MAE@5 than behavioral.
ese observations show that our model can still achieve a good performance even when we have scarce behavioral evidence. But that together, the three di erent footprints can complement each other, leading to even be er user topical pro les.
5.3 Evaluating UTop and UTop+
Given the evidence of the importance of di erent footprints, we now turn to evaluating the two proposed models -- UTop and UTop+ -- versus alternatives. As we can see in Figure 4, both UTop and UTop+ perform be er than the Nearest Neighbor (NN) and the Cross-domain Triadic Factorization (CTF) across all four evaluation metrics. For precision@5, UTop+ is 36% and 13% be er than NN and CTF with p-values of 0.001 and 0.003 under McNemar's test, respectively. For MAE@10, UTop+ outperforms NN by 20% with the p-value of 0.002 and CTF by 11.8% with the p-value of 0.001. e gaps become even larger for the two ranking correlation coe cients, as we can see in Figure 4c and 4d. ese results suggest that the proposed learning models can be er leverage all footprints together than either the neighborhood-based propagation or the immediate tensor decomposition. Note that the CTF method is fundamentally di erent from our problem se ing where we cannot simply put together all heterogeneous footprints. In contrast, we exploit latent factors to build a user similar matrix and nd its graph Laplacian as

750

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Precision MAE
Kendall Spearman

0.5

0.4

0.3

0.2

0.1

0 Top-5

Top-10

(a) Precision

0.3

NN

0.2

CTF

UTop

UTop+

0.1

0.5

0.4

NN

0.3

CTF

UTop UTop+

0.2

0.1

0.6

NN

0.4

CTF

UTop

UTop+ 0.2

NN CTF UTop UTop+

0 Top-5

Top-10

0 Top-5

Top-10

0 Top-5

Top-10

(b) MAE

(c) Kendall's 

(d) Spearman's 

Figure 4: Comparisons Between Proposed Models and Alternative Baselines

a new regularization term. We show the e ectiveness of this step in Section 5.4.
Recall that we introduced UTop+ as an extension to UTop to provide a more compact factorization and to jointly handle relationships across multiple implicit footprints. In Figure 4 we nd UTop+ surpasses UTop in all se ings. UTop+ has an improvement of 4.2% in precision@10, 3% in MAE@5, 5.9% in Kendall correlation@10, and 3.8% in Spearman correlation@5. ese ndings indicate that the proposed UTop+ can be er exploit the joint correlations between all heterogeneous footprints for improved learning of user topical pro les. All these nding are conducted under McNemar's test with p-values less than 0.01.

5.4 Considering Other Variants

Why We Need Regularization? A natural question is why we

need a regularization model. Why not just put all footprints into one

large matrix and directly apply state-of-the-art matrix factorization

methods? To investigate this question, we put them into one matrix

upon which we adopt the standard factorization technique, where

we denote such a method MF. We do normalization for the data of

each footprint since their values can have distinct scales. We follow

the same evaluation methodology and show the comparisons in

Figure 5. All results are measured at the top-10. We clearly see the

proposed UTop results in be er performances than MF in every

metric. ese results suggest that heterogeneous footprints require

careful integration, and that the proposed UTop approach is a good

solution in comparison.

0.5

MF

0.4

UTop

0.3

0.2

0.1

0 Precision MAE Kendall Spearman

Figure 5: Comparisons Between UTop and Standard MF
Why We Do Regularization A er Tensor Factorization? In UTop+, a er having the latent factors of users from tensor factorization, we build a user similar matrix and nd its graph Laplacian as the new regularization term. Why not just directly replace the user's latent matrix U in X a er factorizing the tensor? We call such a scheme Tensor Factorization-based Matrix Factorization (TFMF), and we show the comparison results in Figure 6 for all

0.5

TFMF

0.4

UTop+

0.3

0.2

0.1

0 Precision MAE Kendall Spearman

Figure 6: Comparisons between UTop+ and TFMF
metrics at top 10. Our UTop+ outperforms TFMF in all se ings (e.g., 68% precison, 38% MAE, 45% Kendall correlation). ese outcomes show that regularization a er tensor factorization can signi cantly improve the performance.

Precision@10 Kendall 

0.46

0.44

0.42

0.4

0.38

0.36

0.34 0.001

0.01

0.1

1

1

0.1

0.01 10 0.001





0.35 0.3 0.25 0.2

0.001

0.01

10

0.1

1

10 1 0.1 0.01

10 0.001





(a) Precision@10

(b) Kendall's 

Figure 7: Impact of  and  on UTop+

Impact of Parameters. Finally, two critical parameters in UTop+ are  and . Recall that  is used to avoid over ing;  is to control the contribution of the user similarity derived from three types of footprints. In order to be er understand the impacts of these two parameters, we evaluate the performance of UTop+ across various parameter se ings. We vary values of these parameters in [0.001 0.01, 0.1, 1, 10] and present the results of precision and Kendall's  in Figure 7 for learning the top-10 tags. As we can see, UTop+ achieves relatively consistent performance across a wide range. Particularly, we nd the se ing  = 0.1 and  = 0.01 gives the best performance. ese results indicate the stability of UTop+ to these parameters.

6 CONCLUSION
Mining user's topical pro les (e.g., user interests and expertise) has important applications in diverse domains such as personalized search and recommendation, as well as expert detection. In this

751

Session 7A: Social

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

paper, we tackled the problem of learning user topical pro les. In particular, we investigated how to leverage user-generated information in heterogeneous and diverse footprints. Concretely, we proposed UTop+ -- a generalized model that integrates multiple implicit footprints with explicit footprints for learning high-quality user topical pro les. By taking into account pairwise relations among multiple footprints, the proposed UTop+ intelligently combines the potential bene ts of each footprint to nd the best evidence across footprints for learning high-quality user pro les. And indeed, extensive experiments demonstrate the e ectiveness of UTop+. For instance, it surpasses other alternatives up to 36% in precision@5 and 20% in MAE@10. URL sharing, as one type of publicly-accessible user behavior, brings be er results than other implicit footprints in every evaluation se ing. Moreover, compared with other variants in terms of modeling, our model also has the best performances, e.g., up to 68% for precision@10 and Kendall correlation@10.
ACKNOWLEDGMENTS
is work was supported in part by NSF grants IIS-1149383 and IIS-1657196. Any opinions, ndings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily re ect those of the sponsors.
REFERENCES
[1] E. Acar, D. M. Dunlavy, and T. G. Kolda. A scalable optimization approach for ing canonical tensor decompositions. Journal of Chemometrics, 25(2):67­86,
February 2011. [2] A. Anandkumar, R. Ge, D. Hsu, S. M. Kakade, and M. Telgarsky. Tensor decom-
positions for learning latent variable models. JMLR, 2014. [3] E. Bakshy, I. Rosenn, C. Marlow, and L. Adamic. e role of social networks in
information di usion. In WWW, 2012. [4] P. Bha acharya, S. Ghosh, J. Kulshrestha, M. Mondal, M. B. Zafar, N. Ganguly,
and K. P. Gummadi. Deep twi er diving: Exploring topical groups in microblogs at scale. In CSCW, 2014. [5] J. Bollen, B. Gon¸calves, G. Ruan, and H. Mao. Happiness is assortative in online social networks. Arti cial life, 2011. [6] C. Cao, J. Caverlee, K. Lee, H. Ge, and J. Chung. Organic or organized?: Exploring url sharing behavior. In CIKM, 2015. [7] D. Centola. An experimental study of homophily in the adoption of health behavior. Science, 2011. [8] L. De Lathauwer, B. De Moor, and J. Vandewalle. A multilinear singular value decomposition. SIMAX, 2000. [9] W. Feng and J. Wang. Incorporating heterogeneous information for personalized tag recommendation in social tagging systems. In SIGKDD, 2012. [10] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and characterizing social spam campaigns. In SIGCOMM, 2010. [11] S. Ghosh, N. Sharma, F. Benevenuto, N. Ganguly, and K. Gummadi. Cognos: crowdsourcing search for topic experts in microblogs. In SIGIR, 2012. [12] A. A. Goldstein. Constructive real analysis. Courier Corporation, 2013. [13] I. Guy, N. Zwerdling, I. Ronen, D. Carmel, and E. Uziel. Social media recommendation based on people and tags. In SIGIR, 2010. [14] J. Hannon, M. Benne , and B. Smyth. Recommending twi er users to follow using content and collaborative ltering approaches. In RecSys, 2010. [15] L. Hong, A. S. Doumith, and B. D. Davison. Co-factorization machines: modeling user interests and predicting individual decisions in twi er. In WSDM, 2013. [16] L. Hu, J. Cao, G. Xu, L. Cao, Z. Gu, and C. Zhu. Personalized recommendation via cross-domain triadic factorization. In WWW, 2013. [17] X. Hu, J. Tang, H. Gao, and H. Liu. Unsupervised sentiment analysis with emotional signals. In WWW, 2013. [18] X. Hu, L. Tang, J. Tang, and H. Liu. Exploiting social relations for sentiment analysis in microblogging. In WSDM, 2013. [19] Y. Hu, K. Talamadupula, S. Kambhampati, et al. Dude, srsly?: e surprisingly formal nature of twi er's language. In ICWSM, 2013. [20] M. Jamali and L. Lakshmanan. Heteromf: recommendation in heterogeneous information networks using context dependent factor models. In WWW, 2013. [21] M. Jiang, P. Cui, R. Liu, Q. Yang, F. Wang, W. Zhu, and S. Yang. Social contextual recommendation. In CIKM, 2012.

[22] M. Jiang, P. Cui, F. Wang, X. Xu, W. Zhu, and S. Yang. Fema: Flexible evolutionary multi-faceted analysis for dynamic behavioral pa ern discovery. In SIGKDD, 2014.
[23] H. A. Kiers, J. M. Ten Berge, and R. Bro. Parafac2-part i. a direct ing algorithm for the parafac2 model. Journal of Chemometrics, 13(3-4):275­294, 1999.
[24] T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM review, 2009.
[25] I. Konstas, V. Stathopoulos, and J. M. Jose. On social networks and collaborative recommendation. In SIGIR, 2009.
[26] H. Kwak, C. Lee, H. Park, and S. Moon. What is twi er, a social network or a news media? In WWW, 2010.
[27] T. Lappas, K. Punera, and T. Sarlos. Mining tags using social endorsement networks. In SIGIR, 2011.
[28] Q. Liu, E. Chen, H. Xiong, C. H. Ding, and J. Chen. Enhancing collaborative ltering by user interest expansion via personalized ranking. IEEE SMC, 2012.
[29] X. Liu and K. Aberer. Soco: a social network aided context-aware recommender system. In WWW, 2013.
[30] H. Lu, J. Caverlee, and W. Niu. Discovering what you're known for: A contextual poisson factorization approach. In RecSys, 2016.
[31] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. Exploiting social context for review quality prediction. In WWW, 2010.
[32] H. Ma. On measuring social friend interest similarities in recommender systems. In SIGIR, 2014.
[33] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King. Recommender systems with social regularization. In WSDM, 2011.
[34] A. Majumder and N. Shrivastava. Know your personalization: learning topic level personalization in online services. In WWW, 2013.
[35] M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds of a feather: Homophily in social networks. Annual Review of Sociology, 2001.
[36] A. Mislove, B. Viswanath, K. P. Gummadi, and P. Druschel. You are who you know: inferring user pro les in online social networks. In WSDM, 2010.
[37] R. O oni, D. Las Casas, J. P. Pesce, W. Meira Jr, C. Wilson, A. Mislove, and V. Almeida. Of pins and tweets: Investigating how users behave across imageand text-based social networks. ICWSM, 2014.
[38] M. Qiu, F. Zhu, and J. Jiang. It is not just what we say, but how we say them: Lda-based behavior-topic model. In SDM, 2013.
[39] V. Rakesh, D. Singh, B. Vinzamuri, and C. K. Reddy. Personalized recommendation of twi er lists using content and network information. In AAAI, 2014.
[40] S. Rendle, L. Balby Marinho, A. Nanopoulos, and L. Schmidt- ieme. Learning optimal ranking with tensor factorization for tag recommendation. In SIGKDD, 2009.
[41] S. Rendle and L. Schmidt- ieme. Pairwise interaction tensor factorization for personalized tag recommendation. In WSDM, 2010.
[42] A. Sieg, B. Mobasher, and R. Burke. Web search personalization with ontological user pro les. In CIKM, 2007.
[43] A. P. Singh and G. J. Gordon. Relational learning via collective matrix factorization. In SIGKDD, 2008.
[44] B. Suh, L. Hong, P. Pirolli, and E. H. Chi. Want to be retweeted? large scale analytics on factors impacting retweet in twi er network. In SocialCom, 2010.
[45] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. Tag recommendations based on tensor dimensionality reduction. In RecSys, 2008.
[46] J. Tang, Y. Chang, and H. Liu. Mining social media with social theories: a survey. SIGKDD Explorations Newsle er, 2014.
[47] Y. Wang, R. Chen, J. Ghosh, J. C. Denny, A. Kho, Y. Chen, B. A. Malin, and J. Sun. Rubik: Knowledge guided tensor factorization and completion for health data analytics. In SIGKDD, 2015.
[48] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twi errank: nding topic-sensitive in uential twi erers. In WSDM, 2010.
[49] R. Xiang, J. Neville, and M. Rogati. Modeling relationship strength in online social networks. In WWW, 2010.
[50] D. Yin, Z. Xue, L. Hong, and B. D. Davison. A probabilistic model for personalized tag prediction. In SIGKDD, 2010.
[51] H. Yin, B. Cui, L. Chen, Z. Hu, and Z. Huang. A temporal context-aware model for user behavior modeling in social media systems. In SIGMOD, 2014.
[52] X. Yu, X. Ren, Y. Sun, Q. Gu, B. Sturt, U. Khandelwal, B. Norick, and J. Han. Personalized entity recommendation: A heterogeneous information network approach. In WSDM, 2014.
[53] X. Zhang, J. Cheng, T. Yuan, B. Niu, and H. Lu. Toprec: domain-speci c recommendation through community topic mining in social network. In WWW, 2013.
[54] Z. Zhao, Z. Cheng, L. Hong, and E. H. Chi. Improving user topic interest pro les by behavior factorization. In WWW, 2015.
[55] Y. Zheng, L. Capra, O. Wolfson, and H. Yang. Urban computing: concepts, methodologies, and applications. TIST, 2014.
[56] E. Zhong, N. Liu, Y. Shi, and S. Rajan. Building discriminative user pro les for large-scale content recommendation. In SIGKDD, 2015.

752

