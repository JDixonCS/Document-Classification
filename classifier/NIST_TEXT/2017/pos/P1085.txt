Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Term Proximity Constraints for Pseudo-Relevance Feedback

Ali Montazeralghaem
School of ECE, College of Engineering University of Tehran, Iran ali.montazer@ut.ac.ir

Hamed Zamani
Center for Intelligent Information Retrieval,
University of Massachuse s Amherst zamani@cs.umass.edu

Azadeh Shakery
School of ECE, College of Engineering University of Tehran, Iran
School of Computer Science, Institute for Research in Fundamental Sciences
shakery@ut.ac.ir

ABSTRACT
Pseudo-relevance feedback (PRF) refers to a query expansion strategy based on top-retrieved documents, which has been shown to be highly e ective in many retrieval models. Previous work has introduced a set of constraints (axioms) that should be satis ed by any PRF model. In this paper, we propose three additional constraints based on the proximity of feedback terms to the query terms in the feedback documents. As a case study, we consider the log-logistic model, a state-of-the-art PRF model that has been proven to be a successful method in satisfying the existing PRF constraints, and show that it does not satisfy the proposed constraints. We further modify the log-logistic model based on the proposed proximity-based constraints. Experiments on four TREC collections demonstrate the e ectiveness of the proposed constraints. Our modi cation to the log-logistic model leads to signi cant and substantial (up to 15%) improvements. Furthermore, we show that the proposed proximity-based function outperforms the well-known Gaussian kernel which does not satisfy all the proposed constraints.
KEYWORDS
Term proximity, term position, axiomatic analysis, pseudo-relevance feedback, query expansion
ACM Reference format: Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Term Proximity Constraints for Pseudo-Relevance Feedback. In Proceedings of SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages. DOI: 10.1145/3077136.3080728
1 INTRODUCTION
Pseudo-relevance feedback (PRF) is a query expansion strategy to address the vocabulary mismatch problem in information retrieval (IR). In PRF, a small set of top-retrieved documents (i.e., pseudo-relevant documents) are assumed to be relevant to the initial query. ese pseudo-relevant documents are further used for updating the query model in order to improve the retrieval performance. PRF has been proven to be highly e ective in many retrieval models [2, 10, 13, 14].
eoretical analysis of PRF models has shown that there are several constraints (axioms) that every PRF model should satisfy. Based
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: 10.1145/3077136.3080728

on these theoretical studies, several modi cations, e.g., [1, 3, 9, 10], have been made to the existing PRF models which lead to signi cant improvements in the retrieval performance. Although term proximity has been shown to be a strong evidence for improving the retrieval performance [5, 12], especially in the PRF task [6­8], none of the existing constraints for PRF takes term proximity into account.1
In this paper, we provide a theoretical analysis for the use of term proximity in PRF models. To do so, we introduce three PRF constraints based on the proximity of candidate feedback terms and the query terms in the feedback documents. According to the rst constraint ("proximity e ect"), the candidate feedback terms that are positionally closer to the query terms in the feedback documents should be given higher weights in the feedback model. e second constraint ("convexity e ect") decreases the e ect of term proximity when the distance between terms increases. e third constraint indicates that proximity to the less common query terms is more important than proximity to the query terms that are general.
Furthermore, previous work on leveraging term proximity for IR tasks, including the positional relevance model, showed that the Gaussian kernel is an e ective way for enhancing IR models with term proximity information [5, 6, 8]. In this paper, we show that the Gaussian kernel does not satisfy all the proposed constraints, and thus it could not be the best way for applying term proximity to PRF models.
e primary contributions of this work can be summarized as follows:
· Introducing three proximity-based constraints for theoretical analysis of PRF models.
· Studying and modifying the log-logistic feedback model [2], a state-of-the-art PRF model that outperforms many existing models, including the mixture model [14] and the geometric relevance model [11] (see [3] for more details).
· Introducing a variant of the Exponential kernel that satis es all the proposed constraints.
· Evaluating our models using four TREC collections which demonstrates signi cant improvements over the original log-logistic model as well as the model enriched with the Gaussian kernel, a widely used weighting function for enhancing IR models using term proximity [5, 6, 8].
2 METHODOLOGY
In this section, we rst introduce three proximity-based constraints that (pseudo-) relevance feedback methods should satisfy. We further analyze the log-logistic model [2], and show that this model
1Tao and Zhai [12] proposed two proximity-based constraints for retrieval models, but not for PRF models.

1085

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

does not satisfy the proposed constraints. We nally modify the log-logistic feedback model in order to satisfy all the constraints.
We rst introduce our notation. Let FW (w; F , Pw , Q) denote the feedback weight function that assigns a real-valued weight to each feedback term w for a given query Q based on the feedback document set F . Pw is a set of term-dependent parameters. For simplicity, FW (w) is henceforth used as the feedback weight function. In the following equations, T F and I DF are term frequency and inverse document frequency, respectively. | · | represents the size of the given set.
2.1 Constraints
In this subsection, we introduce three proximity-based constraints for PRF methods.
[Proximity e ect] Let d(w, q, D) denote the proximity weight of a candidate feedback term w and a given query term q in a feedback document D. en, the following constraint should hold:

FW (w) d(w, q, D)

<

0

According to this constraint, the candidate feedback terms that are closer to the query terms in the feedback documents should have higher weights. Intuitively, the closer terms to the query terms are more likely to be relevant to the query.
[Convexity e ect] e feedback weight function should be convex with respect to the distance of candidate feedback terms from the query terms. We can formalize this constraint as follows:

2FW (w) d(w, q, D)2

>0

e intuition behind this constraint is that decreasing the e ect of
the proximity e ect should be less marked in high distance ranges.
[ ery IDF e ect] Let Q = {q1, q2} be a query with two query terms q1 and q2. Let D1 and D2 denote two feedback documents with equal length, such that q1 only appears in D1, and q2 only appears in D2. Let w1 and w2 be two candidate feedback terms, such that T F (w1, D1) = T F (w2, D2), and w1 and w2 only appear in D1 and D2 in the feedback set, respectively. Also assume that d(w1, q1, D1) = d(w2, q2, D2) where d is the function to compute the proximity between two terms in a given document. We can say
if I DF (q1) > I DF (q2), then we should have:

FW (w1) > FW (w2)

Intuitively, this constraint indicates that proximity to the query terms that are general is less important than proximity to the uncommon query terms. For instance, if a query contains a general term (let say a stopword) then proximity to this term should be less important than the discriminative terms that occur in the query.

2.2 Modifying the Log-Logistic Model
As a case study, we analyze and modify the log-logistic feedback model [2]. e reason is that this method has been shown to outperform many strong baselines, including the mixture model [14] and the geometric relevance model [11]. It has been also shown that this method successfully satis es all the PRF constraints proposed in [3]. e log-logistic feedback weight function for each term w is

computed as:

FW (w)

=

1 |F |

D F

log(1 +

t(w, D) ) w

(1)

where

t

(w ,

d

)

=

T

F

(w,

D)

log(1

+

c

a |D

l
|

)

(a

l denotes the average

document length and c is a free hyper-parameter that controls

the document length e ect). e document frequency term w is calculated as:

w = Nw /N

(2)

where Nw and N denote the number of documents in the collection that contain w and the total number of documents in the collection,

respectively. FW (w) is then interpolated with the original query

based on a free parameter (feedback coe cient)[2].

It can be easily shown that the log-logistic feedback model does

not satisfy the proximity-based constraints, since its formulation

does not contain any proximity-based component. To the best of

our knowledge, this is the rst a empt to enrich the log-logistic

feedback model using term proximity information.

Regarding the query term independence assumption, we propose

to modify the log-logistic model as follows to satisfy the proximity-

based constraints:

FWprox (w) = FW (w) 

 (w, q, D)

(3)

D F q Q

where q is a query term and  (w, q, D) is a function that computes the proximity of w and q in document D.
To de ne the function  , we propose to use the Exponential kernel that satis es the "proximity e ect" and the "convexity e ect" constraints. We modify the Exponential kernel by adding an IDF term to satisfy the " ery IDF e ect" constraint, as well. e function  can be computed as follows:

 (w, q, D) = exp

-d(w, q, D) 

. log 1 q

(4)

where d(w, q, D) denotes the distance function for two given terms w and q in document D. q is the document frequency component for the query term q (see Equation (2)) and  is a free parameter. Several approaches have been proposed to compute d(w, q, D), such as average, minimum, and maximum distances. Tao and Zhai [12] showed that using the minimum distance between the term w and the query term q in the feedback document outperforms other distance functions. We also use the minimum distance as follows:

d(w, q, D) = min |wi - qj |

(5)

wi wì & qj qì

where wì and qì are two vectors containing the positions of term w and query term q in document D, respectively.

3 EXPERIMENTS
3.1 Experimental Setup
We used four standard TREC collections in our experiments: AP (Associated Press 1988-89), Robust (TREC Robust Track 2004 collection), WT2g (TREC Web Track 2000 collection), and WT10g (TREC Web Track 2001-2002 collection). e rst two are newswire collections, while the next two are web collections containing more noisy documents. e statistics of these collections are reported in Table 1. We considered the title of topics as queries. All documents

1086

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: Collections statistics.

Collection AP
Robust WT2g WT10g

TREC topics 51-200
301-450 & 601-700 401-450 451-550

#docs 165k 528k 247k 1692k

doc length 287 254 645 399

#qrels 15838 17412 2279 5931

were stemmed using the Porter stemmer and stopped using the standard INQUERY stopword list. We carried out the experiments using the Lemur toolkit2.
3.1.1 Parameter Se ing. e number of feedback documents, the feedback term count, and the feedback coe cient were set using 2-fold cross validation over the queries of each collection. We swept the number of feedback documents between {10, 25, 50, 75, 100}, the feedback term count between {10, 25, 50, 75, 100}, and the feedback coe cient between {0, 0.1, · · · , 1}. e parameters c and  were also selected using the same procedure from {2, 4, · · · , 10} and {25, 50, · · · , 500}, respectively. e parameter  in the Gaussian kernel is also set similarly.
3.1.2 Evaluation Metrics. To evaluate retrieval e ectiveness, we use mean average precision (MAP) of the top-ranked 1000 documents as the main evaluation metric. In addition, we also report the precision of the top 10 retrieved documents (P@10). Statistically signi cant di erences of average precisions are determined using the two-tailed paired t-test computed at a 95% con dence level. To evaluate robustness of methods, we consider the robustness index (RI) introduced in [4].
3.2 Results and Discussion
In this subsection, we rst empirically show that satisfying each of the introduced constraints improves the retrieval performance. Our experiments also demonstrate that the Gaussian kernel that has previously been used in the literature [5, 6, 8] is not as e ective as the proposed proximity weighting function, since the Gaussian kernel does not satisfy all the constraints.
3.2.1 Analysis of the Proximity-based Constraints. We consider two baselines: (1) the document retrieval method without feedback (NoPRF), and (2) the original log-logistic feedback model (LL). Although there are several e ective PRF methods, since in this paper we study the e ect of the proposed constraints in the log-logistic model, we do not consider other existing PRF methods.
To study the in uence of each of the proposed constraints on the retrieval performance, we consider three di erent proximity functions: (1) the quadratic function ( ad) that only satis es the "proximity e ect" constraint, (2) the exponential function (Exp) that satis es both "proximity e ect" and "convexity e ect" constraints, and (3) a modi ed version of the exponential function (Exp*) that satis es all three constraints. More detail is reported Table 2.
e results of the baselines and the aforementioned methods are reported in Table 3. According to this table, modifying the loglogistic method using each of the proximity functions improves the retrieval performance, in all collections. e MAP improvements are statistically signi cant in nearly all cases. is indicates the necessity of taking term proximity into account for the PRF task.
2h p://lemurproject.org/

Table 2: Summary of di erent proximity functions with respect to the proximity-based constraints (x = d(w, q, D)).

Func.  (w, q, D)

Gaus

exp[

-x 2

2 2

]

ad

-(

x 

)2

+

1

Exp

exp[

-x 

]

Exp*

exp[

-x 

].

log

N Nq

Proximity Convexity e ect e ect
Yes Partially

Yes

No

Yes

Yes

Yes

Yes

ery IDF e ect
No
No
No
Yes

e results demonstrate that LL+Exp outperforms LL+ ad and LL+Exp* outperforms LL+Exp, in all collections. e improvements in the web collections are higher than those in the newswire collections. e reason is that these two collections are web crawls and contain more noisy documents compared to the newswire collections. e other reason is that the WT2g and WT10g documents are much longer than the AP and Robust documents on average (see Table 1). e in uence of proximity-based constraints can be highlighted in longer documents. Besides that, in terms of RI, LL+Exp* outperforms all the baselines in AP, WT2g and WT10g which shows the importance and robustness of ery IDF e ect and these improvements are impressive in WT2g and WT10g which shows that this e ect is important in noisy (web) collections.
3.2.2 Analysis of the Gaussian Kernel. In this set of experiments, we study the Gaussian kernel for computing the proximity weight, which has been shown to be the most e ective proximity function among the existing ones [5]. As reported in Table 2, employing the Gaussian kernel for PRF satis es the "proximity e ect" constraint. e "convexity e ect" constraint is only satis ed when d(w, q, D) >  . erefore, it does not satisfy the "convexity e ect" for the candidate feedback terms that are close to the query terms. We evaluate the Gaussian kernel by considering it as a term proximity weight function (LL+Gaus). According to the results reported in Table 3, LL+Exp and LL+Gaus perform comparably in the newswire collections, but LL+Exp outperforms LL+Gaus in the web collections (WT2g and WT10g). LL+Exp* also outperforms LL+Gaus in all collections. e improvements in the web collections are statistically signi cant.
3.2.3 Parameter Sensitivity. In the last set of experiments, we study the sensitivity of the proposed method to the following hyperparameters: the number of feedback terms added to the query, (2) the feedback interpolation coe cient, and (3) the parameter  (see Equation (4)). To do so, we sweep one of the parameters and x the other ones to their default values: 50 for feedback term count, 0.5 for feedback coe cient, and 25 for . In these experiments, we report the result for LL+Exp* that achieves the best performance in Table 3.
e results are plo ed in Figure 1, in terms of MAP. In this gure, the rst plot shows that the performance of LL+Exp* is stable with respect to the changes in the number of feedback terms, when more than 25 terms are added to the query. In other words, 25 terms are enough for expanding the query in most collections. e second plot in Figure 1 demonstrates that the behaviour of LL+Exp* in newswire collections is similar to each other. LL+Exp* also behaves similarly in the web collections. Interestingly, the feedback model estimated by LL+Exp* does not need to be interpolated with the original query

1087

Short Research Paper

SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 3: Performance of di erent proximity functions applied to the log-logistic model. Superscripts 0/1/2 denote that the MAP improvements over NoPRF/LL/LL+Gaus are statistically signi cant. e highest value in each column is marked in bold.

Method

AP MAP P@10 RI

Robust MAP P@10 RI

WT2g MAP P@10 RI

WT10g MAP P@10 RI

NoPRF LL
LL+Gaus
LL+ ad LL+Exp LL+Exp*

0.2642 0.4260 ­
0.3385 0.4622 0.15
0.347101 0.4695 0.19
0.344101 0.4682 0.18 0.346801 0.4688 0.19 0.347501 0.4702 0.21

0.2490 0.4237 ­
0.2829 0.4393 0.33
0.292601 0.4454 0.27
0.292001 0.4530 0.30 0.293601 0.4442 0.28 0.295001 0.4430 0.30

0.3033 0.4480 ­
0.3276 0.4820 0.36
0.33510 0.4920 0.38
0.33090 0.4920 0.34 0.3418012 0.4840 0.38 0.3449012 0.4820 0.47

0.2080 0.3030 ­
0.2127 0.3187 0.08
0.239301 0.3157 0.16
0.21950 0.3075 0.02 0.243501 0.3247 0.19 0.2461012 0.3278 0.24

0.35
0.30

0.25

 AP Robust

WT2g WT10g









0.35

 AP Robust

WT2g WT10g







0.30



 
0.25

 AP Robust

WT2g WT10g

0.35    











0.30

0.25

MAP MAP MAP

0.20 0

25

50

75

100

0.20

0.0

0.2

0.4

0.6

0.8

1.0

0.20 25 75 150

300

400

500

# of feedback terms

feedback coefficient



Figure 1: Sensitivity of LL+Exp* to the number of feedback terms, the feedback coe cient, and the parameter .

model in the newswire collections. In the web collections (WT2g and WT10g), giving a small weight (i.e., 0.2) to the original query model can help to improve the retrieval performance. e reason could be related to the noisy nature of the web collections compared to the newswire collections. e last plot in Figure 1 shows that the proposed method is not highly sensitive to the parameter  when it is higher than 100. e results indicate that 25 and 50 would be proper values for this parameter. e results on the web collections are more sensitive to this parameter. e reason is that the documents in the web collections are much longer than those in the newswire collections (see Table 1).
4 CONCLUSIONS AND FUTURE WORK
In this paper, we proposed three constraints for the pseudo-relevance feedback models, that focus on the proximity of the candidate feedback terms and the query terms in the feedback documents. To show the e ectiveness of the proposed constraints, we considered the log-logistic model, a state-of-the-art feedback model, as a case study. We rst showed that the log-logistic model does not satisfy the proximity-based constraints. We further modi ed it based on the proposed constraints. Our experiments on four standard TREC newswire and web collections demonstrated the e ectiveness of the proposed constraints for the PRF task. e modi ed log-logistic model signi cantly outperforms the original log-logistic model, in all collections. We also showed that the Gaussian kernel that has been used in previous proximity-based methods does not satisfy all the constraints. We show that the performance of the proposed variant of the exponential kernel is superior to those obtained by employing the Gaussian kernel. As a future direction, the other existing PRF models could be analyzed and modi ed based on the introduced constraints.

Acknowledgements. is work was supported in part by the Center for
Intelligent Information Retrieval and in part by a grant from the Institute
for Research in Fundamental Sciences (No. CS1396-4-51). Any opinions,
ndings and conclusions or recommendations expressed in this material
are those of the authors and do not necessarily re ect those of the sponsors.
REFERENCES
[1] Mozhdeh Ariannezhad, Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Iterative Estimation of Document Relevance Score for PseudoRelevance Feedback. In ECIR '17. 676­683.
[2] Ste´phane Clinchant and Eric Gaussier. 2010. Information-based Models for Ad Hoc IR. In SIGIR '10. 234­241.
[3] Ste´phane Clinchant and Eric Gaussier. 2013. A eoretical Analysis of PseudoRelevance Feedback Models. In ICTIR '13. 6­13.
[4] Kevyn Collins- ompson. 2009. Reducing the Risk of ery Expansion via Robust Constrained Optimization. In CIKM '09. 837­846.
[5] Yuanhua Lv and ChengXiang Zhai. 2009. Positional Language Models for Information Retrieval. In SIGIR '09. 299­306.
[6] Yuanhua Lv and ChengXiang Zhai. 2010. Positional Relevance Model for Pseudorelevance Feedback. In SIGIR '10. 579­586.
[7] Yuanhua Lv, ChengXiang Zhai, and Wan Chen. 2011. A Boosting Approach to Improving Pseudo-relevance Feedback. In SIGIR '11. 165­174.
[8] Jun Miao, Jimmy Xiangji Huang, and Zheng Ye. 2012. Proximity-based Rocchio's Model for Pseudo Relevance. In SIGIR '12. 535­544.
[9] Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2016. Axiomatic Analysis for Improving the Log-Logistic Feedback Model. In SIGIR '16. 765­768.
[10] Dipasree Pal, Mandar Mitra, and Samar Bha acharya. 2015. Improving Pseudo Relevance Feedback in the Divergence from Randomness Model. In ICTIR '15. 325­328.
[11] Jangwon Seo and W. Bruce Cro . 2010. Geometric Representations for Multiple Documents. In SIGIR '10. 251­258.
[12] Tao Tao and ChengXiang Zhai. 2007. An Exploration of Proximity Measures in Information Retrieval. In SIGIR '07. 295­302.
[13] Hamed Zamani, Javid Dadashkarimi, Azadeh Shakery, and W. Bruce Cro . 2016. Pseudo-Relevance Feedback Based on Matrix Factorization. In CIKM '16. 1483­ 1492.
[14] Chengxiang Zhai and John La erty. 2001. Model-based Feedback in the Language Modeling Approach to Information Retrieval. In CIKM '01. 403­410.

1088

