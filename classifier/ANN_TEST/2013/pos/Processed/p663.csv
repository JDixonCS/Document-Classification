,sentence,label,data,regex
0,Copulas for Information Retrieval,0,,False
1,Carsten Eickhoff,0,,False
2,"Delft University of Technology Delft, The Netherlands",0,,False
3,c.eickhoff@acm.org,0,,False
4,Arjen P. de Vries,0,,False
5,"CWI Amsterdam Amsterdam, The Netherlands",1,CW,True
6,arjen@acm.org,0,,False
7,Kevyn Collins-Thompson,0,,False
8,"Microsoft Research Redmond, WA, USA",0,,False
9,kevynct@microsoft.com,0,,False
10,ABSTRACT,0,,False
11,"In many domains of information retrieval, system estimates of document relevance are based on multidimensional quality criteria that have to be accommodated in a unidimensional result ranking. Current solutions to this challenge are often inconsistent with the formal probabilistic framework in which constituent scores were estimated, or use sophisticated learning methods that make it difficult for humans to understand the origin of the final ranking. To address these issues, we introduce the use of copulas, a powerful statistical framework for modeling complex multi-dimensional dependencies, to information retrieval tasks. We provide a formal background to copulas and demonstrate their effectiveness on standard IR tasks such as combining multidimensional relevance estimates and fusion of results from multiple search engines. We introduce copula-based versions of standard relevance estimators and fusion methods and show that these lead to significant performance improvements on several tasks, as evaluated on large-scale standard corpora, compared to their non-copula counterparts. We also investigate criteria for understanding the likely effect of using copula models in a given retrieval scenario.",1,ad,True
12,Categories and Subject Descriptors,0,,False
13,Information Systems [Information Retrieval]: Retrieval models,0,,False
14,Keywords,0,,False
15,Relevance models; Multivariate relevance; Ranking; Probabilistic framework; Data fusion.,0,,False
16,1. INTRODUCTION,1,DUC,True
17,"In response to user queries, today's search systems typically return lists of documents ranked by system estimates of relevance. In traditional IR retrieval models, each document's relevance towards the query is expressed as term overlap between query and document [42]. Early on, re-",1,ad,True
18,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.",1,ad,True
19,"searchers began exploring alternative, non-topical document quality criteria such as document recency, credibility or monetary cost. More recently, through a combination of improved algorithms and greatly increased data scale, significant gains in ranking quality and user satisfaction based on employing non-topical factors such as textual complexity [12] or suitability for children [17] have begun influencing the ranking process. Given a scenario such as child-friendly information search, non-topical quality criteria can clearly have a strong influence on usefulness of a document for a specific user. A perfectly relevant document that is not understandable due its complex sentence structure or excessive use of jargon will have significantly diminished user relevance.",0,,False
20,"Beyond the value of individual relevance factors, there can be complex, non-linear dependencies between relevance factors. For example, relevance criteria such as topicality and credibility might appear independent for some document subsets, but extreme values in one dimension may influence the other in a way that is not easily captured by state-of-the-art approaches. As a concrete example, take TREC 2010's faceted blog distillation task [32], that aims at retrieving topically relevant non-factual blog feeds. Here, the relevance space has two dimensions: topicality and subjectivity. Figure 1 shows the distribution of relevance scores for Topic 1171, ""mysql "", across these two relevance dimensions. We can note an apparent correlation in the lower left part of the graph that weakens as scores increase. To underline this, we computed Pearson's  between the two dimensions for the lower score third ( ,"" 0.37), the upper region ( "","" -0.4), as well as the overall distribution ( "","" 0.18). Apparently, the dependency structure of the joint distribution of relevance, in this case, is not easily described by a linear model. Consequently, we can expect dissatisfying performance of linear combination models. And, indeed, when inspecting the performance of a linear combination model with empirically learned mixture parameters , Topic 1171 receives an average precision of only 0.14, well below the method's average across all topics of 0.25. In the course of this work, we will discuss practical means of addressing cases like the present one and will finally revisit this example to demonstrate the effect of our proposed method.""",1,TREC,True
21,"While the machine learning, information retrieval, data mining and natural language processing communities have significant expertise in estimating topical document relevance and additional criteria in isolation, the commonly applied combination schemes have tended to be ad hoc and ignore the problem of modeling complex, multi-dimension dependencies. In practice, they follow statically weighted lin-",1,ad,True
22,663,0,,False
23,"Figure 1: Distribution of bivariate relevance scores for TREC 2010 Blog Track Topic 1171, ""mysql"".",1,TREC,True
24,"ear combinations with empirically determined mixture parameters [42] or deploy sophisticated learning to rank techniques that tend to offer only limited insight to humans about why they were weighted highly for relevance. Ideally, we would demand realistic, yet formally-grounded combination schemes that can lead to results that are both effective and with human-interpretable justification.",1,ad,True
25,"In a different context, the field of quantitative risk management has devised copulas, a flexible, varied class of probability density functions that are designed to capture rich, non-linear dependencies efficiently in multi-dimensional distributions. Copulas work by decoupling the marginal distributions of the data from the underlying dependency structure of the joint distribution. In particular, copulas can account for so-called tail dependencies, i.e., dependencies that play up at the extreme values of the interacting distributions. As an example, let us consider two commodities traded on the stock market, such as rare earth metals and pork bellies. The two commodities are sufficiently different to make the related market segments quasi-independent. However, extreme market situations have been shown to cause investor panics that reach across otherwise independent segments and cause previously unseen interrelationships [9].",1,ad,True
26,"This work makes three contributions to the state of the art in relevance modelling. (1) We give a detailed introduction to the formal framework of copulas and describe how to estimate them from empirical data. (2) Based on a number of sizeable standard data sets such as the Blogs08 collection [32], we demonstrate the merit of using copulas for multivariate relevance estimation. (3) In a related effort, we address the task of score fusion based on historic submissions to the TREC ad hoc task. The remainder of this paper is structured as follows: Sec-",1,ad,True
27,"tion 2 gives a historic overview of IR relevance frameworks, prior work on multidimensional relevance models, score fusion approaches, as well as, examples of copula applications from different fields. Section 3 formally introduces the theoretical foundation of copulas and details key techniques in their application. In Sections 4 and 5 we demonstrate their merit at the tasks of estimating multidimensional relevance scores as well as fusing prior TREC runs. Section 6 further discusses the experimental results and aims at identifying those domains of IR for which copulas are most promising. Section 7 concludes the paper with a concise summary of our findings.",1,TREC,True
28,2. RELATED WORK,0,,False
29,"Over the past decades, a wide range of partially overlapping relevance frameworks have been proposed, a few prominent examples include [44, 22, 34, 8]. They unanimously consider relevance as a complex, potentially multidimensional concept that may be composed from a number of constituents. In the further course of this section, we will focus on the practical implementation of formal relevance estimation schemes employed in information retrieval and related disciplines. Schamber et al. [45] radically revised the definition of relevance, causing a growing interest in probabilistic relevance modelling in the research community. First openly applied at the third TREC competition, the BM25 retrieval model [43] represents a performance landmark that is still valid today (with slight variations such as the 2004 integration of multiple weighted fields [42]). In 1996, Persin et al. [38] introduced the idea of retrieval result lists ranked by their probability of relevance, as an alternative to the previously dominant binary retrieval scenario. Two years later, Ponte and Croft proposed the use of language modelling techniques to determine topical relevance [39]. One of the first notions of non-topical relevance was expressed in Kleinberg's work on hubs and authorities [26] in which the author introduces two document-specific relevance notions independent of the query. Lavrenko and Croft [28, 29] pursued a line of work on dedicated relevance models. While the formal combination of several individual relevance facets in one model has not been extensively studied, there has been an interesting thread of research on score fusion. The task is to combine the result rankings of multiple independent retrieval systems in order to compensate for local inaccuracies of single engines. Early approaches to the task were based on evidence aggregation in the form of products and sums of scores across individual systems [19]. The fused ranking is based on the absolute value of the cross-system aggregates. Vogt et al. [51] first introduced linear interpolation of multiple model rankings for system fusion. Aslam and Montague [5] proposed a probabilistic rank-based method for direct combination of multiple engines. Later on, they devised a similar method based on a majority voting scheme between various retrieval systems [35]. [36] proposed a score normalization scheme that is more robust to outliers in the distribution of relevance than the previously used min/max technique. There has been an extensive body of work on estimating the distribution of relevance scores for document ranking. Recent examples include the work by Arampatzis and Stephenson [4], Kanoulas et al. [25], and, Cummins [14]. Manmatha et al. [33] estimated a search engine's score distribution as a mixture of normal and exponential distributions, for relevant and non-relevant documents respectively. They",1,ad,True
30,664,0,,False
31,"used the resulting distributions for score fusion across multiple engines, but did not attempt to model dependencies in the joint score distribution, instead treating the scores as independent and averaging probabilities, or discarding `bad' engines altogether. In 2002, Wu and Crestani [52] introduced the first of what would become a group of fusion approaches that define an explicit weighting scheme under which the original result lists are combined. [7] and [15] employ various quality notions such as the degree to which a document satisfies a given relevance criterion to dynamically adapt the weighting scheme to the underlying distribution of relevance. In 2005, Craswell et al. investigated relevance model combination by linearly combining constituent scores in the log domain [13]. Tsikrika and Lalmas applied Dempster-Shafer theory for the aggregation of independent relevance criteria in web retrieval in the form of belief functions [49]. Gerani et al. [21] propose non-linear score transformations prior to the standard weighted linear combination step. Their solid results demonstrate the need for models whose capabilities go beyond linear dependency structures between relevance dimensions. In recent years, the variety of IR applications has become significantly more diverse. As a consequence, universal relevance models have become less viable in many areas. Tasks such as legal IR, expert finding, opinion detection or the retrieval of very short documents (e.g., tweets) have brought forward strongly customised relevance models tailored towards satisfying a given task (e.g., [24, 6]). Especially for the retrieval of structured (XML) documents, score combination schemes are of central importance to combine evidence across multiple structural fields within a document. Despite the numerous potential issues pointed out by Robertson et al. [42], most state-of-the-art approaches to XML retrieval rely on linear models [31]. An advance towards the formal combination of several independent relevance criteria in the form of prior probabilities for language models has been made by Kraaij et al. [27] for the task of entry page search. To date, however, most universally applicable relevance models still rely on pure linear combinations of relevance criteria that disregard the underlying data distribution or potential dependencies between the considered dimensions. Learning to rank (L2R) has been established as an alternative approach for signal combination. The aim is to apply machine learning methods to either directly infer a document ranking or a ranking function from a wide range of features, potentially including the previously-discussed relevance criteria [10, 40, 30]. The downside of this approach is that the resulting models tend to yield only limited insight for humans. The classic approach of developing a unifying formal retrieval model would in our view provide better means to increase not just overall performance, but also our qualitative understanding of the problem domain. By introducing copulas for information retrieval, this work proposes a way for closing the gap between linear combinations (that break with the probabilistic framework in which the constituent scores were estimated) and non-linear machine-learned models (that offer only limited insight to scientists and users). Copulas have been traditionally applied for risk analyses in portfolio management [18] as well as derivatives pricing [9] in quantitative finance. Recently, however, there are several successful examples from unrelated disciplines. Renard et",1,ad,True
32,"al. estimate water flow behaviour based on Gaussian copulas [41]. Onken et al. apply copulas for spike count analysis in neuroscience [37]. In meteorology, copulas have been used to combine very high-dimensional observations for the task of climate process modelling [47]. To the best of our knowledge, there has been no prior application of the copula framework to information retrieval problems.",0,,False
33,3. COPULAS,0,,False
34,"At this point, we will give a brief introduction of the general theoretical framework of copulas, before applying them to various IR tasks in subsequent sections. For a more comprehensive overview, please refer to [46] for more detail and pointers to further reading. The term copula was first introduced by Sklar [48] to describe multivariate cumulative distribution functions (cdfs) that allow for a formal decoupling of observations from dependency structures. Formally, given",1,ad,True
35,"X ,"" (x1, x2, . . . , xk)""",0,,False
36,a k-dimensional random vector with continuous margins,0,,False
37,"Fk(x) , P[Xk  x]",0,,False
38,"we can map our observations to the unit cube [0, 1]k as",0,,False
39,"U ,"" (u1, u2, . . . uk) "","" (F1(x1), F2(x2), . . . Fk(xk)).""",0,,False
40,This is where our copulas come into play. A k-dimensional copula C describes the joint cumulative distribution function of random vector U with uniform margins.,0,,False
41,"C : [0, 1]k  [0, 1]",0,,False
42,"This approach has two obvious practical benefits: (1) Separating marginals and dependency structure allows for more straightforward estimation or approximation of each component in isolation. (2) An explicit model of dependency is scale-invariant. The copula describes a reference case of dependency on the unit cube [0, 1]k that can be applied to arbitrary random vectors without further adjustment. A number of key properties make copulas an appealing theoretical framework for a wide number of applications, so we summarize those now.",1,ad,True
43,"· Like all cdfs, a copula C(u1, u2, . . . , uk) is increasing in each component ui",0,,False
44,· A marginal component ui can be isolated by setting all remaining components to 1:,0,,False
45,"C(1, . . . , 1, ui, 1, . . . , 1) , ui",0,,False
46,"· If a single component ui in U is zero, the entire copula is zero:",0,,False
47,"C(u1, . . . , ui-1, 0, ui+1, . . . , uk) , 0",0,,False
48,"· Most importantly, we can assume general applicability of the copula framework, since, as a consequence of Sklar's Theorem [48], for each k-dimensional cdf F and all xi in [-, ] and 1  i  k, there exists a copula C with",0,,False
49,"F (x1, . . . , xk) ,"" C(F1(x1), . . . , Fk(xk))""",0,,False
50,665,0,,False
51,3.1 Extreme conditions,0,,False
52,"Before applying the copula framework to problems in information retrieval, let us visit a number of extreme conditions of dependency that frequently occur in IR scenarios. (1) Independence of observations is a frequently assumed simplification in IR theory that leads to convenient (if na¨ive) probabilistic models. In the copula framework, independence of events can be captured by the so-called independence copula Cindep:",1,ad,True
53,k,0,,False
54,"Cindep (U ) , exp(- - log ui)",0,,False
55,"i,1",0,,False
56,which is equivalent to the product across all constituent probabilities in U . (2) Co-monotonicity describes the case of perfect positive correlation between observations u:,0,,False
57,"CcoMono (U ) ,"" min{u1, . . . , uk}""",0,,False
58,(3) counter-monotonicity of observations is given in the opposite case of perfect negative correlation:,0,,False
59,k,0,,False
60,"CcounterMono (U ) ,"" max{ ui + 1 - k, 0}""",0,,False
61,"i,1",0,,False
62,"Consequently, each copula lies within the so-called Fr´echetH¨offding bounds [23]:",0,,False
63,CcounterMono (U )  C(U )  CcoMono (U ),0,,False
64,3.2 Copula families,0,,False
65,"After having covered the foundations of copula theory let us inspect some concrete examples of copulas that will be used in the course of this work. Three general families of standard copulas have been proposed in the literature, whose corresponding equations are given right after their introduction in this paragraph: (1) Elliptical copulas are directly derived from known distributions and are based on standard distribution functions such as the Gaussian distribution or Student's t distribution. Equation 1 shows the Gaussian copula that requires the observed covariance matrix   Rk×k as a parameter.  denotes the cdf of a standard normal distribution and -1 its inverse. (2) Archimedean copulas are popular as they can be explicitly stated (note that due to their distribution dependency that is not the case for elliptical copulas) and typically depend on only a single degree of freedom. The parameter  expresses the strength of dependency in the model. Equation 2 shows the Clayton copula whose -range is [-1, )\{0}.  ,"" -1 represents counter-monotonicity,   0 gives the independence copula and    approaches co-monotonicity. Finally, (3) Extreme value copulas are robust in cases of extreme observations. The Gumbel copula (Equation 3) has a parameter space of  in [1, ). For  "","" 1 we obtain the independence copula, and, for    we approach co-monotonicity.""",0,,False
66,"CGaussian (U ) ,"" (-1(u1), . . . , -1(uk))""",0,,False
67,(1),0,,False
68,k,0,,False
69,"CClayton (U ) , (1 + (",0,,False
70,1 ,0,,False
71,(u-i ,0,,False
72,-,0,,False
73,1))),0,,False
74,-1 ,0,,False
75,(2),0,,False
76,"i,1",0,,False
77,k,0,,False
78,"CGumbel (U ) , exp(-(",0,,False
79,(-,0,,False
80,log(ui,0,,False
81,)),0,,False
82,),0,,False
83,1 ,0,,False
84,),0,,False
85,(3),0,,False
86,"i,1",0,,False
87,"Figure 3.2 shows contour plots of a number of bivariate standard copulas. The concrete choice of copula family and instantiation has been frequently reported to depend on the application domain [46]. If no prior knowledge about the dependency structure, e.g., prevalence of asymptotic or tail dependencies, is available, practitioners often resort to goodness-of-fit tests or measures of tail dependency in order to choose an appropriate model. We will describe the use of these techniques in the subsequent sections when applying copulas for information retrieval problems.",0,,False
88,3.3 Fitting copulas to observations,0,,False
89,"In the case of elliptical copulas, the fitting process is limited to calculating means and covariance matrices from the available observations. Here, the only degree of freedom is the concrete choice of distribution function (e.g., Gaussian vs. Student) that best approximates the original distribution that generated the observations. In the non-elliptical case, the task is to determine optimal settings of . Commonly, this is achieved by means of maximum likelihood estimates based on the available observations. This is also the approach chosen in this work. It should be noted that there are methods for direct empirical estimations of entire copula functions. The interested reader can find a good overview by Charpentier et al. [11] as a starting point for this line of research, the inclusion of which would however go beyond the scope of this initial exploration of copulas for information retrieval.",1,ad,True
90,4. RELEVANCE ESTIMATION,0,,False
91,"In the previous section, we described the theoretical foundations of copulas including concrete ways of computing C(U ) from multivariate observations U . We now detail their application for relevance estimation in information retrieval. First, we separately estimate the probability of relevance Pr(ekl)(d) and non-relevance Pn(okn) (d) for a document d, under each of the k criteria (dimensions) ­ for example, topicality, recency, readability, etc. Next, we assume random observations Urel and Unon to derive from these distributions and base two distinct copulas, Crel and Cnon on them. Recall that these copulas should capture the dependencies between relevance criteria, in either the relevant (Crel) or the non-relevant (Cnon) documents retrieved. Since it is difficult to predict where these dependencies have the most effect, it is natural to consider three different general approaches of combining multivariate observation scores U into a single probability of relevance that can be used for resource ranking. (1) CPOS (Urel ) multiplies the independent likelihood of observing Urel with the relevance copula Crel , capturing only dependencies between the likelihoods of relevance. (2) CNEG(Urel , Unon ) normalizes the probability of relevance by the non-relevance copula Cnon (Unon ), capturing only the dependencies between the likelihoods of non-relevance. (3) CODDS (Urel , Unon ), finally, multiplies the probability of relevance by the ratio of the two copulas, modelling simultaneously the dependencies between both previous notions.",1,ad,True
92,k,0,,False
93,"CPOS (Urel ) ,"" Crel (Urel ) urel,i""",0,,False
94,"i,1",0,,False
95,"CNEG(Urel , Unon )",0,,False
96,",",0,,False
97,"k i,1",0,,False
98,urel,0,,False
99,",i",0,,False
100,Cnon (Unon ),0,,False
101,666,0,,False
102,"Figure 2: Examples of bivariate copula contour plots. (a) Gaussian copula, (b) Clayton copula with  ,"" 2.0, (c) Gumbel copula with  "", 2.0.",0,,False
103,"CODDS (Urel , Unon )",0,,False
104,",",0,,False
105,Crel (Urel ) Cnon (Unon ),0,,False
106,k,0,,False
107,"urel ,i",0,,False
108,"i,1",0,,False
109,"As performance baselines, we will compare to three popular combination methods from the literature: (1) SUM (Urel ) sums up the relevance scores across all criteria k and uses the sum as the final ranking criterion [19]. (2) PROD(Urel ) builds the product across all constituents [19]. Probabilistically, this combination scheme assumes independence across all criteria and can be expected to be too na¨ive in some settings where dependence is given. (3) Weighted linear combinations LIN(Urel ) build a weighted sum of constituents urel,i with mixture parameters i optimized by means of a parameter sweep with step size 0.1 [51]. It should be noted that all optimizations and parameter estimations, both for the baselines as well as for the copula models are conducted on designated training sets that do not overlap with the final test sets. We relied on the original training portion of the respective corpora. In the case that the original corpus did not specify a dedicated training set, we used a stratified 90%/10% split.",1,corpora,True
110,k,0,,False
111,"SUM (Urel ) ,"" urel,i""",0,,False
112,"i,1",0,,False
113,k,0,,False
114,"PROD (Urel ) ,"" urel,i""",0,,False
115,"i,1",0,,False
116,k,0,,False
117,"LIN(Urel ) ,"" iurel,i""",0,,False
118,"i,1",0,,False
119,"Based on three different standard datasets and tasks, we will highlight the merit of using copulas over the traditional approaches. Each of the settings specifies 2 individual relevance criteria (k ,"" 2) which are crucial for user satisfaction given the retrieval task. Table 1 gives a high-level overview of the relevant corpora that we used. Each of them will be described in more detail in the three following sections. Depending on the strength of tail dependency in the data, we will see varying improvements for the three inspected settings. Comparable as the scenarios appear, there seem to be significant underlying differences in the distribution of relevant documents that influence the benefit from the use""",1,ad,True
120,Table 1: Overview of experimental corpora. ID # docs # topics # labels year,1,corpora,True
121,Blogs08 1.3M,0,,False
122,100,0,,False
123,Delicious 339k,0,,False
124,180,0,,False
125,ODP,1,ODP,True
126,22k,0,,False
127,30,0,,False
128,38.2k 3.8k 1k,0,,False
129,2008 2012 2009,0,,False
130,"of copulas. In Section 6, we will dedicate some room to a detailed investigation of when the use of copula-based retrieval models is most promising.",0,,False
131,4.1 Opinionated blogs,1,blog,True
132,"When conducting marketing analyses for businesses, researching customer reviews of products or gauging political trends based on voter opinions, it can be desirable to focus the search process on subjective, non-factual documents. The Text REtrieval Conference (TREC) accounted for this task within the confines of their Blog Track between the years 2006 and 2010 [32]. The aim of the task is to retrieve blog feeds that are both topically relevant and opinionated. Our experimental corpus for this task is the Blogs08 collection specifically created for the venue. The dataset consists of 1.3 million blog feeds and is annotated by more than 38k manually created labels contributed by NIST assessors.",1,TREC,True
133,"Each document is represented as a two-component vector Ur(e2l). The first component refers to the document's topical relevance given the query and the second represents its degree of opinionatedness. In order for a document to be considered relevant according to the judges' assessments, it has to satisfy both conditions. Topical relevance was estimated by a standard BM25 model and opinionatedness was determined using the output of a state-of-the-art open source classifier [1]. After an initial evaluation of the domain, we chose Clayton copulas (Equation 2) to represent the joint distribution of topicality and opinionatedness. Table 2 shows a juxtaposition of performance scores for the baselines as well as the various copula methods. The highest observed performance per metric is highlighted by the use of bold typeface, statistically significant improvements (measured by means of a Wilcoxon signed-rank test at  ,"" 0.05-level) over all competing approaches are denoted by an asterisk. Of the baseline methods, the score product PROD performs best. However, introducing the use of copulas, we observe that the highest performance was achieved using the CPOS copula,""",0,,False
134,667,0,,False
135,Table 2: Copula-based relevance estimation perfor- Table 3: Copula-based relevance estimation perfor-,0,,False
136,"mance for opinionated blogs (k , 2).",1,blog,True
137,"mance for personalized bookmarks (k , 2).",0,,False
138,Method,0,,False
139,PROD SUM LIN CPOS CNEG CODDS,0,,False
140,P@5,0,,False
141,0.413 0.400 0.387 0.413 0.373 0.373,0,,False
142,P@10,0,,False
143,0.360 0.333 0.333 0.400* 0.373 0.360,0,,False
144,p@100,0,,False
145,0.181 0.154 0.162 0.182 0.181 0.182,0,,False
146,BPREF,0,,False
147,0.289 0.255 0.262 0.306* 0.290 0.283,0,,False
148,MRR,0,,False
149,0.692 0.689 0.689 0.692 0.545 0.544,0,,False
150,MAP,1,MAP,True
151,0.275 0.238 0.245 0.287* 0.245 0.242,0,,False
152,Method,0,,False
153,PROD SUM LIN CPOS CNEG CODDS,0,,False
154,P@5,0,,False
155,0.084 0.095 0.126 0.105 0.137* 0.116,0,,False
156,P@10,0,,False
157,0.079 0.095 0.100* 0.068 0.090 0.074,0,,False
158,p@100,0,,False
159,0.011 0.011 0.011 0.01 0.010 0.01,0,,False
160,BPREF,0,,False
161,0.051 0.071 0.077 0.056 0.079* 0.066,0,,False
162,MRR,0,,False
163,0.192 0.192 0.219* 0.190 0.184 0.202,0,,False
164,MAP,1,MAP,True
165,0.043 0.055 0.063 0.047 0.065 0.058,0,,False
166,"which gave statistically significant gains in MAP, Bpref and precision at rank 10 over all the baseline methods.",1,MAP,True
167,"At this point, we revisit the example query (Topic 1171) that was discussed in the introduction and depicted in Figure 1. For this topic, we observed a clear non-linear dependency structure alongside a lower-than-average linear combination performance of AP ,"" 0.14. When applying CPOS to the topic, however, we obtain AP "","" 0.22, an improvement of over 50%.""",1,AP,True
168,4.2 Personalized bookmarks,0,,False
169,"Finding and re-finding resources on the Internet are frequently accompanied and aided by bookmarking. What started as a local in-browser navigation aid, has in recent years become an active pillar of the social web society. Collaborative bookmarking platforms such as Delicious, Furl, or Simpy allow users to maintain an online profile along with bookmarks that can be shared among friends and collaboratively annotated by the user community. Research into tagging behaviour [2] found that a significant amount of the tags assigned to shared media items and bookmarks are of subjective nature and do not necessarily serve as objective topical descriptors of the content. This finding suggests that bookmarking has a strong personal aspect which we will cater for in our experiment. Vallet et al. [50] compiled a collection of more than 300k Delicious bookmarks and several million tags to describe them. For a share of 3.8k bookmarks and 180 topics, the authors collected manual relevance assessments along two dimensions, topical relevance of the bookmark given the topic and personal relevance of the bookmark for the user. This dataset is one of the very few corpora whose personalized relevance judgements were made by the actual users being profiled. We conduct a retrieval experiment in which we estimate topical and personal relevance for each document and use Gumbel copula models to model the joint distribution of facets. The set of relevant documents comprises only those bookmarks that satisfy both criteria and were judged relevant in terms of topicality and personal relevance. Table 3 shows an overview of the resulting retrieval performances. CNEG stands out as the strongest copula-based model but the overall ranking of systems depends on the concrete metrics evaluated. For some metrics such as precision at rank 10 and MRR, the linear combination baseline prevails, BPREF and precision at 5 documents favour CNEG.",1,corpora,True
170,4.3 Child-friendly websites,0,,False
171,"The third application domain that we will inspect is concerned with the retrieval of child-friendly websites. Children, especially at a young age, are an audience with specific needs that deviate significantly from those of standard web users. Even for adult users it has been shown that focussing",1,ad,True
172,Table 4: Copula-based relevance estimation perfor-,0,,False
173,"mance for child-friendly websites (k , 2).",0,,False
174,Method P@5 P@10 p@100 BPREF MRR MAP,1,MAP,True
175,PROD SUM LIN CPOS CNEG,0,,False
176,0.240 0.246 0.320* 0.238 0.242,0,,False
177,0.143 0.157 0.187* 0.140 0.140,0,,False
178,0.051 0.052 0.071* 0.053 0.048,0,,False
179,0.221 0.213 0.275* 0.215 0.223,0,,False
180,0.349 0.340 0.357 0.351 0.349,0,,False
181,0.196 0.200 0.235* 0.200 0.194,0,,False
182,CODDS 0.241 0.143 0.052 0.220 0.349 0.196,0,,False
183,"the retrieval process on material of appropriate reading level can benefit user satisfaction [12]. In the case of children, this tendency can be expected to be even more pronounced since young users show very different modes of interaction with search engines that reflect their specific cognitive and motor capabilities [16]. Consequently, dedicated web search engines for children should focus their result sets on topically relevant, yet age-appropriate documents. [17] constructed a corpus of 22k web pages, 1,000 of which were manually annotated in terms of topical relevance towards a query as well as the document's likelihood of suitability for children. According to the authors, the class of suitable documents encompasses those pages that were topically relevant for children, presented in a fun and engaging way and textually not too complex to be understood. In our retrieval experiment, we account for both criteria and require documents to be both on topic as well as suitable for children in order to be considered relevant. Table 4 gives an overview of the resulting retrieval performance. In this setting, the various copula models show comparable result quality as the non parametric baselines. Linear combinations with empirically learned weights, however, were consistently the strongest method. We intend to explore the reasons for this in future work. However we note that the distribution of child-suitable ratings has a very large mode at zero, with only a small number of non-zero scores taking a limited number of possible discrete values - limiting the amount of useful dependency information available that copulas could exploit.",1,ad,True
184,5. SCORE FUSION,0,,False
185,"Previously, we investigated the usefulness of copulas for modelling multivariate document relevance scores based on a number of (largely) orthogonal document quality criteria. Now, we will address a different, closely related problem: score fusion (also known as an instance of data fusion). In this setting, rather than estimating document quality from the documents, we attempt to combine the output of several independent retrieval systems into one holistic ranking. This challenge is often encountered in the domains of metasearch or search engine fusion. To evaluate the score fusion performance of copula-based methods, we use historic submissions",1,ad,True
186,668,0,,False
187,"to the TREC Adhoc and Web tracks. We investigate 6 years of TREC (1995 - 2000) and fuse the document relevance scores produced by several of the original participating systems. Intuitively, this task closely resembles the previously addressed relevance estimation based on individual document properties. In practice, as we will show, the scenario differs from direct relevance estimation in that retrieval systems rely on overlapping notions of document quality (e.g., a variant of tf/idf scoring) and are therefore assumed to show stronger inter-criteria dependencies than individual facets of document quality might. Systematically, however, we address a set of document-level scores Ur(ekl), originating from k retrieval systems, exactly in the same way as we did document quality criteria in the previous section. As performance baselines, we will rely on two popular score fusion schemes, CombSUM and CombMNZ [19]. CombSUM adds up the scores of all k constituent retrieval models and uses the resulting sum as a new document score. CombMNZ tries to account for score outliers by multiplying the crosssystem sum by NZ (U ), the number of non-zero constituent scores.",1,TREC,True
188,k,0,,False
189,"CombSUM (Urel ) ,"" urel,i""",0,,False
190,"i,1",0,,False
191,k,0,,False
192,"CombMNZ (Urel ) ,"" NZ (Urel ) urel,i""",0,,False
193,"i,1",0,,False
194,"We introduce statistically principled, copula-based extensions of these established baseline methods: corresponding to CombSUM and CombMNZ, we define CopSUM and CopMNZ that normalize the respective baseline methods by the non-relevance copula.",0,,False
195,"CopSUM (Urel , Unon )",0,,False
196,",",0,,False
197,"k i,1",0,,False
198,"urel ,i",0,,False
199,Cnon (Unon ),0,,False
200,"CopMNZ (Urel , Unon ) ,",0,,False
201,NZ (Urel ),0,,False
202,"k i,1",0,,False
203,"urel ,i",0,,False
204,Cnon (Unon ),0,,False
205,"Due to the close relationship to the baseline methods, the effect of introducing copulas is easily measurable. Based on empirical evidence, we employ Clayton copulas to estimate Cnon (Unon ).",0,,False
206,"Table 5 compares the baselines and copula methods in terms of MAP gain over the best, worst and median historic system run that were fused. Each performance score is averaged over 200 repetitions of randomly selecting k individual runs with k ranging from 2 to 10 for each year of TREC. Statistically significant improvements over the respective baseline method, i.e. of CopSUM over CombSUM and CopMNZ over CombMNZ, are determined by a Wilcoxon signed-rank test at  , 0.05 level and are denoted by an asterisk.",1,MAP,True
207,"Regarding the baseline methods, CombSUM and CombMNZ perform equally well on average, but with a clear dataset bias. On TREC 4, 8 and 9, CombSUM performs consistently better than CombMNZ. For TREC 5, 6 and 7, the inverse is true. With the exception of TREC 4, the fused rankings do not match the performance of the single strongest run that contributed to the fusion.",1,TREC,True
208,"Introducing the copula methods led to consistent improvements over their non-copula baseline counterparts. In 104 out of 168 cases, the copula-based fusion methods gave statistically significant gains, with only 14 out 168 performing",0,,False
209,"worse than the corresponding baseline method. The copulabased methods achieved, on average, 7% gains over the corresponding baseline when comparing to the strongest fused system, 4% gain on median systems and 2% gain on the weakest systems.",0,,False
210,Fusion robustness,0,,False
211,"There are significant differences in fusion effectiveness between individual editions of TREC. Comparing TREC 4 and TREC 6, for example, we observe that TREC 6 fusion results typically showcase performance losses in comparison to the best original run and very high gains for the weakest systems. We seek an explanation in the imbalance in performance of the original systems. Very weak systems have the potential of decreasing the overall quality of the fused result list by boosting the scores of non-relevant documents. As the number of very weak systems increases, so does the chance for performance losses introduced by fusion. When inspecting the number weak submissions (defined as having an MAP score that is at least 2 standard deviations lower than the average score across all participants) included in our fusion experiments, we find that, indeed, our TREC 6 sample includes 27% more weak systems than that of TREC 4.",1,TREC,True
212,"In order to further investigate the influence of weak runs on overall fusion performance and to measure the proposed methods' robustness against this effect, we turn to the 10system fusion scenario and inject more and more weak systems among the regular ones. Figure 3 shows how the fusion improvement over the single strongest system of TREC 4 is affected as the number of weak submissions ranges from 0 to 9 out of 10. As before, each data point is an average across 200 fusions of randomly drawn runs. In the ideal setting, in which there are no weak systems, we note higher performance gains than in the uncontrolled scenario that was shown in Table 5. As the number of weak systems injected into the fusion increases, performance scores quickly drop. As noted earlier, CombSUM performs slightly better on TREC 4 than CombMNZ. This difference, however, is not further influenced by the number of weak systems. The copula-based fusion methods are more resistant to the influence of weak systems. We note the divide between copulamethods and baseline approaches growing as the number of weak systems increases. Each baseline system score is wellseparated from the respective copula-based variant. Error bars in Figure 3 were omitted to prevent clutter.",1,TREC,True
213,6. DISCUSSION,0,,False
214,"In Section 4, we investigated three different domains in which we apply copulas to model the joint distribution of multivariate relevance scores. For each of these settings, we could observe varying degrees of usefulness of the proposed copula scheme. While for child-friendly web search, the linear baseline performed best, we achieved significant improvements in the opinionated blog retrieval setting. At this point, we investigate the reason for this seeming imbalance in performance gains in order to find a way of deciding for which problem domains the application of copulas is most promising.",1,blog,True
215,"One of the key properties of copulas is their ability to account for tail dependencies. Formally, tail dependence describes the likelihood that component urel,i within the observation vector Ur(ekl) will take on extremely high or low values,",0,,False
216,669,0,,False
217,"Table 5: Score fusion performance based on historic TREC submissions. Evaluated in percentages of MAP improvements over the best, median, and worst original systems that were fused.",1,TREC,True
218,TREC 4,1,TREC,True
219,CombSUM CopSUM CombMNZ CopMNZ,0,,False
220,Best,0,,False
221,-9.8 -9.6* -9.5 -9.5,0,,False
222,2 runs Med.,0,,False
223,-,0,,False
224,Worst,0,,False
225,118 116 116 115,0,,False
226,Best,0,,False
227,-4.2 -4.2 -5.4 -5.5,0,,False
228,4 runs Med.,0,,False
229,20 20.5* 18.3 18.2,0,,False
230,Worst,0,,False
231,1128 1136 1071 1080,0,,False
232,Best,0,,False
233,0.0 0.0 -1.1 -1.0,0,,False
234,6 runs Med.,0,,False
235,33.5 33.8* 31.6 31.9*,0,,False
236,Worst,0,,False
237,1709 1721 1675 1689*,0,,False
238,Best,0,,False
239,3.0 3.2* 2.1 1.8,0,,False
240,8 runs Med.,0,,False
241,39.6 40.0* 38.3 38.6*,0,,False
242,Worst,0,,False
243,2344 2350 2310 2318*,0,,False
244,Best,0,,False
245,3.9 4.0 3.6 3.8*,0,,False
246,10 runs Med. Worst,0,,False
247,48.5 3116 49.2* 3125* 48.0 3106 48.0 3117*,0,,False
248,TREC 5,1,TREC,True
249,CombSUM CopSUM CombMNZ CopMNZ,0,,False
250,Best,0,,False
251,-5.6 -5.2* -4.6 -4.5,0,,False
252,2 runs Med.,0,,False
253,-,0,,False
254,Worst,0,,False
255,268 274* 269 274*,0,,False
256,Best,0,,False
257,-10.6 -9.9* -6.7 -6.5,0,,False
258,4 runs Med.,0,,False
259,12.5 13.0* 17.4 17.8*,0,,False
260,Worst,0,,False
261,614 613 652 667*,0,,False
262,Best,0,,False
263,-6.9 -6.7* -3.5 -3.1*,0,,False
264,6 runs Med.,0,,False
265,26.5 28.0* 30.9 32.2*,0,,False
266,Worst,0,,False
267,955 972* 986 991,0,,False
268,Best,0,,False
269,-5.3 -4.9* -2.5 -2.4,0,,False
270,8 runs Med.,0,,False
271,34.3 35.0* 38.2 38.7*,0,,False
272,Worst,0,,False
273,1031 1050* 1074 1092,0,,False
274,Best,0,,False
275,-5.6 -5.2* -3.3 -3.0*,0,,False
276,10 runs,0,,False
277,Med. Worst,0,,False
278,40.1 43.3* 43.5 46.0*,0,,False
279,1479 1503* 1526 1554*,0,,False
280,TREC 6,1,TREC,True
281,CombSUM CopSUM CombMNZ CopMNZ,0,,False
282,Best,0,,False
283,-18.5 -17.7* -17.0 -16.3*,0,,False
284,2 runs Med.,0,,False
285,-,0,,False
286,Worst,0,,False
287,486 471 491 490,0,,False
288,Best,0,,False
289,-24.6 -23.1* -18.6 -17.2*,0,,False
290,4 runs Med.,0,,False
291,7.8 9.1* 15.5 17.4*,0,,False
292,Worst,0,,False
293,2235 2279* 2537 2601*,0,,False
294,Best,0,,False
295,-24.0 -22.9* -18.1 -17.9,0,,False
296,6 runs Med.,0,,False
297,29.6 32.1* 38.8 40.5*,0,,False
298,Worst,0,,False
299,3950 4075* 4386 4458*,0,,False
300,Best,0,,False
301,-22.8 -21.2* -16.7 -16.7,0,,False
302,8 runs Med.,0,,False
303,44.9 48.3* 55.0 59.6*,0,,False
304,Worst,0,,False
305,5585 5699* 6111 6202*,0,,False
306,10 runs Best Med. Worst,0,,False
307,-22.1 56.9 7685,0,,False
308,-20.8* 58.2* -17.3 65.0 -16.4* 66.8*,0,,False
309,7702 8117 8170,0,,False
310,TREC 7,1,TREC,True
311,CombSUM CopSUM CombMNZ CopMNZ,0,,False
312,Best,0,,False
313,-9.3 -9.4 -8.8 -8.8,0,,False
314,2 runs Med.,0,,False
315,-,0,,False
316,Worst,0,,False
317,132 145* 130 139*,0,,False
318,Best,0,,False
319,-16.2 -15.8* -13.7 -13.3*,0,,False
320,4 runs Med.,0,,False
321,6.2 6.5* 9.4 10.1*,0,,False
322,Worst,0,,False
323,303 321* 347 363*,0,,False
324,Best,0,,False
325,-11.7 -11.1* -10.1 -10.2,0,,False
326,6 runs Med.,0,,False
327,25.9 27.2* 28.1 30.5*,0,,False
328,Worst,0,,False
329,504 538* 538 565*,0,,False
330,Best,0,,False
331,-12.8 -12.3* -10.9 -10.7,0,,False
332,8 runs Med.,0,,False
333,30.0 34.1* 32.8 34.7*,0,,False
334,Worst,0,,False
335,708 734* 745 786*,0,,False
336,10 runs Best Med. Worst,0,,False
337,-14.5 36.3 863 -13.8* 39.1* 877 -13.1 38.5 891 -12.4* 40.4* 922,0,,False
338,TREC 8,1,TREC,True
339,CombSUM CopSUM CombMNZ CopMNZ,0,,False
340,Best,0,,False
341,-15.9 -16.1 -17.2 -17.3,0,,False
342,2 runs Med.,0,,False
343,-,0,,False
344,Worst,0,,False
345,475 488 421 447*,0,,False
346,Best,0,,False
347,-11.6 -10.1* -11.8 -11.2,0,,False
348,4 runs Med.,0,,False
349,8.1 8.3 7.6 7.9*,0,,False
350,Worst,0,,False
351,1188 1201 1273 1292,0,,False
352,Best,0,,False
353,-11.5 -10.9* -12.9 -12.8,0,,False
354,6 runs Med.,0,,False
355,16.9 16.7 15.1 14.9,0,,False
356,Worst,0,,False
357,3194 3195 3209 3216,0,,False
358,Best,0,,False
359,-7.7 -7.3* -9.8 -9.2*,0,,False
360,8 runs Med.,0,,False
361,21.8 22.3* 18.6 19.7*,0,,False
362,Worst,0,,False
363,2739 2755 2660 2685,0,,False
364,Best,0,,False
365,-5.4 -4.3* -7.2 -6.7*,0,,False
366,10 runs,0,,False
367,Med. Worst,0,,False
368,21.8 22.4 19.2 20.5*,0,,False
369,3372 3397 3266 3301*,0,,False
370,TREC 9,1,TREC,True
371,CombSUM CopSUM CombMNZ CopMNZ,0,,False
372,Best,0,,False
373,-9.0 -8.5* -11.0 -10.7,0,,False
374,2 runs Med.,0,,False
375,-,0,,False
376,Worst,0,,False
377,173 188* 155 167,0,,False
378,Best,0,,False
379,-14.9 -13.7* -19.0 -17.9*,0,,False
380,4 runs Med.,0,,False
381,20.4 21.2* 14.5 16.0*,0,,False
382,Worst,0,,False
383,473 499* 435 432,0,,False
384,Best,0,,False
385,-15.6 -15.3 -17.4 -17.1,0,,False
386,6 runs Med.,0,,False
387,17.4 17.9 14.4 14.7,0,,False
388,Worst,0,,False
389,178 182 172 176,0,,False
390,Best,0,,False
391,-21.3 -20.9 -25.3 -24.8*,0,,False
392,8 runs Med.,0,,False
393,18.9 19.2* 12.6 13.0*,0,,False
394,Worst,0,,False
395,202 207 186 190,0,,False
396,10 runs Best Med. Worst,0,,False
397,-27.9 12.6 204 -26.6* 13.1* 206 -32.7 4.7 184 -30.4* 5.1* 187,0,,False
398,"as another component urel,j with i ,"" j also takes an extreme value. The strength of this correlation in extreme regions is expressed by the tail dependency indices IU and IL for upper and lower tail dependency, respectively. Higher values of I signal stronger dependencies in the respective tail regions of the distribution.""",0,,False
399,"IU , P {X1 > Fi-1(ui)|X2 > Fj-1(uj )}",0,,False
400,"IL , P {X1  Fi-1(ui)|X2  Fj-1(uj )}",0,,False
401,The literature has brought forward a number of estimators of the tail indices. We use the R implementation of Frees et al.'s method [20].,0,,False
402,"Tail index estimates serve as good tools for separating domains where we are likely to observe performance gains (blog and bookmark retrieval) and those that do not match linear combination performance (child-friendly search). Based on the respective copula models that we fit to our observations, the blog retrieval (IL , 0.07) and personalized bookmarking (IU , 0.49) show moderate tail dependencies while the",1,blog,True
403,"child-friendly web search task has no recognizable dependency among extrema (IL , IU ,"" 0). Since the comparison of absolute tail index scores across observations is not meaningful, we are interested in a method to further narrow down the expected performance. To this end, we took a closer look at the actual data distribution, and investigated goodness-of-fit tests that are used to determine how well an assumed theoretical distribution fits the empirical observations. The higher the likelihood of our observations to have been generated by the copula models that we estimated, the higher resulting performance we can expect. We apply a standard Anderson-Darling test [3] to determine how well the observations are represented by the copula models. In the personalized bookmarking setting, we obtain p "", 0.47 and for the blog data p ,"" 0.67 for the null hypothesis of the observations originating from the present copula model. As we suspected based on the tail dependency strength, the child-friendly web search data only achieved a probability of fit of p "", 0.046.",1,blog,True
404,670,0,,False
405,Figure 3: Performance in terms of MAP when 0 . . . 9 out of 10 fused original systems are weak.,1,MAP,True
406,"To summarize, in this section, we have shown how a combination of tail dependence indices and goodness-of-fit tests can be used to help differentiate between domains that may benefit from copula-based retrieval models and those that may not.",0,,False
407,7. CONCLUSION,0,,False
408,"In this work we introduced the use of copulas, a powerful statistical framework for modeling complex dependencies, for information retrieval tasks. We demonstrated the effectiveness of copula-based approaches in improving performance on several standard IR challenges. First, we applied copulas to the task of multivariate document relevance estimation, where each document is described by several potentially correlated relevance criteria. We learned and evaluated copula models for three different IR tasks, using largescale standard corpora: (1) opinionated blog retrieval; (2) personalized social bookmarking; and (3) child-friendly web search, obtaining significant improvements on the first two of these tasks. Second, we introduced copula-based versions of two existing score fusion methods, COMB-Sum and COMBMNZ, and showed that these improve the performance of score fusion on historic TREC submissions, in terms of both effectiveness and robustness, compared to their non-copula counterparts. Finally, we investigated the performance differences of copula models between different domains, and proposed the use of tail dependency indices and goodnessof-fit tests to understand the likely effect of using copulas for a given scenario.",1,corpora,True
409,"In future work, there are a number of interesting challenges remaining in applying copula-based models to information retrieval. (1) The independence assumption between individual terms in queries and documents is a longstanding simplification in document and language modelling.",0,,False
410,"Most attempts at incorporating more powerful dependency models into the retrieval process resulted in limited performance improvements at best. We would like to investigate the use of copulas in order to more realistically approximate the complex underlying term dependency structure. (2) During our investigation of the blog retrieval scenario, we encountered examples of non-linear multivariate distributions of relevance and briefly pointed out the different correlation regimes that exist within the joint distribution. While the current single-copula models have been shown to outperform linear combination models at capturing such structures, we would like to proceed to inspecting mixture models in which individual copulas account for certain data ranges to represent the underlying regimes better than a single holistic model could. (3) This work represents an exploratory study that aims to introduce the copula framework to the information retrieval community. For reasons of simplicity and brevity, it is based on data-driven estimation of copula parameters . It would, however, be interesting to build on the large body of previous work on formal modelling of the probability of relevance, to derive custom information retrieval copulas from the assumed distribution of relevance among documents.",1,corpora,True
411,8. REFERENCES,0,,False
412,"[1] Alias-i. LingPipe 3.9.2. http://alias-i.com/lingpipe, 2013.",0,,False
413,[2] M. Ames and M. Naaman. Why we tag: motivations for annotation in mobile and online media. In SIGCHI 2007. ACM.,0,,False
414,"[3] TW Anderson and D.A. Darling. A test of goodness of fit. Journal of the American Statistical Association, 49, 1954.",0,,False
415,"[4] Avi Arampatzis and Stephen Robertson. Modeling score distributions in information retrieval. Information Retrieval, 2011.",0,,False
416,"[5] J.A. Aslam and M. Montague. Bayes optimal metasearch: a probabilistic model for combining the results of multiple retrieval systems (poster session). In Proceedings of SIGIR 2000, pages 379­381. ACM.",0,,False
417,"[6] K. Balog, L. Azzopardi, and M. de Rijke. Formal models for expert finding in enterprise corpora. In Proceedings of SIGIR 2006, pages 43­50. ACM.",1,corpora,True
418,"[7] G. Bordogna and G. Pasi. A model for a SOft Fusion of Information Accesses on the web. Fuzzy Sets and Systems, 148(1):105­118, 2004.",0,,False
419,"[8] P. Borlund. The concept of relevance in IR. JASIST, 2003.",0,,False
420,"[9] J.P. Bouchaud and M. Potters. Theory of financial risk and derivative pricing: from statistical physics to risk management. Cambridge University Press, 2003.",0,,False
421,"[10] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML, pages 89­96. ACM, 2005.",1,ad,True
422,"[11] A. Charpentier, J.D. Fermanian, and O. Scaillet. The estimation of copulas: Theory and practice. Copulas: From theory to Application in Finance. Risk Publications, 2007.",0,,False
423,"[12] K. Collins-Thompson, P.N. Bennett, R.W. White, S. de la Chica, and D. Sontag. Personalizing web search results by reading level. In CIKM 2011. ACM.",1,ad,True
424,671,0,,False
425,"[13] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor. Relevance weighting for query independent evidence. In Proceedings of SIGIR 2005, pages 416­423. ACM.",0,,False
426,"[14] Ronan Cummins. Measuring the ability of score distributions to model relevance. In Information Retrieval Technology. Springer, 2011.",0,,False
427,"[15] C. da Costa Pereira, M. Dragoni, and G. Pasi. Multidimensional relevance: A new aggregation criterion. ECIR 2009.",0,,False
428,"[16] A. Druin, E. Foss, L. Hatley, E. Golub, M.L. Guha, J. Fails, and H. Hutchinson. How children search the internet with keyword interfaces. In Proceedings of the 8th International Conference on Interaction Design and Children, pages 89­96. ACM, 2009.",0,,False
429,"[17] C. Eickhoff, P. Serdyukov, and A.P. de Vries. A combined topical/non-topical approach to identifying web sites for children. In WSDM 2011. ACM.",0,,False
430,"[18] P. Embrechts, F. Lindskog, and A. McNeil. Modelling dependence with copulas and applications to risk management. Handbook of heavy tailed distributions in finance, 8(329-384):1, 2003.",0,,False
431,"[19] E. Fox and J. Shaw. Combination of multiple searches. NIST Special Pub., 1994.",0,,False
432,"[20] E.W. Frees and E.A. Valdez. Understanding relationships using copulas. North American actuarial journal, 2(1), 1998.",0,,False
433,"[21] S. Gerani, C.X. Zhai, and F. Crestani. Score transformation in linear combination for multi-criteria relevance ranking. ECIR 2012.",0,,False
434,"[22] S.P. Harter. Psychological relevance and information science. JASIS, 43(9):602­615, 1992.",0,,False
435,"[23] W. H¨offding. Scale-invariant correlation theory. Schriften des Mathematischen Instituts und des Instituts fur Angewandte Mathematik der Universit¨at Berlin, 5(3):181­233, 1940.",0,,False
436,"[24] X. Huang and W.B. Croft. A unified relevance model for opinion retrieval. In Proceeding of CIKM 2009, pages 947­956. ACM.",0,,False
437,"[25] Evangelos Kanoulas, Keshi Dai, Virgil Pavlu, and Javed A Aslam. Score distribution models: assumptions, intuition, and robustness to score manipulation. In SIGIR 2010. ACM.",0,,False
438,"[26] J.M. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM (JACM), 46(5):604­632, 1999.",0,,False
439,"[27] W. Kraaij, T. Westerveld, and D. Hiemstra. The importance of prior probabilities for entry page search. In SIGIR. ACM, 2002.",0,,False
440,"[28] V. Lavrenko and W.B. Croft. Relevance based language models. In Proceedings of SIGIR 2001, pages 120­127. ACM.",0,,False
441,"[29] V. Lavrenko and W.B. Croft. Relevance models in information retrieval. Language modeling for information retrieval, pages 11­56, 2003.",0,,False
442,"[30] T.Y. Liu. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval, 2009.",0,,False
443,"[31] W. Lu, S. Robertson, and A. MacFarlane. Field-weighted xml retrieval based on bm25. Advances in XML Information Retrieval and Evaluation, pages 161­171, 2006.",0,,False
444,"[32] C. Macdonald, R.L.T. Santos, I. Ounis, and I. Soboroff. Blog track research at trec. In SIGIR Forum 2010. ACM.",1,trec,True
445,"[33] R. Manmatha, Toni M. Rath, and Fangfang Feng. Modeling score distributions for combining the outputs of search engines. In SIGIR 2001.",0,,False
446,"[34] S. Mizzaro. Relevance: The whole history. JASIS, 1997.",0,,False
447,"[35] M. Montague and J.A. Aslam. Condorcet fusion for improved retrieval. In Proceedings of CIKM 2002, pages 538­548. ACM.",0,,False
448,[36] M. Montague and J.A. Aslam. Relevance score normalization for metasearch. In CIKM 2001. ACM.,0,,False
449,"[37] A. Onken, S. Gru¨new¨alder, M.H.J. Munk, and K. Obermayer. Analyzing short-term noise dependencies of spike-counts in macaque prefrontal cortex using copulas and the flashlight transformation. PLoS computational biology, 5(11):e1000577, 2009.",0,,False
450,"[38] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered document retrieval with frequency-sorted indexes. JASIS, 47(10):749­764, 1996.",0,,False
451,"[39] J.M. Ponte and W.B. Croft. A language modeling approach to information retrieval. In Proceedings of SIGIR 1998, pages 275­281. ACM.",0,,False
452,"[40] F. Radlinski and T. Joachims. Query chains: learning to rank from implicit feedback. In SIGKDD, pages 239­248. ACM, 2005.",1,ad,True
453,"[41] B. Renard and M. Lang. Use of a gaussian copula for multivariate extreme value analysis: Some case studies in hydrology. Advances in Water Resources, 30(4):897­912, 2007.",0,,False
454,"[42] S. Robertson, H. Zaragoza, and M. Taylor. Simple BM25 extension to multiple weighted fields. In CIKM 2004.",0,,False
455,"[43] S.E. Robertson, S. Walker, M.M. Hancock-Beaulieu, and M. Gatford. Okapi at TREC-3. Gaithersburgh, MD, 1994.",1,TREC,True
456,"[44] T. Saracevic. Relevance reconsidered. In Conference on Conceptions of Library and Information Science, 1996.",0,,False
457,"[45] L. Schamber, M.B. Eisenberg, and M.S. Nilan. A re-examination of relevance: toward a dynamic, situational definition. IPM, 26(6):755­776, 1990.",0,,False
458,"[46] T. Schmidt. Coping with copulas. Risk Books: Copulas from Theory to Applications in Finance, 2007.",0,,False
459,"[47] C. Schoelzel, P. Friederichs, et al. Multivariate non-normally distributed random variables in climate research­introduction to the copula approach. Nonlin. Processes Geophys., 15(5):761­772, 2008.",0,,False
460,"[48] A. Sklar. Fonctions de r´epartition a` n dimensions et leurs marges. Publ. Inst. Statist. Univ. Paris, 8(1):11, 1959.",0,,False
461,[49] T. Tsikrika and M. Lalmas. Combining evidence for relevance criteria: a framework and experiments in web retrieval. ECIR 2007.,0,,False
462,[50] D. Vallet and P. Castells. Personalized diversification of search results. In SIGIR 2012. ACM.,0,,False
463,"[51] C.C. Vogt and G.W. Cottrell. Fusion via a linear combination of scores. Information Retrieval, 1(3):151­173, 1999.",0,,False
464,[52] S. Wu and F. Crestani. Data fusion with estimated weights. In CIKM 2002. ACM.,0,,False
465,672,0,,False
466,,0,,False
