,sentence,label,data,regex
0,Extracting Query Facets from Search Results,1,Query,True
1,Weize Kong and James Allan,0,,False
2,Center for Intelligent Information Retrieval School of Computer Science,0,,False
3,"University of Massachusetts Amherst Amherst, MA 01003",0,,False
4,"{wkong, allan}@cs.umass.edu",0,,False
5,ABSTRACT,0,,False
6,"Web search queries are often ambiguous or multi-faceted, which makes a simple ranked list of results inadequate. To assist information finding for such faceted queries, we explore a technique that explicitly represents interesting facets of a query using groups of semantically related terms extracted from search results. As an example, for the query ""baggage allowance"", these groups might be different airlines, different flight types (domestic, international), or different travel classes (first, business, economy). We name these groups query facets and the terms in these groups facet terms. We develop a supervised approach based on a graphical model to recognize query facets from the noisy candidates found. The graphical model learns how likely a candidate term is to be a facet term as well as how likely two terms are to be grouped together in a query facet, and captures the dependencies between the two factors. We propose two algorithms for approximate inference on the graphical model since exact inference is intractable. Our evaluation combines recall and precision of the facet terms with the grouping quality. Experimental results on a sample of web queries show that the supervised method significantly outperforms existing approaches, which are mostly unsupervised, suggesting that query facet extraction can be effectively learned.",1,ad,True
7,Categories and Subject Descriptors,0,,False
8,"H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval--Clustering, Query formulation",1,Query,True
9,General Terms,0,,False
10,"Algorithms, Experimentation",0,,False
11,Keywords,0,,False
12,"Query Facet, Semantic Class Extraction, Multi-faceted Query",1,Query,True
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.",1,ad,True
14,1. INTRODUCTION,1,DUC,True
15,"Web search queries are often ambiguous or multi-faceted [27]. Current popular approaches try to diversify the result list to account for different search intents or query subtopics [24]. A weakness of this approach is that the query subtopics are hidden from the user, leaving him or her to guess at how the results are organized.",0,,False
16,"In this work, we attempt to extract query facets from web search results to assist information finding for these queries. We define a query facet as a set of coordinate terms ­ i.e., terms that share a semantic relationship by being grouped under a more general hypernym (""is a"" relationship). For example, for the query mars landing, three possible query facets are shown in Table 1.",0,,False
17,"Table 1: Example query facets Query: mars landing 1. Curiosity, Opportunity, Spirit 2. USA, UK, Soviet Union 3. video, pictures, news Query: baggage allowance 1. Delta, Jetblue, AA, Continental, ... 2. domestic, international 3. first class, business class, economy class 4. weight, size, quantity Query: mr bean 1. comics, movies, tv, books 2. the curse of mr bean, mr bean goes to town, ... 3. rowan atkinson, richard wilson, jean rochefort, ... 4. mr bean, irma gobb, rupert, hubert, ...",1,Query,True
18,"The first query facet, {Curiosity, Opportunity, Spirit}, includes different Mars rovers. The second query facet, {USA, UK, Soviet Union}, includes countries relevant to Mars landings. These are both facets where the terms are instances of the same semantic class. Somewhat differently, the last facet, {video, pictures, news}, includes labels for different query subtopics. These labels can be viewed as instances of a special semantic class, the subtopics of the query mars landing.",0,,False
19,"Query facets can be used to help improve search experience in many ways. Like in faceted search [6], query facets can help users to navigate through different topics of the search results by applying multiple filters. Using the examples in Table 1, for query baggage allowance, a user can select Delta, international, business class, quantity from each of its facets, to find pages discussing the number of bags allowed on Delta's international business class flights. Query facets",1,Query,True
20,93,0,,False
21,"can also be used as query suggestions or clarification questions to help users specify search intent. For example, for the query mars landing, a system might suggest the query facet {video, pictures, news} or generate clarification questions like ""Which Mars rover are you looking for? a) Curiosity, b) Opportunity, c) Spirit"". Query facets are also useful for exploratory search since they succinctly summarize interesting facts for the issued query. For example, facets for the query mr bean list episodes titles, characters and casts for the Mr. Bean television series.",1,Query,True
22,"In this paper we develop a supervised method based on a graphical model for query facet extraction. The graphical model learns how likely it is that a term should be selected and how likely it is that two terms should be grouped together in a query facet. Further, the model captures the dependencies between the two factors. We propose two algorithms for approximate inference on the graphical model since exact inference is intractable. Also, we design an evaluation metric for query facet extraction, which combines recall and precision of the facet term, with the grouping quality.",0,,False
23,"The rest of this paper is organized as follows. We discuss related work in Section 2, and then present the problem formulation in Section 3. Section 4 describes the general framework we use for query facet extraction. Section 5 describes our graphical model based approach in detail. Section 6 briefly describes two alternate approaches that we use as baselines. We describe the dataset as well as the metrics we used for evaluation in Section 7, and report experimental results in Section 8. Finally, we conclude the work in Section 9.",0,,False
24,2. RELATED WORK,0,,False
25,Related work of query facet extraction can be divided into the following topics.,0,,False
26,2.1 Search Results Diversification,0,,False
27,"Search result diversification has been studied as a method of tackling ambiguous or multi-faceted queries while a ranked list of documents remains the primary output feature of Web search engine today[24]. It tries to diversify the ranked list to account for different search intents or query subtopics. A weakness of search result diversification is that the query subtopics are hidden from the user, leaving him or her to guess at how the results are organized. Query facet extraction addresses this problem by explicitly presenting different facets of a queries using groups of coordinate terms.",1,Query,True
28,2.2 Search Results Clustering/Organization,0,,False
29,"Search results clustering is a technique that tries to organize search results by grouping them into, usually labeled, clusters by query subtopics [4]. It offers a complementary view to the flat ranked list of search results. Most previous work exploited different textual features extracted from the input texts and applied different clustering algorithms with them. Instead of organizing search results in groups, there is also some work [14, 15, 16] that summarizes search results or a collection of documents in a topic hierarchy. For example, Lawrie et al. [14, 15] used a probabilistic model for creating topical hierarchies, in which a graph is constructed based on conditional probabilities of words, and the topic words are found by approximately maximizing the predictive power and coverage of the vocabulary. Our work is different from",1,ad,True
30,"these work in that our target is to extract different facets of a query from search results, instead of organizing the search results.",1,ad,True
31,2.3 Query Subtopic/Aspect Mining,1,Query,True
32,"To address multi-faceted queries, much previous work studied mining query subtopics (or aspects). A query subtopic is often defined as a distinct information need relevant to the original query. It can be represented as a set of terms that together describe the distinct information need [29, 31, 5] or as a single keyword that succinctly describes the topic [28]. Different resources have been used for mining query subtopics, including query logs [30, 11, 32, 29, 31, 33], document corpus [2] and anchor texts [5].",1,ad,True
33,"A query subtopic is different from a query facet in that the terms in a query subtopic are not restricted to be coordinate terms, or have peer relationships. Query facets, however, organize terms by grouping ""sibling"" terms together. For example, {news, cnn, latest news, mars curiosity news} is a valid query subtopic for the query mars landing, which describes the search intent of Mars landing news, but it is not a valid query facet, given our definition, since the terms in it are not coordinate terms. A valid query facet that describes Mars landing news could be {cnn, abc, fox }, which includes different news channels. In a recent work [7], Dou et al. developed a system to extract query facets from web search results and showed the potential of doing so. However, the unsupervised method they proposed is far from optimal, and it does not improve by having human labels available. Also, to the best of our knowledge, their evaluation can be problematic in some cases, which will be discussed in Section 7.2.3.",1,Query,True
34,2.4 Semantic Class Mining,0,,False
35,"Semantic class mining can be used to help query facet extraction. Class attribute extraction [17, 18] aims to extract attributes for a target semantic class usually specified by as a set of representative instances. For example, given a semantic class country, together with some instances like USA, UK, China, some class attributes can be capital city, president, population. Those extracted class attributes can be used as query subtopics. However, class attribute extraction targets semantic classes, not general search queries.",0,,False
36,"Semantic class extraction aims to automatically mine semantic classes represented as their class instances from certain data corpus. Existing approaches can be roughly divided into two categories: distributional similarity and pattern-based [25]. The distributional similarity approach is based on the distributional hypothesis [8], that terms occurring in analogous contexts tend to be similar. Different types contexts has been studied for this problem, including syntactic context [20] and lexical context [21, 1, 19]. The patternbased approach applied textual patterns [9, 22], HTML patterns [26] or both [34, 25] to extract instances of a semantic class from some corpus. The raw semantic class extracted can be noisy. To address this problem, Zhang et al. [34] used topic modeling to refine the extracted semantic classes. Their assumption is that, like documents in the conventional setting, raw semantic classes are generated by a mixture of hidden semantic class. In this paper, we apply pattern-based semantic class extraction on the top-ranked Web documents to extract candidates for finding query facets.",1,ad,True
37,94,0,,False
38,2.5 Faceted Search,0,,False
39,"Faceted search is a technique for accessing information organized according to a faceted classification system, allowing users to digest, analyze and navigate through multidimensional data. It is widely used in e-commerce and digital libraries [6]. Faceted search is similar to query facet extraction in that both of them use sets of coordinate terms to represent different facets of a query. However, most existing works for faceted search are build on as specific domain or predefined categories [7], while query facet extraction does not restrict queries in a specific domain, like products, people, etc.",0,,False
40,3. PROBLEM FORMULATION,0,,False
41,"Query facet extraction is the problem of finding query facets for a given query q from available resources, such as web search results. A query facet F ,"" {t} is a set of coordinate terms, terms that are part of a semantic set, which we call facet terms. These facet terms can be instances of a semantic class, for example Curiosity, Opportunity, Spirit are all Mars rovers. They can be labels for query subtopics, such as video, pictures, news for the query mars landing. We use F "", {F } to denote the set of query facets. TF ,"" {t|t  F, F  F } is the set of all the facets terms that appear in F.""",1,Query,True
42,"Query facets can be extracted from a variety of different resources, such as a query log, anchor text, taxonomy and social folksonomy. In this work, we only focus on extracting query facets from the top k web search results D ,"" {D1, D2, . . . , Dk}. We intend to explore the use of other information sources for this problem in future work.""",1,Query,True
43,4. GENERAL FRAMEWORK,0,,False
44,"In this section, we describe the general framework we use for extracting query facet from web search results. Given a query q, we retrieve the top k search results, D, as input to our system. Then query facets F are extracted by, first, extracting candidates from search results D and then finding query facets from the candidates.",0,,False
45,4.1 Extracting candidate lists,0,,False
46,"Similar to Dou et al. [7], we use pattern-based semantic class extraction approach [25] to extract lists of coordinate terms from search results as candidates for query facets. In pattern-based semantic class extraction, patterns are applied on the corpus to discover specific relationships between terms. For example, the pattern ""NP such as NP, NP, ..., and NP "" can be used to extract coordinate terms and their hypernyms from text. Besides lexical patterns, HTML patterns are often used on HTML documents to extract coordinate terms from some HTML structures, like <UL>, <SELECT> and <TABLE>.",1,NP,True
47,Table 2: Semantic class extraction patterns,0,,False
48,Type Pattern,0,,False
49,"Lexical item, {,item}, (and|or) {other} item",0,,False
50,<select><option>item </option>...</select>,0,,False
51,HTML,0,,False
52,<ul><li>item </li>...</ul> <ol><li>item </li>...</ol>,0,,False
53,<table><tr><td>item <td>...</table>,0,,False
54,"We use both of the two types of patterns, summarized in",0,,False
55,"Table 2. In the table, all items in each pattern are extracted as a candidate list. For example, from the text sentence ""... Mars rovers such as Curiosity, Opportunity and Spirit"", according to the lexical pattern, we will extract a candidate list {Curiosity, Opportunity, Spirit}. For the lexical pattern, we also restrict those items to be siblings in the parse tree of that sentence. We use the PCFG parser [12] implemented in Stanford CoreNLP1 for parsing documents. For HTML tables, following Dou et al. [7], lists from each column and each row are extracted.",0,,False
56,"After extracting the lists from the top ranked results D, we further process them as follows. First, all the list items are normalized by converting text to lowercase and removing non-alphanumeric characters. Then, we remove stopwords and duplicate items in each lists. Finally, we discard all lists that contain fewer than two item or more than 200 items. After this process, we have a set of candidate lists L ,"" {L}, where each list L "", {t} is a set of list items.",0,,False
57,4.2 Finding query facets from candidate lists,0,,False
58,"The candidate lists extracted are usually noisy [34], and could be non-relevant to the issued query, therefore they cannot be used directly as query facets. Table 3 shows four candidate lists extracted for the query mars landing. L1 contains list items that are relevant to mars landing, but they are not coordinate terms. L2 is a valid query facet, but it is incomplete ­ another Mars rover Spirit appears in L3. L3 is extracted from the sentence, ""It is bigger than the 400-pound Mars Exploration rovers, Spirit and Opportunity, which landed in 2004 "". The list item ""the 400 pound mars exploration rovers"" is an extraction error.",0,,False
59,"Table 3: Four candidate lists for query mars landing L1: curiosity rover, mars, nasa, space L2: curiosity, opportunity L3: the 400 pound mars exploration rovers, spirit, opportunity L4: politics, religion, science technology, sports, ...",0,,False
60,"Since the candidate lists are frequently noisy, we need an effective way to find query facets from extracted candidate lists. More formally, given a set of candidate lists L ,"" {l}, the task is to find a set of query facets F , where TF  TL. Similar to TF , TL "","" {t|t  L, L  L} is the set of all list items in L. To address this problem, we develop a graphical model, which learns how likely a list item is a facet term, how likely two list items should be grouped in a query facet, and capture the dependencies between the two factors.""",1,ad,True
61,5. A GRAPHICAL MODEL FOR FINDING QUERY FACETS,1,AP,True
62,"In this section, we describe the directed graphical model we use to find query facts form noisy candidate lists. A directed graphical model (or Bayesian network) is a graphical model that compactly represents a probability distribution over a set of variables [23]. It consists of two parts: 1) a directed acyclic graph in which each vertex represents a variable, and 2) a set of conditional probability distributions that describe the conditional probabilities of each vertex given its parents in the graph.",0,,False
63,"We treat the task of finding query facets from candidate lists as a labeling problem, in which we are trying to predict",0,,False
64,1http://nlp.stanford.edu/software/corenlp.shtml,0,,False
65,95,0,,False
66,"1) whether a list item is a facet term, and 2) whether a pair of list items is in one query facet. Then, we used a directed graphical model to exploit the dependences that exist between those labels. Similar to conditional random fields [13], we directly model the conditional probability P (y|x), where y is the label we are trying to predict and x is the observed data ­ list items and item pairs. Thus, it avoids modeling the dependencies among the input variables x, and can handle a rich set of features. For our graph model, exact maximum a posteriori inference is intractable; therefore, we approximate the results using two algorithms.",0,,False
67,5.1 The Graphical Model,0,,False
68,5.1.1 Graph,0,,False
69,"First we define all the variables in our graphical model. Let Y ,"" {yi}, where yi "","" 1{ti  TF } is a label indicating whether a list item ti is a facet term. Here 1{·} is an indicator function which takes on a value of 1 if its argument is true, and 0 otherwise. pi,j denotes the list items pair (ti, tj ), and PL "","" {pi,j |pi,j "","" (ti, tj ), ti, tj  TL, ti "", tj } denotes all the items pairs in TL. Let Z ,"" {zi,j}, where zi,j "","" 1{F  F , ti  F  tj  F } is a label indicates whether the corresponding item pair pi,j should be grouped together in a query facet. The vertices in our graphical model are V "","" TL  PL  Y  Z. Note that the list items TL, and item pairs PL are always observed.""",0,,False
70,"As shown in Figure 1, there are three types of edges in the graph: 1) edges from each list item ti to its corresponding labels yi; 2) edges that point to each item pair label zi,j from the two corresponding list items yi and yj; 3) edges from each item pair pi,j to its corresponding label zi,j.",0,,False
71,p,0,,False
72,p,0,,False
73,"1,2",0,,False
74,"1,i",0,,False
75,"p 1,j",0,,False
76,"p 2,i",0,,False
77,"p ... 2,j",0,,False
78,...,0,,False
79,...,0,,False
80,...,0,,False
81,...,0,,False
82,z,0,,False
83,z,0,,False
84,z,0,,False
85,z,0,,False
86,z ...,0,,False
87,"1,2",0,,False
88,"1,i",0,,False
89,"1,j",0,,False
90,"2,i",0,,False
91,"2,j",0,,False
92,"p ... i,j",0,,False
93,"z ... i,j",0,,False
94,y1,0,,False
95,y ... 2,0,,False
96,yi,0,,False
97,...,0,,False
98,yj ...,0,,False
99,t1,0,,False
100,t 2 ...,0,,False
101,t i ...,0,,False
102,t j ...,0,,False
103,Figure 1: A graphical model for candidate list data,0,,False
104,5.1.2 Conditional Probability Distribution,0,,False
105,"We use logistic-based conditional probability distributions (CPDs) for variable yi and zi,j, defined as in Equation 1 and Equation 2.",0,,False
106,1,0,,False
107,"P (yi , 1|ti) , 1 + exp{- k kfk(ti)}",0,,False
108,(1),0,,False
109,"P (zi,j",0,,False
110,",",0,,False
111,"1|pi,j , yi, yj )",0,,False
112,",",0,,False
113,"yiyj 1 + exp{- k µkgk(pi,j )}",0,,False
114,(2),0,,False
115,"fk and gk are features that characterize a list item and a item pair respectively.  and µ are the weights associated with fk and gk respectively. Compared to a conventional logistic function, Equation 2 has an extra term, yiyj, in the numerator. When yi , 0 or yj ,"" 0, we have P (zi,j "","" 1|pi,j, yi, yj) "", 0. This means when either of the two list",0,,False
116,"items is not a facet term, the two items can never appear in a query facet together. When both of the ti and tj are facet terms, P (zi,j ,"" 1|pi,j, yi, yj) becomes a conventional logistic function, which models the probability of ti and tj being grouped together in a query facet, given the condition that both ti and tj are facet term.""",0,,False
117,The joint conditional probability for the graphical model is calculated as,0,,False
118,"P (Y, Z|TL, PL) ,",0,,False
119,P (yi|ti),0,,False
120,"P (zi,j |pi,j , yi, yj ) (3)",0,,False
121,yi Y,0,,False
122,"zi,j Z",0,,False
123,where the CPDs are defined in Equation 1 and Equation 2.,0,,False
124,5.1.3 Parameter Estimation,0,,False
125,"The training set for the graphical model can be denoted as {TL, PL, Y , Z}, where Y , Z are the ground truth labels for the list items TL and item pairs PL. The conditional probability of the training set can be calculated according to Equation 4.",0,,False
126,"P (, µ) ,",0,,False
127,"P (Y , Z|TL, PL)",0,,False
128,(4),0,,False
129,"TL ,PL",0,,False
130,"The log-likelihood l(, µ), can be calculated as follows,",0,,False
131,"l(, µ) , lt() + lp(µ)",0,,False
132,(5),0,,False
133,"lt() ,",0,,False
134,log P (yi|ti) -,0,,False
135,k 2k 22,0,,False
136,(6),0,,False
137,TL yiY,0,,False
138,"lp(µ) ,",0,,False
139,"log P (zi,j |pi,j , yi, yj ) -",0,,False
140,k µ2k 22,0,,False
141,(7),0,,False
142,"TL zi,j Z",0,,False
143,"l(, µ) is separated into two parts, lt() and lp(µ). The last terms of Equation 6 and Equation 7 are served as regularizers which penalize large values of , µ.  and  are regularization parameters that control the strength of penalty. Notice that, in the train set, for those item pairs pi,j with any of its list item not being a facet term, their labels zi,j ,"" 0. According to Equation 2, for those item pairs, log P (zi,j|pi,j, yi, yj) "","" 0, which makes no contribution to lp(µ), and thus lp(µ) can be simplified as""",0,,False
144,"lp(µ) ,",0,,False
145,"log P (zi,j |pi,j , yi, yj ) -",0,,False
146,k µ2k 22,0,,False
147,(8),0,,False
148,"TL zi,j Z",0,,False
149,"where Z is a subset of Z, which contains only the labels for item pairs with both of its list items being facet terms.",0,,False
150,"We can see that Equations 6 and 8 are exactly the same as log-likelihoods for two separated logistic regressions. In fact, Equation 6 learns a logistic regression model for whether a list item is a facet term, and Equation 8 learns a logistic regression model for whether two facet terms should be grouped together. The parameter  and µ can be learned by maximizing the log-likelihood using gradient descent, exactly same as in logistic regression.",1,ad,True
151,5.2 Inference,0,,False
152,"When given a new labeling task, we could perform maximum a posteriori inference - compute the most likely labels Y , Z by maximizing the joint conditional probability P (Y, Z|TL, PL). After that, the query facet set F can be easily induced from the labeling Y , Z. (Collect list items with yi ,"" 1 as facet terms, and group any two of them into""",0,,False
153,96,0,,False
154,"a query facet if the corresponding zi,j ,"" 1.) Note that the graphical model we designed does not enforce the labeling to produce strict partitioning for facet terms. For example, when Z1,2 "","" 1, Z2,3 "","" 1, we may have Z1,3 "","" 0. Therefore, an optimal labeling results may induce an overlapping clustering. To simplify the problem, we add the strict partitioning constraint that each facet term belongs to exactly one query facet. Also, to directly produce the query facets, instead of inducing them after predicting labels, we rephrase the optimization problem as follows. First, we use the following notations for log-likelihoods,""",1,ad,True
155,"st(ti) , log P (yi , 1|ti) st(ti) , log (1 - P (yi ,"" 1|ti)) sp(ti, tj ) "","" log P (pi,j "","" 1|pi,j , yi "","" 1, yj "","" 1) sp(ti, tj ) "","" log (1 - P (pi,j "","" 1|pi,j , yi "","" 1, yj "", 1))",0,,False
156,"Using the notations above, the log-likelihood l(F) for a particular query facet set F formed from L can be written as",0,,False
157,"l(F ) , lt(F ) + lp(F )",0,,False
158,"lt(F ) ,",0,,False
159,st(ti) +,0,,False
160,st(ti),0,,False
161,tTF,0,,False
162,tTF,0,,False
163,"lp(F ) ,",0,,False
164,"sp(ti, tj ) +",0,,False
165,"sp(ti, tj ) (9)",0,,False
166,"F F ti,tj F",0,,False
167,"F,F tiF, F tj F",0,,False
168,"In the right hand side of Equation 9, the first term is the intra-facet score, which sums up sp(·, ·) for all the item pairs in each query facet. The second term is the inter-facet score, which sums up the sp(·, ·) for each item pair that appears in different query facets. Then the optimization target becomes F ,"" arg maxFF l(F ), where F is the set of all possible query facet sets that can be generated from L with the strict partitioning constraint.""",0,,False
169,"This optimization problem is NP-hard, which can be proved by a reduction from the Multiway Cut problem [3]. Therefore, we propose two algorithms, QF-I and QF-J, to approximate the results.",1,NP,True
170,5.2.1 QF-I,0,,False
171,"QF-I approximates the results by predicting whether a list item is a facet term and whether two list items should be grouped in a query facet independently, which is accomplished two phases. In the first phase, QF-I selects a set of list items as facet terms according to P (yi|ti). In this way, the algorithm predicts whether a list item ti is a facet term independently, ignoring the dependences between yi and its connected variables in Z. In our implementation, we simply select list items ti with P (ti) > wmin as facet terms. (For convenience, we use P (ti) to denote P (yi ,"" 1|ti).) In the second phase, the algorithm clusters the facet terms TF selected in the first phase into query facets, according to P (ti, tj). (P (ti, tj) is used to denote P (zi,j "","" 1|pi,j, yi "","" 1, yj "","" 1)). Many clustering algorithm can be applied here, using P (ti, tj) as the distance measure. For our implementation, we use a cluster algorithm based on WQT [7], because it considers the importance of nodes while clustering. We use P (ti) as the measure for facet term importance, and dt(ti, tj) "","" 1 - P (ti, tj) as the distance measure for facet terms. The distance between a cluster and a facet term is computed using complete linkage distance, df (F, t) "","" maxt F d(t, t ), and the diameter of a""",0,,False
172,"cluster can be calculated as dia(F ) ,"" maxti,tjF dt(ti, tj ). The algorithm is summarized in Algorithm 1. It processes the facet terms in decreasing order of P (t). For each facet term remaining in the pool, it builds a cluster by iteratively including the facet term that is closest to the cluster, until the diameter of the cluster surpasses the threshold dmax.""",0,,False
173,Algorithm 1 WQT for clustering facet term used in QF-I,0,,False
174,"Input: TF , P (t), df (F, t), dia(F ), dmax Output: F , {F } 1: Tpool  F 2: repeat 3: t  arg maxtTpool P (t) 4: F  {t} 5: iteratively include facet term t  Tpool that is closest",0,,False
175,"to F , according to df (F, t ), until the diameter of the cluster, dia(F ), surpasses the threshold dmax. 6: F  F  {F }, Tpool  Tpool - F 7: until Tpool is empty 8: return F",0,,False
176,5.2.2 QF-J,0,,False
177,"QF-I finds query facets based on the graphical model by performing inference of yi and zi,j independently. The second algorithm, QF-J, instead tries to perform joint inference by approximately maximizing our target l(F) with respect to yi and zi,j iteratively. The algorithm first guesses a set of list items as facet terms. Then it clusters those facet terms by approximately maximizing lp(F ), using a greedy approach. After clustering, the algorithm checks whether each facet term ""fits"" in its cluster, and removes those that do not fit. Using the remaining facet terms, the algorithm repeats the process (clustering and removing outliers) until convergence.",1,ad,True
178,"QF-J is outlined in Algorithm 2. The input to the algorithm are the candidate list item set TL, and the loglikelihoods l(F ), lp(F ). In the first step, we select top n list items according to st(t) as the initial facet terms, because it is less sensitive to the absolute value of the log-likelihood. In our experiment, n is set to 1000 to make sure most of the correct facet terms are included. Then, the algorithm improves l(F) by iteratively performing functions Cluster and RemoveOutliers. Cluster performs clustering over a given set of facet terms. In step 10 to 12, it puts each facet terms into a query facet by greedily choosing the best facet, or creates a singleton for the list item, according to the resulting log-likelihood, lp(F ). We choose to process these list items in decreasing order of st(t), because it is more likely to form a good query facet in the beginning by doing so. RemoveOutliers removes facet terms according to the joint log-likelihood l(F). In step 20 to 22, it checks each facet term to see if it fits in the facet, and removes outliers. F is the set of facet terms the algorithm selected when processing each facet F .",0,,False
179,5.2.3 Ranking Query Facets,1,Query,True
180,"The output of QF-I and QF-J is a query facet set F. To produce ranking results, we defined a score for a query facet as scoreF (F ) ,"" tF P (t), and rank the query facets according to this scoring, in order to present more facet terms in the top. Facet terms within a query facet are ranked according to scoret(t) "", P (t).",0,,False
181,97,0,,False
182,Algorithm 2 QF-J,0,,False
183,"Input: TL ,"" {t}, l, lp""",0,,False
184,"Output: F , {F }",0,,False
185,1: TF  top n list items from TL according to st(·),0,,False
186,2: repeat,0,,False
187,"3: F  Cluster(TF , lp)",0,,False
188,"4: TF  RemoveOutliers(F , l)",0,,False
189,5: until converge,0,,False
190,6: return F,0,,False
191,7:,0,,False
192,"8: function cluster(TF , lp)",0,,False
193,9: F  ,0,,False
194,10: for each t  TF in decreasing order of st(t) do,0,,False
195,11:,0,,False
196,Choose to put t into the best facet in F or add,1,ad,True
197,"t as a singleton into F, whichever that has the highest",0,,False
198,resulting lp(F ).,0,,False
199,12: end for,0,,False
200,13: return F,0,,False
201,14: end function,0,,False
202,15:,0,,False
203,"16: function RemoveOutliers(F, l)",0,,False
204,17: TF  all facet terms in F,0,,False
205,18: for each F  F do,0,,False
206,19:,0,,False
207,"F ,",0,,False
208,20:,0,,False
209,for each t  F in decreasing order of st(·) do,0,,False
210,21:,0,,False
211,"choose to add t into F or not, whichever has",1,ad,True
212,the highest resulting l({F }),0,,False
213,22:,0,,False
214,"if not, TF  F - {t}",0,,False
215,23:,0,,False
216,end for,0,,False
217,24: end for,0,,False
218,25: return TF,0,,False
219,26: end function,0,,False
220,27: return F,0,,False
221,5.3 Features,0,,False
222,There are two types of features used in our graphical,0,,False
223,"model, summarized in Table 4.",0,,False
224,"Item features, fk(t) in the graphical model, character-",0,,False
225,ize a single list item. To capture the relevance of item t,0,,False
226,"to the query, we use some TF/IDF-based features extracted",0,,False
227,"from the top k search results, D. For example, snippetDF",0,,False
228,is the number of snippets in top k search results that con-,0,,False
229,tain item t. snippetDF and other frequency-based features,0,,False
230,are normalized using log(f requency + 1). To capture how,0,,False
231,"likely item t is to be an instance of a semantic class, we",0,,False
232,"use features extracted from candidate lists. For example,",0,,False
233,listTF is the frequency of t in the candidate lists extracted,0,,False
234,from D. Some list items occur frequently in candidate lists,0,,False
235,"across different queries, such as home, contact us and pri-",0,,False
236,"vacy policy. They are treated as stopwords, and removed",0,,False
237,from the candidate lists. We also use listIDF to cope with,0,,False
238,this problem. listIDF is the IDF of a list item in a general,0,,False
239,collection of candidate lists we extracted (see Section 7.1).,0,,False
240,It,0,,False
241,is,0,,False
242,calculated,0,,False
243,as,0,,False
244,listIDF (t),0,,False
245,",",0,,False
246,log,0,,False
247,N -Nt+0.5 Nt +0.5,0,,False
248,",",0,,False
249,where,0,,False
250,N,0,,False
251,is,0,,False
252,"the total number of lists in the collection, Nt is the number",0,,False
253,"of lists contain t. The same form is used for clueIDF, IDF",0,,False
254,in ClueWeb092 collection.,1,ClueWeb,True
255,"Item Pair Features, g(pi,j) in the graphical model, are",0,,False
256,used to capture how likely a pair of list items should be,0,,False
257,"grouped into a query facet, given that the two list item both",0,,False
258,2http://lemurproject.org/clueweb09,0,,False
259,Table 4: Two types of features,0,,False
260,Item Features for list item t,0,,False
261,length,0,,False
262,Number of words in t,0,,False
263,clueIDF,0,,False
264,IDF of t in ClueWeb09 collection,1,ClueWeb,True
265,TF,0,,False
266,Term frequency of t in D,0,,False
267,DF,0,,False
268,Document frequency of t in D,0,,False
269,wDF,0,,False
270,Weighted DF. Each document count weighted by 1/ docRank,0,,False
271,SF,0,,False
272,Site frequency. Number of unique,0,,False
273,websites in D that contain t,0,,False
274,titleTF,0,,False
275,TF of t for the titles of D,0,,False
276,titleDF,0,,False
277,DF of t for the titles of D,0,,False
278,titleSF,0,,False
279,SF of t for the titles of D,0,,False
280,snippetTF,0,,False
281,TF of t for the snippets of D,0,,False
282,snippetDF,0,,False
283,DF of t for the snippets of D,0,,False
284,snippetSF,0,,False
285,SF of t for the snippets of D,0,,False
286,listTF,0,,False
287,Frequency of t in candidate lists,0,,False
288,extracted from D,0,,False
289,listDF,0,,False
290,Number of documents that contain t,0,,False
291,in their candidate lists,0,,False
292,listSF,0,,False
293,Number of unique websites that,0,,False
294,contain t in their candidate lists,0,,False
295,listIDF,0,,False
296,IDF of t in a general candidate list,0,,False
297,collection,0,,False
298,TF.clueIDF,0,,False
299,TF × clueIDF,0,,False
300,listTF.listIDF listTF × lisIDF,0,,False
301,"Item Pair Features for item pair pi,j ,"" (ti, tj)""",0,,False
302,lengthDiff listCooccur,0,,False
303,"Length difference, |len(ti) - len(tj)| Number of candidate lists extracted",0,,False
304,"from D, in which ti, tj co-occur textContextSim Similarity between text contexts",0,,False
305,listContextSim Similarity between list contexts,0,,False
306,"are facet terms. This can be measured by context similarity [25]. For textContextSim, we use window size 25, and represent text context as a vector of TF weights. Cosine similarity is used as the similarity measure. Similarly, we use the candidate lists that contain the list item as its list context, and calculate listContextSim in the same way as textContextSim.",0,,False
307,6. OTHER APPROACHES,1,AP,True
308,"In this section, we describe two alternative approaches for finding query facets from candidate lists. They are used as baselines in our experiments.",0,,False
309,6.1 QDMinder,0,,False
310,"Dou et al. [7] developed QDMiner/QDM for query facet extraction, which appears to be the first work that addressed the problem of query facet extraction. To solve the problem of finding query facets from the noisy candidate lists extracted, they used an unsupervised clustering approach. It first scores each candidate list by combining some TF/IDFbased scores. The candidate lists are then clustered with bias toward important candidate lists, using a variation of the Quality Threshold clustering algorithm [10]. After clustering, clusters are ranked and list items in each clusters are ranked/selected based on some heuristics. Finally, the top k clusters are returned as results. This unsupervised approach does not gain by having human labels available. Also, by clustering lists, they lose the flexibility of breaking a candidate list into different query facets.",1,ad,True
311,98,0,,False
312,6.2 Topic modeling,0,,False
313,"In semantic class extraction, Zhang et al. [34] proposed to use topic models to find high-quality semantic classes from a large collection of extracted candidate lists. Their assumption is, like documents in the conventional setting, candidate lists are generated by a mixture of hidden topics, which are the query facets in our case. pLSA and LDA are used in their experiments. We find this approach can be directly used for finding query facets from candidate lists. The major change we need to make is that: in semantic class extraction, topic modeling is applied globally on the candidate lists (or a sample of them) from the entire corpus; in query facet extraction, we apply topic modeling only on the top k search results D, assuming the coordinate terms in D are relevant to the query. Then, the topics are returned as query facets, by using the top n list items in each topic (according to the list item's probability in the topic). Though this topic modeling approach is more theoretically motivated, it does not have the flexibility of adding different features to capture different aspects such as query relevance.",1,ad,True
314,7. EVALUATION,0,,False
315,7.1 Data,0,,False
316,"Queries. We constructed a pool of 232 queries from different sources, including random samples from a query log, TREC 2009 Web Track queries 3, example queries appearing in related publications [32, 29] and queries generated by our annotators. Annotators were asked to select queries that they are familiar with from the pool for annotating. Overall, we collect annotations for 100 queries (see Table 5).",1,TREC,True
317,Table 5: Query statistics,1,Query,True
318,Source #queries #queries,0,,False
319,collected annotated,0,,False
320,query log,0,,False
321,100,0,,False
322,30,0,,False
323,related publications,0,,False
324,20,0,,False
325,10,0,,False
326,TREC 2009 Web Track,1,TREC,True
327,50,0,,False
328,20,0,,False
329,annotators generated,0,,False
330,62,0,,False
331,40,0,,False
332,sum,0,,False
333,232,0,,False
334,100,0,,False
335,"Search results. For each query, we acquire the top 100 search results from a commercial Web search engine. A few search results are skipped due to crawl errors, or if they are not HTML Web pages. For the 232-query set, we crawled 22,909 Web pages, which are used for extracting feature listIDF described in Section 5.3. For the 100 annotated queries, the average number of crawled Web pages is 98.7, the minimum is 79, both the maximum and the median are 100.",0,,False
336,"Query facet annotations. We asked human annotators to construct query facets as ground truth. For each query, we first constructed a pool of terms by aggregating facet terms in the top 10 query facets generated by different models, including two runs from QDM, one run from each of pLSA and LDA using top 10 list items in each query facets, and one run for our graphical model based approach. Then, annotators were asked to group terms in the pool into query facets for each query they selected. Finally, the annotator was asked to give a rating for each constructed query facet,",1,Query,True
337,3http://trec.nist.gov/data/web/09/wt09.topics.queriesonly,1,trec,True
338,"regarding how useful and important the query facet is. The rating scale of good,2/fair,""1 is used. Annotation statistics are given in Table 6. There are 50 query facets pooled per query, with 224.8 distinct facet terms per query.""",0,,False
339,Table 6: Annotation statistics fair good pooled,0,,False
340,#terms per query 26.6 55.8 224.8,0,,False
341,#facets per query 3.1 4.8 50.0,0,,False
342,#terms per facet 8.6 11.6,0,,False
343,8.8,0,,False
344,7.2 Evaluation Metrics,0,,False
345,"Query facet extraction can be evaluated from different aspects. We use standard clustering and classification evaluation metrics, as well as metrics designed for this particular task to combine different evaluation aspects.",1,Query,True
346,"Notation: we use """" to distinguish between system generated results and human labeled results, which we used as ground truth. For example, F denotes the system generated query facet set, and F  denotes the human labeled query facet set. For convenience, we use T to denote TF in this section, omitting subscript F . T  denotes all the facet terms in human labeled query facet set. We use rF  to denote the rating score for a human labeled facet F .",0,,False
347,7.2.1 Effectiveness in finding facet terms,0,,False
348,"One aspect of query facet extraction evaluation is how well a system finds facet terms. This can be evaluated using standard classification metrics as follows,",0,,False
349,·,0,,False
350,facet,0,,False
351,term,0,,False
352,precision:,0,,False
353,"P (T, T ) ,",0,,False
354,|T T | |T |,0,,False
355,·,0,,False
356,facet,0,,False
357,term,0,,False
358,recall:,0,,False
359,"R(T, T ) ,",0,,False
360,|T T | |T |,0,,False
361,·,0,,False
362,facet,0,,False
363,term,0,,False
364,F1:,0,,False
365,"F T (T, T ) ,",0,,False
366,2|T T | |T |+|T |,0,,False
367,where facet term F1 is denoted as FT (the T stands for facet term) to avoid confusion with a query facet F and clustering F1 defined below. These metrics do not take clustering quality into account.,0,,False
368,7.2.2 Clustering quality,0,,False
369,"To evaluate how well a system groups facet terms correctly, similar to Dou et al. [7], we use several existing cluster metrics, namely, Purity, NMI/Normalized Mutual Information and F1 for clustering. To avoid confusion with facet term F1, FT, we call F1 for facet term clustering facet clustering F1, and denote it as FP (with P standing for term pair ).",0,,False
370,"In our task, we usually have T ,"" T . The facet terms in the system generated and human labeled clustering results might be different: the system might fail to include some human identified facet terms, or it might mistakenly include some """"incorrect"""" facet terms. These standard clustering metrics cannot handle these cases properly. To solve this problem, we adjust F as if only facet terms in T  were clustered by the system, since we are only interested in how well the """"correct"""" facet terms are clustered from these metrics. The adjusting is done by removing """"incorrect"""" facet terms (t  T - T ) from F , and adding each missing facet term (t  T  - T ) to F as singletons. By this adjusting, we do not take into account the effectiveness of finding correct facet terms.""",1,ad,True
371,99,0,,False
372,7.2.3 Overall quality,0,,False
373,"To evaluate the overall quality of query facet extraction,",0,,False
374,Dou et al. [7] proposed variations of nDCG (Normalized Dis-,0,,False
375,"counted Cumulative Gain), namely fp-nDCG and rp-nDCG.",0,,False
376,It first maps each system generated facet F to a human la-,0,,False
377,beled facet F  that covers the maximum number of terms,0,,False
378,"in F . Then, it assigns the rating rF  to F , and evalu-",0,,False
379,ates F as a ranked list of query facets using nDCG. The,0,,False
380,discounted gains are weighted by precision and/or recall of,0,,False
381,"facet terms in F , against its mapped human labeled facet",0,,False
382,F .,0,,False
383,For,0,,False
384,"fp-nDCG,",0,,False
385,only,0,,False
386,precision,0,,False
387,are,0,,False
388,used,0,,False
389,as,0,,False
390,"weight,",0,,False
391,|F,0,,False
392, F |F |,0,,False
393,|,0,,False
394,.,0,,False
395,"For rp-nDCG, precision and recall are multiplied as weight,",0,,False
396,. |F F |2,0,,False
397,|F ||F |,0,,False
398,"However, to the best of our understanding, this",0,,False
399,metric can be problematic in some cases. When two facets,0,,False
400,"F1 and F2 are mapped to a same human labeled facet F ,",0,,False
401,"only the first facet F1 is credited and F2 is simply ignored, even if it is more appropriate to map F2 to F  (e.g. F2 is exactly same as F , while F1 contain only one facet term in F ).",0,,False
402,The quality of query facet extraction is intrinsically multi-,0,,False
403,faceted. Different applications might have different empha-,0,,False
404,sis in the three factors mentioned above - precision of facet,0,,False
405,"terms, recall of facet terms and clustering quality of facet",0,,False
406,"terms. We propose a metric P RF, to combine the three",0,,False
407,"factors together, using weighted harmonic mean. Let p ,"" P (T, T ), r "","" R(T, T ), f "","" F P (F , F ), then P RF, can""",0,,False
408,"be expressed as follows,",0,,False
409,"P RF, (F , F )",0,,False
410,",",0,,False
411,(2 + 2 + 1)prf 2rf + 2pf + pr,0,,False
412,(10),0,,False
413,where  and  are used to adjust the emphasis between the,1,ad,True
414,"three factors. When  ,  ,"" 1, we omit the subscript part""",0,,False
415,"for simplicity, i.e. P RF  P RF1,1. While P RF, has the flexibility to adjust emphasis be-",1,ad,True
416,"tween the three factors, it does not take into account the dif-",0,,False
417,"ferent ratings associated with query facets. To incorporate ratings, we use a weighted version of P (T, T ), R(T, T ) and F P (F , F ) in P RF,. We call the new metric wP RF,. The weighted facet term precision, recall and FT are defined",1,corpora,True
418,as follows,0,,False
419,"· weighted facet term precision: wP (T, T ) ,",0,,False
420,tT T  w(t) tT w(t),0,,False
421,"· weighted facet term recall: wR(T, T ) ,",0,,False
422,tT T  w(t) tT  w(t),0,,False
423,·,0,,False
424,weighted facet term F1:,0,,False
425,"wF T (T, T ) ,",0,,False
426,"2wP (T,T )wR(T,T ) wP (T,T )+wR(T,T )",0,,False
427,"where w(t) is the weight for facet term t, and assigned as",0,,False
428,follows,0,,False
429,"w(t) ,",0,,False
430,rF  if t  T  1 otherwise,0,,False
431,"Similarly, wF P (F , F ) is computed by weighting its pairwise precision and recall in the same fashion as the weighted facet term precision and recall above. Instead of w(t), we need weight for a pair of facet terms w(t1, t2) in this calculation. We assign weight for facet term pair w(t1, t2) using their sum, w(t1) + w(t2).",1,ad,True
432,8. EXPERIMENT RESULTS,0,,False
433,8.1 Experiment settings,0,,False
434,"We compare effectiveness of the five models, QDM, pLSA, LDA and QF-I, QF-J, on the 100-query data set. All the",0,,False
435,"models take the same candidate lists extracted/cleaned (see Section 4.1) as input. We perform 10-fold cross validation for training/testing and parameter tuning in all experiments and for all models (if applicable). When training the graphical model, we standardize features by removing the mean and scaling to unit variance. We set both of the two regularizers  and  in Equation 5 to be 1. There are too many negative instances (yi ,"" 0, zi,j "","" 0) in the training data, so we stratify samples by labels with the ratio of positive:negative to be 1:3. For QDM, we tune the two parameters used in the clustering algorithm Diamax (the diameter threshold for a cluster) and Wmin (the weight threshold for a valid cluster), as well as two parameters used for selecting facet terms in each facet (St|F > |Sites(F )| and St|F > ). For pLSA and LDA, we tune the number of facet terms in a query facet. For QF-I, we tune the weight threshold for facet terms, wmin, and the diameter threshold, dmax. For QF-J, there are no parameter need to be tuned. We returned top 10 query facets from all the five models in all evaluation.""",0,,False
436,8.2 Finding Facet terms,0,,False
437,"To evaluate effectiveness in finding facet terms, we tune all the models on wFT, which combines both precision and recall, and takes into account facet term weighting.",0,,False
438,"Table 7: Facet term precision, recall and F1 tuned",0,,False
439,on wFT,0,,False
440,Model P,0,,False
441,wP,0,,False
442,R,0,,False
443,wR FT wFT,0,,False
444,pLSA 0.284 0.385 0.562 0.561 0.351 0.430,0,,False
445,LDA 0.292 0.394 0.595 0.593 0.364 0.446,0,,False
446,QDM 0.407 0.523 0.378 0.388 0.360 0.420,0,,False
447,QF-I 0.347 0.458 0.644 0.652 0.427 0.514,0,,False
448,QF-J 0.426 0.534 0.525 0.526 0.449 0.511,0,,False
449,Table 8: Average number of facet terms in output,0,,False
450,per query for different models,0,,False
451,Model #terms/query,0,,False
452,pLSA,0,,False
453,153.1,0,,False
454,LDA,0,,False
455,154.8,0,,False
456,QDM,0,,False
457,68.0,0,,False
458,QF-I,0,,False
459,153.7,0,,False
460,QF-J,0,,False
461,97.8,0,,False
462,"Table 7 shows facet term precision, recall and F1 and their weighted version described in Section 7.2. QF-I and QF-J perform relatively well for both precision and recall. Their improvements over the other three models shown are all significant (p < 0.05, using paired t-test), except the improvements of QF-J over QDM for P and wP. The two topic model based approaches, pLSA and LDA, have relatively high recall and low precision. Contrarily, QDM has high precision and low recall. This difference can be explain by Table 8, which gives the number of facet terms output per query from each models. QDM only outputs 68 facet terms per query, while pLSA and LDA both output over twice that number. One possible reason for the low precision of pLSA and LDA is that they select facet terms solely according to term probabilities in the learned topics (query facets in our case) and do not explicitly incorporate query relevance. We find most of their facet terms are frequently-occurring list items, which are not necessary relevant to the query.",1,corpora,True
463,100,0,,False
464,"While the number of facet terms QF-I outputs is similar to pLSA and LDA, QF-I obtain much higher precision and recall, likely due to the rich set of features used. Table 9 shows the five most important item features according to the absolute values of learned weights. Not surprisingly, list TF/IDF features which are used to capture the likelihood of being a coordinate term have relatively high weights, as well as some features that are used to capture query relevance, e.g. T F.clueIDF .",0,,False
465,"Table 9: Top 5 item features, ranked by absolute",0,,False
466,weights,0,,False
467,Feature,0,,False
468,Weight,0,,False
469,listTF.listIDF 2.6424,0,,False
470,listSF,0,,False
471,2.1374,0,,False
472,wDF,0,,False
473,-1.0754,0,,False
474,TF.clueIDF 1.0115,0,,False
475,SF,0,,False
476,0.6873,0,,False
477,"From Table 7, we also find the the weighted metrics are usually consistent with their corresponding unweighted metric. One exception is that QF-J performs better than QF-I in FT, but it does slightly worse than QF-J in wFT. This is likely to be caused by the high recall for QF-I, which may include more highly rated facet terms.",0,,False
478,8.3 Clustering Facet terms,0,,False
479,"Table 10 shows clustering performance of the five models, which are tuned on wFP. The improvements of QF-I and QF-J over the other three models shown are all significant (p < 0.05, using paired t-test). pLSA and LDA do not perform well in clustering, which could be caused by data sparsity. There are on average 5159 candidate lists per query, but only 3.9 items per list.",0,,False
480,Table 10: Facet clustering performance tuned on wFP,0,,False
481,Model Purity NMI FP wFP,0,,False
482,pLSA 0.793 0.524 0.230 0.229 LDA 0.773 0.511 0.227 0.226 QDM 0.871 0.565 0.367 0.380 QF-I 0.843 0.606 0.408 0.410 QF-J 0.922 0.631 0.352 0.346,0,,False
483,Table 11: Weights learned for item pair features,0,,False
484,Feature,0,,False
485,Weight,0,,False
486,listContextSim 1.4944,0,,False
487,textContextSim 0.7186,0,,False
488,listCooccur,0,,False
489,0.0817,0,,False
490,lengthDiff,0,,False
491,0.0563,0,,False
492,"The better performance in clustering for QF-I and QF-J can be explained by their incorporating factors other than list item co-occurrence information. In Table 11, we list the weights learned for item pair features. Besides one item co-occurrence related feature, listContextSim, we also find that textContextSim has a relatively high weight. textContextSim is used to capture the similarity of the two list items using their surrounding text, so it can help to group two facet terms together even if they might not co-occur a lot",1,corpora,True
493,"in candidate lists. As an example, for the query baggage allowance, we find different airlines do not co-occur a lot in candidate lists, (e.g. delta and jetblue only co-occur twice), but they tend to have high textContextSim (e.g. textContextSim(delta, jetblue) ,"" 0.81), and are therefore grouped together by QF-I and QF-J.""",0,,False
494,8.4 Overall Evaluation,0,,False
495,"To compare overall effectiveness of the five models, we tune all the models on wPRF, and the results are reported in Table 12.",0,,False
496,Table 12: Overall performance tuned on wPRF Model wP wR wFP wPRF pLSA 0.353 0.630 0.229 0.309 LDA 0.358 0.670 0.225 0.311 QDM 0.523 0.388 0.253 0.319 QF-I 0.450 0.667 0.399 0.444 QF-J 0.534 0.526 0.346 0.417,0,,False
497,"Unweighted metrics are very similar to their corresponding weighted metrics in terms of conclusions, and are omitted due to space limitation. Results here are consistent with the results that were tuned on wFT or wFP. pLSA and LDA have high recall, but low precision and FP. QDM has relatively high precision, but low recall and FP. It has on average 68 facet terms per query as output, and fails to improve the overall effectiveness when including more facet terms in its output. QF-I and QF-J are among the best two models according to both PRF and wPRF.",0,,False
498,"Since wPRF does not account for facet ranking effectiveness, we also report fp-NDCG and rp-NDCG tuned on themselves in Table 13. QF-J gives the best performance for both fp-NDCG and rp-NDCG. The improvements of QF-I and QF-J over the other three models shown in the Table 12 and 13 are all significant (p < 0.05, using paired t-test), except the improvements of QF-J over QDM for wP and QF-I over QDM for fp-nDCG.",0,,False
499,Table 13: fp-nDCG and rp-nDCG tuned on them-,0,,False
500,selves,0,,False
501,Model fp-nDCG rp-nDCG,0,,False
502,pLSA 0.250,0,,False
503,0.071,0,,False
504,LDA 0.238,0,,False
505,0.063,0,,False
506,QDM 0.257,0,,False
507,0.093,0,,False
508,QF-I 0.290,0,,False
509,0.157,0,,False
510,QF-J 0.336,0,,False
511,0.193,0,,False
512,9. CONCLUSIONS,0,,False
513,"In this paper, we studied the problem of extracting query facets from search results. We developed a supervised method based on a graphical model to recognize query facets from the noisy facet candidate lists extracted from the top ranked search results. We proposed two algorithms for approximate inference on the graphical model. We designed a new evaluation metric for this task to combine recall and precision of facet terms with grouping quality. Experimental results showed that the supervised method significantly outperforms other unsupervised methods, suggesting that query facet extraction can be effectively learned.",0,,False
514,101,0,,False
515,10. ACKNOWLEDGMENTS,0,,False
516,"This work was supported in part by the Center for Intelligent Information Retrieval and in part under subcontract #19-000208 from SRI International, prime contractor to DARPA contract #HR0011-12-C-0016. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.",0,,False
517,11. REFERENCES,0,,False
518,"[1] E. Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pa¸sca, and A. Soroa. A study on similarity and relatedness using distributional and wordnet-based approaches. In Proceedings of NAACL-HLT'09, pages 19­27, 2009.",0,,False
519,"[2] J. Allan and H. Raghavan. Using part-of-speech patterns to reduce query ambiguity. In Proceedings of SIGIR'02, pages 307­314, 2002.",0,,False
520,"[3] N. Bansal, A. Blum, and S. Chawla. Correlation clustering. In MACHINE LEARNING, pages 238­247, 2002.",0,,False
521,"[4] C. Carpineto, S. Osin´ski, G. Romano, and D. Weiss. A survey of web clustering engines. ACM Comput. Surv., 41(3):17:1­17:38, July 2009.",0,,False
522,"[5] V. Dang, X. Xue, and W. B. Croft. Inferring query aspects from reformulations using clustering. In Proceedings of CIKM '11, pages 2117­2120, 2011.",0,,False
523,"[6] D. Dash, J. Rao, N. Megiddo, A. Ailamaki, and G. Lohman. Dynamic faceted search for discovery-driven analysis. In Proceedings of CIKM '08, pages 3­12, 2008.",0,,False
524,"[7] Z. Dou, S. Hu, Y. Luo, R. Song, and J.-R. Wen. Finding dimensions for queries. In Proceedings of CIKM '11, pages 1311­1320, 2011.",0,,False
525,"[8] Z. Harris. Distributional structure. The Philosophy of Linguistics, 1985.",0,,False
526,"[9] M. A. Hearst. Automatic acquisition of hyponyms from large text corpora. In Proceedings of COLING '92, pages 539­545, 1992.",1,corpora,True
527,"[10] L. Heyer, S. Kruglyak, and S. Yooseph. Exploring expression data: identification and analysis of coexpressed genes. Genome research, 9(11):1106­1115, 1999.",0,,False
528,"[11] Y. Hu, Y. Qian, H. Li, D. Jiang, J. Pei, and Q. Zheng. Mining query subtopics from search log data. In Proceedings of SIGIR '12, pages 305­314, 2012.",0,,False
529,"[12] D. Klein and C. D. Manning. Accurate unlexicalized parsing. In Proceedings of ACL '03, pages 423­430, 2003.",0,,False
530,"[13] J. D. Lafferty, A. McCallum, and F. C. N. Pereira. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML '01, pages 282­289, 2001.",0,,False
531,"[14] D. Lawrie, W. B. Croft, and A. Rosenberg. Finding topic words for hierarchical summarization. In Proceedings of SIGIR '01, pages 349­357, 2001.",0,,False
532,"[15] D. J. Lawrie and W. B. Croft. Generating hierarchical summaries for web searches. In Proceedings of SIGIR '03, pages 457­458, 2003.",0,,False
533,"[16] C. G. Nevill-manning, I. H. Witten, and G. W. Paynter. Lexically-generated subject hierarchies for",0,,False
534,"browsing large collections. International Journal on Digital Libraries, 2:111­123, 1999. [17] M. Pa¸sca. Organizing and searching the world wide web of facts ­ step two: harnessing the wisdom of the crowds. In Proceedings of WWW '07, pages 101­110, 2007. [18] M. Pa¸sca and E. Alfonseca. Web-derived resources for web information retrieval: from conceptual hierarchies to attribute hierarchies. In Proceedings of SIGIR '09, pages 596­603, 2009. [19] P. Pantel, E. Crestan, A. Borkovsky, A.-M. Popescu, and V. Vyas. Web-scale distributional similarity and entity set expansion. In Proceedings of EMNLP '09, pages 938­947, 2009. [20] P. Pantel and D. Lin. Discovering word senses from text. In Proceedings of KDD '02, pages 613­619, 2002. [21] P. Pantel, D. Ravichandran, and E. Hovy. Towards terascale knowledge acquisition. In Proceedings of COLING '04, 2004. [22] M. Pasca. Acquisition of categorized named entities for web search. In Proceedings of CIKM '04, pages 137­145, 2004. [23] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. 1988. [24] T. Sakai and R. Song. Evaluating diversified search results using per-intent graded relevance. In Proceedings of SIGIR '11, pages 1043­1052. ACM, 2011. [25] S. Shi, H. Zhang, X. Yuan, and J.-R. Wen. Corpus-based semantic class mining: distributional vs. pattern-based approaches. In Proceedings of COLING '10, pages 993­1001, 2010. [26] K. Shinzato and K. Torisawa. Acquisition of categorized named entities for web search. In Proceedings of RANLP '05. [27] C. Silverstein, H. Marais, M. Henzinger, and M. Moricz. Analysis of a very large web search engine query log. SIGIR Forum, 33(1):6­12, Sept. 1999. [28] R. Song, M. Zhang, T. Sakai, M. Kato, Y. Liu, M. Sugimoto, Q. Wang, and N. Orii. Overview of the ntcir-9 intent task. In Proceedings of NTCIR-9 Workshop Meeting, pages 82­105, 2011. [29] X. Wang, D. Chakrabarti, and K. Punera. Mining broad latent query aspects from search sessions. In Proceedings of KDD '09, pages 867­876, 2009. [30] X. Wang and C. Zhai. Learn from web search logs to organize search results. In Proceedings of SIGIR '07, pages 87­94, 2007. [31] F. Wu, J. Madhavan, and A. Halevy. Identifying aspects for web-search queries. J. Artif. Int. Res., 40(1):677­700, Jan. 2011. [32] X. Xue and X. Yin. Topic modeling for named entity queries. In Proceedings of CIKM '11, pages 2009­2012, New York, NY, USA, 2011. ACM. [33] X. Yin and S. Shah. Building taxonomy of web search intents for name entity queries. In Proceedings of WWW '10, pages 1001­1010, 2010. [34] H. Zhang, M. Zhu, S. Shi, and J.-R. Wen. Employing topic models for pattern-based semantic class discovery. In Proceedings of ACL '09, pages 459­467, 2009.",1,ad,True
535,102,0,,False
536,,0,,False
