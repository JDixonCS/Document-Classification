,sentence,label,data,regex
0,On the Measurement of Test Collection Reliability,0,,False
1,Julián Urbano jurbano@inf.uc3m.es,0,,False
2,Mónica Marrero mmarrero@inf.uc3m.es,0,,False
3,Diego Martín dmartin@dit.upm.es,0,,False
4,University Carlos III of Madrid Department of Computer Science,1,ad,True
5,"Leganés, Spain",0,,False
6,Technical University of Madrid Department of Telematics Engineering,1,ad,True
7,"Madrid, Spain",1,ad,True
8,ABSTRACT,0,,False
9,"The reliability of a test collection is proportional to the number of queries it contains. But building a collection with many queries is expensive, so researchers have to find a balance between reliability and cost. Previous work on the measurement of test collection reliability relied on databased approaches that contemplated random what if scenarios, and provided indicators such as swap rates and Kendall tau correlations. Generalizability Theory was proposed as an alternative founded on analysis of variance that provides reliability indicators based on statistical theory. However, these reliability indicators are hard to interpret in practice, because they do not correspond to well known indicators like Kendall tau correlation. We empirically established these relationships based on data from over 40 TREC collections, thus filling the gap in the practical interpretation of Generalizability Theory. We also review the computation of these indicators, and show that they are extremely dependent on the sample of systems and queries used, so much that the required number of queries to achieve a certain level of reliability can vary in orders of magnitude. We discuss the computation of confidence intervals for these statistics, providing a much more reliable tool to measure test collection reliability. Reflecting upon all these results, we review a wealth of TREC test collections, arguing that they are possibly not as reliable as generally accepted and that the common choice of 50 queries is insufficient even for stable rankings.",1,TREC,True
10,Categories and Subject Descriptors,0,,False
11,H.3.4 [Information Storage and Retrieval]: Systems and Software--Performance evaluation.,0,,False
12,General Terms,0,,False
13,"Experimentation, Measurement, Reliability.",0,,False
14,Keywords,0,,False
15,"Test Collection, Evaluation, Reliability, Generalizability Theory, TREC.",1,TREC,True
16,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prof t or commercial advantage and that copies bear this notice and the full citation on the f rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specif c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.",1,ad,True
17,1. INTRODUCTION,1,DUC,True
18,The purpose of evaluating the effectiveness of an Informa-,0,,False
19,tion Retrieval (IR) system is to assess how well it would sat-,0,,False
20,isfy real users. The main tool used in these evaluations are,0,,False
21,"test collections, which comprise a collection of documents",0,,False
22,"to search, a set of queries Q, and a set of relevance judg-",0,,False
23,ments that contains information as to what documents are,0,,False
24,"relevant, and to which degree, to the queries [16]. Given",0,,False
25,the results returned by a system A for one of the queries,0,,False
26,"q  Q, an effectiveness measure uses the information in the",0,,False
27,"relevance judgments to compute a score q,A that represents",0,,False
28,the effectiveness of the system for that query. After run-,0,,False
29,"ning the system for all queries in the collection, the average",0,,False
30,"Q,A",0,,False
31,",",0,,False
32,1 |Q|,0,,False
33,"i,A is usually reported as the main measure",0,,False
34,"of system effectiveness, representing the expected behavior",0,,False
35,of the system for an arbitrary new query. When comparing,0,,False
36,"two systems A and B, the main measure reported is the av-",0,,False
37,"erage effectiveness difference Q,AB ,"" Q,A - Q,B. Based""",0,,False
38,"on this difference, we conclude which system is better.",0,,False
39,The immediate question to ask is: how reliable are those,0,,False
40,"conclusions about system effectiveness? Ideally, researchers",0,,False
41,would evaluate the system with the set of all possible queries,0,,False
42,"that a user might request. In such a case, we could be sure",0,,False
43,that the true average performance of the system corresponds,0,,False
44,to the score we computed with the collection. The prob-,0,,False
45,lem is that building such a collection is either impractical,0,,False
46,for requiring an enormous amount of queries and relevance,0,,False
47,"judgments, or just impossible if the potential query set is",0,,False
48,"not defined, which use to be the case because we can not",0,,False
49,"account for future queries that do not yet exist. Therefore,",0,,False
50,the query set Q in a test collection must be regarded as,0,,False
51,"a sample from the universe of all queries, and the sample",0,,False
52,"mean Q,A as an estimate of the true effectiveness mean A.",0,,False
53,But because we are estimating this score with a sample of,0,,False
54,"queries, our estimates are erroneous to some degree. The",0,,False
55,"results may change drastically with a different query set Q,",0,,False
56,so much that differences between systems could be reversed.,0,,False
57,An evaluation result is reliable if it can be replicated with,0,,False
58,another collection: if the set of queries Q suggests that sys-,0,,False
59,"tem A outperforms system B, we can be very sure that the conclusion would hold for a different set of queries Q, and in",0,,False
60,"the end, for the universe of all queries. A simple way to make",0,,False
61,a collection reliable is to include many queries; the more we,0,,False
62,employ the smaller the variance of the estimates and thus,0,,False
63,the more reliable the conclusion. The problem is that more,0,,False
64,"queries also means more cost to create the collection, so re-",0,,False
65,searchers have to find a balance between the reliability of,0,,False
66,"the results and the cost of the collection. To this end, it is",0,,False
67,necessary to develop indicators of test collection reliability.,0,,False
68,393,0,,False
69,"Several works in the last fifteen years have studied the problem of reliability in IR evaluation experiments. The basic methodology consisted in evaluating a series of systems with two different and random sets of queries, computing several reliability indicators that measured how similar those evaluations were. Using different query sample sizes and randomizing query selection, researchers were able to map query set size to reliability and extrapolate results to larger query sets. The data used consisted in runs submitted to several TREC tracks (mostly the Ad Hoc tracks), and the sets of queries employed in each edition. While these approaches are clearly faithful to the data, they are limited in that the full query set had to be partitioned in two disjoint sets to comply with the assumption that they were independent.",1,TREC,True
70,"In 2007 Bodoff and Li [6] proposed Generalizability Theory (GT) as an alternative [7, 18]. GT is grounded on analysis of variance components, which allows to dissect the variability in effectiveness scores and figure out how much of it is due to system differences, query difficulty, assessors, etc. In an ideal evaluation setting, we would like all variance to be due to actual differences between systems and not due to query variability; if the queries in the collection are too varied, or differences between systems too small, then we need many queries to ensure that our estimates are reliable. From these variance components GT allows researchers to estimate the reliability of a test collection even before it has been created. Based on some previous data, GT can estimate the reliability of a collection with a larger number of queries, more than one assessor providing judgments for each query, etc. GT provides indicators for the stability of both the absolute scores and the relative differences by computing different variance ratios.",0,,False
71,"The main advantages of GT against the traditional databased approaches are that 1) it is based on statistical theory, 2) it is easy to employ because it does not require tedious and repetitive what if scenarios, and 3) it allows us to estimate the reliability of a collection or experimental design that does not exist yet. But it has disadvantages too: 1) it is unknown the extent to which reliability indicators are affected by the data used to estimate variance components, and 2) it is very hard to interpret them in practical terms.",1,ad,True
72,"We address these two problems of GT applied to the measurement of test collection reliability. In the next section we review past work following data-based approaches and the reliability indicators used. We then review the use of GT and discuss the motivation for this work. In Section 3 we show how the initial data used in GT studies has a very large effect on the results, discussing minimum sample sizes and interval estimators. Section 4 reports a study to provide an empirical mapping between GT-based indicators of reliability and the well known data-based ones. Next we discuss the reliability of several TREC collections based on the results from previous sections, presenting conclusions in Section 6.",1,ad,True
73,2. INDICATORS OF RELIABILITY,0,,False
74,Several indicators of test collection reliability have been proposed in the literature. This section reviews traditional indicators found in the early data-based studies and the GTbased indicators more recently proposed.,1,ad,True
75,2.1 Data-based Indicators,0,,False
76,"Given a query set Q and a similar set Q of the same size, we can define the following data-based reliability indicators:",0,,False
77,"· Kendall correlation ( ), compares the order in which systems are ranked according to Q and Q, regardless of the magnitude of the differences AB. It ranges from 1 (same rankings) to -1 (reversed rankings), counting the number of system pairs that are swapped between the two rankings. For Q to be reliable,  must therefore tend to 1.",0,,False
78,"· AP correlation (AP ), adds a top-heaviness component to Kendall  , such that swaps between systems towards the top of the rankings are more penalized than swaps towards the bottom [23].",1,AP,True
79,"· Power ratio (), is the fraction of pairwise system differences that result statistically significant according to query set Q. If the difference Q,AB between two systems is deemed as statistically significant, it serves as further evidence that the true difference AB has the same sign. For Q to be reliable,  must therefore tend to 100%. In this paper we compute standard 2-tailed t-tests at the 0.05 level [19].",0,,False
80,"· Minor Conflict ratio (-), is the fraction of statistically significant differences with Q that have a sign swap with Q but are not statistically significant there. - is therefore the fraction of uncertain conclusions when measuring statistical significance, so for Q to be reliable - must therefore tend to 0%.",0,,False
81,"· Major Conflict ratio (+), is the fraction of statistically significant differences with Q that are also significant with Q but have a sign swap. + is therefore the fraction of incorrect conclusions when measuring statistical significance, so for Q to be reliable + must therefore tend to 0% as well.",0,,False
82,"· Absolute Sensitivity (a), is the minimum absolute difference Q,AB that need be observed between any two systems such that the differences with Q have the same sign at least 95% of the times. For Q to be reliable, a must therefore tend to 0, meaning that even small differences can be trusted.",0,,False
83,"· Relative Sensitivity (r), is the minimum relative difference Q,AB/ max Q,A, Q,B that need be observed with Q such that the differences with Q have the same sign at least 95% of the times. For Q to be reliable, r must therefore tend to 0% too.",0,,False
84,"· Root Mean Squared Error (), measures the difference between the absolute scores with Q and with Q. Thus, for Q to be reliable  must tend to 0 too.",0,,False
85,"One of the first reliability studies was conducted in 1998 by Voorhees [20], who analyzed the effect of having different assessors provide relevance judgments. Employing a methodology based on randomization, she concluded that the absolute scores could suffer wide variations between assessors, but that the ranking of systems was seldom altered, establishing  ,"" 0.9 as the de facto minimum on ranking similarity. She also studied swap rates as a function of  and suggested a minimum of 25 queries to have a somewhat stable ranking. Also in 1998, Zobel [24] studied the effect of pool depth on absolute system scores, extrapolating trends to larger pool depths. He also compared different statistical procedures in terms of power and conflict ratios.""",0,,False
86,"Buckley and Voorhees [8] compared in 2000 the reliability of various effectiveness measures by mapping effectiveness differences to error rates. Extrapolating to 50 queries, they concluded that   0.05 produced less than 1.5% system swaps when computing Average Precision (AP), while",1,AP,True
87,394,0,,False
88,"other measures such as Precision at cutoff 10 (P@10) produced 3.6% of swaps. In 2002, Voorhees and Buckley [22] extended their work with other collections and methods, but again extrapolating trends. They concluded that with 50 queries the sensitivity of AP was a ,"" 0.05, while increasing the query set size to 100 would yield a "","" 0.03. They also reported large differences across collections and effectiveness measures. Lin and Hauptmann [13] showed that the empirical model used by Voorhees and Buckley can be derived theoretically, and that the three factors affecting reliability are query set size, mean effectiveness scores, and variability of scores. Sanderson and Zobel [17] also revisited this work by computing relative sensitivity and incorporating statistical procedures to account for score variability. They concluded r "","" 10% with AP if coupled with statistical significance, and r "","" 25% if not. They observed very similar relative sensitivity between AP and P@10, arguing the use of more queries with fewer judgments as previous work suggested that much of the score variability is due to queries [4].""",1,AP,True
89,"In 2007 Sakai [15] used similar methods to compare the reliability of several effectiveness measures, though he did not extrapolate to larger query sets. He computed  correlations, absolute sensitivity a and a variation of r, and observed that these indicators were not very correlated with statistical significance, arguing the importance of considering score variability rather than just means. Voorhees revisited in 2009 [21] the use of statistical procedures with the TREC Robust 2004 collection, computing reliability indicators with an unprecedented set of 100 queries, therefore avoiding the need to extrapolate to the usual size 50. When using AP, she observed power  , 47% and conflict ratios - , 2.7% and + ,"" 0.04%. She showed again that P@10 is less reliable than AP also in these terms; and that nDCG showed higher reliability (agreeing with Sakai [15]). She also found that minor conflicts were usually coupled with large relative differences, thus suggesting that researchers employ several large collections to draw general conclusions.""",1,TREC,True
90,2.2 GT-based Indicators,0,,False
91,"Bodoff and Li [6] proposed Generalizability Theory [7, 18] as an alternative to measure test collection reliability that directly addresses variability of scores rather than just the mean as was common before. GT has two stages: a Generalizability study (G-study) to estimate variance components based on previous data, and a Decision study (D-study) that subsequently computes reliability indicators for a different experimental design. We consider a fully crossed design and decompose variability of scores into three components: variance due to actual differences among systems (s2), variance due to differences in difficulty among queries (q2), and variance due to the system-query interaction effect whereby some systems are particularly good (or bad) for some queries (s2:q). The variance due to other effects, such as assessors, is in our case confounded with the interaction effect.",1,ad,True
92,"Using Analysis of Variance (ANOVA) procedures, these variance components can be estimated from previous data:",0,,False
93,"^s2:q , ^e2 , EMresidual",0,,False
94,(1),0,,False
95,^s2,0,,False
96,",",0,,False
97,EMs - nq,0,,False
98,^e2,0,,False
99,(2),0,,False
100,^q2,0,,False
101,",",0,,False
102,EMq - ^e2 ns,0,,False
103,(3),0,,False
104,"where EM is the expected Mean Square of component , and ns and nq are the number of systems and queries [7, 18]. These estimates can be used to compute the proportion of total variance that is due to each of the effects, such as how much of it is due to actual differences between systems.",0,,False
105,"In the D-study, we can use the variance estimates from the G-study to compute the reliability of a larger query set. To this end, two reliability indicators are usually employed:",0,,False
106,"· Generalizability Coefficient (E2), is the ratio of system variance to itself plus relative error variance:",0,,False
107,E2,0,,False
108,nq,0,,False
109,",",0,,False
110,s2,0,,False
111,s2,0,,False
112,+,0,,False
113,2 e,0,,False
114,n,0,,False
115,(4),0,,False
116,q,0,,False
117,"and it provides a measure of the stability of relative differences between systems . By extension, it measures the reliability of the ranking. For a collection to be reliable, E2 must therefore tend to 1.",0,,False
118,"· Index of Dependability (), is the ratio of system variance to itself plus absolute error variance:",0,,False
119, nq,0,,False
120,",",0,,False
121,s2,0,,False
122,s2,0,,False
123,+ 2+2 qe nq,0,,False
124,(5),0,,False
125,"and it provides a measure of the stability of absolute effectiveness scores . For a collection to be reliable,  must therefore tend to 1 as well.",0,,False
126,"The main advantage of these indicators is that they allow us to estimate the reliability of an arbitrary query set size nq, so there is no need to follow the traditional methodologies based on random what if scenarios and extrapolation. From equations (4) and (5) it can be seen that the reliability of the collection increases as nq increases, because the estimates of query difficulty (i.e. average system performance per query) are more precise. These indicators were used by Kanoulas and Aslam [12] to derive the gain and discount functions of nDCG that yield optimal reliability when nq is constant.",1,ad,True
127,"With simple algebraic manipulation, we can calculate the minimum number of queries needed to reach some level of relative or absolute stability :",0,,False
128,"nE2 () ,",0,,False
129, · e2 s2 (1 - ),0,,False
130,(6),0,,False
131,"n () ,",0,,False
132, q2 + e2 s2 (1 - ),0,,False
133,(7),0,,False
134,"which can be used to estimate how many more queries we need to add to our collection for it to be reliable. The main use of this approach can be found in the TREC Million Query Track [2, 1], which set out to study whether many queries with a few judgments yield more reliable results than a few queries with many judgments. The conclusion was that nq  80 queries are sufficient for a reliable ranking, while nq  130 are needed for reliable absolute scores.",1,ad,True
135,2.3 Motivation,0,,False
136,"The two problems of GT can be clearly spotted at this point. First, equations (1) to (3) show that we do not compute the true 2 variance components, but just estimates ^2 based on some previous data. If we use a different, yet similar set of systems or queries to estimate these variance components, the resulting E^2 and ^ scores might be very",0,,False
137,395,0,,False
138,Ad Hoc 3 Ad Hoc 4 Ad Hoc 5 Ad Hoc 6 Ad Hoc 7 Ad Hoc 8 Web adhoc 8 Web adhoc 9 Web adhoc 2001 Web adhoc 2009 Web adhoc 2010 Web adhoc 2011 Web distillation 2002 Web distillation 2003 Web distillation 2004 Web diversity 2009 Web diversity 2010 Web diversity 2011 Novelty 2002 Novelty 2003 Novelty 2004 Genomics 2003 Genomics 2004 Genomics 2005 Robust 2003 Robust 2004 Robust 2005 Terabyte 2004 Terabyte 2005 Terabyte 2006 Terabyte all 2006 Enterprise 2005 Enterprise 2006 Enterprise 2007 Enterprise 2008 1MQ MTC 2007 1MQ MTC 2008 1MQ MTC 2009 1MQ statAP 2007 1MQ statAP 2008 1MQ statAP 2009 Medical 2011 Microblog 2011,1,adhoc,True
139,Span covering 95% of ^ observations 0.0 0.2 0.4 0.6 0.8 1.0,0,,False
140,Span covering 95% of E^2 observations 0.0 0.2 0.4 0.6 0.8 1.0,0,,False
141,Variability due to queries,0,,False
142,20,0,,False
143,40,0,,False
144,60,0,,False
145,80,0,,False
146,100,0,,False
147,Initial number of queries in the G-study,0,,False
148,20,0,,False
149,40,0,,False
150,60,0,,False
151,80,0,,False
152,100,0,,False
153,Initial number of queries in the G-study,0,,False
154,Span covering 95% of ^ observations 0.0 0.2 0.4 0.6 0.8 1.0,0,,False
155,Span covering 95% of E^2 observations 0.0 0.2 0.4 0.6 0.8 1.0,0,,False
156,Variability due to systems,0,,False
157,20,0,,False
158,40,0,,False
159,60,0,,False
160,80,0,,False
161,100,0,,False
162,Initial number of systems in the G-study,0,,False
163,20,0,,False
164,40,0,,False
165,60,0,,False
166,80,0,,False
167,100,0,,False
168,Initial number of systems in the G-study,0,,False
169,Figure 1: Variability in E^2 (top) and ^ (bottom) scores as a function of the initial number of queries (left) and number of systems (right) used in the G-study to estimate variance components.,0,,False
170,"different. In a revised paper, Bodoff [5, §4.6] briefly discussed this issue and argued that differences are marginal. However, he reports the results when randomly selecting only one system per research group instead of all of them, and only one trial of such experiment. We argue that this situation is not representative because the full set of systems and the reduced set after removing runs by the same groups are actually very similar to begin with, so it is expected that reliability scores do not change much. Also, only one such randomly reduced set is compared, so there is really no evidence to support that claim. Likewise, he further suggests that as few as five queries or systems are often enough to provide stable estimates of the variance components in the G-study [5, §3.1]. We further analyze this issue in Section 3.",1,ad,True
171,"Second, equations (6) and (7) allow us to estimate the minimum number of queries nq to reach some stability level , but the greater question is: how much is stable enough? Bodoff [5] mentions that in most Social Science applications a stability coefficient of 0.8 is acceptable, but there is no similar standard for Engineering applications. Kanoulas and Aslam [12] set  ,"" 0.95 as the target in their experiments, but this choice is arbitrary. In their analysis of the Million Query Track 2007 [2] and 2008 [1], Allan et al. [1] and Carterette et al. [9, 10] also set E2 "", 0.95 as the target. They mention in a footnote that in their experiments E2 , 0.95 approximately corresponded to  ,"" 0.9, but details are omitted. We study this issue in Section 4 by empirically mapping GT-based indicators onto data-based indicators that are easier to understand and use in practice.""",1,Query,True
172,3. VARIABILITY OF GT INDICATORS,0,,False
173,"To measure the effect of the number of queries and number of systems used in the G-study to estimate variance components, we use data from 43 TREC collections covering 12 tasks across 10 tracks, from TREC 3 to TREC 2011 (see Table 1). As in previous studies [22, 17, 6, 21], we remove",1,TREC,True
174,"the bottom 25% of systems so that our results are not obscured by possibly buggy implementations. For each collection, we randomly selected nq ,"" 5 queries and computed the variance components using the full set of systems. We then calculated E2 and  for the full query set size, and the required number of queries to reach 0.95 stability. This was repeated with increments in nq of 5 queries, up the maximum permitted by the collection or 100. For each query set size, we ran 200 random trials, each of which can be considered as the possible data available for a G-study when analyzing a test collection design. The same process was followed by varying the initial number of systems ns and using the full set of queries instead.""",1,ad,True
175,"Figure 1 shows the variability in G-study results1. For each collection and initial number of queries used, the y-axis plots the length of the span covering 95% of the E^2 and ^ observations in the 200 random trials. The right hand side plots show the same span lengths, but for different number of systems used in the G-study. As expected, the queries have a larger effect. Most importantly, we see that the average span length with just 5 queries is about 0.5 across collections. That is, the stability estimates could be as low as 0.3 or as high 0.8, for example, just depending on the particular set of queries we use in the G-study. In fact, estimates of the minimum number of queries required can vary in orders of magnitude if not using enough data. For example, with as many as 30 initial queries and all 184 systems from the Microblog 2011 collection, GT may suggest from 63 to 133 queries to reach E2 ,"" 0.95. Similarly, from 40 initial systems and all 34 queries from the Medical 2011 collection, GT may suggest from 109 to 566 queries. In general, at least 50 queries and 50 systems seem necessary for 95% of estimates to be within a 0.1 span. This means that GT may be trusted to measure the reliability of an existing collection, but that""",1,blog,True
176,"1Given the amount of datapoints displayed in this paper, we recommend to access the full-color version available online.",0,,False
177,396,0,,False
178,L - nq,0,,False
179,"1,",0,,False
180,U - nq,0,,False
181,1,0,,False
182,", where",0,,False
183,(8),0,,False
184,L,0,,False
185,",",0,,False
186,"Ms Me F:dfs ,dfe",0,,False
187,U,0,,False
188,",",0,,False
189,"Ms Me F1-:dfs ,dfe",0,,False
190,nsL nsL +,0,,False
191,nq,0,,False
192,",",0,,False
193,nsU nsU +,0,,False
194,nq,0,,False
195,", where",0,,False
196,(9),0,,False
197,L,0,,False
198,",",0,,False
199,Ms2,0,,False
200,"- F:dfs,MsMe + (F:dfs, - F:dfs,dfe ) F,dfs,dfe Me2 (ns - 1)F:dfs,MsMe + F:dfs,dfq MsMq",0,,False
201,U,0,,False
202,",",0,,False
203,Ms2,0,,False
204,"- F1-:dfs,MsMe + (F1-:dfs, - F1-:dfs,dfe ) F1-,dfs,dfe Me2 (ns - 1)F1-:dfs,MsMe + F1-:dfs,dfq MsMq",0,,False
205,researchers should be cautious when planning a collection,0,,False
206,based on the results of a handful of systems and queries.,0,,False
207,These results clearly evidence the need for a measure of,0,,False
208,confidence on GT indicators. Bodoff [5] suggests the use of,0,,False
209,"confidence intervals to account for this variability, but only",0,,False
210,computes them for the variance components in the G-study.,0,,False
211,Confidence intervals for the ultimately more useful D-study,0,,False
212,"can be worked out from various variance ratios (see equations (8) and (9)2). Feldt [11] derived exact 100(1 - 2)% confidence intervals for the ratio  , s2/e2 under the assumption of normally distributed scores. The confidence interval on E2(nq) is computed using the endpoints in (8):",0,,False
213,E2,0,,False
214,nq,0,,False
215,",",0,,False
216,nq  1 + nq,0,,False
217,(10),0,,False
218,"Arteaga et al. [3] derived approximate 100(1 - 2)% confidence intervals for the ratio  ,"" s2/ s2 + q2 + e2 , again""",0,,False
219,assuming a normal distribution of scores. The confidence interval on  nq is computed using the endpoints in (9):,0,,False
220,nq,0,,False
221,", 1+",0,,False
222,nq  nq - 1 ,0,,False
223,(11),0,,False
224,"Brennan [7, §6] discusses different methods to compute confidence intervals in both G-studies and D-studies, showing that the above intervals work reasonably well even when the normality assumption is violated. The right hand side of Table 1 reports the point and 95% interval estimates of the stability of the 43 TREC collections we consider in this paper. These intervals provide a more suitable estimate of test collection reliability because they account for variability in the G-study. For example, researchers could use these intervals to infer the required number of queries to reach the lower endpoint of the interval instead of the point estimate:",1,TREC,True
225,"nE2 () ,",0,,False
226,  (1 - ),0,,False
227,(12),0,,False
228,"n () ,",0,,False
229, (1 - )  (1 - ),0,,False
230,(13),0,,False
231,4. INTERPRETING GT INDICATORS,0,,False
232,"To empirically derive a mapping between GT-based and data-based reliability indicators, we again used the 43 TREC collections in Table 1. For each collection we proceeded as follows. Two random and disjoint query subsets of size nq ,"" 10 were selected from the full set of queries; let these subsets be Q and Q. The full set of systems was evaluated with both query subsets, and all data-based reliability indicators in Section 2.1 were computed, along with the two GTbased indicators according to Q and Q. This was repeated""",1,TREC,True
233,"2F:df1,df2 is the quantile function of the F distribution with df1 and df2 degrees of freedom. In our fully crossed design, dfs ,"" ns - 1, dfq "","" nq - 1, and dfe "", (ns - 1)(nq - 1).",0,,False
234,"with increments in nq of 10 queries, up to the maximum permitted by the collection. For query subset size we ran",0,,False
235,"50 random trials, each trial providing us with 32 datapoints (E^2 and ^ according to Q and to Q, mapped to ^,^AP , ^, ^-, ^+, ^a, ^r and ^). Theoretically though, E2 is better related to  , AP , , -, + and a because it measures the stability of relative differences, while  is better related to",1,AP,True
236,r and  because it measures the stability of absolute scores.,0,,False
237,We thus mapped only these combinations.,0,,False
238,Figure 2 shows the mappings. For each collection we fitted,0,,False
239,"a model with all available datapoints. However, we dropped points for which E^2 < 0.8 and ^ < 0.5 so that the trends",0,,False
240,were not affected by mappings with such small stability to,0,,False
241,be even practical. These thresholds were chosen based on,0,,False
242,the observed stability of the 43 TREC collections; about,1,TREC,True
243,85% of them show larger stability scores (see Table 1). This,0,,False
244,"resulted in over 28,000 points for each plot. In the top three plots ( , AP and ) we fitted the model y ,"" xa, where a is""",1,AP,True
245,the parameter to fit. This resulted in the desired theoretical,0,,False
246,"behavior that limx1 y , 1 and limx0 y ,"" 0, that is, when all variability is due to system differences  should be 1""",0,,False
247,"because the ranking cannot be altered, and if all variance is",0,,False
248,due to queries then  should be 0 because the rankings are,0,,False
249,"completely random. Similarly, in the bottom four plots we fitted the model y ,"" (1 - x)a, such that limx1 y "", 0 and limx0 y ,"" 1, that is,  should for example be 0 if there is no variability due to queries.""",0,,False
250,"As the first plot shows, all 43 collections do actually need E2 > 0.95 to reach  ,"" 0.9. In general, E2 "","" 0.95 corresponds to   0.85, and on average E2  0.97 is needed""",0,,False
251,"across collections to reach  , 0.9. The two clear exceptions",0,,False
252,are found in the Million Query Track. The 2008 collection,1,Query,True
253,"is the one that reaches the target  ,"" 0.9 with the lowest stability (E2  0.93), while the 2007 collection needs the largest (E2  0.98). Note that these were the two collections for which the E2 "", 0.95   , 0.9 correspondence",0,,False
254,"was established [1, 9, 10]. It should be noted here that these",0,,False
255,"fits have an exponential-like shape, meaning that it is hard to achieve a mid level of  , but once E2 is large enough",0,,False
256,"small improvements in stability translate into large improvements in  . However, the relation between nq and E2 has a logarithmic-like shape, meaning that it is increasingly more expensive to improve E2 to begin with. Thus, it should be",0,,False
257,considered the required effort for slight improvements in  .,0,,False
258,"The second plot shows quite high AP scores at these levels of relative stability, but generally below  . This suggests",1,AP,True
259,that the swaps in the rankings are still happening between,0,,False
260,systems at the top of the rankings [23]. The third plot shows,0,,False
261,that at these stability levels it is expected to observe statis-,0,,False
262,tical significance in about 80% of system comparisons. In,0,,False
263,the middle right plot we can see that the proportion of con-,0,,False
264,"flicting results is generally below the  , 0.05 significance level when E2  0.9.",0,,False
265,397,0,,False
266,Ad Hoc 3 Ad Hoc 4 Ad Hoc 5 Ad Hoc 6 Ad Hoc 7 Ad Hoc 8 Web adhoc 8 Web adhoc 9 Web adhoc 2001 Web adhoc 2009 Web adhoc 2010 Web adhoc 2011 Web distillation 2002 Web distillation 2003 Web distillation 2004 Web diversity 2009 Web diversity 2010 Web diversity 2011 Novelty 2002 Novelty 2003 Novelty 2004 Genomics 2003 Genomics 2004 Genomics 2005 Robust 2003 Robust 2004 Robust 2005 Terabyte 2004 Terabyte 2005 Terabyte 2006 Terabyte all 2006 Enterprise 2005 Enterprise 2006 Enterprise 2007 Enterprise 2008 1MQ MTC 2007 1MQ MTC 2008 1MQ MTC 2009 1MQ statAP 2007 1MQ statAP 2008 1MQ statAP 2009 Medical 2011 Microblog 2011,1,adhoc,True
267,0.3,0,,False
268,0.4,0,,False
269,0.5,0,,False
270,0.6,0,,False
271,0.7,0,,False
272,0.8,0,,False
273,0.9,0,,False
274,1.0,0,,False
275,Kendall correlation,0,,False
276,AP correlation,1,AP,True
277,Power ratio,0,,False
278,1.0,0,,False
279,1.0,0,,False
280,0.9,0,,False
281,0.9,0,,False
282,0.8,0,,False
283,0.8,0,,False
284,0.7,0,,False
285,0.7,0,,False
286,AP,1,AP,True
287,0.6,0,,False
288,0.6,0,,False
289,0.5,0,,False
290,0.5,0,,False
291,0.4,0,,False
292,0.4,0,,False
293,0.3,0,,False
294,0.3,0,,False
295,0.80,0,,False
296,0.85,0,,False
297,0.90,0,,False
298,0.95,0,,False
299,1.00,0,,False
300,E2,0,,False
301,Absolute Sensitivity,0,,False
302,0.80,0,,False
303,0.85,0,,False
304,0.90,0,,False
305,0.95,0,,False
306,1.00,0,,False
307,E2,0,,False
308,0.80,0,,False
309,0.85,0,,False
310,0.90,0,,False
311,0.95,0,,False
312,1.00,0,,False
313,E2,0,,False
314,Minor Conflict ratio,0,,False
315,0.20,0,,False
316,0.12,0,,False
317,0.15,0,,False
318,0.09,0,,False
319,0.10,0,,False
320,-,0,,False
321,0.06,0,,False
322,a,0,,False
323,0.05,0,,False
324,0.03,0,,False
325,0.00,0,,False
326,0.00,0,,False
327,0.80,0,,False
328,0.85,0,,False
329,0.90,0,,False
330,0.95,0,,False
331,1.00,0,,False
332,0.80,0,,False
333,0.85,0,,False
334,0.90,0,,False
335,0.95,0,,False
336,1.00,0,,False
337,E2,0,,False
338,E2,0,,False
339,Relative Sensitivity,0,,False
340,RMS Error,0,,False
341,0.15,0,,False
342,0.10,0,,False
343,r 0.0 0.1 0.2 0.3 0.4 0.5 0.6,0,,False
344,0.05,0,,False
345,0.00,0,,False
346,0.5,0,,False
347,0.6,0,,False
348,0.7,0,,False
349,0.8,0,,False
350,0.9,0,,False
351,1.0,0,,False
352,0.5,0,,False
353,0.6,0,,False
354,0.7,0,,False
355,0.8,0,,False
356,0.9,0,,False
357,1.0,0,,False
358,Figure 2: Mapping from GT-based to data-based reliability indicators on a per-collection basis.,0,,False
359,"Researchers interested in the particular mapping for one of these collections may use the estimates in Table 1 and the plots in Figure 2 to get a better understanding of the evaluation results and draw more informed conclusions. To assess the reliability of future collections and guide in their development process, we fitted a single model using all available data instead of one model per collection. Figure 3 shows these fits, along with 95% and 90% prediction intervals that theoretically cover 95% and 90% of all future observations. In terms of sensitivity, the middle left plots show that a  0.03 for E2  0.9, which is about 60% of what Voorhees and Buckley reported for the Ad Hoc tracks [22]; although the intervals cover their values well. In the bottom",1,ad,True
360,"left plot we see that r  20% for   0.75, generally agreeing with Sanderson and Zobel [17]. As to statistical significance, we replicated Voorhees's [21] study with random sets of 50 queries from the Ad Hoc 7-8 topics and Robust 2004 systems. The average relative stability is E^2  [0.81, 0.88], which corresponds to   [37%, 54%], -  [3.9%, 7.8%] and +  [0.38%, 1.3%]. These are again larger than she reported, but the intervals cover her values well.",1,Robust,True
361,"Overall, these models produce a decent fit on the data, and they fill the gap between data-based methodologies and Generalizability Theory. They provide a valuable tool to rapidly assess and easily understand the reliability of a test collection design.",0,,False
362,398,0,,False
363,Ad Hoc 3 Ad Hoc 4 Ad Hoc 5 Ad Hoc 6 Ad Hoc 7 Ad Hoc 8 Web adhoc 8 Web adhoc 9 Web adhoc 2001 Web adhoc 2009 Web adhoc 2010 Web adhoc 2011 Web distillation 2002 Web distillation 2003 Web distillation 2004 Web diversity 2009 Web diversity 2010 Web diversity 2011 Novelty 2002 Novelty 2003 Novelty 2004 Genomics 2003 Genomics 2004 Genomics 2005 Robust 2003 Robust 2004 Robust 2005 Terabyte 2004 Terabyte 2005 Terabyte 2006 Terabyte all 2006 Enterprise 2005 Enterprise 2006 Enterprise 2007 Enterprise 2008 1MQ MTC 2007 1MQ MTC 2008 1MQ MTC 2009 1MQ statAP 2007 1MQ statAP 2008 1MQ statAP 2009 Medical 2011 Microblog 2011,1,adhoc,True
364,0.3,0,,False
365,0.4,0,,False
366,0.5,0,,False
367,0.6,0,,False
368,0.7,0,,False
369,0.8,0,,False
370,0.9,0,,False
371,1.0,0,,False
372,Kendall correlation,0,,False
373,AP correlation,1,AP,True
374,Power ratio,0,,False
375,1.0,0,,False
376,1.0,0,,False
377,0.9,0,,False
378,0.9,0,,False
379,0.8,0,,False
380,0.8,0,,False
381,0.7,0,,False
382,0.7,0,,False
383,AP,1,AP,True
384,0.6,0,,False
385,0.6,0,,False
386,0.5,0,,False
387,0.5,0,,False
388,0.4,0,,False
389,0.4,0,,False
390,0.3,0,,False
391,0.3,0,,False
392,0.80,0,,False
393,0.85,0,,False
394,0.90,0,,False
395,0.95,0,,False
396,1.00,0,,False
397,E2,0,,False
398,Absolute Sensitivity,0,,False
399,0.80,0,,False
400,0.85,0,,False
401,0.90,0,,False
402,0.95,0,,False
403,1.00,0,,False
404,E2,0,,False
405,0.80,0,,False
406,0.85,0,,False
407,0.90,0,,False
408,0.95,0,,False
409,1.00,0,,False
410,E2,0,,False
411,Minor Conflict ratio,0,,False
412,0.20,0,,False
413,0.12,0,,False
414,0.15,0,,False
415,0.09,0,,False
416,0.10,0,,False
417,-,0,,False
418,0.06,0,,False
419,a,0,,False
420,0.05,0,,False
421,0.03,0,,False
422,0.00,0,,False
423,0.00,0,,False
424,0.80,0,,False
425,0.85,0,,False
426,0.90,0,,False
427,0.95,0,,False
428,1.00,0,,False
429,0.80,0,,False
430,0.85,0,,False
431,0.90,0,,False
432,0.95,0,,False
433,1.00,0,,False
434,E2,0,,False
435,E2,0,,False
436,Relative Sensitivity,0,,False
437,RMS Error,0,,False
438,0.15,0,,False
439,0.10,0,,False
440,r 0.0 0.1 0.2 0.3 0.4 0.5 0.6,0,,False
441,0.05,0,,False
442,0.00,0,,False
443,0.5,0,,False
444,0.6,0,,False
445,0.7,0,,False
446,0.8,0,,False
447,0.9,0,,False
448,1.0,0,,False
449,0.5,0,,False
450,0.6,0,,False
451,0.7,0,,False
452,0.8,0,,False
453,0.9,0,,False
454,1.0,0,,False
455,"Figure 3: General mapping from GT-based to data-based reliability indicators, with 95% (dark grey) and 90% (light grey) prediction intervals.",0,,False
456,5. DISCUSSION,0,,False
457,"The last columns in Table 1 report point and 95% interval estimates of the stability of the 43 TREC collections we considered. Collections in the same group correspond to the same tasks, providing a historical perspective on the reliability of the collections used so far since 1994 and for a variety of tasks. For example, the average relative stability in the Ad Hoc collections was E2  [0.86, 0.93], which according to Figure 3 corresponds to   [0.65, 0.81]. For the Web Ad Hoc collections we find E2  [0.8, 0.93], which would correspond to   [0.53, 0.81]. There are large differences within some tasks, such as Web Distillation, Genomics, Terabyte",1,TREC,True
458,"and Enterprise. This is further evidence of the variability in D-study results due to the data used in the G-study. Except for a few particular cases though, the computation of confidence intervals smooths the problem. Across collections the averages are E2 , 0.88 and  ,"" 0.74, with some tasks having very low scores. According to Figure 3 the expected  correlation is 0.69 with variations from 0.49 to 0.95, that is, much lower than desired.""",0,,False
459,"Figure 4 plots the historical trend of test collection reliability. The left plot shows that relative stability has varied in the (0.8,1) interval for the most part, but most importantly it suggests that the stability of collections has decreased very",0,,False
460,399,0,,False
461,Track Documents,1,Track,True
462,Query Set,1,Query,True
463,Measure ns nq,0,,False
464,Ad Hoc 3 Disks 1 & 2,0,,False
465,151-200,0,,False
466,AP 40 50,1,AP,True
467,Ad Hoc 4 Disks 2 & 3,0,,False
468,201-250,0,,False
469,AP 33 49,1,AP,True
470,Ad Hoc 5 Ad Hoc 6 Ad Hoc 7 Ad Hoc 8,0,,False
471,Disks 2 & 4 Disks 4 & 5 Disks 4 & 5 Disks 4 & 5,0,,False
472,251-300 301-350  351-400  401-450 ,0,,False
473,AP 94 50 AP 74 50 AP 103 50 AP 129 50,1,AP,True
474,WebAdHoc 8 WebAdHoc 9 WebAdHoc 2001 WebAdHoc 2009 WebAdHoc 2010 WebAdHoc 2011,0,,False
475,WebDistillation 2002 WebDistillation 2003 WebDistillation 2004,0,,False
476,WebDiversity 2009 WebDiversity 2010 WebDiversity 2011,0,,False
477,Novelty 2002,1,Novelty,True
478,WT2g WT10g WT10g ClueWeb09 ClueWeb09 ClueWeb09,1,WT,True
479,.GOV .GOV .GOV,0,,False
480,ClueWeb09 ClueWeb09 ClueWeb09,1,ClueWeb,True
481,Disks 4 & 5,0,,False
482,401-450 ,0,,False
483,AP 44 50,1,AP,True
484,451-500,0,,False
485,AP 104 50,1,AP,True
486,501-550,0,,False
487,AP 97 50,1,AP,True
488,W1-W50  AP (MTC) 71 50,1,AP,True
489,W51-W100 ,0,,False
490,AP 56 48,1,AP,True
491,W101-W150 ,0,,False
492,AP 37 50,1,AP,True
493,551-600,0,,False
494,AP 71 49,1,AP,True
495,TD1-TD50,1,TD,True
496,AP 93 50,1,AP,True
497,WT04,1,WT,True
498,AP 74 75,1,AP,True
499,W1-W50  -nDCG@20 48 50,0,,False
500,W51-W100  -nDCG@20 32 50,0,,False
501,W101-W150  -nDCG@20 25 50,0,,False
502,50 from 300-450 ,0,,False
503,F 42 49,0,,False
504,Novelty 2003 AQUAINT,1,Novelty,True
505,N1-N50,0,,False
506,F 55 50,0,,False
507,Novelty 2004 AQUAINT,1,Novelty,True
508,N51-N100,0,,False
509,F 60 50,0,,False
510,GenomicsAdHoc 2003 GenomicsAdHoc 2004 GenomicsAdHoc 2005,0,,False
511,Robust 2003,1,Robust,True
512,Robust 2004,1,Robust,True
513,Robust 2005,1,Robust,True
514,MEDLINE MEDLINE MEDLINE,0,,False
515,Disks 4 & 5 Disks 4 & 5 AQUAINT,1,AQUAINT,True
516,G1-G50,0,,False
517,G51-G100,0,,False
518,G101-150 50 from 301-450 & 601-650 ,0,,False
519,301-450 & 601-700  50 from 301-700 ,0,,False
520,AP 49 50 AP 43 50 AP 62 49,1,AP,True
521,AP 78 100 AP 110 249 AP 74 50,1,AP,True
522,Terabyte 2004,1,Terabyte,True
523,Terabyte 2005,1,Terabyte,True
524,Terabyte 2006,1,Terabyte,True
525,TerabyteAll 2006 EnterpriseExpert 2005 EnterpriseExpert 2006 EnterpriseExpert 2007 EnterpriseExpert 2008,1,Terabyte,True
526,GOV2 GOV2 GOV2 GOV2,0,,False
527,W3C W3C CERC CERC,1,W3C,True
528,701-750  751-800  801-850  701-850 ,0,,False
529,EX01-EX50 EX51-EX105 CE001-CE050 CE051-CE127,0,,False
530,bpref 70 49 bpref 58 50 bpref 80 50 bpref 61 149,0,,False
531,AP 37 50 AP 91 49 AP 55 50 AP 42 55,1,AP,True
532,1MQ 2007,1,MQ,True
533,GOV2,0,,False
534,MQ1-MQ10000 AP (MTC) 29 1692,1,MQ,True
535,1MQ 2008,1,MQ,True
536,GOV2,0,,False
537,MQ10001-MQ20000 AP (MTC) 25 784,1,MQ,True
538,1MQ 2009 ClueWeb09,1,MQ,True
539,MQ20001-MQ60000 AP (MTC) 35 542,1,MQ,True
540,1MQ 2007,1,MQ,True
541,GOV2,0,,False
542,MQ1-MQ10000,1,MQ,True
543,statAP 29 1153,1,AP,True
544,1MQ 2008,1,MQ,True
545,GOV2,0,,False
546,MQ10001-MQ20000,1,MQ,True
547,statAP 25 564,1,AP,True
548,1MQ 2009 ClueWeb09,1,MQ,True
549,MQ20001-MQ60000,1,MQ,True
550,statAP 35 475,1,AP,True
551,Medical 2011,0,,False
552,NLP,0,,False
553,M101-M135,0,,False
554,bpref 127 34,0,,False
555,Microblog 2011 Tweets2011,1,blog,True
556,MB1-MB50,0,,False
557,P@30 184 49,0,,False
558,E^2 (nq ) 0.933 0.893-0.963 0.907 0.847-0.952 0.856 0.804-0.9 0.898 0.855-0.933 0.919 0.891-0.943 0.908 0.88-0.932,0,,False
559,0.929 0.89-0.96 0.876 0.833-0.912 0.862 0.813-0.904 0.81 0.729-0.876 0.829 0.746-0.895 0.804 0.685-0.895,0,,False
560,0.901 0.858-0.935 0.45 0.249-0.619 0.89 0.844-0.927,0,,False
561,0.903 0.852-0.943 0.882 0.803-0.94 0.844 0.725-0.929,0,,False
562,0.919 0.873-0.955 0.966 0.949-0.979 0.801 0.708-0.876,0,,False
563,0.94 0.909-0.965 0.903 0.848-0.945 0.77 0.664-0.855,0,,False
564,0.846 0.784-0.897 0.95 0.934-0.964 0.864 0.807-0.911,0,,False
565,0.953 0.933-0.97 0.875 0.815-0.923 0.762 0.668-0.841 0.94 0.913-0.962,0,,False
566,0.916 0.864-0.955 0.965 0.952-0.976 0.884 0.827-0.929 0.565 0.315-0.757,0,,False
567,0.999 0.999-1 0.998 0.996-0.999 0.96 0.936-0.979 0.992 0.986-0.996 0.978 0.962-0.99 0.96 0.935-0.979,0,,False
568,0.774 0.704-0.835,0,,False
569,0.92 0.899-0.938,0,,False
570,^ (nq) 0.786 0.661-0.88 0.79 0.658-0.89 0.62 0.488-0.732 0.806 0.714-0.875 0.799 0.71-0.864 0.701 0.59-0.787,0,,False
571,0.83 0.728-0.904 0.76 0.662-0.835 0.711 0.598-0.801 0.619 0.473-0.744 0.662 0.513-0.787 0.702 0.537-0.835,0,,False
572,0.84 0.762-0.898 0.315 0.144-0.492 0.747 0.643-0.832,0,,False
573,0.847 0.759-0.911 0.804 0.676-0.899 0.719 0.535-0.865,0,,False
574,0.792 0.671-0.883 0.944 0.91-0.967 0.181 0.1-0.301,0,,False
575,0.87 0.792-0.925 0.768 0.64-0.868 0.422 0.269-0.586,0,,False
576,0.509 0.384-0.636 0.824 0.768-0.872 0.693 0.564-0.797,0,,False
577,0.877 0.809-0.924 0.648 0.501-0.774 0.427 0.283-0.575 0.719 0.617-0.812,0,,False
578,0.824 0.713-0.905 0.939 0.909-0.96 0.785 0.674-0.87 0.28 0.11-0.498,0,,False
579,0.998 0.997-0.999 0.988 0.979-0.995 0.908 0.854-0.951 0.982 0.97-0.991 0.969 0.946-0.986 0.929 0.886-0.963,0,,False
580,0.497 0.348-0.628,0,,False
581,0.818 0.747-0.869,0,,False
582,"Table 1: Summary of all 43 TREC collections analyzed. Query sets with  are used in more than one collection. Query numbers in quotes are not official, but arbitrarily named for this paper. The last two columns report the point and 95% interval estimates of the GT-based reliability indicators.",1,TREC,True
583,"slightly with the years. The clear exceptions are again the Million Query Track collections, which specifically aimed at increasing the number of queries. Within each task it appears that stability tended to decrease as the tasks got older despite that query set sizes were normally unaltered. The second plot shows that this decrease in stability could be due to system variance getting smaller with the years. That is, systems perform more similarly as the tasks get older, indicating that retrieval techniques are generally improved. The right plot shows that query difficulty also varied within tasks. Sudden peaks may be explained by changes in the document set or in the task definition. The general trend suggests that queries are getting more alike with the years, further contributing to the decrease in reliability.",1,Query,True
584,"Bodoff [5, §5] discusses the incorporation of the document set as another facet in Generalizability Theory, much like queries and systems, to measure variability due to documents [14]. He argues that it does not make sense in general, because we do no assign performance scores for indi-",1,corpora,True
585,"vidual documents but for sets of documents (e.g. the first k retrieved when computing P @k). In our case we could compare different editions of the same task but with different document sets to get a (weak) clue of the variability due to documents. For example, the Ad Hoc task of the Web Track shows quite different stability scores in the first three editions (WT2g and WT10g collections) compared to the last three editions (ClueWeb09), given that they all used the standard query set size of 50. Similarly, the Expert Search task in the Enterprise Track shows very different stability levels when using the W3C collection or the CERC collection. We must bear in mind though that these differences might actually be due to the systems and queries used, which varied from year to year.",1,Track,True
586,"From the confidence intervals in Table 1, we used the models fitted in Section 4 to provide in Table 2 the estimated data-based reliability scores for all 43 collections. It is evident that expected  correlations are well below the desired 0.9 in most cases. In that line, some collections are clearly",0,,False
587,400,0,,False
588,Track,1,Track,True
589,Ad Hoc 3 Ad Hoc 4 Ad Hoc 5 Ad Hoc 6 Ad Hoc 7 Ad Hoc 8,0,,False
590,WebAdHoc 8 WebAdHoc 9 WebAdHoc 2001 WebAdHoc 2009 WebAdHoc 2010 WebAdHoc 2011 WebDistillation 2002 WebDistillation 2003 WebDistillation 2004 WebDiversity 2009 WebDiversity 2010 WebDiversity 2011 Novelty 2002 Novelty 2003 Novelty 2004,1,Novelty,True
591,GenomicsAdHoc 2003 GenomicsAdHoc 2004 GenomicsAdHoc 2005,0,,False
592,Robust 2003 Robust 2004 Robust 2005,1,Robust,True
593,Terabyte 2004 Terabyte 2005 Terabyte 2006 TerabyteAll 2006 EnterpriseExpert 2005 EnterpriseExpert 2006 EnterpriseExpert 2007 EnterpriseExpert 2008,1,Terabyte,True
594,1MQ 2007 1MQ 2008 1MQ 2009 1MQ 2007 1MQ 2008 1MQ 2009,1,MQ,True
595,Medical 2011,0,,False
596,Microblog 2011,1,blog,True
597,^,0,,False
598,0.725-0.898 0.622-0.87,0,,False
599,0.537-0.741 0.641-0.821,0,,False
600,0.72-0.846 0.695-0.819,0,,False
601,0.718-0.89 0.595-0.77 0.554-0.749 0.406-0.686 0.434-0.729 0.34-0.728,0,,False
602,0.647-0.827 0.019-0.255 0.617-0.807,0,,False
603,0.633-0.847 0.535-0.839 0.401-0.811,0,,False
604,0.679-0.877 0.86-0.941,0,,False
605,0.374-0.685,0,,False
606,0.762-0.903 0.624-0.852 0.311-0.641,0,,False
607,0.5-0.734 0.823-0.902 0.544-0.766,0,,False
608,0.82-0.916 0.558-0.795,0,,False
609,0.316-0.61 0.772-0.897,0,,False
610,0.661-0.877 0.868-0.932 0.582-0.812 0.037-0.453,0,,False
611,0.997-0.999 0.989-0.997 0.827-0.942 0.962-0.989 0.896-0.972 0.826-0.941,0,,False
612,0.368-0.598,0,,False
613,0.74-0.833,0,,False
614,^AP,1,AP,True
615,0.637-0.86 0.515-0.823 0.418-0.657 0.537-0.758 0.631-0.791,0,,False
616,0.6-0.756,0,,False
617,0.629-0.849 0.484-0.694 0.437-0.668,0,,False
618,0.283-0.59 0.311-0.643 0.221-0.642,0,,False
619,0.544-0.766 0.004-0.148 0.508-0.741,0,,False
620,0.528-0.792 0.416-0.782 0.278-0.746,0,,False
621,0.582-0.833 0.81-0.919,0,,False
622,0.252-0.589,0,,False
623,0.684-0.867 0.517-0.799 0.195-0.537,0,,False
624,0.379-0.649 0.761-0.865 0.426-0.689,0,,False
625,0.758-0.884 0.442-0.725,0,,False
626,0.2-0.5 0.696-0.859,0,,False
627,0.56-0.831 0.821-0.907 0.468-0.746,0,,False
628,0.01-0.33,0,,False
629,0.995-0.999 0.985-0.996,0,,False
630,0.767-0.92 0.947-0.984 0.858-0.961 0.765-0.919,0,,False
631,0.246-0.486,0,,False
632,0.656-0.774,0,,False
633,^ (%),0,,False
634,58-83 45-79 35-60 47-72 58-76 54-72,0,,False
635,57-82 42-65 37-62 22-53 25-59 16-59,0,,False
636,48-73 0-10,0,,False
637,44-70,0,,False
638,46-76 35-74 22-70,0,,False
639,52-80 78-90 19-53,0,,False
640,63-84 45-76 14-47,0,,False
641,31-60 72-84 36-64,0,,False
642,72-86 38-68 14-44 65-83,0,,False
643,50-80 79-89 40-70,0,,False
644,0-26,0,,False
645,99-100 98-100,0,,False
646,73-90 94-98 83-95 73-90,0,,False
647,19-42,0,,False
648,60-74,0,,False
649,^- (%),0,,False
650,0.6-3.2 0.9-5.6 2.9-8.2 1.6-5.2 1.2-3.3 1.6-3.9,0,,False
651,0.7-3.4 2.4-6.4 2.8-7.7 4.1-13.5 3.1-12.2 3.2-17,0,,False
652,1.5-5 22.8-64.4,0,,False
653,1.8-5.8,0,,False
654,1.2-5.4 1.3-8.3 1.7-13.8,0,,False
655,0.9-4.2 0.3-1.1 4.1-15.1,0,,False
656,0.6-2.5 1.2-5.6 5.2-18.8,0,,False
657,3.1-9.6 0.6-1.6,0,,False
658,2.5-8,0,,False
659,0.5-1.6 2-7.5,0,,False
660,6-18.5 0.7-2.4,0,,False
661,0.9-4.7 0.3-1,0,,False
662,1.7-6.8 11.4-56,0,,False
663,0-0 0-0 0.3-1.5 0-0.1 0.1-0.7 0.3-1.5,0,,False
664,6.3-15.5,0,,False
665,1.4-3,0,,False
666,^+ (%),0,,False
667,0.02-0.28 0.03-0.72 0.23-1.38 0.08-0.62 0.05-0.29 0.08-0.38,0,,False
668,0.02-0.3 0.17-0.9 0.21-1.22 0.41-3.24 0.27-2.73 0.27-4.81,0,,False
669,0.07-0.59 7.89-47.06,0,,False
670,0.1-0.76,0,,False
671,0.05-0.66 0.06-1.4,0,,False
672,0.09-3.35,0,,False
673,0.03-0.44 0-0.04,0,,False
674,0.42-3.93,0,,False
675,0.02-0.18 0.05-0.71 0.62-5.69,0,,False
676,0.25-1.78 0.02-0.08 0.17-1.32,0,,False
677,0.01-0.08 0.12-1.19,0,,False
678,0.8-5.52 0.02-0.16,0,,False
679,0.03-0.52 0.01-0.03,0,,False
680,0.09-1 2.41-37.02,0,,False
681,0-0 0-0 0-0.07 0-0 0-0.02 0-0.08,0,,False
682,0.88-4.08,0,,False
683,0.07-0.24,0,,False
684,^a,0,,False
685,0.01-0.03 0.01-0.06 0.03-0.08 0.02-0.05 0.01-0.03 0.02-0.04,0,,False
686,0.01-0.03 0.02-0.06 0.03-0.08 0.04-0.13 0.03-0.12 0.03-0.17,0,,False
687,0.01-0.05 0.23-0.64 0.02-0.06,0,,False
688,0.01-0.05 0.01-0.08 0.02-0.14,0,,False
689,0.01-0.04 0-0.01,0,,False
690,0.04-0.15,0,,False
691,0.01-0.02 0.01-0.05 0.05-0.19,0,,False
692,0.03-0.09 0.01-0.02 0.02-0.08,0,,False
693,0-0.02 0.02-0.07 0.06-0.18 0.01-0.02,0,,False
694,0.01-0.05 0-0.01,0,,False
695,0.02-0.07 0.11-0.56,0,,False
696,0-0 0-0 0-0.01 0-0 0-0.01 0-0.01,0,,False
697,0.06-0.15,0,,False
698,0.01-0.03,0,,False
699,^r (%),0,,False
700,6-25 6-25 18-42 7-20 8-20 13-31,0,,False
701,5-18 10-24 12-31 17-44 13-39 10-37,0,,False
702,5-16 41-82 10-26,0,,False
703,4-16 5-23 7-37,0,,False
704,6-24 1-4,0,,False
705,63-87,0,,False
706,3-13 7-27 32-67,0,,False
707,27-53 7-15,0,,False
708,13-34,0,,False
709,4-12 15-41 33-65 11-29,0,,False
710,5-20 2-4,0,,False
711,7-23 41-86,0,,False
712,0-0 0-1 2-8 0-1 0-2 1-6,0,,False
713,28-57,0,,False
714,7-17,0,,False
715,^,0,,False
716,0.001-0.029 0.001-0.03,0,,False
717,0.013-0.112 0.001-0.017 0.001-0.017 0.006-0.054,0,,False
718,0-0.014 0.003-0.028 0.005-0.051 0.011-0.122 0.006-0.095,0,,False
719,0.003-0.08,0,,False
720,0.001-0.009 0.108-0.6,0,,False
721,0.003-0.034,0,,False
722,0-0.009 0.001-0.025 0.001-0.081,0,,False
723,0.001-0.026 0-0,0,,False
724,0.309-0.709,0,,False
725,0-0.006 0.001-0.035 0.055-0.358,0,,False
726,0.036-0.204 0.001-0.008 0.005-0.066,0,,False
727,0-0.004 0.008-0.103,0,,False
728,0.06-0.336 0.004-0.043,0,,False
729,0-0.017 0-0,0,,False
730,0.001-0.025 0.104-0.683,0,,False
731,0-0 0-0 0-0.002 0-0 0-0 0-0.001,0,,False
732,0.039-0.246,0,,False
733,0.001-0.011,0,,False
734,n^E2(.95) 37-114 47-169,0,,False
735,106-233 69-161 58-117 69-130,0,,False
736,40-118 92-190 102-220 135-354 107-311 112-438,0,,False
737,65-154 585-2862,0,,False
738,112-264,0,,False
739,58-166 61-234 73-360,0,,False
740,44-136 21-52,0,,False
741,135-392,0,,False
742,35-95 56-171 158-472,0,,False
743,218-525 175-336,0,,False
744,94-227,0,,False
745,30-68 80-217 181-474 111-269,0,,False
746,46-149 24-48,0,,False
747,73-200 335-2277,0,,False
748,11-38 16-59 219-710 88-304 107-421 194-628,0,,False
749,129-273,0,,False
750,62-105,0,,False
751,n^(.95),0,,False
752,130-487 116-484 348-999 136-381 150-389 257-662,0,,False
753,102-355 189-484 236-640 327-1058 247-868 188-819,0,,False
754,106-292 980-5631,0,,False
755,288-791,0,,False
756,93-301 107-457 149-826,0,,False
757,124-457 33-94,0,,False
758,2203-8579,0,,False
759,78-250 146-536 657-2528,0,,False
760,1087-3043 693-1428 242-733,0,,False
761,77-220 279-947 702-2406 657-1761,0,,False
762,100-383 39-93,0,,False
763,143-459 1053-8458,0,,False
764,30-104 81-313 534-1756 196-685 156-616 352-1156,0,,False
765,383-1208,0,,False
766,141-315,0,,False
767,Table 2: Predicted reliability of all 43 TREC collections analyzed. All confidence intervals are based on the fits from Figure 3 at the endpoints of the 95% confidence intervals computed with equations (10) and (11).,1,TREC,True
768,"not reliable, such as the Web Distillation 2003, Genomics Ad Hoc 2005, Terabyte 2006, Enterprise Expert Search 2008, or the very recent Medical 2011 and Web Ad Hoc 2011. Regarding the expected RMS Error of absolute scores, we can see that collections are somewhat stable, but with clear exceptions such as Web Distillation 2003, Novelty 2004 and Enterprise Expert Search 2008.",1,Terabyte,True
769,"The last two columns in Table 2 report intervals on the number of queries, as per equations (12) and (13), required to achieve 0.95 stability. In general the number of queries needs to be at least doubled, and in many cases a few hundred queries seem to be needed. This is particularly interesting for the most recent collections, such as Web Ad Hoc 2010 and 2011, Medical 2011 and Microblog 2011, which stick to the traditional size of 50 queries but need about 200. What becomes clear from these figures is that the ideal size of a collection depends greatly on the task it will be used for, and thus it is not appropriate to fix some acceptable size such as 50 or 100 throughout tasks. Each task has different characteristics and should be analyzed accordingly.",1,blog,True
770,6. CONCLUSIONS,0,,False
771,"In this paper we discussed the measurement of test collection reliability from the perspective of traditional databased methodologies and of Generalizability Theory. GT is regarded as a more appropriate, easy to use, and powerful method to assess reliability, but it has two drawbacks. First, we showed that GT is very sensitive to the particular sample of systems and queries used to estimate reliability of a larger query set. We showed that about 50 systems and 50 queries are needed for robust estimates of collection reliability. Therefore, researchers should be cautious in using GT when building new collections from scratch. To account for all this variability we discussed a more robust approach based on interval estimates of the stability indicators, which helps in making more appropriate decisions regarding number of queries or different structure in the experimental design. Second, we empirically established a mapping between GT-based and traditional data-based indicators to help interpreting results from GT which, otherwise, do not have a",1,ad,True
772,401,0,,False
773,Ad Hoc Web adhoc Web distillation Web diversity Novelty Genomics Robust Terabyte Enterprise 1MQ MTC 1MQ statAP Medical Microblog,1,adhoc,True
774,Linear trend,0,,False
775,E^2 0.5 0.6 0.7 0.8 0.9 1.0,0,,False
776,Relative Stability,0,,False
777,1995,0,,False
778,2000,0,,False
779,Year,0,,False
780,2005,0,,False
781,2010,0,,False
782,^s2 (% of total),0,,False
783,0,0,,False
784,5 10 15 20 25,0,,False
785,Variability due to Systems,0,,False
786,1995,0,,False
787,2000,0,,False
788,Year,0,,False
789,2005,0,,False
790,2010,0,,False
791,^2q (% of total) 30 40 50 60 70 80 90,0,,False
792,Variability due to Queries,0,,False
793,1995,0,,False
794,2000,0,,False
795,Year,0,,False
796,2005,0,,False
797,2010,0,,False
798,"Figure 4: Historical trend of relative stability (left), variability due to systems (middle) and to queries (right).",0,,False
799,"clear and easily understandable meaning. Based on these results, we reviewed the reliability of 43 TREC test collections, evidencing that some of them are very little reliable. We show that the traditional choice of 50 queries is clearly not enough even for stable rankings, and in most cases a couple hundred queries are needed. Our results also show that the ideal query set size varies significantly across tasks, suggesting that we avoid the use of some fixed size such as 50 or 100 and that we analyze tasks and collections separately.",1,TREC,True
800,"There are two clear lines for future research. First, we completely ignored the assessor facet in our study. It is evident that different assessors provide different results, so it would be interesting to include them in the analysis. Second, although we fitted the theoretically correct models, it is clear that they can be improved (see for instance Power and RMS Error in Figure 3). IR evaluation experiments generally violate assumptions of GT, such as normality of distributions and random sampling, so different models and features to better fit the actual data should be investigated.",0,,False
801,We created some scripts for the statistical software R that can help researchers perform all these computations to easily assess the reliability of custom test collection designs. They can be downloaded from http://julian-urbano.info.,1,ad,True
802,7. REFERENCES,0,,False
803,"[1] J. Allan, J. A. Aslam, B. Carterette, V. Pavlu, and E. Kanoulas. Million Query Track 2008 Overview. In Text REtrieval Conference, 2008.",1,Query,True
804,"[2] J. Allan, B. Carterette, J. A. Aslam, V. Pavlu, B. Dachev, and E. Kanoulas. Million Query Track 2007 Overview. In Text REtrieval Conference, 2007.",1,Query,True
805,"[3] C. Arteaga, S. Jeyaratnam, and G. A. Franklin. Confidence Intervals for Proportions of Total Variance in the Two-Way Cross Component of Variance Model. Communications in Statistics: Theory and Methods, 11(15):1643­1658, 1982.",0,,False
806,"[4] D. Banks, P. Over, and N.-F. Zhang. Blind Men and Elephants: Six Approaches to TREC data. Information Retrieval, 1(1-2):7­34, 1999.",1,TREC,True
807,"[5] D. Bodoff. Test Theory for Evaluating Reliability of IR Test Collections. Information Processing and Management, 44(3):1117­1145, 2008.",0,,False
808,"[6] D. Bodoff and P. Li. Test Theory for Assessing IR Test Collections. In ACM SIGIR, pages 367­374, 2007.",0,,False
809,"[7] R. L. Brennan. Generalizability Theory. Springer, 2001.",0,,False
810,"[8] C. Buckley and E. M. Voorhees. Evaluating Evaluation Measure Stability. In ACM SIGIR, pages 33­34, 2000.",0,,False
811,"[9] B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. Evaluation Over Thousands of Queries. In ACM SIGIR, pages 651­658, 2008.",0,,False
812,"[10] B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. If I Had a Million Queries. In ECIR, pages 288­300, 2009.",1,ad,True
813,"[11] L. S. Feldt. The Approximate Sampling Distribution of Kuder-Richardson Reliability Coefficient Twenty. Psychometrika, 30(3):357­370, 1965.",0,,False
814,"[12] E. Kanoulas and J. A. Aslam. Empirical Justification of the Gain and Discount Function for nDCG. In ACM CIKM, pages 611­620, 2009.",0,,False
815,"[13] W.-H. Lin and A. Hauptmann. Revisiting the Effect of Topic Set Size on Retrieval Error. In ACM SIGIR, pages 637­638, 2005.",0,,False
816,"[14] S. Robertson and E. Kanoulas. On Per-Topic Variance in IR Evaluation. In ACM SIGIR, pages 891­900, 2012.",0,,False
817,"[15] T. Sakai. On the Reliability of Information Retrieval Metrics Based on Graded Relevance. Information Processing and Management, 43(2):531­548, 2007.",1,ad,True
818,"[16] M. Sanderson. Test Collection Based Evaluation of Information Retrieval Systems. Foundations and Trends in Information Retrieval, 4(4):247­375, 2010.",0,,False
819,"[17] M. Sanderson and J. Zobel. Information Retrieval System Evaluation: Effort, Sensitivity, and Reliability. In ACM SIGIR, pages 162­169, 2005.",0,,False
820,"[18] R. J. Shavelson and N. M. Webb. Generalizability Theory: A Primer. Sage Publications, 1991.",0,,False
821,"[19] J. Urbano, M. Marrero, and D. Mart´in. A Comparison of the Optimality of Statistical Significance Tests for Information Retrieval Evaluation. In ACM SIGIR, 2013.",0,,False
822,"[20] E. M. Voorhees. Variations in Relevance Judgments and the Measurement of Retrieval Effectiveness. In ACM SIGIR, pages 315­323, 1998.",0,,False
823,"[21] E. M. Voorhees. Topic Set Size Redux. In ACM SIGIR, pages 806­807, 2009.",0,,False
824,"[22] E. M. Voorhees and C. Buckley. The Effect of Topic Set Size on Retrieval Experiment Error. In ACM SIGIR, pages 316­323, 2002.",0,,False
825,"[23] E. Yilmaz, J. A. Aslam, and S. Robertson. A New Rank Correlation Coefficient for Information Retrieval. In ACM SIGIR, pages 587­594, 2008.",0,,False
826,"[24] J. Zobel. How Reliable are the Results of Large-Scale Information Retrieval Experiments? In ACM SIGIR, pages 307­314, 1998.",0,,False
827,402,0,,False
828,,0,,False
