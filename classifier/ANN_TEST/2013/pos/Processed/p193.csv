,sentence,label,data,regex
0,Faster and Smaller Inverted Indices with Treaps ,0,,False
1,Roberto Konow,0,,False
2,"Dept. of Computer Science Univ. of Chile, Chile",0,,False
3,"EIT, Univ. Diego Portales",0,,False
4,Gonzalo Navarro,0,,False
5,"Dept. of Computer Science Univ. of Chile, Chile",0,,False
6,Charles L. A. Clarke Alejandro López-Ortíz,0,,False
7,"School of Computer Science Univ. of Waterloo, Canada",1,ad,True
8,ABSTRACT,0,,False
9,"16]. In the first stage, a fast and simple filtration proce-",0,,False
10,"We introduce a new representation of the inverted index that performs faster ranked unions and intersections while using less space. Our index is based on the treap data structure, which allows us to intersect/merge the document identifiers while simultaneously thresholding by frequency, instead of the costlier two-step classical processing methods. To achieve compression we represent the treap topology using compact data structures. Further, the treap invariants allow us to elegantly encode differentially both document identifiers and frequencies. Results show that our index uses about 20% less space, and performs queries up to three times faster, than state-of-the-art compact representations.",1,ad,True
11,"dure extracts a subset of a few hundreds or thousands of candidates from the possibly billions of documents forming the collection. In the second stage, more complex learned ranking algorithms are applied to the reduced candidate set in order to obtain a handful of high-quality results. In this paper, we focus on improving the efficiency of the first stage, freeing more resources for the second stage and increasing the overall performance. In contexts where traditional ranking methods are sufficient, the goal of the first stage is to directly convey a few top-quality results to the final user.",1,ad,True
12,The first stage aims to return either a set of the highest ranked documents containing all the query terms (a ranked intersection) or some of the most important query terms (a,0,,False
13,Categories and Subject Descriptors,0,,False
14,"ranked union). In most cases, ranked intersections are solved via a Boolean intersection, followed by the computation of",0,,False
15,H.3.3 [INFORMATION STORAGE AND RETRIEVAL]: scores for the resulting documents. Ranked unions are gen-,0,,False
16,Information Search and Retrieval,0,,False
17,"erally solved only in approximate form, avoiding a costly",0,,False
18,"Boolean union. However, Ding and Suel [21] showed that",0,,False
19,General Terms,0,,False
20,ranked intersections can be processed faster than Boolean intersections. They also obtained the best known performance,0,,False
21,"Algorithms, Performance",0,,False
22,"for ranked unions, giving exact, rather than approximate re-",0,,False
23,"sults, and demonstrating the feasibility of their approach.",0,,False
24,Keywords,0,,False
25,"In this paper, we introduce a new compressed representation for posting lists that performs ranked intersections and",0,,False
26,"Treap, Inverted Index, Top-k, Query Processing",1,Query,True
27,(exact) unions directly. This representation is based on the,0,,False
28,"treap data structure [34], a binary tree that simultaneously",0,,False
29,1. INTRODUCTION,1,DUC,True
30,"Modern Web search engines, and other information retrieval systems, face two competing challenges. On the one hand, they have to manage huge amounts of data. On the other hand, they have to provide very precise results in response to user queries, often identifying a few relevant documents among increasingly larger collections. These requirements can be addressed via a two-stage ranking process [37,",1,ad,True
31,"represents a left-to-right and a top-to-bottom ordering. We use the left-to-right ordering for document identifiers (which supports fast Boolean operations) and the top-to-bottom ordering for term weights (which supports the thresholding of results simultaneously with the intersection process). Using this data structure, we can obtain the top-k results for a ranked intersection/union without having to first produce the full Boolean result.",0,,False
32,"Additionally, the treap representation allows us to dif-",0,,False
33,"Partially funded by Fondecyt grant 1-110066 , by the Conicyt PhD Scholarship Program, Chile and by the Emerging Leaders in the Americas Program, Government of Canada.",1,ad,True
34,"ferentially encode both document identifiers and weights, which is crucial for the space-efficient representation of inverted indexes. Posting lists have been compressed for de-",0,,False
35,cades [38] to handle very large collections within minimal,1,ad,True
36,Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation,1,ad,True
37,"space. Using other representations we must choose either identifiers or weights for differential encoding, but not both.",0,,False
38,Our experiments show that the space usage of our treap-,0,,False
39,on the first page. Copyrights for components of this work owned by others than the,0,,False
40,based inverted index representation is less than the state-of-,0,,False
41,"author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or",0,,False
42,the-art compressed representations: around 22% less space,0,,False
43,"republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright is held by the owner/author(s). Publication rights licensed to ACM.",0,,False
44,"than Block-Max [21] and 18% less space than Dual-Sorted [25]. As for the time, treaps outperform previous techniques for k up to 30 on intersections, and up to 130 on unions,",0,,False
45,Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.,0,,False
46,193,0,,False
47,"being up to three times faster than the alternatives in some cases. Those ranges of k values make this result of particular interest both in applications where a limited result set is of interest, and in large-scale distributed systems in which each node contributes a limited set to the global result.",0,,False
48,2. BASIC CONCEPTS,0,,False
49,The inverted index plays a central role in the efficient pro-,0,,False
50,"cessing of ranked and Boolean queries [38, 41, 18, 16, 5].",0,,False
51,"It can be seen as an array of lists or postings, where each",0,,False
52,entry of the array corresponds to a different term or word in,0,,False
53,"the collection, and the lists contain one element per distinct",0,,False
54,"document where the term appears. For each document, the",0,,False
55,index stores the document identifier (docid) and the weight,0,,False
56,of the term in the document. The set of terms is called the,0,,False
57,"vocabulary of the collection, which is comparatively small in",0,,False
58,most cases [24].,0,,False
59,"In the first stage of query processing, a simple metric is",0,,False
60,used to assign a score to a document with respect to a query.,0,,False
61,"In the classical bag-of-words model, the query Q is seen as",0,,False
62,"a set of q terms t  Q, and the score of a document d is",0,,False
63,"computed as score(Q, d) ,"" tQ w(t, d), where w(t, d) is the weight of term t in document d. For example, in the""",0,,False
64,"well-known tf-idf scoring scheme, this weight is computed",0,,False
65,"as w(t, d) ,"" tf t,d · idft. Here, tf t,d is the term frequency of t""",0,,False
66,"in d, that is, the number of times t occurs in d. The second",0,,False
67,term,0,,False
68,is,0,,False
69,idft,0,,False
70,",",0,,False
71,log,0,,False
72,D dft,0,,False
73,",",0,,False
74,where,0,,False
75,dft,0,,False
76,is,0,,False
77,the,0,,False
78,document,0,,False
79,"frequency,",0,,False
80,"that is, the number of documents where the term t appears,",0,,False
81,and D is the total number of documents. Since idft (or,0,,False
82,"dft) depends only on t, an efficient way to store w(t, d) in",0,,False
83,an inverted index is to store idft or dft together with each,0,,False
84,"distinct vocabulary term, and store the values tf t,d in the posting list of term t, together with each docid d. In this",0,,False
85,paper we will assume that term frequencies are stored in the,0,,False
86,"posting lists, but any other integer measure, such as impacts",0,,False
87,[2] could be used.,0,,False
88,"In the bag-of-words model we are given Q and k, and asked",0,,False
89,"to retrieve k documents d with the highest score(Q, d) val-",0,,False
90,"ues. In the two-stage model, typical values of k are hundreds",0,,False
91,"to thousands, as discussed earlier. In simpler one-stage sys-",0,,False
92,"tems, typical values of k are below 20. Note that it is not",0,,False
93,necessary for all the terms of Q to appear in a returned doc-,0,,False
94,"ument d; a missing term t simply implies that w(t, d) , 0.",0,,False
95,This problem is frequently called ranked union. A variant,0,,False
96,"of the problem, popularized by Web search engines to favor",0,,False
97,"precision over recall, is the ranked intersection, where only",0,,False
98,"documents containing all the terms are returned. Nowadays,",1,ad,True
99,ranked intersections are more common than unions.,0,,False
100,"The Boolean intersection problem, without ranking, aims",0,,False
101,at retrieving all the documents d where all the terms of,0,,False
102,Q appear. A typical way to solve a ranked intersection is,0,,False
103,"to first compute a Boolean intersection, then compute the",0,,False
104,"scores of all the resulting documents, and finally keep the",0,,False
105,documents with the k highest scores. This approach has,0,,False
106,triggered much research on the Boolean intersection problem,0,,False
107,"[20, 6, 32, 8, 25]. This approach is, of course, suboptimal,",0,,False
108,since in principle one could use weight information to filter,0,,False
109,out documents that belong to the intersection but one can,0,,False
110,ensure will not make it to the top-k list. Only recently some,0,,False
111,schemes specifically aimed at solving ranked intersections,0,,False
112,have appeared [21]. All these schemes store the posting lists,0,,False
113,"in increasing docid order, which is convenient for skipping",0,,False
114,documents during intersections.,0,,False
115,"Ranked unions, instead, cannot be efficiently solved through a Boolean union, as this returns too many results. In this case, most research has aimed at returning an approximate answer within good time bounds [30, 2]. Most of these techniques order the posting lists by decreasing weight values, not by docids. Recently, it has been shown that ranked unions can be solved in exact form within reasonable time [15, 35, 21] by using increasing docid order for the posting lists in the best solution [21].",1,ad,True
116,"Traditionally, the posting lists were stored on disk. With the availability of large amounts of main memory, this trend has changed to use the main memory of a cluster of machines, and many intersection algorithms have been designed for random access [20, 6, 32, 19, 33, 35, 8, 25]. In distributed main-memory systems, usually documents are distributed across independent inverted indexes, and each index contributes with a few results to the final top-k list. Therefore, it is most interesting that an individual inverted index solves top-k queries efficiently for k values in the range 10­100 [16].",1,ad,True
117,"Both when stored on disk and in main memory, reducing the size of the inverted index representation is crucial. On disk, it reduces transfer time. In main memory, it increases the size of the collections that can be managed within a given RAM budget, or alternatively reduces the amount of servers that must be allocated in a cluster to hold the index, the energy they consume, and the amount of communication. Compression of inverted indexes is possibly the oldest and most successful application of compressed data structures (e.g., see [38]). The main idea to achieve compression is to differentially encode either the document identifers or the weights (depending on how the lists are sorted), whereas the other value (weight or docid, respectively) becomes harder to compress. The problem of this duality in the sorting, and how it affects compression and query algorithms, has been discussed in past work [38, 4, 25].",0,,False
118,"In this context, our contribution is a new in-memory posting list representation that, on the one hand, achieves improved compression because it allows differential encoding of both docids and frequencies, and on the other hand, performs exact ranked intersections and unions directly and natively without having to first intersect/merge and then rank.",0,,False
119,3. RELATED WORK,0,,False
120,3.1 Query Processing Strategies,1,Query,True
121,Two kinds of approaches are used for unions and intersections (ranked or Boolean): Term-at-a-time (TAAT) and Document-at-a-time (DAAT) [16].,0,,False
122,"TAAT processes one posting list after the other. The lists are considered from shortest to longest, starting with the first one as a candidate answer set, and refining it as we consider the next lists. TAAT is especially popular for processing ranked unions [30, 2, 35], as the successive lists have decreasing idft value and thus a decreasing impact on the result, not only for the tf-idf model, but also for BM25 and other models. The documents in each list are sorted by decreasing weight. Thus heuristic thresholds can be used to obtain an approximate ranked union efficiently, by pruning the processing of lists earlier, or avoiding lists completely, as we reach less relevant documents and our candidate set becomes stronger [30, 2]. A more sophisticated approach based on similar ideas can be used to guarantee that the answer is exact [35].",0,,False
123,194,0,,False
124,"DAAT processing is more popular for Boolean intersections and unions. Here the q lists are processed in parallel, looking for the same document in all of them. Posting lists must be sorted by increasing docid, and we keep a pointer to the current position in each of the q lists. Once a document is processed, the pointers move forward. Much research has been carried out on Boolean intersections [20, 6, 32, 19, 8]. While a DAAT processing is always used to intersect two lists, experimental results suggest that the most efficient way to handle more lists is to intersect the two shortest ones, then the result with the third, and so on. This can be seen as a TAAT strategy.",0,,False
125,"Many ranked intersection strategies employ a full Boolean intersection followed by a postprocessing step for ranking. However, recent work has shown that it is possible to do better [21]. The advantage of DAAT processing is that, once we have processed a document, we have complete information about its score, and thus we can maintain a current set of top-k candidates whose final scores are known. This set can be used to establish a threshold on the scores other documents need to surpass to become relevant for the current query. Thus the emphasis on ranked DAAT is not on terminating early but on skipping documents. This same idea has been successfully used to solve exact (not approximate) ranked unions [15, 21].",1,ad,True
126,The strategies we use to solve ranked union and intersection queries in this paper are best classified as DAAT. We use sophisticated mechanisms to skip documents using the current threshold given by the current top-k candidate set.,0,,False
127,3.2 Compressed Posting List Representations,0,,False
128,"A list p1, p2, p3, . . . p is usually represented as a sequence of d-gaps p1, p2 - p1, p3 - p2, . . . , p - p -1 , and uses a variable-length encoding for these differences, for example -codes, -codes or Rice/Golomb codes [38], the latter usually giving the best compression. Recent proposals make use of byte-aligned [33, 19] or word-aligned [39, 1] codes, which are faster at decoding at a small loss in compression. Extracting a single list or merging lists is done optimally by traversing the lists from the beginning, but intersections can be done much faster if random access to the sequences is possible. A typical solution to provide random access is to perform a sampling of the sequences, cutting them into blocks that are differentially encoded, while storing in a separate sequence the absolute values of the block headers and pointers to the encoded blocks. Different sampling strategies have been used [19, 32] and the intersection algorithms have been tailored to them.",1,ad,True
129,"When lists are sorted by decreasing weight (for approximate ranked unions), the differential compression of docids is not possible, in principle. Instead, term weights can be stored differentially. When storing tf values, one can take advantage of the fact that long runs of equal tf values (typically low ones) are frequent, and thus not only run-length encode them, but also sort the corresponding docids increasingly, so as to encode them differentially [4, 41].",1,ad,True
130,3.3 State of the Art for Exact Ranked Queries,0,,False
131,The following two approaches have recently displayed the best performance for exact ranked intersections and unions.,0,,False
132,3.3.1 Block-Max,0,,False
133,"Block-Max [21] is a special-purpose structure for ranked intersections and unions. It sorts the lists by increasing docid, cuts the lists into blocks, and stores the maximum weight for each block. This enables them to skip whole blocks whose maximum possible contribution is very low, by comparing its maximum weight with a threshold given by the current candidate set. Block-Max obtains considerable performance gains over the previous techniques for exact ranked unions [15, 35], and also over the techniques that perform ranked intersections via a Boolean preprocessing.",0,,False
134,"The basic concept is as follows: Suppose the next document of interest, d, belongs to blocks b1, . . . , bq in the q lists. Compute an upper bound to score(Q, d) using the block maxima instead of the weights w(t, d). If even this upper bound does not surpass the kth best score known up to now, no document inside the current blocks can make it to the top-k list. So we can safely skip some blocks.",1,ad,True
135,"Our technique can be seen as a generalization of the BlockMax idea, in which we use the treap concept to naturally define a hierarchical blocking scheme. The generalization is algorithmically nontrivial, but it is practical and beats the flat Block-Max. In addition, the treap structure allows us to differentially encode both docids and weights, which translates into space savings with respect to Block-Max.",1,ad,True
136,3.3.2 Dual-sorted inverted lists,0,,False
137,"Dual-Sorted inverted lists [29, 25] represent the posting lists sorted by decreasing frequency, using a wavelet tree data structure [23, 28]. The wavelet tree efficiently simulates ordering by increasing docids. TAAT processing is used for approximate ranked unions and DAAT-like processing for (exact) ranked intersections. The latter, although building on Boolean intersections, is implemented in native form on wavelet trees, which makes it particularly fast, even faster than Block-Max. Basically, the wavelet tree can recursively subdivide the universe of docids and efficiently determine that some list has no documents in the current interval.",0,,False
138,"Our technique shares with Dual-Sorted the ability to maintain the lists sorted by both docids and weights simultaneously, and is able to perform a similar kind of native intersection, that is, determine that in an interval of documents there is a list with no elements. In contrast, Dual-Sorted does not know the frequencies until reaching the individual documents, whereas our treaps give an upper bound to the frequencies in the current interval. This allows us to perform ranked intersections faster than the Boolean intersections of Dual-Sorted. In addition, the treap uses less space, since Dual-Sorted cannot use differential encoding on docids.",1,ad,True
139,4. DIFFERENTIALLY ENCODED TREAPS,1,AP,True
140,"We describe our data structure in this section. First, we survey the treap data structure and show it can be used to represent a posting list. Then we describe how we represent the resulting data structure using little space. In addition, we describe some practical improvements on the basic idea. At the end, we describe how query processing is carried out on the final representation.",1,ad,True
141,4.1 The Treap Data Structure,0,,False
142,A treap [34] is a binary tree where nodes have two attributes: a key and a priority. The treap satisfies the invariants of a binary search tree with respect to the keys: the root key is larger than those of its left subtree and smaller,0,,False
143,195,0,,False
144,docids 4 9 13 14 15 22 27 30 35 37 39 44 freqs 6 2 14 1 1 2 1 24 6 1 2 3,0,,False
145,24 30,0,,False
146,6 4,0,,False
147,14 13,0,,False
148,21,0,,False
149,9,0,,False
150,14,0,,False
151,2 22,0,,False
152,1 27,0,,False
153,1 15,0,,False
154,6 35,0,,False
155,3 44,0,,False
156,2 39,0,,False
157,1 37,0,,False
158,Figure 1: An example posting list (with docids and frequencies) and the corresponding treap representation in our scheme. Note that docids (inside the nodes) are sorted inorder and frequencies (outside the nodes) are sorted top to bottom.,0,,False
159,"than those of its right subtree. Furthermore, the treap satisfies the invariants of a binary heap with respect to the priorities: the priority of the parent is larger than those of its descendants.",0,,False
160,"Given its invariants, a treap can be searched for a key just as a binary search tree, and it can be simultaneously used as a binary heap. While in the literature it has mostly been used with randomly assigned priorities [34, 26, 13] to ensure logarithmic expected height independently of the order of insertions, a treap can also be seen as the Cartesian tree [36] of the sequence of priorities once the values are sorted by keys. Such Cartesian tree can be built in O(n) time from a sequence of n elements already sorted by key, even in compressed form [10, 9, 22].",1,ad,True
161,"Treaps are a particular case of priority search trees [27], which can guarantee balancedness but are unlikely to be as compressible as Cartesian trees. There has been some work on using priority search trees for returning top-k elements from suffix trees and geometric range searches [12, 11] but, as far as we know, our use of treaps for ranked queries on inverted indexes, plus their differential compression, is novel.",0,,False
162,4.2 Inverted Index Representation,0,,False
163,"We consider the posting list of each term as a sequence sorted by docids (which act as keys), each with its own term frequency (which act as priorities). Term impacts, or any other term weights, may also be used as priorities. We then use a treap to represent this sequence. Therefore the treap will be binary searchable by docid, whereas it will satisfy a heap ordering on the frequencies. This means, in particular, that if a given treap node has a frequency below a desired threshold, then all the docids below it in the treap can be discarded as well.",0,,False
164,Figure 1 illustrates a treap representation of a posting list. This treap will be used as a running example.,0,,False
165,4.3 Compressing the Treap,0,,False
166,"In order to compete with existing compressed representations of posting lists, we represent the treap data (topology,",0,,False
167,"docids, and frequencies) in compact form. The key issue is that we choose a representation where all the treap operations can be carried out efficiently, so as to exploit the treap properties at query time.",0,,False
168,4.3.1 Compact topology representation,0,,False
169,"Given a posting list of n documents, the treap will be a binary tree of n nodes. We represent it as a general tree using a well-known isomorphism: First, a fake root node vr is created. The children of vr become the nodes in the rightmost path of the treap, from the root to the leaf. Then each of those nodes are converted recursively.",0,,False
170,"With this transformation, the treap root is the first child of vr. The left child of a treap node v is its first child in the general tree. The right child of v is its next sibling in the general tree. An inorder traversal of the treap corresponds to a postorder traversal of the general tree.",0,,False
171,"There are (4n/n3/2) general trees of n nodes, and thus one needs log2(4n/n3/2) ,"" 2n - (log n) bits to represent any such tree. There exist various compact tree representations using 2n+o(n) bits that can in addition carry out many tree operations efficiently, including taking the first child, next sibling, computing postorder of a node, and so on. We will use a recent representation that has proven to be efficient in practice [31, 3]. It is based on a balanced parentheses representation of the tree, obtained by a preorder traversal where we append an opening parenthesis when reaching a node and a closing parenthesis when leaving it.""",1,ad,True
172,4.3.2 Differentially encoded trees,0,,False
173,"In addition to the tree topology, we must represent docids and term frequencies. Our plan is not to access the posting lists in sequential form as in classical schemes, thus a differential encoding each docid with respect to the previous one is not directly applicable. Instead, we make use of the invariants of the treap data structure.",1,ad,True
174,"Let id(v) be the docid of a treap node v, and f (v) its frequency. We represent id(v) and f (v) for the root in plain form, and then represent those of its left and right children recursively. For each node v that is the left child of its parent u, we represent id(u) - id(v) instead of id(v). If, on the other hand, v is the right child of its parent u, we represent id(v) - id(u) [17]. In both cases, we represent f (u) - f (v) instead of f (v). Those numbers get smaller as we move downwards in the treap.",1,ad,True
175,"The sequence of differentially encoded id(v) and f (v) values is represented according to an inorder traversal of the treap. As we move down the treap, we can easily maintain the correct id(v) and f (v) values for any node arrived at, and use it to compute the values of the children as we descend.",0,,False
176,"For this sake we need to randomly access a differential value in the sequence, given a node. We store those values in an array indexed by node preorders (in the general tree), which we can easily compute in our topology representation. Furthermore, we need a storage mechanism for the differences that: i) can access any value in the sequence directly, while ii) uses fewer bits to represent smaller numbers. We use Direct Addressable Codes (DACs) [14], which are designed precisely with this aim.",0,,False
177,"DACs encode a sequence of numbers x1, . . . , xn as follows. The log2(max{xi} + 1) bits needed to represent any xi are divided into chunks of varying size. Then the first chunk of lowest bits of all the numbers are represented in",0,,False
178,196,0,,False
179,24 30,0,,False
180,6 4,0,,False
181,14 13,0,,False
182,21,0,,False
183,9,0,,False
184,14,0,,False
185,2 22,0,,False
186,1 27,0,,False
187,6 35,0,,False
188,3 44,0,,False
189,2 39,0,,False
190,1 15,0,,False
191,1 37,0,,False
192,Topology ( ( ( ( ) ( ) ) ( ( ) ( ) ) ( ) ) ( ) ( ( ( ) ) ) ),0,,False
193,diff ids 9 5 17 8 1 9 5 30 5 2 5 9,0,,False
194,diff freqs 8 4 10 1 0 12 1 24 18 1 1 3,0,,False
195,"Figure 2: The compressed representation of the example treap. The original binary tree edges (dashed) are replaced by a general tree, whose topology is represented with parentheses. Docids and frequencies are sorted inorder and represented in differential form with respect to their parent.",0,,False
196,"a first sequence, the second chunks in a second sequence, and so on. Some numbers xi will only participate in the first sequences because they are smaller than others. Compact bitmap representations are used to drive the extraction process for any xi through the different sequences where its chunks are represented. DACs can tune the block sizes so as to use minimum space, given the sequence of xi values.",0,,False
197,Figure 2 illustrates our compressed treap representation.,0,,False
198,4.4 Practical Improvements,0,,False
199,"The scheme detailed above would not be so successful without two important improvements. First, because many posting lists are very short, it turns out to be more efficient to store two single DAC sequences, with all the differential docids and all the differential frequencies for all the lists together, even if using individual DACs would have allowed us to optimize their space for each sequence separately. The overhead of storing the chunk lengths and other administrative data overweights the benefits for short sequences.",1,ad,True
200,"A second improvement is to break ties in frequencies so as to make the treap as balanced as possible, by choosing the maximum that is closest to the center of each interval. This improves the binary searches for docids.",0,,False
201,"The third, and more important, improvement is to omit from the treap representation all the elements of the lists where the frequency is below some threshold f0. According to Zipf's law [40, 18, 16, 5], a large number of elements will have low frequencies, and thus using a separate posting list for each frequency below f0 will save us from storing those frequencies wherever those elements would have appeared in the treap. Further, the docids of each list can be differentially encoded in classical sequential form, which is more efficient than in treap order.",0,,False
202,"It turns out that many terms do not have to store a treap at all, as they never occur more than f0 times in any document. We represent the gap-encoded lists using Rice codes and take an absolute sample every 128 values (which form",0,,False
203,24 30,0,,False
204,14 13,0,,False
205,6 4,0,,False
206,21,0,,False
207,9,0,,False
208,14,0,,False
209,2 22,0,,False
210,1 27,0,,False
211,6 35,0,,False
212,3 44,0,,False
213,2 39,0,,False
214,1 15,0,,False
215,1 37,0,,False
216,ids1 14 15 27 37 ids2 9 22 39,0,,False
217,diff ids1 14 1 12 10 diff ids2 9 13 17,0,,False
218,"Figure 3: Separating frequencies below f0 ,"" 2 in our example treap. The part that is removed from the treap is dashed. For the documents with frequencies 1 and 2, we show the absolute docids on the left and their differential version on the right.""",0,,False
219,"a block). Samples are stored separately and explicitly in an array, with pointers to the block [19]. Searches in these lists will ask for consecutively larger values, so we remember the last element found and exponentially search for the next query starting from there. Figure 3 illustrates the separation of low-frequency elements from our example treap.",0,,False
220,"A neat feature of these lists is that often we will not need to access them at all during queries, since ranked queries aim at the highest frequencies.",0,,False
221,4.5 Query Processing,1,Query,True
222,4.5.1 General procedure,0,,False
223,"Let Q be a query composed of q terms t  Q. To obtain the top-k documents from the intersection or union of q posting lists we proceed in DAAT fashion: We traverse the q posting lists in synchronization, identifying the documents that appear in all or some of them, and accumulating their weights w(t, d) into a final score(Q, d) ,"" t w(t, d) "",",0,,False
224,"t tf t,f · idft. Those documents are inserted in a minpriority queue limited to k elements, where the priority is the score. Each time we insert a new element and the queue size reaches k + 1, we remove the minimum. At the end of the process, the priority queue contains the top-k results. Furthermore, at any stage of the process, if the queue has reached size k, then its minimum score L is a lower bound to the scores we are interested in for the rest of the documents.",0,,False
225,4.5.2 Intersections,0,,False
226,"Let d be the smallest docid not yet considered (initially d , 1). All the treaps t maintain a stack of nodes (initially holding just a sentinel value element ut with id(ut) , + and f (ut) ,"" +), and a cursor vt (initially the treap root). The stack will contain the nodes in the path from the root to vt where we descend by the left child. We will always call ut the top of the stack, thus ut is an ancestor of vt and it holds id(ut) > id(vt).""",0,,False
227,"We advance in all the treaps simultaneously towards a node v with docid id(v) ,"" d, while skipping nodes using the current lower bound L. In all the treaps t we maintain the""",1,ad,True
228,197,0,,False
229,"invariant that, if v is in the treap, it must appear in the subtree rooted at vt. In particular, this implies d < id(ut).",0,,False
230,"Because of the decreasing frequency property of treaps, if d is in a node v within the subtree rooted at vt, then f (v)  f (vt). Therefore, we can compute an upper bound U to the score of document d by using values f (vt) instead of f (v), for example U ,"" tQ f (vt) · idft for a tf-idf scoring1. If this upper bound is U  L, then there is a valid topk answer where d does not participate, so we can discard d. Further, no node that is below all the current vt nodes can qualify. Therefore, we can safely compute a new target d  mint(id(ut)). Each time the value of d changes (it always increases), we must update the stack of all the treaps t to restore the invariants: While id(ut)  d, we assign vt  ut and remove ut from the stack. We then resume the global intersection process with this new target d. The upper bound U is recomputed incrementally each time any vt value changes (U may increase or decrease).""",1,ad,True
231,"When U > L, it is still feasible to find d with sufficiently high score. In this case we have to advance towards the node containing d in some treap. We obtained the best results by choosing the treap t of the shortest list. We must choose a treap where we have not yet reached d; if we have reached d in all the treaps then we can output d as an element of the intersection, with a known score (the current U value is the actual score of d), insert it in the priority queue of top-k results as explained (which may increase the lower bound L), and resume the global intersection process with d  d + 1 (we must update stacks, as d has changed).",1,ad,True
232,"In order to move towards d ,"" id(vt) in a treap t, we proceed as follows. If d < id(vt), we move to the left child of vt, lt, push vt in the stack, and make vt  lt. Instead, if d > id(vt), we move to the right child of vt, rt, and make vt  rt. We then recompute U with the new vt value.""",1,ad,True
233,"If we have to move to the left and there is no left child of vt, then d does not belong to the intersection. We stay at node vt and redefine a new target d  id(vt). If we have to move to the right and there is no right child of vt, then again d is not in the intersection. We make vt  ut, remove ut from the stack, and redefine d  id(ut). In both cases we adjust the stacks of the other treaps to the new value of d, as before, and resume the intersection process.",1,ad,True
234,Algorithm 1 gives pseudocode for the intersection.,0,,False
235,4.5.3 Handling low-frequency lists,0,,False
236,"We have not yet considered the lists of documents with frequencies up to f0, which are stored separately, one per frequency, outside the treap. While a general solution is feasible (but complicated), we describe a simple strategy for the case f0 ,"" 1, which is the case we implemented.""",0,,False
237,"Recall that we store the posting lists in gap-encoded blocks. Together with the treap cursor, we will maintain a list cursor, which points inside some block that has been previously decompressed. Each time there is no left or right child in the treap, we must search the list for potential elements omitted in the treap. More precisely, we look for elements in the range [d, id(vt) - 1] if we cannot go left, or in the range [d, id(ut) - 1] if we cannot go right. Those elements must be processed as if they belonged to the treap before proceeding",0,,False
238,"1Replacing f (v) by f (vt) will yield an upper bound whenever the scoring function is monotonic with the frequencies. This is a reasonable assumption and holds for most weighting formulas, including tf-idf and BM25.",0,,False
239,Algorithm 1 Top-k of intersection using treaps.,0,,False
240,"Intersect(Q, k)",0,,False
241,"results   // priority queue of pairs (key, priority) for t  Q do",0,,False
242,"stackt   // stack of treap t, id() , f () ,"" + vt  root of treap t end for compute score U using f (vt) values, e.g. tQ f (vt) · idft d1 L  - while d < + do while U  L do""",0,,False
243,"changed(mintQ id(top(stackt))) end while if t  Q, d , id(vt) then",0,,False
244,"report(d, U ) changed(d + 1) else t  treap of shortest list such that d , id(vt) if d < id(vt) then",0,,False
245,lt  left child of vt if lt is not null then,0,,False
246,"push(stackt,vt) changev(t, lt) else changed(id(vt)) end if else rt  right child of vt if rt is not null then changev(t, rt) else changev(t, pop(stackt)) changed(id(vt)) end if end if end if end while return results",0,,False
247,changed(newd),0,,False
248,d  newd for t  Q do,0,,False
249,v  vt while d  id(top(stackt)) do,0,,False
250,"v  top(stackt) pop(stackt) end while changev(t, v) end for",0,,False
251,"report(d, s)",0,,False
252,"results  results  (d, s) if |results| > k then",0,,False
253,remove minimum from results L  minimum priority in results end if,0,,False
254,"changev(t, v)",0,,False
255,"remove contribution of f (vt) from U , e.g. U - f (vt) · idft vt  v add contribution of f (vt) to U , e.g. U + f (vt) · idft",1,ad,True
256,198,0,,False
257,"in the actual treap. Finding this new range [l, r] in the list may imply seeking and decompressing a new block.",0,,False
258,"The cleanest way to process range [l, r] is to search as if it formed a subtree fully skewed to the right, descending from vt. If we descended to the left of vt towards the range, we push vt into the stack. Since all the elements in the list have the same frequency, when we are required to advance towards (a new) d we simply scan the interval until reaching or exceeding d, and the docid found acts as our new id(vt) value. When the interval [l, r] is exhausted, we return to the treap. Note that the interval [l, r] may span several physical list blocks, which may be subsequently decompressed.",1,ad,True
259,4.5.4 Unions,0,,False
260,"The algorithm for ranked unions requires a few changes on the algorithm for intersections. First, in the two lines that call changed(id(vt)), we do not change the d for all the treaps when the current treap does not find it. Rather, we keep values nextdt where each treap stores the minimum d  d it contains, thus those lines are changed by nextdt  id(vt). Second, we will choose the treap t to advance only among those where id(vt) , d and nextdt ,"" d, as if nextdt > d we cannot find d in treap t. Third, when all the treaps t where id(vt) "","" d satisfy nextdt > d, we have found exactly the treaps where d appears. We add up score(Q, d) over those treaps where id(vt) "","" d, report d, and advance to d+1. If, however, this happens but no treap t satisfies id(vt) "","" d, we know that d is not in the union and we can advance d with changed(mintQ nextdt). Finally, changed(newd) should not only update d but also update, for all the treaps t, nextdt to max(nextdt, newd).""",1,ad,True
261,5. EXPERIMENTS AND RESULTS,0,,False
262,5.1 Experimental Setup,0,,False
263,"We use the TREC GOV2 collection, parsed using Porter's stemming algorithm. The collection contains about 25.2 million documents and about 32.8 million terms in the vocabulary. The inverted lists contain about 4.9 billion postings in total. We used the TREC2006 Efficiency Queries dataset using distinct amounts of terms, from q , 2 to 5.",1,TREC,True
264,"We compare our results with two baselines: (1) BlockMax [21], using their implementation and modifying it to use tf-idf scoring, and (2) Dual-Sorted [25], using their implementation. As additional baselines, we implemented (3) our own version of a traditional docid-sorted inverted index using Rice encoding of the gaps, sampling values every 128 values to support random access via exponential search, and Rice encoding of absolute frequencies, and (4) our own version of a traditional frequency-sorted inverted index, using gap- and run-length encoding for the frequencies, and Rice encoding of absolute docids (except within equal frequencies, where docids are sorted and differentialy encoded).",1,ad,True
265,"Our experiments were performed on an Intel(r) Xeon(r) model E5620 running at 2.40 GHz with 96GB of RAM and 12,288KB of cache, running version 2.6.31-41 64 bits of the Linux kernel. All solutions were implemented in C++, compiled with g++ version 4.4.3 and -O3 optimization.",0,,False
266,5.2 Space Usage,0,,False
267,"Figure 4 shows the space usage of the main structures compared, for increasing subsets of GOV2. The line ""Treap w/o f0"" shows the space of our basic treap mechanism with-",0,,False
268,Size (MB),0,,False
269,12000 10000 8000,0,,False
270,Treap Treap w/o f0,0,,False
271,Block Max DualSorted,0,,False
272,6000,0,,False
273,4000,0,,False
274,2000,0,,False
275,0 40 80 120 160 200 240 Documents Inserted (x 100000),0,,False
276,Figure 4: Space usage per document inserted.,0,,False
277,docid freq,0,,False
278,Differential,0,,False
279,8.9 1.6,0,,False
280,Treap,0,,False
281,8.9 2.1,0,,False
282,Treap w/o f0 11.0 5.6,0,,False
283,Absolute,0,,False
284,14.8 5.7,0,,False
285,Figure 5: Pie chart with fraction of space used by the structures in our index. Bottom right: bpp for different representations of docids and frequencies.,0,,False
286,"out representing the low-frequency lists separately. As it can be seen, the treap mechanism to encode both docids and frequencies in partially differential form is not sufficient by itself to beat a representation like Block-Max (which does not encode frequencies differentially, but encodes docids differentially much better, in left-to-right order) or Dual-Sorted (which does not encode docids differentially, but encodes frequencies differentially and with run-length encoding).",0,,False
287,"When we separate the low-frequency lists (""Treap"" in the figure), the situation is much better, as this is roughly equivalent to run-length compressing consecutive postings with frequency 1, and in addition the overhead of the tree topology and of non-left-to-right differential encoding of documents disappears within those lists. With this improvement, our compressed treap structures offer a space gain of 22% over Block-Max and of 18% over Dual-Sorted. While the idea of low-frequency lists could be applied to Block-Max and Dual-Sorted, it would probably make them slower (unlike our treaps, which become faster when processing lowfrequency lists) and the impact in their space would not be as high as on the treaps (e.g., they have no tree topology and their differential encoding of docids would not improve).",1,ad,True
288,"Our tree representation (with low-frequency lists) requires about 12.3 bits per posting (bpp). Figure 5 shows how that space distributes across our structures. Almost half of the space is used for the treap DACs, the docids using about twice the space of the frequencies. The docids for frequency",0,,False
289,199,0,,False
290,Docid sorted Freq sorted Treap,0,,False
291,Treap w/o f0 Block-Max Dual-Sorted,0,,False
292,Docid 8.9,0,,False
293,14.8 8.9,0,,False
294,11.0,0,,False
295,Freq 5.7 1.6 2.1 5.6,0,,False
296,Topology,0,,False
297,1.3 2.4,0,,False
298,Total,0,,False
299,14.6 16.4 12.3 19.0 15.8 15.0,0,,False
300,Table 1: Bpps of main components of the indexes.,0,,False
301,"f0 ,"" 1 (F0), differentially encoded, use more than 40% of the space, which shows again how large is their impact on the space. Finally, the compressed treap topologies require about 10% of the space. Adding DACs and F0, we use 8.9 bpp for the docids, plus 2.1 bpp for the frequencies and 1.3 bpp for the topology. Our version without separating lowfrequency lists, instead, uses 11 bpp for the docids, 5.6 bpp for the frequencies, and 2.4 bpp for the topology, adding up to 19 bpp. This is compared in the figure (bottom right) with differential and absolute encodings of docids and frequencies (as detailed in Section 5.1), showing how treaps achieve intermediate results. Table 1 shows how the space of the various indexes adds up from those components.""",1,ad,True
302,5.3 Ranked Intersection,0,,False
303,"Figure 6 gives ranked intersection times for varying k, averaging over all the queries, and for k , 10 and k ,"" 20, separating the queries by number of words (q). As noted in previous work [25], Dual-Sorted is unique in that it improves for longer queries, taking over for queries of 4­5 words or more. Averaged over all the queries, it performs similarly to Block-Max, and both are superior to a Boolean intersection followed by a ranking (labeled """"Intersection"""") implemented over our docid-sorted inverted index. None of these methods is much affected by k (which is expected for Dual-Sorted and Intersection since they always produce the full intersection and then rank the resulting documents).""",0,,False
304,"Our treaps are more affected by the value of k, achieving larger speedups over a plain intersection for smaller k. Indeed, they are much faster than all the alternatives for small k values, and become similar to them for k , 30. For k ,"" 10, treaps outperform the others by a wide margin (up to 3 times faster than Block-Max, its closest competitor) for queries up to 4 words. For more than 4 words, as explained, Dual-Sorted takes over. The scenario is similar, yet less sharp, for k "", 20.",0,,False
305,"To explain the improved times of the treap representation compared to a plain intersection, Figure 7 shows the number of documents accessed in both cases. It can be seen that the treap data structure is very effective to prune the number of documents that must be considered, starting examining about 2.6% of the documents considered by a Boolean intersection for k ,"" 10, and becoming ineffective only at k "","" 1000. On the other hand, the compact data structures of the treap (namely the compressed representation of the topology and the DAC representation of the docids and frequencies) are significantly slower than a plain representation: both require about 300 nanoseconds per basic operation [3, 14], whereas a plain memory access costs 15­30 nanoseconds. This 10­20-fold slowdown makes the final time competitive only up to k "","" 30. The figure also shows the number of docids accessed at the low-frequency lists (F0), which increases with k but stays around 20% of the total.""",0,,False
306,"Intersection, varying k",0,,False
307,25 Treap,0,,False
308,Block-Max,0,,False
309,20,0,,False
310,Dual-Sorted,0,,False
311,Intersection,0,,False
312,15,0,,False
313,Milliseconds per query,0,,False
314,10,0,,False
315,5,0,,False
316,0,0,,False
317,10,0,,False
318,20,0,,False
319,30,0,,False
320,40,0,,False
321,50,0,,False
322,60,0,,False
323,k,0,,False
324,"Intersection, k,10",0,,False
325,25 Treap,0,,False
326,Block-Max,0,,False
327,20,0,,False
328,Dual-Sorted,0,,False
329,Intersection,0,,False
330,15,0,,False
331,Milliseconds per query,0,,False
332,10,0,,False
333,5,0,,False
334,0,0,,False
335,2,0,,False
336,3,0,,False
337,4,0,,False
338,5,0,,False
339,Query length,1,Query,True
340,"Intersection, k,20",0,,False
341,25 Treap,0,,False
342,Block-Max,0,,False
343,20,0,,False
344,Dual-Sorted,0,,False
345,Intersection,0,,False
346,15,0,,False
347,Milliseconds per query,0,,False
348,10,0,,False
349,5,0,,False
350,0,0,,False
351,2,0,,False
352,3,0,,False
353,4,0,,False
354,5,0,,False
355,Query length,1,Query,True
356,"Figure 6: Time performance for ranked intersections. On top, for all the queries and increasing k. The other two discriminate by number of words in the query and use fixed k , 10 and k , 20.",0,,False
357,5.4 Ranked Union,0,,False
358,"Figure 8 shows the results for ranked union queries. Using a Boolean union as a filter for these queries is ineffective, so we use our frequency-sorted inverted index to implement an approximate ranked union, Persin et al.'s [30] (labeled ""Persin"" in the plots). Dual-Sorted also implements Persin et al.'s algorithm, so both report only approximate results. Only Block-Max and our treaps give exact results.",0,,False
359,"It can be seen that all the times worsen as k and q increase, more than linearly on q and sublinearly on k. Our treaps outperform Block-Max and Dual-Sorted for all k values up to 130. They are 2.5 times faster, for example for 3-word",0,,False
360,200,0,,False
361,30000 25000 20000,0,,False
362,Intersection Treap f0,0,,False
363,Amount of documents,0,,False
364,15000,0,,False
365,10000,0,,False
366,5000,0,,False
367,0 10 100 200 300 400 500 600 700 800 900 1000,0,,False
368,k,0,,False
369,Figure 7: Documents evaluated during a ranked intersection query.,0,,False
370,"queries. Treaps are only outperformed by the native Persin implementation, which however is not exact.",0,,False
371,6. EXTENSIONS,0,,False
372,"It is not hard to adapt our algorithm for unions to the ranked version of the more general thresholded queries [7], which in addition to Q give a value q < q, so that at least q of the q query terms must appear in the reported documents. In this more general view, ranked unions correspond to q , 1 and ranked intersections to q , q. The more general Weak-AND operator [15] can also be easily supported. When we find which treaps t reach value id(vt) ,"" d, we can evaluate document d and determine whether it qualifies.""",1,ad,True
373,"On the other hand, approximate answers for ranked union queries have been the norm for decades, and our treap data structures can efficiently implement those as well. For example, we could easily implement Persin et al.'s [30] TAAT processing, even better than classical frequency-sorted lists. We could maintain the candidate set as a list sorted by docid. Each new treap that is processed is traversed in docid order, stopping at nodes where the threshold for considering documents is reached. As we produce the qualifying documents in docid order, we can simply merge them with the candidate set, without the need of more sophisticated structures. Furthermore, for subtrees of treap nodes whose frequency is below the threshold for inserting new documents in the candidate set, we can switch to a mode where the subtree is intersected with the candidates, using the next candidate docid to skip treap nodes.",1,ad,True
374,7. CONCLUSIONS AND FUTURE WORK,0,,False
375,"We have introduced a new inverted index representation based on the treap data structure. Treaps turn out to be an elegant and flexible tool to represent simultaneously the docid and the weight ordering of a posting list. We use them to design efficient ranked intersection and union algorithms that simultaneously filter out document by docid and frequency. The treap also allows us to represent both docids and frequencies in differential form, thus enabling better compression of the posting lists. Our experiments show significant gains in space and time compared to the state of the art: not only our structure uses about 20% less space than previous ones, but also it is faster (sometimes as much as",0,,False
376,"Union, varying k",0,,False
377,60 Treap,0,,False
378,50,0,,False
379,Block-Max Dual-Sorted,0,,False
380,Persin 40,0,,False
381,Milliseconds per query,0,,False
382,30,0,,False
383,20,0,,False
384,10,0,,False
385,Milliseconds per query,0,,False
386,0 10 20 30 40 50 60 70 80 90 100 110 120 130,0,,False
387,k,0,,False
388,"Union, k,10",0,,False
389,60 Treap,0,,False
390,50,0,,False
391,Block-Max,0,,False
392,Dual-Sorted,0,,False
393,Persin 40,0,,False
394,30,0,,False
395,20,0,,False
396,10,0,,False
397,0,0,,False
398,2,0,,False
399,3,0,,False
400,4,0,,False
401,5,0,,False
402,Query length,1,Query,True
403,"Union, k,20",0,,False
404,60 Treap,0,,False
405,50,0,,False
406,Block-Max,0,,False
407,Dual-Sorted,0,,False
408,Persin 40,0,,False
409,Milliseconds per query,0,,False
410,30,0,,False
411,20,0,,False
412,10,0,,False
413,0,0,,False
414,2,0,,False
415,3,0,,False
416,4,0,,False
417,5,0,,False
418,Query length,1,Query,True
419,"Figure 8: Time performance for ranked unions. On top, for all the queries and increasing k. The other two discriminate by number of words in the query and use fixed k , 10 and k , 20.",0,,False
420,"three times faster) for up to k , 30 on ranked intersections and k , 130 on ranked unions.",0,,False
421,"A first future work question is how the scheme performs with other scoring formulas. We have used simple tf-idf, but we could use BM25, impacts, etc. Some require to adapt the way we compute the upper bound U , such as considering document sizes in BM25 (but this has been solved [15, 21]).",1,ad,True
422,"A second question is what would be the impact of reassigning docids. There is much recent research on this topic (see, e.g., [21]) that shows that reassignment can significantly improve both space and processing time. How much would treaps improve with such schemes? Can we optimize the reassignment for a treap layout?",0,,False
423,201,0,,False
424,"An important part of our gain owed to separating lists with frequency f0 ,"" 1. How to efficiently separate lists with higher frequencies is a challenge, and it can lead to substantial further gains. It is also interesting to test how this idea impacts on schemes like Block-Max and Dual-Sorted.""",1,ad,True
425,"Finally, our performance degrades sharply with q, an effect already noted before in Block-Max [21]. We believe the time would become almost nonincreasing with q if we used treaps under a TAAT scheme where the longer lists were processed after determining good lower bounds with the shorter lists.",1,ad,True
426,8. REFERENCES,0,,False
427,"[1] V. Anh and A. Moffat. Inverted index compression using word-aligned binary codes. Inf. Retr., 8(1):151­166, 2005.",0,,False
428,"[2] V. Anh and A. Moffat. Pruned query evaluation using pre-computed impacts. In Proc. 29th SIGIR, pages 372­379, 2006.",0,,False
429,"[3] D. Arroyuelo, R. Ca´novas, G. Navarro, and K. Sadakane. Succinct trees in practice. In Proc. 11th ALENEX, pages 84­97, 2010.",1,ad,True
430,"[4] R. Baeza-Yates, A. Moffat, and G. Navarro. Searching large text collections. In Handbook of Massive Data Sets, pages 195­244. Kluwer, 2002.",0,,False
431,"[5] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley, 2nd edition, 2011.",0,,False
432,"[6] R. Baeza-Yates and A. Salinger. Experimental analysis of a fast intersection algorithm for sorted sequences. In Proc. 12th SPIRE, pages 13­24, 2005.",0,,False
433,"[7] J. Barbay and C. Kenyon. Adaptive intersection and t-threshold problems. In Proc. 13th SODA, pages 390­399, 2002.",0,,False
434,"[8] J. Barbay, A. Lo´pez-Ortiz, T. Lu, and A. Salinger. An experimental investigation of set intersection algorithms for text searching. ACM J. Exp. Alg., 14:art. 7, 2009.",0,,False
435,"[9] M. Bender and M. Farach-Colton. The LCA problem revisited. In Proc. 9th LATIN, pages 88­94, 2000.",0,,False
436,"[10] O. Berkman and U. Vishkin. Recursive star-tree parallel data structure. SIAM J. Comp., 22(2):221­242, 1993.",0,,False
437,"[11] I. Bialynicka-Birula. Ranked Queries in Index Data Structures. PhD thesis, University of Pisa, 2008.",0,,False
438,"[12] I. Bialynicka-Birula and R. Grossi. Rank-sensitive data structures. In Proc. 12th SPIRE, pages 79­90, 2005.",0,,False
439,"[13] G. Blelloch and M. Reid-Miller. Fast set operations using treaps. In Proc. 10th SPAA, pages 16­26, 1998.",0,,False
440,"[14] N. Brisaboa, S. Ladra, and G. Navarro. DACs: Bringing direct access to variable-length codes. Inf. Proc. Manag., 49(1):392­404, 2013.",1,ad,True
441,"[15] A. Broder, D. Carmel, M. Herscovici, A. Soffer, and J. Zien. Efficient query evaluation using a two-level retrieval process. In Proc. 12th CIKM, pages 426­434, 2003.",0,,False
442,"[16] S. Bu¨ttcher, C. Clarke, and G. Cormack. Information Retrieval: Implementing and Evaluating Search Engines. MIT Press, 2010.",0,,False
443,"[17] F. Claude, P. Nicholson, and D. Seco. Differentially encoded search trees. In Proc. 22nd DCC, pages 357­366, 2012.",0,,False
444,"[18] B. Croft, D. Metzler, and T. Strohman. Search Engines: Information Retrieval in Practice. Pearson Education, 2009.",0,,False
445,"[19] J. Culpepper and A. Moffat. Compact set representation for information retrieval. In Proc. 14th SPIRE, pages 137­148, 2007.",0,,False
446,"[20] E. Demaine, A. Lo´pez-Ortiz, and J. Munro. Adaptive set intersections, unions, and differences. In Proc. 11th SODA, pages 743­752, 2000.",0,,False
447,"[21] S. Ding and T.Suel. Faster top-k document retrieval using block-max indexes. In Proc. 34th SIGIR, pages 993­1002, 2011.",0,,False
448,"[22] J. Fischer and V. Heun. Space-efficient preprocessing schemes for range minimum queries on static arrays. SIAM J. Comp., 40(2):465­492, 2011.",0,,False
449,"[23] R. Grossi, A. Gupta, and J. Vitter. High-order entropy-compressed text indexes. In Proc. 14th SODA, pages 841­850, 2003.",0,,False
450,"[24] H. Heaps. Information Retrieval - Computational and Theoretical Aspects. Academic Press, NY, 1978.",1,ad,True
451,"[25] R. Konow and G. Navarro. Dual-sorted inverted lists in practice. In Proc. 19th SPIRE, pages 295­306, 2012.",0,,False
452,"[26] C. Mart´inez and S. Roura. Randomized binary search trees. J. ACM, 45(2):288­323, 1997.",0,,False
453,"[27] E. McCreight. Priority search trees. SIAM J. Comp., 14(2):257­276, 1985.",0,,False
454,"[28] G. Navarro. Wavelet trees for all. In Proc. 23rd CPM, pages 2­26, 2012.",0,,False
455,"[29] G. Navarro and S. Puglisi. Dual-sorted inverted lists. In Proc. 17th SPIRE, pages 309­321, 2010.",0,,False
456,"[30] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered document retrieval with frequency-sorted indexes. J. Am. Soc. Inf. Sci., 47(10):749­764, 1996.",0,,False
457,"[31] K. Sadakane and G. Navarro. Fully-functional succinct trees. In Proc. 21st SODA, pages 134­149, 2010.",1,ad,True
458,"[32] P. Sanders and F. Transier. Intersection in integer inverted indices. In Proc. 9th ALENEX, 2007.",0,,False
459,"[33] F. Scholer, H. Williams, J. Yiannis, and J. Zobel. Compression of inverted indexes for fast query evaluation. In Proc. 25th SIGIR, pages 222­229, 2002.",0,,False
460,"[34] R. Seidel and C. Aragon. Randomized search trees. Algorithmica, 16(4/5):464­497, 1996.",0,,False
461,"[35] T. Strohman and B. Croft. Efficient document retrieval in main memory. In Proc. 30th SIGIR, pages 175­182, 2007.",0,,False
462,"[36] J. Vuillemin. A unifying look at data structures. Comm. ACM, 23(4):229­239, 1980.",0,,False
463,"[37] L. Wang, J. Lin, and D. Metzler. A cascade ranking model for efficient ranked retrieval. In Proc. 34th SIGIR, pages 105­114, 2011.",1,ad,True
464,"[38] I. Witten, A. Moffat, and T. Bell. Managing Gigabytes. Morgan Kaufmann, 2nd edition, 1999.",0,,False
465,"[39] H. Yan, S. Ding, and T. Suel. Inverted index compression and query processing with optimized document ordering. In Proc. 18th WWW, pages 401­410, 2009.",0,,False
466,"[40] G. Zipf. Human Behaviour and the Principle of Least Effort. Addison-Wesley, 1949.",0,,False
467,"[41] J. Zobel and A. Moffat. Inverted files for text search engines. ACM Comp. Surv., 38(2):art. 6, 2006.",0,,False
468,202,0,,False
469,,0,,False
