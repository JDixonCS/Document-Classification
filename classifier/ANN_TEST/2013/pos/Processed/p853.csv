,sentence,label,data,regex
0,Estimating Query Representativeness for Query-Performance Prediction,1,Query,True
1,Mor Sondak,0,,False
2,Anna Shtok,0,,False
3,Oren Kurland,0,,False
4,mor@tx.technion.ac.il annabel@tx.technion.ac.il kurland@ie.technion.ac.il,0,,False
5,"Faculty of Industrial Engineering and Management, Technion Haifa 32000, Israel",0,,False
6,ABSTRACT,0,,False
7,"The query-performance prediction (QPP) task is estimating retrieval effectiveness with no relevance judgments. We present a novel probabilistic framework for QPP that gives rise to an important aspect that was not addressed in previous work; namely, the extent to which the query effectively represents the information need for retrieval. Accordingly, we devise a few query-representativeness measures that utilize relevance language models. Experiments show that integrating the most effective measures with state-of-the-art predictors in our framework often yields prediction quality that significantly transcends that of using the predictors alone.",1,ad,True
8,Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval]: Retrieval models,0,,False
9,"General Terms: Algorithms, Experimentation",0,,False
10,Keywords: query-performance prediction,0,,False
11,1. INTRODUCTION,1,DUC,True
12,"The task of estimating retrieval effectiveness in the absence of relevance judgments -- a.k.a. query-performance prediction (QPP) -- has attracted much research attention [2]. Interestingly, an important aspect of search effectiveness has been overlooked, or not explicitly modeled, in previously proposed prediction approaches; namely, the presumed extent to which the query effectively represents the underlying information need for retrieval.",0,,False
13,"Indeed, an information need can be represented by various queries which in turn might represent various information needs. Some of these queries might be more effective for retrieval over a given corpus than others for the information need at hand. Furthermore, relevance is determined with respect to the information need rather than with respect to the query. These basic observations underlie the development of the novel query-performance prediction framework that we present. A key component of the framework is the use of measures for the query representativeness of the information need. We propose several such measures that are based on using relevance language models [8].",0,,False
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.",1,ad,True
15,Empirical evaluation shows that integrating the most effective representativeness measures with state-of-the-art predictors in our framework yields prediction quality that often significantly transcends that of using these predictors alone.,0,,False
16,2. RELATED WORK,0,,False
17,"Our query-performance prediction framework essentially generalizes a recently proposed framework [7], the basis of which was the estimation of the relevance of a result list to a query. Our framework relies on the basic definition of relevance with respect to the information need, and therefore accounts for the connection between the query and the information need. This connection was not (explicitly) addressed in previous work including [7]. For example, preretrieval predictors, which use only the query and corpusbased statistics, are mostly based on estimating the discriminative power of the query with respect to the corpus, but do not account for the query-information need connection.",1,ad,True
18,"Post-retrieval predictors analyze also the result list of topretrieved documents [2]. Our framework provides formal grounds to integrating pre-retrieval, post-retrieval, and queryrepresentativeness, which turn out to be three complementary aspects of the prediction task. Furthermore, we demonstrate the merits of integrating post-retrieval predictors with query representativeness measures in the framework.",0,,False
19,"The query representativeness measures that we devise utilize relevance language models [8]. Relevance models were used for other purposes in various predictors [3, 14, 5, 10]. We demonstrate the merits of integrating in our framework one such state-of-the-art predictor [14].",0,,False
20,3. PREDICTION FRAMEWORK,0,,False
21,"Let q, d and D denote a query, a document, and a corpus of documents, respectively. The task we pursue is estimating the effectiveness of a retrieval performed over D in response to q when no relevance judgments are available [2] -- i.e., query performance prediction (QPP).",0,,False
22,"Let Iq be the information need that q represents. Since relevance is determined with respect to Iq rather than with respect to q, the QPP task amounts, in probabilistic terms, to answering the following question:",0,,False
23,"What is the probability that the result list Dres, of the most highly ranked documents with respect to q, is relevant to Iq?",0,,False
24,"Formally, the task is estimating",0,,False
25,"p(r|Iq, Dres)",0,,False
26,",",0,,False
27,"p(Dres|Iq, r)p(r|Iq) , p(Dres |Iq )",0,,False
28,(1),0,,False
29,853,0,,False
30,"where r is the relevance event and p(r|Iq, Dres) is the probability that the result list Dres satisfies Iq.",0,,False
31,"Estimating p(Dres|Iq, r) is the (implicit) basis of many post-retrieval prediction methods, if q serves for Iq, as recently observed [7]. The denominator, p(Dres|Iq), is the probability that the result list Dres is retrieved using some representation of Iq regardless of relevance. If q is used for Iq, then the probability of retrieving Dres depends on the properties of the retrieval method employed. Accordingly, the denominator in Equation 1 can serve as a normalizer across different retrieval methods [7]. However, standard QPP evaluation [2] is based on estimating the retrieval effectiveness of a fixed retrieval method across different queries. Thus, the denominator in Equation 1 need not be computed for such evaluation, if q serves for Iq [7].",0,,False
32,"The (novel) task we focus on is estimating the probability p(r|Iq) from Equation 1 that a relevance event happens for Iq. Obviously, the ability to satisfy Iq depends on the corpus D; e.g., if there are no documents in D that pertain to Iq then the estimate should be zero. Furthermore, the satisfaction of Iq also depends on the query q used to represent it. Thus, the estimate for p(r|Iq) can be approximated by:",0,,False
33,p^(r|Iq ),0,,False
34,"p^(r|Iq, q, D)",0,,False
35,",",0,,False
36,"p^(q|Iq, D, r)p^(r|Iq, D) , p^(q|Iq, D)",0,,False
37,(2),0,,False
38,"where p^(·) is an estimate for p(·). The estimate p^(q|Iq, D) for the probability that q is chosen",0,,False
39,"to represent Iq for retrieval over D can be used to account, for example, for personalization aspects. We leave this task for future work, and assume here a fixed user model, and accordingly, a fixed (across queries) p^(q|Iq, D).",0,,False
40,"If we use q for Iq in the estimate p^(r|Iq, D), we get the probabilistic basis for pre-retrieval prediction methods [6, 4]. These predictors implicitly estimate the probability for a relevance event using information induced from the query and the corpus, but not from the result list (Dres).",0,,False
41,"The task left for completing the instantiation of Equation 2, and as a result that of Equation 1, is devising p^(q|Iq, D, r) -- the estimate for the probability that q is the most likely query to effectively represent Iq for retrieval over D.",0,,False
42,3.1 Estimating query representativeness,0,,False
43,The only signal about the information need Iq is the (short),0,,False
44,"query q. To induce a ""richer"" representation for Iq, we use",0,,False
45,"the generative theory for relevance [8]. Specifically, we con-",0,,False
46,struct a (unigram) relevance language model R from doc-,0,,False
47,uments in the corpus D. (Details are provided in Section,0,,False
48,"4.1.) Then, estimating q's representativeness amounts to es-",0,,False
49,"timating the probability p(q|R, D, r) of generating q by R.",0,,False
50,"Henceforth, we refer to such estimates as measures of q's",0,,False
51,"representativeness, denoted X(q; R).",0,,False
52,"We assume, as in the original relevance model's formula-",0,,False
53,"tion [8], that q's terms ({qi}) are generated independently",0,,False
54,by ity,0,,False
55,"R: p^(q|R, D, r) d,ef assigned to qi by R.",0,,False
56,"qTi op(pqri|eRve);ntp(tqhie|Rq)ueisryt-hleenpgrtohbbaibaisl-,",0,,False
57,we use the geometric mean of the generation probabilities,0,,False
58,which results in the GEO measure:,0,,False
59,"GEO(q; R) d,ef |q|",0,,False
60,p(qi|R);,0,,False
61,qi q,0,,False
62,|q| is the number of terms in q.,0,,False
63,"We also consider the arithmetic mean of the generation probabilities, ARITH, as a representativeness measure:",0,,False
64,"ARIT H(q; R) d,ef",0,,False
65,1 |q|,0,,False
66,p^(qi|R).,0,,False
67,qi q,0,,False
68,"For comparison purposes, we study the min and max aggregators of the generation probabilities:",0,,False
69,"M IN (q; R) d,ef min p(qi|R);",0,,False
70,qi q,0,,False
71,"M AX(q; R) d,ef max p(qi|R).",0,,False
72,qi q,0,,False
73,"Another measure that we consider is the weighted entropy of R, where q's terms are assigned with a unit weight and all other terms in the vocabulary are assigned a zero weight:",0,,False
74,"EN T (q; R) d,ef - p^(qi|R) log p^(qi|R).",0,,False
75,qi q,0,,False
76,"The underlying assumption is that high entropy, which implies to a relatively uniform importance assigned to q's terms by R, is indicative of effective representation by q. Indeed, too little emphasis on some query aspects was identified as a major cause for retrieval failures [1].",0,,False
77,4. EVALUATION,0,,False
78,"We next present an evaluation of our query-performance prediction (QPP) framework. We begin by describing the experimental setup in Section 4.1. In Section 4.2.1 we focus on using the query-representativeness measures. To that end, we use an oracle-based experiment where the relevance model is constructed only from relevant documents. In Section 4.2.2 we study the integration of the representativeness measures with post-retrieval predictors in our framework.",0,,False
79,Collection,0,,False
80,TREC12 TREC5 ROBUST,1,TREC,True
81,WT10G,1,WT,True
82,Data,0,,False
83,"Disks 1,2 Disks 2,4 Disks 4,5-CR",0,,False
84,WT10g,1,WT,True
85,# of Docs,0,,False
86,"741,854 524,929 528,155",0,,False
87,"1,692,096",0,,False
88,Topics,0,,False
89,"51-200 251-300 301-450, 601-700 451-550",0,,False
90,Avg. query length,0,,False
91,3.52 3.08 2.64,0,,False
92,2.66,0,,False
93,Table 1: TREC datasets used for experiments.,1,TREC,True
94,4.1 Experimental setup,0,,False
95,"Table 1 presents the TREC datasets used for experiments. TREC12, TREC5 and ROBUST are composed (mostly) of newswire documents, while WT10G is a noisy Web collection. Titles of TREC topics serve for queries. Documents and queries were stemmed with the Krovetz stemmer and stopwords (on the INQUERY list) were removed. The Indri toolkit (www.lemurproject.org) was used for experiments.",1,TREC,True
96,"Following common practice [2], prediction quality is measured by the Pearson correlation between the true average precision (AP@1000) for the queries, as determined using the relevance judgments in the qrels files, and the values assigned to these queries by a predictor.",1,AP,True
97,"The query likelihood method [11] serves for the retrieval method, the effectiveness of which we predict. Document d's retrieval score is the log query likelihood: log qiq p(qi|d); p(qi|d) is the probability assigned to qi by a Dirichlet",0,,False
98,854,0,,False
99,smoothed unigram language model induced from d with the,0,,False
100,smoothing parameter set to 1000 [13].,0,,False
101,We use relevance model #1 (RM1) [8] in the query repre-,0,,False
102,"sentativeness measures: p(w|R) d,ef dS p(w|d)p(d|q); S is",0,,False
103,a set of documents; p(w|d) is the maximum likelihood esti-,0,,False
104,mate,0,,False
105,of,0,,False
106,term,0,,False
107,w,0,,False
108,with,0,,False
109,respect,0,,False
110,to,0,,False
111,d;,0,,False
112,p(d|q),0,,False
113,is,0,,False
114,(i),0,,False
115,1 |S|,0,,False
116,when,0,,False
117,S,0,,False
118,is,0,,False
119,a set of relevant documents as is the case in Section 4.2.1;,0,,False
120,"and, (ii) d's normalized query likelihood:",0,,False
121,p(q|d) dS p(q|d),0,,False
122,",",0,,False
123,when,0,,False
124,S is the set of all documents in the corpus that contain at,0,,False
125,least one query term as is the case in Section 4.2.2. No term,0,,False
126,clipping was employed for RM1.,0,,False
127,4.2 Experimental results,0,,False
128,4.2.1 The query-representativeness measures,0,,False
129,"The query-representativeness measures play an important role in our QPP framework, and are novel to this study. Thus, we first perform a controlled experiment to explore the potential extent to which these measures can attest to query performance. To that end, we let the measures use a relevance model of a (very) high quality. Specifically, RM1 is constructed from all relevant documents in the qrels files as described in Section 4.1. Table 2 presents the prediction quality of using the representativeness measures by themselves as query-performance predictors. As can be seen, the prediction quality numbers are in many cases quite high. All these numbers -- which are Pearson correlations -- are different than zero to a statistically significant degree according to the two-tailed t-test with a 95% confidence level.",0,,False
130,"We can also see in Table 2 that GEO is the most effective measure except for TREC5. ARITH and MIN are also quite effective, although often less than GEO. ENT is highly effective for TREC5 and WT10G but much less effective for TREC12 and ROBUST. The MAX measure is evidently less effective than the others, except for TREC5. All in all, we see that different statistics of the generation probabilities assigned by the relevance model to the query terms can serve as effective query representativeness measures for query-performance prediction.",1,TREC,True
131,GEO ARITH MIN MAX ENT,0,,False
132,TREC12,1,TREC,True
133,0 588 .,0,,False
134,"0.457g 0.523g 0.216gn,a 0.251gn,a",0,,False
135,TREC5 0.295 0.398 0.334 0.351 0.526x,1,TREC,True
136,ROBUST,0,,False
137,0 376 . 0.274 0.328,0,,False
138,"0.153gn,a 0.222gx",0,,False
139,WT10G,1,WT,True
140,0 414 . 0.356 0.373,0,,False
141,"0.24g,a 0.375x",0,,False
142,"Table 2: Using the representativeness measures by themselves as query-performance predictors with RM1 constructed from relevant documents. Boldface: the best result in a column. 'g', 'a', 'n', 'x' and 'e' mark statistically significant differences in correlation [12] with GEO, ARITH, MIN, MAX, and ENT, respectively.",0,,False
143,4.2.2 Integrating query-representativeness measures with post-retrieval predictors,0,,False
144,"Query-representativeness measures are one component of our QPP framework. Other important components are postretrieval and pre-retrieval prediction as described in Section 3. Since (i) the query representativeness measures constitute a novel contribution of this paper, (ii) the merits of the integration of post-retrieval and pre-retrieval prediction were",1,Query,True
145,"already demonstrated in previous work [7], and, (iii) postretrieval predictors often yield prediction quality that is substantially better than that of pre-retrieval predictors [2], we focus on the integration of the representativeness measures with the post-retrieval predictors in our framework. The integration is performed using Equations 1 and 2. In contrast to the case in Section 4.2.1, we use the standard practical QPP setting; that is, no relevance judgments are available. The relevance model used by the query-representativeness measures is constructed as described in Section 4.1 from all the documents in the corpus that contain at least one query term. Using only top-retrieved documents for constructing the relevance model resulted in inferior prediction quality.",1,ad,True
146,"Three state-of-the-art post-retrieval predictors, NQC [9], WIG [14] and QF [14], are used. As these predictors incorporate free parameters, we apply a train-test approach to set the values of the parameters. Since Pearson correlation is the evaluation metric for prediction quality, there should be as many queries as possible in both the train and test sets. Thus, each query set is randomly spit into two folds (train and test) of equal size. We use 40 such splits and report the average prediction quality over the test folds. For each split, we set the free-parameter values of each predictor by maximizing prediction quality over the train fold.",1,WIG,True
147,"NQC and WIG analyze the retrieval scores of top-retrieved documents, the number of which is set to values in {5, 10, 50, 100, 500, 1000}. QF incorporates three parameters. The number of top-retrieved documents used to construct the relevance model (RM1) utilized by QF is selected from {5, 10, 25 , 50, 75, 100, 200, 500, 700, 1000} and the number of terms used by this RM1 is set to 100 following previous recommendations [10]. The cuttoff used by the overlap-based similarity measure in QF is set to values in {5, 10, 50, 100, 500, 1000}.",1,WIG,True
148,"In Table 3 we present the average (over the 40 test folds) prediction quality of using the query-representativeness measures alone; using the post-retrieval predictors alone; and, integrating the representativeness measures with the postretrieval predictors in our framework. Although the queryrepresentativeness measures do not incorporate free parameters, we report their prediction quality when used alone using the same test splits. When the measures are integrated with the post-retrieval predictors, the free-parameters of the integration are those of the post-retrieval predictors. In this case, the parameters are tuned by optimizing the prediction quality of the integration over the train folds, as is the case when using the post-retrieval predictors alone. Differences of prediction quality (i.e., Pearson correlations) are tested for statistical significance using the two tailed paired t-test computed over the 40 splits with a 95% confidence level.1",1,corpora,True
149,"We first see in Table 3 -- specifically, by referring to the underlined numbers -- that the best prediction quality for the majority of the corpora is attained by integrating a representativeness measure with a post-retrieval predictor.",1,corpora,True
150,"Further exploration of Table 3 reveals the following. The GEO and ARITH measures are effective -- specifically, in comparison to the other representativeness measures which is reminiscent of the case in Table 2 -- both as stand-alone",0,,False
151,"1Note that the numbers in Table 2 are not comparable to those in Table 3. This is because the latter presents averages over the train-test splits while the former is based on using the all queries for the test set. Furthermore, as noted above, the relevance models used for the representativeness measures are constructed using different sets of documents.",0,,False
152,855,0,,False
153,GEO ARITH MIN MAX ENT,0,,False
154,NQC,0,,False
155,NQCGEO NQCARITH NQCMIN NQCMAX NQCENT,0,,False
156,WIG WIGGEO WIGARITH WIGMIN WIGMAX WIGENT,1,WIG,True
157,QF QFGEO QFARITH QFMIN QFMAX QFENT,0,,False
158,TREC12 0.642 0.635 0.583 0.465 0.277,1,TREC,True
159,0.666 0.705pq 0.713pq 0.663q 0.672q 0.598pq,0,,False
160,0.665 0.688pq 0.689pq 0.645pq 0.604pq 0.462pq,0,,False
161,0.673 0.723pq 0.711pq 0.692q 0.608pq 0.498pq,0,,False
162,TREC5 0.380 0.435 0.272 0.396 0.381,1,TREC,True
163,0.289,0,,False
164,0.303q 0.323q 0.272 0.303q 0.299q,0,,False
165,0.250 0.371p 0.373pq 0.319pq 0.338pq 0.334pq,0,,False
166,0.313 0.378p 0.429p 0.314q 0.438pq 0.393p,0,,False
167,ROBUST 0.407 0.419 0.352 0.366 0.309,0,,False
168,0.506 0.520pq 0.534pq 0.456pq 0.508q 0.491pq,0,,False
169,0 514 .,0,,False
170,0.467pq 0.480pq 0.416pq 0.447pq 0.409pq,0,,False
171,0.500 0.518pq 0.528pq 0.471pq 0.504q 0.485pq,0,,False
172,WT10G 0.317 0.287 0.305 0.210 0.256,1,WT,True
173,0 422 .,0,,False
174,0.411q 0.375pq 0.405q 0.309pq 0.421q,0,,False
175,0 393 .,0,,False
176,0.316p 0.285p 0.313p 0.240pq 0.333pq,0,,False
177,0.267 0.372pq 0.353pq 0.361pq 0.272q 0.307pq,0,,False
178,"Table 3: Average prediction quality over the test folds of the query-representativeness measures, post-retrieval predictors, and their integration (marked with ). Boldface: the best result per corpus and a post-retrieval block; underline: the best result in a column. 'q' and 'p' mark statistically significant differences with using the query-representativeness measure alone and the post-retrieval predictor alone, respectively.",0,,False
179,"predictors and when integrated with the post-retrieval predictors. Indeed, integrating each of GEO and ARITH with a post-retrieval predictor yields prediction quality that transcends that of using the post-retrieval predictor alone in 9 out of the 12 relevant comparisons (three post-retrieval predictors and four corpora); many of these improvements are substantial and statistically significant.",1,corpora,True
180,"These findings, as those presented above, attest to the merits of our QPP framework that integrates two different, and evidently complementary, aspects of prediction; namely, post-retrieval analysis of the result list and queryrepresentativeness estimation.2",0,,False
181,"In comparing the prediction quality numbers in Table 3 for the three post-retrieval predictors we make the following observation. For QF and WIG the integration with the queryrepresentativeness measures yields the highest and lowest number, respectively, of cases of improvement over using the post-retrieval predictor alone.",1,WIG,True
182,"2It is not a surprise, therefore, that the post-retrieval predictors when used alone outperform in most cases the representativeness measures when used alone. This is because the post-retrieval predictors analyze the result list, while the representativeness measures do not. For TREC5, however, the reverse holds. Presumably, this is because there are only 50 queries for TREC5, while for all other corpora there are at least 100 queries. A relatively small query set makes it difficult to learn the free-parameter values of the post-retrieval predictors, while representativeness measures do not incorporate free parameters.",1,TREC,True
183,5. CONCLUSIONS AND FUTURE WORK,0,,False
184,We presented a novel probabilistic framework for the queryperformance prediction task. The framework gives rise to an important aspect that was not addressed in previous work: the extent to which the query effectively represents the underlying information need for retrieval. We devised queryrepresentativeness measures using relevance language models. Empirical evaluation showed that integrating the most effective measures with state-of-the-art post-retrieval predictors in our framework often yields prediction quality that significantly transcends that of using the predictors alone.,1,ad,True
185,"Devising additional query-representativeness measures, and integrating pre-retrieval predictors with post-retrieval predictors and query-representativeness measures in our framework, are future venues to explore.",1,ad,True
186,6. ACKNOWLEDGMENTS,0,,False
187,"We thank the reviewers for their comments. This work has been supported in part by the Israel Science Foundation under grant no. 433/12 and by a Google faculty research award. Any opinions, findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsors.",0,,False
188,7. REFERENCES,0,,False
189,"[1] C. Buckley. Why current IR engines fail. In Proceedings of SIGIR, pages 584­585, 2004. Poster.",0,,False
190,"[2] D. Carmel and E. Yom-Tov. Estimating the Query Difficulty for Information Retrieval. Synthesis Lectures on Information Concepts, Retrieval, and Services. Morgan & Claypool Publishers, 2010.",1,Query,True
191,"[3] S. Cronen-Townsend, Y. Zhou, and W. B. Croft. Predicting query performance. In Proceedings of SIGIR, pages 299­306, 2002.",0,,False
192,"[4] C. Hauff, D. Hiemstra, and F. de Jong. A survey of pre-retrieval query performance predictors. In Proceedings of CIKM, pages 1419­1420, 2008.",0,,False
193,"[5] C. Hauff, V. Murdock, and R. Baeza-Yates. Improved query difficulty prediction for the web. In Proceedings of CIKM, pages 439­448, 2008.",0,,False
194,"[6] B. He and I. Ounis. Inferring query performance using pre-retrieval predictors. In Proceedings of SPIRE, pages 43­54, 2004.",0,,False
195,"[7] O. Kurland, A. Shtok, S. Hummel, F. Raiber, D. Carmel, and O. Rom. Back to the roots: A probabilistic framework for query-performance prediction. In Proceedings of CIKM, pages 823­832, 2012.",0,,False
196,"[8] V. Lavrenko and W. B. Croft. Relevance-based language models. In Proceedings of SIGIR, pages 120­127, 2001.",0,,False
197,"[9] A. Shtok, O. Kurland, and D. Carmel. Predicting query performance by query-drift estimation. In Proceedings of ICTIR, pages 305­312, 2009.",0,,False
198,"[10] A. Shtok, O. Kurland, and D. Carmel. Using statistical decision theory and relevance models for query-performance prediction. In Proccedings of SIGIR, pages 259­266, 2010.",0,,False
199,"[11] F. Song and W. B. Croft. A general language model for information retrieval (poster abstract). In Proceedings of SIGIR, pages 279­280, 1999.",0,,False
200,"[12] J. H. Steiger. Tests for comparing elements of a correlation matrix. Psychological Bulletin, 87(2):245­251, 1980.",0,,False
201,"[13] C. Zhai and J. D. Lafferty. A study of smoothing methods for language models applied to ad hoc information retrieval. In Proceedings of SIGIR, pages 334­342, 2001.",1,ad,True
202,"[14] Y. Zhou and W. B. Croft. Query performance prediction in web search environments. In Proceedings of SIGIR, pages 543­550, 2007.",1,Query,True
203,856,0,,False
204,,0,,False
