,sentence,label,data,regex
0,Session 4A: Fairness & Robustness,1,Session,True
1,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
2,Ranking Robustness Under Adversarial Document Manipulations,1,Robust,True
3,Gregory Goren,0,,False
4,gregory.goren@campus.techion.ac.il Technion -- Israel Institute of Technology,0,,False
5,Moshe Tennenholtz,0,,False
6,moshet@ie.technion.ac.il Technion -- Israel Institute of Technology,0,,False
7,ABSTRACT,0,,False
8,"For many queries in the Web retrieval setting there is an on-going ranking competition: authors manipulate their documents so as to promote them in rankings. Such competitions can have unwarranted effects not only in terms of retrieval effectiveness, but also in terms of ranking robustness. A case in point, rankings can (rapidly) change due to small indiscernible perturbations of documents. While there has been a recent growing interest in analyzing the robustness of classifiers to adversarial manipulations, there has not yet been a study of the robustness of relevance-ranking functions. We address this challenge by formally analyzing different definitions and aspects of the robustness of learning-to-rank-based ranking functions. For example, we formally show that increased regularization of linear ranking functions increases ranking robustness. This finding leads us to conjecture that decreased variance of any ranking function results in increased robustness. We propose several measures for quantifying ranking robustness and use them to analyze ranking competitions between documents' authors. The empirical findings support our formal analysis and conjecture for both RankSVM and LambdaMART.",1,ad,True
9,"ACM Reference Format: Gregory Goren, Oren Kurland, Moshe Tennenholtz, and Fiana Raiber. 2018. Ranking Robustness Under Adversarial Document Manipulations. In SIGIR '18: The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval, July 8-12, 2018, Ann Arbor, MI, USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3209978.3210012",1,Robust,True
10,1 INTRODUCTION,1,DUC,True
11,"In adversarial retrieval settings (e.g., the Web) there is an on-going ranking competition for many queries: authors of some Web documents manipulate them so as to have them ranked high. The ranking competition can have various undesirable effects. First, ranking effectiveness can degrade due to adversarial changes of documents that result in having them ranked higher than they",1,ad,True
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00 https://doi.org/10.1145/3209978.3210012",1,ad,True
13,Oren Kurland,0,,False
14,kurland@ie.technion.ac.il Technion -- Israel Institute of Technology,0,,False
15,Fiana Raiber,0,,False
16,fiana@oath.com Yahoo Research,1,Yahoo,True
17,"should; i.e., black-hat search engine optimization (SEO) [11]. Furthermore, rankings can potentially (rapidly) change due to small document perturbations that might be indiscernible.",0,,False
18,"Motivated by the ranking competitions that take place in the adversarial Web retrieval setting, and the growing body of work on robust classification -- specifically, with respect to adversarial manipulations [4, 6­10, 14, 20, 21, 25], we present the first (to the best of our knowledge) theoretical and empirical study of the robustness of document relevance-ranking functions to document manipulations. Our focus is learning-to-rank-based functions [13] where a document-query pair is represented as a feature vector.",1,ad,True
19,"We start by adapting a basic classifier-robustness notion used in recent work on robust classification [7, 20] to the case of a document ranking function. We formally analyze implications of applying this notion and highlight a notable drawback: the treatment of documents independently of each other -- i.e., this is a pointwise robustness perspective. However, ranking depends on the relative retrieval scores of documents. Hence, we formulate a definition of pairwise robustness that addresses the effect of small document changes on the relative ranking of pairs of documents. We formally analyze the implications of applying our pairwise robustness definition and the connections with pointwise robustness.",1,ad,True
20,"The different definitions of robustness that we propose are based on a worst-case scenario; namely, quantifying the minimal document change needed to change a ranking. Using the definitions to compare the robustness of different ranking functions can be quite difficult. Thus, we explore an additional aspect of robustness which we term stability (cf. [20]): changes of retrieval scores and relative ranking with respect to a given fixed change of a document. We then establish formal connections for linear (in features) ranking functions between the extent of their regularization and their stability. Motivated by these formal findings, we state a variance conjecture: the higher the variance of a learned ranking function, the less robust the rankings it induces. A ranking is considered robust if it does not significantly change due to small documents' changes. We propose a few methods of measuring ranking robustness.",1,ad,True
21,"While our motivation is to address documents' changes introduced by incentivized authors, our formal analysis makes no assumptions on the cause and nature of documents' changes. Thus, the analysis constitutes a general treatment of ranking robustness under document manipulations. Since, in practice, documents' changes in competitive retrieval settings are often incentivized (adversarial), we use for evaluation a recently published dataset of document ranking competitions held between students [17]. The",1,ad,True
22,395,0,,False
23,Session 4A: Fairness & Robustness,1,Session,True
24,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
25,mere motivation to change documents in the competitions was to have them ranked high as possible.,0,,False
26,"The analysis of the ranking competitions provides support to the formal analysis and the variance conjecture. First, increased regularization of a linear ranking function (RankSVM [12]), which leads to reduced variance, results in improved ranking robustness. Second, increased regularization of a non-linear ranking function, namely, the state-of-the-art LambdaMART method [27], also results in improved ranking robustness. Third, LambdaMART induces rankings that are less robust than those induced by RankSVM; the former has higher variance than the latter.",1,ad,True
27,Our contributions can be summarized as follows:,0,,False
28,· We present the first formal and empirical analysis of the robustness of learning-to-rank-based relevance ranking functions to (adversarial) manipulations of documents.,1,ad,True
29,"· We formally demonstrate, and provide empirical support to, the connection between regularization of linear learning-to-rank functions and ranking robustness.",0,,False
30,"· Motivated by our formal findings, we post a conjecture about the connection between the variance of a ranking function and ranking robustness, and provide empirical support.",0,,False
31,2 RANKING ROBUSTNESS,0,,False
32,"We assume that the following have been fixed: a query q, a document corpus D, and a document relevance ranking function f . As is the case for many learning-to-rank-based retrieval methods [13], the ranking function takes as input a feature vector d  m that represents the pair of document d ( D) and the query1 q; d[i] is the i'th component of d. Features can model query-document relations, query-independent properties of documents and documentindependent properties of the query [13]. The output of the ranking function (wlog) is a retrieval score f (d)  + used to induce a ranking over the corpus. We assume that ties of retrieval scores are consistently broken (e.g., using documents' IDs). We use L2 norms of vectors. For a linear (in features) ranking function f , f (d) d,ef w d + b; w is the weight vector and b is the intercept.",0,,False
33,"Our goal is to define and quantify notions of the robustness of ranking functions f to small perturbations of documents. Rather than directly address documents' changes (e.g., with respect to content, hyperlink, hypertext, etc.), we study the effects of the resultant perturbations of the corresponding feature vectors.",1,ad,True
34,"We first motivate our analysis of ranking robustness in Section 2.1. Then, in Section 2.2 we adapt a recently used classifierrobustness definition [6, 20] to ranking functions. The definition addresses documents independently. Since ranking is determined by the relative retrieval scores of documents, we study the notion of pairwise document robustness in Section 2.3; that is, we examine effects of documents' perturbations on the relative ranking of two documents. Given our formal findings in Section 2.3, we post a conjecture about the connection between ranking robustness and the variance of a ranking function in Section 2.4. Finally, in Section 2.5 we present a few methods to measure ranking robustness.",1,ad,True
35,1We omit q from the feature-vector notation as it is fixed throughout the section.,0,,False
36,2.1 Motivation,0,,False
37,"Much of the practical motivation for the recent line of work on robustness of classifiers comes from the vision realm [7, 8, 10, 20, 25]. The assumption is that small perturbations of images not discernible by humans should not result in changes to classification decisions.",0,,False
38,"We make a similar assumption about the ranking of documents. That is, a ranking should not (significantly) change as a result of small, potentially indiscernible, perturbations of documents2. A case in point, users might suspect the validity of rankings given rapid changes that are hard to explain (a.k.a., ""explainable IR"").",0,,False
39,"To further support our premise, we appeal to the cluster hypothesis which states that ""closely associated documents tend to be relevant to the same requests"" [22]. An important operational manifestation of the hypothesis is the premise that ""similar documents should receive similar retrieval scores"" [5]. That is, by the cluster hypothesis, similar documents would be relevant to the same requests (i.e., queries). Therefore, their retrieval scores which reflect relevance status should not be very different. In other words, small perturbations of documents should not result in significant changes of retrieval scores, and hence, significant ranking changes3.",0,,False
40,"Accordingly, below we focus on the effects of documents' perturbations on induced rankings; i.e., ranking robustness. The formal treatment of the effects on document relevance, and consequently ranking effectiveness, is an intriguing research venue at its own right which we leave for future work.",0,,False
41,2.2 Pointwise Robustness,1,Robust,True
42,"The recently adopted notion of classifier robustness was defined based on the minimal change of an object required to change the class to which the object is classified [7, 20]. We conceptually adapt this robustness notion to the case of retrieval scores. We term this robustness ""pointwise"" as documents are considered independently -- i.e., the effects of the change of a document retrieval score on its relative ranking with respect to other documents are not considered. To simplify the following definitions and analysis, and without loss of generality, we focus, unless otherwise stated, on the increase of a retrieval score rather than a change which could be negative.",1,ad,True
43,"Definition 1 (Pointwise Robustness). The pointwise robustness of ranking function f with respect to document d and query q is: point ( f ; d, q) d,ef minv m ||v|| s.t. f (d + v) > f (d). The robustness with respect to q is the expectation over all documents d ( D) sampled using some distribution P(D): point ( f ; q) d,""ef EdP(D) point ( f ; d, q).""",1,Robust,True
44,"In other words, the pointwise robustness with respect to document d is the minimal extent of a change (i.e., norm of a vector) needed to be applied to d so as to increase d's retrieval score.",0,,False
45,"We now analyze the pointwise robustness of linear ranking functions: f (d) d,""ef w d + b. RankSVM [12] and coordinate ascent [15] are examples of commonly used, effective linear ranking functions.""",0,,False
46,"2In contrast to spamming, white-hat SEO attempts to promote documents in rankings often do not result in a significant drift with respect to the original document [17]. 3The cluster hypothesis was originally stated with respect to textual content of documents [22]. It could be that the document content does not change but its feature-vector representation does -- e.g., due to changes of hyperlinks and anchor text.",0,,False
47,396,0,,False
48,Session 4A: Fairness & Robustness,1,Session,True
49,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
50,Proposition 1. The pointwise robustness of a linear ranking function is less or equal to  for any  > 0.,0,,False
51,"Proof. Let d be some document. Then, f (d + v) > f (d) ",0,,False
52,wv > 0. Suppose wlog that w [i] > 0. We define a vector v such that,0,,False
53,"v[j] , 0 for all j i and v[i] ,"" . Thus, we get that wv > 0 and""",0,,False
54,"point ( f ; d, q)  ||v|| ,"" . Consequently, point ( f ; q)  .""",0,,False
55,"There are various ranking functions whose robustness can be substantially higher than 0. For example, in gradient boosted regression trees which are the basis of the state-of-the-art LambdaMART ranking function [27], not every change of a document's feature vector necessarily results in a retrieval score change.",1,ad,True
56,"2.2.1 Pointwise stability. Definition 1 refers to the worst case scenario per document d. That is, the minimal change to d required so as to increase d's retrieval score. Indeed, as we showed above, every linear ranking function has, under this definition, robustness",0,,False
57,"that approaches 0. However, linear functions differ by the extent to",0,,False
58,"which a retrieval score changes with respect to a given magnitude ||v|| of a document change v. Therefore, pointwise robustness, as defined in Definition 1, cannot be used to quantify this specific",0,,False
59,"aspect of robustness, and we turn to the following definition:",0,,False
60,"Definition 2 (Pointwise Stability). A ranking function f is pointwise stable at level K ( +) with respect to a document change v if d, | f (d + v) - f (d)|  K ||v||. The lower K, f becomes more pointwise stable with respect to v.4",0,,False
61,"Contractive (Lipschitz) ranking functions f are pointwise stable at level K where K is the Lipschitz coefficient. Various ranking functions are contractive. For example, some neural-network architectures were shown to be contractive [20]5. Linear ranking functions are also contractive. Specifically, for f (d) d,""ef w d + b we get, using the Cauchy-Schwarz inequality:""",0,,False
62,| f (d + v) - f (d)|  ||w ||||v||.,0,,False
63,"Hence, the Lipshitz bound K  ||w ||, and f is pointwise stable at level K  ||w ||. This observation has an important implication. In linear ranking functions, such as RankSVM, the loss function used for training is often regularized by adding ||w || where  is the parameter that controls the extent of regularization. Higher value of  results in decreased ||w || (i.e., stronger regularization) as the goal is to minimize the objective function (loss+regularization). We",1,ad,True
64,thus arrive to:,0,,False
65,"Corollary 1. Ceteris paribus, stronger regularization of linear ranking functions increases pointwise stability.",0,,False
66,"We note that when using L2 norms, decreasing the norm of w (i.e., increasing regularization) is intended to improve generalization and prevent overfitting; in other words, stronger regularization increases the bias of the ranking function and decreases its variance. We re-visit this point below.",0,,False
67,"The pointwise analysis treats documents independently of each other. However, ranking is determined by the relative retrieval scores of documents. Specifically, a change to a retrieval score, as",0,,False
68,4,0,,False
69,"Obviously,",0,,False
70,a,0,,False
71,function,0,,False
72,stable,0,,False
73,at,0,,False
74,a,0,,False
75,level,0,,False
76,K,0,,False
77,is,0,,False
78,also,0,,False
79,stable,0,,False
80,at,0,,False
81,any,0,,False
82,level,0,,False
83,>,0,,False
84,K.,0,,False
85,5Some classification architectures were shown to be contractive [20]. It can be shown,0,,False
86,that using these architectures for regression (ranking) also yields a contractive function.,0,,False
87,"large as it may be, need not necessarily affect ranking. Hence, we now turn to address the robustness of ranking functions in terms of the relative ranking of pairs of documents.",1,ad,True
88,2.3 Pairwise Robustness,1,Robust,True
89,"Definition 3 (Pairwise Robustness). Let d1 and d2 be two documents such that f (d1)  f (d2). The pairwise robustness of f with respect to d1,d2 and the query q is: pair ( f ; d1, d2, q) d,ef minv m ||v|| s.t. f (d2 + v) > f (d1). The pairwise robustness of f with respect to the query is the expectation over document pairs: pair ( f ; q) d,""ef Ed1P(D),d2P(D\{d:f (d )>f (d1) }) pair ( f ; d1, d2, q).""",1,Robust,True
90,Pairwise robustness generalizes pointwise robustness: setting,0,,False
91,"d1 , d2 in Definition 3 results in the pointwise robustness definition",0,,False
92,"from Definition 1. Accordingly, it directly follows that:",0,,False
93,"Proposition 2. Pairwise robustness entails pointwise robustness but the reverse does not hold. That is, pair ( f ; q)  point ( f ; q).",0,,False
94,"In other words, the minimal document change (on average)",0,,False
95,needed to change the relative ranking of a document with respect,0,,False
96,to another document is higher than the minimal change needed,0,,False
97,to have the document's retrieval score increase. This trivial ob-,0,,False
98,servation touches on the fundamental difference between treating,0,,False
99,documents independently and accounting for their relations.,0,,False
100,"Specifically, an important difference between pointwise and pair-",0,,False
101,wise robustness is the potential dependence of the latter on dis-,0,,False
102,"tances between documents' feature vectors. For example, we now show that for a linear ranking function f (d) d,""ef w d + b, the smallest change of d2 required to increase its retrieval score beyond that of d1 approaches its distance from d1. Furthermore, we show that for any linear ranking function, there exists a pair of documents' feature vectors for which the pairwise robustness of f is not smaller than the distance between d1 and d2.""",0,,False
103,"Proposition 3. Let f be a linear ranking function. Then, d1, d2 s.t. d1 d2 and f (d1)  f (d2) and  > 0, pair ( f ; d1, d2, q)  ||d1 - d2|| +  . And, d1, d2 s.t. pair ( f ; d1, d2, q) > ||d1 - d2||.",0,,False
104,"Proof. Suppose wlog that w [i] > 0. Fix  > 0 and some d1 and d2 ( d1) s.t. f (d1)  f (d2). Let v , d1 - d2 +  where [i] ,  and [j] ,"" 0 for j i. Then, f (d2 + v) - f (d1) > 0 iff w [i] > 0. Since pair ( f ; d1, d2, q)  ||v|| and by the triangle inequality ||v||  ||d1 -d2|| +, we get that pair ( f ; d1, d2, q)  ||d1 -d2|| +.""",0,,False
105,We now turn to prove the second part of the proposition. Let,0,,False
106,"d1 d,ef -w and d2 d,""ef -2w ; thus, f (d1) > f (d2). Furthermore, v:""",0,,False
107,f (d2 + v) - f (d1) > 0 iff vw > ||w ||2. By the Cauchy-Schwarz,0,,False
108,"inequality, vw  ||v||||w ||. Thus, f (d2 + v) - f (d1) > 0  ||v|| >",0,,False
109,"||w || ,"" ||d1 - d2||. Thus, pair ( f ; d1, d2, q) > ||d1 - d2||.""",0,,False
110,Additional question we are interested in is the connection be-,0,,False
111,"tween pointwise stability of retrieval scores and pairwise robustness6, specifically, for linear functions: f (d) d,ef w d + b.",0,,False
112,"6Recall that we showed above that the pointwise robustness of linear ranking functions approaches 0; however, their pointwise stability varies across different functions.",0,,False
113,397,0,,False
114,Session 4A: Fairness & Robustness,1,Session,True
115,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
116,"Proposition 4. Let f be a linear ranking function. There exist d1 and d2 s.t. pair ( f ; d1, d2, q) > Kmin where Kmin is the minimal level at which f is pointwise stable with respect to any v.",0,,False
117,"Proof. Let d1 , 2w and d2 , w . Note that f (d1) > f (d2). For",0,,False
118,"any v, f (d2 + v) > f (d1) iff wv > ||w ||2. Thus, by the Cauchy-",0,,False
119,"Schwarz inequality, ||w ||2 < wv  ||w ||||v||. Consequently,",0,,False
120,"pair ( f ; d1, d2, q)  ||v|| > ||w ||. As shown in Section 2.2, for",0,,False
121,linear ranking functions | f (d+v) - f (d)|  ||w ||||v|| and therefore,0,,False
122,"Kmin  ||w || < pair ( f ; d1, d2, q).",0,,False
123,"Proposition 4 might seem counter intuitive at first glance. That is, the higher Kmin , which means reduced stability, the higher pair ( f ; d1, d2, q) can be -- the pairwise robustness for some pair of documents (or more precisely, their feature vectors). However, recall that Kmin is determined with respect to all possible v. Thus, it suffices that there is some v whose addition to some d increases substantially d's retrieval score and hence Kmin . The effect on pair ( f ; d1, d2, q) can only be an increase or no change.",1,ad,True
124,"There are two implications of these observations. First, pointwise",0,,False
125,"stability and pairwise robustness are, in general, complementary",0,,False
126,"properties of a ranking function. Second, pointwise stability should",0,,False
127,mainly be used to contrast different ranking functions with respect to the same document change v.,0,,False
128,"2.3.1 Pairwise stability. Definition 3, as was the case for Definition 1, refers to the worst case scenario: the minimal extent of a change that can be introduced to document d2 which is ranked lower than d1 so as to have it ranked higher than d1. However, this robustness definition does not allow to compare the effect of a",0,,False
129,"given fixed change on rankings induced by different rankers. To address this task, we observe the following. Let d1 and d2 be",1,ad,True
130,"two documents. Their relative ranking is determined by sin( f (d2)- f (d1)). Thus, to estimate whether the relative ranking of the two documents changes after d2 was changed by v, we can examine",0,,False
131,"(d1, d2; v) d,ef | f (d2 + v) - f (d1) - f (d2) - f (d1) |.",0,,False
132,"The lower (d1, d2; v) the higher the likelihood that the score difference after the document change has the same sign as that before the",0,,False
133,"change; that is, the higher the likelihood that the relative ranking would not change. Now, (d1, d2; v) ,"" | f (d2 + v) - f (d2)|. Thus, we are led to the following definition and consequence:""",0,,False
134,"Definition 4 (Pairwise Stability). A ranking function f is pairwise stable at level K ( +) with respect to a document change v if d1 d2, (d1, d2; v)  K ||v||.",0,,False
135,"And, we got that f is pairwise stable at level K iff it is pointwise stable at level K; i.e., d, | f (d + v) - f (d)|  K ||v||.",0,,False
136,Note that we essentially used f to classify pairs of documents. This practice is also the basis of RankSVM [12]: a ranking func-,0,,False
137,tion is learned by using it as a classifier upon pairs of documents.,0,,False
138,We argued that classification decisions are stable if the difference,0,,False
139,between retrieval scores after a document has changed is close,0,,False
140,to the difference before the change. A similar argument was used,0,,False
141,in recent work on estimating classifier stability with respect to a,0,,False
142,single object that has changed [20].,0,,False
143,"At the technical level, the pair-classification practice we have taken resulted in backing off from addressing both documents involved to only the one which has changed. Specifically, pairwise stability at a level K is attained with respect to a given change v for all document pairs iff the ranking function is pointwise stable at a level K with respect to v; i.e., the same change introduced to any document is not likely to result in a rank swap of this document with another document if the change of the document's retrieval score is not large. It is therefore important to highlight an additional difference between the definitions of pairwise robustness and stability. Robustness is computed as the worst case scenario for a given pair of documents and is aggregated over all document pairs via the expectation. Stability level is a constraint imposed on all document pairs. Accounting for all specific pairwise relations to derive a bound on stability level is a highly difficult task.",1,ad,True
144,"In Section 2.2.1 we showed that for a linear ranking function f , | f (d + v) - f (d)|  ||w ||||v||. Since (d1, d2; v) ,"" | f (d2 + v) - f (d2)| we get that f is pairwise stable at a level K  ||w ||. Recall that the stronger the regularization of a linear function trained by minimizing loss + ||w ||, i.e., the higher the value of , the lower ||w ||. Hence, for a given small document change (i.e., small ||v||) we get that stronger regularization results in decreased likelihood of rank swaps. In other words:""",0,,False
145,"Corollary 2. Ceteris paribus, stronger regularization of linear ranking functions results in more robust rankings; that is, the rankings are less likely to change as a result of changing documents.",0,,False
146,"Herein we use the terms ""ranking robustness"" and ""ranking stability"" interchangeably so as to refer to changes, or lack thereof, of a given ranking of a document list with respect to documents' changes; this is in contrast to the pointwise and pairwise analysis where we used the terms ""robustness"" and ""stability"" to refer to different notions. Measuring the robustness of a given ranking with respect to given documents' changes is a task we address in Section 2.5. Before delving into the details, we briefly discuss simultaneous changes of two documents. Then, in Section 2.4, we further discuss the connection between regularization and ranking robustness.",1,ad,True
147,"Simultaneous change of two documents. Heretofore, we discussed the pairwise case with respect to a change, v, of one of the two documents involved. Now, suppose that document d1 is changed by v1 and document d2 is simultaneously changed by v2. Similarly to the case above, we can examine",0,,False
148,"(d1, d2; v1, v2) d,ef | f (d2 + v2) - f (d1 + v1) - f (d2) - f (d1) |.",0,,False
149,We can then adapt Definition 4 (pairwise stability) as follows:,1,ad,True
150,"Definition 5 (Simultaneous Pairwise Stability). A ranking function f is simultaneously pairwise stable at level K ( +) with respect to pairwise simultaneous changes v1 and v2 if d1 d2, (d1, d2; v1, v2)  K (||v1|| + ||v2||).",0,,False
151,"By the triangle inequality,",0,,False
152,"(d1, d2; v1, v2)  | f (d1 + v1) - f (d1)| + | f (d2 + v2) - f (d2)|.",0,,False
153,"Thus, if f is pointwise stable with respect to each of v1 and v2 at a level K, it is simultaneously pairwise stable at level K.",0,,False
154,398,0,,False
155,Session 4A: Fairness & Robustness,1,Session,True
156,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
157,"For a linear ranking function f (d) d,ef w d + b we get that:",0,,False
158,"(d1, d2; v1, v2) ,",0,,False
159,(1),0,,False
160,|wv2 - wv1|  ||w ||||v2 - v1||  ||w ||(||v1|| + ||v2||).,0,,False
161,"Thus, the function is simultaneously pairwise stable at level ||w ||. Hence, we arrive again to the conclusion that stronger regularization of linear ranking functions, which results in reduced ||w ||, yields rankings of increased robustness.",0,,False
162,2.4 The Variance Conjecture,0,,False
163,We established above the connection between stronger regulariza-,0,,False
164,tion of linear ranking functions and increased ranking robustness.,0,,False
165,Stronger regularization results in decreased variance and increased,0,,False
166,bias of the ranking function.,0,,False
167,"For example, in RankSVM [12], the width of the margin of the sep-",0,,False
168,arating hyperplane is,0,,False
169,2,0,,False
170,| |w | | . The lower,0,,False
171,"||w ||, as a result of stronger",0,,False
172,"regularization, the wider the margin. This results in higher bias and",0,,False
173,"lower variance of the learned ranking function. Indeed, larger mar-",0,,False
174,"gin means a more ""robust/stable"" decision surface, which resonates",0,,False
175,"with the fact that ranking robustness is higher. Accordingly, we",0,,False
176,post the following variance conjecture for any ranking function:,0,,False
177,Conjecture 1 (The variance conjecture). The lower the variance of a learned ranking function the more robust the rankings induced by the function7.,0,,False
178,"In Section 3 we provide some empirical support to the conjecture. Specifically, we show that reducing the variance of RankSVM, which is a linear ranker, and that of LambdaMART which is a non-linear ranker, results in increased ranking robustness.",0,,False
179,2.5 Measuring Ranking Robustness,1,Robust,True
180,One of our goals is to empirically contrast the robustness of rank-,0,,False
181,ings induced by different ranking functions. Suppose that L is a ranked document list retrieved using some,0,,False
182,"ranking function. Suppose that some of the authors of documents in L changed them (e.g., to have the documents ranked higher). After the changes, the ranking function is used to rank the documents in L again; the result is a ranked list L. The question is how to quantify the robustness of L with respect to the changes of documents it contains given that the resultant (re-)ranked list is L.",0,,False
183,"We can use any inter-ranking similarity or distance measure to quantify robustness. To compute these measures for L and L, we consider a document d before its change, and after its change, denoted d , as the same item.",0,,False
184,"Kendall's- distance (KT in short) is defined as the number of discordant pairs between two paired lists normalized with respect to the number of pairs of items in a list; its value is in [0, 1]. A",0,,False
185,discordant pair is two items whose relative ranking in one list is,0,,False
186,"different than that in the other list. The higher the value, the higher the ""distance"" between the two lists8.",0,,False
187,7Low variance corresponds to improved generalization of a ranker to unseen queries.,0,,False
188,This is a different notion of robustness than that we focus on here.,0,,False
189,8,0,,False
190,In,0,,False
191,contrast,0,,False
192,to,0,,False
193,Kendall's-,0,,False
194,"distance,",0,,False
195,Kendall's-,0,,False
196,coefficient,0,,False
197,also,0,,False
198,considers,0,,False
199,concordant,0,,False
200,"pairs and its value is in [-1, 1].",0,,False
201,KT treats equally swaps between documents at high ranks and,0,,False
202,"at low ranks. However, the former have higher effect on precision-",0,,False
203,"based retrieval effectiveness measures (e.g., average precision, p@k,",0,,False
204,"NDCG) than the latter. Thus, we also consider the inter-list similar-",0,,False
205,"ity measure RBO (rank-biased overlap) that differentiates swaps according to their ranks [26]. (We set the free parameter of RBO, p,",0,,False
206,"to 0.7.) Additional robustness measure we are interested in is ""top",0,,False
207,"change"" (TC): the value is 1 if the highest ranked document in L and L is different, and 0 otherwise.",0,,False
208,All three measures just discussed do not consider the amount of,0,,False
209,"document change. However, changes in ranking due to small (po-",0,,False
210,tentially indiscernible) document changes are a stronger evidence,0,,False
211,for reduced robustness than those that result from large document,0,,False
212,"changes. Indeed, our pointwise (Definition 2), pairwise (Definition",0,,False
213,4) and simultaneous pairwise (Definition 5) stability definitions cap-,0,,False
214,"ture this notion. Hence, we define normalized measures of ranking",0,,False
215,robustness where normalization is with respect to the extent to,0,,False
216,which two documents have changed. We normalize KT and TC;,0,,False
217,normalizing RBO is more evolved and left for future work.,0,,False
218,Let d1 and d2 be documents in L that might have changed to,0,,False
219,"d  and d  in L, respectively. Inspired by Definitions 4 and 5 and",0,,False
220,1,0,,False
221,2,0,,False
222,"Equation 1, we use the sum, difference and relative functions to",0,,False
223,quantify changes to d1 and d2:,0,,False
224,"sum (d1, d2) d,ef",0,,False
225,| |d,0,,False
226,2,0,,False
227,-,0,,False
228,d2,0,,False
229,||,0,,False
230,+,0,,False
231,| |d,0,,False
232,1,0,,False
233,-,0,,False
234,"d1 | |,",0,,False
235,"dif f (d1, d2) d,ef",0,,False
236,| |d,0,,False
237,2,0,,False
238,-,0,,False
239,d2 | |,0,,False
240,-,0,,False
241,| |d,0,,False
242,1,0,,False
243,-,0,,False
244,d1,0,,False
245,||,0,,False
246,",",0,,False
247,"r el (d1, d2) d,ef",0,,False
248,| | (d,0,,False
249,2,0,,False
250,-,0,,False
251,d2 ),0,,False
252,-,0,,False
253,(d,0,,False
254,1,0,,False
255,-,0,,False
256,d1 ) | | .,0,,False
257,"To normalize KT, rather than count the number of discordant",0,,False
258,"pairs of documents, for each discordant pair (d1,d2) we use the",0,,False
259,1,0,,False
260,"value:  (d1,d2)+1 . We then simply sum the values for all discordant pairs. The resulting distance measures are denoted KT-sum, KTdiff and KT-rel, respectively. Note that the smaller the changes of",0,,False
261,"two documents which are a discordant pair, the higher the effect",0,,False
262,"of the swap between them -- i.e., the higher the distance and the",0,,False
263,lower the robustness. It is also important to note that the values of,0,,False
264,"these measures are  0 but are not bound from above. If we were to use the standard weighted Kendall- distance (cf., [19]), then we",0,,False
265,1,0,,False
266,"should have normalized by the sum of  (d1,d2)+1 over all documents pairs. Then, the upper bound would have been 1. However, while",0,,False
267,weighted Kendall- differentiates the effect of discordant pairs on,0,,False
268,"the distance between two rankings, it does not allow to effectively",0,,False
269,"compare distances between different pairs of lists. A case in point,",0,,False
270,"if a list L contains two documents, then the standard weighted Kendall's- distance between L and L is equivalent to TC which",0,,False
271,does not take into account the amount of documents' changes that,0,,False
272,led to ranking changes.,0,,False
273,To normalize TC we do the following. Suppose that d1 is the,0,,False
274,highest ranked document in L and d  ( d ) is the highest ranked,0,,False
275,21,0,,False
276,document,0,,False
277,in,0,,False
278,L.,0,,False
279,We,0,,False
280,attribute,0,,False
281,the,0,,False
282,value,0,,False
283,"1  (d1,d2)+1",0,,False
284,to,0,,False
285,this,0,,False
286,change,0,,False
287,"of the highest ranked document. Thus, the more d1 and d2 were",0,,False
288,"changed to become d  and d , respectively, the less weight we",0,,False
289,1,0,,False
290,2,0,,False
291,"attribute to this change. The resultant measures are: TC-sum, TC-",0,,False
292,diff and TC-rel.,0,,False
293,399,0,,False
294,Session 4A: Fairness & Robustness,1,Session,True
295,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
296,3 EMPIRICAL EXPLORATION,0,,False
297,"The goal of the exploration we present next is two-fold. First, studying the connection between the regularization of a linear ranking function and the robustness of the rankings it induces to (adversarial) documents' manipulations. According to the formal analysis presented in Section 2.3, the stronger the regularization, the more robust the rankings should be. The second goal is to empirically study Conjecture 1. That is, we explore the connection between the variance of the learned ranking function and ranking robustness using two ranking functions.",1,ad,True
298,3.1 Experimental Setup,0,,False
299,"3.1.1 Dataset. To study the effect of adversarial document manipulations on ranking robustness, we used a recently published dataset that was created as a result of an on-going ranking competition [17]. The dataset is available at https://github.com/asrcdataset/.",1,ad,True
300,"The competition involved 31 repeated matches that lasted for 8 rounds; each match was with respect to a different query. The queries are a subset of TREC 2009-2012 topic titles that have a clear commercial intent and were more likely to stir up the competition. Students in an information retrieval course served as documents' authors. In the first round, in addition to the query itself, students were provided with an example relevant document, and were incentivized by bonus points to the course's grade to modify their documents so as to have them ranked as high as possible in the next round. Thus, the documents' modifications applied by the students can be considered as adversarial. There was no incentive, however, for producing documents relevant to the queries except for some general encouragement. Indeed, the percentage of relevant documents produced was declining throughout the competition [17]. Starting from the second round, students were presented with the ranking as well as the content of all documents submitted in the previous round in the match. To alleviate the task, documents were plain text and their length was restricted to 150 terms. Students had no prior knowledge of the ranking function and all data was anonymized. Statistics of the dataset is provided in Table 1.",1,TREC,True
301,"The ranking function in all matches throughout the competition was based on LambdaMART [27] applied with a subset of the content-based features from Microsoft's learning-to-rank datasets9. In addition, several external modifications were made to ensure high ranking quality. First, each document in the dataset was labeled as valid, keyword stuffed or spam by five Figure Eight (https: //www.figure-eight.com/) annotators. (All annotations are available as part of the dataset.) Documents with at least four non-valid labels were penalized in the ranking. Second, documents similar to the example relevant document were demoted in the ranking. Third, documents were penalized in rankings if their content was duplicated from other documents in the previous round.",1,ad,True
302,"3.1.2 Ranking Functions. The exploration we present uses the documents created in the ranking competition just described. Rather than using the original ranking induced for each query in each round of the competition, we re-rank the documents using the ranking functions we study. One advantage of this practice is that we refrain from infusing noise caused by external interventions as",1,ad,True
303,9 https://tinyurl.com/rmslr,0,,False
304,Table 1: The dataset used for experiments [17].,0,,False
305,Queries Rounds,0,,False
306,31 Queries per student 3 8 Students per query 5 - 6,0,,False
307,Students 52 Unique documents 897,0,,False
308,Documents 1279 Relevant documents 1113,0,,False
309,"those describe above (e.g., penalizing documents whose content was duplicated), and we focus on the ranking functions of interest. Thus, while the ranking functions we study were not exactly those used in the competition, the manipulations of documents were adversarial as the only incentive was to have them ranked high, and the basic ranking function employed in the competition, LambdaMART, is highly effective. In other words, we measure ranking robustness by examining adversarial manipulations of documents introduced in response to a strong ranker.",1,ad,True
310,"We learned two families of ranking functions: RankSVM and LambdaMART. As was the case for the LambdaMART ranker used in the ranking competition, the ClueWeb09 Category B collection, henceforth ClueWeb, was used to train all ranking functions10. Titles of topics 1-200 from TREC 2009-2012 served for queries. We applied Krovetz stemming and removed stopwords on the INQUERY list from queries only. The Indri toolkit11 was used for experiments. To learn the ranking functions, 75% randomly sampled queries served for training and the remaining 25% for validation of hyperparameter values. Once hyper-parameter values were set, either using the procedure just described or to some predefined values as detailed below, all the queries were used to train the final ranking functions. These were then applied to rank documents in each round of the competition for each query. When we present evaluation for ClueWeb, we report the results of using five-fold cross validation. NDCG@20 served as the optimization criterion in all cases.",1,ClueWeb,True
311,"The ranking functions we use are trained with, and applied on, document-query feature vectors composed of 26 content-based features; 25 of these features are those used in the ranking competition [17]. We generated an additional query-independent document quality feature as follows. Instead of directly penalizing non-valid documents as was the case in the competition, we used these annotations to simulate Waterloo's spam classification scores [3]. Specifically, we used 100 - 20(k + s), where k and s are the number of keyword-stuffed and spam labels a document received, respectively; the scores for the example relevant documents were set to 100. Since k +s  5, the simulated scores are in [0, 100] as is the case for Waterloo's scores12. Thus, while the learned ranking function is based on Waterloo's scores, for the competition dataset it is applied with the human-annotation-based score we created which serves as a document quality measure.",1,ad,True
312,3.1.3 Outline of Experiments. The goal of the regularizationbased experiments we report is to study the connection between the regularization of a linear RankSVM and LambdaMART and the robustness and effectiveness of rankings they induce. An additional,1,ad,True
313,10The document collection created in the competition is too small to effectively learn ranking functions. 11 www.lemurproject.org/indri,0,,False
314,12,0,,False
315,"Waterloo's classifier scores represent the percentage of documents in a collection that are ""spammier"" than the given document.",0,,False
316,400,0,,False
317,Session 4A: Fairness & Robustness,1,Session,True
318,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
319,"experiment is intended to contrast the ranking robustness of the two rankers. Hence, we now turn to describe the regularization approaches we have employed for the rankers.",0,,False
320,Regularization of RankSVM. The objective function of RankSVM,0,,False
321,can be expressed using hinge loss:,0,,False
322,"min L(w ; c) d,ef",0,,False
323,w,0,,False
324,1 w 2 2,0,,False
325,+c,0,,False
326,"i, j, t",0,,False
327,"max(0, 1 - w (diqt",0,,False
328,-,0,,False
329,dqj t,0,,False
330,)ldqiqt t,0,,False
331,",",0,,False
332,d,0,,False
333,qt j,0,,False
334,);,0,,False
335,c(>,0,,False
336,0),0,,False
337,is,0,,False
338,a,0,,False
339,regularization parameter; diqt,0,,False
340,and,0,,False
341,d,0,,False
342,qt j,0,,False
343,are,0,,False
344,two,0,,False
345,documents,0,,False
346,"roeftdriiqetviesdhfiogrheqruethryanqtth; aldqtiqtotf,ddjqqjtt",0,,False
347,",1 and",0,,False
348,if the relevance label for qt -1 otherwise. The objective,0,,False
349,function can be re-written as follows [16]:,0,,False
350,min L(w ; ),0,,False
351,w,0,,False
352,",",0,,False
353, ||w ||2 2,0,,False
354,+,0,,False
355,1 n,0,,False
356,"i, j, t",0,,False
357,"max(0, 1 - w (diqt",0,,False
358,-,0,,False
359,dqj t,0,,False
360,)ldqiqt t,0,,False
361,",",0,,False
362,d,0,,False
363,qt j,0,,False
364,);,0,,False
365,n is the number of document pairs across queries used for training;,0,,False
366,c,0,,False
367,",",0,,False
368,1 n,0,,False
369,.,0,,False
370,"Thus,",0,,False
371,the,0,,False
372,lower,0,,False
373,the,0,,False
374,value,0,,False
375,of,0,,False
376,"c,",0,,False
377,the,0,,False
378,higher,0,,False
379,the,0,,False
380,value,0,,False
381,of,0,,False
382,",",0,,False
383,and,0,,False
384,"hence the lower ||w || -- i.e., the regularization is stronger. Indeed,",0,,False
385,lower c corresponds to higher margin of the separating hyperplane,0,,False
386,(,0,,False
387,|,0,,False
388,2 |w,0,,False
389,|,0,,False
390,|,0,,False
391,"),",0,,False
392,and,0,,False
393,therefore,0,,False
394,to,0,,False
395,reduced,0,,False
396,variance,0,,False
397,and,0,,False
398,increased,0,,False
399,bias.,0,,False
400,One of our goals is to study the correlation between ||w || and,0,,False
401,"ranking effectiveness and robustness. To that end, we vary the value",0,,False
402,"of c for learning w , and study the impact on induced rankings. We set c in these experiments to 189 different values in [0, 10000]13. We used SVMr ank 14 to train RankSVM; except for the value of c, all",0,,False
403,"other parameters were set to default values. We found high positive correlation between the value of c and the resultant ||w ||. Herein,",0,,False
404,"correlations are measured using Spearman coefficient, which is an",0,,False
405,"estimate of the monotonic relationship between variables, Pear-",0,,False
406,"son correlation, which is an estimate for linear relationship, and Kendall's- . The values of all three measures are in [-1, 1]: -1 and",0,,False
407,"1 indicate perfect negative and positive correlation, respectively.",0,,False
408,The statistical significance of correlations (with respect to 0) is,0,,False
409,"determined at a 95% confidence level. The Spearman, Pearson and",0,,False
410,"Kendall correlations between c and ||w || are 0.951, 0.448 and 0.867, respectively; all the correlations are statistically significant15.",0,,False
411,"As noted above, in another experiment we performed, we com-",0,,False
412,"pared the robustness of rankings induced by RankSVM and LambdaMART. Here we set c to values in {0.001, 0.01, 0.1} using the",0,,False
413,75-25 split for queries over ClueWeb described above. Recall that,1,ClueWeb,True
414,NDCG@20 was the optimization criterion. The ranking compe-,0,,False
415,tition did not have enough rounds so as to optimize directly for,0,,False
416,"robustness and then test it. Hence, we optimized for ranking ef-",0,,False
417,"fectiveness and evaluated the effect on robustness. We hasten to point out, however, that these values of c resulted in high ranking",0,,False
418,robustness. We describe below how we measured robustness.,0,,False
419,"Regularization of LambdaMART. LambdaMART uses gradient boosted regression trees. The higher the number of trees and leaves, the lower the regularization, and the higher the variance.",1,ad,True
420,13,0,,False
421,Random,0,,False
422,sampling,0,,False
423,of,0,,False
424,the,0,,False
425,value,0,,False
426,of,0,,False
427,c,0,,False
428,results,0,,False
429,in,0,,False
430,a,0,,False
431,very,0,,False
432,short,0,,False
433,range,0,,False
434,of,0,,False
435,values,0,,False
436,of,0,,False
437,|,0,,False
438,|w,0,,False
439,|,0,,False
440,|.,0,,False
441,"Hence, we sampled from [10x , 9 ·10x ] with steps of size 10x for x  {-4, -3, . . . , 2}.",0,,False
442,"We sampled from [1000, 10000] with steps of 1000. We further sampled 60 values uni-",0,,False
443,"formly from [0, 10000]; in addition, we used values in {1, 40, 80, 120, 160, . . . , 1000}",1,ad,True
444,"and {1, 45, 90, 135, 180, . . . , 1125}.",0,,False
445,14 https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html,0,,False
446,15We consider only values of c for which | |w | | < 15. See Section 3.2.1 for details.,0,,False
447,"We used RankLib's16 implementation of LambdaMART. To study the connection between the regularization of LambdaMART and the effectiveness and robustness of rankings it induces, we set (#leaves, #trees) to values in {(5, 150), (10, 160), (15, 170), . . . , (150, 440)}.",0,,False
448,"To compare the ranking robustness of LambdaMART with that of RankSVM, we set the number of leaves and trees to values in {250, 500} and {25, 50}, respectively, using the 75-25 split mentioned above. These values resulted in high ranking robustness. We now turn to describe how ranking robustness was evaluated.",0,,False
449,"3.1.4 Evaluating Ranking Robustness. Suppose that at round i of the competition for query q the set of documents created by the students is S. Now, we rank S using a ranking function to produce a ranked list Li . Then, we consider the set of documents created by the same students in round i + 1 of the competition for query q. Ranking this set yields the list Li+1. We can then apply upon Li and Li+1 each of the ranking-robustness measures we described in Section 2.5. For each query, we average these values over pairs of rounds i, i + 1; we then average the resultant values over queries. Thus, for each ranking function and robustness measure we get a single ranking robustness value.",1,Robust,True
450,"Accordingly, we can measure the correlation between the regularization strength of RankSVM (as manifested in different values of ||w ||) and ranking robustness; and, between LambdaMART's regularization strength (with (#leaves, #trees) serving as a proxy) and its ranking robustness. As at the above, we use Spearman, Pearson and Kendall's- to measure correlations. Then, to contrast the ranking robustness of RankSVM and LambdaMART, we compare the values of the robustness measures. Statistically significant differences of retrieval performance and of values assigned by robustness measures are determined using the two-tailed paired t-test at a 95% confidence level. Recall that the robustness measure value for each query is the average over pairs of consecutive rounds. These values are compared for statistical significance over queries.",0,,False
451,"3.1.5 Evaluating Ranking Effectiveness. All documents in the competition were judged for relevance via Figure Eight by five annotators [17]. The relevance judgments are available as part of the dataset. Here, we consider a document relevant if it was labeled as such by at least three annotators. To estimate retrieval effectiveness we use MAP (mean average precision) and NDCG (normalized discounted cumulative gain) at cutoff 5; this is the number of students that participated in a competition per query17.",1,MAP,True
452,"We also evaluate retrieval effectiveness over ClueWeb. In this case, MAP was computed for the top 1000 retrieved documents and NDCG for the top 20; the latter also served as the optimization metric for training LambdaMART.",1,ClueWeb,True
453,3.2 Experimental Results,0,,False
454,"3.2.1 Ranking Robustness of RankSVM. In Figure 1 we present the values of the (unnormalized) robustness measures as a function of ||w || in RankSVM. Recall that high values of KT and TC attest to decreased ranking robustness, as these are measures of inter-list",1,Robust,True
455,16,0,,False
456,"https://tinyurl.com/ranklib 17To generate graded relevance judgments we followed Raifer at al. [17]: documents labeled relevant by 3, 4 and 5 annotators were considered marginally relevant, fairly relevant, and highly relevant, respectively; documents with at most 2 relevant labels were considered non-relevant.",1,ad,True
457,401,0,,False
458,Session 4A: Fairness & Robustness,1,Session,True
459,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
460,KT TC,0,,False
461,RBO,0,,False
462,0.28 0.27 0.26 0.25 0.24 0.23 0.22 0.21,0,,False
463,0,0,,False
464,5,0,,False
465,10,0,,False
466,15,0,,False
467,20,0,,False
468,||w||,0,,False
469,0.74 0.73 0.72 0.71 0.70 0.69 0.68 0.67,0,,False
470,0,0,,False
471,5,0,,False
472,10,0,,False
473,15,0,,False
474,20,0,,False
475,||w||,0,,False
476,0.50 0.48 0.46 0.44 0.42 0.40 0.38 0.36,0,,False
477,0,0,,False
478,5,0,,False
479,10,0,,False
480,15,0,,False
481,20,0,,False
482,||w||,0,,False
483,Figure 1: Robustness per ||w || in RankSVM.,1,Robust,True
484,"Table 2: The correlation between ||w || and robustness measures' values for RankSVM. 'S', 'P' and 'K' stand for Spearman, Pearson and Kendall, respectively. `': the correlation is statistically significant.",0,,False
485,KT KT-sum KT-diff KT-rel RBO TC TC-sum TC-diff TC-rel,0,,False
486,S .748 .745 P .889 .872 K .574 .560,0,,False
487,.678 .737 -.756 .528 .574 .850 .875 -.841 .567 .632 .509 .562 -.558 .374 .413,0,,False
488,.475 .591 .483 .656 .336 .427,0,,False
489,"distance, and high values of RBO attest to increased robustness as this is an inter-list similarity measure. We see that increasing ||w ||, which means weaker regularization, results in decreased ranking",0,,False
490,robustness when measured using KT and RBO. (The differences,0,,False
491,with TC are discussed below.) This finding is aligned with our,0,,False
492,formal analysis of linear ranking functions in Section 2.,0,,False
493,"To compute correlations between ranking robustness measures and ||w ||, we first observe the following in Figure 1. Our sampling of values of c, the regularization parameter in RankSVM, resulted in over-sampling of ||w || values somewhat larger than ||w || ,"" 15. This can substantially affect correlation values. Hence, for the correlation""",0,,False
494,"analysis to follow, and for studying RankSVM's ranking effectiveness as a function of ||w ||, we do not consider RankSVM functions with ||w ||  15. The resulting sample contains 71 RankSVM functions. We hasten to point out that this sampling did not change the",0,,False
495,"polarity of the correlations we found, nor their statistical significance, but only the actual correlation numbers which increased18.",0,,False
496,"Table 2 presents the correlation between ||w || and the values of all ranking-robustness measures. As can be seen, there are high, statistically significant, correlations between ||w || and the values of all robustness measures for all three correlation metrics (Spearman, Pearson and Kendall)19. Thus, the findings in Table 2 provide sup-",0,,False
497,port to our formal analysis with respect to linear ranking functions,0,,False
498,18,0,,False
499,For,0,,False
500,"example,",0,,False
501,without,0,,False
502,removing,0,,False
503,models,0,,False
504,with,0,,False
505,| |w,0,,False
506,||,0,,False
507,"15,",0,,False
508,the,0,,False
509,Spearman,0,,False
510,correlation,0,,False
511,"for KT, RBO and TC is: .33, -.466 and .284, respectively; Pearson correlation is",0,,False
512,".806, -.780, and .503, respectively; Kendall's- numbers are: .246, -.343, and .217,",0,,False
513,respectively. All correlations are statistically significant.,0,,False
514,19,0,,False
515,"Recall that RBO is an inter-list similarity measure, in contrast to the other two; hence",0,,False
516,increasing values of RBO attest to increased robustness.,0,,False
517,"Table 3: The correlation between #leaves and #trees in LambdaMART and the values of the robustness measures. 'S', 'P' and 'K' stand for Spearman, Pearson and Kendall, respectively. `': the correlation is statistically significant.",0,,False
518,KT KT-sum KT-diff KT-rel RBO TC TC-sum TC-diff TC-rel,0,,False
519,S .725 .733 P .674 .714 K .549 .568,0,,False
520,.754 .727 -.600 .506 .521 .728 .732 -.615 .525 .530 .609 .563 -.453 .366 .366,0,,False
521,.507 .547 .568 .577 .379 .398,0,,False
522,"-- RankSVM in this case: stronger regularization (decreased ||w ||) results in increased ranking robustness. This also provides support to our variance conjecture (Conjecture 1): increased ||w || means higher variance; thus, higher variance is indeed correlated with decreased ranking robustness for RankSVM.",0,,False
523,"In comparing the normalized robustness measures in Table 2 (X-sum, X-diff and X-rel measures) with their unnormalized counterparts we see the following. For KT, the normalized versions yield minor to moderate decrease of correlation with ||w ||, although the correlations remain statistically significant and high. Similarly, TCdiff yields lower correlation than TC. However, TC-sum and TC-rel yield higher correlations than TC.",0,,False
524,"Table 2 also shows that in almost all cases, KT-rel yields higher correlation than KT-sum and KT-diff, and TC-rel yields higher correlation than TC-sum and TC-diff. Recall from Section 2.5 that the X-rel measures use for normalization the norm of the difference between the vector change of one document and that of the other. This norm is ||v2 - v1|| used in the upper bound for simultaneous pairwise stability of a linear ranking function in Equation 1.",0,,False
525,"Finally, Table 2 shows that KT and its normalized variants, and RBO, yield higher correlation than TC and its variants. This is not a surprise as KT and RBO consider changes in the entire document list, while TC only considers changes at the highest rank; thus, TC is a less robust measure of ranking robustness. (These findings are aligned with the patterns observed in Figure 1.) We also see that RBO yields lower Pearson and Kendall correlation than KT. RBO attributes more weight to swaps of documents at high ranks and KT does not. However, the document lists are short (composed of 5 documents); hence, the differences in correlations potentially should not be attributed to different weighting of different ranks.",0,,False
526,"3.2.2 Ranking Robustness of LambdaMART. Table 3 shows the correlations between the number of leaves (#leaves) and trees (#trees) used to train LambdaMART, which were increased simultaneously, and the resulting values of ranking robustness. This increase corresponds to decreased regularization; i.e., higher variance. Indeed, Table 3 shows that according to all three correlation metrics and for all three ranking-robustness measures, robustness decreases with decreased regularization. This finding provides further support to our variance conjecture (Conjecture 1): ranking functions with higher variance yield rankings of decreased robustness. Thus, we attained support for the conjecture for two different rankers: the first is linear (RankSVM) and the second is not (LambdaMART).",1,Robust,True
527,Table 3 also shows that KT yields higher correlation than RBO which in turn yields higher correlation than TC. These findings are aligned with those presented above for RankSVM. We also,0,,False
528,402,0,,False
529,Session 4A: Fairness & Robustness,1,Session,True
530,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
531,Table 4: Comparison of RankSVM and LambdaMART in terms of ranking robustness and effectiveness. The numbers in parentheses indicate the percentage of queries for which the robustness number attained for one ranking function is higher than that attained for the other. Percentages do not necessarily sum to 100 due to ties and rounding. `' marks statistically significant differences with LambdaMART. Bonferroni correction was applied for robustness comparisons.,0,,False
532,KT TC RBO TC-diff TC-rel TC-sum KT-diff KT-rel KT-sum MAP NDCG,1,MAP,True
533,LambdaMART,0,,False
534,0.343 (54.8) 0.599 (30.9) 0.613 (26.3) 0.361 (53.5) 0.246 (50.7) 0.213 (51.6) 2.071 (62.7) 1.399 (63.6) 1.204 (60.8) 0.825 (16.5) 0.837 (26.7),0,,False
535,RankSVM,0,,False
536,0.264 (27.2) 0.401 (11.1) 0.703 (60.8) 0.219 (28.6) 0.153 (31.3) 0.133 (30.4) 1.505 (31.8) 1.008 (30.9) 0.874 (33.6),0,,False
537,0.846 (22.7),0,,False
538,0.854 (37.5),0,,False
539,"see that the normalized versions of KT and TC (KT-X and TCX) yield increased correlations with respect to the unnormalized versions (KT and TC). This finding implies here to the importance of accounting not only for the change of ranking, but also for the change in documents that drove the change in ranking when measuring ranking robustness. Finally, we see that for TC, the normalized version TC-rel yields the highest correlations which is aligned with the findings above for both TC and KT. However, for KT here, KT-rel does not dominate KT-sum and KT-diff.",0,,False
540,"3.2.3 Comparing RankSVM and LambdaMART. In Table 4 we contrast the robustness and effectiveness of rankings induced by RankSVM and LambdaMART over the ranking-competition dataset. Recall that RBO measures the similarity between two lists, hence higher values attest to higher robustness. In contrast, KT and its normalized variants as well as TC and its normalized variants measure the differences between two lists; hence, lower values attest to higher robustness. We see that the ranked lists induced by RankSVM are (on average) more robust than those induced using LambdaMART according to all considered ranking-robustness measures; all the differences are statistically significant. Furthermore, the robustness of lists induced by RankSVM surpasses that of lists induced by LambdaMART for the majority of queries. (Refer to the numbers in parentheses.) These findings provide additional support to our variance conjecture. Since RankSVM is linear and LambdaMART is not, the variance of RankSVM is in general lower, and we saw that its ranking robustness is higher.",1,ad,True
541,"In the last two lines of Table 4 we compare the retrieval effectiveness of RankSVM and LambdaMART. Although the differences are not statistically significant, we see that lists induced by RankSVM are not only more robust but also somewhat more effective compared to LambdaMART on the competition dataset. The high MAP and NDCG values can be attributed to the fact that most documents generated by the students were judged to be relevant. (See Table 1.)",1,MAP,True
542,MAP NDCG,1,MAP,True
543,Table 5: Correlation between regularization of RankSVM (||w ||) and that of LambdaMART (#leaves and #trees) and re-,0,,False
544,trieval effectiveness. Competition: Raifer et al.'s dataset [17]. `': the correlation is statistically significant.,0,,False
545,RankSVM LambdaMART,0,,False
546,Spearman Pearson Kendall,0,,False
547,Competition ClueWeb,1,ClueWeb,True
548,MAP NDCG MAP NDCG,1,MAP,True
549,-.777 -.787,0,,False
550,.220 .259,0,,False
551,-.918 -.897,0,,False
552,.549 .636,0,,False
553,-.559 -.564,0,,False
554,.079,0,,False
555,.141,0,,False
556,MAP Competition,1,MAP,True
557,NDCG,0,,False
558,ClueWeb,1,ClueWeb,True
559,MAP NDCG,1,MAP,True
560,-.732 -.726 -.849 -.804,0,,False
561,-.732 -.710 -.871 -.812,0,,False
562,-.549 -.545 -.692 -.635,0,,False
563,0.27 0.26 0.25 0.24 0.23 0.22 0.21,0,,False
564,0,0,,False
565,5,0,,False
566,10,0,,False
567,15,0,,False
568,20,0,,False
569,||w||,0,,False
570,0.32 0.30 0.28 0.26 0.24,0,,False
571,0,0,,False
572,5,0,,False
573,10,0,,False
574,15,0,,False
575,20,0,,False
576,||w||,0,,False
577,Figure 2: The connection between ||w || and retrieval effectiveness (MAP and NDCG) on ClueWeb of RankSVM.,1,MAP,True
578,"3.2.4 Regularization and Retrieval Effectiveness. Table 5 presents the correlation between retrieval effectiveness (MAP and NDCG) and regularization for RankSVM (||w ||) and LambdaMART (#leaves and #trees). As most documents in the ranking-competition dataset are relevant, we also analyze retrieval performance for ClueWeb that has a much higher percentage of non-relevant documents.",1,MAP,True
579,"Table 5 shows that except for the case of RankSVM over ClueWeb, there is high statistically significant positive correlation between increased regularization and retrieval effectiveness. (Decreasing ||w || and #leaves, #trees amounts to increased regularization.) Figure 2, which presents the connection between MAP/NDCG and ||w || of RankSVM on ClueWeb, shows a positive trend for ||w ||  5 and a negative trend for ||w ||  5. Substantially increasing (decreasing) ||w || can result in overfitting (underfitting). Thus, the correlations for RankSVM in Table 5 seem to be quite affected by a long range of underfitting which results in decreased retrieval performance; increasing ||w || then reduces underfitting and improves performance until the ranker overfits. In Figure 3 we see that, in general, decreased regularization of LambdaMART (i.e., higher number of leaves and trees) results in decreased MAP performance over ClueWeb. This finding is aligned with those that emerge based on Table 5.",1,ClueWeb,True
580,4 RELATED WORK,0,,False
581,There are notions of robustness of ad hoc retrieval functions different than that we examine here: the performance variance over queries [23] and the relative performance over queries with respect to another ranking function [24]. We study changes to rankings that result from documents' (adversarial) manipulations.,1,ad,True
582,403,0,,False
583,MAP MAP,1,MAP,True
584,Session 4A: Fairness & Robustness,1,Session,True
585,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
586,0.245 0.240 0.235 0.230 0.225 0.220 0.215 0.210 0.205 0.200,0,,False
587,0,0,,False
588,20 40 60 80 100 120 140 160 #leaves,0,,False
589,0.245 0.240 0.235 0.230 0.225 0.220 0.215 0.210 0.205 0.200,0,,False
590,0,0,,False
591,100,0,,False
592,200,0,,False
593,300,0,,False
594,400,0,,False
595,500,0,,False
596,#trees,0,,False
597,Figure 3: The connection between #leaves and #trees used in LambdaMART and its MAP effectiveness over ClueWeb.,1,MAP,True
598,The changes of a ranked document list that result from synthetic random noise introduced to documents were used to predict query performance [28]. We address a different setting -- adversarial document changes intended to promote documents in rankings -- and present a different analysis.,1,ad,True
599,"Much of the work on adversarial information retrieval focuses on identifying and addressing different types of spam (e.g., contentbased and hyperlink-based) [1, 2]. In contrast to our work, there was no formal and empirical analysis of ranking robustness with respect to (adversarial) documents' manipulations.",1,ad,True
600,"Recent work analyzes the strategies employed by documents' authors in ranking competitions [17]. In contrast, we analyze the robustness of ranking functions. We use the datasets of ranking competitions organized in this work [17] in our empirical analysis.",0,,False
601,"The probability ranking principle [18] was shown to be suboptimal in competitive retrieval settings, where authors manipulate their documents so as to have them highly ranked. However, the robustness of ranking functions was not studied as in our work.",0,,False
602,"There is a growing body of work on adversarial and robust classification; e.g., [4, 6­10, 14, 20, 21, 25]. The focus is on improving classifier's robustness to adversarial (often, minuscule) manipulations of objects and their feature values. In contrast to our work, the robustness of document ranking functions was not studied; specifically, the pairwise robustness notions we analyze, which are a core aspect of ranking robustness, were not studied.",1,ad,True
603,"The connection between neural network regularization and the stability of classification decisions has recently been demonstrated [20]. We demonstrate the connection between regularization of linear ranking functions and stability of retrieval scores, and more importantly, ranking robustness.",0,,False
604,5 CONCLUSIONS AND FUTURE WORK,0,,False
605,"We presented a formal and empirical analysis of the robustness of rankings induced by feature-based relevance-ranking functions to (adversarial) manipulations of documents. We formally showed that increased regularization of linear ranking functions results in increased ranking robustness. Accordingly, we conjectured that increased variance of any learned ranking function results in decreased ranking robustness. We provided empirical support to our formal findings and the conjecture by analyzing ranking competitions where authors introduced adversarial changes to documents.",1,ad,True
606,"We plan to further study and improve the robustness of nonlinear learning-to-rank functions. We also intend to extend the robustness analysis to sets of queries; e.g., those representing the same information needs.",0,,False
607,Acknowledgments We thank the reviewers for their comments.,0,,False
608,This work was supported by funding from the European Research,0,,False
609,Council (ERC) under the European Union's Horizon 2020 research,0,,False
610,and innovation programme (grant agreement 740435).,0,,False
611,REFERENCES,0,,False
612,[1] 2005­2009. AIRWeb -- International Workshop on Adversarial Information Retrieval on the Web.,0,,False
613,"[2] Carlos Castillo and Brian D. Davison. 2010. Adversarial Web Search. Foundations and Trends in Information Retrieval 4, 5 (2010), 377­486.",0,,False
614,"[3] Gordon V. Cormack, Mark D. Smucker, and Charles L. A. Clarke. 2011. Efficient and effective spam filtering and re-ranking for large web datasets. Informaltiom Retrieval Journal 14, 5 (2011), 441­465.",0,,False
615,"[4] Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai, and Deepak Verma. 2004. Adversarial Classification. In Proc. of KDD. 99­108.",0,,False
616,"[5] Fernando Diaz. 2007. Regularizing query-based retrieval scores. Information Retrieval 10, 6 (2007), 531­562.",0,,False
617,"[6] Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2015. Analysis of classifiers' robustness to adversarial perturbations. CoRR abs/1502.02590 (2015).",1,ad,True
618,"[7] Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. 2016. Robustness of classifiers: from adversarial to random noise. In Proc. of NIPS. 1624­1632.",1,Robust,True
619,"[8] Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. 2017. The Robustness of Deep Networks: A Geometrical Perspective. IEEE Signal Processing Magazine 34, 6 (2017), 50­62.",1,Robust,True
620,[9] Amir Globerson and Sam T. Roweis. 2006. Nightmare at test time: robust learning by feature deletion. In Proc. of ICML. 353­360.,0,,False
621,"[10] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In Proc. of ICLR.",0,,False
622,[11] Zoltán Gyöngyi and Hector Garcia-Molina. 2005. Web Spam Taxonomy. In Proc. of AIRWeb 2005. 39­47.,0,,False
623,[12] Thorsten Joachims. 2006. Training linear SVMs in linear time. In Proc. of KDD. 217­226.,0,,False
624,"[13] Tie-Yan Liu. 2011. Learning to Rank for Information Retrieval. Springer. I­XVII, 1­285 pages.",0,,False
625,[14] Daniel Lowd and Christopher Meek. 2005. Adversarial Learning. In Proc. of SIGKDD. 641­647.,0,,False
626,"[15] Donald Metzler and W. Bruce Croft. 2007. Linear feature-based models for information retrieval. Information Retrieval 10, 3 (2007), 257­274.",0,,False
627,[16] Constantinos Panagiotakopoulos and Petroula Tsampouka. 2013. The Stochastic Gradient Descent for the Primal L1-SVM Optimization Revisited. In Proc. of ECML PKDD. 65­80.,1,ad,True
628,"[17] Nimrod Raifer, Fiana Raiber, Moshe Tennenholtz, and Oren Kurland. 2017. In-",0,,False
629,"formation Retrieval Meets Game Theory: The Ranking Competition Between Documents' Authors. In Proc. of SIGIR. 465­474. [18] Stephen E. Robertson. 1977. The Probability Ranking Principle in IR. Journal of Documentation (1977), 294­304. Reprinted in K. Sparck Jones and P. Willett (eds), Readings in Information Retrieval, pp. 281­286, 1997. [19] Grace S.Shieh. 1998. A weighted Kendall's tau statistic. Statistics & Probability Letters 39, 1 (1998). [20] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,",1,ad,True
630,"Ian J. Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks. In Proc. of ICLR. [21] Thomas Tanay and Lewis D. Griffin. 2016. A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples. CoRR abs/1608.07690 (2016). [22] C. J. van Rijsbergen. 1979. Information Retrieval (second ed.). Butterworths. [23] Ellen M. Voorhees. 2004. Overview of the TREC 2004 Robust Retrieval Track. In Proc. of TREC. [24] Lidan Wang, Paul N. Bennett, and Kevyn Collins-Thompson. 2012. Robust ranking models via risk-sensitive optimization. In Proc. of SIGIR. 761­770. [25] Yizhen Wang, Somesh Jha, and Kamalika Chaudhuri. 2017. Analyzing the Robustness of Nearest Neighbors to Adversarial Examples. CoRR abs/1706.03922 (2017).",1,TREC,True
631,"[26] William Webber, Alistair Moffat, and Justin Zobel. 2010. A Similarity Measure for Indefinite Rankings. ACM Transactions on Information Systems 28, 4 (2010), 20:1­20:38.",0,,False
632,"[27] Qiang Wu, Christopher J. C. Burges, Krysta Marie Svore, and Jianfeng Gao. 2010. Adapting boosting for information retrieval measures. Information Retrieval 13, 3 (2010), 254­270.",0,,False
633,[28] Yun Zhou and Bruce Croft. 2006. Ranking robustness: a novel framework to predict query performance. In Proc. of CIKM. 567­574.,0,,False
634,404,0,,False
635,,0,,False
