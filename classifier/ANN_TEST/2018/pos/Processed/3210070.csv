,sentence,label,data,regex
0,Short Research Papers I,0,,False
1,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
2,ery Performance Prediction using Passage Information,0,,False
3,Haggai Roitman,0,,False
4,"IBM Research AI Haifa, Israel",0,,False
5,haggai@il.ibm.com,0,,False
6,ABSTRACT,0,,False
7,2 RELATED WORK,0,,False
8,"We focus on the post-retrieval query performance prediction (QPP) task. Speci cally, we make a new use of passage information for this task. Using such information we derive a new mean score calibration predictor that provides a more accurate prediction. Using an empirical evaluation over several common TREC benchmarks, we show that, QPP methods that only make use of document-level features are mostly suited for short query prediction tasks; while such methods perform signi cantly worse in verbose query prediction settings. We further demonstrate that, QPP methods that utilize passage-information are much better suited for verbose settings. Moreover, our proposed predictor, which utilizes both documentlevel and passage-level features provides a more accurate and consistent prediction for both types of queries. Finally, we show a connection between our predictor and a recently proposed supervised QPP method, which results in an enhanced prediction.",1,TREC,True
9,1 INTRODUCTION,1,DUC,True
10,"We focus on the post-retrieval query performance prediction (QPP) task [4]. Given a query, a corpus and a retrieval method that evaluates the query, our goal is to predict the query's performance based on its retrieved result list [4].",0,,False
11,"Motivated by previous works on document retrieval using passage information [1­3], we propose to use such information for the post-retrieval QPP task as well. To this end, we extend Kurland et al.'s probabilistic QPP framework [10] and show how passage information may be utilized for an enhanced prediction.",0,,False
12,"Using an evaluation with several TREC corpora, we rst demonstrate that, existing state-of-the-art document-level post retrieval QPP methods, are mostly suited for prediction tasks that involve short (and probably more ambiguous) queries; whereas such methods are less suited for prediction tasks that involve verbose (long and probably more informative) queries. We next demonstrate that, our proposed QPP method which makes use of passage information provides a more robust prediction, regardless of query type. We further set a direct connection with Roitman et al.'s mean retrieval score estimation framework [12]. Moreover, by integrating our proposed passage-information QPP signal as an additional calibration feature within Roitman et al.'s framework [12], we are able to achieve the overall best QPP accuracy.",1,TREC,True
13,"The query performance prediction task has been extensively studied, where two main approaches have been proposed, either preretrieval or post-retrieval prediction [4]. Yet, most of previous QPP research has focused on ad-hoc retrieval prediction tasks that involved short (keyword-based) queries [4]. In this work, we further study QPP in cases with verbose (long) queries [8].",1,ad-hoc,True
14,"Passage information has been shown to assist in ad-hoc document retrieval [2, 3] and verbose query evaluation tasks [1]. Motivated by these previous works, in this work, we rely on passage information as a strong evidence source for query performance. A couple of previous works [6, 9] have predicted the outcome of passage retrieval for question answering tasks. Yet, as we shall later show, predictors that were suggested for the passage retrieval QPP task are less suited for the document retrieval QPP task.",1,ad-hoc,True
15,"Our work extends Kurland et al.'s [10] probabilistic QPP framework with passage information. Finally, Roitman et al. [12] have recently proposed an extension to [10], where the authors derived a generic calibrated (discriminative) mean retrieval score estimator for post-retrieval QPP tasks. Using their proposed predictor (dubbed WPM2), the authors achieved the best reported QPP accuracy [12]. In this work, we further show a connection between our proposed passage-based QPP method and Roitman et al.'s [12] framework, where we utilize it to provide overall better prediction.",0,,False
16,3 FRAMEWORK,0,,False
17,3.1 Preliminaries,0,,False
18,"Let q denote a query and let C denote a corpus on which the query is evaluated. For a given text x (e.g., a document d  C or a passage",0,,False
19," d), let sq (x) denote the (retrieval) score assigned to x given q. In this work, we estimate each query q's performance using a post-retrieval approach [4]. Accordingly, let D denote the top-k documents in C with the highest retrieval score sq (d) as determined by the underlying retrieval method. The post-retrieval QPP task is to estimate p(D|q, r ) ­ the likelihood that D contains relevant information to query q [4].",0,,False
20,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org.",1,ad,True
21,"SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA",0,,False
22,© 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00 https://doi.org/10.1145/3209978.3210070,0,,False
23,3.2 QPP using passage information,0,,False
24,"Our goal is to predict a given query q's performance as accurate as possible. To this end, we propose to utilize passage information extracted from documents in D as an additional source for QPP. Our main hypothesis is that, relevant passage information obtained in D may provide valuable evidence whether a given retrieval was (overall) e ective or not.",1,ad,True
25,893,0,,False
26,Short Research Papers I,0,,False
27,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
28,Our prediction framework is built on top of Kurland et al.'s [10],0,,False
29,"probabilistic QPP framework. According to [10], p(D|q, r ) may be estimated1 as follows:",0,,False
30,p^d,0,,False
31,oc,0,,False
32,(D,0,,False
33,"|q,",0,,False
34,r,0,,False
35,),0,,False
36,def,0,,False
37,",",0,,False
38,"p(D|d, r )p(d |q, r ).",0,,False
39,(1),0,,False
40,d D,0,,False
41,"p(d |q, r ) denotes document d's likelihood of being a relevant re-",0,,False
42,"sponse to query q. p(D|d, r ) denotes the likelihood that such rele-",0,,False
43,"vant response will be further included in D, which we assume in",0,,False
44,"this work to be uniformly distributed. Applying this assumption,",0,,False
45,our QPP estimator can be de ned as follows:,0,,False
46,p^ps,0,,False
47,(D,0,,False
48,"|q,",0,,False
49,r,0,,False
50,),0,,False
51,def,0,,False
52,",",0,,False
53,"p(d |q, r ).",0,,False
54,(2),0,,False
55,d D,0,,False
56,"We next show how p^ps (D|q, r ) can be estimated using passage-",0,,False
57,"information. As a rst step, we note that:",0,,False
58,p(d,0,,False
59,"|q,",0,,False
60,r,0,,False
61,),0,,False
62,def,0,,False
63,",",0,,False
64,"p(q|d, r )p(r |d)p(d) p(r |q)p(q) .",0,,False
65,(3),0,,False
66,"The term p(r |d) denotes the likelihood that document d contains relevant information regardless of any speci c query. Using a MaxPs estimation approach [2], we now estimate this term as follows:",0,,False
67,p^(r,0,,False
68,|d ),0,,False
69,def,0,,False
70,",",0,,False
71,max sq (,0,,False
72,)p(r |,0,,False
73,)p(,0,,False
74,|d ).,0,,False
75,(4),0,,False
76,d,0,,False
77,sq ( ) is the query score assigned to passage ( d). p(r | ) represents the likelihood that passage contains relevant information.,0,,False
78,We estimate this term as a combination of two sub-terms as fol-,0,,False
79,lows:,0,,False
80,p^(r |,0,,False
81,),0,,False
82,def,0,,False
83,",",0,,False
84,H(,0,,False
85,) · posBias(,0,,False
86,).,0,,False
87,def,0,,False
88,"H( ) , -",0,,False
89,p(w | ) log p(w | ) is the entropy of passage 's,0,,False
90,w,0,,False
91,unsmoothed language model ­ preferring more diverse passages.,0,,False
92,posBias(,0,,False
93,),0,,False
94,def,0,,False
95,",",0,,False
96,1+,0,,False
97,1 log(2+,0,,False
98,".s) , where",0,,False
99,.s denotes the start position,0,,False
100,(in character o sets) of passage within its containing document.,0,,False
101,"Hence, posBias( ) prefers passages that are located as earlier as",0,,False
102,possible within their containing documents.,0,,False
103,p( |d) in Eq. 4 further captures the relationship between passage,0,,False
104,"and its containing document d, estimated as the Bhattacharyya",0,,False
105,similarity between their unsmoothed language models:,0,,False
106,p^(,0,,False
107,|d ),0,,False
108,def,0,,False
109,",",0,,False
110,p(w | )p(w |d).,0,,False
111,w,0,,False
112,We,0,,False
113,next,0,,False
114,assume,0,,False
115,"that,",0,,False
116,p(q),0,,False
117,is,0,,False
118,uniformly,0,,False
119,distributed;,0,,False
120,p (d ),0,,False
121,def,0,,False
122,",",0,,False
123,1 |D |,0,,False
124,is uniformly distributed over D;,0,,False
125,and,0,,False
126,sq,0,,False
127,(d,0,,False
128,),0,,False
129,def,0,,False
130,",",0,,False
131,"p(q|d, r ).",0,,False
132,Applying these assumptions back into Eq. 3 and using our deriva-,0,,False
133,"tion of p^(r |d) according to Eq. 4, we obtain our new estimator ac-",0,,False
134,cording to Eq. 2 as follows:,0,,False
135,p^ps,0,,False
136,(D,0,,False
137,"|q,",0,,False
138,r,0,,False
139,),0,,False
140,def,0,,False
141,",",0,,False
142,1 |D|,0,,False
143,max sq ( )p^(r | )p^( |d),0,,False
144,d,0,,False
145,sq (d) ·,0,,False
146,p(r |q),0,,False
147,. (5),0,,False
148,d D,0,,False
149,1See Eq. 3 in [10].,0,,False
150,"Finally, we note that, similarly to many post-retrieval predic-",0,,False
151,"tors [4], p(r |q) is a query-sensitive normalization term, estimated",0,,False
152,in,0,,False
153,this,0,,False
154,work,0,,False
155,according,0,,False
156,to,0,,False
157,q's,0,,False
158,length:,0,,False
159,p^(r,0,,False
160,|q),0,,False
161,def,0,,False
162,",",0,,False
163,|q |.,0,,False
164,3.3 Connection with the WPM method,0,,False
165,"We conclude this section by showing that our proposed passageenhanced QPP method shares direct connection with the recently proposed mean retrieval score estimation framework of Roitman et al. [12]. According to [12], many previous post-retrieval predictors (e.g., Clarity [5], WIG [15], etc) share the following general form:",1,WIG,True
166,p^(D,0,,False
167,"|q,",0,,False
168,r,0,,False
169,),0,,False
170,def,0,,False
171,",",0,,False
172,1 |D|,0,,False
173,d D,0,,False
174,sq (d),0,,False
175,·,0,,False
176,"r , F",0,,False
177,"(d ),",0,,False
178,"where r, F (d)",0,,False
179,def,0,,False
180,",",0,,False
181,fj (d) j is a Weighted Product Model,0,,False
182,j,0,,False
183,discriminative calibrator; with fj (d) is some retrieval feature and,0,,False
184,j  0 denotes its relative importance [12].,0,,False
185,"According to Eq. 5, our predictor is essentially a calibrated mean",0,,False
186,retrieval estimator [12]; Our predictor utilizes two calibration fea-,0,,False
187,"tures, namely",0,,False
188,f1 (d ),0,,False
189,", p^(r |d) (see Eq. 4) and",0,,False
190,f2 (d ),0,,False
191,",",0,,False
192,1 p^(r |q),0,,False
193,;,0,,False
194,both,0,,False
195,"features are assigned with equal weights of 1 , 2 , 1. Using this",0,,False
196,"connection in mind, we make two important observations. First,",0,,False
197,"by calibrating the two feature weights i ; i  {1, 2}, we might improve our own predictor's performance [12]. Second, we can utilize",0,,False
198,"f1(d) as a new passage-based calibration feature within Roitman et al.'s [12] QPP framework. As we shall shortly demonstrate, such",0,,False
199,an extension indeed signi cantly boosts prediction performance;,0,,False
200,even in cases where the prediction quality was already relatively,1,ad,True
201,high.,0,,False
202,4 EVALUATION 4.1 Datasets,0,,False
203,Corpus #documents,0,,False
204,Queries,0,,False
205,Disks,0,,False
206,TREC5,1,TREC,True
207,"524,929",0,,False
208,251-300,0,,False
209,2&4,0,,False
210,WSJ,0,,False
211,"173,252",0,,False
212,151-200,0,,False
213,1-2,0,,False
214,AP,1,AP,True
215,"242,918",0,,False
216,51-150,0,,False
217,1-3,0,,False
218,"ROBUST 528,155 301-450, 601-700 4&5-{CR}",0,,False
219,"WT10g 1,692,096",1,WT,True
220,451-550,0,,False
221,WT10g,1,WT,True
222,"GOV2 25,205,179",0,,False
223,701-850,0,,False
224,GOV2,0,,False
225,Table 1: Summary of TREC benchmarks.,1,TREC,True
226,"The details of the TREC corpora and queries that we used for the evaluation are summarized in Table 1. These benchmarks were used by many previous QPP works [4, 12]. We evaluated two main types of queries, namely: short (keyword) queries and verbose queries. To this end, for short queries evaluation, we used the titles of TREC topics. For verbose queries evaluation, we further used the TREC topic descriptions, following [1, 8]. We used the Apache Lucene2 open source search library for indexing and searching documents. Documents and queries were processed using Lucene's English text analysis (i.e., tokenization, Porter stemming, stopwords, etc.).",1,TREC,True
227,2http://lucene.apache.org,0,,False
228,894,0,,False
229,Short Research Papers I,0,,False
230,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
231,"As the underlying retrieval method we used Lucene's Dirichletsmoothed query-likelihood implementation, with its Dirichlet parameter xed to µ ,"" 1000, following [10, 12].""",0,,False
232,4.2 Baselines,0,,False
233,"We compared our proposed QPP method (hereinafter referred to as PI3) with several di erent baseline QPP methods, as follows.",0,,False
234,"As a rst line of baselines, we compared with Clarity [5], WIG [15] and NQC [13], which are commonly used document-level postretrieval QPP methods [4]. The Clarity [5] method estimates query performance proportionally to the divergence between the relevance model [11] induced from D and the background model induced from C. The WIG method [15] estimates query performance according to the di erence between the average retrieval score in D and that of C. The NQC [13] method estimates query performance according to standard deviation of the retrieval scores of documents in D, further normalized by the corpus score sq (C).",1,WIG,True
235,"As alternative QPP methods that also utilize passage information, we closely followed [6, 9] and implemented the passage-level counterparts of the three former baselines; denoted Clarity(psg) [6, 9], WIG(psg) [9], NQC(psg) [9], respectively.",1,WIG,True
236,"As a very strong document-level baseline, we further compared with the WPM2 method [12]. WPM2 utilizes 10 di erent document retrieval score calibration features4, whose weights need to be learned [12].",0,,False
237,"Following the rst observation we made in Section 3.3, we also implemented a calibrated version of our PI method (denoted C-PI). Finally, following the second observation we made in Section 3.3, we further extended the WPM2 method with our new passagelevel calibration feature (denoted WPM2+PI).",1,ad,True
238,4.3 Setup,0,,False
239,We evaluated the various methods using two di erent query set-,0,,False
240,tings: once using the short (title) queries and once using the ver-,0,,False
241,"bose (description) queries. On each setting, we predicted the perfor-",0,,False
242,mance of each query based on its top-1000 retrieved documents [4].,0,,False
243,"Following a common practice [4], we assessed prediction over queries",0,,False
244,quality according to the Pearson's- correlation between the pre-,0,,False
245,dictor's values and the actual average precision (AP@1000) values,1,AP,True
246,calculated using TREC's relevance judgments.,1,TREC,True
247,"In order to realize our predictor in Eq. 5, according to Eq. 4, for",0,,False
248,"each document d( D), we need to obtain the passage  d with",0,,False
249,"the highest likelihood (score) p^(r |d). To this end, given document",0,,False
250,"d( D), we rst extracted candidate passages from it using a xed",0,,False
251,"L , 500 characters-windowing approach [14]; and then scored the",0,,False
252,candidates according to Eq. 4. We used Okapi-BM25 as our choice,0,,False
253,"of sq ( ), with k1 , 0.8 and b ,"" 0.3, following [7]. Most of the methods that we evaluated (and among them the PI""",0,,False
254,and WPM2 variants) required to tune some free parameters. Com-,0,,False
255,mon,0,,False
256,to,0,,False
257,all,0,,False
258,methods,0,,False
259,is,0,,False
260,the,0,,False
261,free,0,,False
262,parameter k,0,,False
263,def,0,,False
264,",",0,,False
265,"|D|, which is the",0,,False
266,number of top scored documents (out of a total of 1000 retrieved,0,,False
267,"documents) to be used for the prediction. To this end, for each",0,,False
268,"method we selected k  {5, 10, 20, 50, 100, 150, 200, 500, 1000}.",0,,False
269,"3PI stands for ""Passage Information"". 4The full list of features is described in Section 5 of [12].",0,,False
270,TREC5 WSJ AP WT10g Robust GOV2,1,TREC,True
271,Clarity WIG NQC,1,WIG,True
272,.490bp .347p .483bp,0,,False
273,.607p .677b .718b,0,,False
274,.596p .526bp .554bp,0,,False
275,.380bp .434bp .486p,0,,False
276,.477p .411bp .575b,0,,False
277,.407p .535b .432bp,0,,False
278,Clarity(psg) WIG(psg) NQC(psg),1,WIG,True
279,.204bp .344p .292bp,0,,False
280,.629p .576bp .497b,0,,False
281,.622p .397bp .304bp,0,,False
282,.289bp .494bp .488p,0,,False
283,.477p .435bp .401bp,0,,False
284,.395p .468b .220bp,0,,False
285,PI C-PI,0,,False
286,.567pc .613c,0,,False
287,.677 .718c,0,,False
288,.684pc .694c,0,,False
289,.518pc .532c,0,,False
290,.577pc .585c,0,,False
291,.465c .501c,0,,False
292,WPM2 WPM2+PI,0,,False
293,.738w .787w,0,,False
294,.725w .738w .743w .764w,0,,False
295,.540w .557w,0,,False
296,.640w .647w,0,,False
297,.655w .661w,0,,False
298,Table 2: Results of prediction over short queries. The super-,0,,False
299,script b denotes a statistically signi cant di erence between,0,,False
300,one of the rst document-level baselines and its passage-,0,,False
301,level counterpart. The superscript p denotes a signi cant dif-,0,,False
302,ference between PI and the six rst baselines. The subscript,0,,False
303,c denotes a signi cant di erence between PI and C-PI. The,0,,False
304,subscript w denotes a signi cant di erence between WPM2,0,,False
305,and WPM2+PI.,0,,False
306,"To implement the three passage-level alternatives (i.e., Clarity(psg),WIG(psg)",1,WIG,True
307,"and NQC(psg)), we rst used the same window-based passage ex-",0,,False
308,traction approach [14] and ranked candidate passages extracted,0,,False
309,from the various documents in D according to their Okapi-BM25,0,,False
310,"score with k1 , 0.8 and b , 0.3 [7]. We then used the top-m scored",0,,False
311,"passages over D for prediction [6, 9], with m  {5, 10, 20, 50, 100, 150, 200}.",0,,False
312,"For Clarity and Clarity(psg), following [5, 6, 9], we further clipped",0,,False
313,"the induced relevance model at the top-n terms cuto , with n ",0,,False
314,"{5, 10, 20, 50, 100, 150, 200}.",0,,False
315,"To learn the calibration feature weights of C-PI, WPM2 and",0,,False
316,"WPM2+PI, following [12], we used a Coordinate Ascent approach.",0,,False
317,"Similar to [12], we selected the feature weights {j }hj,""1 in the grid [0, 5]h with a step size of 0.1 within each dimension, with h """,0,,False
318,"{2, 10, 11} such di erent features implemented within the C-PI,",0,,False
319,"WPM2 and WPM2+PI methods, respectively. Further following [12],",0,,False
320,feature,0,,False
321,values,0,,False
322,were,0,,False
323,smoothed,0,,False
324,fj (d; ),0,,False
325,def,0,,False
326,",",0,,False
327,"max(fj (d), ), where",0,,False
328," , 10-10 is a hyperparameter.",0,,False
329,"Following [12, 13], we trained and tested all methods using a",0,,False
330,"holdout (2-fold cross validation) approach. Accordingly, on each",0,,False
331,"benchmark, we generated 30 random splits of the query set; each",0,,False
332,split had two folds. We used the rst fold as the (query) train set.,1,ad,True
333,We kept the second fold untouched for testing. We recorded the,0,,False
334,"average prediction quality over the 30 splits. Finally, we measured",0,,False
335,statistical signi cant di erences of prediction quality using a two-,0,,False
336,tailed paired t-test with (Bonferroni corrected) p < 0.05 computed,0,,False
337,over all 30 splits.,0,,False
338,4.4 Prediction over short queries,0,,False
339,"The results of our rst evaluation setting with short queries are summarized in Table 2. First, we observe that, the three rst documentlevel QPP baselines (i.e., Clarity WIG and NQC) and their passagelevel counterparts (i.e., Clarity(psg) WIG(psg) and NQC(psg)) exhibit a mixed relative performance. This serves as a rst evidence that passage-information is an important QPP signal.",1,WIG,True
340,895,0,,False
341,Short Research Papers I,0,,False
342,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
343,TREC5 WSJ AP WT10g Robust GOV2,1,TREC,True
344,Clarity WIG NQC,1,WIG,True
345,.254p .011bp .271bp,0,,False
346,-.005bp .368bp,0,,False
347,.642,0,,False
348,.174bp .510p .528bp,0,,False
349,.381bp .377p .397bp,0,,False
350,.288bp .278bp .461bp,0,,False
351,.281bp .303bp .360p,0,,False
352,Clarity(psg) WIG(psg) NQC(psg),1,WIG,True
353,.256p .292bp .338bp,0,,False
354,.188bp .588bp,0,,False
355,.640,0,,False
356,.198bp .526p .545bp,0,,False
357,.267bp .377p .458bp,0,,False
358,.468bp .446bp .499bp,0,,False
359,.446bp .343bp .361p,0,,False
360,PI C-PI,0,,False
361,.512p .528,0,,False
362,.655pc .678c,0,,False
363,.637pc .689c,0,,False
364,.464pc .476c,0,,False
365,.559pc .624c,0,,False
366,.460pc .482c,0,,False
367,WPM2,0,,False
368,.732,0,,False
369,WPM2+PI .740,0,,False
370,.650 .621w .406w .587w .509w .660 .729w .487w .602w .521w,0,,False
371,Table 3: Results of prediction over verbose (long) queries.,0,,False
372,The superscripts and subscripts notations are identical to,0,,False
373,those de ned in Table 2.,0,,False
374,"verbose query performance prediction settings. Moreover, such a strategy guarantees a more robust QPP, which is less sensitive to query type. Finally, again, we can observe that, by further calibrating PI (i.e., C-PI), even better prediction quality can be achieved. Moreover, the contribution of PI's passage-level calibration feature p^(r |d) to WPM2+PI is even more notable in this setting.",0,,False
375,5 CONCLUSIONS,0,,False
376,"The conclusions of this work are two-fold. First, this work clearly demonstrates that existing post-retrieval QPP methods that only focus on document-level features are not well suited to the prediction of verbose queries performance. Utilizing passage-information for such QPP sub-task is clearly important. As we further demonstrated, a mixed strategy that considers both types of features, such as the one employed by the PI variants, may result in an enhanced prediction, which is less sensitive to query type.",0,,False
377,"Next, in most cases, our newly proposed method, PI, had a better prediction. We note that, while the former baselines either uti-",1,ad,True
378,REFERENCES,0,,False
379,[1] Michael Bendersky and W. Bruce Croft. Modeling higher-order term dependencies in information retrieval using query hypergraphs. In Proceedings of the 35th,0,,False
380,"lize only document-level or only passage-level features, PI basi-",0,,False
381,International ACM SIGIR Conference on Research and Development in Information,0,,False
382,"cally utilizes both feature types. This, therefore, supports again the importance of passage-level QPP signals for the document-level",0,,False
383,"Retrieval, SIGIR '12, pages 941­950, New York, NY, USA, 2012. ACM. [2] Michael Bendersky and Oren Kurland. Utilizing passage-based language models",0,,False
384,"for document retrieval. In Proceedings of the IR Research, 30th European Confer-",0,,False
385,"QPP task. Furthermore, by calibrating the two ""features"" of PI ac-",0,,False
386,"ence on Advances in Information Retrieval, ECIR'08, pages 162­174, Berlin, Hei-",0,,False
387,"cording to our rst observation in Section 3.3, we obtained an enhanced performance of C-PI over PI.",0,,False
388,"delberg, 2008. Springer-Verlag. [3] James P. Callan. Passage-level evidence in document retrieval. In Proceedings",0,,False
389,of the 17th Annual International ACM SIGIR Conference on Research and Devel-,0,,False
390,"Overall, WPM2 was the best document-level only QPP method. Yet, further following the second observation we made in Section 3.3,",1,ad,True
391,"opment in Information Retrieval, SIGIR '94, pages 302­310, New York, NY, USA, 1994. Springer-Verlag New York, Inc. [4] David Carmel and Oren Kurland. Query performance prediction for ir. In Pro-",1,Query,True
392,"we can observe that, by solely adding the single passage-level fea-",1,ad,True
393,ceedings of the 35th International ACM SIGIR Conference on Research and Develop-,0,,False
394,"ture of p^(r |d) (see again Eq. 4) to WPM2, which resulted in the WPM2+PI extension, has obtained a signi cant boost in predic-",0,,False
395,"ment in Information Retrieval, SIGIR '12, pages 1196­1197, New York, NY, USA, 2012. ACM. [5] Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. Predicting query per-",0,,False
396,tion quality. This is yet another strong testimony on the impor-,0,,False
397,formance. In Proceedings of the 25th Annual International ACM SIGIR Conference,0,,False
398,tance of passage-level QPP signals for the document-level QPP task.,0,,False
399,"on Research and Development in Information Retrieval, SIGIR '02, pages 299­306, New York, NY, USA, 2002. ACM. [6] Steve Cronen-Townsend, Yun Zhou, and W Bruce Croft. Precision prediction",0,,False
400,"based on ranked list coherence. Information Retrieval, 9(6):723­755, 2006.",0,,False
401,4.5 Prediction over verbose queries,0,,False
402,"[7] Mathias Géry and Christine Largeron. Bm25t: A bm25 extension for focused information retrieval. Knowl. Inf. Syst., 32(1):217­241, July 2012.",0,,False
403,"The results of our second evaluation setting with verbose (long) queries are summarized in Table 3. First, comparing these results",0,,False
404,"[8] Manish Gupta and Michael Bendersky. Information retrieval with verbose queries. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15, pages 1121­1124,",0,,False
405,"with the results in Table 2, it becomes clear that those baseline methods that only utilize document-level features, perform signif-",0,,False
406,"New York, NY, USA, 2015. ACM. [9] Eyal Krikon, David Carmel, and Oren Kurland. Predicting the performance of",0,,False
407,passage retrieval for question answering. In Proceedings of the 21st ACM Interna-,0,,False
408,icantly worse in this setting compared to their performance over,0,,False
409,"tional Conference on Information and Knowledge Management, CIKM '12, pages",0,,False
410,"short queries. Moreover, those QPP methods that utilize passagelevel information (i.e., Clarity(psg), WIG(psg), NQC(psg), PI, C-",1,WIG,True
411,"2451­2454, New York, NY, USA, 2012. ACM. [10] Oren Kurland, Anna Shtok, Shay Hummel, Fiana Raiber, David Carmel, and Ofri",0,,False
412,Rom. Back to the roots: A probabilistic framework for query-performance pre-,0,,False
413,PI and WPM2+PI) provide signi cantly better prediction. This,0,,False
414,diction. In Proceedings of the 21st ACM International Conference on Information,0,,False
415,"demonstrates that, utilizing passage-information for QPP becomes even more eminent in verbose query settings. Verbose queries are",0,,False
416,"and Knowledge Management, CIKM '12, pages 823­832, New York, NY, USA, 2012. ACM. [11] Victor Lavrenko and W. Bruce Croft. Relevance based language models. In",0,,False
417,"usually more informative than short queries [8]; yet, existing document-",0,,False
418,Proceedings of SIGIR '01.,0,,False
419,level QPP methods are not well-designed to predict their quality.,0,,False
420,"[12] Haggai Roitman, Shai Erera, Oren Sar-Shalom, and Bar Weiner. Enhanced mean retrieval score estimation for query performance prediction. In Proceedings of",0,,False
421,Verbose queries tend to express more focused information needs [8];,0,,False
422,"the ACM SIGIR International Conference on Theory of Information Retrieval, ICTIR",0,,False
423,"hence, passage-information may provide a better ""proxy"" to such needs satisfaction within retrieved documents [1].",0,,False
424,"'17, pages 35­42, New York, NY, USA, 2017. ACM. [13] Anna Shtok, Oren Kurland, David Carmel, Fiana Raiber, and Gad Markovits.",1,ad,True
425,"Predicting query performance by query-drift estimation. ACM Trans. Inf. Syst.,",0,,False
426,"Further notable is that, compared to the six rst baseline meth-",0,,False
427,"30(2):11:1­11:35, May 2012.",0,,False
428,"ods, PI provided signi cantly better prediction quality; and even exceeded in some of the cases that of WPM2 ­ a very strong",0,,False
429,"[14] Stefanie Tellex, Boris Katz, Jimmy Lin, Aaron Fernandes, and Gregory Marton. Quantitative evaluation of passage retrieval algorithms for question answering. In Proceedings of SIGIR '03.",0,,False
430,"document-level QPP baseline. This serves as another strong evidence that, a mixed document-level and passage-level prediction",0,,False
431,"[15] Yun Zhou and W. Bruce Croft. Query performance prediction in web search environments. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '07, pages",1,Query,True
432,"strategy, such as the one employed by PI, is a better choice for",0,,False
433,"543­550, New York, NY, USA, 2007. ACM.",0,,False
434,896,0,,False
435,,0,,False
