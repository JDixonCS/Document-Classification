,sentence,label,data,regex
0,Short Research Papers I,0,,False
1,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA",0,,False
2,Split-Lists and Initial Thresholds for WAND-based Search,0,,False
3,Andrew Kane,0,,False
4,"University of Waterloo Waterloo, Ontario, Canada",1,ad,True
5,arkane@uwaterloo.ca,0,,False
6,ABSTRACT,0,,False
7,"We examine search engine performance for rank-safe query execution using the WAND and state-of-the-art BMW algorithms. Supported by extensive experiments, we suggest two approaches to improve query performance: initial list thresholds should be used when k values are large, and our split-list WAND approach should be used instead of the normal WAND or BMW approaches. We also recommend that reranking-based distributed systems use smaller k values when selecting the results to return from each partition.",1,ad,True
8,CCS CONCEPTS,0,,False
9,· Information systems  Retrieval eciency; Information retrieval query processing; Search engine indexing;,0,,False
10,KEYWORDS,0,,False
11,"Information retrieval, Query performance, Eciency, Optimization",1,Query,True
12,"ACM Reference Format: Andrew Kane and Frank Wm. Tompa. 2018. Split-Lists and Initial Thresholds for WAND-based Search. In SIGIR '18: The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, July 8­ 12, 2018, Ann Arbor, MI, USA. ACM, New York, NY, USA, 4 pages. https: //doi.org/10.1145/3209978.3210066",0,,False
13,1 INTRODUCTION,1,DUC,True
14,"With huge amounts of data and large query volumes, search engines consume signicant resources, both in terms of computer hardware and energy usage. The end user sees fast queries because the dataset is partitioned across many machines. However, resource costs are still present, so any improvement in eciency will give signicant cost savings. In this paper, we present various optimization techniques for search execution that maintain the ranking eectiveness of the system, so called rank-safe execution.",0,,False
15,"The details of executing queries in a search system are complex, but the basic idea is simple. At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset. Each list is stored in a compressed format and often in document identier (docid) order. Within-document locations are often dropped and only <docid, frequency> pairs are stored. At query time, the system nds the lists for the query terms",0,,False
16,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00 https://doi.org/10.1145/3209978.3210066",1,ad,True
17,Frank Wm. Tompa,0,,False
18,"University of Waterloo Waterloo, Ontario, Canada",1,ad,True
19,fwtompa@uwaterloo.ca,0,,False
20,"and combines them to give the top-k best documents according to a specied ranking algorithm. The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5].",0,,False
21,"During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now). The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored. The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found.",0,,False
22,next,0,,False
23,start,0,,False
24,"state: <query_lists, current_list_pointers, heap, max_list_scores>",0,,False
25,SELECT,0,,False
26,"<docid, max_potential_score>",0,,False
27,SCORE,0,,False
28,"<docid, score>",0,,False
29,SAVE,0,,False
30,end,0,,False
31,Figure 1: Search execution loop used by WAND and BMW.,0,,False
32,"The WAND (Weak-AND) [4] and state-of-the-art BMW (BlockMax WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve. The details of this transition produce both fast query execution and rank-safe results. The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more ecient skipping of potential candidates during SELECT processing. This is done by ordering the query lists by their current docid and summing up their maximum list scores --in order-- until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate. The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation. Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage. The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).",1,ad,True
33,We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]. We then improve upon this original code in three ways:,0,,False
34,"First, we apply small code optimizations to both the WAND and BMW implementations that give signicant runtime improvements.",0,,False
35,"Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.",0,,False
36,877,0,,False
37,Short Research Papers I,0,,False
38,"SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA",0,,False
39,"Third, we show that split-lists (i.e., 2-layer lists split by score) can signicantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many congurations. While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined.",0,,False
40,2 RELATED WORK,0,,False
41,"Compression and Reordering. There are many encoding techniques that can make postings lists both fast and compact. For this study we use QMX [16] to compress lists, as this method is used in the original code, but many other approaches are available, such as OptPFD [19], PForDelta (PFD) [21], Simple-9 [1], Simple-16 [20], and partitioned Elias-Fano codes [12]. It is common to encode in blocks and include skips, as we do, to jump over unused portions of the lists. Ranking information can be stored immediately inside the encoding or in parallel on the block encoding level.",0,,False
42,"Reordering documents (i.e., renumbering internal document identiers) can improve both space and runtime. One common technique that produces superior results reorders by URL [15], but others reorder at random or by clustering [3, 14], document size [5, §6.3.7], or global rank [11]. We examine both URL and random ordering and expect other approaches to lie between these results.",0,,False
43,"Query Execution. Executing a query typically involves combining postings lists containing document identier and occurrence frequency pairs using a ranking function. This combining is often done using either document-at-a-time or term-at-a-time processing [18]; the former requires little temporary space, while the latter can give better memory access performance. When lists are ordered by document identier this is a simple merge with skipping within lists. Alternatively, lists could be stored in impact order, which allows for score-at-a-time processing and early termination [2].",1,Query,True
44,"Rather than storing frequencies in postings lists, partial scores per-term can be stored instead, often as quantized values. Using quantized scores can give runtime performance gains when combining document ordered lists, but the indexes are larger because quantized scores are less compressible than frequencies [6, 9].",1,ad,True
45,3 EXPERIMENTAL SETUP,0,,False
46,Our experiments are run on two datasets with associated workloads: the GOV2 dataset is 426GB of data in 25.2 million documents using the TREC '04-'06 query topic workload (701-850) and the ClueWeb09b dataset is 1.39 TB of data in 50.2 million documents using the TREC '10-'12 query topic workload (51-200). Associated user evaluations ensure no degradation of ranking eectiveness.,1,ad,True
47,"Our experiments are run on a large 4x22 core Xeon 2.2GHz Linux machine with 1TB of memory. Postings lists are loaded into memory and full query workloads are executed ten times single threaded to avoid CPU caching. We explore various top-k values, namely k 2 {1, 10, 50, 100, 500, 1000, 2000}, to give a broad understanding of query performance. We nd that workload runtimes are stable with small standard deviations of less than 1.3% for k 10.",1,TB,True
48,4 ORIGINAL CODE,0,,False
49,The WAND and BMW code with which we started is a state-of-theart publicly available1 implementation developed at RMIT and used,0,,False
50,1 https://github.com/jmmackenzie/Quant-BM-WAND/,0,,False
51,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA Andrew Kane and Frank Wm. Tompa",0,,False
52,runtime (ms/query),0,,False
53,40  WAND original code  BMW original code WAND new code BMW new code,0,,False
54,30,0,,False
55,GOV2,0,,False
56,(URL order),0,,False
57,20,0,,False
58,10,0,,False
59,0 1,0,,False
60,10,0,,False
61,50 100,0,,False
62,500 1000 2000,0,,False
63,runtime (ms/query),0,,False
64,140  WAND original code,0,,False
65, BMW original code,0,,False
66,120,0,,False
67,WAND new code,0,,False
68,BMW new code,0,,False
69,100,0,,False
70,80 ,0,,False
71,60,0,,False
72,ClueWeb09b,1,ClueWeb,True
73,(URL order),0,,False
74,40 20,0,,False
75,0 1,0,,False
76,10,0,,False
77,50 100,0,,False
78,500 1000 2000,0,,False
79,k value,0,,False
80,Figure 2: Query runtime performance using original and new implementations over various top-k values.,1,Query,True
81,"for recent research presented in a WSDM 2017 paper [6]. This code rst indexes the data using ATIRE [17], then converts that index to a document ordered encoding with QMX [16] compression on 128 element blocks and skip structures over blocks. We use the faster variant storing precomputed partial BM25 scores in the index quantized as small integers, rather than storing document frequencies and calculating the partial scores at runtime, even though this does increase index size. In the query execution loop, the SCORE portion of the query is done incrementally, which avoids full scoring for many candidate documents and makes execution faster.",0,,False
82,"We added code to allow reordering of documents during conversion from the ATIRE index into WAND and BMW indexes. We follow the standard approach of reordering our indexes by URL, which produces a signicant performance improvement [15].",1,ad,True
83,"We nd that this original implementation of the WAND and BMW algorithms has good performance over a range of k values, as shown for URL ordered versions of GOV2 and ClueWeb09b in Figure 2 (orange lines). Since using smaller k values can give signicant performance gains, reranking systems with multiple partitions should use smaller k values in the partitions and ensure rank-safe results by revisiting a partition for more results as needed [13]. Thus, for example, rather than retrieving 1000 matches from each partition, a highly distributed web search engine could use a very small k value for each partition, and revisit very few partitions, to produce the top-1000 matches needed for reranking.",1,ClueWeb,True
84,5 NEW CODE OPTIMIZATIONS,0,,False
85,"While it is quite common to add assertion type checks in low level methods, these can cause performance slowdowns if they are not",1,ad,True
86,878,0,,False
87,Short Research Papers I Split-Lists and Initial Thresholds for WAND-based Search,0,,False
88,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA",0,,False
89,"removed or turned o in production code. As such, we removed two assertion type checks from the underlying compressed list access methods to give performance gains.",0,,False
90,"Standard template classes are highly useful and often well optimized, but using some generalized accessor paradigms may not be the most ecient choice for simple tasks. The original implementation uses std::array objects to store the sorted list pointers and general std::iterators are used to traverse over these objects. We changed these traversals to use operator[] accesses, which is signicantly faster, especially when the arrays are small.",1,ad,True
91,"Returning multiple objects from a method can be accomplished by forming std::pair or std::tuple objects to pass back to the caller, but this can be expensive if the method is called a large number of times. We changed such methods to pass objects by reference so that the method can update and the caller can access the object.",0,,False
92,"The search execution loop must SAVE candidates with high enough scores, as shown in Figure 1. This is done using a heap, so that a candidate is added when the heap size is less than k, or the minimum scored value in the heap is replaced by the candidate when the candidate's score is higher (i.e., a minimum heap). Rather than checking if the heap size is less than k for each candidate, we initialize the heap with k dummy values having a score of zero, and then avoid outputting them at the end of query execution. This improves performance and also allows for easy implementation of the initial list thresholds described in the next section.",1,ad,True
93,"Combining these simple code optimizations results in runtime performance gains, as shown in Figure 2 (blue lines). While these optimizations improve performance for both approaches, the WAND algorithm benets somewhat more than does BMW (average speedup of 1.22x vs. 1.16x).",0,,False
94,6 INITIAL LIST THRESHOLDS,0,,False
95,"During indexing, we determine the kth highest scoring value for each list of at least size k and store the values in a separatele on disk. Before we start executing a query, we calculate the initial threshold by simply taking the maximum kth score value for all the query lists (minus one for quantized scoring or minus a small epsilon for exact ranking). Using our pre-populated heap optimization from the last section, we set the score of the dummy values to be this initial list threshold, thus dening a minimum starting threshold for query execution. Since one of the query lists can generate k values higher than this threshold, we know that the nal threshold must be higher than this value, and thus, the query execution will be rank-safe (i.e., it will produce the k highest ranked results). This initial threshold approach was briey explored in recent work [7].",0,,False
96,"This approach does restrict the choice of k at query time, though any query using a k value smaller than what was used at indexing time to produce the stored scores can be used and still produce ranksafe results. If k is large, the number of lists of at least size k will likely be small and require little space to store their list thresholds (e.g., our indexes add less than 0.01% space overhead at k ,"" 1000). For a multi-partition index, these list thresholds could be calculated globally, giving higher values that would improve performance; thus the larger the system, the bigger the gain.""",1,ad,True
97,We nd that using list thresholds as we have described improves performance for large k values and does not noticeably degrade,1,ad,True
98,40 WAND new code BMW new code WAND list thresholds BMW list thresholds,0,,False
99,30,0,,False
100,GOV2,0,,False
101,(URL order),0,,False
102,runtime (ms/query),0,,False
103,20,0,,False
104,10,0,,False
105,0 1,0,,False
106,10,0,,False
107,50 100,0,,False
108,500 1000 2000,0,,False
109,140,0,,False
110,WAND new code,0,,False
111,ClueWeb09b,1,ClueWeb,True
112,BMW new code,0,,False
113,120,0,,False
114,WAND list thresholds,0,,False
115,(URL order),0,,False
116,BMW list thresholds,0,,False
117,100,0,,False
118,runtime (ms/query),0,,False
119,80,0,,False
120,60,0,,False
121,40,0,,False
122,20,0,,False
123,0 1,0,,False
124,10,0,,False
125,50 100,0,,False
126,500 1000 2000,0,,False
127,k value,0,,False
128,Figure 3: Query runtime performance using list thresholds over various top-k values.,1,Query,True
129,"performance in other situations. Using list thresholds, we nd that the GOV2 dataset has signicant gains for a range of large k values, while ClueWeb09b has some gains for large k values, as shown in Figure 3 (red lines). Since list thresholds can produce performance gains without noticeably degrading any conguration and they can be stored in the index with little overhead, we expect that employing list thresholds will be benecial in many search systems.",1,ClueWeb,True
130,7 SPLIT-LISTS,0,,False
131,"During indexing time, we split each list into two parts, where the rst part contains the highest scored documents for that term and the second part contains the remaining documents (i.e., 2-layer lists split by score [10]). There are many ways to decide how many documents to place in each list, but we simply pick a percentage of the list. Since we are using a quantized score value we split along quantum boundaries, but these boundaries could be far apart, so we pick the last boundary before the desired cut point. In addition, we only split lists with more than 10,000 postings.",1,ad,True
132,"At query time, the split-lists are both included in the WAND pivot processing, but the maximum list scores used depend on whether the paired split-list has already been included in the pivot process (i.e., both lists cannot contain the same document, so if both are in the pivot calculation, then the maximum score of the paired lists is used). This checking of pairs adds some overhead, but allows for more skipping. We nd that for our split-list WAND implementation, checking pairs is faster than not checking.",1,ad,True
133,"Our split-list WAND implementation produces signicant gains over traditional WAND processing, as shown in Figure 4 (green lines). Indeed, split-list WAND is faster than the state-of-the-art",1,ad,True
134,879,0,,False
135,"Short Research Papers I SIGIR '18, July 8­12, 2018, Ann Arbor, MI, USA",0,,False
136,40 WAND list thresholds BMW list thresholds WAND split-lists,0,,False
137,30,0,,False
138,GOV2,0,,False
139,(URL order),0,,False
140,runtime (ms/query),0,,False
141,20,0,,False
142,10,0,,False
143,0 1,0,,False
144,10,0,,False
145,50 100,0,,False
146,500 1000 2000,0,,False
147,140,0,,False
148,WAND list thresholds,0,,False
149,ClueWeb09b,1,ClueWeb,True
150,BMW list thresholds,0,,False
151,120,0,,False
152,WAND split-lists,0,,False
153,(URL order),0,,False
154,runtime (ms/query),0,,False
155,100,0,,False
156,80,0,,False
157,60,0,,False
158,40,0,,False
159,20,0,,False
160,0 1,0,,False
161,10,0,,False
162,50 100,0,,False
163,500 1000 2000,0,,False
164,k value,0,,False
165,Figure 4: Query runtime performance using split-lists over various top-k values.,1,Query,True
166,"BMW algorithm in ClueWeb09b for all k values and in GOV2 for small k values. The improvement in the ClueWeb09b dataset is quite signicant, split-list WAND at k ,"" 10 gives a 1.41x speedup over an already highly optimized BMW implementation for URL order (and more for random order). Importantly, compared to using a normal WAND implementation, the improvement from switching to splitlist WAND is large for all k values in both datasets (ranging from 1.20x to 6.39x speedup with a 10% space overhead). We expect that split-list WAND can be combined with other existing approaches for additional gains (e.g., ltering [8] and 3-phase retrieval [7]).""",1,ClueWeb,True
167,"Previous work on 2-layer BMW suggests it is faster than BMW when no pair checking is implemented [10], but we found 2-layer BMW to be slower both with and without pair checking, likely from our fast scoring limiting gains from additional BMW candidate pruning. Our split-list WAND approach can exploit much larger high-score splits than previously recommended for the 2layer BMW approach, in particular, we use a cuto of 10%, which outperforms the 2% split recommended for 2-layer BMW.",1,ad,True
168,8 CONCLUSIONS,0,,False
169,"A summary of the runtime performance of the algorithms presented in this paper for k 2 {10, 1000} is shown in Table 1. We nd that using smaller k values in partitions and making some simple code changes can greatly improve query execution times. The simple idea of using initial thresholds based on the kth highest score in each query list can also improve performance for both WAND and BMW when k is large. Finally, we nd that our split-list WAND approach signicantly outperforms the basic WAND approach and can also outperform the state-of-the-art BMW approach. As such, split-list",0,,False
170,"SIGIR'18, July 8-12, 2018, Ann Arbor, MI, USA Andrew Kane and Frank Wm. Tompa",0,,False
171,"Table 1: Runtime performance for k,10 and k,1000 (ms).",0,,False
172,WAND original code WAND original code WAND new code WAND list thresholds WAND split-lists (10%) BMW original code BMW original code BMW new code BMW list thresholds BMW 2-layer (2%) BMW 2-layer (10%),0,,False
173,order rand,0,,False
174,url url url url rand url url url url url,0,,False
175,"GOV2 k,10 k,1000 23.25 56.20 9.91 29.47 8.35 23.60 8.30 19.74 4.81 15.95 18.93 51.71 6.10 19.86 5.29 17.03 5.23 14.74 6.03 17.31 8.28 20.34",0,,False
176,"ClueWeb09b k,10 k,1000 121.00 179.98 74.94 118.80 60.61 97.35 61.03 87.01 15.35 55.18 54.51 152.59 24.68 78.12 21.69 65.65 21.66 62.10 29.61 70.94 52.92 83.70",1,ClueWeb,True
177,WAND should be considered for use in many search systems. Our implementation of these algorithms is publicly available2.,0,,False
178,Acknowledgments. The computing resources used in this research were made available by the University of Waterloo.,1,ad,True
179,REFERENCES,0,,False
180,"[1] Vo Ngoc Anh and Alistair Moat. 2005. Inverted index compression using wordaligned binary codes. Information Retrieval 8, 1 (2005), 151­166.",0,,False
181,[2] Vo Ngoc Anh and Alistair Moat. 2005. Simplied similarity scoring using term ranks. In SIGIR. 226­233.,0,,False
182,[3] Dan Blandford and Guy Blelloch. 2002. Index compression through document reordering. In DCC. 342­351.,0,,False
183,"[4] Andrei Z. Broder, David Carmel, Michael Herscovici, Aya Soer, and Jason Zien. 2003. Ecient query evaluation using a two-level retrieval process. In CIKM. 426­434.",0,,False
184,"[5] Stefan Büttcher, Charles Clarke, and Gordon V. Cormack. 2010. Information retrieval: Implementing and evaluating search engines. The MIT Press.",0,,False
185,"[6] Matt Crane, J. Shane Culpepper, Jimmy Lin, Joel Mackenzie, and Andrew Trotman. 2017. A Comparison of Document-at-a-Time and Score-at-a-Time Query Evaluation. In WSDM. 201­210.",1,Query,True
186,"[7] Caio Moura Daoud, Edleno Silva de Moura, Andre Carvalho, Altigran Soares da Silva, David Fernandes, and Cristian Rossi. 2016. Fast top-k preserving query processing using two-tier indexes. Information processing & management 52, 5 (2016), 855­872.",0,,False
187,"[8] Constantinos Dimopoulos, Sergey Nepomnyachiy, and Torsten Suel. 2013. A candidate ltering mechanism for fast top-k query processing on modern CPUs. In SIGIR. 723­732.",0,,False
188,"[9] Constantinos Dimopoulos, Sergey Nepomnyachiy, and Torsten Suel. 2013. Optimizing top-k document retrieval strategies for block-max indexes. In WSDM. 113­122.",0,,False
189,[10] Shuai Ding and Torsten Suel. 2011. Faster top-k document retrieval using blockmax indexes. In SIGIR. 993­1002.,0,,False
190,[11] Xiaohui Long and Torsten Suel. 2003. Optimized query execution in large search engines with global page ordering. In VLDB. 129­140.,0,,False
191,[12] Giuseppe Ottaviano and Rossano Venturini. 2014. Partitioned Elias-Fano indexes. In SIGIR. 273­282.,0,,False
192,"[13] Oscar Rojas, Veronica Gil-Costa, and Mauricio Marin. 2013. Ecient parallel block-max WAND algorithm. In Euro-Par. 394­405.",0,,False
193,"[14] Wann-Yun Shieh, Tien-Fu Chen, Jean Jyh-Jiun Shann, and Chung-Ping Chung. 2003. Inverted le compression through document identier reassignment. Information Processing & Management 39, 1 (2003), 117­131.",0,,False
194,"[15] Fabrizio Silvestri. 2007. Sorting out the document identier assignment problem. Advances in Information Retrieval (2007), 101­112.",0,,False
195,"[16] Andrew Trotman. 2014. Compression, SIMD, and postings lists. In ADCS. 50­57. [17] Andrew Trotman, Xiangfei Jia, and Matt Crane. 2012. Towards an ecient and",0,,False
196,eective search engine. In Workshop on Open Source Information Retrieval. 40­47. [18] Howard Turtle and James Flood. 1995. Query evaluation: strategies and optimiza-,1,Query,True
197,"tions. Information Processing & Management 31, 6 (1995), 831­850. [19] Hao Yan, Shuai Ding, and Torsten Suel. 2009. Inverted index compression and",0,,False
198,"query processing with optimized document ordering. In WWW. 401­410. [20] Jiangong Zhang, Xiaohui Long, and Torsten Suel. 2008. Performance of com-",0,,False
199,"pressed inverted list caching in search engines. In WWW. 387­396. [21] Marcin Zukowski, Sandor Heman, Niels Nes, and Peter Boncz. 2006. Super-scalar",0,,False
200,RAM-CPU cache compression. In ICDE. 59:1­12.,0,,False
201,2 https://github.com/andrewrkane/Quant-BM-WAND/,0,,False
202,880,0,,False
203,,0,,False
