,sentence,label,data,regex
0,Efficient Partial-Duplicate Detection Based on Sequence Matching,0,,False
1,"Qi Zhang, Yue Zhang, Haomin Yu, Xuanjing Huang",0,,False
2,"School of Computer Science, Fudan University 825 Zhangheng Road, Shanghai, P.R.China",1,ad,True
3,"{qi_zhang, 09210240052, 09210240086, xjhuang}@fudan.edu.cn",0,,False
4,ABSTRACT,0,,False
5,"With the ever-increasing growth of the Internet, numerous copies of documents become serious problem for search engine, opinion mining and many other web applications. Since partial-duplicates only contain a small piece of text taken from other sources and most existing near-duplicate detection approaches focus on document level, partial duplicates can not be dealt with well. In this paper, we propose a novel algorithm to realize the partial-duplicate detection task. Besides the similarities between documents, our proposed algorithm can simultaneously locate the duplicated parts. The main idea is to divide the partial-duplicate detection task into two subtasks: sentence level near-duplicate detection and sequence matching. For evaluation, we compare the proposed method with other approaches on both English and Chinese web collections. Experimental results appear to support that our proposed method is effectively and efficiently to detect both partial-duplicates on large web collections.",0,,False
6,Categories and Subject Descriptors,0,,False
7,"H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - Information Search and Retrieval; H.3.7 [Digital Libraries]: Collection, Systems Issues",0,,False
8,General Terms,0,,False
9,"Algorithms, Experimentation.",0,,False
10,Keywords,0,,False
11,"Partial-Duplicate Detection, Sequence Matching, MapReduce",0,,False
12,1. INTRODUCTION,1,DUC,True
13,"Because of the explosion of Internet and the fact that digital documents can be easily replicated, enormous duplicated web pages and mirrored documents cause serious problem",0,,False
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10, July 19­23, 2010, Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",1,ad,True
15,"for search engine, product review, and many other Web applications. Along with the increasing requirements, nearduplicate detection has received much attentions in recent years [24, 25, 11, 26, 20].",0,,False
16,"Existing studies on near-duplicate detection usually focus on the whole document level to figure out web pages that have the same content but only differ in the framing, navigation bar, advertisements, footer, and so on. Thus there are several factors that can not be well processed by existing methods.",1,ad,True
17,"Collection: Figure 1 shows a pair of Web pages1 2 which both of contain the article ""Droid is No. 2 in Android traffic: Admob"". Besides this article, the page in Figure 1.(a) contains another nine related ones. Thus, the similarity between the pages in Figure 1.(a) and (b) is low in the document level.",0,,False
18,"Multiple-page: In order to facilitate user's browsing, some articles are divided into multiple pages. Websites may use different strategies to split articles. Moveover, a number of websites may display the article in one page according to their own styles. It also leads to the similarities between the pages are low in document level.",1,ad,True
19,"Threads in Forum: Millions of people contribute more than 10 gigabytes content everyday through forums, blogs and other consumer-generated mediums [21]. However, user generated content often contains a couple of sentences/pragraphs copied from news sites or other users [14]. Since the duplications are usually only a small piece of text, they can not be effectively detected by existing methods.",1,ad,True
20,"Besides the factors listed above, there are a number of problems like, plagiarize sentences, non-cleaned web pages, sentences/paragraphs quotation, can also be generalized to partial duplicate. If a pair of documents are partial-duplicate with each other, it means they contain a number of sentences or paragraphs with similar content. With requirements of applications such as plagiarism detection, information flow tracking, opinion mining, and so on, partial-duplicate detection task is proposed and studied in this paper. Local text reuse detection [23] can be used to partially address this task. However, we argue that only similarities and category types do not provide sufficient information for all applica-",1,ad,True
21,1http://iphandroid.com/ 2http://www.chinapost.com.tw/business/companyfocus/2009/11/25/234147/Droid-is.htm,0,,False
22,675,0,,False
23,tions and are not convenient enough for user to easily find the duplications in dozens of lines.,0,,False
24,Type here your search,0,,False
25,Home,0,,False
26,DroidisNo. 2in Andoridtraffci: Amdo b,0,,False
27,"Posted Novemb er24,2009 ­ 9:39pm in:Android Updates",0,,False
28,"MotorolaInc.'s Droid handled the snedc-o largest share of traffciamong mo bile phones equippde withGoogleInc.'s Android operating systemtwo weeks after the nhdaset's introduction, according toma rket researcherAdmo b Inc.",0,,False
29,Share,0,,False
30,"Droid,introduced on Nov.6 to comp ete againstApple In.c's iPhone and Research InMotionLtd.'s BalckBerry,had 24 percentofallrequestsfrom Android phonesasofNov.18,according toestima tesby teh San Mateo, Calfiorni-abased resaerch firm.",1,ad,True
31,"That's second toHTC Corp.'sDream phone taht handled 36 percent oAfndroid traffci, according to Amdo b,which cmop iels thedatafrom requestsfor asdon its neotrwk ofmo bile Web sitesand iPhone and Android applications.",0,,False
32,Motorolaintroduced theDroid tomeetdema nd for smart phones tahtallowuserstobrowse the,0,,False
33,(a),0,,False
34,Subcrbie vaiRSS,0,,False
35,Subcrbie via Em ail,0,,False
36,Blac k Fr id ay Amaz in g Dea l Hu rry and check out these am azing Black Friday deals for Ch ristma s ww w.am azon.com,0,,False
37,"Make Mo ne y Fr om 3G Ap ps Profitfrom the 3G APPS trend, create apps & ma ke mo ney today www. appleipho neapps.co.uk",1,AP,True
38,3G Millio na ir es Club EasilyJointhem Today CreatingSelling3G apps Huge Cash Income 3 g-appcash.co m,0,,False
39,"Yo ur Smartp ho ne , Ho ts po t Turn your Wind ow s Mob ilephone intoan internet Ho tspot.Try for free! ww w.WM WifRio uter.com",0,,False
40,Categoreis,0,,False
41,AndroidUpdates iPhandroid News iPhone Updates,0,,False
42,Monthly archives,0,,False
43,November 2009,0,,False
44,News Opinion Taiwan Living Learn English The China Post Subscribe,0,,False
45,RSS Feeds,0,,False
46," Search

Business
Updated Wednesday, November 25, 2009 11:00 am TWN, By Jason Clenfield, Bloomberg
Droid is No. 2 in Android traffic: Admob

Motorola Inc.'s Droid handled the second-largest share of traffic among mobile phones equipped with Google Inc.'s Android operating system two weeks after the handset's introduction, according to market researcher Admob Inc.

Le ar n Chin es e On li ne 1,300+ audio and video lessons Speaking practice by phone Ch inesePo d.co m

~¢...

g

 ´,,·­ ~ R ,, ... ¨,,¨

¤

www .MarsEnglihs.cn

In du ct io n Ligh ti ng SO LARA Probably themo st environm entallamp inthe wo rld www .amk o.com.tw/SOL AR A

Droid, introduced on Nov. 6 to compete against Apple Inc.'s iPhone and Research In Motion Ltd.'s BlackBerry, had 24 percent of all requests from Android phones as of Nov. 18, according to estimates by the San Mateo, California-based research firm.
That's second to HTC Corp.'s Dream phone that handled 36 percent of Android traffic, according to Admob, which compiles the data from requests for ads on its network of mobile Web sites and iPhone and Android applications.

Motorola introduced the Droid to meet demand for smart phones that allow users to browse the Internet, send e-mails and download software, the fastest-growing part of the mobile-phone industry.

(b)

Global Markets Asia Americas Europe Middle East Africa
Company Focus Breaking News Updated Wednesday, November 25, 2009 11:40 am TWN
Toyota said to plan moving some U.S. jobs from Calif. Cadbury shares rise on report of Nestle interest

Figure 1: Examples of partial-duplicate web pages

In this paper, we present an efficient algorithms for detecting partial-duplicates and locating their positions. Figure 2 shows an example on partial-duplicates. As shown in the graph, a sequence of sentences in Page A are similar with a number of sentences in Page B. Page A and C also contains duplicated text. From these pairs, we try to get the following results:
· Page A (Seni to Senj) Page B (Senk to Senl).
· Page A (Senm to Senn) Page C (Senp to Senq).
Since the proposed method can not only detect duplicates but also locate their positions, the near-duplicates of the whole document level can also be precisely detected. As the Web collections contain hundreds of millions pages, the algorithm is explored with MapReduce [8], which is a framework for large-scale distributed computing. We implement our method and compare it with the state-of-the-art approaches on four web collections and one manually constructed evaluation corpus. The experimental results show that it achieves good performance, both effectiveness and efficiency are significantly improved.
The contributions of this work are as follows: 1) We convert the partial-duplicate detection task into sentence level near-duplicate detection task and sequence matching task. 2) In order to handle hundreds of millions documents, the algorithm is designed and implemented under the MapReduce framework. 3) Shingles, I-Match, and Spotsigs are compared and evaluated in experiments, and experimental analyses of the signatures for sentences are provided. 4) Evaluations on manually labeled Oracle Set"" and four large web collections are used to measure the effectiveness and efficiency.",1,ad,True
47,"The remaining of the paper is organized as follows: In section 2, we review a number of related work and the stateof-the-art approaches in related areas. Section 3 provides an brief introduction of MapReduce. Section 4 presents the proposed method. Experimental results in test collections",0,,False
48,"2,CA)",0,,False
49,"2,CA*",0,,False
50,"2,CA+",0,,False
51,Figure 2: Partial-duplicate content,0,,False
52,and analyses are shown in section 5. Section 6 concludes this paper.,0,,False
53,2. RELATED WORK,0,,False
54,"Near-duplicate detection has received considerable attentions over the past several years. Previous studies on duplicate and near-duplicate detection can be roughly divided into two research directions: document representation and efficient detection. The first one focuses on representing documents with or without linguistic knowledge. Since collection contains hundreds of millions of documents, the second one, efficiency, has also received lots of attentions. This section introduces related approaches briefly.",0,,False
55,"Broder [3] defined the resemblance and containment between two documents. He used shingles to represent documents and Jaccard overlap to calculate the similarity between documents. In order to reduce the complexity of shingling, Broder [4] proposed to use meta-sketches for this task.",0,,False
56,"Indyk and Motwani[15] proposed the notion of localitysensitive hashing and applied it to sublinear-time similarity searching. LSH maintains a number of hash tables, which each of is parameterized by the number of hashed dimensions. Points close to each other in some metric space have the same hash value with high probability. Gionis et al. [11] also used LSH for approximate similarity search.",0,,False
57,I-Match [7] hinges on the premise that removal of very infrequent terms and very common terms results in good document representations for the near-duplicate detection task. They filter the input document based on collection statistics and compute a single hash value for the remainder text. The documents with same hash value are duplicates.,0,,False
58,"Schleimer et al. [22] proposed a local document fingerprinting algorithm, which is called winnowing. They described and analyzed the winnowing algorithm for selecting fingerprints from hashes of k-grams. They also presented the complexity of any local document fingerprinting algorithm and gave the non-trivial lower bound.",0,,False
59,"Henzinger [13] performed an evaluation of Border et al.'s [4] shingling and Charikar's [6] random projection near-duplicate algorithms on 1.6B web pages. The results showed that neither of the algorithms works well for detecting near-duplicate pairs on the same site, while both of them achieve high precision for near-duplicate pairs on different sites.",0,,False
60,"Manku et al. [19] proposed an approach for both online and batch types near-duplicate detection. They used Charikar's fingerprinting technique [6] and demonstrated it's effectiveness. They also presented an algorithmic technique for identifying existing f-bit fingerprints that differ from a given fingerprint in at most k bit-positions, for small k.",0,,False
61,"Theobald et al. [26] presented their work SpotSigs, which combine stopword antecedents with short chains of adjacent content terms. Through demonstrating the upper bounds of Jaccard similarity, they also proposed several pruning conditions, which could ignore all pairs of documents safely during",1,ad,True
62,676,0,,False
63,the matching process when SpotSig vectors exceed a certain difference in length.,0,,False
64,"Besides the approaches focused on Web pages or documents, Muthmann et al. [20] proposed their work to identify threads with near-duplicate content and to group these threads in the search results. They incorporated text-based features, features based on extracted entities for products, and structure-based features to capture the near-duplicate threads.",1,ad,True
65,"Local text reuse detection proposed by Seo and Croft [23] is also related to our method. Different from duplicate detection, text reuse tries to capture the loose restatements of the information from the previous sources [2]. They defined six categories of text reuse and a general framework for text reuse detection. Several fingerprinting techniques for the framework were evaluated under the framework.",0,,False
66,"Lin [18] explored the problem of pairwise similarity on large document collections and introduced three MapReduce algorithms to solve this problem, which are based on brute force, large-scale ad hoc retrieval, and the Cartesian product of postings lists. Different with us, the granularity of this work is also document level.",1,ad,True
67,"Kolak and Schilit [16] described an approach to mine popularly quoted passages and add links among them on a digital library. They use shingle table method to find repeated sequences between different books. Since the storage complexity of shingle methods is huge and extracting shared shingles is timing consuming tasks, the method can not be directly used for partial-duplicate detection task.",1,ad,True
68,"In order to handle hundreds of millions web collections, we also use MapReduce framework in this work, which is introduced by Dean and Ghemawat [8]. It is used an associated implementation for processing and generating large data sets. The MapReduce programming model has been successfully used at Google for many different purposes.",0,,False
69,3. MAPREDUCE,1,MAP,True
70,"As number of data such as web pages, web request logs, and so on grows rapidly, applications have to be distributed across thousands of machines in order to finish in time. Bulk-synchronous parallel (BSP) model [27] and some higherlevel abstractions(MPI [12]) have been supported programmers to write parallel programs. However, because of its higher-level abstractions, programmers usually spend too much time on details. MapReduce [8], which is difference from these systems, exploits a restricted programming model to parallelize the user program automatically. And the transparent fault-tolerance and load balancing are also provided, because of the restrictions.",1,ad,True
71,"The key concept behind MapReduce is inspired by the map and reduce primitives present in many functional languages. Dean and Ghemawat [8] presented the observation that most information processing computations share the same two-stage structure, which contains map and reduce operations. The map operation is applied to every logical ""record"" of input to compute a set of intermediate key/value pairs. Then the reduce operation is applied to all the values that shared the same key, in order to combine the derived data. Figure 3 shows the two-stage structure.",0,,False
72,"Under this framework, the computation takes a set of input key/value pairs, and produces a set of output key/value pairs. A programmer only needs to implement two opera-",0,,False
73,input input input input,0,,False
74,map map map map,0,,False
75,key-value pairs,0,,False
76,key-value pairs,0,,False
77,key-value pairs,0,,False
78,key-value pairs,0,,False
79,Group &,0,,False
80,Sort,0,,False
81,reduce reduce reduce,0,,False
82,output output output,0,,False
83,Figure 3: The basic structure of MapReduce,0,,False
84,tions: map and reduce. The intermediate key/value pairs will be grouped and sorted by the key automatically.,0,,False
85,"Many different implementations of MapReduce interface are available now. Google's MapReduce implementation is coupled with Google File System (GFS) [10], a kind of distributed file system. Apache's MapReduce implementation, Hadoop3, which follows the same architecture, uses a distributed file system named Hadoop Distributed File System (HDFS) to store data and the intermediate results. Hadoop tries to schedule the MapReduce computation tasks to the node where the data locates in order to reduce the overall network I/O. Besides Hadoop, MapReduce has also been implemented by many corporations, such as Greenplum, GridGain, Cell Broadband Engine, and so on.",1,ad,True
86,"In this paper, we implement our algorithms under the open-source implementation Hadoop 0.20. HDFS is used to provide the distributed storage.",1,ad,True
87,4. OUR APPROACH,1,AP,True
88,"A partial-duplicate is a pairwise relationship. Given a pair of documents, we need to identify and locate the duplicated parts between them. To make questions simple, we limit granularity to sentence level. Based on this assumption, we propose the algorithm PDC-MR, which converts the partial-duplicate detection task into three MapReduce jobs (illustrated in Figure 4 and Figure 5).",0,,False
89,"1) Indexing: We use a MapReduce job to build a standard inverted index [9] for collections. Signatures used as terms in the inverted index are extracted from each sentences in map procedure. The map procedures emit the signature as the key, and a tuple consists of the document id and sentence id. After grouping and sorting, the reduce procedures take the tuples as input and write out the inverted index to the disk. Since signatures would highly impact the final result, a detail description of it will be given in the Section 4.1.",0,,False
90,"2) Sentence Duplication Detecting: Jaccard coefficient is used to measure the similarities between sentences. If the Jaccard similarity between a sentence pair is over a threshold, they are considered duplicates. Another MapReduce job is used to detect the sentence duplicates. The map procedures read the inverted index from disks and emit a pair of sentences which both contain a same signature as the key. After grouping and sorting, all signature ids belonging to the same sentence pair are brought together. The reduce procedures take them as inputs, and emit the sentence duplications. The procedure is shown in the right of Figure 4.",1,ad,True
91,3http://hadoop.apache.org/,1,ad,True
92,677,0,,False
93,d 1,0,,False
94,map,0,,False
95,d 2,0,,False
96,map,0,,False
97,d 3,0,,False
98,map,0,,False
99,ds 11,0,,False
100,ds 12,0,,False
101,ds 13,0,,False
102,ds 14,0,,False
103,f ff 1 23,0,,False
104,ff 3 4,0,,False
105,fff 1 4 8,0,,False
106,f 2,0,,False
107,ds 21,0,,False
108,ds 22,0,,False
109,ds 23,0,,False
110,ff 5 6,0,,False
111,f ff 2 37,0,,False
112,ff 1 4,0,,False
113,ds 31,0,,False
114,ds 32,0,,False
115,ds 33,0,,False
116,ds 34,0,,False
117,f 8,0,,False
118,f ff 3 79,0,,False
119,ff 3 4,0,,False
120,ff 2 10,0,,False
121,Group &,0,,False
122,Sort,0,,False
123,f,0,,False
124,ds ds ,0,,False
125,1,0,,False
126,11 13,0,,False
127,f,0,,False
128,ds ds ,0,,False
129,2,0,,False
130,11 14,0,,False
131,f,0,,False
132,ds ds ,0,,False
133,3,0,,False
134,11 12,0,,False
135,f,0,,False
136,ds ds ,0,,False
137,4,0,,False
138,12 13,0,,False
139,f ds,0,,False
140,5,0,,False
141,21,0,,False
142,f ds,0,,False
143,6,0,,False
144,21,0,,False
145,f ds ds,0,,False
146,7,0,,False
147,22 32,0,,False
148,f ds ds,0,,False
149,8,0,,False
150,31 13,0,,False
151,f ds,0,,False
152,9,0,,False
153,32,0,,False
154,f ds,0,,False
155,10,0,,False
156,34,0,,False
157,reduce reduce reduce reduce reduce,0,,False
158,f ds ds ,0,,False
159,1,0,,False
160,11 13,0,,False
161,f,0,,False
162,ds ds ,0,,False
163,2,0,,False
164,11 14,0,,False
165,f,0,,False
166,ds ds ,0,,False
167,3,0,,False
168,11 12,0,,False
169,f,0,,False
170,ds ds ,0,,False
171,4,0,,False
172,12 13,0,,False
173,f ds,0,,False
174,5,0,,False
175,21,0,,False
176,f ds,0,,False
177,6,0,,False
178,21,0,,False
179,f ds ds,0,,False
180,7,0,,False
181,22 32,0,,False
182,f ds ds,0,,False
183,8,0,,False
184,31 13,0,,False
185,f ds,0,,False
186,9,0,,False
187,32,0,,False
188,f ds,0,,False
189,10,0,,False
190,34,0,,False
191,Indexing,0,,False
192,map map map map map map map map map map,0,,False
193,(d s d s ) 11 13,0,,False
194,(d s d s ) 11 22,0,,False
195,(d s d s ) 13 22,0,,False
196,(d s d s ) 11 14,0,,False
197,(d s d s ) 11 34,0,,False
198,(d s d s ) 14 34,0,,False
199,(d s d s ) 11 12,0,,False
200,(d s d s ) 11 22,0,,False
201,(d s d s ) 11 32 ,0,,False
202,Group &,0,,False
203,Sort,0,,False
204,(d s d s ) 1 11 12,0,,False
205,(d s d s ) 1 11 13,0,,False
206,(d s d s ) 1 11 14,0,,False
207,(d s d s ) 0 11 21,0,,False
208,(d s d s ) 2 11 22,0,,False
209,(d s d s ) 1 11 23,0,,False
210,(d s d s ) 0 11 31,0,,False
211,(d s d s ) 1 11 32,0,,False
212,(d s d s ) 1 11 33,0,,False
213,(d s d s ) 1 11 34,0,,False
214,reduce reduce,0,,False
215,Sentence Duplication Detecting,0,,False
216,Figure 4: Detecting sentence duplication of a toy collection of 3 documents.,0,,False
217,d 2,0,,False
218,d 1,0,,False
219,d 3,0,,False
220,d 1,0,,False
221,d 3,0,,False
222,d 2,0,,False
223,dj,0,,False
224,S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S1,0,,False
225,S2,0,,False
226,S3,0,,False
227,S4,0,,False
228,di S5,0,,False
229,S6,0,,False
230,S7,0,,False
231,S8,0,,False
232,S9,0,,False
233,Figure 5: The sequence matching strategy,0,,False
234,"3) Sequence Matching: With the results of sentence duplicate detection, matrixes representing sentence duplicates for each pair of documents are generated. Figure 5 shows an example of the sentence duplicates between page di and page dj. The dot plots in the figure represents duplicated sentence pairs. The sequences of duplicated sentences are partial duplications we try to extract and locate. Based on that, the problem can be straightly converted to the sequence matching task, which aims to find all diagonals in the matrix. We also use a MapReduce job to do that. The outputs of the job include partial duplicates among documents and their locations. Since numerous of document pairs are needed to be processed, Section 4.3 gives detail descriptions about the efficient sequence matching method.",0,,False
235,4.1 Signatures,0,,False
236,"As described in the Section 2, a number of signature extraction methods have been proposed for document level near-duplicate detections. Since the average number of words per sentence is much fewer than document, we introduce several signature methods in this section.",0,,False
237,4.1.1 Shingles,0,,False
238,"Shingles is the simplest method, which is proposed by Broder et al. [5]. It tokenizes documents into a list of words and extracts all word sequences of adjacent words to represent the document. ""n-shingles"" represents the number of n adjacent words in a shingle. As the shingles uses all chunks, it might not be suitable for large collections because of too many signatures.",1,ad,True
239,4.1.2 I-Match,0,,False
240,"I-Match [7] uses SHA1 hash function over concatenation of terms filtered by stopwords and infrequent terms. It hinges on the assumption that removal of very infrequent terms and stop words results in good document representations for the near-duplicate detection task. Although the computationally of I-Match is attractive, it usually unstable even to small perturbations of content.",0,,False
241,4.1.3 SpotSigs,0,,False
242,"SpotSigs [26] combines stopword antecedents with short chains of adjacent content terms. A spotsig si of a location in a document consists of a chain of words that follow an antecedent word ai at a fixed spot distance di. Antecedent words are predefined and typically chosen to be stop words. Experimental results in [26] show that SpotSigs with five common terms as antecedent achieve better result than a full stopword list. However, we observe that signatures can not be extracted from more than 15.2% sentences in English collection with the five common terms. The experimental results about selecting the number of antecedents are shown in Section 5.3.",1,ad,True
243,4.2 Sentence Duplication Detection,0,,False
244,"As shown in Figure 4, the sentence duplicate detection algorithm, which is implemented by a MapReduce job, extracts near duplicated sentence pairs whose Jaccard similarity are higher than a threshold. Sentences are represented by a group of signatures. The upper bounds for Jaccard similarity [26] is",0,,False
245,"J(A, B)",0,,False
246,",",0,,False
247,|A |A,0,,False
248,B| B|,0,,False
249,"min (|A|, |B|) max (|A|, |B|)",0,,False
250,(1),0,,False
251,"For |A|  |B|, we can get:",0,,False
252,"J(A, B)",0,,False
253,|A| |B|,0,,False
254,(2),0,,False
255,With the upper bound and vector representation of docu-,0,,False
256,"ments, we observe that only similar length sentence pairs",0,,False
257,"can be near duplicate. If we set the threshold to  , sen-",0,,False
258,tence,0,,False
259,pairs,0,,False
260,where,0,,False
261,|A| |B|,0,,False
262,  can be safely removed.,0,,False
263,Based,0,,False
264,"on that, the pseudo-code of this method is show in Algo-",0,,False
265,rithm 1. The input of the procedure map is the signature,0,,False
266,"id (sigi) and associated postings list ([d1s1, d2s2, ...], where disj represents document id and sentence id). Inside each mapper, all candidate sentence pairs, which follow the upper",0,,False
267,678,0,,False
268,"bound of the Jaccard similarity, are emitted to the key-value pair ( disj, dksl , sigi). After grouping and sorting, all signature ids belonging to the same sentence pair are brought together. With the list, Jaccard similarity can be easily calculated. The procedure reduce takes the sentence pair and corresponding list as input and emit the duplication judgments based on the Jaccard similarity and predefined threshold  .",0,,False
269,Algorithm 1 Pseudo-code of sentence duplication detection algorithm in MapReduce,0,,False
270,"MAP(sigi, [d1s1, d2s2, ...])",1,MAP,True
271,"1: for all disj  [d1s1, d2s2, ...] do",0,,False
272,"2: for all dksl  [d1s1, d2s2, ...] do",0,,False
273,3:,0,,False
274,"if disj , dksl then",0,,False
275,4:,0,,False
276,if,0,,False
277,(,0,,False
278,|disj |  |dksl|,0,,False
279,and,0,,False
280,|dk sl| |disj |,0,,False
281,),0,,False
282,or,0,,False
283,(,0,,False
284,|disj |  |dksl|,0,,False
285,and,0,,False
286,|disj | |dk sl|,0,,False
287,),0,,False
288,then,0,,False
289,5:,0,,False
290,"EMIT( disj , dksl , sigi)",0,,False
291,6:,0,,False
292,end if,0,,False
293,7:,0,,False
294,end if,0,,False
295,8: end for,0,,False
296,9: end for,0,,False
297,"REDUCE( disj , dksl , [sig1, sig2, ...])",1,DUC,True
298,1: if,0,,False
299,|di sj |di sj,0,,False
300,dk sl| dk sl|,0,,False
301,<,0,,False
302,then,0,,False
303,"2: EMIT( di, dk , sj , sl )",0,,False
304,3: end if,0,,False
305,4.3 Sequence Matching,0,,False
306,"As described in the previous sections, the sequence matching procedure aims to find all diagonals in the matrix. Algorithm 2 shows the pseudo-code of the MapReduce job. Inputs to the procedure map consists document pairs (keys, di, dj ) and a corresponding list of duplicated sentence pairs between these documents (values, [ sk, sl , sp, sq , ...]). For each duplicated sentence pair, the longest diagonal whose root is the pair is extracted and emitted. Extracted sentence pairs will be eliminated.  is used as the threshold for the diagonal length. The final output, which contains document pair, respective start positions, and length, are generated in the procedure reduce. In practical, the reducer can also be merged into the mapper to trim the intermediate data.",0,,False
307,5. EXPERIMENTS,0,,False
308,5.1 Collections,0,,False
309,"We evaluate our methods with four corpora WT10g, TREC Blogs064, SogouT 2.05, and ClueWeb09-T09B6. Table 1 shows the statistics of the four collections. WT10g is used by TREC Web tracks, which contains more than 1.6 million documents collected from about 11,000 servers. Besides that, BLOGS06 corpus, which is used by TREC 2006 and TREC 2007 blog tracks, is also selected to evaluate systems. It is a big sample of the blogsphere, and contains more than 3.2 millions documents including spam as well as",1,corpora,True
310,4http://ir.dcs.gla.ac.uk/test collections 5http://www.sogou.com/labs/dl/t.html 6http://boston.lti.cs.cmu.edu/Data/clueweb09/,0,,False
311,Algorithm 2 Pseudo-code of sequence matching algorithm in MapReduce,0,,False
312,"MAP( di, dj , [ sk, sl , sp, sq , ...])",1,MAP,True
313,"1: P  [ sk, sl , sp, sq , ...]",0,,False
314,2: 3:,0,,False
315,forDall DsiIsAj GinOPNAdLoEXTRACT(sisj ),0,,False
316,4: if |D| >  then,0,,False
317,5:,0,,False
318,"EMIT( di, dj , D)",0,,False
319,6:,0,,False
320,P P -D,0,,False
321,7: end if,0,,False
322,8: end for,0,,False
323,DIAGONALEXTRACT(sisj ),0,,False
324,1: while sisj in P do 2: D  D sisj 3: si  si+1 4: sj  sj+1 5: end while,0,,False
325,"REDUCE( di, dj , [D1, D2, ...])",1,DUC,True
326,"1: for all D  [D1, D2, ...] do 2: EMIT( di, dj , Start.di, Start.dj, D.Length ) 3: end for",0,,False
327,"possibly non-blogs. SogouT 2.0 corpus is made up of 24.8M Chinese Web pages and crawled from all domains. TREC Category B dataset(ClueWeb09-T09B), which is a subset of the ClueWeb09, contains 50 million English pages and has been used in various TREC tracks.",1,blog,True
328,Table 1: Statistics of the evaluation corpora,1,corpora,True
329,Corpus WT10g Blogs06 SogouT 2.0 ClueWeb09-T09B,1,WT,True
330,Language English English Chinese English,0,,False
331,"#Docs 1,692,096 3,215,171 24,833,521 50,220,423",0,,False
332,Size 11GB 88.8GB 372.5GB 490.4GB,0,,False
333,5.2 Implementation and Setup,0,,False
334,"All the MapReduce jobs were implemented in Java for Hadoop framework. HDFS was used to provide the distributed storage. All experiments were evaluated on a 16 machines cluster. Each machine contains two Xeon quad core CPUs (2.0GHz), and 32GB RAM. Software stack of the experiments used Java 1.6 and Hadoop version 0.20. For web page cleaning, we just removed all HTML markup tags from the collections. Since the impact of sentence boundary detection's performance would not be heavy and a number of manually written rules can achieve good result [1] with little attractive computational consumption, we used around 50 rules to do that in our experiment.",1,ad,True
335,5.3 Comparison of Signatures,0,,False
336,"In order to compare the performances of different signatures, we manually select 2000 documents, which contain 57135 sentences totaly, from ClueWeb09-T09B (Oracle Eng is used to represent the corpus in the following section for simple). For Chinese corpus SogouT, we also constructed a manually labeled corpus (Oracle Chn), which contains",1,ClueWeb,True
337,679,0,,False
338,F1 Score F1 Score,0,,False
339,F1 Score,0,,False
340,5 10 20 30 40 50 60 70 80 90 100 200 500,0,,False
341,F1 Score,0,,False
342,10 100 500 1K 2K 5K 10K 15K 20K,0,,False
343,Oracle Chn,0,,False
344,1,0,,False
345,0.9,0,,False
346,0.8,0,,False
347,0.7,0,,False
348,0.6,0,,False
349,0.5,0,,False
350,0.4,0,,False
351,2-Shingles,0,,False
352,0.3,0,,False
353,3-Shingles,0,,False
354,4-Shingles 0.2,0,,False
355,0.1 1,0,,False
356,0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
357,Oracle Eng,0,,False
358,1,0,,False
359,0.9,0,,False
360,0.8,0,,False
361,0.7,0,,False
362,0.6,0,,False
363,0.5,0,,False
364,0.4,0,,False
365,2-Shingles,0,,False
366,0.3,0,,False
367,3-Shingles,0,,False
368,4-Shingles 0.2,0,,False
369,0.1 1,0,,False
370, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
371,Figure 6: Shingles' performances of varying the threshold  for corpora Oracle Eng and Oracle Chn,1,corpora,True
372,F1 Score F1 Score,0,,False
373,Oracle Chn,0,,False
374,1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
375,0,0,,False
376,Oracle Eng,0,,False
377,1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
378,0,0,,False
379,0.0-1.0 0.1-1.0 0.2-1.0 0.3-1.0 0.4-1.0 0.5-1.0 0.6-1.0 0.7-1.0 0.8-1.0 0.9-1.0 0.0-1.0 0.1-1.0 0.2-1.0 0.3-1.0 0.4-1.0 0.5-1.0 0.6-1.0 0.7-1.0 0.8-1.0 0.9-1.0,0,,False
380,IDF,0,,False
381,IDF,0,,False
382,Figure 7: I-Match' performances of varying IDF for corpora Oracle Eng and Oracle Chn,1,corpora,True
383,80516 sentences extracted from 2000 documents. Six in-,0,,False
384,dividuals were asked to label them. The average Kappa,0,,False
385,"statistic among them is around 91.6%, which shows good",0,,False
386,agreement.,0,,False
387,"Figure 6 shows the performances comparison of 2-Shingles,",0,,False
388,"3-Shingles, and 4-Shingles. We observe that 4-Shingles con-",0,,False
389,sistently performs better than 2-Shingles and 3-Shingles in,0,,False
390,both English and Chinese collections. Different with results,0,,False
391,"in document level [18, 26], threshold  , 0.9 achieves the",0,,False
392,best performance in both of the collections. The reason is,0,,False
393,that around 91% of duplicated sentences in Oracle Chn and,0,,False
394,89% of them in Oracle Eng are exactly same with each other,0,,False
395,"in our evaluation collections. However, this kind of factor is",0,,False
396,rare in the document level.,0,,False
397,Figure 7 shows the performances of I-Match with different,0,,False
398,IDF ranges. Tokens exceeding IDF range were filtered. We,0,,False
399,use,0,,False
400,idfi,0,,False
401,",",0,,False
402,log(N/dfj ) log(N ),0,,False
403,to,0,,False
404,calculate,0,,False
405,the,0,,False
406,IDF,0,,False
407,value,0,,False
408,for,0,,False
409,token,0,,False
410,"i,",0,,False
411,"where N is the corpus size, dfj is the document frequency",0,,False
412,of the token. Since the similarities calculated by I-Match,0,,False
413,"are either 0 or 1, the threshold  does not need to adjusted.",1,ad,True
414,"The best result is achieved by [0.1, 1.0] in both Oracle Chn",0,,False
415,and Oracle Eng. It means that most of the tokens should,0,,False
416,be kept and used to calculate the hash result. The main,0,,False
417,reason is that sentences usually contain a small number of,0,,False
418,tokens and most of the duplicated sentences are same with,0,,False
419,each other. When tokens whose IDF is lower than 0.4 are,0,,False
420,"filtered, most of the sentences have less than 2 tokens left",0,,False
421,"in Oracle Chn. Because of that, the recall for [0.4, 1.0] is",0,,False
422,"almost perfect 100%, but the precision is only 1.4%.",0,,False
423,The impacts of the number of antecedents for Spotsig are,0,,False
424,shown in Figure 8. The x-axis represents the number of an-,0,,False
425,tecedents and varies from 5 to 500 in Oracle Chn and 10 to,0,,False
426,20K in Oracle Eng. The numbers below each point represent,0,,False
427,the average number of signatures per sentences with corre-,0,,False
428,sponding antecedents. It shows that the antecedents' num-,0,,False
429,Oracle Chn,0,,False
430,1,0,,False
431,3.8 4.2 4.5 4.8 5.0 6.9 9.0 0.9,0,,False
432,2.6 3.0 3.5,0,,False
433,0.8,0,,False
434,2.1 1.4,0,,False
435,0.7 0.9,0,,False
436,0.6,0,,False
437,# Antecedent,0,,False
438,Oracle Eng,0,,False
439,1,0,,False
440,0.9,0,,False
441,3.4 3.7 3.8 3.9,0,,False
442,0.8,0,,False
443,3.0,0,,False
444,0.7,0,,False
445,2.6,0,,False
446,0.6,0,,False
447,2.2,0,,False
448,0.5 0.7,0,,False
449,1.5,0,,False
450,0.4,0,,False
451,0.3,0,,False
452,0.2,0,,False
453,0.1,0,,False
454,# Antecedent,0,,False
455,Figure 8: Spotsigs' performances of varying the number of antecedents for corpora Oracle Eng and Oracle Chn,1,corpora,True
456,F1 Score,0,,False
457,Oracle Chn,0,,False
458,1,0,,False
459,0.9,0,,False
460,0.8,0,,False
461,0.7,0,,False
462,0.6,0,,False
463,0.5,0,,False
464,0.4,0,,False
465,"# Antecedent , 5",0,,False
466,0.3,0,,False
467,"# Antecedent, 60",0,,False
468,"# Antecedent , 100",0,,False
469,0.2,0,,False
470,0.1 1,0,,False
471, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
472,F1 Score,0,,False
473,Oracle Eng,0,,False
474,1,0,,False
475,0.9,0,,False
476,0.8,0,,False
477,0.7,0,,False
478,0.6,0,,False
479,0.5,0,,False
480,0.4,0,,False
481,"# Antecedent , 1K",0,,False
482,0.3,0,,False
483,"# Antecedent , 5K",0,,False
484,"# Antecedent, 10K",0,,False
485,0.2,0,,False
486,0.1 1,0,,False
487, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
488,Figure 9: Spotsigs' performances of varying the threshold  for corpora Oracle Eng and Oracle Chn,1,corpora,True
489,"ber would highly impact the performance. We think that the main reason is that sentences cannot be well represented by a small number of signatures. By trading-off between efficiency and effectiveness, we choose # antecedent ,"" 60 to achieve 95.2% F1 score in Chinese collection. For English one, we choose # antecedent "","" 10K. We observe that the number of antecedents is much different between English and Chinese collections. However the best results are both achieved at the similar average number of signatures per sentence. It shows that a sentence can be well described by around 4 signatures. Figure 9 shows the performances with different thresholds. Comparing with shingles, spotsigs show the similar trends. We achieve the best result with  "", 0.9 in Oracle Chn and Oracle Eng.",1,ad,True
490,"In summary, 4-Shingles achieve the best result in the sentence level duplicate detection. However, the performances of 2-Shingles, 3-Shingles, Spotsigs, and I-Match are comparable. The parameters used for sentence level are much different with document level ones. We think that it is caused by the characters of sentence collections, such as length, standard for labeling and so on. We also observe that although all three signature extraction methods are highly tunable, the results prove to be robust for a large variety of parameters.",0,,False
491,5.4 Effectiveness Evaluation,0,,False
492,"After evaluating three different methods to extract duplicated sentences, we now consider the impact of sequence matching. Table 2 summaries the sequence matching results with different signatures. The configurable parameters IDF range, similarity threshold  , and # antecedent are selected by the previous experiments and listed in the brackets. We use Precision, Recall, and F1-Score as our choice of evaluation metric to measure how accurately the dupli-",0,,False
493,680,0,,False
494,"Table 2: Summary of sequence matching results with Shingles, I-Match and Spotsigs for Oracle sets",0,,False
495,Corpus Oracle Chn,0,,False
496,Oracle Eng,0,,False
497,Signature,0,,False
498,"2-Shingles( , 0.9) 3-Shingles( , 0.9) 4-Shingles( , 0.9) I-Match(IDF,""[0.1,1.0]) Spotsigs(#A"",""60,  "", 0.9)",0,,False
499,"2-Shingles( , 0.9) 3-Shingles( , 0.9) 4-Shingles( , 0.9) I-Match(IDF,""[0.1,1.0]) Spotsigs(#A"",""10K,  "", 0.9)",0,,False
500,P,0,,False
501,0.936 0.937 0.942 0.935 0.938,0,,False
502,0.987 0.987 0.987 0.985 0.981,0,,False
503,R,0,,False
504,0.937 0.937 0.942 0.938 0.930,0,,False
505,0.966 0.966 0.967 0.960 0.965,0,,False
506,F1,0,,False
507,0.936 0.937 0.942 0.937 0.934,0,,False
508,0.977 0.977 0.977 0.972 0.973,0,,False
509,"cation is located. From analyzing the Oracle collections, we observe that lengths of most duplications are bigger than three. Hence, , which is the threshold of diagonal length, is set to 3 in all the experiments. We observe that the final results are heavily related to the performances of sentence duplicate detection. Since the performances of 2-Shingles, 3-Shingles, 4-Shingles, I-Match and Spotsigs are similar, the final F1-scores do not have significant difference. In order to evaluate the impact of , we also evaluate the performances at  ,"" 1. In Oracle Eng, the F1-score of 2-Singles is only 0.952, which is significantly 7 different from the results shown in the Table 2. 3-Shingles, 4-Shingles, I-Match and Spotsigs have the similar results. By trading-off efficiency and effectiveness, we determine to use I-Match method to extract signatures in our method.""",1,ad,True
510,"Figure 10 summarizes our results of PDC-MR versus the document level near-duplicate detection. For convenient comparison among copra, the top one million documents of each corpus are used in this experiment. For document level near-duplicate detection, the state-of-the-art method Spotsig is used, whose parameters are set up based on [26]. The y-axis represents the number of unique documents. The bottom parts of each bar represent results of Spotsig. The top parts represent the number of documents which can be detected by our PDC-MR method but can not be detected by document level Spotsig. In WT10g, Spotsig extracts around 31K documents which contain duplications in the same corpus. They compose more than 1.89 million duplication pairs. Besides those documents, through our method, another 94K documents which contain partial-duplicates are detected. In Blogs06, ClueWeb09-T09B, and Chinese corpus SogouT2.0, we get similar results. It shows that partial-duplications are common in web collections and our proposed method can effectively detect them.",1,WT,True
511,"In order to evaluate the validity of the extracted partial duplicates, we random select 200 documents from the detection results of each corpus and manually classify them into four types as listed in the Table 3. ""News Collection"" and ""Multiple Page"" are described in the Section 1. ""Partial Quotation"" represents all types of short piece of text quotation. Banner, copyright notice, navigation bar, and other non-content parts are classified into ""Other"". The results show that ""Partial quotation"" account for the majority of all instances. The average length of this kind of duplications",0,,False
512,7The paired  -test (<0.05) is used to measure the significance.,0,,False
513,Table 3: Partial duplicates in the web collections,0,,False
514,Corpus,0,,False
515,WT10g Blogs06 SogouT 2.0 ClueWeb09-T09B,1,WT,True
516,News Collection,0,,False
517,4% 2.5% 10% 3%,0,,False
518,Multiple Page,0,,False
519,8.5% 5% 18% 7%,0,,False
520,Partial Quotation,0,,False
521,80% 79% 60% 58%,0,,False
522,Other,0,,False
523,7.5% 13.5% 12% 32%,0,,False
524,140K 120K 100K,0,,False
525,80K 60K 40K 20K,0,,False
526,0K,0,,False
527,"21,397 31,486 WT10g",1,WT,True
528,"70,930",0,,False
529,"12,261",0,,False
530,"44,862",0,,False
531,"58,134",0,,False
532,"60,814",0,,False
533,"13,657",0,,False
534,Blogs06,1,Blogs06,True
535,SogouT 2.0,1,Sogou,True
536,Spotsig(Doc Level),0,,False
537,PDC-MR,0,,False
538,ClueWeb09-T09B,1,ClueWeb,True
539,Figure 10: Summary of PDC-MR vs. document level Spotsig in four web collections,0,,False
540,"is around 6 sentences. While the average length of document is more than 23 sentences in SogouT 2.0 and 26 sentences in WT10g. Thus those partial duplications can not be easily detected by the existing document level detection methods. The results show that most of extracted partial duplications are useful and meaningful. Except ClueWeb09T09B, the percentages of ""Other"" type in other collections are less than 15%. While, there are 32% instances belonging to this type in ClueWeb09-T09B. We think the main reason is that ClueWeb09-T09B is not well cleaned and contains lots of advertisements.",1,Sogou,True
541,5.5 Efficiency Evaluation,0,,False
542,"Figure 11 plots the running times of spotsigs based nearduplicate detection and our proposed PDC-MR method for different corpus size. ClueWeb09-T09B is used in this experiment. All Hadoop jobs in the efficiency experiments were configured with 60 mappers and 60 reducers. The graph suggests that although the number of sentence is huger than the number of documents, our proposed method is more efficient than Spotsig. We think that it makes sense since I-match is efficient and its performance is also comparable in sentence level.",1,ClueWeb,True
543,6. CONCLUSIONS,0,,False
544,"This paper presents our work on partial-duplicate detection task. A number of factors like news collection, multiple pages, threads in forums, plagiarize sentences, non-cleaned web pages, and sentences/paragraphs quotation belong to it. In order to address this problem, we propose a novel MapReduce algorithm, which converts the task into three MapReduce jobs. Except for the similarities between documents, the algorithm can simultaneously output the positions where the duplicated parts occur. The contributions of the work include both empirical analysis of signatures for",1,ad,True
545,681,0,,False
546,Runing TIme (seconds ),0,,False
547,16K,0,,False
548,14K 12K,0,,False
549,Spotsig(Doc Level) PDC-MR,0,,False
550,10K,0,,False
551,8K,0,,False
552,6K,0,,False
553,4K,0,,False
554,2K,0,,False
555,0K,0,,False
556,1,0,,False
557,2,0,,False
558,3,0,,False
559,4,0,,False
560,5,0,,False
561,# DOC (millions),0,,False
562,Figure 11: Running time of the PDC-MR and Spotsig with different corpus size,0,,False
563,sentence and algorithm design. Experimental results in four real-world web collections show that the proposed method can be effectively and efficiently used to detect partial- and near-duplicate.,0,,False
564,7. ACKNOWLEDGMENTS,0,,False
565,"The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Program (2010CB327906), Shanghai Leading Academic Discipline Project (B114), Doctoral Fund of Ministry of Education of China (200802460066), and Shanghai Science and Technology Development Funds (08511500302).",1,ad,True
566,8. REFERENCES,0,,False
567,"[1] J. Aberdeen, J. Burger, D. Day, L. Hirschman, P. Robinson, and M. Vilain. Mitre: description of the alembic system used for muc-6. In Proceedings of MUC6, pages 141­155, Morristown, NJ, USA, 1995.",0,,False
568,"[2] M. Bendersky and W. B. Croft. Finding text reuse on the web. In WSDM '09, pages 262­271, New York, NY, USA, 2009. ACM.",0,,False
569,"[3] A. Z. Broder. On the resemblance and containment of documents. In Proceedings of SEQUENCES 1997, page 21, Washington, DC, USA, 1997. IEEE Computer Society.",0,,False
570,"[4] A. Z. Broder. Identifying and filtering near-duplicate documents. In Proceedings of COM 2000, pages 1­10, London, UK, 2000.",0,,False
571,"[5] A. Z. Broder, S. C. Glassman, M. S. Manasse, and G. Zweig. Syntactic clustering of the web. Comput. Netw. ISDN Syst., 29(8-13):1157­1166, 1997.",0,,False
572,"[6] M. S. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings of STOC 2002, pages 380­388, New York, NY, USA, 2002. ACM.",0,,False
573,"[7] A. Chowdhury, O. Frieder, D. Grossman, and M. C. McCabe. Collection statistics for fast duplicate document detection. ACM Trans. Inf. Syst., 20(2):171­191, 2002.",0,,False
574,"[8] J. Dean and S. Ghemawat. Mapreduce: Simplified data processing on large clusters. In Proceedings of OSDI 2004, San Francisco, CA, USA, 2004.",0,,False
575,"[9] W. B. Frakes and R. A. Baeza-Yates. Information Retrieval: Data Structures & Algorithms. Prentice-Hall, 1992.",0,,False
576,"[10] S. Ghemawat, H. Gobioff, and S.-T. Leung. The google file system. SIGOPS Oper. Syst. Rev., 37(5):29­43, 2003.",0,,False
577,"[11] A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In VLDB '99, pages 518­529, San Francisco, CA, USA, 1999.",0,,False
578,"[12] W. Gropp, E. Lusk, and A. Skjellum. Using MPI: portable parallel programming with the message-passing interface. MIT Press, Cambridge, MA, USA, 1994.",0,,False
579,"[13] M. Henzinger. Finding near-duplicate web pages: a large-scale evaluation of algorithms. In SIGIR '06, pages 284­291, New York, NY, USA, 2006. ACM.",0,,False
580,"[14] S. C. Herring, L. A. Scheidt, I. Kouper, and E. Wright. A longitudinal content analysis of weblogs: 2003-2004. Blogging, Citizenship and the Future of Media, pages 3­20, 2006.",1,blog,True
581,"[15] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse of dimensionality. In STOC '98, pages 604­613, New York, NY, USA, 1998. ACM.",0,,False
582,"[16] O. Kolak and B. N. Schilit. Generating links by mining quotations. In Proceedings of HT 2008, pages 117­126, New York, NY, USA, 2008. ACM.",0,,False
583,"[17] A. Kolcz, A. Chowdhury, and J. Alspector. Improved robustness of signature-based near-replica detection via lexicon randomization. In Proceedings of SIGKDD 2004, pages 605­610, New York, NY, USA, 2004. ACM.",0,,False
584,"[18] J. Lin. Brute force and indexed approaches to pairwise document similarity comparisons with mapreduce. In Proceedings of SIGIR '09, pages 155­162, New York, NY, USA, 2009. ACM.",0,,False
585,"[19] G. S. Manku, A. Jain, and A. Das Sarma. Detecting near-duplicates for web crawling. In WWW '07, pages 141­150, New York, NY, USA, 2007. ACM.",0,,False
586,"[20] K. Muthmann, W. M. Barczyn´ski, F. Brauer, and A. L¨oser. Near-duplicate detection for web-forums. In IDEAS '09, pages 142­151, New York, NY, USA, 2009. ACM.",0,,False
587,"[21] R. Ramakrishnan and A. Tomkins. Toward a peopleweb. Computer, 40(8):63­72, 2007.",0,,False
588,"[22] S. Schleimer, D. S. Wilkerson, and A. Aiken. Winnowing: local algorithms for document fingerprinting. In SIGMOD '03, pages 76­85, New York, NY, USA, 2003. ACM.",0,,False
589,"[23] J. Seo and W. B. Croft. Local text reuse detection. In SIGIR '08, pages 571­578, New York, NY, USA, 2008. ACM.",0,,False
590,"[24] N. Shivakumar and H. Garcia-Molina. Scam: A copy detection mechanism for digital documents. In Digitial Library, 1995.",0,,False
591,"[25] N. Shivakumar and H. Garcia-Molina. Finding near-replicas of documents and servers on the web. In Proceedings of WebDB 1998, pages 204­212, London, UK, 1999. Springer-Verlag.",0,,False
592,"[26] M. Theobald, J. Siddharth, and A. Paepcke. Spotsigs: robust and efficient near duplicate detection in large web collections. In SIGIR '08, pages 563­570, New York, NY, USA, 2008. ACM.",0,,False
593,"[27] L. G. Valiant. A bridging model for parallel computation. Commun. ACM, 33(8):103­111, 1990.",0,,False
594,682,0,,False
595,,0,,False
