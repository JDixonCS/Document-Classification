,sentence,label,data,regex
0,Learning Hidden Variable Models for Blog Retrieval,0,,False
1,Mengqiu Wang,0,,False
2,Computer Science Department Stanford University,0,,False
3,"Stanford, CA 94305, USA",0,,False
4,mengqiu@cs.stanford.edu,0,,False
5,ABSTRACT,0,,False
6,"We describe probabilistic models that leverage individual blog post evidence to improve blog seed retrieval performances. Our model offers a intuitive and principled method to combine multiple posts in scoring a whole blog site by treating individual posts as hidden variables. When applied to the seed retrieval task, our model yields state-of-the-art results on the TREC 2007 Blog Distillation Task dataset.",1,blog,True
7,Categories and Subject Descriptors,0,,False
8,H.3.3 [Information Storage and Retrieval]: Retrieval Models,0,,False
9,General Terms,0,,False
10,"Design, Algorithms, Experimentation, Performance",0,,False
11,Keywords,0,,False
12,"Learning to Rank, Passage Retrieval, Blog Retrieval",0,,False
13,1. INTRODUCTION,1,DUC,True
14,"In blog seed retrieval tasks, we are interested in finding blogs with relevant and recurring interests for given topics. Rather than ranking individual blog posts, whole sites are ranked (i.e. all posts within a blog). We propose two discriminatively trained probabilistic models that model individual posts as hidden variables.",1,blog,True
15,2. PROBABILISTIC PASSAGE MODELS,0,,False
16,"We make a modeling assumption that given a set of topranked passages of a document, the document is relevant if any one of the passages is relevant.",0,,False
17,The first independent model (IND) assumes that the relevance of a specific top-ranked passage si is independent of the relevance of any other passage in s. We use the logistic function to model the relevance of a passage. Our second model (RBM) takes a step further and exploit the correlations among individual passages in a Restricted Boltzmann Machine framework.,0,,False
18,"P (z , 0|s) , e-f(s)",0,,False
19,1+e-f (s),0,,False
20,P (z^|s)),0,,False
21,",",0,,False
22,1 Z,0,,False
23,exp(Pi<j,0,,False
24,f,0,,False
25,(si,0,,False
26,",",0,,False
27,sj,0,,False
28,",",0,,False
29,"zi,",0,,False
30,zj,0,,False
31,),0,,False
32,+,0,,False
33,P|s|,0,,False
34,"i,1",0,,False
35,g(si,0,,False
36,",",0,,False
37,zi,0,,False
38,)),0,,False
39,"Copyright is held by the author/owner(s). SIGIR'10, July 19­23, 2010, Geneva, Switzerland. ACM 978-1-60558-896-4/10/07.",0,,False
40,"where f (s) is a feature vector of the passage s, and  is",0,,False
41,"the corresponding weight vector. Z is the partition function computed by summing over all possible relevance assignments. f (si, sj, zi, zj) are passage correlation features (cosine-sim, URL overlapping) and g(si, zi) are passage relevance feature (e.g., rank, score).",0,,False
42,3. BLOG SEED RETRIEVAL,0,,False
43,"We evaluated our models on TREC 2007 Blog Distillation Track dataset. We would first obtain top 5 ranked passages for each document using Indri's LM-based retrieval system, and then apply our model to re-rank each document. Training and testing is done by performing 5-fold cross-validation. We compare our models with four strong baselines. The first two are the Indri language model passage and document retrieval systems (Indri-psg, Indri-doc). The third one is the CMU system, which gives the best performance in TREC 2007 and 2008 evaluations [1]. The last one is the ReDDE federated search algorithm used in [2]. Our IND model showed significant improvements over the Indri passage and document retrieval baselines (58.5% and 9.4% relative improvements). The RBM model gained a small improvement over the IND model, and significantly outperformed the baseline CMU and ReDDE models.",1,TREC,True
44,Baseline,0,,False
45,This work,0,,False
46,Indri-psg 0.2267,0,,False
47,IND,0,,False
48,0.3596,0,,False
49,Indri-doc 0.3284,0,,False
50,RBM,0,,False
51,0.3702,0,,False
52,CMU 0.3385 RBM+cosine sim 0.3779,0,,False
53,ReDDE 0.3150 RBM+url 0.3685,0,,False
54,4. CONCLUSIONS,0,,False
55,"In this paper, we introduced two probabilistic models that model individual blog posts as hidden variables for blog seed retrieval tasks. Our models produced state-of-the-art results on TREC 2007 Blog Distillation dataset.",1,blog,True
56,5. REFERENCES,0,,False
57,"[1] J. Elsas, J. Arguello, J. Callan, and J. Carbonell. Retrieval and feedback models for blog distillation. In Proceedings of TREC, 2007.",1,blog,True
58,"[2] J. Elsas, J. Arguello, J. Callan, and J. Carbonell. Retrieval and feedback models for blog feed search. In Proceedings of SIGIR, 2008.",1,blog,True
59,922,0,,False
60,,0,,False
