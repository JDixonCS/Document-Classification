,sentence,label,data,regex
0,Mining Adjacent Markets from a Large-scale Ads Video Collection for Image Advertising,1,Video,True
1,Guwen Feng,0,,False
2,"Nanjing University Nanjing, Jiangsu, P.R.China",0,,False
3,linvondepp@gmail.com,0,,False
4,"Xin-Jing Wang, Lei Zhang, Wei-Ying Ma",0,,False
5,"Microsoft Research Asia Beijing, P.R.China",0,,False
6,"{xjwang,leizhang,wyma}@microsoft.com",0,,False
7,ABSTRACT,0,,False
8,"The research on image advertising is still in its infancy. Most previous approaches suggest ads by directly matching an ad to a query image, which lacks the power to identify ads from adjacent market. In this paper, we tackle the problem by mining knowledge on adjacent markets from ads videos with a novel Multi-Modal Dirichlet Process Mixture Sets model, which is a unified model of (video frames) clustering and (ads) ranking. Our approach is not only capable of discovering relevant ads (e.g. car ads for a query car image), but also suggesting ads from adjacent markets (e.g. tyre ads). Experimental results show that our proposed approach is fairly effective.",1,ad,True
9,Categories and Subject Descriptors,0,,False
10,I.5.4 [Pattern Recognition]: Applications ­ computer vision. G.3 [Probability and Statistics]: Nonparametric statistics.,0,,False
11,General Terms,0,,False
12,"Algorithms, Performance.",0,,False
13,Keywords,0,,False
14,"Image advertising, adjacent marketing, video retrieval.",1,ad,True
15,1. INTRODUCTION,1,DUC,True
16,"Though image has become an important media in the Web, how to monetize web images is a seldom touched problem. Few research works have been published in the literature. Among them, most of the works suggest directly mapping an ad to an image [2]. They suffer from the vocabulary impedance problem so that if a term does not appear in both an image and an ad' features, no connections will be built between them. The approach of Wang et al. [4] improves this by leveraging the ODP ontology to bridge the vocabulary gap, but it is still limited by the available texts.",1,ad,True
17,"Adjacent marketing means to develop additional items which compliment a customer's needs in some manner, e.g. suggest insurance when one buys a car. The insurance package thus makes up of qualified adjacent markets of cars. A key challenge is to discover the potential adjacent market (e.g. insurance) of a certain",1,ad,True
18, This work was performed in Microsoft Research Asia.,0,,False
19,"Copyright is held by the author/owner(s). SIGIR'10, July 19­23, 2010, Geneva, Switzerland. ACM 978-1-60558-896-4/10/07.",0,,False
20,Retrieved And Expanded Frames,0,,False
21,... ...,0,,False
22,Query,1,Query,True
23,Ranking Results,0,,False
24,Advertise,0,,False
25,Benz,0,,False
26,Insurance,0,,False
27,Tires,0,,False
28,Figure 1. Key idea: the story frames (in red blocks) and ads frames (cyan blocks) of video ads suggest adjacent markets.,1,ad,True
29,product/object (e.g. car).,0,,False
30,"In this paper we propose a solution of adjacent marketing for image advertising based on a large-scale ads video collection. It is motivated by the fact that generally a video ad contains two types of frames ­ story frames and ads frames, as shown in Figure 1. Story frames in general provide the main concepts (e.g. cars) that are related to the corresponding ads (e.g. insurance, tires). They imply certain human knowledge on the adjacent markets, e.g. showing tire ads on car images. A novel Multi-Modal Dirichlet Process Mixture Sets (MoM-DPM Sets) model is proposed as the key technique behind.",1,ad,True
31,2. SYSTEM OVERVIEW,0,,False
32,"Figure 2 shows the system overview. In the offline stage, we extract video keyframes and perform auto-tagging on them. The online stage contains three steps: 1) multimodal search on keyframes of ads videos given a query image (or query images). Both visual and textual similarities are taken into consideration. The texts come from three resources: image auto-tagging, OCR and surrounding texts; 2) search result expansion. Since the search step tends to find video frames of similar content, to incorporate the adjacent information between objects, we expand the retrieved frames with the rest frames in corresponding videos. For example, given the pizza image in Figure 2, the retrieved frames are generally about food, but by expanding them with the rest frames from the same ads videos, we are able to retrieve those soft drink and restaurant video frames which suggest the adjacent markets; and 3) ads clustering and ranking. The disadvantage brought by frame expansion is that the search results become noisy and with scattered topics. We propose the MoM-DPM Sets model to automatically learn the key topics from the expanded search results, and rank an ads database with the learnt topics. The top-",1,ad,True
33,893,0,,False
34,Query Image,1,Query,True
35,Pizza 1. Search,0,,False
36,Advertise,0,,False
37,Annotate Using Arista,0,,False
38,Visutal Features Detection Using ColorDescriptor,0,,False
39,Large-Scale Video Frames DB,1,Video,True
40,2. Cosine Measurement,0,,False
41,Expanded Video Frames 3. Expand,1,Video,True
42,Suggested Ads,0,,False
43,Pizza,0,,False
44,Pepsi Restaurant,0,,False
45,6. Sorting Approach,0,,False
46,Ads DB,0,,False
47,MoM-DPM Sets,0,,False
48,Clusters,0,,False
49,5. Ranking,0,,False
50,4. Clustering,0,,False
51,...,0,,False
52,...,0,,False
53,Figure 2. System Overview.,0,,False
54,ranked ads will be output. Therefore we find ads of Pepsi Cola and restaurants for the pizza image.,1,ad,True
55,3. THE MoM-DPM SETS MODAL,0,,False
56,"The MoM-DPM Sets model addresses four challenges: 1) discover the latent topics shared among the frames, 2) automatically determine the number of topics, 3) leverage both the visual and textual features to ensure a better performance of topic discovery, and 4) unify the approaches of topic mining and ads ranking.",1,ad,True
57,"Let be the th latent topic and , be the visual and textual features of a query image respectively. Let , , denote the",0,,False
58,"concentration parameter and base distributions of visual and textual features respectively. Let , be model parameters and",0,,False
59,", be the visual and textual features of the observed video",0,,False
60,frames labeled by the topic respectively. The general form of is MoM-DPM Sets is given in Eq(1).,0,,False
61,"| , ,, ,",0,,False
62,",",0,,False
63,|,0,,False
64,",",0,,False
65,|,0,,False
66,"|,",0,,False
67,(1),0,,False
68,if,0,,False
69,for some ;,0,,False
70,|,0,,False
71,|,0,,False
72,|,0,,False
73,|,0,,False
74,if,0,,False
75,for all .,0,,False
76,"where and are the observed video frames corresponding to topic . is the normalization factor. is the number of observed video frames and , is the number of observed video frames (except the th) which belong to topic . We use Gibbs sampling to solve the model, which generally converges in 30 iterations.",0,,False
77,"MoM-DPM Sets has two key features which make it different from previous multimodal DP Mixture processes [3]. Firstly, rather than to learn an optimal parameter set of , , it intends to figure out the membership of each video frame given the observed video frames , . In our approach, , , and",0,,False
78,"are known ( and are learnt from the clustering step), while",0,,False
79,"the model parameters are going to be integrated out analytically. Such a set-based reasoning strategy [1] is more powerful in discovering analogical objects, e.g. given a frame set of Pepsi-cola and Coca-cola, this model is able to discover soda because they share the same concept of soft drinks. Secondly, since the model does not rely on certain parameter set, the clustering (topic mining) step and ranking step shares the same model formulation. The ranking process is as Eq.(2).",0,,False
80,Average Precision,0,,False
81,0.8,0,,False
82,0.7,0,,False
83,0.6,0,,False
84,0.5,0,,False
85,0.4,0,,False
86,0.3,0,,False
87,0.2,0,,False
88,1,0,,False
89,3,0,,False
90,5,0,,False
91,Our Approach,0,,False
92,7,0,,False
93,10,0,,False
94,15,0,,False
95,20,0,,False
96,top N,0,,False
97,Argo [4] DM [2],0,,False
98,Figure 3. Average precision performance @ top N.,0,,False
99,"| .. , ,",0,,False
100,max,0,,False
101,|,0,,False
102,",",0,,False
103,(2),0,,False
104,|,0,,False
105,",",0,,False
106,where ..,0,,False
107,", , ... , defines the latent topic space.",0,,False
108,4. EXPERIMENTS,0,,False
109,"We crawled about 32k videos from Youtube.com initiated by 30 popular concepts for advertising. In total 327,889 key frames were extracted, which make up of the ads videos collection for frame search. We randomly selected 450 ads as a separate ads DB for the ranking purpose. 100 Flickr images were used as queries.",1,ad,True
110,"Figure 3 illustrates the average precision at top 20 ads of our approach compared with those of the baselines Argo [4] and direct match [2]. It can be seen that our approach consistently outperforms the baselines. The gap between the blue curve and the green one indicates that our approach is able to identify the relevant ads from potential adjacent market, which have little overlap with the query image in both visual and textual features. And the gap between the red curve and the green one indicates that Argo [4] also tackles the adjacent marketing problem to a certain extent but it is not effective enough.",1,ad,True
111,"There are big gaps between our methods and the baselines in top 3 results, while the gap narrows down from top 5 to top 20. This may due to the limited size of our ads DB. Considering that generally a publisher such as Google shows less than five targeted ads, our method suggests a promising research direction for adjacent marketing.",1,ad,True
112,5. CONCLUSION,0,,False
113,Web image is an uncovered gold mine. Our method is the first work to tackle the adjacent marketing problem for image advertising. It leverages the human intelligence embedded in video ads to build the connections among ads objects based on a novel Multi-Modal Dirichlet Process Mixture Sets model.,1,ad,True
114,6. REFERENCES,0,,False
115,"[1] Z. Ghahramani, and K. A. Heller. Bayesian Sets. Neural Information Processing Systems (NIPS). 2005.",0,,False
116,"[2] T. Mei, X.-S. Hua, and S.-P. Li. Contextual In-Image Advertising. 2008.",0,,False
117,"[3] A. Velivelli, and T.S. Huang. Automatic Video Annotation Using Multimodal Dirichlet Process Mixture Model. ICNSC 2008.",1,Video,True
118,"[4] X.-J. Wang, M. Yu, et al. Argo: Intelligent Advertising by Mining a User's Interest from His Photo Collections, in conjunction with SIGKDD (ADKDD), Paris, 2009.",0,,False
119,894,0,,False
120,,0,,False
