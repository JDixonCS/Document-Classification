,sentence,label,data,regex
0,Estimation of Statistical Translation Models Based on Mutual Information for Ad Hoc Information Retrieval,0,,False
1,Maryam Karimzadehgan,1,ad,True
2,Department of Computer Science University of Illinois at Urbana-Champaign,0,,False
3,"Urbana, IL 61801",0,,False
4,mkarimz2@illinois.edu,0,,False
5,ABSTRACT,0,,False
6,"As a principled approach to capturing semantic relations of words in information retrieval, statistical translation models have been shown to outperform simple document language models which rely on exact matching of words in the query and documents. A main challenge in applying translation models to ad hoc information retrieval is to estimate a translation model without training data. Existing work has relied on training on synthetic queries generated based on a document collection. However, this method is computationally expensive and does not have a good coverage of query words. In this paper, we propose an alternative way to estimate a translation model based on normalized mutual information between words, which is less computationally expensive and has better coverage of query words than the synthetic query method of estimation. We also propose to regularize estimated translation probabilities to ensure sufficient probability mass for self-translation. Experiment results show that the proposed mutual information-based estimation method is not only more efficient, but also more effective than the synthetic query-based method, and it can be combined with pseudo-relevance feedback to further improve retrieval accuracy. The results also show that the proposed regularization strategy is effective and can improve retrieval accuracy for both synthetic query-based estimation and mutual information-based estimation.",1,ad,True
7,Categories and Subject Descriptors,0,,False
8,H.3.3 [Information Search and Retrieval]: Retrieval Models,0,,False
9,General Terms,0,,False
10,"Algorithms, Theory",0,,False
11,Keywords,0,,False
12,"Statistical Machine Translation, Language Models, Estimation, Smoothing, Feedback",0,,False
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10, July 19­23, 2010, Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",1,ad,True
14,ChengXiang Zhai,0,,False
15,Department of Computer Science University of Illinois at Urbana-Champaign,0,,False
16,"Urbana, IL 61801",0,,False
17,czhai@cs.illinois.edu,0,,False
18,1. INTRODUCTION,1,DUC,True
19,"Designing effective retrieval models is central for information retrieval. In the past, many retrieval models such as vector space model [28, 29, 30] and probabilistic model [6, 22, 25, 27, 34] have been proposed and gained certain success. Recently, language modeling approaches have received considerable attentions because of its sound statistical foundation and good empirical performance [22, 42]. In language modeling approaches, documents are ranked according to how likely a query is generated from the corresponding document models. In basic language models, document models are estimated based on multinomial distribution and smoothing techniques are critical for document model estimation [42]. When ranking documents, the basic language modeling approach is primarily based on exact matching of terms between documents and queries. Since queries are generally succinct and relevant documents may use different vocabulary, such an approach can suffer from vocabulary gap problem.",0,,False
20,"As a principled approach to capturing semantic word relations, statistical translation language models have been proposed for information retrieval to reduce the gap between documents and queries [2, 8]. Based on statistical machine translation [3], the basic idea of translation language models is to estimate the likelihood of translating a document to a query. Since a term has certain probability to be translated into a different term, translation language models can alleviate the vocabulary gap problem in a direct manner. As a result, translation language models have been successfully applied to different tasks such as cross-lingual information retrieval [12, 20, 39], question answering [40], sentence retrieval [19], and tracking information flow [18].",0,,False
21,"Surprisingly, there has been little work on applying translation models to ad hoc retrieval. Indeed, the original paper [2] that proposed translation models for ad hoc retrieval appears to be the only study that we are aware of. One possible reason may be because of the difficulty in estimating translation models. In [2], authors solved the problem by generating synthetic queries. Unfortunately, this method has two deficiencies: (1) it is inefficient; (2) there is no guarantee that a query word is covered.",1,ad,True
22,"In this paper, we propose a simpler method for estimating a translation model, which is based on normalized mutual information between words. Our Contributions are as follows:",0,,False
23,1. We propose an efficient and effective way of estimating word-to-word translation probabilities based on mutual information.,0,,False
24,323,0,,False
25,"2. We propose regularization of self-translation probabilities, which can improve retrieval performance of translation models with both the existing estimation approach and the proposed mutual information-based approach.",0,,False
26,3. We study the issue of smoothing in the context of translation language modeling and show that translation language models are less sensitive to the effect of smoothing.,0,,False
27,"4. We show that with mutual information, the translation language model can be combined with pseudorelevance feedback to further improve the retrieval accuracy.",0,,False
28,2. STATISTICAL TRANSLATION MODEL FOR RETRIEVAL,0,,False
29,"In this section, we review basic language modeling approach, statistical translation language model and smoothing methods for statistical translation model. Finally, we discuss the estimation of translation model.",0,,False
30,2.1 Basic Language Modeling Approach,0,,False
31,"The language modeling approach to information retrieval was first introduced by Ponte and Croft [22]. The basic idea can be described as follows. We assume that a query q is generated by a probabilistic model based on a document d. Given a query q ,"" q1, q2, . . . , qm, and a document d, we are interested in estimating p(d|q) , i.e. the probability that document d has been used to generate query q. By applying Bayes' formula, we have:""",0,,False
32,p(d|q)  p(q|d)p(d),0,,False
33,"p(d) on the right hand side of the above formula is our prior belief that document d is relevant to any query. p(q|d) is the query likelihood for the given document d, which intuitively measures how well document d matches query q. p(d) is often assumed to be uniform and thus can be ignored for ranking documents. Further assuming that each query word is generated independently, we can rewrite the above formula as (in the form of log likelihood):",0,,False
34,"log p(d|q) , rank",0,,False
35,"c(w, q). log p(w|d)",0,,False
36,wV,0,,False
37,"where ,"" rank means equivalence for the purpose of ranking documents, c(w, q) is count of word w in query q, and V is the vocabulary set. The challenging part is to estimate a document model p(w|d). Based on multinomial distribution, the simplest way to estimate p(w|d) is the maximum likelihood estimator :""",0,,False
38,"pml(w|d) ,",0,,False
39,"c(w, d) w c(w , d)",0,,False
40,"Where c(w, d) is count of word w in document d. Due to the data sparseness problem, maximum likelihood estimator under-estimates the probability of unseen words in a document. Smoothing techniques address this problem by assigning non-zero probabilities to the unseen words and thus improving the accuracy of probability estimation. Specifically, smoothing is to discount the probabilities of words seen in the text and then assign extra probability mass to the unseen words according to some fallback model. Usually, collection",1,ad,True
41,language model is used as fallback model [42]. Two commonly used methods are Jelinek-Mercer and Dirichlet Prior smoothing methods:,0,,False
42,"Jelinek-Mercer Method (JM Smoothing): This is a linear interpolation of maximum likelihood model with the collection model, using  as a coefficient weight.",0,,False
43,"p(w|d) , (1 - )pml(w|d) + p(w|C)",0,,False
44,(1),0,,False
45,Where p(w|C) is probability of word w in collection C. Bayesian Smoothing using Dirichlet Prior (Dirichlet Prior,0,,False
46,"Smoothing): Since the conjugate prior of a multinomial distribution is the Dirichlet distribution, we can specify a Dirichlet prior distribution parameterized as",0,,False
47,"(p(w1|C), p(w2|C), . . . , p(wn|C))",0,,False
48,where  is a parameter. The estimated document model based on the posterior mean is then:,0,,False
49,p(w|d),0,,False
50,",",0,,False
51,|d| |d| +,0,,False
52, pml(w|d),0,,False
53,+,0,,False
54, |d| +,0,,False
55,p(w|C ) ,0,,False
56,(2),0,,False
57,2.2 Statistical Translation Language Model,0,,False
58,"Another interesting way of estimating p(w|d) introduced by Berger and Lafferty [2] is based on statistical machine translation [3]. In order to assess the relevance of a document to a user's query, they have estimated the probability that the query would have been generated as a translation of the document. In other words, they allow the query likelihood to be computed based on a translation model of form p(w|u), which is the probability that word u is semantically translated to word w.",0,,False
59,"To put it more formally, in their model, the query likelihood can be calculated by using the following ""translation document model"":",0,,False
60,"pt(w|d) , pt(w|u)p(u|d)",0,,False
61,ud,0,,False
62,"where pt(w|u) is the probability of ""translating"" word u into word w and it allows us to score a document by counting the matches between a query word and semantically related words in the document. If pt(w|u) only allows a word to be translated into itself, the simple exact matching query likelihood would be achieved. However, pt(w|u) would in general allow us to translate u into other semantically related words with non-zero probabilities, thus achieving ""semantic smoothing"" of the document language model.",0,,False
63,2.3 Smoothing for Translation Language Model,0,,False
64,"In this section, we consider statistical machine translation when combined with two basic smoothing methods described in section 2.1.",0,,False
65,"The basic component in the translation language model is pt(w|d) , ud pt(w|u)p(u|d) which can be used to replace pml(w|d) in all basic language model approaches. This will give us 1) translation language model with Dirichlet prior smoothing and 2) translation language model with Jelinek-Mercer smoothing. When we replace pml(w|d) with pt(w|d) ,"" ud p(u|d)pt(w|u) in equation 2, we have the following:""",0,,False
66,pt(w|d),0,,False
67,",",0,,False
68,|d| |d| +,0,,False
69,[,0,,False
70,p(u|d),0,,False
71,·,0,,False
72,pt(w|u)],0,,False
73,+,0,,False
74, |d| +,0,,False
75, p(w|C),0,,False
76,(3),0,,False
77,ud,0,,False
78,324,0,,False
79,"And when pt is replaced with pml in equation 1, we have the following:",0,,False
80,"pt(w|d) , (1 - )[ p(u|d) · pt(w|u)] + p(w|C) (4)",0,,False
81,ud,0,,False
82,"Equations 3 and 4 give us Dirichlet prior smoothing and Jelinek-Mercer (JM) smoothing with translation language model, respectively.",0,,False
83,Authors in [2] only considered translation language model with Jelinek-Mercer smoothing.,0,,False
84,2.4 Estimation of Translation Model,0,,False
85,The key part for translation language model is to learn,0,,False
86,"the word-to-word translation probability, pt(w|u). It is clear",0,,False
87,that the performance of the proposed smoothed translation,0,,False
88,model depends on the quality of the word-to-word trans-,0,,False
89,lation probabilities. In the scenario of statistical machine,0,,False
90,"translation [3], a parallel corpus of two languages is often",0,,False
91,"assumed to be available, and the EM algorithm [5] can be",0,,False
92,used to estimate a translation model.,0,,False
93,In order to gain word-to-word probabilities in monolingual,0,,False
94,"scenario, ideally, we should have a sample of queries and rel-",0,,False
95,"evant documents, but since we do not often have, Berger and",0,,False
96,Lafferty [2] use the idea of synthetic queries as their training,0,,False
97,data. The idea is to take a document and synthesize a query,0,,False
98,to which the document would be relevant. They proposed,0,,False
99,a sampling technique which distinguishes a document from,0,,False
100,other documents.,0,,False
101,In order to select words which are representative of a doc-,0,,False
102,"ument, for each document d  D, they compute the mutual",0,,False
103,information statistics [7] for each of its words according to:,0,,False
104,"I(w, d)",0,,False
105,",",0,,False
106,"p(w, d) log",0,,False
107,p(w|d) p(w|D),0,,False
108,",",0,,False
109,where,0,,False
110,p(w|d),0,,False
111,is,0,,False
112,the,0,,False
113,probabil-,0,,False
114,"ity of word w in document d, and p(w|D) is the probabil-",0,,False
115,ity of word w in the collection. Their proposed algorithm,0,,False
116,"for generating synthetic queries is shown in figure 1, where",0,,False
117,"synthetic queries are sampled based on normalized mutual information I~, and the Poisson parameter  is set to 15. The",0,,False
118,"resulting (d, q) of documents and synthetic queries are used",0,,False
119,to estimate the probabilities with the EM algorithm. More,0,,False
120,details can be found in [2].,0,,False
121,1. Begin,0,,False
122,2.,0,,False
123,Do for each document d  D,0,,False
124,3.,0,,False
125,"Do for x , 1 to 5",0,,False
126,4.,0,,False
127,Begin,0,,False
128,5.,0,,False
129,Select a length m for this query according to,0,,False
130,Poisson distribution,0,,False
131,6.,0,,False
132,"Do for i , 1 to m",0,,False
133,7.,0,,False
134,Select the next query word by sampling the,0,,False
135,scaled distribution: qi  I~,0,,False
136,8.,0,,False
137,"Record (d, q)",0,,False
138,9.,0,,False
139,End,0,,False
140,10. End,0,,False
141,Figure 1: A sampling for synthetic queries,0,,False
142,"Although generating synthetic queries is a reasonable way to estimate the translation probabilities, this method has two deficiencies: (1) it is inefficient; (2) there is no guarantee that a query word is covered. In the next section, we propose a mutual information-based estimation which is more efficient than this method and has a better word coverage.",0,,False
143,3. ESTIMATION OF TRANSLATION MODEL BASED ON MUTUAL INFORMATION,0,,False
144,"In this section, we propose a more efficient way to estimate translation probabilities which can have a better coverage of query words than the existing method discussed in the previous section. We will also present a way to combine translation language model with pseudo-relevance feedback.",0,,False
145,3.1 Mutual Information-Based Approach,0,,False
146,"Mutual information [26] is a good measure to assess how two words are related. In our method, for each word in the collection, we compute all words which have high mutual information scores with it and normalize the computed mutual information scores as follows:",0,,False
147,"First, we compute the mutual information scores for each pair of two words w and u in the collection. Informally, mutual information compares the probability of observing w and u together (the joint probability) with the probabilities of observing w and u independently. The mutual information between words w and u are calculated as follows:",0,,False
148,I (w;,0,,False
149,u),0,,False
150,",",0,,False
151,"Xw ,""0,1""",0,,False
152,"Xu ,""0,1""",0,,False
153,"p(Xw,",0,,False
154,Xu),0,,False
155,log,0,,False
156,"p(Xw, Xu) p(Xw )p(Xu )",0,,False
157,(5),0,,False
158,where Xu and Xw are binary variables indicating whether u,0,,False
159,or w is present or absent. The probabilities are estimated as follows:,0,,False
160,"p(Xw , 1)",0,,False
161,",",0,,False
162,"c(Xw , 1) N",0,,False
163,"p(Xw , 0) , 1 - p(Xw , 1)",0,,False
164,"p(Xu , 1)",0,,False
165,",",0,,False
166,"c(Xu , 1) N",0,,False
167,"p(Xu , 0) , 1 - p(Xu , 1)",0,,False
168,"p(Xw ,"" 1, Xu "", 1)",0,,False
169,",",0,,False
170,"c(Xw ,"" 1, Xu "", 1) N",0,,False
171,"p(Xw ,"" 1, Xu "", 0)",0,,False
172,",",0,,False
173,"(c(Xw , 1) - c(Xw ,"" 1, Xu "", 1)) N",0,,False
174,"p(Xw ,"" 0, Xu "", 1)",0,,False
175,",",0,,False
176,"(c(Xu , 1) - c(Xw ,"" 1, Xu "", 1)) N",0,,False
177,"p(Xw ,"" 0, Xu "", 0) , 1 - p(Xw ,"" 0, Xu "", 1)",0,,False
178,"-p(Xw ,"" 1, Xu "", 0) - p(Xw ,"" 1, Xu "", 1)",0,,False
179,"where c(Xw , 1) and c(Xu ,"" 1) are the numbers of documents containing word w and u, respectively, c(Xw "","" 1, Xu "","" 1) is the number of documents that contain both w and u, and N in the total number of documents in the collection.""",0,,False
180,We then normalize the mutual information score to obtain a translation probability:,0,,False
181,"pmi(w|u) ,",0,,False
182,I(w; u) w I(w ; u),0,,False
183,(6),0,,False
184,"pmi(w|u) gives us the probability of translating word u to another word w; intuitively, the probability would be higher if the two words tend to co-occur with each other.",0,,False
185,3.2 Optimizing Self-Translation Probability,0,,False
186,"The approaches described in sections 3.1 and 2.4 might under-estimate the self-translation probabilities, i.e., it is possible that p(w|u) > p(w|w). This may lead to nonoptimal retrieval performance because it is possible that a document that matches a query word exactly (p(w|w)) gets",1,ad,True
187,325,0,,False
188,Table 1: Sample word translation probabilities using,0,,False
189,synthetic queries (left) and mutual information (right).,0,,False
190,Note that words are stemmed.,0,,False
191,"w,everest",0,,False
192,"w,everest",0,,False
193,q,0,,False
194,p(q|w),0,,False
195,q,0,,False
196,p(q|w),0,,False
197,everest 0.079,0,,False
198,everest 0.1051,0,,False
199,climber 0.042,0,,False
200,climber 0.0423,0,,False
201,climb 0.0365,0,,False
202,mount 0.0339,0,,False
203,mountain 0.0359,0,,False
204,028,0,,False
205,0.0308,0,,False
206,mount 0.033,0,,False
207,expedit 0.0303,0,,False
208,reach 0.0312,0,,False
209,peak,0,,False
210,0.0155,0,,False
211,expedit summit,0,,False
212,0.0314 0.0253,0,,False
213,himalaya 0.01532,0,,False
214,nepal,0,,False
215,0.015,0,,False
216,whittak 0.016,0,,False
217,sherpa 0.01431,0,,False
218,peak,0,,False
219,0.0149,0,,False
220,hillari 0.01431,0,,False
221,MAP Precision at 10,1,MAP,True
222,0.29 0.28 0.27 0.26 0.25 0.24 0.23 0.22 0.21,0,,False
223,0,0,,False
224,0.44 Synthetic Queries Mutual Information,0,,False
225,0.43,0,,False
226,0.42,0,,False
227,0.41,0,,False
228,0.4,0,,False
229,0.39,0,,False
230,0.38,0,,False
231,0.2,0,,False
232,0.4,0,,False
233,0.6,0,,False
234,0.8,0,,False
235,Alpha,0,,False
236,0.37,0,,False
237,1,0,,False
238,0,0,,False
239,Synthetic Queries Mutual Information,0,,False
240,0.2,0,,False
241,0.4,0,,False
242,0.6,0,,False
243,0.8,0,,False
244,1,0,,False
245,Alpha,0,,False
246,Figure 2: Comparison of mutual information and synthetic queries according to MAP (Left) and Precision at 10 (right). (Both are according to Dirichlet prior smoothing).,1,MAP,True
247,"less score contribution from matching the query word exactly than a document that ""matches"" a query word through translation (p(w|u)). To overcome this bias, we introduce a parameter  to control the effect of self-translation. This is a general method that can be applied to adjust the estimated probabilities from any given estimation method.",1,ad,True
248,"pt(w|u) ,",0,,False
249, + (1 - )p(u|u) (1 - )p(w|u),0,,False
250,"w,u w,u",0,,False
251,"and p(w|u) is estimated either with mutual information or synthetic queries.  is a parameter that controls the effect of self-translation probability and when we set  ,"" 1, we recover the basic query likelihood method.""",0,,False
252,"The ""regularized"" translation model pt(w|u) can then be used in Equations 3 and 4 to rank documents.",0,,False
253,3.3 Translation Language Model with Feedback,0,,False
254,"Feedback techniques have been shown to improve retrieval accuracy substantially[13, 27, 41]. A natural question with translation model is whether translation model can benefit from feedback techniques. In this section, we use pseudorelevance feedback to expand our query model [41] and then score the expanded query model with translation language model based on the negative cross entropy of the expanded query language model and the translation document model (also equivalent to scoring based on negative KL-divergence):",0,,False
255,p(w|q). log pt(w|d),0,,False
256,p(w|q )>0,0,,False
257,where p(w|q) is the query model generated by pseudo-relevance feedback and pt(w|d) is a smoothed translation model and can be computed using either of equations 3 or 4.,0,,False
258,4. EXPERIMENTS,0,,False
259,4.1 Data Set,0,,False
260,"The experiments in this section use four main document collections: (1) news articles (AP90) with TREC topics 51100 and 78,321 articles. (2) San Jose Mercury News (SJMN) articles with TREC topics 51-100 and 90,250 articles (3) ad hoc data in TREC7 with topics 351-400 and 528,155 articles and (4) TREC8 with topics 401-450 and 528,155 articles.",1,AP,True
261,"In the experiments, we only use title of the queries. As for preprocessing, we do stemming using Porter stemmer [23] and stop word removal. All experiments are done using the",0,,False
262,Lemur toolkit 1. The performance is measured using two standard measures: MAP(mean average precision) and precision @10 (precision at 10).,1,MAP,True
263,The optimal value for Dirichlet prior smoothing for baseline is 1000 for all data sets and optimal value for JM smoothing for baseline method is gained when coefficient is set to 0.5 for AP90 data set and 0.3 for the rest of data sets.,1,AP,True
264,"The methods used for experiments in the following sections are: BL (baseline), i.e., either Dirichlet prior smoothing or JM smoothing [42], TM-MI (translation language model with mutual information2 for word-to-word translation probabilities), TM-SYN (translation language model with synthetic queries), fb (pseudo-relevance feedback on baseline) and fb+TM(pseudo-relevance feedback combined with translation language model using mutual information).",0,,False
265,4.2 Comparing Synthetic Queries with Mutual Information,0,,False
266,"We first look into the question whether mutual information (MI) can be an alternative way of estimating translation model. Table 2 shows the results for both TM-SYN and TMMI methods with both Dirichlet prior smoothing and JM smoothing, respectively. The results indicate that TM-MI method is able to better capture word relatedness. Indeed, statistical significance tests indicate that the difference between TM-MI and TM-SYN is statistically significant. In addition, estimating translation probabilities by mutual information for all data sets is more efficient than learning translation probabilities by synthetic queries. Table 1 shows a document word together with ten most probable query words that it will translate to by both synthetic queries and mutual information estimation methods. The table shows that the related words for word ""everest"" in case of mutual information are more specific than for words learned via synthetic queries.",1,ad,True
267,Figure 2 shows the sensitivity of mutual information and synthetic queries to  parameter according to MAP measure (left) and Precision@ 10 (right). The difference indeed makes clearer that mutual information works better than synthetic queries. (Our results for synthetic queries are comparable to those reported in [2].),1,MAP,True
268,"According to these results, we can conclude that mutual",0,,False
269,1http://www.lemurproject.org/ 2We use mutual information throughout the paper for simplicity but we mean the normalized mutual information described in section 3.1.,0,,False
270,326,0,,False
271,Table 2: Performance of Translation Language model with synthetic queries and mutual information estimation,0,,False
272,"according to Dirichlet prior smoothing (left) and JM smoothing (right), * means improvements over TM-SYN are",0,,False
273,statistically significant with Wilcoxon signed-rank test. We only show the significance tests for MAP measure.,1,MAP,True
274,Data,0,,False
275,MAP,1,MAP,True
276,Precision @10,0,,False
277,Data,0,,False
278,MAP,1,MAP,True
279,Precision @10,0,,False
280,AP-90 SJMN,1,AP,True
281,TM-MI 0.272,0,,False
282,0.2,0,,False
283,TM-SYN 0.251 0.195,0,,False
284,TM-MI 0.423 0.28,0,,False
285,TM-SYN 0.404 0.266,0,,False
286,AP-90 SJMN,1,AP,True
287,TM-MI 0.264* 0.197*,0,,False
288,TM-SYN 0.25 0.189,0,,False
289,TM-MI 0.381 0.252,0,,False
290,TM-SYN 0.357 0.267,0,,False
291,Table 3: Performance of Translation Language model on different datasets with Dirichlet Prior smoothing (left) and,0,,False
292,"JM smoothing (right), * means improvements over baseline are statistically significant with Wilcoxon signed-rank test.",0,,False
293,We only show the significance tests for MAP measure.,1,MAP,True
294,Data,0,,False
295,AP-90 SJMN TREC7,1,AP,True
296,MAP,1,MAP,True
297,BL 0.248 0.195 0.183,0,,False
298,TM-MI 0.272,0,,False
299,0.2 0.187,0,,False
300,Precision @10 BL TM-MI 0.398 0.423 0.266 0.28 0.412 0.404,0,,False
301,Data,0,,False
302,AP-90 SJMN TREC7,1,AP,True
303,MAP BL TM-MI 0.246 0.264* 0.188 0.197* 0.165 0.172,1,MAP,True
304,Precision @10 BL TM-MI 0.357 0.381 0.252 0.267 0.354 0.362,0,,False
305,TREC8 0.248 0.249 0.452 0.456,1,TREC,True
306,TREC8 0.236 0.244* 0.428 0.436,1,TREC,True
307,information works better than synthetic queries and it is also more efficient.,0,,False
308,"Because of the high computational complexity of synthetic queries, we cannot compare mutual information with it on larger collections, but later we will further experiment with mutual information on larger collections.",0,,False
309,4.3 Comparing Translation Language Model with Standard Query Likelihood,1,Query,True
310,We now look into how well a translation model with our mutual information-based estimation method performs as compared with the standard query likelihood method. Table 3 shows the results for BL and TM-MI methods according to two measures MAP and Precision @10.,1,MAP,True
311,Comparing the columns TM-MI with BL in both tables indeed indicates that the TM-MI outperforms method BL. Significant tests using Wilcoxon signed-rank test [37] show the difference between these two methods for cases marked in the tables are statistically significant. Comparing TM-MI with Dirichlet prior smoothing and TM-MI with JM smoothing shows that TM-MI with Dirichlet prior smoothing has higher MAP than TM-MI with JM smoothing.,1,MAP,True
312,"Stress Tests: In order to have a better understanding of the translation language model, we applied some stress tests on AP90 data set3. This experiment is to help us understand when exactly the translation language model would be most beneficial. For the stress test, we gradually and randomly remove query words from relevant documents and compare the performance of BL method with TM-MI method. The results of MAP and Precision @10 are shown in Figure 3.",1,AP,True
313,"The results indeed indicate that the baseline method (BL) is purely based on exact matching and the performance will drop significantly if the exact matching does not happen. On the other hand, translation language model (TM-MI) is still able to find relevant documents by translating query words to semantically related words in the documents. This indicates that the translation language model works significantly better than the baseline when there is a vocabulary gap between queries and documents.",0,,False
314,"3We got the same trends on other data sets, but we only show the results for AP90 data set.",1,AP,True
315,4.4 Effect of Smoothing on Translation Language Model,0,,False
316,"Understanding the influence of smoothing on translation language model is important and no previous work has looked into this. We have a good understanding of smoothing methods for basic language models [42], but it is not clear how smoothing affects the performance of statistical translation language models. In this section, we look into how statistical translation model behaves with the smoothing parameters.",0,,False
317,"We vary the smoothing parameters (both JM and Dirichlet prior smoothing) for both BL and TM-MI methods. Figure 4 (left and middle) shows the variation of the JM smoothing parameter and Dirichlet prior smoothing parameter on AP90, respectively (we do not show the results on other data sets since they are similar). The result of TM-MI with JM smoothing indicates that the translation model does need a very little smoothing. As shown, the optimal values for translation language model with Dirichlet prior smoothing is 1000 and with JM smoothing is 0.1. As a result, translation language model is less sensitive to the choice of smoothing parameter than the baseline method. And this is intuitively expected, as smoothing is implicitly gained by translating a document word to other semantically related words.",1,AP,True
318,"Please note that in the translation language model, we have one other parameter to tune, i.e., the number of words used for translation. Figure 4 (right) shows the sensitivity of the number of the words according to MAP measure. As shown in the figure, the translation language model is not so sensitive to the number of words used for translation.",1,MAP,True
319,4.5 Results with Pseudo-Relevance Feedback,0,,False
320,"Both statistical translation model and pseudo-relevance feedback are to capture word associations, so it would be interesting to see whether they are essentially taking advantage of the same associations or they can be combined to achieve even more improvement.",1,ad,True
321,"Table 4 shows the pseudo-relevance feedback results for baseline (fb) and when pseudo-relevance feedback is combined with translation language model (fb+TM). For fb+TM method, we first apply pseudo-relevance feedback on initial results (i.e., KL-divergence retrieval model [11]), and then this new query model from pseudo-relevance feedback is used with translation language model to score documents. The feedback parameters are fixed to extract 20 expanded",0,,False
322,327,0,,False
323,Precision at 10,0,,False
324,0.12 Baseline - Precision @10 Tanslation - Precision @10,0,,False
325,0.1,0,,False
326,0.08,0,,False
327,0.06,0,,False
328,0.04,0,,False
329,0.02,0,,False
330,0,0,,False
331,1,0,,False
332,1.5,0,,False
333,2,0,,False
334,2.5,0,,False
335,3,0,,False
336,3.5,0,,False
337,4,0,,False
338,4.5,0,,False
339,5,0,,False
340,Number of query words removed,0,,False
341,MAP,1,MAP,True
342,0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01,0,,False
343,0 1,0,,False
344,Baseline - MAP Translation - MAP,1,MAP,True
345,1.5 2 2.5 3 3.5 4 4.5 5 Number of query words removed,0,,False
346,Precision,0,,False
347,0.25 0.2,0,,False
348,0.15 0.1,0,,False
349,0.05 0 0,0,,False
350,Baseline Translation Model,0,,False
351,0.2,0,,False
352,0.4,0,,False
353,0.6,0,,False
354,0.8,0,,False
355,1,0,,False
356,Recall,0,,False
357,"Figure 3: Stress Tests on AP90 Collection, Precision @10 (left) and MAP (middle). Precision-Recall curve when only ""one query word"" is removed from relevant documents (right)",1,AP,True
358,MAP,1,MAP,True
359,0.3 0.25,0,,False
360,0.2 0.15,0,,False
361,0.1 0.05,0,,False
362,0 0,0,,False
363,Baseline Translation - Mutual information,0,,False
364,0.2,0,,False
365,0.4,0,,False
366,0.6,0,,False
367,0.8,0,,False
368,1,0,,False
369,JM Parameter,0,,False
370,MAP,1,MAP,True
371,0.3 0.25,0,,False
372,0.2 0.15,0,,False
373,0.1 0.05,0,,False
374,0 0,0,,False
375,Baseline Translation - Mutual information,0,,False
376,2000,0,,False
377,4000,0,,False
378,6000,0,,False
379,8000,0,,False
380,Dirichlet Prior Parameter,0,,False
381,10000,0,,False
382,MAP,1,MAP,True
383,0.3 0.25,0,,False
384,0.2 0.15,0,,False
385,0.1 0.05,0,,False
386,0 0,0,,False
387,AP90 SJMN TREC7 TREC8,1,AP,True
388,20,0,,False
389,40,0,,False
390,60,0,,False
391,80,0,,False
392,100,0,,False
393,Number of Words Used for Translation,0,,False
394,"Figure 4: JM parameter variation on AP90 (left), Dirichlet prior parameter variation on AP90 (middle) and Sensitivity of number of words used for translation to MAP (right).",1,AP,True
395,"words from the top 10 retrieved documents in the initial run. As shown in table 4, fb-TM method indeed outperforms fb method when used with JM smoothing. Statistical significant tests reveal that the difference is indeed statistically significant. However, fb+TM method does not significantly outperform fb method when used with Dirichlet prior smoothing. An interesting observation is that although the performance of pseudo-feedback (fb) method with JM smoothing is lower than pseudo-feedback with Dirichlet prior smoothing, when pseudo-feedback (fb) is combined with translation language model, i.e., fb+TM method, the better performance is gained with JM smoothing. In fact, the performance of fb+TM with JM smoothing is consistently better than the fb+TM with Dirichlet prior smoothing.",0,,False
396,"Figure 5 shows the P-R curves for BL, fb and fb+TM methods with JM Smoothing on AP904. This figure indeed indicates that the precision of fb+TM method at different recall points is higher than BL and fb methods. This is an interesting conclusion that translation language model brings in co-occurrence word knowledge that once combined with pseudo-relevance feedback, significant improvement is gained.",1,AP,True
397,4.6 The Need for Self-Translation Regularization,0,,False
398,"A potential problem of the estimated translation probabilities is that it is possible that p(w|u) > p(w|w). This may lead to non-optimal retrieval performance because it is possible that a document that matches a query word exactly (p(w|w)) gets less score contribution from matching the query word exactly than a document that ""matches"" a",1,ad,True
399,4We do not show other curves due to their similarity.,0,,False
400,Precision,0,,False
401,0.7,0,,False
402,Baseline,0,,False
403,0.6,0,,False
404,Feedback Feedback&Translation,0,,False
405,0.5,0,,False
406,0.4,0,,False
407,0.3,0,,False
408,0.2,0,,False
409,0.1,0,,False
410,0,0,,False
411,0,0,,False
412,0.2,0,,False
413,0.4,0,,False
414,0.6,0,,False
415,0.8,0,,False
416,1,0,,False
417,Recall,0,,False
418,Figure 5: Comparison of Baseline with Translation Language model combined with pseudo-feedback and pseudo-feedback alone on AP90 data set with JM smoothing,1,AP,True
419,"query word through translation (p(w|u)). The interpolation formula (with ) can help alleviate this problem; indeed, if   0.5, we can always ensure that this constraint be satisfied. So, it would be interesting to see how  affects the performance. Figure 6 shows the sensitivity of  parameter according to MAP measure. We indeed observe that when  is very small (close to no interpolation) the performance is poor, suggesting that it is important to regulate the selftranslation probabilities to ensure that it is sufficiently large. In Figure 6, we can see that when 0.5    0.8 for most data sets, we can gain the optimal value. Note that when  ,"" 1, we reach the baseline.""",1,MAP,True
420,4.7 Findings,0,,False
421,1. Translation language model is statistically significant bet-,0,,False
422,328,0,,False
423,Table 4: Performance of Translation Language model combined with pseudo-feedback with Dirichlet Prior smoothing,0,,False
424,"(left) and JM smoothing (right), * and + mean improvements over baseline and fb, respectively, are statistically",0,,False
425,significant with Wilcoxon signed-rank test. We only show the significance tests for MAP measure.,1,MAP,True
426,Data,0,,False
427,AP-90 SJMN TREC7 TREC8,1,AP,True
428,BL 0.248 0.195 0.183 0.248,0,,False
429,MAP fb 0.285 0.231 0.226 0.270,1,MAP,True
430,fb+TM 0.285 0.232 0.226 0.278,0,,False
431,Precision @10,0,,False
432,BL,0,,False
433,fb fb+TM,0,,False
434,0.3978 0.404 0.406,0,,False
435,0.266 0.295,0,,False
436,0.3,0,,False
437,0.412 0.38,0,,False
438,0.38,0,,False
439,0.452 0.456 0.438,0,,False
440,Data,0,,False
441,AP-90 SJMN TREC7 TREC8,1,AP,True
442,BL 0.246 0.188 0.165 0.236,0,,False
443,MAP,1,MAP,True
444,fb,0,,False
445,fb+TM,0,,False
446,0.271 0.298*+,0,,False
447,0.229 0.234*+,0,,False
448,0.209 0.222*+,0,,False
449,0.240 0.281*+,0,,False
450,Precision @10,0,,False
451,BL,0,,False
452,fb fb+TM,0,,False
453,0.357 0.383 0.411,0,,False
454,0.252 0.316 0.313,0,,False
455,0.354 0.38 0.384,0,,False
456,0.428 0.4,0,,False
457,0.452,0,,False
458,MAP,1,MAP,True
459,0.35 0.3,0,,False
460,0.25 0.2,0,,False
461,0.15 0.1,0,,False
462,0.05 0,0,,False
463,AP90 SJMN TREC7 TREC8,1,AP,True
464,0.2,0,,False
465,0.4,0,,False
466,0.6,0,,False
467,0.8,0,,False
468,1,0,,False
469,Alpha,0,,False
470,Figure 6: Sensitivity of  parameter to MAP measure,1,MAP,True
471,ter than the baseline query likelihood especially when there is a vocabulary gap. 2. Normalized mutual information can be used for wordto-word translation effectively and the results in the previous sections indicate that it is more accurate than synthetic queries. Synthetic queries are inefficient for a large collection such as TREC7 or TREC8. 3. The performance of translation language model combined with pseudo-relevance feedback outperforms pseudorelevance feedback alone; this indicates that translation language model brings in co-occurrence knowledge in addition. 4. Translation language model is less sensitive to the choice of smoothing parameter than the baseline. 5. Translation language model is robust as it improves over all individual queries.,1,TREC,True
472,5. RELATED WORK,0,,False
473,"Language modeling approaches received considerable attentions recently [22]. One of the most important challenges in language model-based information retrieval is to estimate a better document model. Smoothing is an important approach for document model estimation and has been shown to be critical for information retrieval [42]. To further improve the estimation of document models, different heuristics have been proposed in the past. For example, cluster or topic-model based approaches have been studied in [16, 36]. Tao et al. [33] proposed a document expansion approach to enrich document representation before estimating document models.",0,,False
474,"Statistical translation models were originally studied in machine translation with the goal of automatically translating sentences between different languages (e.g., French and English) [3] where authors proposed five different translation models. The simplest model (i.e., IBM 1) [3] ignores position information when learning word-to-word translation probabilities. This model has been adopted in information retrieval by Berger and Lafferty [2]. To train translation mod-",1,ad,True
475,"els, they synthetically generated (query, document) pairs. An alternative way of estimating the translation model is based on document titles [8]. In this work, the authors proposed to use (title, document) pairs as training data. These estimation methods are inefficient and the coverage of query words is low. Our proposed mutual information-based estimation is more efficient and has a better query words coverage.",0,,False
476,"Translation models have been naturally used in crosslingual information retrieval domain [20, 39]. For example, Nie et al. [20] used parallel corpus as training data to learn translation models. The work by Lavrenko et al. [12] has adapted the relevance model in two different ways based on KL-divergence retrieval models to perform cross-lingual information retrieval. The cluster-based query likelihood proposed in [10] can be regarded as a form of a translation model where the whole document is translated into the query. Recently, translation models have been applied in many applications including question answering, sentence retrieval and tracking information flow [18, 19, 40]. For example, Xue et al [40] has applied translation model on question-answer archives where question and answer pairs are used to train the translation model. In Contrary to all these works, we studied statistical translation model in ad hoc retrieval context.",1,ad,True
477,"Vocabulary gap has also been studied in the past. Many studies have tried to bridge the vocabulary gap between documents and queries both based on co-occurrence thesaurus [1, 9, 14, 21, 24, 31, 32, 38] and hand-crafted thesaurus [15, 35]. Some other works have considered to combine both approaches [4, 17]. In this paper, we considered word co-occurrence relationship based on mutual information and incorporated it into translation language model in a more principled way.",1,corpora,True
478,6. CONCLUSIONS AND FUTURE WORK,0,,False
479,"As a principled approach to capturing semantic relation of words in information retrieval, statistical translation models have been shown to outperform simple language models which rely on exact matching of words in the query and documents. In this paper, we propose a new simple way to estimate translation probabilities based on mutual information. Our experiment results indicate that the proposed mutual information estimation method is both more efficient and more effective than the existing synthetic query estimation method. We also proposed to regularize translation probability to ensure sufficient self-translation probability mass, which has been shown to be effective for both estimation methods we experimented with. Our results also show that the translation language model is not so sensitive to the effect of smoothing, and it can be combined with pseudorelevance feedback to further improve the performance.",0,,False
480,329,0,,False
481,"For future, it would be interesting to propose some other efficient estimation methods. It would also be interesting to explore other ways of incorporating the translation probabilities into the retrieval formula. Another interesting direction is to study how to transfer the knowledge learned from one collection to another collection.",1,corpora,True
482,7. ACKNOWLEDGMENTS,0,,False
483,"We thank the anonymous reviewers for their useful comments. This material is based upon work supported by a Sohaib and Sara Abbasi Fellowship, Yahoo! Key Scientific Challenge Award, the National Science Foundation under Grant Numbers IIS-0347933, IIS-0713581, IIS-0713571, and CNS-0834709, and by NIH/NLM grant 1 R01 LM009153-01. Any opinions, findings, conclusions, or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsors.",1,Yahoo,True
484,8. REFERENCES,0,,False
485,"[1] J. Bai, D. Song, P. Bruza, J. Y. Nie, and G. Cao. Query expansion using term relationships in language models for information retrieval. ACM CIKM, pages 688­695, 2005.",1,Query,True
486,"[2] A. Berger and J. Lafferty. Information retrieval as statistical translation. ACM SIGIR, pages 222­229, 1999.",0,,False
487,"[3] P. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. Mercer. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263­311, 1993.",0,,False
488,"[4] G. Cao, J. Y. Nie, and J. Bai. Integrating word relationships into language models. ACM SIGIR, pages 298­305, 2005.",0,,False
489,"[5] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. ACM SIGKDD, 39(B):1­38, 1997.",0,,False
490,"[6] N. Fuhr. Probabilistic models in information retrieval. The Computer Journal, 35(3):243­255, 1992.",0,,False
491,"[7] F. Jelinek. Statistical Methods for speech recognition. MIT Press., 1997.",0,,False
492,"[8] R. Jin, A. G. Hauptmann, and C. X. Zhai. Title language model for information retrieval. In ACM SIGIR, pages 42­48, 2002.",0,,False
493,"[9] Y. Jing and B. Croft. An association thesaurus for information retrieval. RIAO, pages 141­160, 1994.",0,,False
494,"[10] O. Kurland and L. Lee. Corpus structure, language models, and ad hoc information retrieval. ACM SIGIR, pages 194­201, 2004.",1,ad,True
495,"[11] J. Lafferty and C. Zhai. Document language models, query models and risk minimization for information retrieval. ACM SIGIR, pages 111­119, 2001.",0,,False
496,"[12] V. Lavrenko, M. Choquette, and B. Croft. Cross-lingual relevance models. ACM SIGIR, pages 175­182, 2002.",0,,False
497,"[13] V. Lavrenko and B. Croft. Relevance-based language models. ACM SIGIR, pages 120­127, 2001.",0,,False
498,"[14] M. Lesk and B. Croft. Word-word associations in document retrieval systems. American Documentation, 20:20­27, 1969.",0,,False
499,"[15] S. Liu, F. Lin, C. Yu, and W. Meng. An effective approach to document retrieval via utilizing wordnet and recognizing phrases. ACM SIGIR, pages 266­272, 2004.",0,,False
500,"[16] X. Liu and W. B. Croft. Cluster-based retrieval using language models. In ACM SIGIR, pages 186­193, 2004.",0,,False
501,"[17] R. Mandala, T. tokunaga, H. Tanaka, and K. Satoh. Ad hoc retrieval experiments using wordnet and automatically constructed thesauri. TREC-7, pages 475­481, 1998.",1,hoc,True
502,"[18] D. Metzler, Y. Bernstein, B. Croft, A. Moffat, and J. Zobel. Similarity measures for tracking information flow. ACM CIKM, pages 517­524, 2005.",0,,False
503,"[19] V. Murdock and B. Croft. Simple translation models for sentence retrieval in factoid question answering. ACM SIGIR, pages 31­35, 2004.",0,,False
504,"[20] J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web. In ACM SIGIR, pages 74­81, 1999.",0,,False
505,"[21] H. J. Peat and P. Willett. The limitations of term co-occurrence data for query expansion in document retrieval systems. J. of Information science, 42(5):378­383, 1991.",0,,False
506,"[22] J. Ponte and W. B. Croft. A language modeling approach to information retrieval. ACM SIGIR, pages 275­281, 1998.",0,,False
507,"[23] M. Porter. An algorithm for suffix stripping. Program, 14(3), 1980.",0,,False
508,"[24] Y. Qiu and H. Frei. Concept based query expansion. ACM SIGIR, pages 160­169, 1993.",0,,False
509,"[25] C. J. V. Rijbergen. A theoretical basis for the use of co-occurrence data in information retrieval. Journal of Documentation, pages 106­119, 1977.",0,,False
510,"[26] C. J. V. Rijsbergen. Information retrieval. Butterworths, 1979.",0,,False
511,"[27] S. Robertson and K. Sparck. Relevance weighting of search terms. Journal of American Society for Information Science, 27:129­146, 1976.",0,,False
512,"[28] G. Salton. Automatic Text Processing: The Transformation, Analysis and Retrieval of Information by Computer. Addison-Wesley, 1989.",0,,False
513,"[29] G. Salton and M. McGill. Introduction to Modern Information Retrieval. McGraw-Hill., 1983.",0,,False
514,"[30] G. Salton, C. S. Yang, and C. T. Yu. A theory of term importance in automatic text analysis. Journal of American Society for Information Science, 26(1):33­44, 1975.",0,,False
515,"[31] H. Schutze and J. O. Pedersen. A co-occurrence based thesaurus and two applications to information retrieval. Information and processing management, 33(3):307­318, 1997.",0,,False
516,"[32] A. F. Smeaton and C. J. V. Rijsbergen. The retrieval effects of query expansion on a feedback document retrieval system. The Computer Journal, 26(3):239­246, 1983.",0,,False
517,"[33] T. Tao, X. Wang, Q. Mei, and C. Zhai. Language model information retrieval with document expansion. In HLT-NAACL, pages 407­ 414, 2006.",0,,False
518,"[34] H. Turtle and W. B. Croft. Evaluation of an inference network-based retrieval model. ACM Transactions on Information Systems, 9(3):187­222, 1991.",0,,False
519,"[35] E. M. Voorhess. Query expansion using lexical-semantic relations. ACM SIGIR, pages 61­69, 1994.",1,Query,True
520,"[36] X. Wei and W. B. Croft. Lda-based document models for ad-hoc retrieval. In ACM SIGIR, pages 178­185, 2006.",1,ad-hoc,True
521,"[37] F. Wilcoxon. Individual comparisons by ranking methods. Biometrics, 1:80­83, 1945.",0,,False
522,"[38] J. Xu and B. Croft. Query expansion using local and global document analysis. ACM SIGIR, pages 4­11, 1996.",1,Query,True
523,"[39] J. Xu, R. Weischedel, and C. Nguyen. Evaluating a probabilistic model for cross-lingual information retrieval. ACM SIGIR, pages 105­110, 2001.",0,,False
524,"[40] X. Xue, J. Jeon, and W. B. Croft. Retrieval models for question and answer archives. In ACM SIGIR, pages 475­482, 2008.",0,,False
525,"[41] C. Zhai and J. Lafferty. Model-based feedback in the language modeling approach to information retrieval. ACM CIKM, pages 403­410, 2001.",0,,False
526,"[42] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to ad hoc information retrieval. ACM SIGIR, pages 334­342, 2001.",1,ad,True
527,330,0,,False
528,,0,,False
