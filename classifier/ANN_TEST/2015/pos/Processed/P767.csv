,sentence,label,data,regex
0,Time Pressure and System Delays in Information Search,0,,False
1,Anita Crescenzi,0,,False
2,"School of Information and Library Science, University of",0,,False
3,"North Carolina Chapel Hill, NC, USA",0,,False
4,amcc@email.unc.edu,0,,False
5,Diane Kelly,0,,False
6,"School of Information and Library Science, University of",0,,False
7,"North Carolina Chapel Hill, NC, USA",0,,False
8,dianek@email.unc.edu,0,,False
9,Leif Azzopardi,0,,False
10,"School of Computing Science, University of Glasgow",0,,False
11,"Glasgow, United Kingdom",0,,False
12,leif@dcs.gla.ac.uk,0,,False
13,ABSTRACT,0,,False
14,"We report preliminary results of the impact of time pressure and system delays on search behavior from a laboratory study with forty-three participants. To induce time pressure, we randomly assigned half of our study participants to a treatment condition where they were only allowed five minutes to search for each of four ad-hoc search topics. The other half of the participants were given no task time limits. For half of participants' search tasks (n,""2), five second delays were introduced after queries were submitted and SERP results were clicked. Results showed that participants in the time pressure condition queried at a significantly higher rate, viewed significantly fewer documents per query, had significantly shallower hover and view depths, and spent significantly less time examining documents and SERPs. We found few significant differences in search behavior for system delay or interaction effects between time pressure and system delay. These initial results show time pressure has a significant impact on search behavior and suggest the design of search interfaces and features that support people who are searching under time pressure.""",1,ad-hoc,True
15,Categories and Subject Descriptors,0,,False
16,H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval--Search Process,0,,False
17,Keywords,0,,False
18,Search Behavior; Time Pressure; System Delays,0,,False
19,1. INTRODUCTION,1,DUC,True
20,"Recently, increased attention has been paid to how system delays impact search behavior and the user experience in the context of interactive information retrieval (IIR) [1, 8, 15, 16]. Users of search systems with slower query response times have been found to have lower perceptions of system usability and helpfulness [1]. Studies examining system delays have found users are tolerant of search delays up",0,,False
21,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.",1,ad,True
22,"SIGIR'15, August 09 - 13, 2015, Santiago, Chile Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3621-5/15/08 ...$15.00 DOI: http://dx.doi.org/10.1145/2766462.2767817.",0,,False
23,"to a ""tipping point"" beyond which behaviors and perceptions change [15]. User sensitivity to delay varies across individuals, the average speed of the system used [1], and how the information is presented [15]. It has also been found that searchers who experience both query and document response delays view fewer documents, but mark a higher percentage as relevant, although the delay had no impact on the number of queries issued, the number of documents marked relevant, the depth of results inspected or search accuracy [8].",1,ad,True
24,"Although there has been a resurgence of interest in the impact of search system delay on user experience, a long line of research precedes this interest. In 1968, Miller [9] described system response times exceeding two seconds as changing the character of ""man-computer conversational transactions"" and provided a taxonomy of acceptable response times depending on the type and complexity of system interactions and the extent to which the response delay would disrupt the user's task. Since this early work, researchers have found that perceived wait time and the impact of delays can be reduced by informing users of the system response status [11], incrementally loading pages [2], or displaying filler text or images [6] while the system is processing its response.",1,ad,True
25,"While system delays have been investigated in IIR, one variable that has not been investigated much is time pressure. Research on time pressured decision-making has found that people adapt under time pressure: they may spend less time in each decision stage, spend less time processing individual pieces of information, accelerate the pace of the task or information processing, or even satisfice in their decisions [12]. Time has been shown to be an important contextual factor in search [13]; however, the impact of time pressure on search behaviors and perceptions is less well understood. Recent studies have have shown when searchers have less time to complete tasks, they have lower perceptions of their search performance [7] and task completion [17], less satisfaction with results [7, 17] and less knowledge gained [7]. Searchers also report lower pre-task search confidence [7] and more negative affect [7] and stress [17]. Time pressure has also been found to impact search satisfaction even when the same amount of time was given to complete tasks [4]. Finally, Mishra et al. [10] found dissatisfaction among people who searched for time-critical information.",1,ad,True
26,"In this paper, we report preliminary results of a study investigating the impact of time pressure, system delays and interaction effects on search behaviors and user experience. We present the results of our analyses of interaction measures as well as time pressure and delay manipulation checks.",0,,False
27,767,0,,False
28,2. METHOD,0,,False
29,"We conducted a laboratory experiment where we manipulated task time limit and system response time. To manipulate task time limit, half of the participants were given an unexpected task time limit just before they started the experimental search tasks. This time limit was presented via pop-up message after they completed the practice task and informed them they had only 5 minutes to complete each experimental search task (Figure 1). These instructions were intended to simulate a situation in which an urgent notification changes one's expectations about the time available to complete a task. The 5 minute time limit represented approximately half of the mean task completion times from a prior study [5] where different participants used the same system to complete three of the same tasks without time limits. The system tracked the time, and after participants had been searching for 5 minutes, popped-up another message indicating time was up.",1,ad,True
30,Figure 1: Task time limit instructions,0,,False
31,"Participants who were not given a task time limit were not provided with any instructions regarding the amount of time to spend on each task, although all participants were aware that the experimental session would last 1hr and 15min. If these participants were still searching after 1hr and 5min (i.e., with approximately 10 minutes remaining in the experimental session), we stopped them so they could complete the exit questionnaire and interview. Based on our previous experiences, we did not expect we would need to do this; however, this occurred in seven cases. To minimize time pressure caused by researcher presence [14], the researcher was stationed in an adjacent room while participants completed the study.",1,ad,True
32,System response time was a within-subjects variable with two levels: delay and no delay. Participants completed two tasks in which we introduced 5 second delays after they submitted queries and clicked on SERP results and two tasks in which the system was not delayed. We selected a 5 second delay based on prior research which indicated that a delay of 4 seconds changed behaviors but not attitudes and is usually considered acceptable to users (delays of 7-10 seconds have been found to be unacceptable by users [15]). We presented delays in 2 orders: half of the participants experienced delays during their first and third tasks while the other half experienced delays during their second and fourth tasks.,0,,False
33,"The basic procedure was as follows. Participants were first shown the experiment instructions on screen including the simulated work task scenario and then completed a practice task to become familiar with the system; we did not impose a time limit or system delay during the practice task. Once participants completed the practice task, those with a task time limit were shown the instructions in Figure 1 before being presented with their first search task. For each search task, participants were shown the topic, completed",0,,False
34,"a pre-search questionnaire, conducted their search and then completed a post-search questionnaire. After conducting all four searches, participants completed an exit questionnaire. Following this, the researcher returned to the room for a final interview and debriefing.",0,,False
35,2.1 Scenario and Tasks,0,,False
36,"Following Borlund's [3] guidelines, search tasks were situated in the context of a project in which a research team needs to compare news coverage about four topics during the (consecutive) U.S. presidential terms of Clinton, Bush and Obama. Participants were told their job was to examine news during Clinton's second term, 1996-2000, which corresponded to the date range of the test collection [18]. We wanted the scenario to provide participants with a rationale for searching articles from this time period and to make this characteristic of the collection salient to help ground participants' relevance judgments. The scenario indicated that participants should find 8-12 articles per topic.",0,,False
37,"We selected topics from the collection with contemporary relevance where prior studies have reported that participants found the tasks at least moderately interesting and difficult [5]. We aimed to minimize potential variability in interest and difficulty in order to examine the impact of our independent variables. Four topics were used: wildlife extinction (347), journalist risks (354), piracy (367) and population growth (435). Participants were presented with the topic descriptions before each search.",0,,False
38,"To minimize order effects, we created a set of 24 topic rotations. We assigned the topic rotations to time limit and delay order combinations such that each topic rotation was used twice: once in each time limit condition and once in each delay order. We randomly assigned participants to time limit, delay order and topic rotation.",0,,False
39,2.2 Search Questionnaires,0,,False
40,"Our search questionnaires measured several constructs including system usability, task difficulty, metacognitive actions and satisfaction. Several items functioned as manipulation checks to see if participants felt time pressure and noticed system delays (see Table 1). Participants responded to these items with a 7-point scale (1 ,"" strongly disagree, 7 "","" strongly agree). In this paper, we only present items related to the manipulation checks and will analyze the additional measures in future work.""",1,ad,True
41,2.3 Search System,0,,False
42,"All participants used the same search system which resembled a standard search engine. The Whoosh IR Toolkit was used as the core of the retrieval system, with BM25 as the retrieval algorithm, using standard parameters, but with an implicit ANDing of query terms to restrict the retrieval set. Only a portion of the collection was indexed to ensure that the natural response time of the system was quick and constant. This was to control the effects of both the natural and experimental delays as much as possible. The documents included in the index consisted of all the TREC pooled documents for the given topics, along with the top 100 documents retrieved from the full index given a set of user generated queries from a past study (approximately 100-200 queries per topic). In total, over 200,000 documents were indexed. In all conditions, the search system displayed a spinning wheel when it was busy.",1,TREC,True
43,768,0,,False
44,2.4 Participants,0,,False
45,"Forty-five people from a major research university participated including undergraduate students (n,""13), graduate students (n"",8) and staff (n,22) representing many different majors and occupations. Participants ranged in age from 18-59 years (M,""32.1, SD"",12.8) and 31 were female. Participants were compensated $20 USD.",1,ad,True
46,3. RESULTS,0,,False
47,"We analyzed 163 tasks completed by 43 participants using a mixed ANOVA. We excluded data from 2 participants with no task time limit who spent most of the time completing a single search task, 7 tasks where participants with no task time limit were stopped in their third task or final task, and 2 tasks where participants accidentally ended the tasks by pressing the wrong button.",0,,False
48,3.1 Time and Delay,0,,False
49,"We conducted a series of manipulation checks to make sure our experimental manipulations were successful. We found those with the task time limit reported feeling significantly more time pressure, a greater need to work fast and more rushed (Table 1). We found significant differences in perceived quickness of SERP and document display between the delay conditions. We found no interaction effects, but note a significant effect of delay on perceived time pressure.",0,,False
50,"We examined task completion times and found significant effects of task time limit and system delay on the total task time as shown in Table 1. The introduction of time limits and system delays complicates comparison of interaction measures as the total delay experienced by any one person is a function of the number of queries issued and documents viewed by this person. For this reason, we also examined adjusted task times where we subtracted the cumulative delay experienced by each participant for each task from the total task time; we found significant main effects of time limit and no main effect of delay. Interaction effects were significant (F(2,118),""7.03, p<.01).""",1,ad,True
51,"To check the delay manipulation, we examined query and document processing times (in seconds). As expected, we found no significant differences in organic system response times and significant differences in the mean total processing time (organic + delay) according to delay condition. It took longer for the system to return requests for tasks with delay condition (query: M,""5.92, SD"",0.96; document: M,""5.20, SD"",1.16) than for tasks without delay (query: M,""0.94, SD"",0.84; document: M,""0.29, SD"",0.34). We found no main effect for time limit or interaction effects.",0,,False
52,3.2 Search Behaviors,0,,False
53,"Table 1 shows the means and standard deviations of participants' search behaviors by time limit and response time condition. With one exception, there were no significant interaction effects, so we only report main effects. We normalized time-based measures to facilitate comparison. The adjusted rate-based measures reflect the number of queries, document views and documents marked relevant per minute using adjusted times; that is, total time minus time spent in delay as in Taylor, Dennis & Cummings [15]. While participants who experienced a task time limit had higher rates of querying, document viewing and marking documents as relevant, only the difference for query rate was significant. There were no significant differences according to whether or",1,ad,True
54,"not participants experienced delays; in fact, these measures were very similar in these two conditions.",0,,False
55,"When we examine actions per query, we see those who experienced the task time limit examined search results more shallowly. They viewed fewer SERPs and documents and also did not navigate as deeply in the search results list. All of these differences were statistically significant. Participants with a task time limit also spent significantly less time viewing documents and SERPs. Although the trend was for participants to view fewer SERPs and documents per query when they experienced delays and not go as deeply in the search results list, these differences were not significant. Participants spent significantly more time viewing documents for delayed tasks, but they spent roughly equal amounts of time viewing SERPs for their delayed and non-delayed tasks.",0,,False
56,"With respect to performance, there were no differences in participants' save rates (% viewed marked relevant) according to time limit or response time conditions. Although we have not examined the content of the documents participants saved, we examined whether participants met the scenario goal of finding 8-12 relevant articles. This goal was achieved more often for tasks where no task time limit was present (96% vs. 84% of tasks) and for tasks where no delays were present (92% vs. 86% of tasks). Only 76% of tasks with both a delay and a task time limit had at least 8 pages marked relevant compared to 100% of tasks with no task time limit and delay.",1,ad,True
57,4. DISCUSSION AND CONCLUSIONS,0,,False
58,"We investigated the impact of time pressure and system delays on search behaviors. Results showed participants who were given task time limits queried at a significantly higher rate, viewed significantly fewer documents per query, had significantly shallower hover and view depths, and spent significantly less time SERPs. They also spent significantly less time examining documents, and presumably, making judgments about which documents to save.",1,ad,True
59,"We did not find significant differences in search behavior with respect to system delays beyond the time spent completing the task (total and adjusted) and the time spent per document. While the delay was noticed by most participants, it did not significantly impact their search behaviors. These findings are consistent with other studies [1, 8]. Of course, it is likely that larger delay times would produce different results: Taylor et al. [15] found a tipping point between 7 and 11 seconds for behavioral impacts but some changes to satisfaction were observed at lower thresholds. Whether the delay is consistent or intermittent also seems to play a role [1]. Further analysis of the questionnaires and debriefings will likely provide additional insight about how time pressure and system delays impacted the user experience.",1,ad,True
60,"Interestingly, we found considerable variability in the task completion times for those without task time limits and two participants, whose data were excluded, used nearly the entire experimental session to search for a single task. For those tasks included in analyses, task completion times ranged from 1.76min to 36.27min. For 10 tasks, the total task completion time exceeded 15min. These variations surprised us because they differ considerably from what we have observed in previous laboratory studies, where the general challenge is often to create tasks that will require sustained interaction.",0,,False
61,769,0,,False
62,Manipulation checks felt time pressure,0,,False
63,needed to work fast felt hurried or rushed displayed search results quickly displayed articles quickly Interaction measures,0,,False
64,total task time (m) adjusted task time (m),1,ad,True
65,adjusted query rate adjusted view rate adjusted mark relevant rate SERPs viewed per q docs viewed per q hover depth per q,1,ad,True
66,view depth per q total time per doc (s) total SERP time per q (s),0,,False
67,save rate,0,,False
68,Time Limit (main effects),0,,False
69,Session,1,Session,True
70,Task,0,,False
71,F,0,,False
72,3.43 (1.62) 3.56 (1.56) 3.03 (1.49) 4.31 (1.67) 4.39 (1.54),0,,False
73,5.25 (1.62) 5.62 (1.50) 4.91 (1.75) 4.65 (1.78) 4.68 (1.92),0,,False
74,15.27*** 27.30*** 17.93*** 0.99 0.63,0,,False
75,9.04 (6.12) 8.25 (5.63) 0.61 (0.44) 2.28 (0.93) 1.64 (0.98) 2.25 (1.67) 6.09 (5.75) 17.52 (16.70) 14.88 (15.95),0,,False
76,14.05 (6.50) 61.53 (60.35),0,,False
77,0.70 (0.18),0,,False
78,4.60 (0.98) 4.08 (1.02) 1.04 (0.61) 2.63 (1.24) 2.05 (1.24) 1.64 (0.79) 3.90 (3.47) 11.34 (8.78) 8.89 (7.98),0,,False
79,8.82 (5.46) 34.86 (23.44),0,,False
80,0.73 (0.21),0,,False
81,21.82**** 21.29**** 16.72*** 2.55 3.22 5.36* 4.81* 5.23* 6.51*,0,,False
82,17.26*** 13.18*** 0.64,0,,False
83,Response Time (main effects),0,,False
84,No Delay,0,,False
85,Delay,0,,False
86,F,0,,False
87,4.29 (1.90) 4.70 (1.82) 4.03 (1.96) 4.96 (1.58) 5.00 (1.68),0,,False
88,4.61 (1.80) 4.71 (1.86) 4.11 (1.82) 4.01 (1.76) 4.09 (1.74),0,,False
89,4.12* 0.00 0.18 19.73*** 17.72***,0,,False
90,6.13 (4.00) 6.13 (4.00) 0.85 (0.61) 2.52 (1.18) 1.85 (1.19) 1.98 (1.54) 5.08 (5.04) 14.77 (15.46) 11.91 (14.46),0,,False
91,10.22 (5.54) 46.73 (52.80),0,,False
92,0.69 (0.20),0,,False
93,7.01 (5.27) 5.70 (4.67) 0.85 (0.54) 2.42 (1.07) 1.89 (1.12) 1.83 (0.96) 4.65 (4.41) 13.34 (10.43) 11.15 (10.11),0,,False
94,12.07 (7.23) 46.55 (36.98),0,,False
95,0.74 (0.20),0,,False
96,7.61** 0.03 0.03 1.60 0.00 0.90 0.71 0.77 0.20,0,,False
97,10.63*** 0.00 2.30,0,,False
98,"Table 1: Manipulation check and interaction signals. Means (sd) and F-test results by time constraint (df,"" 1, 41) and response time (df"",""1,118), *p<0.05; **p<0.01; ***p<0.001; ****p<0.0001""",0,,False
99,"While preliminary, our initial results open a new line of inquiry into how time pressure impacts search behaviors and how search tools might be designed to support people who are searching under time pressure. For example, interface features that make it easier for people to query, assess relevance and monitor progress might be especially beneficial. Displaying fewer results per SERP might also help keep people who are searching under time pressure stay focused.",0,,False
100,5. REFERENCES,0,,False
101,"[1] I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proc. of the 37th ACM SIGIR conference, pages 103­112, 2014.",0,,False
102,"[2] N. Bhatti, A. Bouch, and A. Kuchinsky. Integrating user-perceived quality into Web server design. Computer Networks, 33(1-6):1­16, 2000.",0,,False
103,"[3] P. Borlund. The IIR evaluation model: A framework for evaluation of interactive information retrieval systems. Information Research, 8(3):1­34, 2003.",0,,False
104,"[4] A. Crescenzi, R. Capra, and J. Arguello. Time pressure, user satisfaction and task difficulty. Proc. of the American Society for Info. Sci. and Tech., 50(1):1­4, 2013.",0,,False
105,"[5] A. Edwards, D. Kelly, and L. Azzopardi. The impact of query interface design on stress, workload and performance. In Proc. of the 37th ECIR Conference, pages 691­702, Vienna, Austria, 2015.",1,ad,True
106,"[6] Y. Lee, A. N. K. Chen, and V. Ilie. Can online wait be managed? The effect of filler interfaces and presentation modes on perceived waiting time online. MIS Quarterly, 36(2):365­394, 2012.",0,,False
107,"[7] C. Liu, F. Yang, Y. Zhao, Q. Jiang, and L. Zhang. What does time constraint mean to information searchers? In Proc. of the 5th IIIX Conference, pages 227­230, 2014.",0,,False
108,"[8] D. Maxwell and L. Azzopardi. Stuck in traffic: How temporal delays affect search behavior. In Proc. of the 5th IIIX Conference, pages 155­164, 2014.",0,,False
109,"[9] R. B. Miller. Response time in man-computer conversational transactions. In Proc. of the 1968 Fall Joint Computer Conference, pages 267­277, 1968.",0,,False
110,"[10] N. Mishra, R. W. White, S. Ieong, and E. Horvitz. Time-critical search. In Proc. of the 37th ACM SIGIR conference, pages 747­756, 2014.",0,,False
111,"[11] R. Molich and J. Nielsen. Improving a human-computer dialogue. Comm. of the ACM, 33(3):338­348, 1990.",0,,False
112,"[12] J. W. Payne, J. R. Bettman, and E. J. Johnson. The Adaptive Decision Maker. Cambridge Uni. Press, 1993.",0,,False
113,"[13] R. Savolainen. Time as a context of information seeking. Library & Info. Sci. Research, 28(1):110­127, Mar. 2006.",0,,False
114,"[14] D. N. Stone and K. Kadous. The joint effects of task-related negative affect and task difficulty in multiattribute choice. Organizational Behavior and Human Decision Processes, 70(2):159­174, May 1997.",1,ad,True
115,"[15] N. J. Taylor, A. R. Dennis, and J. W. Cummings. Situation normality and the shape of search: The effects of time delays and information presentation on search behavior. J. of the A. Soc. for Info. Sci. and Tech., 64(5):909­928, 2013.",0,,False
116,"[16] J. Teevan, K. Collins-Thompson, R. W. White, S. T. Dumais, and Y. Kim. Slow search: Information retrieval without time constraints. In Proc. of the 7th HCIR Symposium, pages 1­10, 2013.",0,,False
117,"[17] A. Tombros, I. Ruthven, and J. M. Jose. How users assess web pages for information seeking. J. of the American Society for Info. Sci. and Tech., 56(4):327­344, 2005.",0,,False
118,"[18] E. M. Voorhees. Overview of the trec 2005 robust retrieval track. In Proceedings of TREC-14, 2006.",1,trec,True
119,770,0,,False
120,,0,,False
