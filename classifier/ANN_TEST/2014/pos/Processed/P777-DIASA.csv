,sentence,label,data,regex
0,Query Log Driven Web Search Results Clustering,1,Query,True
1,Jose G. Moreno,0,,False
2,"Normandie University UNICAEN, GREYC CNRS",0,,False
3,"F-14032 Caen, France",0,,False
4,jose.moreno@unicaen.fr,0,,False
5,Gaël Dias,0,,False
6,"Normandie University UNICAEN, GREYC CNRS",0,,False
7,"F-14032 Caen, France",0,,False
8,gael.dias@unicaen.fr,0,,False
9,Guillaume Cleuziou,0,,False
10,University of Orléans LIFO,0,,False
11,"F-45067 Orléans, France",0,,False
12,cleuziou@univ-orleans.fr,0,,False
13,ABSTRACT,0,,False
14,"Different important studies in Web search results clustering have recently shown increasing performances motivated by the use of external resources. Following this trend, we present a new algorithm called Dual C-Means, which provides a theoretical background for clustering in different representation spaces. Its originality relies on the fact that external resources can drive the clustering process as well as the labeling task in a single step. To validate our hypotheses, a series of experiments are conducted over different standard datasets and in particular over a new dataset built from the TREC Web Track 2012 to take into account query logs information. The comprehensive empirical evaluation of the proposed approach demonstrates its significant advantages over traditional clustering and labeling techniques.",1,TREC,True
15,Categories and Subject Descriptors,0,,False
16,H.3.3 [Information Storage and Retrieval]: Information search and retrieval--clustering,0,,False
17,General Terms,0,,False
18,"Algorithms, Experimentation",0,,False
19,Keywords,0,,False
20,"Web Search Results Clustering, Dual C-means, Automatic Labeling, Evaluation",0,,False
21,1. INTRODUCTION,1,DUC,True
22,"Web search results clustering (SRC), also known as post-retrieval clustering, multifaceted clustering or ephemeral clustering has received much attention for the past twenty years. SRC systems return meaningful labeled clusters from a set of Web snippets retrieved from any Web search engine for a given user's query. So far, most works have focused on the study of topical clustering [9] although some studies have been appearing in temporal clustering [1] and geospatial clustering [39]. As a consequence, SRC systems",0,,False
23,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609583.",1,ad,True
24,"can be particularly useful to understand query intents (topical clustering) and query diversity (temporal/geospatial clustering). In this paper, we particularly focus on topical SRC.",0,,False
25,"As opposed to classical text clustering, SRC must deal with small text fragments (Web snippets) and be processed in run-time. As a consequence, it is hard to implement efficiently and effectively [9]. So, most successful methodologies follow a monothetic approach [40, 10, 12, 35]. The underlying idea is to discover the most discriminant topical words in the collection and group together Web snippets containing these relevant terms. On the other hand, the polythetic approach, in which the main idea is to represent Web snippets based on the Vector Space Model (VSM) has received less attention [18, 22, 41, 30]. The main reason is the fact that the labeling process is a surprisingly hard extra task [9].",0,,False
26,"Our research is motivated by the fact that the adequate combination of the polythetic and monothetic approaches in a single algorithm should lead to improved performance over three important factors in SRC: clustering accuracy, labeling quality and partitionning shape. For that purpose, we present a new algorithm called Dual C-Means, which provides a theoretical background for dualrepresentation clustering. Its originality relies on the fact that different representation spaces can drive the clustering process as well as the labeling task in a single step.",1,ad,True
27,"We evaluated the proposed algorithm over different metrics (e.g. F1N [13], Fb3 [2], ARI [37], D#-nDCG [34]), well-studied datasets (e.g. ODP-239 [10], SEMEVAL [28]) and different representation spaces (e.g. text and query logs). The results show that the combination of the VSM representation of Web snippets and a querylog-based representation of cluster centroids achieves the best configuration for the SRC task. In particular, increased performance is shown against most SRC solutions (e.g. STC [40], LINGO [30], TOPICAL [35], LDA [7]). Our main contributions are :",1,ODP,True
28,"· A new algorithm (Dual C-Means), which can be seen as an extension of K-means [21] for dual-representation spaces;",0,,False
29,"· An instantiation of the Dual C-Means for SRC, which takes advantage of external resources such as query logs to improve clustering accuracy, labeling quality and partitioning shape;",1,ad,True
30,· A new annotated dataset (WEBSRC401) based on the TREC Web Track 2012 for full SRC evaluation over the Web.,1,TREC,True
31,"In the next section, we present the most important recent studies for SRC. In the third section, we present the general model of the Dual C-Means algorithm and its instantiation in the context of SRC. In the fourth section, we explain the construction of the WEBSRC401 dataset. In the fifth and sixth sections, we present the experimental setups and show the results obatined for different strategies over an exhaustive set of well-known evaluation metrics,",0,,False
32,777,0,,False
33,"datasets and state-of-the-art algorithms. Finally, we draw some conclusions about our experiments and propose new perspectives.",0,,False
34,2. RELATED WORK,0,,False
35,"A good survey of SRC methodologies can be found in [9]. As a consequence, we give a brief overview of older methodologies and focus on more recent works. The first important work in SRC is certainly proposed by [18]. They define a polythetic approach based on the VSM representation where similarity between documents is computed with cosine similarity measure. Then, a nonhierarchical partitioning strategy called fractionation is performed to discover the number of clusters suggested by the user. Initial results show that their ""approach to document clustering is one which can produce significant improvements over similarity search ranking alone"". Although they present the foundations of SRC, labeling is not tackled and evaluation is based on a small dataset and a limited user study.",0,,False
36,"In order to propose a more realistic solution, which includes labeling, [40] defined the Suffix Tree Clustering (STC) algorithm. They propose a monothetic clustering technique, which merges base clusters with high string overlap. Instead of using the VSM representation, they propose to represent Web snippets as compact tries. Their evaluation over a small set of 10 queries shows that STC outperforms group-average agglomerative hierarchical clustering, K-Means, buckshot, fractionation and single-pass algorithms. STC is still considered as a hard baseline to compete with.",1,ad,True
37,"Later, [30] proposed a polythetic approach called LINGO, which takes into account the string representation proposed by [40]. They first extract frequent phrases based on suffix-arrays. Then, they reduce the term-document matrix (defined as a VSM) using Single Value Decomposition to discover latent structures. Finally, they match group descriptions with the extracted topics and assign relevant documents to them. LINGO is evaluated with 7 users over a set of 4 search results and as such, no conclusive remarks can be drawn. However, their publicly available implementations of LINGO, STC and BiKM (Bi-section K-means) provide researchers with useful tools to build SRC systems.",0,,False
38,"More recently, [10] showed that the characteristics of the outputs of SRC algorithms suggest the adoption of a meta clustering approach. For that purpose, they introduce a novel criterion to measure the concordance of two partitions of Web snippets into different clusters based on the information content associated with the decisions made by the partitions on single pairs of Web snippets. A meta clustering phase is then casted to an optimization problem of the concordance between the clustering combination and the given set of clusterings. The results of their OPTIMSRC system demonstrate that meta clustering is superior over individual clustering techniques. In particular, they propose a dataset called ODP-239, which is widely used in the community.",1,ad,True
39,"Another polythetic methodology is proposed in [26]. Their underlying idea is that informative text similarity measures can improve SRC by adequately capturing the latent semantics conveyed by Web snippets. They propose a K-means based algorithm called GK-means within which a new objective function defined for a third-order similarity measure must be maximized. As different partitions are possible depending on the K value, they propose an automatic stopping criterion to retrieve one ""optimal"" clustering solution. Their main contribution is the fact that labels are built during the clustering process thus avoiding an extra processing step. Their results show improvements for ODP-239 in terms of Fb3 over all text-based SRC algorithms.",1,ad,True
40,"While all studies mentioned so far treat the task of SRC as a textbased problem, some other works propose to introduce external re-",0,,False
41,sources. The first relevant work is presented in [16] where Web snippets are enriched with anchor text information and high quality indexes extracted from DMOZ. The underlying idea of their monothetic approach called SNAKET is that better labeling and clustering can be obtained from these external resources. Results over a non-standard dataset show that the introduction of external information improves Precision at different clustering levels. [16] certainly proposed a new trend in SRC.,0,,False
42,"Following the same idea, [35] proposed TOPICAL, a top performing SRC system over ODP-239 dataset. They propose to move away from the bag of words representation towards a graph of topics paradigm derived from TAGME, a wikification algorithm [38]. Each Web snippet is annotated with a set of topics, which are represented by Wikipedia articles. A bipartite-like graph structure is built where nodes are either Web snippets or topics and edges are either topic-to-topic or topic-to-snippet. Then, a spectral-like clustering algorithm is run over the graph to discover relevant clusters and meaningful labels. TOPICAL is an interesting approach as clustering is driven by the presence of Wikipedia titles in Web snippets and inderectly assures the quality of the labeling.",1,ODP,True
43,"Another idea has recently been proposed in [13], which relies on Web n-grams. In order to better capture the similarity between Web snippets, a first step consists in building a co-occurence graph based on Dice coefficient calculated over the Google Web1T corpus [8] from which senses are discovered by word sense induction algorithms. Each Web snippet is represented as a bag-of-words (polythetic approach) but Similarity is computed over discovered word senses. Their experiments show that enhanced diversification and clustering performance results can be obtained based on the adjusted RandIndex [37] for a specific dataset built for ambiguous queries (MORESQUE). Recently, researchers from the same team proposed a new dataset within the context of the SEMEVAL task 11 [28], in which the goal is to provide an evaluation framework for the objective comparison of word sense disambiguation and induction algorithms in SRC for ambiguous queries.",1,ad,True
44,"All works propose interesting issues for SRC. On one hand, the monothetic approach mainly focuses on the identification of strong meaningful labels. The underlying idea is that good labels are a key factor for the success of user experience in Web search. On the other hand, the polythetic approach concentrates on discovering high quality clusters and the labeling task is usually treated as a separate process. The subjacent motivation is that good clustering should be provided to improve user experience in search for information. Moreover, recent studies show that the introduction of external resources improves overall results.",0,,False
45,"In this paper, we propose that both monothetic and polythetic approaches should be combined in a single algorithm capable of accepting external resources. For that purpose, we present the Dual C-Means algorithm, which extends the well-known K-Means for dual representation spaces. It particularity relies on the fact that different representation spaces compete to reach high clustering quality and meaningful labeling. In particular, we propose that query logs are introduced as external information to ensure quality labeling and drive the clustering process. The main characteritics of our proposal are as follows:",0,,False
46,· New combination of polythetic and monothetic approaches in one single algorithm;,0,,False
47,· Introduction of dual representations for Web snippets allowing the introduction of external resources;,0,,False
48,· Theoretical framework based on an extension of K-means;,0,,False
49,· First proposal with query logs as external resource for SRC.,0,,False
50,778,0,,False
51,3. DUAL C-MEANS ALGORITHM,0,,False
52,"This section is devoted to the presentation of the Dual C-Means algorithm that extends the classical K-means [21] for dual representation spaces. In the first subsection, we present the general model and in the second one we propose its instantiation for the specific task of SRC.",0,,False
53,3.1 General Model,0,,False
54,"Let S be a dataset to partition where each data si  S is described on a representation space E1 and additionally, E2 denotes another space supporting cluster representation. We hypothesize the existence of a function d : E1 × E2  R+ quantifying the dissimilarity between any data from E1 and any cluster representative (cluster centroid) from E2. The new proposed clustering model (Dual CMeans) is driven by the objective criterion defined in Equation 1, which must be minimized.",1,ad,True
55,c,0,,False
56,"Jdcm(, M) ,""   d(si, mk)""",0,,False
57,(1),0,,False
58,"k,1 sik",0,,False
59,"As illustrated in Figure 1, the aim of the minimization of Jdcm(, M) is to find a partition of S into c clusters ( ,"" {1, . . . , c}) such that in each cluster k any object is as closed as possible to a common""",0,,False
60,"cluster representative mk (M ,"" {m1, . . . , mc}).""",0,,False
61,E2 mk,0,,False
62,"d(si, mk)",0,,False
63,E1,0,,False
64,k,0,,False
65,si,0,,False
66,Figure 1: Dual C-Means aims to discover clusters of objects in E1 closed to a common cluster representative in E2.,0,,False
67,"as dissimilarity d(., .), the Dual C-Means algorithm comes down exactly to the usual K-means algorithm (mtk+1 ,"" sikt si/|kt |). Finally, such as K-means, Dual C-Means is sensitive to random initialization and requires the number of expected clusters (C) as parameter1.""",0,,False
68,3.2 Instantiation in the SRC Context,0,,False
69,"In the context of SRC, objects are naturally Web snippets represented in the E1 space (si  S) and cluster representatives are labels represented in the E2 space (mk  M).",0,,False
70,"The crucial hypothesis of the Dual C-Means algorithm is the existence of a dissimilarity metric d(., .) capable of comparing objects from different feature spaces. For that purpose, a matching process between the two feature sets is required that can be formalized as a transition matrix P (p1 × p2) quantifying this matching for each of the p1 features defined in E1 with each of the p2 features from E2.",0,,False
71,"Without loss of generality, we define a generic dissimilarity measure considering such a transition matrix in Equation 2 where mTk is the transposed label vector, siPmTk quantifies a similarity between a Web snippet si and a label mk, and  is a constant to adjust in order to ensure dissimilarity values in R+.",1,ad,True
72,"d(si, mk) ,  - siPmTk",0,,False
73,(2),0,,False
74,Such a dissimilarity form allows us to rewrite the Dual C-Means algorithm as a maximization problem defined in Equation 3.,0,,False
75,c,0,,False
76,c,0,,False
77,    min,0,,False
78,",M",0,,False
79,"k,1",0,,False
80,si,0,,False
81,k,0,,False
82,d,0,,False
83,(si,0,,False
84,",",0,,False
85,mk,0,,False
86,),0,,False
87,max,0,,False
88,",M",0,,False
89,"k,1",0,,False
90,si,0,,False
91,k,0,,False
92,si,0,,False
93,PmTk,0,,False
94,(3),0,,False
95,"Let us notice that when the label space E2 is unconstrained (e.g. E2 ,"" Rp2 ), the resolution of Equation 3 has no sense (M "", +).",0,,False
96,"But in the SRC context, a small set of words (i.e. the labels)",0,,False
97,are usually chosen to help the user in his search for information.,0,,False
98,"Thus, we consider two vocabularies V1 and V2 defining the two",0,,False
99,feature spaces E1 and E2 respectively. We constrain Web snip-,0,,False
100,"pet descriptions to be word distributions over V1 (si, j  [0, 1] i, j",0,,False
101,and,0,,False
102,"p1 j,1",0,,False
103,"si, j",0,,False
104,",",0,,False
105,1),0,,False
106,and,0,,False
107,cluster,0,,False
108,labels,0,,False
109,to,0,,False
110,subsets,0,,False
111,of,0,,False
112,p,0,,False
113,words,0,,False
114,from,0,,False
115,V2,0,,False
116,"(E2 ,"" {mk  {0, 1}p2 | lp"",""2 1 mk,l "", p}).",0,,False
117,"Within that context, the computation of optimal cluster labels is",0,,False
118,a discrete optimization process solved for each cluster k indepen-,0,,False
119,"dently, by first sorting the vocabulary V2 from the most relevant word (l1k) to the less relevant one (lkp2 ) using the relevance function defined in Equation 4",0,,False
120,The optimization process can be achieved by an usual dynamic reallocation algorithm starting with a random initial clustering 0 and then iterating the following two steps (Update and Assignment) until convergence:,0,,False
121,"1. Update: compute new optimal cluster representatives Mt+1 considering a fixed partition t ,",0,,False
122,2. Assignment: compute new optimal assignments t+1 considering fixed cluster representatives Mt+1 and use the following rule to assign each object to its closest representative:,0,,False
123,"si, si  k  k , arg minl,""1,...,c d(si, ml ).""",0,,False
124,"Note that the update of cluster representatives has to be defined depending on both the dissimilarity measure d(., .) and the representative space E2 in order to ensure that the objective criterion Jdcm(., .) decreases. Let us also notice that in the specific case where E1 , E2 , Rn and the squared euclidean distance is chosen",0,,False
125,"l, k k(l) ,""  siP.,l""",0,,False
126,(4),0,,False
127,si k,0,,False
128,and then defining a cluster label vector mk as the combination of the p most relevant words from V2 for the snippets in k as proposed in,0,,False
129,Equation 5.,0,,False
130,{,0,,False
131,"mk,l ,",0,,False
132,1 if l  lkp 0 otherwise,0,,False
133,(5),0,,False
134,"It is interesting to notice that the GK-means, recently proposed by [26], falls into such an SRC instantiation of the Dual C-Means algorithm if the following constraints are true:",0,,False
135,"· Web snippet and label representation spaces are not dissociated (i.e. V1 , V2) thus not taking benefit from the duality of the clustering algorithm;",0,,False
136,1These issues will be tackled in the Evaluation section.,0,,False
137,779,0,,False
138,"· The transition matrix P is computed with the Symmetric Conditional Probability (SCP [36]) or the Pointwise Mutual Information (PMI [11]) on the unique vocabulary V1 , V2.",0,,False
139,"To make use of the duality concept from the new proposed algorithm in the SRC context, we suggest differentiating the two vocabularies V1 and V2. First, V1 is defined as the bag of words occurring in all Web snippets retrieved for a given query. Second, if we consider a set Y of query logs, the vocabulary V2 is defined by the bag of words occurring in Y and E2 is restricted to the set of query logs defined as distributions in the vector space model induced by V2. This situation is formalized in Equation 6 with i denoting the size of the query log yi.",0,,False
140, E2,0,,False
141,",",0,,False
142,{yi,0,,False
143,"{0,",0,,False
144,1 i,0,,False
145,}p2 |,0,,False
146,p2,0,,False
147,"yi,",0,,False
148,"j,1",0,,False
149,j,0,,False
150,",",0,,False
151,1,0,,False
152,and,0,,False
153,yi,0,,False
154,Y,0,,False
155,},0,,False
156,(6),0,,False
157,As such clustering is polythetic but query log driven. Figure 2 illustrates the instantiation of the Dual C-Means algorithm in the SRC context where the restricted set of available query logs guides the cluster formation process.,0,,False
158,"E2 , {query - logs}",0,,False
159,"y1 ,"" (jaguar, animal, black) y2 "","" (jaguar, car)""",0,,False
160,"s1 ,"" """"The black jaguar is one of three called panther...""""""",0,,False
161,"E1 , {snippets}",0,,False
162,Figure 2: Example of the Dual C-Means instantiated for the SRC context with query logs as cluster label space.,0,,False
163,4. THE WEBSRC401 DATASET,0,,False
164,"Different gold standards have been used for the evaluation of SRC algorithms among which the most cited are: AMBIENT [6], ODP-239 [10], MORESQUE [27] and SEMEVAL [28]. As ODP239 is an evolution of AMBIENT and SEMEVAL is the next generation of MORESQUE, we will only give an overview of the most recent datasets.",1,ODP,True
165,"In ODP-239, each document is represented by a title and a Web snippet and the subtopics are chosen from the top levels of DMOZ2. However, this dataset does not represent the typical kind of results obtained through querying a given search engine as the number of possible subtopics is always equal to 10. It is clear that this structure clearly differs from a typical Web results set. Moreover, queries are not extracted from query logs but rather chosen based on the categories present in DMOZ. However, it is a publicly available dataset that allows us to conduct experiments to evaluate clustering accuracy. 2http://www.dmoz.org [Last access: 27/01/2014].",1,ODP,True
166,"On the other hand, the subtopics in SEMEVAL follow a more natural distribution as they are defined based on the disambiguation pages of Wikipedia. As such, these subtopics are likely to cover most of the senses present in the Web for the 100 evaluated queries. However, SEMEVAL is built to specifically deal with ambiguous queries, which are self-contained in Wikipedia. But, it is clear that not all queries in general are Wikipedia articles or ambiguous. For example, many queries are multifaceted but not ambiguous [19]. Let us take ""Olympic Games"". Its Wikipedia entry is not ambiguous but it presents many different facets such as History, Logos, Year dates or Cities, to name but a few.",1,Wiki,True
167,"As a consequence, it is clear that different results can be obtained from one dataset to another. A quick summary of both datasets is presented in Table 1.",0,,False
168,Dataset,0,,False
169,ODP-239 SEMEVAL WEBSRC401,1,ODP,True
170,# of queries,0,,False
171,239 100 50,0,,False
172,# of Subtopics Avg / Min / Max,0,,False
173,10 / 10 / 10 7.7 / 2 / 19 3.9 / 3 / 6,0,,False
174,# of Web snippets,0,,False
175,25580 6400 5560,0,,False
176,Table 1: Description of the SRC gold standard datasets.,0,,False
177,"To afford a more realistic situation in the context of Web search results, we propose a new SRC dataset based on the ClueWeb09 Category B text collection (CCB)3, which comprises about 50 million English-language pages, including the entirety of the Englishlanguage Wikipedia and task descriptions of the TREC Web Track 2012. The goal of TREC Web Track 2012 is to return a ranked list of Web pages that together provide complete topical coverage of a given query, while avoiding excessive redundancy of the subtopics in the result list. In particular, each topic contains a query field, a description field and several subtopic fields which can be ambiguous or multifaceted. And for each topic, a judgement file (i.e. qrel) includes the list of relevant Web pages from CCB and the manually attributed grade of the Web page subtopic.",1,ClueWeb,True
178,"Instead of retrieving relevant Web pages, we are interested in obtaining relevant clusters (i.e. Web pages with the same subtopic) with high coverage of all the subtopics. So, we propose transforming the data available in the TREC Web Track 2012 in a typical SRC format [10], which result in the WEBSRC401 dataset4. First, for each Web page considered as query-relevant, its Web snippet is retrieved using the SnippetGenerator function of ChatNoir5. By default, a Web snippet composed of a maximum of 500 characters found around the query words is provided.",1,ad,True
179,"Secondly, for each query, its subtopics are defined as in the TREC Web Track 2012 and each qrel is encoded in a new format, which contains the Web page id, the subtopic id and the query6. Additionally, it is important to notice that the WEBSRC401 dataset facilitates the evaluation of new techniques based on more complex resources provided by researchers as it is based on the well-studied ClueWeb09. For example, cluster ranking or spam cluster filtering studies could be endeavored with the PageRank scores and the spam rankings of ClueWeb09 dataset which are publicly available.",1,TREC,True
180,5. CLUSTERING EVALUATION,0,,False
181,"As mentioned in [9], evaluating SRC systems is a hard task. Indeed, the evaluation process is three-fold. A successful SRC sys-",0,,False
182,"3http://lemurproject.org/clueweb09/ [Last access: 27/01/2014] 4http://websrc401.greyc.fr/ [Last access: 10/05/2014]. 5http://chatnoir.webis.de/ [Last access: 27/01/2014]. 6Note that these steps could be used to extend the dataset with the TREC Web tracks of the years 2009, 2010 and 2011.",1,TREC,True
183,780,0,,False
184,tem must discover relevant topical clusters (clustering accuracy) and propose meaningful labels at the same time (labeling quality). We will also see in our experiments that partition shape is also an important factor to study.,0,,False
185,5.1 Evaluation of SRC,0,,False
186,"Firstly, a successful SRC system must evidence high quality level clustering. Ideally, each query subtopic should be represented by a unique cluster containing all the relevant Web pages inside. However, this task is far from being achievable. As such, this constraint can be reformulated as for the TREC Web Track 2012: the task of SRC systems is to provide complete topical cluster coverage of a given query, while avoiding excessive redundancy of the subtopics in the result list of clusters.",1,TREC,True
187,"Secondly, SRC systems should present meaningful labels to the user to ease their search for information. As such, the evaluation of the labeling task is of the utmost importance. As far as we know, only [10, 35] propose the evaluation of both dimensions. However, their experiments are not reproducible as they rely on manually annotated datasets, which are not publicly available.",0,,False
188,"Thirdly, SRC differs from classical text clustering as the partitioning shape, more precisely the distribution of the Web snippets into clusters, shows evidence of some particularity. Indeed, it is well-known that subtopics on the Web are not equally distributed. For example, for the query ""Apple"", it is much more likely to find Web snippets related to the company than the concept of fruit. In particular, we will see in our experiments that not all evaluation metrics cover this situation.",0,,False
189,"In the next sections, we propose a complete set of repeatable experiments to give an exhaustive overview of the SRC field. We start by focusing on the experimental setups.",0,,False
190,5.2 Experimental Setups,0,,False
191,"In this section, we propose the comparison of different configurations of the Dual C-Means to several state-of-the-art algorithms using well-studied evaluation metrics.",0,,False
192,Dual C-Means Configurations.,0,,False
193,"The originality of the Dual C-Means is to embody a great number of possible configurations due to the expressiveness of its model. In this paper, we will particularly focus on two main issues. The first one deals with using different similarity measures to compute the transition matrix P. The underlying idea is supported by the fact that different word similarity measures produce different results [31]. As a consequence, we aim to understand their impact on the SRC task. The second one aims to test our initial hypothesis stating that the introduction of external resources can improve SRC. As a consequence, we propose two different space representations: text-text (i.e. V1 , V2) and text-query logs (i.e. V1 , V2).",0,,False
194,Word Similarity Measures.,0,,False
195,"The use of word similarity metrics is an important and interchangeable component of our algorithm encoded in the transition matrix. In this study, we propose the comparison of a total of five collocation metrics7. In particular, we used the Symmetric Conditional Probability (SCP) [36], the Pointwise Mutual Information (PMI) [11], the Dice coefficient [14], the LogLikelihood ratio (LogLike) [15] and 2 [17]. Each metric is defined in Table 2. The expressiveness of the Dual C-means permits the definition of different types of word similarity measures. As a consequence, we",0,,False
196,"7It is clear that a great deal of association measures that could be tested exist. However, we selected the ones which best complement themselves.",0,,False
197,"also compute word-word similarity based on the VSM representation. In particular, for each snippet si  S, a simple word-word similarity measure is ST S where ST is the transposed of the snippetterm matrix S. In this case, P ,"" ST S. Another interesting similarity measure is LSA [20], which can be formulated as follows: P "","" U e UT where U  UT is the eigen decomposition of ST S, and e is the number of highest eigen values selected to represent the latent space8.""",0,,False
198,SRC Algorithms.,0,,False
199,"We aim to compare our algorithm to the most competitive strategies proposed so far in the SRC literature. For that purpose, we show the results of STC [40], LINGO [30], TOPICAL [35] and LDA [7]. It is worth noticing that for evaluation purposes, we developed an open source implementation9 of TOPICAL using the Wikipedia Miner API proposed by [24] and the spectral algorithm proposed by [29] included in SCIKit learning tool10. For LINGO and STC algorithms, we used the Carrot2 API11. And for LDA, we used the topic modeling package included in MALLET toolkit [23]. The parameters were set following the toolkit instructions (i.e. stop-words removal, t ,"" 0.01, w "", 0.01 and limited to 1000 iterations) and the cluster membership is assigned taken the maximum topic probability value.",1,Wiki,True
200,Evaluation Metrics.,0,,False
201,"Different metrics have been proposed to evaluate text clustering. Within this paper, we present the results for the most relevant metrics. The first complete study in terms of evaluation has certainly been proposed by [10]. In the specific case of SRC, the authors propose the F1C metric, which is a specific implementation of the more general F measure. Other metrics have also been proposed. For example, the Fb3 measure [2] addresses many important problems in clustering such as cluster homogeneity, completeness, rag-bag and size-vs-quantity constraints, and has shown interesting properties for the SRC task as formulated in [26]. Two other important metrics have been studied in [13]: F1N and the Adjusted RandIndex (ARI) [37]. In particular, F1N can be seen as a complementary metric of F1C as it is also based on the classical F measure but computed in a different manner12, while ARI evidences an interesting property for SRC. While it measures clustering accuracy, it also takes into account the fact that a given partition shows a similar partitioning shape compared with the reference gold standard. The underlying idea is that the number of clusters and the average number of Web snippets in each cluster approximate as much as possible the reference clustering. An illustration of this situation can be seen in [25] although the authors do not refer to this issue as an important one for SRC. In terms of implementation, we used the Java evaluator13 to compute both F1N and ARI evaluation metrics, and the implementation provided by [3]14 to compute Fb3 . In Table 3, we defined all the metrics used for our experiments.",1,ad,True
202,"8In our experiments, this value was set to the minimum which guarantees that ei,1 i  0.9 ip,""11 i. 9This implementation is publicly available upon request. 10http://scikit-learn.org/stable/ [Last access: 27/01/2014]. 11http://search.carrot2.org/stable/search [Last access: 27/01/2014]. 12Let us notice that these are two F1 measures, which computation is defined differently in [10] and [13]. 13http://www.cs.york.ac.uk/semeval2013/task11/index.php?id"",data [Last access: 27/01/2014]. 14http://nlp.uned.es/~enrique/software/RS.zip [Last access: 27/01/2014].",0,,False
203,781,0,,False
204,"Collocation Metric SCP(wi, w j) PMI(wi, w j) DICE(wi, w j)",0,,False
205,"LogLike(wi, w j) 2(wi, w j)",0,,False
206,Formula,0,,False
207,"P(wi,w j)2",0,,False
208,P(wi)P(w j),0,,False
209,log2,0,,False
210,"P(wi,w j) P(wi)P(w j)",0,,False
211,"2 f (wi,w j)",0,,False
212,f (wi)+ f (w j),0,,False
213,"-2  logLike( f (wi, w j),",0,,False
214,"f (wi),",0,,False
215,f,0,,False
216,(w N,0,,False
217,j,0,,False
218,),0,,False
219,),0,,False
220,+,0,,False
221,l,0,,False
222,ogLike(,0,,False
223,f,0,,False
224,(w,0,,False
225,j,0,,False
226,),0,,False
227,-,0,,False
228,"f (wi, w j), N",0,,False
229,-,0,,False
230,"f (wi),",0,,False
231,f,0,,False
232,(w N,0,,False
233,j,0,,False
234,),0,,False
235,),0,,False
236,"-logLike( f (wi, w j),",0,,False
237,"f (wi),",0,,False
238,f,0,,False
239,"(wi,w j f (wi)",0,,False
240,),0,,False
241,),0,,False
242,-,0,,False
243,l,0,,False
244,ogLike(,0,,False
245,f,0,,False
246,(w,0,,False
247,j,0,,False
248,),0,,False
249,-,0,,False
250,"f (wi, w j), N",0,,False
251,-,0,,False
252,"f (wi),",0,,False
253,"f (w j)- f (wi,w j) N- f (wi))",0,,False
254,"where logLike(a, b, c) , (a  Log(c)) + ((b - a)  Log(1 - c))",0,,False
255,"P(wi,w j)-P(wi)P(w j) P(wi)P(w j)(1-P(wi))(1-P(w j))",0,,False
256,"Table 2: Collocation metrics used in our framework where P(wi, w j) is the joint probability of words wi and w j, P(wi) is the marginal probability of the word wi, f (wi, w j) is the frequency of word pairs (wi, w j), f (wi) is the frequency of the word wi and N is the number of retrieved Web snippets.",0,,False
257,Evaluation Metric,0,,False
258,F1C,0,,False
259,",",0,,False
260,2PR P+R,0,,False
261,Fb3,0,,False
262,",",0,,False
263,2Pb3 Rb3 Pb3 +Rb3,0,,False
264,F1N,0,,False
265,",",0,,False
266,2PR P+R,0,,False
267,"ARI(, ) and",0,,False
268,where,0,,False
269,k,0,,False
270,k,0,,False
271,P,0,,False
272,",",0,,False
273,T,0,,False
274,TP P+F P,0,,False
275,",",0,,False
276,R,0,,False
277,",",0,,False
278,TP T P+FN,0,,False
279,",TP",0,,False
280,",",0,,False
281,"   g0(x j, xl), FP",0,,False
282,"z,""1x jzxl z,l"", j",0,,False
283,",",0,,False
284,"i,1x",0,,False
285,j i,0,,False
286,xl,0,,False
287,"i ,l ,",0,,False
288,(1,0,,False
289,j,0,,False
290,-,0,,False
291,g0,0,,False
292,(x,0,,False
293,j,0,,False
294,",",0,,False
295,xl,0,,False
296,")),",0,,False
297,k,0,,False
298,"FN ,""    (1 - g0(x j, xl))""",0,,False
299,"z,""1x jzxl z,l"", j",0,,False
300,Pb3,0,,False
301,",",0,,False
302,1 N,0,,False
303,k,0,,False
304,"i,1",0,,False
305,1 |i,0,,False
306,|,0,,False
307,x,0,,False
308,j i,0,,False
309,xl i,0,,False
310,g0,0,,False
311,(x,0,,False
312,j,0,,False
313,",",0,,False
314,xl,0,,False
315,"),",0,,False
316,Rb3,0,,False
317,",",0,,False
318,1 N,0,,False
319,k,0,,False
320,"z,1",0,,False
321,1 |z,0,,False
322,|,0,,False
323,x,0,,False
324,j,0,,False
325,z,0,,False
326,xl,0,,False
327,z,0,,False
328,g0,0,,False
329,(x,0,,False
330,j,0,,False
331,",",0,,False
332,xl,0,,False
333,),0,,False
334,k,0,,False
335,k,0,,False
336,P,0,,False
337,",",0,,False
338,"1 ki,1 |i",0,,False
339,|,0,,False
340,"i,1maxz",0,,False
341,(,0,,False
342,f,0,,False
343,(z,0,,False
344,",",0,,False
345,i,0,,False
346,")),",0,,False
347,R,0,,False
348,",",0,,False
349,"1 kz, 1 |z",0,,False
350,|,0,,False
351,"z,1",0,,False
352,f,0,,False
353,(z,0,,False
354,",",0,,False
355,i,0,,False
356,z,0,,False
357,i,0,,False
358,),0,,False
359,b  z,0,,False
360,"z ,"" arg maxa( f (a, b)),""",0,,False
361,f,0,,False
362,(a,0,,False
363,",",0,,False
364,b,0,,False
365,),0,,False
366,",",0,,False
367,x,0,,False
368,j,0,,False
369,a,0,,False
370,xl,0,,False
371,b,0,,False
372,g1,0,,False
373,(x,0,,False
374,j,0,,False
375,",",0,,False
376,xl,0,,False
377,),0,,False
378,"ARI(, ) ,",0,,False
379,"RI (, )-E (RI (, )) maxRI (, )-E (RI (, ))",0,,False
380,where,0,,False
381,{,0,,False
382,"RI(, )",0,,False
383,",",0,,False
384,T,0,,False
385,T P+T P+F P+F,0,,False
386,N N+T,0,,False
387,N,0,,False
388,",",0,,False
389,T,0,,False
390,N,0,,False
391,",",0,,False
392,N,0,,False
393,-{T P - FP - FN,0,,False
394,"g0(xi, x j) ,",0,,False
395,"1  l : xi  l  x j  l 0, otherwise",0,,False
396,"g0(xi, x j) ,",0,,False
397,"1  l : 0, otherwise",0,,False
398,xi  l  x j  l,0,,False
399,"where i is the cluster solution i ( , i) and{i is the gold standard of the category i ( , i).",0,,False
400,"g1(xi, x j) ,",0,,False
401,"1  xi ,"" x j 0, otherwise""",0,,False
402,Table 3: Clustering Evaluation Metrics.,0,,False
403,Text Processing and Implementation.,0,,False
404,"All Web snippets were tokenized with the GATE platform15 but we did not apply stop-words removal so that we can propose a language-independent solution. In terms of dynamic reallocation algorithm, we used the optimized version of K-means++ proposed in [4] as the intialization process is semi-deterministic16 and there exists an efficient implementation called Scalable K-means++ [5].",0,,False
405,5.3 Clustering Results,0,,False
406,"A great deal of experiments have been performed to achieve conclusive results. We first propose evaluating the clustering accuracy of the Dual C-Means against different state-of-the-art algorithms. For that purpose, we propose an exhaustive search as in [35], whose underlying idea is to evaluate the behavior of a given algorithm along with the increasing number of output partitions. In this first set of experiments, we pretend to understand the clustering quality of our approach when only text information is taken into account",0,,False
407,"15http://gate.ac.uk/ [Last access: 27/01/2014]. 16Note that for our experiments, the first seed Web snippet is selected as the one, which is most similar to all other ones in S.",0,,False
408,"(i.e. V1 ,"" V2 and the number of p words composing the centroids is set to 2) and compare it to state-of-the-art algorithms. In particular,""",0,,False
409,"we present the results for 20 runs (K ,"" 2..20) and illustrate the Fb3 values over ODP-239 and WEBSRC401 in Figure 3. Indeed, recent""",1,ODP,True
410,studies in [2][3] show that Fb3 is a superior metric to the classical F measures to compute clustering accuracy.,0,,False
411,"The obtained results show interesting situations. In all cases,",0,,False
412,Dual C-means outperforms state-of-the-art algorithms in terms of,0,,False
413,"clustering accuracy. In particular, SCP, DICE and LogLike show",0,,False
414,"improved results and outperform other word-word similarity metrics. It is interesting to notice that PMI and 2, which are known",0,,False
415,to give less importance to more frequent events show less relevant,0,,False
416,"results. As for the state-of-the-art algorithms, best results are ob-",0,,False
417,tained by STC improving over TOPICAL and LDA.,0,,False
418,These results only give a small idea of the overall phenomena.,0,,False
419,"In Tables 4, 5 and 6, results for 10 cluster outputs are given for",0,,False
420,all metrics and all datasets. These new results show interesting,0,,False
421,"properties of evaluation metrics. Although Dual C-means shows improvements over all competitors in terms of Fb3 or F1C (except in one case) for ODP-239, SEMEVAL and WEBSRC401, this situation does not stand for the other metrics, ARI or F1N . For ODP-239,",1,ODP,True
422,782,0,,False
423,Fbcubed-measure Fbcubed-measure,0,,False
424,0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
425,0 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 k,0,,False
426,SCP PMI DICE LogLike PHISquared TOPICAL STC Lingo,0,,False
427,0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,0,,False
428,0 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 k,0,,False
429,Figure 3: Impact of K for Fb3 against ODP-239 (left) and WEBSRC401 (right) datasets.,1,ODP,True
430,SCP PMI DICE LogLike PHISquared STS TOPICAL STC Lingo LDA,0,,False
431,"the best results are obtained by LDA in terms of ARI and LINGO in terms of F1N . For SEMEVAL, the best performances are provided by STC in terms of ARI and LINGO in terms of F1N . Deep analysis shows that ARI embodies an interesting property for the SRC task",0,,False
432,as it is well-known that the sizes of the clusters are not distributed,0,,False
433,"equally on the Web. Indeed, ARI tends to favor solutions, which",0,,False
434,show similar partitioning shapes to the gold standard. As a con-,0,,False
435,"sequence, a good SRC system should be performant both in terms of ARI and Fb3 . On the other hand, F1N shows inconsistent results when compared to all other metrics. In particular, it tends to give",0,,False
436,high results when the other metrics decrease.,0,,False
437,Although different results are obtained for SEMEVAL and ODP-,1,ODP,True
438,"239, steady results are obtained for WEBSRC401 by the Dual CMeans configured with the ST S word-word similarity metric. In-",1,ad,True
439,"deed, it clearly outperforms all other algorithms in terms of Fb3 , F1C and ARI. At this stage of our experiements, we can conclude that this configuration provides the best performance both in terms",0,,False
440,of clustering accuracy and partitioning shape.,0,,False
441,ODP-239 SEMEVAL WEBSRC,1,ODP,True
442,LDA LINGO,0,,False
443,STC TOPICAL,0,,False
444,LDA LINGO,0,,False
445,STC TOPICAL,0,,False
446,LDA LINGO,0,,False
447,STC TOPICAL,0,,False
448,F1N 0.5978 0.6636 0.5499 0.5760,0,,False
449,0.7159 0.7742 0.7223 0.6791,0,,False
450,0.7020 0.7123 0.6779 0.6932,0,,False
451,ARI 0.2571 0.0920 0.1597 0.1505,0,,False
452,0.1313 0.0783 0.1704 0.0621,0,,False
453,0.0268 0.0247 0.0220 0.0203,0,,False
454,Fb3 0.4370 0.3461 0.4027 0.3799,0,,False
455,0.3966 0.3662 0.4632 0.3998,0,,False
456,0.3214 0.3095 0.4293 0.3083,0,,False
457,F1C 0.3900 0.2029 0.3238 0.2839,0,,False
458,0.2840 0.2072 0.3682 0.2723,0,,False
459,0.2613 0.2502 0.3905 0.2522,0,,False
460,"Table 4: Results of state-of-the-art algorithms for the ODP-239, SEMEVAL, WEBSRC401. K fixed to 10 Clusters for LDA and TOPICAL.",1,ODP,True
461,"The second set of our experiments aims to analyse the behavior of Dual C-Means when external resources are included. In this case, we use the set of query logs provided by the NTCIR-10 Intent2 task [32] and propose to drive the clustering process by this external information. As such, a cluster centroid is represented by its most representative query log. Results are presented in Table 6 where V1 , V2 for WEBSRC401. Let us notice that this is the only dataset for which experiments with query logs can be performed and easily reproduced.",0,,False
462,SEMEVAL ODP239,1,ODP,True
463,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
464,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
465,F1N 0.6114 0.6634 0.6245 0.5753 0.6797 0.6225 0.6219,0,,False
466,0.4961 0.5671 0.5181 0.5078 0.5479 0.5294 0.5482,0,,False
467,ARI 0.0435 0.1072 0.0545 0.0209 0.1055 0.0319 0.0240,0,,False
468,0.0865 0.1741 0.1213 0.1388 0.1618 0.1304 0.1490,0,,False
469,Fb3 0.5632 0.4198 0.5763 0.5416 0.3972 0.5722 0.5645,0,,False
470,0.4845 0.4041 0.4939 0.4285 0.3759 0.4852 0.4712,0,,False
471,F1C 0.4856 0.3297 0.4914 0.4934 0.2932 0.4808 0.4684,0,,False
472,0.3785 0.3231 0.3885 0.3650 0.3059 0.3822 0.3731,0,,False
473,"Table 5: Results of the Dual C-Means algorithm for ODP-239 and SEMEVAL. K fixed to 10 Clusters. Let us notice that for all experiments, the number of p words composing the centroids was set to 2 and the vocabulary is the set of words appearing in the retrieved Web snippets.",1,ODP,True
474,"V1 , V2 (Text)",0,,False
475,"V1 , V2 (QL)",0,,False
476,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
477,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
478,F1N 0.6698 0.6788 0.6718  0.6566 0.6841 0.6713 0.6706,0,,False
479,0.6580 0.6866 0.6593 0.6636 0.6783 0.6645 0.6719,0,,False
480,ARI 0.0317 0.0280 0.0341 0.0242 0.0213 0.0343 0.0170,0,,False
481,0.0418 0.0366 0.0320 0.0219 0.0267 0.0470 0.0403 ,0,,False
482,Fb3 0.6597 0.3981 0.6575 0.5499 0.4299 0.6666  0.6327 ,0,,False
483,0.6572 0.3806 0.6343 0.5728 0.4333 0.6160 0.5577,0,,False
484,F1C 0.6217 0.3514 0.6202 0.5131 0.3836 0.6260  0.5884 ,0,,False
485,0.6239 0.3338 0.6023 0.5394 0.3926 0.5847 0.5264,0,,False
486,"Table 6: Results of the Dual C-Means algorithm for WEBSRC401. K fixed to 10 Clusters. Let us notice that for all experiments where V1 ,"" V2, the number of p words composing the centroids was set to 2 and the vocabulary is the set of words appearing in the retrieved Web snippets. Note that  means paired student's t-test statistical relevance for p - value < 0.05 between a given metric in V1 "", V2 and its counterpart in V1 , V2.",0,,False
487,783,0,,False
488,"Not surprinsingly, the introduction of external information decreases clustering accuracy. But, this is true only for a glimpse when comparing ST S for V1 , V2 and SCP for V1 ,"" V2 (statistical relevance is not true in this case). However, the difference in terms of ARI is higher in favor of the dual representation space, although not with statistical relevance. In this case, we can conclude that while clustering accuracy slightly drops, partitioning shape seems to be put in advance by the query log driven approach. The other benefit of this new dual approach may be embodied by the expressiveness of the query logs as meaningful labels. This is the objective of the next section.""",1,ad,True
489,6. LABELING EVALUATION,0,,False
490,"As mentioned in [9], the labeling process plays an important role in the success of SRC systems. As a consequence, a clear objective evaluation is needed. However, this has not yet been the case. Indeed, [18][16] proposed user studies, which are difficult to replicate. In order to solve reproducibility problems, [10][35] proposed to evaluate the kSSL metric but their datasets are defined in two different ways and they are not publicly available. So, in order to propose a conclusive evaluation of the labeling process, we propose to use a new gold standard dataset provided by the Subtopic Mining subtask of the NTCIR-10 Intent-2 [32] and apply recent evaluation metrics proposed by [34]: I-rec@10, D-nDCG@10 and D#-nDCG@10.",0,,False
491,"These metrics aim to measure Precision and Recall of the users' intents. Within our context, we can use the labels provided by the SRC algorithms as the users' intents candidates. If so, we can directly apply the given metrics. In particular, I-rec measures the number of intents discovered by the algorithm over the total different intents of the query. This metric can simply be viewed as an intent Recall. Then, D-nDCG is obtained by sorting all relevant intents by the global gain, which is defined as the sum of all the individual intent gains. Finally, the D#-nDCG metric is the linear combination of I-rec and D-nDCG, using  and 1 -  factors. Note that defining the probabilities of each intent as well as the relevant intents can be a hard task. However, as our experiments are realized over WEBSRC401 based on ClueWeb09, these values are known and publicly available [32]. In particular, the NTCIREVAL toolkit17 was used for the calculation of these metrics. Let us notice that for the specific task of SRC, we propose to use I-rec@10, D-nDCG@10 and D#-nDCG@10 as for most queries the number of intents is limited. These metrics are defined in the Equations 7, 8 and 9.",1,ClueWeb,True
492,|I |,0,,False
493,"I-rec@N ,",0,,False
494,(7),0,,False
495,|I|,0,,False
496,where I is the set of known intents for a query q and I is the set of intents covered by the returned labels at level N.,0,,False
497,D-nDCG@N,0,,False
498,",",0,,False
499,"Nr,1 i Pr(i|q)gi(r)/log(r + 1) Nr,1 i Pr(i|q)gi (r)/log(r + 1)",0,,False
500,(8),0,,False
501,where Pr(i|q) (resp. Pr(i|q)) denotes the intent probability ob-,0,,False
502,tained for the discovered labels (resp. for the reference labels) and gi(r) (resp. gi (r)) is the gain value of the label at rank r with respect to i for the output of the labeling (resp. for the reference,0,,False
503,labeling).,0,,False
504,17http://research.nii.ac.jp/ntcir/tools/ntcireval-en.html [Last access: 27/01/2014].,0,,False
505,"D#-nDCG@N , I-rec@N + (1 - )D-nDCG@N (9)",0,,False
506,where  was set to 0.5 following the framework evaluation proposed in the Subtopic Mining subtask of the NTCIR-10 Intent-2.,0,,False
507,"The results provided by [33] for different query completions (BingC, GoogleC and YahooC), query suggestions (BingS) services and a simple merging strategy (Merge) are reported in Table 7 as well as the results of our approach. In particular, we show the results when clustering is query log driven (V1 , V2) and when labeling is performed a posteriori (V1 ,"" V2). By a posteriori, we mean that clustering is first performed on the exclusive text representation. Then, as a usual second step, the label is computed by any heuristic. In our experiments, the query log that best represents each text-based cluster is computed using one iteration of the update function defined in section 3, which allows direct comparison results.""",1,Yahoo,True
508,"V1 , V2 V1 , V2 Baselines",0,,False
509,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
510,SCP PMI DICE LOGLIKE 2 ST S LSA,0,,False
511,BingS BingC GoogleC YahooC Merge,1,Yahoo,True
512,I - rec@10 0.2804 0.3136 0.2952 0.2269 0.3390 0.2837 0.3238,0,,False
513,0.3669  0.4136  0.3761  0.3937  0.4249  0.4033  0.3946,0,,False
514,0.3068 0.3231 0.3735 0.3829 0.3365,0,,False
515,nDCG@10 0.3195 0.3444 0.3242 0.2885 0.3642 0.3063 0.3694,0,,False
516,0.3932  0.4257  0.3884  0.4146  0.4221  0.4273  0.4197 ,0,,False
517,0.2787 0.3268 0.3841 0.3815 0.3181,0,,False
518,D# - nDCG@10 0.2959 0.3250 0.3093 0.2550 0.3523 0.2935 0.3456,0,,False
519,0.3793  0.4203  0.3814  0.4046  0.4225  0.4119  0.4050 ,0,,False
520,0.2928 0.3250 0.3788 0.3822 0.3273,0,,False
521,"Table 7: Evaluation results of the labeling process with query logs over the NTCIR-10 Intent-2 dataset. Note that  means paired student's t-test statistical relevance for p - value < 0.05 between a given metric in V1 , V2 and its counterpart in V1 , V2.",0,,False
522,"The results of the query driven Dual C-Means outperform all baselines and a posteriori labeling. Moreover, all the differences between a given metric in V1 , V2 and its counterpart in V1 ,"" V2 are statistically relevant. These results also show interesting behaviors. Indeed, while PMI and 2 collocation metrics previously showed worst clustering accuracy results compared to other configurations, they show improved results in terms of labeling. The fact that these metrics tend to favour less frequent associations is an interesting characteristic for labeling purposes and a conclusive remark. Moreover, the ST S word-word similarity measure shows high nDCG@10 value and competitive overall D# - nDCG@10. These results clearly point at this last configuration as the best compromise for clustering accuracy, labeling quality and partitioning shape.""",0,,False
523,7. CONCLUSIONS AND PERSPECTIVES,0,,False
524,"In this paper, we proposed a new algorithm called Dual C-Means, which can be seen as an extension of the classical K-Means for dual representation spaces. Its originality relies in the fact that the clustering process can be driven by external resources by defining two distinct representation spaces. In particular, we proposed",0,,False
525,784,0,,False
526,"that query logs are used as external information to guide clustering and afford meaningful labels to users in their search for information. We also built a new publicly available dataset called WEBSRC401 based on ClueWeb09, which affords a more realistic situation for Web SRC. A complete and reproducible evaluation was performed over different gold standard datasets (ODP-239 and SEMEVAL) based on different publicly available evaluation tools. In particular, a great deal of evaluation metrics have been applied over diffferent configurations of the Dual C-Means integrating distinct word-word similarity measures. Results showed that our approach steadily outperforms all existing state-of-the-art SRC algorithms in terms of clustering accuracy (Fb3 ) but is less competitive in terms of ARI. This situation is handled by the introduction of query logs, which allows high labeling quality with outperforming values of I - rec@10, D - nDCG@10 and D# - nDCG@10 and adequate partitioning shape with high values of ARI.",1,ClueWeb,True
527,"The final findings that show that collocation metrics sensitive to high frequency events tend to produce high quality clusters and low frequency sensitive ones give rise to quality labels, is an interesting issue. Indeed, like the dual representation space, it suggests a multiobjective implementation of the dynamic reallocation algorithm to the problem of SRC. Moreover, the next steps that are being carried out are the introduction of different resources to drive the clustering process, the definition of new P transition matices taking into account recent developments in word-word similarity and the definition of powerful instantiation functions provided by the introduced general model.",0,,False
528,8. REFERENCES,0,,False
529,"[1] O. Alonso, M. Gertz, and R. Baeza-Yates. Clustering and exploring search results using timeline constructions. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM), pages 97­106, 2009.",0,,False
530,"[2] E. Amigó, J. Gonzalo, J. Artiles, and F. Verdejo. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Information Retrieval, 12(4):461­486, 2009.",0,,False
531,"[3] E. Amigó, J. Gonzalo, and F. Verdejo. A general evaluation measure for document organization tasks. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 643­652, 2013.",0,,False
532,"[4] D. Arthur and S. Vassilvitskii. K-means++: the advantages of careful seeding. In Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 1027­1035, 2007.",1,ad,True
533,"[5] B. Bahmani, B. Moseley, A. Vattani, R. Kumar, and S. Vassilvitskii. Scalable k-means++. Proceedings of the Very Large Data Base Endowment (PVLDB), 5(7):622­633, 2012.",0,,False
534,"[6] A. Bernardini, C. Carpineto, and M. D'Amico. Full-subtopic retrieval with keyphrase-based search results clustering. In Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), pages 206­213, 2009.",0,,False
535,"[7] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993­1022, 2003.",0,,False
536,"[8] T. Brants and A. F. Web 1t 5-gram, 2006. [9] C. Carpineto, S. Osinski, G. Romano, and D. Weiss. A",0,,False
537,"survey of web clustering engines. ACM Computer Survey, 41(3):1­38, 2009. [10] C. Carpineto and G. Romano. Optimal meta search results clustering. In 33rd International ACM SIGIR Conference on",0,,False
538,"Research and Development in Information Retrieval (SIGIR), pages 170­177, 2010. [11] K. Church and P. Hanks. Word association norms mutual information and lexicography. Computational Linguistics, 16(1):23­29, 1990. [12] A. Di Marco and R. Navigli. Clustering web search results with maximum spanning trees. In Proceedings of the 12th International Conference on Artificial Intelligence Around Man and Beyond (AI*AI), pages 201­212, 2011. [13] A. Di Marco and R. Navigli. Clustering and diversifying web search results with graph-based word sense induction. Computational Linguistics, 39(4):1­43, 2013. [14] L. Dice. Measures of the amount of ecologic association between species. Journal of Ecology, 26:297­302, 1945. [15] T. Dunning. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61­74, 1993. [16] P. Ferragina and A. Gulli. A personalized search engine based on web-snippet hierarchical clustering. Software: Practice and Experience, 38(2):189­225, 2008. [17] W. Gale and K. Church. Concordances for parallel texts. In Proceedings of the 7th Annual Conference of the UW Center for the New OED and Text Research, Using Corpora, pages 40­62, 1991. [18] M. Hearst and J. Pedersen. Re-examining the cluster hypothesis: Scatter/gather on retrieval results. In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 76­84, 1996. [19] W. Kong and J. Allan. Extracting query facets from search results. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 93­102, 2013. [20] T. Landauer and S. Dumais. A solution to plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, pages 211­240, 1997. [21] S. Lloyd. Least squares quantization in pcm. IEEE Transactions on Information Theory, 28(2):129­137, 1982. [22] Y. Maarek, R. Fagin, I. Ben-Shaul, and D. Pelleg. Ephemeral document clustering for web applications. Technical report, IBM, 2000. [23] A. K. McCallum. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu, 2002. [24] D. Milne and I. Witten. An open-source toolkit for mining wikipedia. Journal of Artificial Intelligence, 194:222­239, 2013. [25] J. Moreno and G. Dias. Using text-based web image search results clustering to minimize mobile devices wasted space-interface. In Proceedings of 35th European Conference on Information Retrieval (ECIR), pages 532­544, 2013. [26] J. Moreno, G. Dias, and G. Cleuziou. Post-retrieval clustering using third-order similarity measures. In Proceedings of the 51st Annual Meeting of the Association of Computational Linguisitcs (ACL), pages 153­158, 2013. [27] R. Navigli and G. Crisafulli. Inducing word senses to improve web search result clustering. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 116­126, 2010. [28] R. Navigli and D. Vannella. Semeval-2013 task 11: Word sense induction & disambiguation within an end-user",1,wiki,True
539,785,0,,False
540,"application. In Proceedings of the International Workshop on Semantic Evaluation (SEMEVAL), pages 1­9, 2013.",0,,False
541,"[29] A. Ng, M. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In Proceedings of the 15th Neural Information Processing Systems Conference (NIPS), pages 849­856, 2001.",0,,False
542,"[30] S. Osinski and D. Weiss. A concept-driven algorithm for clustering search results. IEEE Intelligent Systems, 20(3):48­54, 2005.",0,,False
543,"[31] P. Pecina and P. Schlesinger. Combining association measures for collocation extraction. In Proceedings of the Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics (COLING/ACL), pages 651­658, 2006.",0,,False
544,"[32] T. Sakai, Z. Dou, T. Yamamoto, Y. Liu, M. Zhang, M. Kato, R. Song, and M. Iwata. Summary of the ntcir-10 intent-2 task: Subtopic mining and search result diversification. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 761­764, 2013.",0,,False
545,"[33] T. Sakai, Z. Dou, T. Yamamoto, M. Lui, Y. Zhang, and R. Song. Overview of the ntcir-10 intent-2 task. In Proccedings of the Research Infrastructure for Comparative Evaluation of Information Retrieval and Access Technologies (NTCIR), 2013.",0,,False
546,"[34] T. Sakai and R. Song. Evaluating diversified search results using per-intent graded relevance. In Proceedings of the 34th international ACM conference on Research and development in Information Retrieval (SIGIR), pages 1043­1052, 2011.",1,ad,True
547,"[35] U. Scaiella, P. Ferragina, A. Marino, and M. Ciaramita. Topical clustering of search results. In 5th ACM International Conference on Web Search and Data Mining (WSDM), pages 223­232, 2012.",0,,False
548,"[36] J. Silva, G. Dias, S. Guilloré, and J. Lopes. Using localmaxs algorithm for the extraction of contiguous and non-contiguous multiword lexical units. In Proceedings of 9th Portuguese Conference in Artificial Intelligence (EPIA), pages 113­132, 1999.",0,,False
549,"[37] N. Vinh, J. Epps, and J. Bailey. Information theoretic measures for clusterings comparison: Is a correction for chance necessary? In Proceedings of the 26th Annual International Conference on Machine Learning (ICML), pages 1073­1080, 2009.",0,,False
550,"[38] D. Vitale, P. Ferragina, and U. Scaiella. Classification of short texts by deploying topical annotations. In 34th European Conference on Advances in Information Retrieval (ECIR), pages 376­387, 2012.",0,,False
551,"[39] X. Wang, W. Gu, D. Ziebelin, and H. Hamilton. An ontology-based framework for geospatial clustering. International Journal of Geogaphical Information Science, 24(11):1601­1630, 2010.",0,,False
552,"[40] O. Zamir and O. Etzioni. Web document clustering: A feasibility demonstration. In 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 46­54, 1998.",0,,False
553,"[41] D. Zhang and Y. Dong. Semantic, hierarchical, online clustering of web search results. In Proceedings of the 6th Asia Pacific Web Conference (APWEB), pages 69­78, 2004.",1,AP,True
554,786,0,,False
555,,0,,False
