,sentence,label,data,regex
0,Leveraging Knowledge across Media for Spammer Detection in Microblogging,1,Spammer,True
1,"Xia Hu, Jiliang Tang, and Huan Liu",0,,False
2,"Computer Science and Engineering Arizona State University Tempe, AZ 85287, USA",0,,False
3,"{xia.hu, jiliang.tang, huan.liu}@asu.edu",0,,False
4,ABSTRACT,0,,False
5,"While microblogging has emerged as an important information sharing and communication platform, it has also become a convenient venue for spammers to overwhelm other users with unwanted content. Currently, spammer detection in microblogging focuses on using social networking information, but little on content analysis due to the distinct nature of microblogging messages. First, label information is hard to obtain. Second, the texts in microblogging are short and noisy. As we know, spammer detection has been extensively studied for years in various media, e.g., emails, SMS and the web. Motivated by abundant resources available in the other media, we investigate whether we can take advantage of the existing resources for spammer detection in microblogging. While people accept that texts in microblogging are different from those in other media, there is no quantitative analysis to show how different they are. In this paper, we first perform a comprehensive linguistic study to compare spam across different media. Inspired by the findings, we present an optimization formulation that enables the design of spammer detection in microblogging using knowledge from external media. We conduct experiments on real-world Twitter datasets to verify (1) whether email, SMS and web spam resources help and (2) how different media help for spammer detection in microblogging.",1,blog,True
6,Categories and Subject Descriptors,0,,False
7,H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval--Classification; I.2.7 [Artificial Intelligence]: Natural Language Processing,0,,False
8,General Terms,0,,False
9,"Algorithm, Performance, Experimentation",0,,False
10,Keywords,0,,False
11,"Spammer Detection, Twitter, Emails, SMS, Web, CrossMedia Mining, Social Media",1,Spammer,True
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609632 .",1,ad,True
13,1. INTRODUCTION,1,DUC,True
14,"Microblogging ­ a style of communicating through shortform content ­ has emerged as a popular social networking platform. Microblogging systems have been increasingly used for large-scale information dissemination and sharing in various fields such as marketing, journalism or public relations. With microblogging's growing popularity, activities of spamming have become rampant in launching various attacks in the medium. For example, the spammers spread ads to generate sales, disseminate pornography, viruses, phishing, or simply to compromise a system's reputation [3]. To improve user experience and the overall value of a system, it is essential to detect spammers in microblogging.",1,blog,True
15,"Existing methods for spammer detection in social media [26] focus on using social networking information. These network-based methods characterize the spammers by analyzing the network features, e.g., social status. The assumption behind this strategy is that it is difficult for the spammers to establish a large number of social relations with legitimate users. Different from other social media sites, in microblogging, users can follow anyone without prior consent from the followee. Many users just follow back when they are followed by someone for the sake of courtesy [20]. So, the spammers can easily enhance their influence score to fool the system. In this case, content analysis could complement network-based methods in spammer detection; thus, we explore the use of content information in this work.",1,blog,True
16,"A straightforward way to perform content-based spammer detection [22] is to model this task as a supervised learning problem. These methods extract effective textual features from the messages and build a classifier or a regressor based on the features. Given a new user, the built model can output a class label or score to determine whether it is a spammer based on microblogging messages the user posted. Content-based methods become difficult to be directly applied due to the distinct features of microblogging data. First, in microblogging, it is time-consuming and labor intensive to obtain labeled data, which is essential in building an effective supervised spammer detection model. Given the size and dynamic nature of microblogging, a manual labeling process is neither scalable nor sensible. Second, the texts in microblogging are short and noisy; thus, we lack sufficient aggregated information to evaluate the given messages. These present great challenges to directly making use of existing content-based methods for effective spammer detection in microblogging.",1,blog,True
17,"While the problem of spamming in microblogging is relatively new, it has been extensively studied for years in other",1,blog,True
18,547,0,,False
19,"platforms, e.g., email communication [4], SMS [14] and the web [31]. Similarly, the spammers in these platforms unfairly overwhelm other users by spreading unwanted information, which leads to phishing, malware, and scams [20]. Also, it has been reported in Natural Language Processing (NLP) literature that microblogging is not as noisy as was expected [2]. Although microblogging is an informal communication medium, it has been shown to be similar to other platforms [21] and it is seemingly possible to employ NLP tools to ""clean"" it [11]. Motivated by the previous findings, we explore the possibility of using knowledge learned from other platforms to facilitate spammer detection in the context of microblogging.",1,ad,True
20,"In this paper, we explore the use of resources available in other media to help spammer detection in microblogging. To study this problem, we need to answer the following questions: Are the resources from other media potentially helpful for spammer detection in microblogging? How do we explicitly model and make use of the resources from other media for spammer detection? Is the knowledge learned from other media helpful for microblogging spammer detection? By answering the above questions, this paper presents the following contributions:",1,blog,True
21,· Conducting a quantitative analysis of linguistic variation of spam resources from different media;,0,,False
22,· Formally defining the problem of leveraging knowledge across media for spammer detection in microblogging;,1,blog,True
23,· Presenting a novel framework of leveraging knowledge from existing corpora to help spammer detection in microblogging; and,1,corpora,True
24,"· Systematically evaluating the proposed method on realworld Twitter, email, SMS and web datasets and elaborating the effects of the knowledge learned from different media on spammer detection in Twitter.",1,Twitter,True
25,"The remainder of this paper is organized as follows. In Section 2, we conduct a quantitative study to examine the differences between spam corpora in different media from a linguistic perspective. In Section 3, we formally define the problem of leveraging knowledge across media for spammer detection in microblogging. In Section 4, we propose a novel framework for the problem we study. In Section 5, we report empirical results on real-world datasets. In Section 6, we review existing literature related to our work. In Section 7, we conclude this work and present some future work.",1,corpora,True
26,2. LINGUISTIC VARIATION ANALYSIS,0,,False
27,"This work is motivated by numerous spam resources available in other well-studied media, e.g., email, SMS and web. A natural question could be, given the short and noisy form of microblogging messages, how different are the texts in microblogging when compared to those in other media? Before proceeding further, we also examine whether the textual information from other media is potentially useful in the problem we study.",1,blog,True
28,2.1 Datasets,0,,False
29,"Two Twitter datasets are used in our study for experiment purposes, i.e., TAMU Social Honeypots and Twitter Suspended Spammers. In addition, three representative datasets from different types of media, including Enron",1,Twitter,True
30,"Email Dataset, SMS Dataset and Web Dataset, are used in the analysis. The statistics of the datasets are presented in Table 1. Now we introduce the datasets in detail.",0,,False
31,"TAMU Social Honeypots Dataset (TweetH): Lee et al. [22] created a collection of 41,499 Twitter users with identity labels: spammers and legitimate users. The dataset was collected from December 30, 2009 to August 2, 2010 on Twitter. It consists of users, their number of followers and tweets. We filtered the non-English tweets and users with less than two tweets.",1,Tweet,True
32,"Twitter Suspended Spammers Dataset (TweetS): We employed a data crawling process, which is similar to [32, 34], to construct this dataset. We first crawled a Twitter dataset from July to September 2012 via the Twitter Search API. The users that were suspended by Twitter during this period are considered as the gold standard [32] of spammers in the experiment. We then randomly sampled the legitimate users from a publicly available Twitter dataset provided by TREC 2011.1 We filtered the non-English tweets and users with less than two tweets.",1,Twitter,True
33,"The first dataset TweetH has balanced number of spammers and legitimate users. To avoid effects brought by different class distribution, according to the literature of spammer detection [22], we made the two classes in TweetS imbalanced, i.e., the number of legitimate users is much greater than that of spammers in the dataset.",1,Tweet,True
34,"Enron Email Dataset (Email): We used a subset of a widely used Enron email dataset,2 which is collected during the investigation of Enron corporation and contains more than 200,000 emails between its employees. The emails in this dataset are preprocessed and used as a testbed in [25] for experiments. Each email in the dataset is labeled as either ""spam"" or ""ham"".",1,corpora,True
35,"SMS Dataset(SMS): We used the SMS spam collection provided by Almeida et al. [1] for analysis. This dataset is constructed based on two sources, Grumbletext web site3 and NUS SMS Corpus.4 The spam messages were manually labeled, and the ham messages were randomly sampled from the NUS SMS Corpus. To the best of our knowledge, this is the largest public SMS spam dataset.",0,,False
36,Web Dataset (Web): Web spam is a key challenge for internet users. Web pages which are created to deceive other users by manipulating search engine. Webb et al. [31] constructed the Web Dataset. This is the largest publicly available dataset to the best of our knowledge. We removed the web pages that have no textual content or only contain http request error information.,0,,False
37,2.2 Lexical Analysis,0,,False
38,"To evaluate the style of a language, many metrics have been proposed in literature of linguistics and communication [2, 30]. In this subsection, we first introduce the metrics used in our study and then discuss lexical analysis results on the datasets from different media.",0,,False
39,"Basic Statistics: average Word Length (WL, in characters) and average Sentence Length (SL, in words) are used to evaluate the basic style of different datasets. In addition to those, we further employ other widely used lexical metrics in the analysis. We list the metrics below.",1,ad,True
40,1http://trec.nist.gov/data/tweets/ 2http://www.isi.edu/~adibi/Enron/Enron.htm 3http://www.grumbletext.co.uk/ 4http://wing.comp.nus.edu.sg/SMSCorpus/,1,trec,True
41,548,0,,False
42,Table 1: Statistics of the Datasets TweetH TweetS Email,1,Tweet,True
43,# of Spam Messages # of Legitimate Messages # of Messages Avg. # of Words per Document,0,,False
44,"1,310,318 1,220,198 2,530,516",0,,False
45,18.64,0,,False
46,"71,842 308,957 380,799",0,,False
47,17.88,0,,False
48,"10,582 13,990 24,572 168.87",0,,False
49,SMS,0,,False
50,747 4827 5574 14.59,0,,False
51,Web,0,,False
52,"22,386 N.A. 82,386 57.67",0,,False
53,Table 2: Lexical Analysis Results,0,,False
54,Basics,0,,False
55,Lexical Analysis,0,,False
56,WL SL TTR LD OOV,0,,False
57,TweetH TweetS Email SMS Web,1,Tweet,True
58,4.12 12.95 5.42 0.48 0.32 3.95 12.38 5.65 0.50 0.31 4.52 17.88 5.46 0.53 0.29 3.99 12.60 6.54 0.45 0.34 4.81 18.66 6.13 0.48 0.32,0,,False
59,Type-Token Ratio (TTR): This is a widely used metric,0,,False
60,"to evaluate the difficulty (or readability) of words, sentences",1,ad,True
61,"and documents by measuring their lexical variety [7, 33].",0,,False
62,The basic assumption of using TTR is that difficult words,0,,False
63,are those that appear least often in a document. Given a,0,,False
64,"corpus D, TTR is calculated as T T R(D) ,",0,,False
65,wD,0,,False
66,F req(w) Size(D),0,,False
67,",",0,,False
68,"where w means a word (token) in the corpus, F req(w) means",0,,False
69,"word frequency of w in D, and Size(D) means the number",0,,False
70,"of distinct words (types) in D. In practice, a higher TTR",0,,False
71,indicates a larger amount of lexical variation and a lower,0,,False
72,score indicates relatively less lexical variation [33].,0,,False
73,Lexical Density (LD): We employ lexical density to,0,,False
74,further analyze the stylistic difference between different cor-,0,,False
75,"pora. Lexical words [15], also known as content or infor-",0,,False
76,"mation carrying words, refer to verbs, nouns, adjectives and",1,ad,True
77,"adverbs. Similarly, given a document D, LD is defined as",1,ad,True
78,"LD(D) ,",0,,False
79,wLex,0,,False
80,F req(w) Size(D),0,,False
81,",",0,,False
82,where,0,,False
83,Lex,0,,False
84,means,0,,False
85,the,0,,False
86,whole,0,,False
87,lex-,0,,False
88,"ical words dictionary. In general, a higher lexical density",0,,False
89,"indicates that it is a more formal document, and a lower",0,,False
90,lexical density represents a more conversational one.,0,,False
91,Out-of-Vocabulary (OOV): This metric is to measure,0,,False
92,the ratio of out-of-vocabulary words in the corpora. We use,1,corpora,True
93,"a list of top 10,000 words with highest frequency provided",0,,False
94,"by the Project Gutenberg [16] in our study. In general, a",0,,False
95,higher OOV rate indicates that the language is more infor-,0,,False
96,mal. Many NLP and IR models suffer from high OOV rates.,0,,False
97,Experimental results of the lexical analysis are presented,0,,False
98,"in Table 2. By comparing the results of different metrics, we",0,,False
99,observe the following: (1) The word lengths of different cor-,0,,False
100,"pora are very similar, and the sentence lengths of TweetH,",1,Tweet,True
101,TweetS and SMS are smaller than those of more formal me-,1,Tweet,True
102,dia Email and Web. This indicates that the textual form of,0,,False
103,"microblogging data is similar to SMS, and relatively different",1,blog,True
104,"from email and web. (2) In most of the tests, microblogging",1,blog,True
105,data is similar to the datasets from the other media. It,0,,False
106,"demonstrates that, although microblogging is considered an",1,blog,True
107,"informal media, the language use is similar to that in other",0,,False
108,"media, especially in email and SMS. We observe that the",0,,False
109,type-token ratios of microblogging are smaller than those of,1,blog,True
110,SMS and web. It suggests that the language used in mi-,0,,False
111,croblogging is easier than that in the other two platforms.,1,blog,True
112,We further employ hypothesis testing to examine the lex-,0,,False
113,ical differences between microblogging datasets and other,1,blog,True
114,Table 3: Hypothesis Testing Results (P-Values),0,,False
115,TweetH,1,Tweet,True
116,TweetS,1,Tweet,True
117,TTR LD OOV TTR LD OOV,0,,False
118,Email 0.318 0.108 0.442 0.234 0.267 0.308 SMS <0.01 0.205 0.350 <0.01 0.082 0.163 Web <0.01 0.623 0.398 0.108 0.551 0.462,0,,False
119,"datasets. For each lexical metric, we form a null hypothesis for a microblogging dataset and a dataset from the other media. The null hypothesis is: in terms of the specific lexical metric, there is no difference between microblogging data and data from the other media. We test the hypotheses on all pairs of the datasets for all the three lexical metrics.",1,blog,True
120,"In particular, to verify the difference between TweetH and Email datasets on the TTR, we construct two vectors ttrth and ttrem. Each element of the first vector ttrth is obtained by calculating the TTR score of a subset sampled with bootstrapping from TweetH dataset. Similarly, each element in the second vector corresponds to the TTR score of a subset sampled with bootstrapping from Email dataset. In the experiment, the two vectors contain equal number of elements.5 Each element in the vectors corresponds to 100 data instances. We formulate a two-sample two-tail t-test on the two constructed vectors ttrth and ttrem. We examine whether there is sufficient statistical evidence to support the hypothesis that the two datasets have the same sample mean, and it is defined as follows:",1,Tweet,True
121,"H0 : th - em , 0",0,,False
122,(1),0,,False
123,"H1 : th - em , 0",0,,False
124,"where H0 is the null hypothesis, H1 is the alternative hypothesis, and c and r represent the sample means of the two vectors, respectively. Similarly, we form the hypothesis testings for other pairs of datasets with other lexical metrics.",0,,False
125,"The t-test results, p-values, are summarized in Table 3. From the table, we can observe the following: (1) With few exceptions, the results are much greater than the significance level  ,"" 0.05. It demonstrates that there is no statistical evidence to reject the null hypothesis in the tests on the two datasets. In other words, the results suggest that microblogging data is not significantly different from the datasets in other media. (2) In some tests, microblogging data appears more similar to Email than the other datasets.""",1,blog,True
126,"In conclusion, while characteristics of different datasets appear different, there are no statistically significant lexical differences between them. The resources from other media are potentially useful in the task we study. Next, we formally define the problem we study and introduce the proposed learning framework for spammer detection.",0,,False
127,"5Note this is the setting used for experiment purposes, and it is not a mandatory setting for a two-sample t-test.",0,,False
128,549,0,,False
129,3. PROBLEM STATEMENT,0,,False
130,"In this section, we first present the notations and then",0,,False
131,formally define the problem we study.,0,,False
132,"Notation: lower-case bold Roman letters (e.g., a) denote",0,,False
133,"column vectors, upper-case letters (e.g., A) denote matri-",0,,False
134,"ces, and lowercase letters (e.g., a) denote scalars. A(i, j) denotes the entry at the ith row and jth column of a ma-",0,,False
135,"trix A. Let A denote the Euclidean norm, and A F",0,,False
136,"the Frobenius norm of the matrix A. Specifically, A F ,",0,,False
137,"m i,1",0,,False
138,"n j,1",0,,False
139,"A(i,",0,,False
140,j)2.,0,,False
141,Let AT,0,,False
142,and,0,,False
143,T r(A) denote the trans-,0,,False
144,"pose and trace of A, respectively.",0,,False
145,"Let S ,"" [X, Y] be available resources from other media,""",0,,False
146,with the content information X and identity label matrix Y. We use term-user matrix X  Rm×d to denote con-,0,,False
147,"tent information, i.e., posts written by the users, where",0,,False
148,"m is the number of textual features, and d is the number",0,,False
149,"of users in the other media. X ,"" {X1, X2, ..., Xr} means""",0,,False
150,"the combination of content information from multiple media, and Y  Rd×c ,"" {Y1, Y2, ..., Yr} means the combi-""",0,,False
151,"nation of label information from the media. For each user (xi, yi)  Rm+c consists of message content and identity label, where xi  Rm is the message feature vector and yi  Rc is the spammer label vector. In this paper, we con-",0,,False
152,"sider the task we study as a two-class classification problem,",0,,False
153,"i.e., c ,"" 2. For example, yi "","" (1, 0) means this user is a spammer. yiT yi "", 1 constrains that yi has to have one la-",0,,False
154,"bel and cannot be (0, 0) or (1, 1). It is practical to extend",0,,False
155,this setting to a multi-class or regression problem. We use T  Rm×n to denote the content information of microblog-,1,blog,True
156,"ging users, where m is the number of textual features, and",0,,False
157,n is the number of users in microblogging. The texts from,1,blog,True
158,microblogging and other media share the same feature space.,1,blog,True
159,We now formally define the problem as follows:,0,,False
160,"We have a set of resources S from different media, with",0,,False
161,"the content information X ,"" {X1, X2, ..., Xr} and identity label information Y "","" {Y1, Y2, ..., Yr}. Given the content""",0,,False
162,"information T from microblogging, our goal is to automat-",1,blog,True
163,ically infer the identity labels for unknown users in T as,0,,False
164,spammers or legitimate users.,0,,False
165,4. LEVERAGING KNOWLEDGE ACROSS MEDIA FOR SPAMMER DETECTION,0,,False
166,"We plot the work flow of our proposed framework in Figure 1. From the figure, we see that there are two constraints on the learned model for spammer detection. As shown in the upper right part of the figure, the first constraint is from the lexicon information U, which is learned from the other media sources S. As shown in the lower right part of the figure, the second constraint is a Laplacian regularization M learned from microblogging content information. We now introduce each part of the proposed framework in detail.",1,blog,True
167,4.1 Modeling Knowledge across Media,0,,False
168,"As we discussed in the last section, from a linguistic perspective, it does not show significant difference between microblogging data and other types of data. A straightforward method to make use of external information is to learn a supervised model based on data from the other media, and apply the learned classifier on microblogging data for spammer detection. However, this method yields two problems to be directly applied to our task. First, text representation models, like n-gram model, often lead to a high-dimensional",1,blog,True
169,"T ,",0,,False
170,Ut Ht,0,,False
171,Vt,0,,False
172,Spammer Detection,1,Spammer,True
173,Modeling Knowledge across Media,0,,False
174,"UH V ,",0,,False
175,"S ,"" {Email, SMS, Web}""",0,,False
176,M,0,,False
177,Microblogging,1,blog,True
178,Modeling Content Information,0,,False
179,Figure 1: Illustration of the Proposed Spammer Detection Framework,1,Spammer,True
180,"feature space because of the large size of data and vocabulary. Second, texts in the media are short, thus making the data representation very sparse [21].",0,,False
181,"To tackle the problems, instead of learning knowledge at word-level, we propose to capture the external knowledge from topic-level. In particular, the proposed method is built on the orthogonal nonnegative matrix tri-factorization model (ONMTF) [9]. The basic idea of the ONMTF model is to cluster data instances based on distribution of features, and cluster features according to the distribution of data instances. The principle of ONMTF is consistent with PLSI [17], in which each document is a mixture of latent topics that each word can be generated from. The ONMTF can be formulated by optimizing:",1,ad,True
182,min,0,,False
183,"U,H,V0",0,,False
184,X - UHVT,0,,False
185,2 F,0,,False
186,",",0,,False
187,(2),0,,False
188,"s.t. UT U ,"" I, VT V "","" I,""",0,,False
189,"where X is the content matrix, and U  Rm + ×c and V  Rd+×c are nonnegative matrices indicating low-dimensional representations of words and users, respectively. m is the size of vocabulary, c is the number of classes, d is the number of users. H  Rc+×c provides a condensed view of X. The orthogonal and nonnegative conditions of U and V provide",0,,False
190,a hard assignment of class label to the words and users.,0,,False
191,"With the ONMTF model, we project the original content",0,,False
192,information from the other media into a latent topic space.,0,,False
193,"By adding a topic-level least squares penalty to the ONMTF,",1,ad,True
194,our proposed framework can be mathematically formulated,0,,False
195,as solving the following optimization problem:,0,,False
196,min,0,,False
197,"U,H,V,W0",0,,False
198,"J,",0,,False
199,X - UHVT,0,,False
200,2 F,0,,False
201,+,0,,False
202,VW - Y,0,,False
203,2 F,0,,False
204,",",0,,False
205,(3),0,,False
206,"s.t. UT U ,"" I, VT V "","" I,""",0,,False
207,"where W represents the weights and Y is the label matrix. In the formulation, the first term is the basic factorization model, and the second introduces label information from the other media by using a linear penalty.  is to control the effect of external information to the learned lexicon U, in which each row represents the predicted label of a word.",0,,False
208,"As the problem in Eq. (3) is not convex with respect to the four variables together, there is no closed-form solution for the problem. Next, we introduce an alternative scheme to solve the optimization problem.",0,,False
209,550,0,,False
210,4.1.1 Optimization Algorithm,0,,False
211,"Following [9], we propose to optimize the objective with respect to one variable, while fixing others. The algorithm will keep updating the variables until convergence.",0,,False
212,Computation of H: Optimizing the objective function in Eq. (3) with respect to H is equivalent to solving,0,,False
213,min,0,,False
214,H0,0,,False
215,"JH ,",0,,False
216,X - UHVT,0,,False
217,2 F,0,,False
218,.,0,,False
219,(4),0,,False
220,Let H be the Lagrange multiplier for constraint H  0; the Lagrange function L(H) is defined as follows:,0,,False
221,"L(H) ,",0,,False
222,X - UHVT,0,,False
223,2 F,0,,False
224,-,0,,False
225,T r(H HT ).,0,,False
226,(5),0,,False
227,"By setting the derivative HL(H) ,"" 0, we get""",0,,False
228,"H , -2UT XV + 2UT UHVT V.",0,,False
229,(6),0,,False
230,The Karush-Kuhn-Tucker complementary condition [6] for the nonnegativity constraint of H gives,0,,False
231,"H (i, j)H(i, j) , 0 ;",0,,False
232,(7),0,,False
233,"thus, we obtain",0,,False
234,"[-UT XV + UT UHVT V](i, j)H(i, j) , 0.",0,,False
235,(8),0,,False
236,"Similar to [9], it leads to the updating rule of H,",1,ad,True
237,"H(i, j)  H(i, j)",0,,False
238,"[UT XV](i, j) [UT UHVT V](i, j) .",0,,False
239,(9),0,,False
240,Computation of U: Optimizing the objective function in Eq. (3) with respect to U is equivalent to solving,0,,False
241,min,0,,False
242,U0,0,,False
243,"JU ,",0,,False
244,X - UHVT,0,,False
245,2 F,0,,False
246,"s.t. UT U , I.",0,,False
247,(10),0,,False
248,"Let U and U be the Lagrange multipliers for constraints U  0 and UT U ,"" I, respectively; the Lagrange function""",0,,False
249,L(U) is defined as follows:,0,,False
250,"L(U) ,",0,,False
251,X - UHVT,0,,False
252,2 F,0,,False
253,- T r(U UT ),0,,False
254,+,0,,False
255,T r(U (UT U,0,,False
256,-,0,,False
257,I)),0,,False
258,(11),0,,False
259,"By setting the derivative UL(U) ,"" 0, we get""",0,,False
260,"U , -2XVHT + 2UHVT VHT + 2UU .",0,,False
261,(12),0,,False
262,"With the KKT complementary condition for the nonnegativity constraint of U, we have",0,,False
263,"U (i, j)U(i, j) , 0;",0,,False
264,(13),0,,False
265,"thus, we obtain",0,,False
266,"[-XVHT + UHVT VHT + UU ](i, j)U(i, j) ,"" 0, (14)""",0,,False
267,where,0,,False
268,"U ,UT XVHT - HVT VHT .",0,,False
269,(15),0,,False
270,"anLdet -U(Ui,,j),+U",0,,False
271,"--U , where (|U (i, j)| -",0,,False
272,"+U (i, j) ,"" (|U U (i, j))/2 [9];""",0,,False
273,"(i, j)|+U we get",0,,False
274,"(i,",0,,False
275,j))/2,0,,False
276,"[-(XVHT + U-U ) + (UHVT VHT + U+U )](i, j)U(i, j) ,"" 0, (16)""",0,,False
277,"which leads to the updating rule of U,",1,ad,True
278,"U(i, j)  U(i, j)",0,,False
279,[XVHT + [UHVT VHT,0,,False
280,"U-U ](i, j) + U+U ](i,",0,,False
281,j,0,,False
282,),0,,False
283,.,0,,False
284,(17),0,,False
285,Algorithm 1: Modeling Knowledge across Media,0,,False
286,"Input: {X, Y, , I} Output: V",0,,False
287,"1: Initialize U, V, H, W  0 2: while Not convergent and iter  I do",0,,False
288,3:,0,,False
289,"Update H(i, j)  H(i, j)",0,,False
290,"[UT XV](i,j) [UT UHVT V](i,j)",0,,False
291,4:,0,,False
292,"Update U(i, j)  U(i, j)",0,,False
293,"[XVHT +U- U ](i,j) [UHVT VHT +U+ U ](i,j)",0,,False
294,5:,0,,False
295,"Update V(i, j)  V(i, j)",0,,False
296,"[XT UH+YWT +V- V ](i,j) [VHT UT UH+VWWT +V+ V ](i,j)",1,WT,True
297,6:,0,,False
298,"Update W(i, j)  W(i, j)",0,,False
299,"[VT Y](i,j) [VT VW](i,j)",0,,False
300,"7: iter , iter + 1",0,,False
301,8: end while,0,,False
302,Computation of V: Optimizing the objective function in Eq. (3) with respect to V is equivalent to solving,0,,False
303,min,0,,False
304,V0,0,,False
305,"J,",0,,False
306,X - UHVT,0,,False
307,2 F,0,,False
308,+,0,,False
309,VW - Y,0,,False
310,2 F,0,,False
311,(18),0,,False
312,"s.t. VT V , I.",0,,False
313,"Similar to the computation of U, by introducing two Lagrange multipliers V and V for the constraints, we get",0,,False
314,"[-(XT UH + YWT + V-V ) + (VHT UT UH + VWWT + V+V )](i, j)V (i, j) ,"" 0,""",1,WT,True
315,"(19) which leads to the updating rule of V,",1,ad,True
316,"V(i, j)  V(i, j)",0,,False
317,"[XT UH + YWT + V-V ](i, j) [VHT UT UH + VWWT + V+V ](i, j)",1,WT,True
318,(20),0,,False
319,Computation of W: Optimizing the objective function,0,,False
320,in Eq. (3) with respect to W is equivalent to solving,0,,False
321,min,0,,False
322,W0,0,,False
323,"J,",0,,False
324,VW - Y,0,,False
325,2 F,0,,False
326,.,0,,False
327,(21),0,,False
328,"Similar to the computation of U, by introducing a Lagrange multiplier and satisfying KKT condition, we obtain",0,,False
329,"[VT VW - VT Y](i, j)W(i, j) ,"" 0,""",0,,False
330,(22),0,,False
331,"which leads to the updating rule of W,",1,ad,True
332,"W(i, j)  W(i, j)",0,,False
333,"[VT Y](i, j) [VT VW](i, j) .",0,,False
334,(23),0,,False
335,"We summarize the algorithm of optimizing Eq. (3) in Algorithm 1, where I is the number of maximum iterations. In line 1, we conduct initialization for the variables. From lines 2 to 8, the four variables are updated with the updating rules until convergence or until they reach the number of maximum iterations. The correctness and convergence of the updating rules can be proven with the standard auxiliary function approach [28].",0,,False
336,4.2 Modeling Content Information,0,,False
337,"In this subsection, as shown in the lower right part of Figure 1, we introduce how to model content information of microblogging data in the proposed model.",1,blog,True
338,551,0,,False
339,To make use of the content information of microblogging,1,blog,True
340,"messages, we introduce a graph Laplacian [8] in the proposed model. We construct a graph based on content information of the users. In the graph, each node represents a user and each edge represents the affinity between two users. The adjacency matrix M  Rn×n of the graph is defined as",1,ad,True
341,1 if u  N (v) or v  N (u),0,,False
342,"M(u, v) ,",0,,False
343,(24),0,,False
344,0 otherwise,0,,False
345,"where u and v are nodes, and N (u) represents the k-nearest neighbor of the user. Content similarity is adopted to obtain the k-nearest neighbor in this work. Since we aim to model the mutual content similarity between two users, the adjacency matrix is symmetric.",1,ad,True
346,"The basic idea of of using the graph Laplacian to model the content information is that if two nodes are close in the graph, i.e., they posted similar messages, their identity labels should be close to each other. It can be mathematically formulated as minimizing the following loss function:",0,,False
347,nn,0,,False
348,R,0,,False
349,",",0,,False
350,1 2,0,,False
351,"Vt(i, ) - Vt(j, )",0,,False
352,2 2,0,,False
353,"M(i,",0,,False
354,j).,0,,False
355,"i,1 j,1",0,,False
356,(25),0,,False
357,This loss function will incur a penalty if two users have dif-,0,,False
358,"ferent predicted labels when they are close to each other in the graph. Let D  Rn×n denote a diagonal matrix, and",0,,False
359,its diagonal element is the degree of a user in the adjacency,1,ad,True
360,"matrix M, i.e., D(i, i) ,",0,,False
361,"n j,1",0,,False
362,"M(i,",0,,False
363,j,0,,False
364,).,0,,False
365,Theorem 1. The formulation in Eq. (25) is equivalent to the following objective function:,0,,False
366,"R ,"" T r(VtT LVt),""",0,,False
367,(26),0,,False
368,"where the Laplacian matrix [8] L is defined as L , D - M.",0,,False
369,Proof. It is easy to verify that Eq. (25) can be rewritten as,0,,False
370,"R,",0,,False
371,", ,",0,,False
372,nn c,0,,False
373,"Vt(i, k)M(i, j)VtT (i, k)",0,,False
374,"i,1 j,1 k,1",0,,False
375,nn c,0,,False
376,-,0,,False
377,"Vt(i, k)M(i, j)VtT (j, k)",0,,False
378,"i,1 j,1 k,1",0,,False
379,T r(VtT (D - M)Vt),0,,False
380,"T r(VtT LVt),",0,,False
381,(27),0,,False
382,which completes the proof. 2,0,,False
383,4.3 Spammer Detection Framework,1,Spammer,True
384,"As illustrated in Figure 1, we employ two types of information to formulate two kinds of constraints on the learned model. By integrating knowledge learned from other media and content information from microblogging, we can perform spammer detection by optimizing",1,blog,True
385,min,0,,False
386,"Ut ,Ht ,Vt 0",0,,False
387,"J,",0,,False
388,T - UtHtVtT,0,,False
389,2 F,0,,False
390,+,0,,False
391,T r(VtT LVt),0,,False
392,+,0,,False
393,GU (Ut - U),0,,False
394,2 F,0,,False
395,"),",0,,False
396,(28),0,,False
397,"s.t. UTt Ut ,"" I, VtT Vt "","" I,""",0,,False
398,"where the first term is to factorize the microblogging data into three variables, which are similar to the idea discussed in Section 4.1. The second term is to introduce content information and the third is to introduce knowledge learned from the other media. U is the lexicon learned from the other",1,blog,True
399,Algorithm 2: Spammer Detection in Microblogging,1,Spammer,True
400,"Input: {T, U, , , I }",0,,False
401,Output: Vt,0,,False
402,1: Construct matrices L in Eq. (26),0,,False
403,"2: Initialize Ut ,"" U, V, H  0 3: while Not convergent and iter  I do""",0,,False
404,4:,0,,False
405,"Update Ht(i, j)  Ht(i, j)",0,,False
406,"[UTt XVt ](i,j) [UTt UtHt VtT Vt](i,j)",0,,False
407,5: Update,0,,False
408,"Ut(i, j)  Ut(i, j)",0,,False
409,"[XVt HTt +GU U+Ut - U ](i,j) [Ut HtVtT Vt HTt +GU Ut+Ut+ U ](i,j)",0,,False
410,6: Update,0,,False
411,7:,0,,False
412,"Vt(i, j)  Vt(i, j)",0,,False
413,"[XT Ut Ht+MVt+Vt - V ](i,j) [Vt HTt UTt UtHt +DVt+Vt + V ](i,j)",0,,False
414,"8: iter , iter + 1",0,,False
415,9: end while,0,,False
416,"media by solving the problem in Eq. (3). GU  {0, 1}m×m is a diagonal indicator matrix to control the impact of the learned lexicon, i.e., GU (i, i) ,"" 1 represents that the i-th word contains identity information, GU (i, i) "", 0 otherwise.",0,,False
417,"This optimization problem is not convex with respect to the three parameters together. Following the optimization procedure to solve Eq. (3), we propose an algorithm to solve the problem in Eq. (28) and summarize it in Algorithm 2. In line 1, we construct the Laplacian matrix L. In line 2, we initialize the variables. From lines 3 to 9, we keep updating the variables with the updating rules until convergence or until the number of maximum iterations is reached.",0,,False
418,5. EXPERIMENTS,0,,False
419,"In this section, we empirically evaluate the proposed learning framework and the factors that could bring in effects to the framework. Through the experiments, we aim to answer the following two questions:",0,,False
420,· How effective is the proposed framework compared with other possible solutions of using external information across media in real-world spammer detection tasks?,0,,False
421,· What impact do the other resources have on the performance of spammer detection in microblogging?,1,blog,True
422,5.1 Experimental Setup,0,,False
423,"We follow a standard experiment setup used in spammer detection literature [34] to evaluate the effectiveness of our proposed framework for leveraging knowledge aCross media for Spammer Detection (CSD). In particular, we compare the proposed framework CSD with different baseline methods for spammer detection. To avoid bias, both TweetH and TweetS, introduced in Section 2.1, are used in the experiments. For email data, we consider each sender a user; For SMS and web data, we do not have user information and consider each message as sent from a distinct user. In the experiment, precision, recall and F1-measure are used as the performance metrics.",1,Spammer,True
424,"To evaluate the general performance of the proposed framework, we use all of the three datasets from different media, i.e., Email, SMS and Web datasets. In the first set of experiments, to be discussed in Section 5.2, we simply combine them together and consider them as homogeneous data sources. In the second set of experiments, to be discussed in",0,,False
425,552,0,,False
426,Least Squares Lasso MFTr MFSD CSD,0,,False
427,Table 4: Spammer Detection Results on TweetH Dataset,1,Spammer,True
428,External Data I (50%),0,,False
429,External Data II (100%),0,,False
430,Precision Recall F1-measure (gain) Precision Recall F1-measure (gain),0,,False
431,0.823 0.834,0,,False
432,0.828 (N.A.),0,,False
433,0.839 0.852,0,,False
434,0.845 (N.A.),0,,False
435,0.865 0.891 0.878 (+5.96%),0,,False
436,0.873 0.905 0.889 (+5.12%),0,,False
437,0.866 0.899 0.882 (+6.49%),0,,False
438,0.887 0.918 0.902 (+6.72%),0,,False
439,0.644 0.703 0.672 (-18.7%),0,,False
440,0.650 0.715 0.681 (-19.5%),0,,False
441,0.906 0.939 0.922 (+11.3%),0,,False
442,0.913 0.944 0.928 (+9.79%),0,,False
443,Least Squares Lasso MFTr MFSD CSD,0,,False
444,Table 5: Spammer Detection Results on TweetS Dataset,1,Spammer,True
445,External Data I (50%),0,,False
446,External Data II (100%),0,,False
447,Precision Recall F1-measure (gain) Precision Recall F1-measure (gain),0,,False
448,0.766 0.813,0,,False
449,0.789 (N.A.),0,,False
450,0.793 0.820,0,,False
451,0.806 (N.A.),0,,False
452,0.801 0.849 0.824 (+4.50%),0,,False
453,0.814 0.848 0.831 (+3.02%),0,,False
454,0.810 0.857 0.833 (+5.58%),0,,False
455,0.833 0.878 0.855 (+6.03%),0,,False
456,0.621 0.69 0.654 (-17.1%),0,,False
457,0.642 0.681 0.661 (-18.0%),0,,False
458,0.832 0.875 0.853 (+8.13%),0,,False
459,0.848 0.919 0.882 (+9.40%),0,,False
460,"Section 5.3, we consider their individual impact on the performance of spammer detection. A standard procedure for data preprocessing is used in our experiments. The unigram model is employed to construct the feature space, tf-idf is used as the feature weight.",0,,False
461,"As we discussed in Sections 4.1 and 4.3, three positive parameters are involved in the experiments, including  in Eq. (3), and  and  in Eq. (28).  is to control the effect of knowledge from other media to the learned lexicon,  is to control the contribution of Laplacian regularization, and  is to control the contribution of lexicon to the spammer detection model. Since all the parameters can be tuned via crossvalidation with a set of validation data, in the experiment, we empirically set  ,"" 0.1,  "", 0.1 and  , 0.1 for general experiment purposes. The effects of the parameters on the learning model will be further discussed in Section 5.4.",0,,False
462,5.2 Performance Evaluation,0,,False
463,"We compare the proposed method CSD with other methods for spammer detection, accordingly answer the first question asked above. The baseline methods are listed below.",0,,False
464,"· Least Squares: One possible solution for our task is to consider it as a supervised learning problem. We simply train a classification model with the available external data and apply the learned model on microblogging data for spammer detection. The widely used classifier, Least Squares [12], is used for comparison.",1,blog,True
465,"· Lasso: Sparse learning methods are effective for highdimensional data in social media. We further include Lasso [29] as the baseline method, which performs continuous shrinkage and automatic feature selection by adding l1 norm regularization to the Least Squares.",1,ad,True
466,"· MFTr : Although we first present a quantitative linguistic variation analysis and provide a unified model for spammer detection across different media, domain adaption and transfer learning have received great attention in various applications [27]. We apply a widely used transfer learning method [23], which transfers the knowledge directly from labeled data in the source do-",1,ad,True
467,"main to the target domain for classification, to test its performance on spammer detection in the experiment.",0,,False
468,"· MFSD: We test the performance of the unsupervised learning method by employing the basic matrix factorization model MFSD. This is a variant of our proposed method without introducing any knowledge learned from external sources. As a common initialization for clustering methods, we randomly assign initial centroids and an initial class indicator matrix for MFSD.",0,,False
469,"Experimental results of the methods on the two datasets, TweetH and TweetS, are respectively reported in Table 4 and 5. To avoid bias brought by the sizes of the training data,6 we conduct two sets of experiments with different numbers of training instances. In the experiments, ""External Data I (50%)"" means that we randomly chose 50% from the whole training data. ""External Data II (100%)"" means that we use all the data for training. Also, ""gain"" represents the percentage improvement of the methods in comparison with the first baseline method Least Squares. In the experiment, each result denotes an average of 10 test runs. By comparing the spammer detection performance of different methods, we observe the following:",1,Tweet,True
470,"(1) From the results in the tables, we can observe that our proposed method CSD consistently outperforms other baseline methods on both datasets with different sizes of training data. Our method achieves better results than the state-of-the-art method MFTr on both datasets. We apply two-sample one-tail t-tests to compare CSD to the four baseline methods. The experiment results demonstrate that the proposed model performs significantly better (with significance level  , 0.01) than the four methods.",0,,False
471,"(2) The performance of our proposed method CSD is better than the first three baselines, which are based on different strategies of using resources from the other media. This demonstrates the excellent use of cross-media knowledge in the proposed framework for spammer detection.",0,,False
472,"6Similar to the definitions in machine learning literature, training data here refers to the labeled data from the external sources, and testing data represents the unlabeled microblogging data.",1,blog,True
473,553,0,,False
474,Performance,0,,False
475,1 0.95,0,,False
476,0.9 0.85,0,,False
477,0.8 0.75,0,,False
478,0.7 Precision,0,,False
479,CSD_Email CSD_SMS CSD_Web CSD,0,,False
480,Recall,0,,False
481,Metrics,0,,False
482,F1-measure,0,,False
483,Figure 2: Results on TweetH Dataset,1,Tweet,True
484,Performance,0,,False
485,1 0.95,0,,False
486,0.9 0.85,0,,False
487,0.8 0.75,0,,False
488,0.7 Precision,0,,False
489,CSD_Email CSD_SMS CSD_Web CSD,0,,False
490,Recall,0,,False
491,Metrics,0,,False
492,F1-measure,0,,False
493,Figure 3: Results on TweetS Dataset,1,Tweet,True
494,"(3) Among the baseline methods, MFTr achieves the best results. It demonstrates that the knowledge transferred from other media help the task of spammer detection in microblogging. Lasso performs better than Least Squares. This shows that, for high-dimensional textual data from email, SMS and web, feature selection is necessary for a supervised learning method for this task we study.",1,blog,True
495,(4) The method MFSD achieves the worst performance among all the baseline methods. It shows that learning based on microblogging data itself can not discriminant well between spammers and legitimate users. It further demonstrates that the knowledge learned from external sources is helpful to build an effective model to tackle the problem.,1,blog,True
496,"In summary, with the effective use of data from the other media, our proposed framework outperforms the baseline methods in spammer detection. Next, we investigate the effects of different resources on the spammer detection task.",0,,False
497,5.3 Effects of External Information,0,,False
498,"In this subsection, we study the effects of the external information from the other media on our proposed framework, accordingly answering the second question asked in the beginning of Section 5.",0,,False
499,"We first evaluate the performance of the proposed framework with data from only one of the three media. In particular, we learn a lexicon based on one of the three types of media, i.e., email, SMS and web, and perform spammer detection on the microblogging datasets. We do not have legitimate web pages in the original Web dataset. To build a classifier CSD Web, following the data construction procedure proposed in [18], we randomly sample 20,100 web",1,blog,True
500,"snippets with BingAPI as legitimate data. The experimental results of the methods on the two microblogging datasets are plotted in Figures 2 and 3, respectively. In the figures, the first three bars represent the performance of the baselines with one type of external information. The last is the method with all three types of external information. From the figures, we observe the following:",1,AP,True
501,"(1) With the integration of all three types of external information, CSD consistently achieves better performance than the three baselines with only one type of information. It demonstrates that the proposed method uses beneficial information to perform effective spammer detection.",0,,False
502,"(2) Among the three baseline methods, CSD Email and CSD SMS achieve better performance than CSD Web. It shows that, as external resources, email and SMS data are more suitable to be used for the spammer detection in microblogging than the web data. This result is consistent with the linguistic variation analysis in Section 2.",1,blog,True
503,"To further explore the effects of different media sources on the performance of spammer detection in microblogging, we employ a ""knockout"" technique in the experiment. Knockout has been widely used in many fields, e.g., gene function analysis, to test the performance variance brought by one component when it is made inoperative in the framework [10]. We conduct the experiments by knocking out one type of the external information from the proposed framework. The results are summarized in Table 6. In the table, ""loss"" represents the performance decrease of the methods as compared to the setting ""Default"" which is learned based on data from all three media sources. The three columns in the middle are experimental settings, in which ""0"" means this resource is knocked out. The last two columns are the F1measure results under different experimental settings. From the table, we observe the following:",1,blog,True
504,"(1) By knocking out one of the external sources, performance of the proposed framework decreases. This suggests that all the three types of external information are useful for spammer detection in microblogging.",1,blog,True
505,(2) Knocking out email from the resources incurs the most performance decrease among all the experimental settings. This demonstrates that email is the most effective source among the three types of information. This finding is consistent with our discussion above.,0,,False
506,"In summary, the use of data from the other media shows the effectiveness in spammer detection task. The superior performance of the proposed method CSD validates its excellent use of knowledge from the other media.",0,,False
507,5.4 Parameter Analysis,0,,False
508,"As discussed in Section 5.1, three positive parameters, i.e., ,  and , are involved in the proposed framework. We first examine the effects brought by , which is to control the contribution of knowledge from other media to the learned lexicon. In previous subsections, for general experimental purposes, we empirically set  ,"" 0.1. We now conduct experiments to compare the spammer detection performance of the four methods introduced in Section 5.3 with different settings of . The experiment results on the TweetH dataset are plotted in Figure 4. From the figure, we observe the following: (1) The general trends of the four methods are similar with the variation of different parameter settings. They achieve relatively good performance when setting  in the range of [0.1, 10]. (2) In most cases, performance of""",1,Tweet,True
509,554,0,,False
510,Table 6: Learning from Different Media for Spammer Detection in Microblogging,1,Spammer,True
511,Email SMS,0,,False
512,Web TweetH (loss),1,Tweet,True
513,TweetS (loss),1,Tweet,True
514,Default,0,,False
515,1,0,,False
516,1,0,,False
517,1,0,,False
518,0.928 (N.A.),0,,False
519,0.882 (N.A.),0,,False
520,Knock Out One Term,0,,False
521,0 1 1,0,,False
522,1,0,,False
523,1,0,,False
524,0.881 (-5.09%),0,,False
525,0.843 (-4.43%),0,,False
526,0,0,,False
527,1,0,,False
528,0.911 (-1.86%),0,,False
529,0.856 (-2.96%),0,,False
530,1,0,,False
531,0,0,,False
532,0.923 (-0.57%),0,,False
533,0.860 (-2.50%),0,,False
534,Spammer Detection Performance,1,Spammer,True
535,1 0.95,0,,False
536,0.9 0.85,0,,False
537,0.8 0.75,0,,False
538,0.7 0.65,0,,False
539,0.6 1e-4,0,,False
540,1e-3,0,,False
541,0.01,0,,False
542,0.1,0,,False
543,1,0,,False
544,Parameter ,0,,False
545,CSD_Email CSD_SMS CSD_Web CSD,0,,False
546,10,0,,False
547,100,0,,False
548,Figure 4: Performance with Different  Settings,0,,False
549,Spammer Detection Performance,1,Spammer,True
550,1,0,,False
551,0.95,0,,False
552,0.9,0,,False
553,0.85,0,,False
554,0.8,0,,False
555,0.75,0,,False
556,0.7,0,,False
557,0.65 10,0,,False
558,5,0,,False
559,10,0,,False
560,1,0,,False
561,5,0,,False
562,0.1 0.01,0,,False
563,1 0.1 0.01,0,,False
564,Parameter -- ,0,,False
565,1e-3 1e-3,0,,False
566,Parameter -- ,0,,False
567,Figure 5: Impact of Content Information () and External Information (),0,,False
568,the proposed CSD is better than the other three methods. It demonstrates that the combination of the three resources improve the spammer detection performance.,0,,False
569,"We further examine the effects of the parameters  and  discussed in Eq. (28) on the proposed framework.  is to control the contribution of content information and  is to control the effects of external information from the other media. To understand the effects brought by the parameters, we compare the spammer detection performance of the proposed CSD on the Twitter datasets with different parameter settings. The results on the TweetH dataset are plotted in Figure 5. From the figure, we observe that the proposed method CSD performs well when   [0.1, 5] and   [0.1, 1]. Generally, the performance of CSD is not quite sensitive to the parameters. The proposed framework can perform well when choosing parameter settings in a reasonable range. Similar results have been observed for the two sets of experiments on the TweetS dataset; we omit the results owing to lack of space.",1,Twitter,True
570,6. RELATED WORK,0,,False
571,"Significant efforts have been devoted to detecting spammers in various online social networks, including Facebook [5], Twitter [19, 20, 22], Renren [32], Blogosphere [24], etc. One effective way to perform spammer detection is to use the social network information. The assumption is that spammers cannot establish a large number of social trust relations with normal users. This assumption might not hold in many social networks. Yang et al. [32] studied the spammers in Renren, and found that spammers can have their friend requests accepted by many other users and thus blend into the Renren social graph. Different from Facebook-like OSNs, microblogging systems feature unidirectional user bindings because anyone can follow anyone else without prior consent from the followee. Ghosh et al. [13] show that spammers can acquire many legitimate followers. Besides the methods based on social networks, some efforts [22] have also been devoted to study characteristics related to tweet content and user social behavior. By understanding spammer activities in social networks, features are extracted to perform effective spammer detection. These methods need a large amount of labeled data, which is hard to obtain in social media.",1,Twitter,True
572,"Spammer detection on emails [4], SMS [14] and the web [31] has been a hot topic for quite a few years. The spams are designed to corrupt the user experience by spreading ads or driving traffic to particular web sites [31]. A popular and well-developed approach for anti-spam applications is learning-based filtering. The basic idea is that we extract effective features from the labeled data and build a classifier. We then classify new users / messages as either spam or ham according to their content information for filtering. The attempts have been done in these areas and the abundant labeled resources are the major motivation of our work.",1,Spammer,True
573,"Some efforts have been made to employ domain adaption and transfer learning in various applications, e.g. sentiment analysis [23] and text classification [27]. Our work started the investigation of leveraging knowledge from other media for spammer detection in microblogging. Different from traditional methods, based on the quantitatively linguistic variation analysis, our proposed framework naturally combines knowledge learned from internal and external data sources in a unified model. In addition, some work has been done to study the linguistic challenges of social media texts. It is accepted that texts in social media are noisy, but it is also reported by researchers that the texts are not as noisy as what people expected [2]. The language used in Twitter is more like a projection of the language of formal media like news and blogs with shorter form [21], and it is possible to make use of normalization and domain adaption to ""clean"" it [11]. The evidence provided by linguists also motivate us to explore the language differences of spams across different media, and make use of resources from other media to help spammer detection in microblogging.",1,ad,True
574,555,0,,False
575,7. CONCLUSIONS AND FUTURE WORK,0,,False
576,"Texts in microblogging are short, noisy, and labeling processing is time-consuming and labor-intensive, which presents great challenges for spammer detection. In this paper, we first conduct a quantitative analysis to study how noisy the microblogging texts are by comparing them with spam messages from other media. The results suggest that microblogging data is not significantly different from data from the other media. Based on the observations, a matrix factorization model is employed to learn lexicon information from external spam resources. By incorporating external information from other media and content information from microblogging, we propose a novel framework for spammer detection. The experimental results demonstrate the effectiveness of our proposed model as well as the roles of different types of information in spammer detection.",1,blog,True
577,This work suggests some interesting future directions. Different types of medium resources have different effects on the spammer detection performance. It would be interesting to quantify the contributions of different types of sources to spammer detection in microblogging. This could be an important support for source selection in spammer detection.,1,blog,True
578,Acknowledgments,0,,False
579,"We truly thank the anonymous reviewers for their pertinent comments. This work is, in part, supported by ONR (N000141410095) and ARO (#025071).",0,,False
580,8. REFERENCES,0,,False
581,"[1] T. A. Almeida, J. M. G. Hidalgo, and A. Yamakami. Contributions to the study of sms spam filtering: new collection and results. In Proceedings of DocEng, 2011.",0,,False
582,"[2] T. Baldwin, P. Cook, M. Lui, A. MacKinlay, and L. Wang. How noisy social media text, how diffrnt social media sources? In Proceedings of IJCNLP, 2013.",0,,False
583,"[3] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All your contacts are belong to us: automated identity theft attacks on social networks. In WWW, 2009.",0,,False
584,"[4] E. Blanzieri and A. Bryl. A survey of learning-based techniques of email spam filtering. Artificial Intelligence Review, 29(1):63­92, 2008.",0,,False
585,"[5] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. The socialbot network: when bots socialize for fame and money. In ACSAC, 2011.",0,,False
586,"[6] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.",0,,False
587,"[7] H. M. Breland. Word frequency and word difficulty: A comparison of counts in four corpora. PSS, 1996.",1,corpora,True
588,"[8] F. Chung. Spectral graph theory. Number 92. Amer Mathematical Society, 1997.",0,,False
589,"[9] C. Ding, T. Li, and M. Jordan. Convex and semi-nonnegative matrix factorizations. TPAMI, 2010.",0,,False
590,"[10] T. Egener, J. Granado, and M. Guitton. High frequency of phenotypic deviations in physcomitrella patens plants transformed with a gene-disruption library. BMC Plant Biology, 2:6, 2002.",1,ad,True
591,"[11] J. Eisenstein. What to do about bad language on the internet. In Proceedings of NAACL-HLT, 2013.",1,ad,True
592,"[12] J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning, 2008.",0,,False
593,"[13] S. Ghosh, B. Viswanath, F. Kooti, N. Sharma, G. Korlam, F. Benevenuto, N. Ganguly, and K. Gummadi. Understanding and combating link farming in the twitter social network. In WWW, 2012.",1,ad,True
594,"[14] J. M. G´omez Hidalgo, G. C. Bringas, E. P. Sa´nz, and F. C. Garc´ia. Content based sms spam filtering. In Proceedings of DocEng, 2006.",0,,False
595,[15] M. A. Halliday and C. M. Matthiessen. An introduction to functional grammar. 2004.,0,,False
596,"[16] M. Hart. Project gutenberg. Project Gutenberg, 1971. [17] T. Hofmann. Probabilistic latent semantic indexing. In",0,,False
597,"Proceedings of SIGIR, 1999. [18] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting",0,,False
598,"internal and external semantics for the clustering of short texts using world knowledge. In CIKM, 2009. [19] X. Hu, J. Tang, and H. Liu. Online social spammer detection. In AAAI, 2014. [20] X. Hu, J. Tang, Y. Zhang, and H. Liu. Social spammer detection in microblogging. In IJCAI, 2013. [21] X. Hu, L. Tang, J. Tang, and H. Liu. Exploiting social relations for sentiment analysis in microblogging. In WSDM, 2013. [22] K. Lee, J. Caverlee, and S. Webb. Uncovering social spammers: social honeypots + machine learning. In Proceedings of SIGIR, 2010. [23] T. Li, Y. Zhang, and V. Sindhwani. A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge. In Proceedings of ACL, 2009. [24] Y.-R. Lin, H. Sundaram, Y. Chi, J. Tatemura, and B. L. Tseng. Splog detection using self-similarity analysis on blog temporal dynamics. In AirWeb, 2007. [25] V. Metsis, I. Androutsopoulos, and G. Paliouras. Spam filtering with naive bayes-which naive bayes? In Proceedings of CEAS, 2006. [26] D. O'Callaghan, M. Harrigan, J. Carthy, and P. Cunningham. Network analysis of recurring youtube spam campaigns. In Proceedings of ICWSM, 2012. [27] S. J. Pan and Q. Yang. A survey on transfer learning. TKDE, pages 1345­1359, 2010. [28] D. Seung and L. Lee. Algorithms for non-negative matrix factorization. NIPS, pages 556­562, 2001. [29] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), pages 267­288, 1996. [30] R. Wardhaugh. An introduction to sociolinguistics, volume 28. Wiley. com, 2011. [31] S. Webb, J. Caverlee, and C. Pu. Introducing the webb spam corpus: Using email spam to identify web spam automatically. In CEAS, 2006. [32] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Zhao, and Y. Dai. Uncovering social network sybils in the wild. In Proceedings of IMC, 2011. [33] S. J. Yates. Oral and written linguistic aspects of computer conferencing. Pragmatics and beyond New Series, 1996. [34] Y. Zhu, X. Wang, E. Zhong, N. Liu, H. Li, and Q. Yang. Discovering spammers in social networks. In Proceedings of AAAI, 2012.",1,blog,True
599,556,0,,False
600,,0,,False
