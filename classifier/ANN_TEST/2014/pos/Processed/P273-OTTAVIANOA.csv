,sentence,label,data,regex
0,Partitioned Elias-Fano Indexes,0,,False
1,Giuseppe Ottaviano,0,,False
2,"ISTI-CNR, Pisa",0,,False
3,giuseppe.ottaviano@isti.cnr.it,0,,False
4,Rossano Venturini,0,,False
5,"Dept. of Computer Science, University of Pisa",0,,False
6,rossano@di.unipi.it,0,,False
7,ABSTRACT,0,,False
8,"The Elias-Fano representation of monotone sequences has been recently applied to the compression of inverted indexes, showing excellent query performance thanks to its efficient random access and search operations. While its space occupancy is competitive with some state-of-the-art methods such as --Golomb codes and PForDelta, it fails to exploit the local clustering that inverted lists usually exhibit, namely the presence of long subsequences of close identifiers.",0,,False
9,"In this paper we describe a new representation based on partitioning the list into chunks and encoding both the chunks and their endpoints with Elias-Fano, hence forming a twolevel data structure. This partitioning enables the encoding to better adapt to the local statistics of the chunk, thus exploiting clustering and improving compression. We present two partition strategies, respectively with fixed and variablelength chunks. For the latter case we introduce a linear-time optimization algorithm which identifies the minimum-space partition up to an arbitrarily small approximation factor.",1,ad,True
10,"We show that our partitioned Elias-Fano indexes offer significantly better compression than plain Elias-Fano, while preserving their query time efficiency. Furthermore, compared with other state-of-the-art compressed encodings, our indexes exhibit the best compression ratio/query time trade-off.",1,ad,True
11,Categories and Subject Descriptors,0,,False
12,H.3.2 [Information Storage and Retrieval]: Information Storage; E.4 [Coding and Information Theory]: Data Compaction and Compression,0,,False
13,Keywords,0,,False
14,Compression; Dynamic Programming; Inverted Indexes,0,,False
15,1. INTRODUCTION,1,DUC,True
16,"The inverted index is the data structure at the core of most large-scale search systems for text, (semi-)structured data, and graphs, with web search engines, XML and RDF",0,,False
17,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609615.",1,ad,True
18,"databases, and graph search engines in social networks as the most notable examples. The huge size of the corpora involved and the stringent query efficiency requirements of these applications have driven a large amount of research with the ultimate goal of minimizing the space occupancy of the index and maximizing its query processing speed. These are two conflicting objectives: a high level of compression is obtained by removing the redundancy in the dataset, high speed is obtained by keeping the data easily accessible and by augmenting the dataset with auxiliary information that drive the query processing algorithm. The effects of space reduction on the memory hierarchy partially mitigate this dichotomy. Indeed, memory transfers are an important bottleneck in query processing, and, thus, fitting more data into higher and faster levels of the hierarchy reduces the transfer time from the slow levels, and, hence, speeds up the algorithm [5]. In fact, in the last few years the focus has shifted from disk-based indexes to in-memory indexes, as in many scenarios it is not possible to afford a single disk seek. However, these beneficial effects can be nullified by slow decoding algorithms. Thus, research has focused its attention on designing solutions that best balance decoding time and space occupancy.",1,corpora,True
19,"In its most basic and popular form, an inverted index is a collection of sorted sequences of integers [6, 16, 27]. Compressing such sequences is a crucial problem which has been studied since the 1950s; the literature presents several approaches, each of which introduces its own trade-off between space occupancy and decompression speed [15, 17, 19, 22, 26]. Most of these methods only allow sequential decoding, so the lists involved while processing a query need to be entirely decoded. This can be avoided by using the standard technique of splitting each sequence into blocks of fixed size (say, 128 elements) and encoding each block independently, so that it is possible to avoid the decompression of portions which are not necessary for answering the query. Still, a block must be fully decoded even if just one of its values is required.",1,ad,True
20,"Recently Vigna [23] overcame this drawback by introducing a new data structure called quasi-succinct index. This index hinges on the Elias-Fano representation of monotone sequences [10, 11], a conceptually simple and elegant data structure that supports fast random access and search operations, combining strong theoretical guarantees and excellent practical performance. Vigna showed that quasi-succinct indexes can compete in speed with mature and highly engineered implementations of state-of-the-art inverted indexes. In particular, Elias-Fano shines when the values accessed are scattered in the list; this is very common in conjunctive queries when the number of results is significantly smaller",0,,False
21,273,0,,False
22,"than the sequences being intersected. A typical scenario,",0,,False
23,"for example, is intersecting edge sets in large social net-",0,,False
24,"work graphs, as Facebook's Graph Search, which has in fact",0,,False
25,adopted an implementationof Elias-Fano indexes [8].,1,ad,True
26,Experiments show however that Elias-Fano indexes can be,0,,False
27,significantly larger than those obtained using state-of-the-art,0,,False
28,encoders. This inefficiency is caused by its inability to exploit,0,,False
29,any characteristics of the sequence other than two global,0,,False
30,"statistics: the number of elements in the list, and the value of",0,,False
31,"the largest element. More precisely, Elias-Fano represents a",0,,False
32,monotone sequence of m integers smaller than u with roughly,0,,False
33,m,0,,False
34,log,0,,False
35,u m,0,,False
36,"+ 2m bits of space, regardless of any regularities",0,,False
37,in the sequence. As an extreme toy example consider the,0,,False
38,"sequence S ,"" [0, 1, 2, . . . , m - 2, u - 1] of length m. This""",0,,False
39,sequence is highly compressible since the length of the first,0,,False
40,"run and the value of u, which can be encoded in O(log u)",0,,False
41,"bits, are sufficient to describe S. Elias-Fano requires instead",1,ad,True
42,log,0,,False
43,u m,0,,False
44,"+ 2 bits for every element in the sequence, which is",0,,False
45,not one single bit less than it would require to represent a,0,,False
46,random sequence of m sorted elements smaller than u. Even,0,,False
47,"if this is just a toy example, it highlights an issue that occurs",0,,False
48,"frequently in compressing posting lists, whose compressibility",0,,False
49,is caused by large clusters of very close values.,0,,False
50,In this paper we tackle this issue by partitioning the se-,0,,False
51,quences into contiguous chunks and encoding each chunk,0,,False
52,"independently with Elias-Fano, so that the encoding of each",0,,False
53,chunk can better adapt to the local statistics. To perform ran-,1,ad,True
54,"dom access and search operations, the lists of chunk endpoints",0,,False
55,"and boundary elements are in turn encoded with Elias-Fano,",0,,False
56,thus forming a two-level data structure which supports fast,0,,False
57,queries on the original sequence. The chunk endpoints can be,0,,False
58,"completely arbitrary, so we propose two strategies to define",0,,False
59,"the partition. The first is a straightforward uniform partition,",0,,False
60,meaning that each chunk (except possibly the last) has the,0,,False
61,same fixed size. The second aims at minimizing the space,0,,False
62,occupancy by setting up the partitioning as an instance of,0,,False
63,"an optimization problem, for which we present a linear-time",0,,False
64,algorithm that is guaranteed to find a solution at most (1 + ),0,,False
65,"times larger than the optimal one, for any given  (0, 1).",0,,False
66,We perform an extensive experimental analysis on two,0,,False
67,"large text corpora, namely Gov2 and ClueWeb09 (Category",1,corpora,True
68,"B), with several query operations, and compare our indexes",0,,False
69,"with the plain quasi-succinct indexes as described in [23], and",0,,False
70,"with three state-of-the-art list encodings, namely Binary In-",0,,False
71,"terpolative Coding [17], the PForDelta variant OptPFD [26],",0,,False
72,"and Varint-G8IU [22], a SIMD-optimized Variable Byte code.",0,,False
73,"Respectively, they are representative of best compression",0,,False
74,"ratio, best compression ratio/processing speed trade-off, and",1,ad,True
75,highest speed in the literature.,0,,False
76,"In our experiments, we show that our indexes are signifi-",0,,False
77,"cantly smaller than the original quasi-succinct indexes, with",0,,False
78,"a small query time overhead. Compared to the others, they",1,ad,True
79,"are slightly larger but significantly faster than Interpolative,",0,,False
80,"both faster and smaller than OptPFD, and slightly slower",0,,False
81,but significantly smaller than Varint-G8IU.,0,,False
82,Our contributions. We list here our main contributions.,0,,False
83,"1. We introduce a two-level representation of monotone sequences which, given a partition of a sequence into chunks, represents each chunk with Elias-Fano and stores the endpoints of the chunks and their boundary values in separate Elias-Fano sequences, in order to support fast random access and search operations.",0,,False
84,"2. We describe two partitioning strategies: an uniform strategy, which divides the sequence into chunks with a fixed size, and a strategy with variable-length chunks, whose endpoints are chosen by solving an optimization problem in order to minimize the overall space occupancy. More precisely, we introduce a linear-time dynamic programming algorithm which finds a partition whose cost is at most (1 + ) times larger than the optimal one, for any given  (0, 1). In the experiments we show that this -optimal strategy gives significantly smaller indexes than the uniform strategy, which in turn are significantly smaller than the indexes obtained with non-partitioned Elias-Fano. Indeed, the latter are more than 23% larger on ClueWeb09 and more than 64% larger on Gov2.",1,ClueWeb,True
85,"3. We show with an extensive experimental analysis that the partitioned indexes are only slightly slower than non-partitioned indexes. Furthermore, in comparison with other indexes from the literature, the -optimal indexes dominate in both space and time methods which are in the same region of the space-time tradeoff curve, and obtain spaces very close to the methods which give the highest compression ratio. More precisely, Binary Interpolative Coding is only 2%-8% smaller but up to 5.5 times slower; OptPFD is roughly 12% larger and almost always slower; Varint-G8IU is 10%-40% faster but more than 2.5 times larger.",1,ad,True
86,2. BACKGROUND AND NOTATION,0,,False
87,"Given a collection D of documents, the posting list of a term t is the list of all the document identifiers, or docIds, that contain the term t. The collection of posting lists for all the terms in the collection is called the inverted index of D; the set of such terms is usually called the dictionary. Posting lists are often augmented with additional information about each docId, such as the number of occurrences of the term in the document (the frequency), and the set of positions where the term occurs. Since the inverted index is a fundamental data structure in virtually all modern search systems, there is a vast amount of literature describing several variants and query processing strategies; we refer the reader to the excellent surveys and books on the subject [6, 16, 27].",1,ad,True
88,"In the following, we adopt the docId-sorted variant, meaning that each posting list is sorted by docId; this enables fast query processing and efficient compression. In our experiments we focus our attention on posting lists storing docIds and frequencies; we do not store positions or other additional data, since they have different nature and often require specialized compression techniques [25], thus they are outside of the scope of this paper. We also ignore additional per-document or per-term information, such as the mappings between docIds and URLs, or between termIds and actual terms, as their space is negligible compared to the index size.",1,ad,True
89,Query Processing. Given a term query as a (multi-)set of,1,Query,True
90,"terms, the basic query operations are the boolean conjunctive (AND) and disjunctive (OR) queries, retrieving the documents that contain respectively all the terms or at least one of them. In many scenarios the query-document pairs can be associated with a relevance score which is usually a function of the term frequencies in the query and in the document, and other global statistics. Instead of the full set of matches,",1,ad,True
91,274,0,,False
92,"for scored queries it is often sufficient to retrieve the k highest scored documents for a given k. A widely used relevance score is BM25 [18], which we will use in our experiments.",0,,False
93,"There exist two popular query processing strategies, dual in nature, namely Term-at-a-Time (TAAT) and Documentat-a-Time (DAAT). The former scans the posting list of each query term separately to build the result set, while the latter scans them concurrently, keeping them aligned by docId. We will focus on the DAAT strategy as it is the most natural for docId-sorted indexes.",0,,False
94,"The alignment of the lists during DAAT scanning can be achieved by means of the NextGEQt(d) operator, which returns the smallest docId in the list of t that is greater than or equal to d. A fast implementation of the function NextGEQt(d) is crucial for the efficiency of this process. The trivial implementation that scans sequentially the whole posting lists is usually too slow; a common solution resorts to skipping strategies. The basic idea is to divide the lists in small blocks that are compressed independently, and to store additional information about each block, in particular the maximum docId present in the block. This allows to find and decode only the block that may contain the sought docId by scanning the list of maxima, thus skipping a potentially large number of useless blocks. In the following we call block-based the indexes that adopt this technique.",1,ad,True
95,"Solving scored queries can be achieved with DAAT by computing the relevance score for the matching documents as they are found, and maintaining a priority queue with the top-k matches. This can be very inefficient for scored disjunctive queries, as the whole lists need to be scanned. Several query processing strategies have been introduced to alleviate this problem. Among them, one the most popular is WAND [3], which augments the index by storing for each term its maximum impact to the score, thus allowing to skip large segments of docIds if they only contain terms whose sum of maximum impacts is smaller than the top-k documents found up to that point. Again, WAND can be efficiently implemented in terms of NextGEQt(d).",0,,False
96,3. RELATED WORK,0,,False
97,"Index compression ultimately reduces to the problem of representing sequences, specifically strictly monotone sequences for docIds, and positive sequences for the frequencies. The two are equivalent: a strictly monotone sequence can be turned into a positive sequence by subtracting from each element the one that precedes it (also known as delta encoding), the other direction can be achieved by computing prefix sums. For this reason most of the work assumes that the posting lists are delta-encoded and focuses on the representation of sequences of positive integers.",0,,False
98,"Representing such sequences of integers in compressed space is a crucial problem which has been studied since the 1950s with applications going beyond inverted indexes. A classical solution is to assign to each integer an uniquelydecodable variable length code; if the codes do not depend on the input they are called universal codes. The most basic example is the unary code, which encodes a non-negative integer x as the bit sequence 0x1. The unary code is efficient only if the input distribution is concentrated on very small integers. More sophisticated codes, such as Elias Gamma/Delta codes and Golomb/Rice codes build on the unary code to efficiently compress a broader class of distributions. We refer to Salomon [19] for an in-depth discussion on this topic.",1,ad,True
99,"Bit-aligned codes can be inefficient to decode as they require several bitwise operations, so byte-aligned or wordaligned codes are usually preferred if speed is a main concern. Variable byte [19] or VByte is the most popular byte-aligned code. In VByte the binary representation of a non-negative integer x is split into groups of 7 bits which are represented as a sequence of bytes. The lower 7 bits of each byte store the data, whereas the eighth bit, called the continuation bit, is equal to 1 only for the last byte of the sequence. Stepanov et al. [22] present a variant of variable byte (called Varint-G8IU) which exploits SIMD operations of modern CPUs to further speed up decoding.",0,,False
100,"A different approach is to encode simultaneously blocks of integers in order to improve both compression ratio and decoding speed. This line of work has seen in the last few years a proliferation of encoding approaches which find their common roots in frame-of-reference (For) [14]. Their underlying idea is to partition the sequence of integers into blocks of fixed or variable length and to encode each block separately. The integers in each block are encoded by resorting to codewords of fixed length. A basic application of this technique (called also binary packing or packed binary [2,15]) partitions the sequence of integers into blocks of b consecutive integers (e.g., b ,"" 128 integers); for each block, the algorithm encodes the range enclosing the values in the block, say [l, r], then each value is subtracted l and represented with h "","" log(r - l + 1) bits. There are several variants of this approach which differentiate themselves for their encoding or partitioning strategies [9, 15, 21]. For example, Simple-9 and Simple-16 [1, 2, 26] are two popular variants of this approach.""",0,,False
101,"A major space inefficiency of For is the fact that the presence of few large values in the block forces the algorithm to encode all its integers with a large h, thus affecting the overall compression performance. To address this issue, PForDelta (PFD) [28] introduces the concept of patching. In PFD the value of h is chosen so that h bits are sufficient to encode a large fraction of the integers in the block, say 90%. Those integers that do not fit within h bits are called exceptions and encoded separately with a different encoder (e.g., Simple-9 or Simple-16). Yan et al.'s introduce the OptPFD variant [26], which selects for each block the value of h that minimizes the space occupancy. OptPFD is more compact and only slightly slower than the original PFD [15, 26].",1,ad,True
102,"A completely different approach is taken by Binary Interpolative Coding [17], which skips the delta-encoding step and directly encodes strictly monotone sequences. This method recursively splits the sequence of integers in two halves, encoding at each split the middle element and recursively the two halves. At each recursive step the range that encloses the middle element is reduced, and so is the number of bits needed to encode it. Experiments [21,24,26] have shown that Binary Interpolative Coding is the best encoding method for highly clustered sequence of integers. However, this space efficiency is paid at the cost of a very slow decoding algorithm.",0,,False
103,"Recently, Vigna [23] introduced quasi-succinct indexes, based on the Elias-Fano representation of monotone sequences, showing that it is competitive with delta-encoded block-based indexes. Our paper aims at making this representation more space-efficient.",0,,False
104,Optimal partitioning algorithms. The idea of partition-,0,,False
105,"ing a sequence to improve compression dates back to Buchsbaum et al. [4], who address the problem of partitioning the",1,ad,True
106,275,0,,False
107,"input of a compressor C so that compressing the chunks individually yields a smaller space than compressing the whole input at once. Their paper discusses only the case of compressing a large table of records with gzip but their solution can be adapted to solve the more general problem stated above. Their approach is to reduce this optimization problem to a dynamic programming recurrence which is solved in (m3) time and (m2) space, where m is the input size.",1,ad,True
108,"Silvestri and Venturini [21] resort to a similar dynamic programming recurrence to optimize their encoder for posting lists. They obtain an O(mh) construction time by limiting the length of the longest part to h. Ferragina et al. [12] significantly improve the result in [4] by computing in O(m log1+ m) time and O(m) space a partition whose compressed size is guaranteed to be at most (1 + ) times the optimal one, for any given > 0, provided that the compression ratio of C on any portion of the input can be estimated in constant time.",0,,False
109,"In this paper we apply the same ideas in [12] to the EliasFano representation and we exploit some of its properties to compute exactly, as opposed to estimating, its encoding cost in constant time. Then, we improve the optimization algorithm reducing its time to O(m) while preserving the same approximation guarantees.",0,,False
110,4. SEARCHABLE SEQUENCES,0,,False
111,"The Elias-Fano representation [10, 11] is an elegant encod-",0,,False
112,"ing for monotone sequences, which provides good compression",0,,False
113,ratio and efficient access and searching operations. Consider,0,,False
114,"a monotonically increasing sequence S[0, m - 1] of m non-",0,,False
115,"negative integers (i.e., S[i]  S[i + 1], for any 0  i < m - 1)",0,,False
116,"drawn from an universe [u] ,"" {0, 1, . . . , u - 1}.""",0,,False
117,"Given an integer , the elements of S are conceptually",0,,False
118,grouped into buckets according to their log u - higher bits. The number of buckets is thus u . The cardinalities of,0,,False
119,2,0,,False
120,these buckets (including the empty ones) are written into a,0,,False
121,bitvector H with negated unary codes; it follows that H has,0,,False
122,length,0,,False
123,at,0,,False
124,most,0,,False
125,m,0,,False
126,+,0,,False
127,u 2,0,,False
128,bits. The remaining,0,,False
129,lower bits of,0,,False
130,"each integer are concatenated into a bitvector L, which thus",0,,False
131,requires m bits. It is easy to see that H and L are sufficient,0,,False
132,to recover S[i] for every i: its log u - higher bits are equal,0,,False
133,"to the number of 0s preceding the ith 1 in H, and the lower",0,,False
134,bits can be retrieved directly from L.,0,,False
135,"While can be chosen arbitrarily between 0 and log u ,",0,,False
136,it can be shown that the value,0,,False
137,",",0,,False
138,log,0,,False
139,u m,0,,False
140,minimizes the,0,,False
141,"overall space. Summing up the lengths of H and L, it follows",0,,False
142,that,0,,False
143,the,0,,False
144,representation,0,,False
145,requires,0,,False
146,at,0,,False
147,most,0,,False
148,m,0,,False
149,log,0,,False
150,u m,0,,False
151,+ 2m bits.,0,,False
152,"Despite its simplicity, it is possible to support efficiently",0,,False
153,powerful operations on S. For our purposes we are interested,0,,False
154,in the following.,0,,False
155,"· Access(i) which, given i  [m], returns S[i];",0,,False
156,"· NextGEQ(x) which, given x  [u], returns the smallest element in S which is greater than or equal to x.",0,,False
157,"The support for these operations requires to augment H with an auxiliary data structure to efficiently answer Select0 and Select1 operations, which, given an index i, return the position of respectively the ith 1 or the ith 0 in H. See [23] and references therein for more details on the implementation",0,,False
158,of these standard operations. To access the ith element of S we have to retrieve and,0,,False
159,"concatenate its higher and lower bits. The value of the higher bits is obtained by computing Select1(i) - i in H, which",0,,False
160,"represents the number of 0s (thus, buckets) ending before",0,,False
161,the ith occurrence of 1. The lower bits are directly accessed,0,,False
162,by reading consecutive bits in L starting from position i .,1,ad,True
163,The operation NextGEQ(x) is supported by observing that,0,,False
164,"p ,"" Select0(hx) - hx is the number of elements of S whose higher bits are smaller than hx, where hx are the higher bits of x. Thus, p is the starting position in S of the elements whose""",0,,False
165,higher bits are equal to hx (if any) or larger. NextGEQ(x) is identified by scanning the elements starting from p.,0,,False
166,Several implementations of Elias-Fano supporting efficiently these operations are available1.,0,,False
167,"All the operations can be implemented in a stateful cursor,",0,,False
168,in order to exploit locality of access by optimizing short,0,,False
169,"forward skips, which are very frequent in query processing.",0,,False
170,"An additional convenient cursor operation is Next, which",1,ad,True
171,advances the cursor from position i to i + 1.,1,ad,True
172,"Note that Elias-Fano requires just weak monotonicity of S,",0,,False
173,"so if only the Access operation is needed, the space occupancy",0,,False
174,can,0,,False
175,be,0,,False
176,reduced,0,,False
177,to,0,,False
178,m,0,,False
179,log,0,,False
180,u-m+1 m,0,,False
181,+ 2m bits by turning S into,0,,False
182,"a weakly monotone sequence S [i] , S[i] - i and encoding S",0,,False
183,with Elias-Fano. At query time we can recover the ith entry,0,,False
184,of S by computing AccessS (i) + i. The quasi-succinct indexes of Vigna [23] are a direct ap-,0,,False
185,plication of Elias-Fano; the posting lists are immediately,0,,False
186,representable with Elias-Fano as the docIds are monoton-,0,,False
187,ically sorted. Since Elias-Fano is not efficient for dense se-,0,,False
188,"quences, a bitvector is used instead when it is convenient to",1,ad,True
189,do so; the Access and NextGEQ can be supported efficiently,0,,False
190,with small additional data structures. The frequencies can,1,ad,True
191,be turned into a strictly monotone sequence by computing,0,,False
192,"their prefix sums, and the ith frequency can be recovered as",0,,False
193,"Access(i)-Access(i-1). Moreover, since the query processing",0,,False
194,"needs only Access on the frequencies, we can use the trick",0,,False
195,mentioned above to reduce the space occupancy of the rep-,0,,False
196,"resentation. In positional indexes, a similar transformation",0,,False
197,can be used to represent the term positions.,0,,False
198,4.1 Uniform partitioning,0,,False
199,As we argued above Elias-Fano uses roughly,0,,False
200,log,0,,False
201,u m,0,,False
202,+2,0,,False
203,bits per element regardless the sequence being compressed.,0,,False
204,Notice,0,,False
205,that,0,,False
206,log,0,,False
207,u m,0,,False
208,is,0,,False
209,the,0,,False
210,logarithm,0,,False
211,of,0,,False
212,the,0,,False
213,average,0,,False
214,distance,0,,False
215,among consecutive elements in the sequence. Apart from this,0,,False
216,"average distance, Elias-Fano does not exploit in any way the",0,,False
217,"nature of the underlying sequence and, thus, for example it",0,,False
218,does not make any distinction between the two extreme cases,0,,False
219,of a randomly generated sequence and a sequence formed by,0,,False
220,only a long run of consecutive integers. While paying,0,,False
221,log,0,,False
222,u m,0,,False
223,bits per element is the best we can hope for in the former,0,,False
224,"case, we would expect to achieve a better space occupancy in",0,,False
225,"the latter. Indeed, a sequence of integers is intuitively more",0,,False
226,compressible than a random one when it contains regions of,0,,False
227,integers which are very close to each other. The presence of,0,,False
228,these regions is typical in posting lists. Consider for example,0,,False
229,a term which is present only in few domains. If the docIds are,0,,False
230,"assigned by sorting the documents by their URLs, then the",0,,False
231,"posting list of this term is, apart from few outliers, formed",0,,False
232,by clusters of integers in correspondence of those domains.,0,,False
233,"Observe that, since the elements within each region are very",0,,False
234,"close to each other, the average distance intra-region is much",0,,False
235,smaller than the global average distance.,0,,False
236,"1Such as the open-source http://github.com/facebook/ folly, http://github.com/simongog/sdsl, http:// github.com/ot/succinct, and http://sux.di.unimi.it.",0,,False
237,276,0,,False
238,The above observation is the main motivation for intro-,0,,False
239,ducing a two-level Elias-Fano. The basic idea is to parti-,0,,False
240,tion the sequence S into m/b chunks of b consecutive in-,0,,False
241,"tegers each, except possibly the last one. The first level is",0,,False
242,an Elias-Fano representation of the sequence L obtained,0,,False
243,"by juxtaposing the last element of each chunk (i.e., L ,",0,,False
244,"S[b - 1], S[2b - 1], . . . , S[m - 1]). The second level is the col-",0,,False
245,"lection of the chunks of S, each represented with Elias-Fano.",0,,False
246,The main advantage of having this first level is that the ele-,1,ad,True
247,ments of the jth chunk can be rewritten in a smaller universe,0,,False
248,"of size uj , L[j] - L[j - 1] - 1 by subtracting L[j - 1] + 1",0,,False
249,"from each element. Thus, the Elias-Fano representation of",0,,False
250,the chunk requires,0,,False
251,quantity,0,,False
252,uj b,0,,False
253,is the,0,,False
254,log,0,,False
255,uj b,0,,False
256,average,0,,False
257,+ 2 bits distance,0,,False
258,per element. Since the of the elements within,0,,False
259,"the chunk, we expect that this space occupancy is much",0,,False
260,smaller that the one obtained by representing the sequence,0,,False
261,"in its entirety, especially for highly compressible sequences.",0,,False
262,Observe that part of this gain vanishes due to the cost of,0,,False
263,the first level which is,0,,False
264,log,0,,False
265,u m/b,0,,False
266,+ 2 bits every b original,0,,False
267,"elements. Indeed, the first level stores m/b integers drawn",0,,False
268,from a universe of size u.,0,,False
269,This two-level representation introduces a level of indi-,0,,False
270,rection in solving the operations Access and NextGEQ. The,0,,False
271,operation Access(i) is solved as follows. Let j be the index,0,,False
272,"of the chunk containing the ith element of S (i.e., j , i/b )",0,,False
273,"and k be its offset within this chunk (i.e., k , i mod b).",0,,False
274,We access L[j - 1] and L[j] on the first level to compute,0,,False
275,the size of the universe uj of the chunk as L[j] - L[j - 1] (or L[j] if j is the first chunk). Knowing uj and b suffices for accessing the kth element of the jth chunk. If e is the,0,,False
276,"value at this position, then we conclude that the value S[i]",0,,False
277,is equal to L[j] + 1 + e. The operation NextGEQ(x) is solved,0,,False
278,"as follows. We first compute the successor of x, say L[j], on",0,,False
279,the first level. This implies that the successor of x in S is,0,,False
280,"within the jth chunk and, thus, it can be identified by solving",0,,False
281,NextGEQ(x - L[j] - 1) on this chunk.,0,,False
282,An important distinction with block-based indexes is that,0,,False
283,the choice of b does not affect significantly the efficiency,0,,False
284,of the operations: while block-based indexes may need to,0,,False
285,"scan the full block to retrieve one element, the chunks in our",0,,False
286,"representation are searchable sequences themselves, so the",0,,False
287,performance does not degrade as b gets larger; it actually,1,ad,True
288,"gets better, as fewer block boundaries have to be crossed",0,,False
289,during a query.,0,,False
290,In our implementation we use different encodings to over-,0,,False
291,come the space inefficiencies of Elias-Fano in representing,0,,False
292,dense chunks. The jth chunk is dense if the chunk covers,0,,False
293,"a large fraction of the elements in the universe [uj] (or,",0,,False
294,"in other words, b is close to uj). Indeed, the space bound",0,,False
295,b,0,,False
296,log,0,,False
297,uj b,0,,False
298,+ 2b bits becomes close to 2uj bits whenever b,0,,False
299,"approaches uj. However, we can always represent the chunk",0,,False
300,within uj bits by writing the characteristic vector of the,0,,False
301,set of its elements as a bitvector. Note that Vigna [23] also,0,,False
302,"uses this technique but only for whole lists, which are very",0,,False
303,unlikely to be so dense except for very few terms such as,0,,False
304,"stop-words. In our case, instead, we expect dense chunks",1,ad,True
305,"to occur frequently in representing posting lists, because",0,,False
306,"they can be contained inside dense clusters of docIds. Hence,",0,,False
307,"besides Elias-Fano, we adopt two other encodings chosen de-",1,ad,True
308,pending on the relation between uj and b. The first encoding,0,,False
309,addresses the extreme case in which the chunk covers the,1,ad,True
310,"whole universe (i.e., whenever uj is equal to b). The first level gives us the values of uj and b which are enough by",0,,False
311,themselves to derive all the elements in the chunk without,0,,False
312,the need of encoding further information. Operations Access,0,,False
313,and NextGEQ become trivial: both Access(i) and NextGEQ(i),0,,False
314,are equal to i. The second encoding is used whenever the,0,,False
315,size of the Elias-Fano representation of the chunk is larger,0,,False
316,than,0,,False
317,uj,0,,False
318,bits,0,,False
319,"(i.e.,",0,,False
320,whenever,0,,False
321,b,0,,False
322,>,0,,False
323,uj 4,0,,False
324,).,0,,False
325,In,0,,False
326,this,0,,False
327,case,0,,False
328,we,0,,False
329,encode,0,,False
330,the set of elements in the chunk by writing its characteristic,0,,False
331,vector in uj bits. The Access and NextGEQ operations can be reduced to the standard Rank and Select operations on,0,,False
332,bitvectors; their implementation is described in detail in [23].,0,,False
333,4.2 Optimal partitioning,0,,False
334,Splitting S into chunks of fixed size is likely to be subopti-,0,,False
335,"mal, since we cannot expect the dense clusters in S to appear",0,,False
336,aligned with the uniform partition. Intuitively it would be,0,,False
337,"better to allow S to be partitioned freely, with chunks of vari-",0,,False
338,able size. It is not obvious however how to find the partition,0,,False
339,"that minimizes the overall space occupancy: on one hand, the",0,,False
340,chunks should be as large as possible to minimize the number,0,,False
341,"of entries in the first level of the representation and, thus, its",0,,False
342,"space occupancy; on the other hand, the chunks should be as",0,,False
343,small as possible to minimize the average distances between,0,,False
344,"their elements, and, thus, the space occupancy of the second",0,,False
345,level of the representation. An optimal partition can be computed in (n2) time,0,,False
346,and space by solving a variant of dynamic programming,0,,False
347,"recurrence introduced in [4]. However, these prohibitive com-",0,,False
348,plexities make this solution unfeasible for inputs larger than,0,,False
349,few thousands of integers. This is the main motivation for de-,0,,False
350,signing an approximation algorithm which reduces the time,0,,False
351,and space complexities to linear at the cost of finding slightly,0,,False
352,"suboptimal solutions. More precisely, in this subsection we",0,,False
353,present an algorithm that identifies in O(m log1+ 1 ) time and linear space a partition whose cost is only 1 + times,0,,False
354,"larger than the optimal one, for any given  (0, 1). Observe",0,,False
355,that the time complexity is linear as soon as is constant.,0,,False
356,"Before entering into the technical details of our solution, it",0,,False
357,is convenient to fix precisely the space costs involved in our,0,,False
358,representation. The space occupancy of a given partition P,0,,False
359,"of k chunks S[i0, i1 - 1] S[i1, i2 - 1] . . . S[ik-1, ik], with i0 , 0",0,,False
360,"and ik ,"" m-1, is C(P ) "",",0,,False
361,"k-1 h,0",0,,False
362,"C (S [ih ,",0,,False
363,ih+1,0,,False
364,-1]),0,,False
365,"bits,",0,,False
366,where,0,,False
367,"C(S[i, j]) is the cost of representing the chunk S[i, j]. Each",0,,False
368,"of these costs C(S[i, j]) is the sum of two terms: a fixed cost",0,,False
369,F to store information regarding the chunk in the first level,0,,False
370,and the cost of representing its elements in the second level.,0,,False
371,"Concerning the fixed cost F , for each chunk we store three",0,,False
372,"integers in the first level: the largest integer within the chunk,",0,,False
373,"the size of the chunk, and the pointer to its second-level Elias-",0,,False
374,"Fano representation. Thus, we can safely upper bound this",0,,False
375,"cost F with the quantity 2 log u + log m bits. Instead, the",1,ad,True
376,"cost of representing the elements in S[i, j] is computed by",0,,False
377,taking the minimum between the costs of the three possible,0,,False
378,encodings introduced in the previous subsection. Depending,0,,False
379,"on the size of the universe u ,"" S[j]-S[i-1] (or, u "","" S[j], if""",0,,False
380,"i , 0) and the number of elements m ,"" j - i + 1, these three""",0,,False
381,costs are i) m,0,,False
382,+m,0,,False
383,+,0,,False
384,u 2,0,,False
385,bits with,0,,False
386,",",0,,False
387,log,0,,False
388,u m,0,,False
389,", if S[i, j]",0,,False
390,"is encoded with Elias-Fano; ii) m bits, if S[i, j] is encoded",0,,False
391,"with its characteristic vector; iii) 0 bits, if m ,"" u and,""",0,,False
392,"thus, S[i, j] covers the whole universe. A crucial property",0,,False
393,to devise our approximation algorithm is the monotonicity,0,,False
394,"of the cost function C, namely, for any i, j and k with",0,,False
395,"0  i < j < k  m, we have C(S[i, j])  C(S[i, k]).",0,,False
396,In the following we first use the algorithm in [12] to ob-,0,,False
397,277,0,,False
398,tain a solution which finds a (1 + )-approximation in time,0,,False
399,O(m log1+,0,,False
400,U F,0,,False
401,"),",0,,False
402,where,0,,False
403,U,0,,False
404,is,0,,False
405,the,0,,False
406,cost,0,,False
407,in,0,,False
408,bits,0,,False
409,of,0,,False
410,representing,0,,False
411,"S as a single partition. Then, we improve the algorithm to",0,,False
412,obtain a linear time solution with the same approximation,0,,False
413,"guarantees. Following [12], it is convenient to recast our",0,,False
414,optimization problem to the problem of finding a shortest,0,,False
415,path in a particular directed acyclic graph (DAG) G. Given,0,,False
416,"the sequence S of m integers, the graph G has a vertex",0,,False
417,"v0, v1, . . . , vm-1 for each position of S plus a dummy vertex vm marking the end of the sequence. The DAG G is complete in the sense that, for any i and j with i < j  m, there",0,,False
418,"exists the edge from vi to vj, denoted as (vi, vj). Notice",0,,False
419,that there is a one-to-one correspondence between paths,0,,False
420,"from v0 to vm in G and partitions of S. Indeed, a path  ,"" (v0, vi1 )(vi1 , vi2 ) . . . (vik-1 , vim ) crossing k edges corresponds to the partition S[0, i1-1] S[i1, i2-1] . . . S[ik-1, m-1] of k chunks. Hence, by assigning the weight w(vi, vj) "","" C(S[i, j - 1]) to each edge (vi, vj), the weight of a path is""",0,,False
421,"equal to the cost in bits of the corresponding partition. Thus,",0,,False
422,a shortest path on G corresponds to an optimal partition of S.,0,,False
423,Computing a shortest path on a DAG has a time complexity,0,,False
424,proportional to the number of edges in the DAG. This is,0,,False
425,done with a classical elegant algorithm which processes the,0,,False
426,vertices from left to right [7]. The goal is to compute the,0,,False
427,value M [v] for each vertex v which is equal to the cost of,0,,False
428,"a shortest path which starts at v0 and ends at v. Initially, M [v0] is set to 0, while M [v] is set to + for any other vertex v. When the algorithm reaches the vertex v in its",0,,False
429,"left-to-right scan, it assumes that M [v] has been already",1,ad,True
430,correctly computed and extends this shortest path with any,0,,False
431,edge outgoing from v. This is done by visiting each edge,0,,False
432,"(v, v ) outgoing from v and by computing M [v] + w(v, v ).",0,,False
433,"If this quantity is smaller than M [v ], the path that follows",0,,False
434,"the shortest path from v0 to v and then the edge (v, v ) is currently the best way to reach v . Thus, M [v ] is updated",0,,False
435,"to M [v] + w(v, v ). The correctness of this algorithm can be",0,,False
436,"proved by induction and, since each edge is relaxed exactly",0,,False
437,"once, its time complexity is proportional to the number of",0,,False
438,edges in the DAG.,0,,False
439,"Unfortunately our DAG G is complete and, thus, it has (n2) edges, so this algorithm by itself does not suffice to",0,,False
440,"obtain an efficient solution for our problem. However, it",0,,False
441,can be used as the last step of a solution which performs,0,,False
442,a non-trivial pruning of G. This pruning produces another,0,,False
443,DAG G with two crucial properties: i) its number of edges,0,,False
444,is substantially reduced from (n2) to O(m log1+,0,,False
445,U F,0,,False
446,"),",0,,False
447,for,0,,False
448,"any given  (0, 1); ii) its shortest path distance is (almost)",0,,False
449,preserved since it increases by no more than a factor 1 + .,0,,False
450,The pruned graph G is constructed as the subgraph of G,0,,False
451,"consisting of all the edges (vi, vj) such that at least one of",0,,False
452,"the following two conditions holds: i) there exists an integer h  0 such that w(vi, vj)  F (1 + )h < w(vi, vj+1); ii) (vi, vj) is the last outgoing edge from vi (i.e., j , m).",0,,False
453,"Since w is monotone, these conditions correspond of keep-",0,,False
454,"ing, for each integer h, the edge of G that better approximates the value F (1 + )h from below. The edges of G are called",0,,False
455,"(1 + )-maximal edges. We point out that, since there exist at",0,,False
456,most log1+,0,,False
457,U F,0,,False
458,"possible values for h, each vertex of G",0,,False
459,has at,0,,False
460,most log1+,0,,False
461,U F,0,,False
462,outgoing (1 +,0,,False
463,")-maximal edges. Thus, the to-",0,,False
464,tal size of G,0,,False
465,is O(m log1+,0,,False
466,U F,0,,False
467,).,0,,False
468,Theorem,0,,False
469,3,0,,False
470,in,0,,False
471,[12],0,,False
472,proves,0,,False
473,that,0,,False
474,the shortest path distance on G is at most 1 + times larger,0,,False
475,"than the one in G. Thus, given G , a (1 + )-approximated",0,,False
476,partition can be computed in O(m log1+,0,,False
477,U F,0,,False
478,),0,,False
479,time,0,,False
480,with,0,,False
481,the,0,,False
482,above algorithm.,0,,False
483,We show now how to further reduce this time complexity,0,,False
484,"to O(m log1+ 1 ) time without altering the approximation guarantees. Let 1  (0, 1] and 2  (0, 1] be two parameters to be fixed later. We first obtain the graph G¯ from G by",0,,False
485,"keeping only edges whose weight is no more than L , F + 2F 1",0,,False
486,"plus the first edge outgoing from every vertex whose cost is larger than L. Then, we apply the pruning above to G¯ by",0,,False
487,fixing the approximation parameter to 2. The only difference,0,,False
488,here is that we force the pruning to retain the m edges in G¯ of,0,,False
489,cost larger than L. In this way we obtain a graph G¯ 2 having,0,,False
490,O(m log1+ 2,0,,False
491,L F,0,,False
492,),0,,False
493,",",0,,False
494,O(m log1+,0,,False
495,2,0,,False
496,1 ) edges. We can prove that,0,,False
497,1,0,,False
498,the shortest path distance in G¯ 2 is at most (1 + 1)(1 + 2),0,,False
499,times larger than the one in G. This implies that the partition,0,,False
500,computed with G¯ is a (1 + )-approximation of the optimal,0,,False
501,"one, by setting 1 , 2 , 3 so that (1 + 1)(1 + 2)  1 + . This result is stated in the following lemma.",0,,False
502,"Lemma 1. For any 1 > 0 and 2 > 0, the shortest path distance in G¯ 2 is at most (1 + 1)(1 + 2) times larger than the one in G.",0,,False
503,"Proof. Let G, G¯ and G¯ 2 denote the shortest paths in G, G¯ and G¯ 2 , respectively. We know that the weight w(G¯ 2 ) of G¯ 2 satisfies w(G¯ 2 )  (1 + 2)w(G¯). It remains to prove that w(G¯)  (1 + 1)w(G) which allows us to conclude that",0,,False
504,w(G¯ 2 )  (1 + 1)(1 + 2)w(G ). We do so by showing that there exists a path  in G¯ such,0,,False
505,that its weight is no more than (1 + 1) times the weight of,0,,False
506,"the shortest path G of G. The thesis follows immediately because G¯ is a shortest path, so by definition w(G¯)  w( ).",0,,False
507,The path  is obtained by transforming G so that its edges are all contained in G¯. Note that this transformation is,0,,False
508,not actually performed by the algorithm but it only serves,0,,False
509,for proving the lemma.,0,,False
510,This transformation is done as follows. For each edge,0,,False
511,"(ui, vj) in G¯, either w(vi, vj)  L, so there is nothing to do, or w(vi, vj) > L, in which case we need to substitute it with a subpath from vi to vj whose edges are all in G¯. This subpath can be found greedily, starting from vi and traversing always the longest edge until we reach vj. It can be proved that the weighting function w satisfies w(vi, vk) + w(vk, vj)  w(vi, vj) + F + 1 for any 0  i < k < j  m; intuitively, this",0,,False
512,means that by breaking an edge into two shorter edges we,0,,False
513,lose at most F + 1 bits. By combining these properties with,0,,False
514,the fact that all the edges in the subpath except possibly,0,,False
515,"the last have cost at least L, it follows that the number of",0,,False
516,edges,0,,False
517,in,0,,False
518,this,0,,False
519,subpath,0,,False
520,cannot,0,,False
521,be,0,,False
522,larger,0,,False
523,than,0,,False
524,"w(vi,vj )-F L-F",0,,False
525,+1,0,,False
526,"and its cost is at most w(vi, vj) +",0,,False
527,"w(vi,vj )-F L-F",0,,False
528,+1,0,,False
529,(F + 1) ,0,,False
530,"w(vi, vj) + 1w(vi, vj), thus proving the thesis.",0,,False
531,"It remains to describe how to generate the pruned graph G¯ 2 in O(n log1+ 1 ) time directly without explicitly constructing G which, otherwise, would require quadratic time. This is done by keeping k ,"" O(log1+ 1 ) windows W0, . . . , Wk sliding over the sequence S, one for each possible exponent h such that F  F (1 + )h  L. These sliding windows cover potentially different portions of S that start at the same position i but have different ending positions. Armed with""",1,ad,True
532,"these sliding windows, we generate the (1 + )-maximal edges",0,,False
533,outgoing from any vertex vi on-the-fly as soon as the shortest,0,,False
534,"path algorithm visits this vertex. Initially, each sliding win-",0,,False
535,"dow Wj starts and ends at position 0. During the execution,",0,,False
536,278,0,,False
537,"every time the shortest path algorithm visits the next vertex vi, we advance the starting position of each Wj by one position and its ending position until the cost of representing the currently covered portion of S is larger than F (1 + )j. It is easy to prove that if at the end of these moves the window Wj covers S[i, r], then (vi, vr) is the (1 + )-maximal edge outgoing from the vertex vi for the weight bound F (1 + )j. Notice that with this approach we generate all the maximal edges of G¯ 2 by performing a scan of S for each sliding window. Every time we move the starting or the ending position of a window we need to evaluate the cost of representing its covered portion of S. This can be done in constant time with simple arithmetic operations. Thus, it follows that generating the pruned graph requires constant time per edge, hence O(n log1+ 1 ) time overall.",1,ad,True
538,"We conclude the section by describing how to modify the first-level data structure to support arbitrary partitions: together with the first-level sequence L with the last element of each block, we write a second sequence E which contains the positions of the endpoints of the partition. This sequence can be again represented with Elias-Fano. The NextGEQ operation can be supported as before, while for Access(i) we can find the chunk of i with NextGEQ on E. Both L and E have as many elements as the number of the chunks in the partition.",0,,False
539,5. EXPERIMENTAL ANALYSIS,0,,False
540,We performed our experiments on the following datasets.,0,,False
541,"· ClueWeb09 is the ClueWeb 2009 TREC Category B test collection, consisting of 50 million English web pages crawled between January and February 2009.",1,ClueWeb,True
542,"· Gov2 is the TREC 2004 Terabyte Track test collection, consisting of 25 million .gov sites crawled in early 2004; the documents are truncated to 256 kB.",1,Gov,True
543,Documents Terms Postings,0,,False
544,Gov2,1,Gov,True
545,"24, 622, 347 35, 636, 425 5, 742, 630, 292",0,,False
546,ClueWeb09,1,ClueWeb,True
547,"50, 131, 015 92, 094, 694 15, 857, 983, 641",0,,False
548,Table 1: Basic statistics for the test collections,0,,False
549,"For each document in the collection the body text was extracted using Apache Tika2, and the words lowercased and stemmed using the Porter2 stemmer; no stopwords were removed. The docIds were assigned according to the lexicographic order of their URLs [20]. Table 1 reports the basic statistics for the two collections.",0,,False
550,Indexes tested. We compare three versions of Elias-Fano,0,,False
551,"indexes, namely EF single, EF uniform, and EF -optimal, that are respectively the original single-partition representation, a partitioned representation with uniform partitions, and a variable-length partitioned representation optimized with the algorithm of Section 4.2. The implementation of the base Elias-Fano sequences is mostly faithful to the original description and source code [23].",0,,False
552,"To validate Elias-Fano indexes against the more widespread block-based indexes, we tested three more indexes, namely",1,ad,True
553,2http://tika.apache.org/,0,,False
554,"Interpolative, OptPFD, and Varint-G8IU, which are representative of best compression ratio, best compression ratio/processing speed trade-off, and highest speed in the literature [15, 21]. For the last two use the code made available by the authors of [15]. Actually, recent experiments [15] show that there exist methods faster than Varint-G8IU by roughly 50% in sequential decoding. However, they require very large blocks (from 211 to 216) making block decoding prohibitively expensive if the lists are sparsely accessed.",1,ad,True
555,"For these three indexes we encoded the lists in blocks of 128 postings; we keep in a separate array the maximum docId of each block to perform fast skipping through linear search (we experimented with falling back to binary search after a small lookahead, but got worse results). Blocks of postings and blocks of frequencies are interleaved, and the frequencies blocks are decoded lazily as needed. The last block of each list is encoded with variable bytes if it is smaller than 128 postings to avoid any block padding overhead.",1,ad,True
556,"All the implementations of posting lists expose the same interface, namely the Access, NextGEQ, and Next operations described in Section 4. The query algorithms are C++ templates specialized for each posting list implementation to avoid the virtual method call overhead, which can be significant for operations that take just a handful of CPU cycles. For the same reason, we made sure that frequent code paths are inlined in the query processing code.",1,ad,True
557,Testing details. All the algorithms were implemented in,0,,False
558,"C++11 and compiled with GCC 4.9 with the highest optimization settings. We do not use any SIMD instructions or special processor features, except for the instructions to count the 1 bits in a word and to find the position of the least significant bit; both are available in modern x86-64 CPUs and exposed by the compiler through portable builtins. Apart from this, all the code is standard C++11. The tests were performed on a machine with 24 Intel Xeon E5-2697 Ivy Bridge cores (48 threads) clocked at 2.70Ghz, with 64GiB RAM, running Linux 3.12.7.",1,ad,True
559,"The data structures were saved to disk after construction, and memory-mapped to perform the queries. Before timing the queries we ensure that the index is fully loaded in memory.",1,ad,True
560,The source code is available at http://github.com/ot/ partitioned_elias_fano/tree/sigir14 for the reader interested in replicating the experiments.,1,ad,True
561,5.1 Space and construction time,0,,False
562,"Before comparing the spaces obtained with the different indexes, we have to set the parameters needed by the partitioned EF indexes, namely the chunk size for EF uniform and the approximation parameters 1, 2 for EF -optimal.",0,,False
563,"For the former, we show in Figure 1 the space obtained by EF uniform on Gov2 for different values of the chunk size. The minimum space is obtained at 128, which is also a widely used block size for block-based indexes; in all the following experiments we will use this chunk size.",1,Gov,True
564,"A little more care has to be put in choosing the parameters 1 and 2 since they significantly affect the construction time, as shown in Figure 2. First we fix 1 at 0, thus posing no upper bound on the chunk costs, and let 2 vary. Notice that the (1 + 2) approximation bound is very pessimistic: even setting 2 as high as 0.5, meaning a potential 50% overhead, the actual overhead is never higher than 1.5%. Hence, we set 2 , 0.3 to control the construction time.",1,ad,True
565,279,0,,False
566,EF single EF uniform EF -optimal,0,,False
567,Interpolative OptPFD Varint-G8IU,0,,False
568,Gov2,1,Gov,True
569,space,0,,False
570,doc,0,,False
571,freq,0,,False
572,GB,0,,False
573,bpi,0,,False
574,bpi,0,,False
575,7.66 (+64.7%) 5.17 (+11.2%) 4.65,0,,False
576,7.53 (+83.4%) 3.14 (+32.4%),0,,False
577,4.63 (+12.9%) 2.58 (+8.4%),0,,False
578,4.10,0,,False
579,2.38,0,,False
580,4.57 (-1.8%) 4.03 (-1.8%) 2.33 (-1.8%) 5.22 (+12.3%) 4.72 (+15.1%) 2.55 (+7.4%) 14.06 (+202.2%) 10.60 (+158.2%) 8.98 (+278.3%),0,,False
581,ClueWeb09,1,ClueWeb,True
582,space,0,,False
583,doc,0,,False
584,freq,0,,False
585,GB,0,,False
586,bpi,0,,False
587,bpi,0,,False
588,19.63 (+23.1%) 17.78 (+11.5%) 15.94,0,,False
589,7.46 (+27.7%) 2.44 (+11.0%),0,,False
590,6.58 (+12.6%) 2.39 (+8.8%),0,,False
591,5.85,0,,False
592,2.20,0,,False
593,14.62 (-8.3%) 5.33 (-8.8%) 2.04 (-7.1%) 17.80 (+11.6%) 6.42 (+9.8%) 2.56 (+16.4%) 39.59 (+148.3%) 10.99 (+88.1%) 8.98 (+308.8%),0,,False
594,"Table 2: Overall space in gigabytes, and average bits per docId and frequency",0,,False
595,8.00 7.50 7.00 6.50 6.00 5.50 5.00 4.50,0,,False
596,32,0,,False
597,EF single EF uniform EF -opt,0,,False
598,64,0,,False
599,128,0,,False
600,256,0,,False
601,512,0,,False
602,1024,0,,False
603,Figure 1: Index size in gigabytes for Gov2 with EF uniform at different chunk sizes,1,Gov,True
604,"After fixing 2, we let 1 vary. Notice the sharp drop in running time without a noticeable increase in space as soon",0,,False
605,"as 1 is non-zero: it is a direct consequence of the algorithm going from O(m log m)-time to O(m)-time. Again, the spread between the worse and best solutions found is smaller than 1%. In the following, we set 1 ,"" 0.03. We found that with these parameters, the average chunk length on Gov2 for docId sequences is 231 and for frequencies 466. On ClueWeb09 they are respectively 142 and 512. For brevity we omit the plots for ClueWeb09, which are very similar to the ones for Gov2.""",1,ad,True
606,4.66 4.65 4.64 4.63 4.62 4.61 4.60 4.59,0,,False
607,0.0,0,,False
608,4.85,0,,False
609,4.80,0,,False
610,4.75,0,,False
611,4.70,0,,False
612,4.65,0,,False
613,4.60 0.00,0,,False
614,0.1,0,,False
615,0.2,0,,False
616,0.3,0,,False
617,0.4,0,,False
618,"(a) 1 ,"" 0, varying 2 from 0.025 to 0.5""",0,,False
619,0.02,0,,False
620,0.04,0,,False
621,0.06,0,,False
622,0.08,0,,False
623,"(b) 2 ,"" 0.3, varying 1 from 0 to 0.1""",0,,False
624,3500 3000 2500 2000 1500 1000 500 0 0.5,0,,False
625,350 300 250 200 150 100 50 0.10,0,,False
626,"Figure 2: Influence of the parameters 1 and 2 on the EF -optimal indexes for Gov2. Solid line is the overall size in gigabytes (left scale), dashed line is",1,Gov,True
627,the construction time in minutes (right scale).,0,,False
628,"Table 2 shows the index space, both as overall size in gigabytes and broken down in bits per integers for docIds and frequencies. Next to each value is shown the relative loss/gain (in percentage) compared to EF -optimal. The results confirm that partitioning the indexes indeed pays off: compared to EF -optimal, EF single is 64.7% larger on Gov2 and 23.1% larger on ClueWeb09. The optimization strategy also produces significant savings: EF uniform is about 11% larger on both Gov2 and ClueWeb09, but still significantly smaller than EF single.",1,Gov,True
629,"Compared to the other indexes, Varint-G8IU is by far the largest, 2.5 to 3 times larger than EF -optimal; it is particularly inefficient on the frequencies, as it needs at least 8 bits to encode an integer. On the other end of the spectrum, Interpolative confirms its high compression ratio and produces the smallest indexes, but the edge with EF -optimal is surprisingly small: only 1.8% on Gov2 and 8.3% on ClueWeb09. To conclude the comparison, we observe that OptPFD loses more than 10% w.r.t. EF -optimal: 12.3% on Gov2 and 11.6% on ClueWeb09. Since, as we will show in the following, EF -optimal is also faster than OptPFD, this implies that our solution dominates OptPFD on the trade-off curve.",1,Gov,True
630,"Regarding construction time, for all the indexes except EF -optimal, Gov2 can be processed on a single thread in 8 to 10 minutes, while ClueWeb09 in 24 to 30 minutes; in both cases the construction is essentially I/O-bound. For EF -optimal, instead, the algorithm that computes the optimal partition, despite linear-time, has a noticeable CPU cost, raising the time for Gov2 to 95 minutes and for ClueWeb09 to 284 minutes. However, since the encoding of each list can be performed independently, using all the 24 cores of the test machine makes EF -optimal construction I/O-bound as well. Parallelization does not improve the construction time of the other encoders.",1,Gov,True
631,5.2 Query processing,1,Query,True
632,"To evaluate the speed of query processing we randomly sampled two sets of 1000 queries respectively from TREC 2005 and 2006 Efficiency Track topics, drawing only queries whose terms are all in the collection dictionary. The two dataset have quite different statistics, as will be apparent in the results.",1,TREC,True
633,"In his experimental analysis, Vigna [23] provides some examples showing that Elias-Fano indexes are particularly efficient in conjunctive queries that have sparse results. To make the analysis more systematic, we define as selective any query such that the fraction of the documents that contain all its terms over those that contain at least one of them is small (we set this threshold to 0.5%). For both datasets,",0,,False
634,280,0,,False
635,"selective queries among TREC 2005 queries are at least 58%, and among TREC 2006 queries at least 78%, hence making up the most part of the samples.",1,TREC,True
636,"The query times were measured by running each query set 3 times, and averaging the results. All the times are reported in milliseconds. In the timings tables, next to each timing is reported in parentheses the relative percentage against EF -optimal. Not very surprisingly, Interpolative is always 50% to 500% slower than the others, and Varint-G8IU is 10% to 40% faster, so for the sake of brevity we will focus the following analysis on the Elias-Fano indexes and OptPFD.",0,,False
637,Boolean queries. We first analyze the basic disjunctive,0,,False
638,"(OR) and conjunctive (AND) queries. Note that these queries do not need the term frequencies, so only the docId lists are accessed. For these types of operations, we measure the time needed to count the number of results matching the query.",0,,False
639,Gov2,1,Gov,True
640,ClueWeb09,1,ClueWeb,True
641,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
642,EF single,0,,False
643,80.7 (+8%) 175.0 (+10%) 261.0 (+0%) 444.0 (-2%),0,,False
644,EF uniform 72.1 (-3%) 154.0 (-3%) 254.0 (-3%) 435.0 (-4%),0,,False
645,EF -optimal 74.5,0,,False
646,159.0,0,,False
647,261.0,0,,False
648,451.0,0,,False
649,Interpolative 121.0 (+62%) 257.0 (+62%) 399.0 (+53%) 680.0 (+51%),0,,False
650,OptPFD,0,,False
651,69.5 (-7%) 148.0 (-7%) 235.0 (-10%) 398.0 (-12%),0,,False
652,Varint-G8IU 67.4 (-10%) 143.0 (-10%) 222.0 (-15%) 375.0 (-17%),0,,False
653,Table 3: Times for OR queries,0,,False
654,"Times for OR queries are reported in Table 3. Unsurprisingly, as OR needs to scan the whole lists, block-based indexes perform better than Elias-Fano indexes, since they are optimized for raw decoding speed. However, the edge is not as high as one could expect, ranging from 7% to 17%. In sequential decoding Varint-G8IU can be even double as fast as OptPFD [15], however in this task it is not even 10% faster. The reason can be most likely traced back to branch misprediction penalties: the cost of decoding an integer is in the order of 2-5 CPU cycles; at each decoded docId, the CPU has to decide whether it is equal to the current candidate docId, or if it must be considered as a candidate for the next docId. The resulting jump is basically unpredictable, and the branch misprediction penalty on modern CPUs can be as high as 10-20 cycles (specifically at least 15 for the CPU we used [13]), thus becoming the main bottleneck of query processing.",0,,False
655,"Among Elias-Fano indexes, EF -optimal and EF uniform are either negligibly slower or slightly faster than EF single; we believe that the additional complexity is balanced by the higher memory throughput caused by the smaller sizes.",1,ad,True
656,"Table 4 reports the times for AND queries. Again, EF -optimal is competitive with EF single, except for selective queries where the overhead is slightly higher, touching 14%. EF uniform is slightly slower, which is likely caused by the smaller chunk sizes compared to EF -optimal. This will also be the case in the other queries. Compared to OptPFD, EF -optimal is 14% to 26% faster in all cases on general queries. The gap becomes even higher for selective queries, ranging from 34% to 40%, confirming the observations made in [23].",1,ad,True
657,Ranked queries. In order to analyze the impact of accessing,0,,False
658,"the frequencies in query time, we measured the time required to find the top-10 results for AND and WAND [3] queries",0,,False
659,Gov2,1,Gov,True
660,ClueWeb09,1,ClueWeb,True
661,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
662,EF single,0,,False
663,2.1 (+10%) 4.7 (+1%) 13.6 (-5%) 15.8 (-9%),0,,False
664,EF uniform 2.1 (+9%) 5.1 (+10%) 15.5 (+8%) 18.9 (+9%),0,,False
665,EF -optimal 1.9,0,,False
666,4.6,0,,False
667,14.3,0,,False
668,17.4,0,,False
669,Interpolative 7.5 (+291%) 20.4 (+343%) 55.7 (+289%) 76.5 (+341%),0,,False
670,OptPFD,0,,False
671,2.2 (+14%) 5.7 (+24%) 16.6 (+16%) 21.9 (+26%),0,,False
672,Varint-G8IU 1.5 (-20%) 4.0 (-13%) 11.1 (-23%) 14.8 (-15%),0,,False
673,(a) All queries,0,,False
674,Gov2,1,Gov,True
675,ClueWeb09,1,ClueWeb,True
676,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
677,EF single,0,,False
678,1.1 (-11%) 2.5 (-9%) 9.2 (-14%) 11.1 (-13%),0,,False
679,EF uniform 1.3 (+8%) 3.0 (+11%) 11.3 (+6%) 13.0 (+2%),0,,False
680,EF -optimal 1.2,0,,False
681,2.7,0,,False
682,10.7,0,,False
683,12.7,0,,False
684,Interpolative 6.0 (+399%) 14.3 (+430%) 49.9 (+368%) 61.0 (+379%),0,,False
685,OptPFD,0,,False
686,1.6 (+34%) 3.8 (+40%) 13.0 (+22%) 17.0 (+33%),0,,False
687,Varint-G8IU 1.1 (-11%) 2.5 (-6%) 8.8 (-18%) 11.3 (-12%),0,,False
688,(b) Selective queries,0,,False
689,Table 4: Times for AND queries,0,,False
690,"using BM25 [18] scoring. Results for scored AND, reported in Table 5, and for",0,,False
691,"WAND, reported in Table 6, are actually very similar. As before, we note that the overhead of EF -optimal against EF single is small, ranging between 2% and 13% for all queries, and between 8% and 18% for selective queries. Also as before, EF uniform is about 10% slower than EF -optimal; this is likely caused by the optimal partitioning algorithm placing chunk endpoints around dense clusters of docId, hence making the query algorithms crossing fewer chunk boundaries. Compared to OptPFD, EF -optimal is slightly slower on Gov2 and slightly faster on the larger ClueWeb09 on all queries. On selective queries, however, it is never slower, and up to 23% faster, thus providing further evidence that Elias-Fano indexes benefit significantly from selectiveness, even for non-conjunctive queries.",1,ad,True
692,Gov2,1,Gov,True
693,ClueWeb09,1,ClueWeb,True
694,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
695,EF single EF uniform EF -optimal,0,,False
696,4.0 (-2%) 8.4 (-7%) 22.8 (-9%) 24.6 (-13%),0,,False
697,4.4 (+7%) 9.8 (+8%) 27.3 (+9%) 31.0 (+9%),0,,False
698,4.1,0,,False
699,9.0,0,,False
700,25.1,0,,False
701,28.4,0,,False
702,Interpolative 14.1 (+242%) 38.6 (+327%) 99.1 (+295%) 132.0 (+365%),0,,False
703,OptPFD,0,,False
704,3.9 (-7%) 9.2 (+1%) 25.8 (+3%) 31.6 (+11%),0,,False
705,Varint-G8IU 2.6 (-38%) 5.5 (-39%) 15.8 (-37%) 18.0 (-37%),0,,False
706,(a) All queries,0,,False
707,Gov2,1,Gov,True
708,ClueWeb09,1,ClueWeb,True
709,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
710,EF single EF uniform EF -optimal,0,,False
711,1.7 (-16%) 2.1 (+7%) 2.0,0,,False
712,4.1 (-14%) 12.5 (-18%) 16.2 (-17%),0,,False
713,5.2 (+9%) 16.3 (+7%) 21.1 (+8%),0,,False
714,4.8,0,,False
715,15.2,0,,False
716,19.4,0,,False
717,Interpolative 10.2 (+412%) 25.9 (+439%) 80.7 (+430%) 99.7 (+412%),0,,False
718,OptPFD,0,,False
719,2.3 (+18%) 5.7 (+18%) 18.8 (+23%) 23.1 (+19%),0,,False
720,Varint-G8IU 1.4 (-32%) 3.3 (-32%) 10.6 (-30%) 13.6 (-30%),0,,False
721,(b) Selective queries,0,,False
722,Table 5: Times for AND top-10 BM25 queries,0,,False
723,281,0,,False
724,Gov2,1,Gov,True
725,ClueWeb09,1,ClueWeb,True
726,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
727,EF single EF uniform EF -optimal,0,,False
728,8.8 (-4%) 15.8 (-7%),0,,False
729,9.7 (+6%) 18.2 (+7%),0,,False
730,9.2,0,,False
731,17.1,0,,False
732,31.5 (-7%) 41.2 (-13%),0,,False
733,36.9 (+9%) 51.2 (+8%),0,,False
734,34.0,0,,False
735,47.4,0,,False
736,Interpolative 28.0 (+203%) 62.6 (+267%) 123.0 (+262%) 200.0 (+322%),0,,False
737,OptPFD,0,,False
738,8.7 (-6%) 16.7 (-2%) 35.6 (+5%) 52.1 (+10%),0,,False
739,Varint-G8IU 6.1 (-34%) 11.1 (-35%) 24.0 (-30%) 34.3 (-28%),0,,False
740,(a) All queries,0,,False
741,Gov2,1,Gov,True
742,ClueWeb09,1,ClueWeb,True
743,TREC 05 TREC 06 TREC 05 TREC 06,1,TREC,True
744,EF single EF uniform EF -optimal,0,,False
745,8.5 (-8%) 12.2 (-9%),0,,False
746,9.8 (+6%) 14.4 (+7%),0,,False
747,9.2,0,,False
748,13.5,0,,False
749,21.0 (-19%) 34.2 (-15%),0,,False
750,27.3 (+6%) 43.0 (+7%),0,,False
751,25.8,0,,False
752,40.1,0,,False
753,Interpolative 33.8 (+265%) 54.7 (+307%) 115.0 (+345%) 179.0 (+346%),0,,False
754,OptPFD,0,,False
755,9.3 (+0%) 14.1 (+4%) 29.9 (+16%) 45.7 (+14%),0,,False
756,Varint-G8IU 6.3 (-32%) 9.2 (-32%) 19.2 (-26%) 30.0 (-25%),0,,False
757,(b) Selective queries,0,,False
758,Table 6: Times for WAND top-10 BM25 queries,0,,False
759,6. CONCLUSION AND FUTURE WORK,0,,False
760,"We introduced two new index representations, EF uniform and EF -optimal, which significantly improve the compression ratio of Elias-Fano indexes at a small query performance cost. EF -optimal is always convenient except when construction time is an issue, in which case EF uniform offers a  12% worse compression ratio without this additional construction overhead. Furthermore, EF -optimal offers a better spacetime trade-off than the state-of-the-art OptPFD.",1,ad,True
761,Future work will focus on making partitioned Elias-Fano indexes even faster; in particular it may be worth exploring the different space-time trade-offs that can be obtained by varying the average chunk size. It would also be interesting to devise faster algorithms to compute optimal partitions preserving the same approximation guarantees.,1,ad,True
762,Acknowledgements,0,,False
763,"This work was supported by Midas EU Project (318786), by MIUR of Italy project PRIN ARS Technomedia 2012 and by eCloud EU Project (325091).",0,,False
764,"We would like to thank Sebastiano Vigna for sharing with us his C++ implementation of Elias-Fano indexes, which we used to validate our implementation.",0,,False
765,7. REFERENCES,0,,False
766,"[1] V. N. Anh and A. Moffat. Inverted index compression using word-aligned binary codes. Inf. Retr., 8(1), 2005.",0,,False
767,"[2] V. N. Anh and A. Moffat. Index compression using 64-bit words. Softw., Pract. Exper., 40(2):131­147, 2010.",0,,False
768,"[3] A. Z. Broder, D. Carmel, M. Herscovici, A. Soffer, and J. Y. Zien. Efficient query evaluation using a two-level retrieval process. In CIKM, pages 426­434, 2003.",0,,False
769,"[4] A. Buchsbaum, G. Fowler, and R. Giancarlo. Improving table compression with combinatorial optimization. Journal of the ACM, 50(6):825­851, 2003.",0,,False
770,"[5] S. Bu¨ttcher and C. L. A. Clarke. Index compression is good, especially for random access. In CIKM, 2007.",0,,False
771,"[6] S. Bu¨ttcher, C. L. A. Clarke, and G. V. Cormack. Information retrieval: implementing and evaluating search engines. MIT Press, Cambridge, Mass., 2010.",0,,False
772,"[7] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms. The MIT Press, 2009.",0,,False
773,"[8] M. Curtiss and et al. Unicorn: A system for searching the social graph. VLDB, 6(11):1150­1161, Aug. 2013.",0,,False
774,"[9] R. Delbru, S. Campinas, and G. Tummarello. Searching web data: An entity retrieval and high-performance indexing model. J. Web Sem., 10:33­58, 2012.",0,,False
775,"[10] P. Elias. Efficient storage and retrieval by content and address of static files. J. ACM, 21(2):246­260, 1974.",1,ad,True
776,"[11] R. M. Fano. On the number of bits required to implement an associative memory. Memorandum 61, Computer Structures Group, MIT, Cambridge, MA, 1971.",0,,False
777,"[12] P. Ferragina, I. Nitto, and R. Venturini. On optimally partitioning a text to improve its compression. Algorithmica, 61(1):51­74, 2011.",0,,False
778,"[13] A. Fog. The microarchitecture of Intel, AMD and VIA CPUs. http: //www.agner.org/optimize/microarchitecture.pdf.",0,,False
779,"[14] J. Goldstein, R. Ramakrishnan, and U. Shaft. Compressing relations and indexes. In ICDE, 1998.",0,,False
780,"[15] D. Lemire and L. Boytsov. Decoding billions of integers per second through vectorization. Software: Practice & Experience, 2013.",0,,False
781,"[16] C. D. Manning, P. Raghavan, and H. Schu¨lze. Introduction to Information Retrieval. Cambridge University Press, 2008.",0,,False
782,"[17] A. Moffat and L. Stuiver. Binary interpolative coding for effective index compression. Inf. Retr., 3(1), 2000.",0,,False
783,"[18] S. E. Robertson and K. S. Jones. Relevance weighting of search terms. Journal of the American Society for Information science, 27(3):129­146, 1976.",0,,False
784,"[19] D. Salomon. Variable-length Codes for Data Compression. Springer, 2007.",0,,False
785,"[20] F. Silvestri. Sorting out the document identifier assignment problem. In ECIR, pages 101­112, 2007.",0,,False
786,"[21] F. Silvestri and R. Venturini. VSEncoding: Efficient coding and fast decoding of integer lists via dynamic programming. In CIKM, pages 1219­1228, 2010.",0,,False
787,"[22] A. A. Stepanov, A. R. Gangolli, D. E. Rose, R. J. Ernst, and P. S. Oberoi. Simd-based decoding of posting lists. In CIKM, pages 317­326, 2011.",0,,False
788,"[23] S. Vigna. Quasi-succinct indices. In WSDM, 2013. [24] I. H. Witten, A. Moffat, and T. C. Bell. Managing",0,,False
789,"gigabytes (2nd ed.): compressing and indexing documents and images. Morgan Kaufmann Publishers Inc., 1999. [25] H. Yan, S. Ding, and T. Suel. Compressing term positions in web indexes. In SIGIR, pages 147­154, 2009. [26] H. Yan, S. Ding, and T. Suel. Inverted index compression and query processing with optimized document ordering. In WWW, pages 401­410, 2009. [27] J. Zobel and A. Moffat. Inverted files for text search engines. ACM Comput. Surv., 38(2), 2006. [28] M. Zukowski, S. Heman, N. Nes, and P. Boncz. Super-scalar RAM-CPU cache compression. In ICDE, 2006.",0,,False
790,282,0,,False
791,,0,,False
