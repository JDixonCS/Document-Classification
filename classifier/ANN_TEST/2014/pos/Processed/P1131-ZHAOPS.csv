,sentence,label,data,regex
0,An Enhanced Context-sensitive Proximity Model for Probabilistic Information Retrieval,0,,False
1,"Jiashu Zhao1, Jimmy Xiangji Huang2",0,,False
2,"Information Retrieval and Knowledge Management Research Lab 1Department of Computer Science & Engineering, 2School of Information Technology",0,,False
3,"York University, Toronto, Canada",1,ad,True
4,"1jessie@cse.yorku.ca, 2jhuang@yorku.ca",0,,False
5,ABSTRACT,0,,False
6,"We propose to enhance proximity-based probabilistic retrieval models with more contextual information. A term pair with higher contextual relevance of term proximity is assigned a higher weight. Several measures are proposed to estimate the contextual relevance of term proximity1. We assume the top ranked documents from a basic weighting model are more relevant to the query, and calculate the contextual relevance of term proximity using the top ranked documents. We propose a context-sensitive2 proximity model, and the experimental results on standard TREC data sets show the effectiveness of our proposed model.",1,TREC,True
7,Keywords,0,,False
8,"Context-Sensitive IR, Measure, Proximity, Probabilistic Model",0,,False
9,1. INTRODUCTION AND MOTIVATION,1,DUC,True
10,"The study of how to integrate the context information of queries and documents into retrieval process draw a lot of attention in recent years [3]. More specifically, many term proximity approaches [2, 9, 10, 11], which reward the documents where the query terms occurring closer to each other, show significant improvements over basic Information Retrieval (IR) models. In these proximity-based approaches, all the query term pairs are usually treated equally and the difference among various query pairs are not considered, although there is a need to distinguish the importance of term proximities. For example, given a query ""recycle automobile tires"", there is a stronger association between ""automobile"" and ""tire"" than the association between ""recycle"" and ""automobile"". In the top ranked documents, ""automobile"" and ""tire"" are expected to occur close to each other, while ""recycle"" and ""automobile"" do not necessarily have to occur close.",0,,False
11,"In this paper, we focus on the problem of differentiating the influence of associated query term pairs. We propose",0,,False
12,1The contextual relevance of term proximity is the relevancy between the query term proximity and the topic of the query. 2Context-sensitive means that the contextual relevance of term proximity is considered.,0,,False
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609527.",1,ad,True
14,"a proximity enhancement approach to integrate the contextual relevance of term proximity into the retrieval process. We also propose four measures for estimating the contextual relevance of term proximity, and reward the query term pairs according to both the proximity and the contextual relevance of proximity. There are several studies that boost proximity retrieval models. A machine learning method is proposed to determine the ""goodness"" of a span in [8]. [1] learns the concept importance from several sources (e.g. google n-gram corpus, query logs and wikipedia titles). SVM is used to learn different weights for various term dependencies in [6]. The importance of the global statistics is examined for proximity weighting [4]. Phrases are treated as providing a context for the component query terms in [7]. The contribution of this paper is that we propose the contextual relevance of term proximity, which represents to what extent the corresponding term pair should be related to the topic of the query. The contextual relevancy of term proximity is combined with the value of term proximity to characterize how much a document should be boosted.",1,wiki,True
15,"The remainder of this paper is organized as follows. In Section 2, we introduce four measures for estimating the contextual relevance of term proximity. In Section 3, we propose an enhanced context-sensitive proximity model using the proposed measures. Section 4 presents the experimental results and parameter sensitivities. Section 5 concludes the findings and discusses possible future directions.",0,,False
16,2. CONTEXTUAL RELEVANCE OF TERM,0,,False
17,PROXIMITY,0,,False
18,"In this section, we propose how to estimate the contextual relevance of term proximity. The contextual relevance of term proximity is defined as how much the corresponding term pair should be related to the topic of the query in the context. The notations used in this paper are shown as follows.",0,,False
19,"· Q ,"" {q1, ..., qm} is a query · D is a relevant document · tf (qi, D) is the term frequency of qi in D · {pos1,i, pos2,i, ..., postfi,i} are the positions of qi in the""",0,,False
20,"document D · dist(posk1,i, posk2,j ) is defined as dist(posk1,i, posk2,j ) ,",0,,False
21,"|posk1,i - posk2,j |, which is the distance between two positions.",0,,False
22,"We measure the contextual relevance of term proximity base on the assumption that distributions of qi and qj in a relevant documents can represent the association between qi and qj. If qi and qj occur closely in relevant documents,",0,,False
23,1131,0,,False
24,RelCoOccur RelSqRecip RelM inDist RelKernel,0,,False
25,"q1, q2 1.0000 0.2331 0.0486 1.3200",0,,False
26,"q1, q3 1.0000 0.0408 0.0009 0.7200",0,,False
27,"q1, q4 1.0000 0.0434 0.0025 0.7200",0,,False
28,"q1, q5 0.0000 0.0000 0.0000 0.0000",0,,False
29,"q2, q3 1.0000 0.0523 0.0067 0.7200",0,,False
30,"q2, q4 1.0000 0.0434 0.0025 0.7200",0,,False
31,"q2, q5 0.0000 0.0000 0.0000 0.0000",0,,False
32,"q3, q4 1.0000 1.0000 0.3133 0.4800",0,,False
33,"q3, q5 0.0000 0.0000 0.0000 0.0000",0,,False
34,Table 1: An example of the contextual relevance of term proximity,0,,False
35,"q4, q5 0.0000 0.0000 0.0000 0.0000",0,,False
36,"the contextual relevance of term proximity between qi and qj is high. On the contrary, if qi and qj do not co-occur or occur far away to each other, the contextual relevance of term proximity between qi and qj is low. Therefore we propose the following four methods for estimating the contextual relevance of term proximity between qi and qj in a relevant document D. For the extreme case when qi and qj do not co-occur in D, we consider the contextual relevance of term proximity equals 0. Otherwise, we define the following measures to generate a positive value for the contextual relevance of term proximity.",0,,False
37,"Definition 1. RelCoOccur(qi, qj , D) is defined to be 1, if qi and qj both occur in D.",0,,False
38,"RelCoOccur(qi, qj , D) , 1{qiDqj D}",0,,False
39,(1),0,,False
40,Definition 2. The RelSqRecip is defined as the sum of squared reciprocal distances between qi and qj.,0,,False
41,"tf (qi,D) tf (qj ,D)",0,,False
42,1,0,,False
43,"RelSqRecip(qi, qj , D) ,",0,,False
44,"k1 ,1",0,,False
45,"k2,""1 dist(posk1,i, posk2,j )2""",0,,False
46,(2),0,,False
47,Definition 3. The RelMinDist is a defined as the following function of the minimum distance between qi and qj.,0,,False
48,"RelMinDist(qi, qj , D) ,"" ln( + e-MinDist(qi,qj ,D)) (3)""",0,,False
49,"where  is a parameter, and M inDist(qi, qj, D) is the minimum distance between all co-occurring qi and qj in D.",0,,False
50,"M inDist(qi, qj, D) ,"" mink1{1..tf (qi,D)},k2{1..tf (qj ,D)}(dist(posk1,i, posk2,j ))""",0,,False
51,Definition 4. The RelKernel is defined as the sum of the kernel functions of distances between qi and qj.,0,,False
52,"RelKernel(qi, qj , D)",0,,False
53,"tf (qi,D) tf (qj ,D)",0,,False
54,1,0,,False
55,(4),0,,False
56,",",0,,False
57,"Kernel( 2 dist(posk1,i, posk2,j ))",0,,False
58,"k1,1 k2,1",0,,False
59,where Kernel(·) is kernel function. Here we use the triangle,0,,False
60,kernel function.,0,,False
61,K ernel(u),0,,False
62,",",0,,False
63,(1,0,,False
64,-,0,,False
65,u) ,0,,False
66,·,0,,False
67,1{u},0,,False
68,(5),0,,False
69,"where u is an input value, and  is the kernel parameter.",0,,False
70,"These functions measure the contextual relevance from different perspectives. RelCoOccur measures whether qi and qj are co-occurring in D. RelSqRecip, RelMinDist and RelKernel considers the positions of qi and qj in D. In RelSqRecip, we generate a squared reciprocal function for the distances between all the occurrences of qi and qj, and accumulate the values over D. Then the query term pairs with terms occurring closer to each other and/or occurring more frequently",0,,False
71,"will have higher contextual relevance. RelMinDist is modified from [9], where the minimum distance is shown to be more effective than the other distance-based and span-based proximity approaches. RelKernel utilizes the term proximity approach proposed in [10], where a query term is simulated by the kernel function, where the triangle kernel function is recognized to be the most effective. Different types of information are incorporated in these measures.",1,corpora,True
72,"To better analyze the contextual relevance measurements defined above, we present an example for a given query Q ,"" {q1, q2, q3, q4, q5} and a relevant document D.""",0,,False
73,"D , {xq1xq2xxxxq3q4xxxxxq1xq2}",0,,False
74,"where x represents a non-query term. By observing the query and the document, we find that the term q5 does not present in D, which means it does not related to D, and therefore do not have an association with other query terms. Since q3 and q4 are adjacent to each other and far apart from other query terms, q3 and q4 are more likely to have a stronger association than the combination of q2 and q4. We calculate the contextual relevance of term proximity between q2 and q4 as an instance, and the procedure will be the same for the rest of the query term pairs. The term frequency of terms q2 and q4 are tf (q2, D) ,"" 2 and tf (q4, D) "","" 1. The positions of q2 and q4 in D are pos(q2, D) "","" {4, 18} and pos(q4, D) "","" {10} correspondingly. Therefore there are 2 co-occurrences of q2 and q4, and the corresponding distances between these co-occurrences are {6, 8}. Then we can calculate Rel(q2, q4, D) with these distances by formulae (1-4). Table 1 shows the values of the contextual relevance of term proximity in this example.""",1,ad,True
75,"We can see that the contextual relevance measures defined above show different characteristics. RelCoOccur detects term pairs with or without an association. For example, q5 and other query terms do not have an association. The term pairs containing q5 are distinguished by RelCoOccur. On the other hand, RelCoOccur does not consider the term distributions in D. RelMinDist takes into account the closest occurrences between a pair of quay terms, and does not consider the frequency of occurrences. RelMinDist and RelKernel accumulates over all the occurrences of two query terms, with different functions and therefore generates different values.",0,,False
76,3. CONTEXT-SENSITIVE PROXIMITY MODEL,0,,False
77,"In this section, we propose a context-sensitive proximity retrieval model, by integrating the proposed measures for contextual relevance of term proximity into retrieval process. Naturally we treat the values of contextual relevance as weights to reward the query term pairs with higher contextual relevance and to penalize the query term pairs with lower contextual relevance. In practice, we assume the top ranked documents returned by a basic retrieval model (for example, BM25) are more relevant than the rest of the documents. The averaged contextual relevance of term proximity over the top ranked documents is multiplied by the proximity part in the weighting function. A general form of the",0,,False
78,1132,0,,False
79,context-sensitive proximity model is,0,,False
80,RelP rox(D ),0,,False
81,","" (1 - )  qi w(qi, D )""",0,,False
82,(6),0,,False
83,"+   qi,qj AR(qi, qj , topDoc)  P rox(qi, qj , D )",0,,False
84,"where D is a given document, w(qi, D ) is the weight of qi in D by a basic probabilistic weighting function, P rox(qi, qj, D ) is a bigram proximity weighting approach,  is a balancing parameter, topDoc is the number of top ranked documents, AR(qi, qj, topDoc) is the average contextual relevance value of term proximity between qi and qj over the top ranked documents",0,,False
85,"1 AR(qi, qj, topDoc) ,"" topDoc Rel(qi, qj, D) (7)""",0,,False
86,D,0,,False
87,"where Rel(qi, qj, D) is one of the measures defined in Section 2. Please note that AR(qi, qj, topDoc), P rox(qi, qj, D ) and w(qi, D ) need to be normalized to the same scale.",0,,False
88,"In formula (6), we use the probabilistic BM25 [5] as the basic weighting function. We adopt the proximity approach used in CRTER [10], since it is an effective pairwise proximity model for probabilistic IR. The BM25 weighting function has the following form.",1,ad,True
89,"w(qi, D )",0,,False
90,","" (k1 + 1)  tf (qi, D )  (k3 + 1)  qtf (qi)  log N - n(qi) + 0.5""",0,,False
91,"K + tf (qi, D )",0,,False
92,k3 + qtf (qi),0,,False
93,n(qi) + 0.5,0,,False
94,(8),0,,False
95,"where N is the number of documents in the collection, n(qi) is the number of documents containing qi, qtf (qi ) is the within-query term frequency, dl (D ) is the length D , avdl is the average document length, the kis are tuning constants, K equals k1  ((1 - b) + b  dl(D)/avdl). The proximity part of CRTER is shown as follows.",0,,False
96,"P rox(qi, qj , D ) ,"" w(qi,j , D )""",0,,False
97,(9),0,,False
98,"where qi,j represents the association between query terms qi and qj, w(qi,j, D ) is the BM25 weighting function with the following features of qi,j [10]",0,,False
99,"tf (qi,j ,",0,,False
100,D,0,,False
101,),0,,False
102,",",0,,False
103,"tf (qi,D",0,,False
104,),0,,False
105,"tf (qj ,D",0,,False
106,),0,,False
107,K,0,,False
108,er,0,,False
109,nel(,0,,False
110,1 2,0,,False
111,dist(posk1,0,,False
112,",i",0,,False
113,",",0,,False
114,"posk2,j ))",0,,False
115,"k1 ,1",0,,False
116,"k2 ,1",0,,False
117,"qtf (qi,j )",0,,False
118,",",0,,False
119,K ernel(,0,,False
120,1 2,0,,False
121,),0,,False
122,·,0,,False
123,"min(qtf (qi),",0,,False
124,qtf,0,,False
125,(qj )),0,,False
126,"n(qi,j ) ,",0,,False
127,D,0,,False
128,"tf (qi,j , D ) Occur(qi,j , D )",0,,False
129,"where Kernel(·) is a kernel function, and Occur(qi,j, D )",0,,False
130,equals,0,,False
131,"tfi k1 ,1",0,,False
132,1 . tfj,0,,False
133,"k2 ,1",0,,False
134,{K,0,,False
135,ernel(,0,,False
136,1 2,0,,False
137,dist(posk1,0,,False
138,",i",0,,False
139,",posk2",0,,False
140,",j",0,,False
141,")),0}",0,,False
142,4. EXPERIMENTS,0,,False
143,We evaluate the proposed approach on three standard,0,,False
144,"TREC data sets. They are AP88-89 with topics 51-100,",1,TREC,True
145,"Web2G with topics 401-450, and TREC8 with topics 401-",1,TREC,True
146,450. AP88-89 contains articles published by Association,1,AP,True
147,Press from the year of 1988 to 1989. The WT2G collec-,1,WT,True
148,tion is a 2G size crawl of Web documents. The TREC8,1,TREC,True
149,"contains newswire articles from various sources, such as Fi-",0,,False
150,"nancial Times (FT), the Federal Register (FR) etc. For all",0,,False
151,"the data sets used, each term is stemmed using Porter's En-",0,,False
152,"glish stemmer, and standard English stopwords are removed.",0,,False
153,"We have three baseline models, BM25, Dirichlet Language",0,,False
154,Data Sets,0,,False
155,BM25 Dirichlet LM,1,LM,True
156,CRTER Improvement over BM25,0,,False
157,RelCoOccur Improvement over BM25 Improvement over CRTER,0,,False
158,RelSqRecip Improvement over BM25 Improvement over CRTER,0,,False
159,RelM inDist Improvement over BM25 Improvement over CRTER,0,,False
160,RelKernel Improvement over BM25 Improvement over CRTER,0,,False
161,AP88-89,1,AP,True
162,0.2708 0.2763,0,,False
163,0.2744 1.329%,0,,False
164,0.2768 2.216% 0.875%,0,,False
165,0.2812* 3.840% 2.478%,0,,False
166,0.2800 3.397% 2.041%,0,,False
167,0.2812* 3.840% 2.478%,0,,False
168,Web2G,0,,False
169,0.3136 0.3060,0,,False
170,0.3298* 5.166%,0,,False
171,0.3375* 7.621% 2.335%,0,,False
172,0.3444*  9.821% 4.427%,0,,False
173,0.3444*  9.821% 4.427%,0,,False
174,0.3425* 9.216% 3.851%,0,,False
175,TREC8,1,TREC,True
176,0.2467 0.2552,0,,False
177,0.2606 * 5.634%,0,,False
178,0.2622* 6.283% 0.614%,0,,False
179,0.2633* 6.729% 1.036%,0,,False
180,0.2615* 5.999% 0.345%,0,,False
181,0.2625* 6.405% 0.729%,0,,False
182,"Table 2: Overall MAP Performance (""*"" indicates significant improvement over BM25, and """" indicates significant improvement over CRTER)",1,MAP,True
183,"Model (LM) and CRTER. The best parameters are chosen in the baseline models for fair comparisons. In BM25, the values of k1, k2, k3 and b are set to be 1.2, 0, 8 and 0.35 respectively, since they are recognized with a good performance. In CRTER model, we use the recommended settings [10]., which are  ,"" 25,  "","" 0.2, and triangle kernel function. In our proposed context-sensitive proximity model, we use the same parameters in the basic weighting model part (e.g. BM25) and the proximity part (e.g. CRTER). In RelKernel, we set the kernel parameter  "","" 25. In RelMinDist, we set  "","" 1, which has the best performance in [9]. We normalize AR(qi, qj, topDoc), P rox(qi, qj, D ) and w(qi, D ) in formula (6) to the scale of [0,1]. We use the Mean Average Precision (MAP) as our evaluation metric.""",1,LM,True
184,"Table 2 shows the overall MAP performance. The proposed context-sensitive proximity model outperforms BM25, Language Model (LM) and CRTER with all of the contextual relevance measuring approaches on all the data sets. For the space limitation, we only include these comparisons. It shows that using the contextual relevance of term proximity can further boost the retrieval performance. We can see that the RelCoOccur, which measures whether two query terms are co-occurring in the relevant documents, reaches the lowest MAP among the contextual relevance measures, which indicates the necessity of considering the term location information in the term pair contextual relevance definition. RelSqRecip has the highest MAP over the other approaches on all the data sets. In general, considering both the closeness and frequency of two query terms in the contextual relevance definition benefits the contextual relevance estimation.",1,MAP,True
185,"In Table 3, we investigate how the number of top relevant documents affects the retrieval performance. We take the topDoc ,"" 5, 10, 20, 30, 40, 50 60, 70, and 80 documents as relevant, and calculate the average contextual relevance obtained from these documents. The bolded values are the best performance among different topDoc values. We can see that the best topDoc will be around 5 to 40. It means that selecting too many top documents as relevant will introduce noises to the model.""",0,,False
186,"Figure ?? shows the sensitivity of  on all the data sets. We can see that with the growth of , MAP first increases",1,MAP,True
187,1133,0,,False
188,AP88-89 Web2G TREC8,1,AP,True
189,RelCoOccur RelSqRecip RelM inDist RelKernel,0,,False
190,RelCoOccur RelSqRecip RelM inDist RelKernel,0,,False
191,RelCoOccur RelSqRecip RelM inDist RelKernel,0,,False
192,5,0,,False
193,0.2757 0.281 0.2800 0.2812,0,,False
194,0.3348 0.3401 0.3351 0.3358,0,,False
195,0.2622 0.2633 0.2612 0.2625,0,,False
196,10,0,,False
197,0.2766 0.2812 0.2794 0.2796,0,,False
198,0.3359 0.342 0.3444 0.3409,0,,False
199,0.2612 0.263 0.2614 0.2622,0,,False
200,20,0,,False
201,0.2768 0.2801 0.2800 0.2801,0,,False
202,0.3354 0.3409 0.3421 0.3425,0,,False
203,0.2614 0.2627 0.2615 0.2619,0,,False
204,30,0,,False
205,0.2767 0.2801 0.2796 0.2801,0,,False
206,0.3367 0.3401 0.3382 0.3406,0,,False
207,0.2611 0.2623 0.2612 0.2615,0,,False
208,40,0,,False
209,0.2762 0.2789 0.2797 0.2789,0,,False
210,0.3375 0.3444 0.3406 0.3423,0,,False
211,0.2611 0.2617 0.2606 0.2607,0,,False
212,50,0,,False
213,0.2759 0.2781 0.2784 0.2781,0,,False
214,0.3369 0.3435 0.3414 0.3418,0,,False
215,0.261 0.2615 0.2605 0.2604,0,,False
216,60,0,,False
217,0.2758 0.278 0.279 0.2783,0,,False
218,0.3367 0.3433 0.3427 0.3421,0,,False
219,0.2608 0.2613 0.2606 0.2605,0,,False
220,Table 3: Performance over the change of topDoc,0,,False
221,70,0,,False
222,0.2755 0.2777 0.2787 0.2781,0,,False
223,0.3374 0.3424 0.3434 0.3414,0,,False
224,0.2601 0.2614 0.2607 0.2605,0,,False
225,80,0,,False
226,0.2753 0.2774 0.2786 0.278,0,,False
227,0.3363 0.3419 0.3433 0.3399,0,,False
228,0.2599 0.2612 0.2605 0.2606,0,,False
229,0.285,0,,False
230,0.28,0,,False
231,0.275,0,,False
232,0.27,0,,False
233,0.265,0,,False
234,0.26,0,,False
235,0.255,0,,False
236,QualityCoOccur,0,,False
237,0.25,0,,False
238,QualitySqRecip,0,,False
239,0.245,0,,False
240,QualityMinDist QualityKernel,0,,False
241,0.24,0,,False
242,0,0,,False
243,0.2,0,,False
244,0.4,0,,False
245,0.6,0,,False
246,0.8,0,,False
247,1,0,,False
248,(a) AP88-89,1,AP,True
249,0.36,0,,False
250,0.35,0,,False
251,0.34,0,,False
252,0.33,0,,False
253,0.32,0,,False
254,0.31,0,,False
255,0.3,0,,False
256,QualityCoOccur,0,,False
257,0.29,0,,False
258,QualitySqRecip,0,,False
259,0.28,0,,False
260,QualityMinDist,0,,False
261,QualityKernel,0,,False
262,0.27,0,,False
263,0,0,,False
264,0.2,0,,False
265,0.4,0,,False
266,0.6,0,,False
267,0.8,0,,False
268,1,0,,False
269,(b) Web2G Figure 1: Sensitivity of ,0,,False
270,0.26,0,,False
271,0.25,0,,False
272,0.24,0,,False
273,0.23,0,,False
274,QualityCoOccur,0,,False
275,QualitySqRecip,0,,False
276,0.22,0,,False
277,QualityMinDist,0,,False
278,QualityKernel,0,,False
279,0.21,0,,False
280,0,0,,False
281,0.2,0,,False
282,0.4,0,,False
283,0.6,0,,False
284,0.8,0,,False
285,1,0,,False
286,(c) TREC8,1,TREC,True
287,MAP MAP MAP,1,MAP,True
288,"and then decreases. Please note that when  ,"" 0, there is no proximity utilized, which is our baseline BM25. When  "","" 1, only term proximity and the contextual relevance of term proximity are considered. In CRTER, the recommended setting for the balancing parameter is 0.2. After introducing the contextual relevance of term proximity, we can see that the balancing parameter  with a value of around 0.3 or 0.4 is better. The reason is that the contextual relevance is normalized to [0,1]. The value for the second part of formula (6) becomes smaller, therefore it requires a larger balancing parameter.""",0,,False
289,5. CONCLUSIONS AND FUTURE WORK,0,,False
290,"We propose a new approach to integrate the contextual relevance of term proximity in retrieval. The contextual relevance of term proximity evaluates how much we should focus on a pair of query terms. In particular, we propose four measures to estimate the contextual relevance of term proximity, namely RelOcOccur, RelSqRecip, RelMinDist, and RelKernel. They incorporate different types of information utilized in the contextual relevance of term proximity. We further propose a context-sensitive proximity model via multiplying the contextual relevance of term proximity by the proximity part in a retrieval model.",1,corpora,True
291,"We evaluate our proposed context-sensitive proximity model on several TREC standard data sets, and the experimental results show the effectiveness of our proposed model over three baselines BM25, Dirichlet LM and CRTER with optimal parameter settings. In more detail, we discuss how many top documents should be selected for calculating the proximity contextual relevance, and how the balancing parameter  affects the retrieval performance.",1,TREC,True
292,"In the future, we can extend the contextual relevance of term proximity to more query terms. In addition, the contextual relevance of term proximity can be adopted in other",1,ad,True
293,basic weighting models (e.g. Language Model) and/or other,0,,False
294,proximity approaches. We can also apply the proposed,0,,False
295,model into relevance feedback.,0,,False
296,6. ACKNOWLEDGEMENTS,0,,False
297,This research is supported by the research grant from the,0,,False
298,NSERC of Canada and the Early Researcher Award. We,1,ad,True
299,thank four anonymous reviewers for their thorough review,0,,False
300,comments on this paper.,0,,False
301,"7. REFERENCES [1] M. Bendersky, D. Metzler, and W. B. Croft. Learning concept importance using a weighted dependence model. In Proc. of WSDM, pages 31­40. ACM, 2010. [2] S. Buttcher, C. Clarke, and B. Lushman. Term proximity scoring for ad-hoc retrieval on very large text collections. In Proc. of SIGIR, page 622. ACM, 2006. [3] W. Croft, D. Metzler, and T. Strohman. Search engines: Information retrieval in practice. Addison-Wesley, 2010. [4] C. Macdonald and I. Ounis. Global statistics in proximity weighting models. In Web N-gram Workshop, pages 30­37, 2010. [5] S. E. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, M. Gatford, et al. Okapi at TREC-3. In Proc. of TREC, pages 109­126. NIST, 1995. [6] L. Shi and J.-Y. Nie. Using various term dependencies according to their utilities. In Proc. of CIKM, pages 1493­1496. ACM, 2010. [7] R. Song, M. J. Taylor, J.-R. Wen, H.-W. Hon, and Y. Yu. Viewing term proximity from a different perspective. In Proc. of ECIR, pages 346­357. Springer, 2008. [8] K. M. Svore, P. H. Kanani, and N. Khan. How good is a span of terms? exploiting proximity to improve web retrieval. In Proc. of SIGIR, pages 154­161. ACM, 2010. [9] T. Tao and C. Zhai. An exploration of proximity measures in information retrieval. In Proc. of SIGIR, pages 259­302. ACM, 2007. [10] J. Zhao, J. Huang, and B. He. CRTER: using cross terms",1,ad-hoc,True
302,"to enhance probabilistic information retrieval. In Proc. of SIGIR, pages 155­164, 2011. [11] J. Zhao, J. X. Huang, and Z. Ye. Modeling term associations for probabilistic information retrieval. ACM Transactions on Information Systems (TOIS), 32(2):7, 2014.",0,,False
303,1134,0,,False
304,,0,,False
