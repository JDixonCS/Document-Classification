,sentence,label,data,regex
0,Injecting User Models and Time into Precision via Markov Chains,0,,False
1,Marco Ferrante,0,,False
2,"Dept. Mathematics University of Padua, Italy",1,ad,True
3,ferrante@math.unipd.it,0,,False
4,Nicola Ferro,0,,False
5,"Dept. Information Engineering University of Padua, Italy",1,ad,True
6,ferro@dei.unipd.it,0,,False
7,Maria Maistro,0,,False
8,"Dept. Information Engineering University of Padua, Italy",1,ad,True
9,maistro@dei.unipd.it,0,,False
10,ABSTRACT,0,,False
11,"We propose a family of new evaluation measures, called Markov Precision (MP), which exploits continuous-time and discrete-time Markov chains in order to inject user models into precision. Continuous-time MP behaves like timecalibrated measures, bringing the time spent by the user into the evaluation of a system; discrete-time MP behaves like traditional evaluation measures. Being part of the same Markovian framework, the time-based and rank-based versions of MP produce values that are directly comparable.",1,ad,True
12,We show that it is possible to re-create average precision using specific user models and this helps in providing an explanation of Average Precision (AP) in terms of user models more realistic than the ones currently used to justify it. We also propose several alternative models that take into account different possible behaviors in scanning a ranked result list.,1,AP,True
13,"Finally, we conduct a thorough experimental evaluation of MP on standard TREC collections in order to show that MP is as reliable as other measures and we provide an example of calibration of its time parameters based on click logs from Yandex.",1,TREC,True
14,Categories and Subject Descriptors,0,,False
15,H.3.4 [Information Search and Retrieval]: Systems and Software--Performance evaluation (efficiency and effectiveness),0,,False
16,General Terms,0,,False
17,"Experimentation, Measurement, Performance",0,,False
18,Keywords,0,,False
19,Evaluation; Markov Precision; User Model; Time,0,,False
20,1. INTRODUCTION,1,DUC,True
21,Experimental evaluation has been central to Information Retrieval (IR) since its beginning [15] and Cranfield is the,0,,False
22,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609637.",1,ad,True
23,"predominant paradigm for carrying out system-oriented experimentation [11]. Over the decades, several measures have been proposed to evaluate retrieval effectiveness.",1,ad,True
24,"AP [5] represents the ""gold standard"" measure in IR [35], known to be stable [3] and informative [1], with a natural top-heavy bias and an underlying theoretical basis as approximation of the area under the precision/recall curve. Nevertheless, due to its dependence on the recall base, it assumes a perfect knowledge of the relevance of each document in the collection, which is an approximation when pooling is adopted and not assessed documents are assumed to be not relevant [14], and is even more exacerbated in the case of large scale or dynamic collections [4, 35].",1,AP,True
25,"However, the strongest criticism to AP comes from the absence of a convincing user model for it, a feature which is deemed extremely important in order to make the interpretation of a measure meaningful and to bridge the gap between system-oriented and user-oriented studies [7, 21, 31]. In this respect, [22] argued that the model behind AP is abstract, complex, and far from the real behavior of users interacting with an IR system, especially when it comes to its dependence on the recall base which is something actually unknown to real users. As a consequence, [25] proposed a simple but moderately plausibile user model for AP, which allows for a mix of different behaviors in the population of users.",1,AP,True
26,"In this paper, we take up from the final considerations of [25], at page 690: ""this argument could provide the basis for a more elaborate model, by for example basing the set of ps(n) on some more sophisticated view of stopping behaviour"", where ps(n) is the probability that the user satisfaction point is the document at rank n.",0,,False
27,"We propose a family of measures of retrieval effectiveness, called Markov Precision (MP), where we exploit Markov chains [23] to inject different user models into precision and which does not depend on the recall base. We represent each position in a ranked result list with a state in a Markov chain and the different topologies and transition probabilities among the states of the Markov chain allow us to model the different and perhaps complex user behaviors and paths in scanning a ranked result list. The invariant distribution of the Markov chain provides us with the probability of the user being in a given state/rank position in stationary conditions and we use these probabilities to compute a weighted average of precision at those rank positions.",0,,False
28,The framework we propose is actually more general and it is based on continuous-time Markov chains in order to take into account also the time a user spends in visiting a sin-,0,,False
29,597,0,,False
30,"gle document. It is then possible to extract a discrete-time Markov chain, when considering only the transitions among rank positions and not the time spent in each document. This gives us a two-fold opportunity: when we consider the discrete-time Markov chain, we are basically reasoning as traditional evaluation measures which assess the utility for the user in scanning the ranked result list; when we consider the continuous-time Markov chain,we also embed the information about the time spent by the user in visiting a document and we have a single measure including both aspects. This represents a valuable contribution of the paper since, up to now, rank and time have been two separate variables according to which retrieval effectiveness is evaluated [31].",1,ad,True
31,"The Markov chain approach relies on some assumptions ­ e.g. no long-term memory and exponentially distributed holding times ­ which may seem oversimplifications of the reality, e.g. a user who considers the whole history of visited documents to decide whether to stop or not. However, other measures, such as Rank-Biased Precision (RBP) [22] where transitioning to the next document or stopping is a step-bystep decision based just on the persistence parameter, are memory-less in this sense. Moreover, a Markovian model is simple enough to be easily dealt with while still being quite powerful and this work intends to be a first step towards a richer world of models that we will explore in the future.",0,,False
32,"We then propose some basic models for the transition matrix of the Markov chain. Clearly, this is not intended to be an exhaustive list of all the possible models but more of an exemplification of how it is possible to plug different user models into the framework. Still, these basic models provide a second valuable contribution of the paper. Indeed, we will show how some of these models, when provided with the same level of information about the recall base as AP, actually are AP, thus giving an explanation of it in terms of a slightly richer user model than the one of [25]. We will also show how some of them are extremely highly correlated to AP, thus suggesting how AP can be considered a very good approximation of more complex user strategies. This helps in shedding some light on why AP is the de-facto ""gold standard"" in IR, even though it has been so often criticized.",1,AP,True
33,"Finally, we conduct a thorough experimental evaluation of the MP measure both using standard Text REtrieval Conference (TREC)1 collections and click-logs with assessed queries made available by Yandex [29]. The results show that MP is comparable to other measures for some desirable properties like robustness to pool downsampling while the Yandex click-logs allow us to estimate the time spent by the users on the documents and apply the continous-time Markov chain.",1,TREC,True
34,The paper is organized as follows: Section 2 presents the related works; Section 3 discusses other pertinent measures to which MP will be compared; Section 4 fully introduces MP; Section 5 reports the conducted experimental evaluation of MP; and Section 6 draws some conclusion and provides an outlook for future work.,0,,False
35,2. RELATED WORKS,0,,False
36,"Markov-based approaches have been previously exploited in IR, for example: Markov chains have been used to generate query models [19], for query expansion [12, 20], and for document ranking [13]. However, to the best of our knowl-",0,,False
37,1http://trec.nist.gov/,1,trec,True
38,"edge, Markov chains have not been applied to the definition of a fully-fledged measure for retrieval effectiveness.",0,,False
39,"[8] uses Markov chains to address the placement problem in the case of two-dimensional results presentation: they have to allocate images on a grid to maximize the expected total utility of the user, according to some evaluation measure, and the Markov chain models how the user moves in the grid. Their approach differs from ours since they are not defining a measure of effectiveness which embeds a Markov chain but they rather solve an optimization problem via a Markov chain; moreover, they only use discrete-time Markov chains and limit transitions only to adjacent states. What we share is the idea that a Markov chain can be used to model how a user scans a result list, mono dimensional in our case, two-dimensional in their case.",1,ad,True
40,"When it comes to other evaluation measures, the focus of the paper is on lab-style evaluation, search tasks with informational intents [2], and binary relevance. So, for example, measures for novelty and diversity are out of the scope of the present paper [10] as are measures for graded relevance like Discounted Cumulated Gain (DCG) [16], Expected Reciprocal Rank (ERR) [6], or Q-measure [26].",1,ad,True
41,"With regard to the time dimension brought in by the continuous-time Markov chain, the most relevant work is Time-Biased Gain (TBG) [30, 31]. We share the idea of getting time into evaluation measures but we adopted a different approach. While TBG substitutes traditional evaluation measures, MP provides a single framework for keeping both aspects depending on which Markov chain you use. With respect to the user model adopted in TBG, there are some relevant differences: first, we use full Markov models while [30] at page 2014 points out that ""our model can be viewed as a semi-Markov model""; then, TBG assumes a sequential scanning of the result lists where MP allows the user to move and jump backward and forward in the results list. What TBG addressed and is not in the scope of the present work is how to calibrate the measure with respect to time: [31] proposed a procedure to calibrate time with respect to document length and [30] extended it to stochastic simulation. In the present work, we provide a basic example of calibration based on the estimation of average time spent per document from click logs, just to show how the parameters of the framework could be tuned. However, in the future, nothing prevents us (or others) from investigating more advanced calibration strategies or applying those proposed by [30, 31].",1,TB,True
42,"Previous work on click logs [17] has reported that, on average, users scan ranked list in a forward linear fashion while MP allow users to move forward and backward in a ranked list. As reported in Section 5.5, from Yandex logs, we found that 21% of the users move backward in the ranked list, thus supporting our assumption, even if more exploration on this is left for future work. Moreover, U-measure [28] is a recent proposal which shares with MP the idea of removing the constraint of the linear scan but it does not adopt Markov models and has also somewhat different goals, such as evaluating complex tasks like multi-query sessions and diversified IR.",1,ad,True
43,"When it comes to other ways of modelling user behaviour into evaluation measures, [7] proposes relying on three components: a browsing model, a model of document utility, and a utility accumulation model. Even if we took up from [25], MP can also be framed in the light of the work of [7]. Indeed,",0,,False
44,598,0,,False
45,"the Markovian model provides us with the browsing model, precision account for the model of document utility, and the weighted average of precision by the invariant distribution of the Markov chain supplies the utility accumulation model.",0,,False
46,"Thus, evaluation measures of direct comparison, which will be detailed in Section 3, are those built around the concept of precision, namely AP, P@10, and Rprec [5]. RBP [22] comes into play as a binary evaluation measure not dependent on the recall base, even though it is not built around the concept of precision despite its name. Finally, we are also interested in Binary Preference (bpref) [4], just to have a comparison point when testing MP with respect to reducedsize pools. In this last respect, we are not interested in infAP [35], since we are neither looking for an estimator of AP nor investigating alternative strategies for pool downsampling. For the same reason, we are not interested here in experimenting with respect to condensed-list measures [27].",1,AP,True
47,3. OTHER EVALUATION MEASURES,0,,False
48,"Let us consider a ranked list of T documents in response to a given topic, let dn be the document retrieved at position n  T whose relevance is denoted by an, equal to 1 if the document is considered relevant and 0 otherwise. The ranked list of documents is denoted with D ,"" {di, i  T } and R "", {ij : j ,"" 1, . . . , T and aij "","" 1} is the set of the ranks of the relevant documents, whose cardinality is r "","" |R| and which indicate the total number of relevant retrieved documents by the system for the given topic. Let RB be the recall base of the topic, i.e. the total number of judged relevant documents for a given topic, and N RB the total number of judged not relevant documents for a given topic.""",0,,False
49,The precision at rank n is thus defined as,0,,False
50,1n,0,,False
51,"Prec(n) , n",0,,False
52,am,0,,False
53,(1),0,,False
54,"m,1",0,,False
55,"which corresponds to the percentage or ""density"" of relevant",0,,False
56,"documents present among the first n, n included, in the",0,,False
57,"list. Note that Rprec is Prec(RB), which makes clear its",0,,False
58,dependence on the recall base.,0,,False
59,The recall at rank T is defined as,0,,False
60,Rec(T ),0,,False
61,",",0,,False
62,r RB,0,,False
63,(2),0,,False
64,which corresponds to the fraction of relevant documents of the specific run with respect to the total number of judged relevant documents.,0,,False
65,3.1 Average Precision (AP),1,AP,True
66,"The original definition of Average Precision (AP) [5] is the average over all RB judged relevant documents of the precision at their ranks, considering zero the precision at the not retrieved relevant documents:",1,AP,True
67,"AP , 1",1,AP,True
68,"Prec(i) , r · 1 Prec(i) (3)",0,,False
69,RB,0,,False
70,RB r,0,,False
71,iR,0,,False
72,iR,0,,False
73,"where, in the last equation, the first operand is the recall and the second one is the arithmetic mean of the precisions at each relevant retrieved document. This formulation further highlights the dependence of AP on the recall base and the recall itself.",1,AP,True
74,"As previously discussed, [25] proposed a simple, probabilistic user model measure of effectiveness called Normalized Cumulative Precision (NCP), which includes AP as a particular case. The author assumes that any given user will stop his search at a given document in the ranked list, that we call its satisfaction point, according to a common probability law.",1,AP,True
75,"Furthermore, he considers that a user will stop his search only at relevant documents and that the probability that he stops at any given relevant documents is fixed and independent from the specific run he is considering, while it is 0 at any non relevant document. So, he defines a probability distribution ps on the set of all the documents available for a given topic.",0,,False
76,"Given a specific run and the set of its retrieved documents D, the definition of the NCP is then the expectation (average) of the precision at the ranks of the retrieved, relevant documents, accordingly to a distribution ps(·), i.e.",0,,False
77,+,0,,False
78,"N CP (ps) , Eps [Prec(n)] , ps(dn)Prec(n) .",0,,False
79,"n,1",0,,False
80,It is easy to see that the above definition of AP is in this con-,1,AP,True
81,text equal to the NCP measure when we choose the uniform,0,,False
82,law pU over all the relevant documents for the topic,0,,False
83,1,0,,False
84,"pU (dn) , ",0,,False
85,RB 0,0,,False
86,if dn is relevant otherwise,0,,False
87,"The previous user model is simple and it can be considered as a starting point for more sophisticated models, as also suggested by [25] itself. As in the case of AP, the assumption that the user knows the recall base of a given topic is a weakness of this model. Furthermore, the probability that a user stops their search at a given document on a specific run depends on a probability distribution defined on the whole set of relevant documents available for a given topic.",1,AP,True
88,"The choice of the uniform distribution to determine the stopping point in a given search is itself of difficult interpretation, since this means that any relevant document in a ranked list of retrieved documents has the same probability.",0,,False
89,"We will see in the next section how, stepping from the intuition behind NCP, we can define, thanks to simple Markov chains, a more realistic user model, how AP can be still considered as a good approximation in many cases and how to generalize AP to a whole new class of Markovian models.",1,AP,True
90,3.2 Rank-Biased Precision (RBP),0,,False
91,"Rank-Biased Precision (RBP) [22] assumes a user model where the user starts from the top ranked document and with probability p, called persistence, goes to the next document or with probability 1 - p stops. RBP is defined as follows:",0,,False
92,"RBP , (1 - p) pi-1",0,,False
93,(4),0,,False
94,iR,0,,False
95,"It can be noted that, despite its name, RBP does not depend on the notion of precision. Nevertheless, it represents a measure for binary relevance which does not depend on the recall base and thus gives a comparison point in this last respect for MP.",0,,False
96,599,0,,False
97,3.3 Binary Preference (bpref),0,,False
98,"Binary Preference (bpref) [4, 32] is a measure based on binary preferences and it evaluates systems using only the judged documents. It can be thought of as the inverse of the fraction of judged irrelevant documents that are retrieved before relevant ones:",0,,False
99,"bpref , 1",0,,False
100,1 - |j ranked higher than i|,0,,False
101,(5),0,,False
102,RB,0,,False
103,"min(RB, N RB)",0,,False
104,iR,0,,False
105,"where j is a member of the first RB not relevant retrieved documents. bpref has proved to be quite robust in the case of incomplete and imperfect relevance judgements. Here, for us, it represents a comparison point when evaluating MP with respect to reduced-size pools.",0,,False
106,"It can be noted how heavily bpref depends on the recall base RB. This is not only a scale factor as in the case of AP but it also determines the cardinality of the set from which the not relevant documents j are taken. Moreover, it makes use also of N RB, the total number of judged not relevant documents, a kind of information which is hard to imagine available to any real user. So, in a sense, it seems much more a ""pool-oriented"" than a system-oriented measure since, for determining its score, it uses much more information about the pool than about the system under examination and this could be an explanation of its robustness to the pool reduction.",1,AP,True
107,4. A MARKOVIAN USER MODEL,0,,False
108,4.1 General framework,0,,False
109,"We will assume that each user starts from a chosen document in the ranked list and considers this document for a random time, that is distributed according to a known positive random variable. Then they decides, according to a probability law that we will specify in the sequel and independent from the random time spent in the first document, to move to another document in the list. Then, they considers this new document for a random time and moves, independently, to a third relevant document and so on.",0,,False
110,"After a random number of forward and backward movements along the ranked list, the user will end their search and we will evaluate the total utility provided by the system to them by taking the average of the precision of the judged relevant documents they has considered during their search. According to this construction when we compute this average, the precision of a document visited k times will contribute to the mean with a k/n weight.",0,,False
111,"We mathematically model the user behavior in the framework of the Markovian processes [23]. To fix the notation, we will denote by X0, X1, X2, . . . the (random) sequence of document ranks visited by the user and by T0, T1, T2 the random times spent, respectively, visiting the first document considered, the second one and so on. Therefore, X0 , i means that the user starts from the first document at rank i and T0 ,"" t0 means that they spends t0 units of time visiting this first document, then X1 "","" j means that they visits the document at rank j as the second one, and so on.""",0,,False
112,"First of all, we will assume that X0 is a random variable on T ,"" {1, 2, . . . , T } with a given distribution  "","" (1, . . . , T ); so for any i  T , P[X0 "", i] ,"" i. Then, we will assume that the probability to pass from the document at rank i to the""",0,,False
113,document at rank j will only depend on the starting rank i and not on the whole list of documents visited before.,0,,False
114,This can be formalized as follows:,0,,False
115,"P[Xn+1 , j|Xn ,"" i, Xn-1 "","" in-1, . . . , X0 "", i0] , (6)",0,,False
116,", P[Xn+1 , j|Xn , i] ,"" pi,j""",0,,False
117,"for any n  N and i, j, i0, . . . , in-1  T .",0,,False
118,"p1,T",0,,False
119,"p1,2",0,,False
120,"p1,T-1 p1,3",0,,False
121,"p2,T-1 p2,3",0,,False
122,"p2,T",0,,False
123,d1,0,,False
124,d2,0,,False
125,d3,0,,False
126,dT-1,0,,False
127,dT,0,,False
128,"pT-1,1",0,,False
129,"pT-1,2",0,,False
130,"pT-1,3",0,,False
131,"pT,T-1 pT,3",0,,False
132,"pT,1",0,,False
133,"pT,2",0,,False
134,Figure 1: Structure of the Markov chain (Xn)nN.,0,,False
135,Thanks to the condition (6) and fixing a starting distribu-,0,,False
136,"tion , the random variables (Xn)nN define a time homoge-",0,,False
137,"nous discrete time Markov Chain, shown in Figure 1, with",0,,False
138,"state space T , initial distribution  and transition matrix",0,,False
139,"P ,"" (pi,j )i,jT (Markov(,P) in the sequel).""",0,,False
140,"To obtain a continuous-time Markov Chain, we have to",0,,False
141,assume that the holding times Tn have all exponential dis-,0,,False
142,"tribution, i.e.  0",0,,False
143,t<0,0,,False
144,"P[Tn  t] ,  1 - exp(-t) t  0",0,,False
145,"Furthermore, conditioned on the fact that Xn ,"" i, the law of Tn will be exponential with parameter i, where i is a positive real number that may depend on the specific state i of the chain the user is visiting at that time.""",0,,False
146,"When our interest is only on the jump chain (Xn)nN, i.e. when we are interested in extracting the corresponding discrete-time Markov chain to act as a traditional evaluation measure, we simply assume that all these variables are exponential with parameter  ,"" 1. When we are also interested in the time dimension, we have to provide a calibration for these exponential variables. We report a very simple example in Section 5 using click logs from Yandex.""",1,ad,True
147,"The reason for choosing such a model will be immediately clear. Let us assume hereafter that the matrix P will be irreducible. This means that we can move in a finite number of steps from any document to any other document with positive probability. Thanks to (6) and the multiplication rule, the probability to pass in n steps from the document i to the document j is equal to p(i,nj), the (i, j) entry of the matrix P n and the irreducibility means that given any pair (i, j) there exists n > 0 such that p(i,nj) > 0. Furthermore, the probability distribution of any random variable Xn, which denotes the rank of the document visited after n movements, is completely determined by  and P , since",0,,False
148,"P[Xn , j] , (P n)j .",0,,False
149,"Given such a model, we assume that a user will visit a number n of documents in the list and then they will stop their search. In order to measure their satisfaction, we will evaluate the average of the precision of the ranks of the judged",0,,False
150,600,0,,False
151,relevant documents visited by the user during their search as,0,,False
152,1 n-1 n Prec(Yk) .,0,,False
153,"k,0",0,,False
154,"where (Yn)nN denotes the sub-chain of (Xn)nN that considers just the visits to the judged relevant documents at ranks R, and shown in Figure 2.",0,,False
155,"p1,2",0,,False
156,"p1,T p2,T",0,,False
157,d1,0,,False
158,d2,0,,False
159,d3,0,,False
160,dT-1,0,,False
161,dT,0,,False
162,"pT,1",0,,False
163,"pT,2",0,,False
164,Figure 2: Structure of the sub-Markov chain (Yn)nN (relevant documents are shown in grey; not relevant ones in white).,0,,False
165,Note that this sub-chain has in general a transition ma-,0,,False
166,"trix different form P . The new transition matrix P can be computed easily from P by solving a linear system as detailed in [23] and discussed in Section 4.3.1. Note that P computed in this way somehow ""absorbs"" and takes into account also the probabilities of passing through not relevant documents (which are basically redistributed over the relevant ones) and makes it different from the transition matrix that you would have obtained by using only the relevant documents since the beginning.",0,,False
167,"Clearly the previous quantity is of little use if evaluated at an unknown finite step n. However, the Ergodic Theorem of the theory of the Markov processes is perfect for approximating this quantity:",0,,False
168,"Theorem 1. Let P be irreducible,  be any distribution",0,,False
169,"and R finite. If (Yn)n0 is Markov(,P ), then for any function f : R  R we have",0,,False
170,P,0,,False
171,1 n,0,,False
172,n-1,0,,False
173,f (Yk) ,0,,False
174,f,0,,False
175,as,0,,False
176,n,0,,False
177,",1",0,,False
178,"k,0",0,,False
179,"where f , iR if (i) and  is the invariant distribution of P .",0,,False
180,"The importance of this class of theorems is clear: almost surely and independently of the initial distribution , we can approximate, for n large, the average over the time by the (much simpler) average over the states of the Markov chain. Indeed, under the previous assumptions it is possible to prove that the matrix P admits a unique invariant distribution, i.e a probability distribution  such that if (Yn)n0 is Markov(,P ), then for any n",1,ad,True
181,"P[Yn , j] , j .",0,,False
182,"Moreover, the invariant distribution in this case is the unique left eigenvector of the eigenvalue 1 of the matrix P , i.e. the unique solution of the linear equation",0,,False
183," , P .",0,,False
184,"Remark 1. Under additional hypotheses, it can be proved that the invariant distribution itself is the limit of any row of the matrix P n, as n  , useful result in order to evaluate in practice the invariant distribution. The convergence is generally very fast and for n , 10 we already have a reasonable approximation of the true value of . This justifies the use of MP to approximate the mean precision of the usually few documents visited by a user.",1,ad,True
185,"We can now define a new family of user oriented retrieval effectiveness measures, called Markov Precision (MP), which depends on the specific user model and the invariant distribution derived.",0,,False
186,"Definition 1. Given a ranked list of retrieved documents, defined by R the ranks of its judged relevant documents and defined a Markov (,P) user model, the Markov Precision metric will be defined as",0,,False
187,"M P , iPrec(i).",0,,False
188,iR,0,,False
189,where Prec(n) represent the Precision at n and  the (unique) invariant distribution of the Markov chain (Yn)nN.,0,,False
190,"MP is defined without knowing the recall base RB of a given topic, but just the ranks of the judged relevant documents in a given run for this topic. As pointed out, for example in [22], the need to know the value of RB represents a weakness in AP that is overcome here.",1,AP,True
191,"In order to include the time dimension and thanks to the Ergodic Theorem for the continuous time Markov chains, we can replicate the previous computations and define a new measure",0,,False
192,"M P cont , iPrec(i).",0,,False
193,iR,0,,False
194,"where i ,",0,,False
195,", i (i )-1",0,,False
196,jR j (j )-1,0,,False
197,denotes,0,,False
198,again,0,,False
199,the,0,,False
200,(unique),0,,False
201,distribution of the Markov chain (Yn)nN and i is the pa-,0,,False
202,rameter of the holding time in state i. To use this alternative,0,,False
203,"measure, we have to provide a calibration for the coefficients",0,,False
204,i and we will compare MP with MPcont in a very simple,0,,False
205,example in Section 5 using click logs from Yandex.,0,,False
206,4.2 Average Precision,0,,False
207,"In order to define a simple Markovian user model, whose MP value will be AP, let us consider the following transition probabilities among the documents in a given ranked list:",1,AP,True
208,P[Xn+1,0,,False
209,",",0,,False
210,j|Xn,0,,False
211,",",0,,False
212,i],0,,False
213,",",0,,False
214,1 T -1,0,,False
215,(7),0,,False
216,"for any i, j  T , i ,"" j, and where, again, T denotes the""",0,,False
217,cardinality of the set T .,0,,False
218,In this model we assume that a user moves from a docu-,0,,False
219,"ment to another document with a fixed, constant probability,",0,,False
220,the value of which depends on the total number of relevant,0,,False
221,documents present in the specific run.,0,,False
222,Since the invariant distribution is,0,,False
223,1 T,0,,False
224,",",0,,False
225,1 T,0,,False
226,",",0,,False
227,.,0,,False
228,.,0,,False
229,.,0,,False
230,",",0,,False
231,1 T,0,,False
232,we obtain,0,,False
233,that,0,,False
234,1,0,,False
235,"MP ,",0,,False
236,P rec(i),0,,False
237,T,0,,False
238,iR,0,,False
239,which is equal to AP,1,AP,True
240,once multiplied by,0,,False
241,T RB,0,,False
242,.,0,,False
243,Note that if,0,,False
244,we create the Markov chain starting directly from the rele-,0,,False
245,vant documents R we have to multiply MP by Rec(T ) as in,0,,False
246,601,0,,False
247,"equation 3. In this way, we explain AP with a slightly richer user model, where the user can move forward and backward among any document and is not forced to visit only the relevant ones. It is also clear from the equation above that MP is not AP unless you provide it with the same amount of information AP knows about the recall base, namely rescaling MP by the recall base.",1,AP,True
248,"Looking at this the other way around, this instantiation of MP (without the rescaling) can be considered a kind of AP where the artificial knowledge of the recall base has been removed and so, it tells us how AP might look like if you remove the dependency on the recall base and insert an explicit user model. This consideration will turn out to be useful in the experimental part when we will find other user models, highly correlated to AP, which may give a richer explanation of it.",1,AP,True
249,"Moreover, the previous constant invariant distribution is common to many others user models. For example, if the transition matrix is irreducible and symmetric or even just bistochastic, meaning that the sum of the entries on each column is equal to 1, the invariant distribution is again the above constant vector. In this sense, if the validity of the present Markovian user model is accepted, it shows once more why AP has become a reference point, since it represents a good approximation for a wide class of models that we can define.",1,AP,True
250,4.3 Other models,0,,False
251,We will analyze three possible choices:,0,,False
252,"· state space choice: the Markov chain (Xn)nN is on the whole set T , indicated with AD (all documents model), or on the set R, indicated with OR (only relevant documents model);",0,,False
253,"· connectedness: the nonzero transition probabilities are among all the documents, indicated with GL (global model), or only among adjacent documents, indicated with LO (local model);",1,ad,True
254,"· transition probabilities: the transition probabilities are proportional to the inverse of the distance, indicated with ID (inverse distance model), or to the inverse of the logarithm of the distance, indicated with LID (logarithmic inverse distance model).",0,,False
255,"We will obtain eight models that we will call after the possible three choices. So, for example, MP GL AD ID is an effectiveness measure with transition probabilities among all the retrieved documents, based on a model on the whole set T , and with transition probabilities proportional to the inverse of the distance of the documents in the ranked list and so on for the other combinations of the parameters.",0,,False
256,4.3.1 State space choice,0,,False
257,"In the AD case, we consider the whole Markov chain (Xn)nN on the whole set T with a given initial distribution  and a transition matrix P ,"" (pi,j )i,jT and then we derive the subchain (Yn)nN on the set R. In order to obtain the invariant distribution of the subchain, we will have to derive its transition matrix P . It can be proved (see [23]) that this matrix can be defined as follows""",0,,False
258,"pi,j ,"" hji for i, j  R""",0,,False
259,Table 1: Main features of the adopted data sets.,1,ad,True
260,Topics Runs Min. Rel Avg. Rel Max. Rel,0,,False
261,TREC 7,1,TREC,True
262,50,0,,False
263,103,0,,False
264,7,0,,False
265,93.48,0,,False
266,361,0,,False
267,TREC 8,1,TREC,True
268,50,0,,False
269,129,0,,False
270,6,0,,False
271,94.56,0,,False
272,347,0,,False
273,TREC 10 50,1,TREC,True
274,97,0,,False
275,2,0,,False
276,67.26,0,,False
277,372,0,,False
278,TREC 14 50,1,TREC,True
279,74,0,,False
280,9,0,,False
281,131.22,0,,False
282,376,0,,False
283,"where the vector (hji , i  T ) is the minimal non-negative solution to the linear system",0,,False
284,"hji ,"" pi,j +""",0,,False
285,pikhjk .,0,,False
286,(8),0,,False
287,"k,R",0,,False
288,"So, once this linear system is solved, we obtain the transition",0,,False
289,matrix P needed to compute the Markov Precision for the given model.,0,,False
290,"In the OR model, we create the Markov Chain (Xn)nN directly on the set R.",0,,False
291,4.3.2 Connectedness,0,,False
292,"In the GL model, we assume that the transition probabilities pi,j > 0 for any choice of i ,"" j. In this case we will assume that there will be a positive, even if very small, probability to pass from any document in the ranked list to any other. For example, the previous model for Average precision is a GL model""",0,,False
293,"By contrast, in LO we will assume that there exist transition probabilities only among adjacent nodes. This is the same kind of logic behind RBP, even though RBP allows only for forward transitions, and is similar to the strategy of [8] for the two-dimensional placement problem.",1,ad,True
294,4.3.3 Transition probabilities,0,,False
295,"In the ID model, we assume that the probability to pass",0,,False
296,from one document to another one in the ranked list is pro-,0,,False
297,portional to the inverse of the relative distance of these two,0,,False
298,documents:,0,,False
299,1 |i-j|+1,0,,False
300,"if i , j",0,,False
301,"(i, j) ,  0",0,,False
302,"if i , j",0,,False
303,(9),0,,False
304,"Denoting by (s1, . . . , sm) the states of the Markov chain, we thus have the following transition probabilities:",0,,False
305,"psi,sj ,",0,,False
306,"(si, sj ) (si, sk)",0,,False
307,k,0,,False
308,(10),0,,False
309,It is immediately clear that the probabilities (10) define an irreducible transition matrix P of a discrete time Markov Chain on the state space and therefore we can define Markov precision for this model.,0,,False
310,"In the LID model, we smooth the distance by using the base 10 logarithm so that that transition probabilities do not decrease not too fast. The choice of the base 10 for the logarithm is due to a typical Web scenario focused on the page of the first 10 results.",0,,False
311,5. EVALUATION,0,,False
312,5.1 Experimental Setup,0,,False
313,"In order to assess MP and compare it to the other pertinent evaluation measures (AP, P@10, Rprec, RBP, and",1,AP,True
314,602,0,,False
315,Table 2: Kendall  correlation between AP and the other comparison measures using complete judgments (high correlations marked with *).,1,AP,True
316,AP P@10 Rprec bpref RBP TREC 7 1.000 0.8018 0.9261* 0.9275 0.7886 TREC 8 1.000 0.8264 0.9219* 0.9361* 0.8090 TREC 10 1.000 0.7551 0.8730 0.8896 0.7401 TREC 14 1.000 0.7295 0.9377 0.8394 0.7229,1,AP,True
317,"bpref), we conducted a correlation analysis and we studied its robustness to pool downsampling. As far as RBP is concerned, we set p ,"" 0.8, which indicates a medium persistence of the user.""",0,,False
318,"We used the following data sets: TREC 7 Ad Hoc, TREC 8 Ad Hoc, TREC 10 Web, and TREC 14 Robust, whose features are summarized in Table 1. We used all the topics and all the runs that retrieved at least one document per topic. In the case of collections with graded relevance assessment (TREC 10 and 14), we mapped them to binary relevance with a lenient strategy, i.e. both relevant and highly relevant documents have been mapped to relevant ones.",1,TREC,True
319,"As far as pool downsampling is concerned, we used the same strategy of [4]: it basically creates separate random lists of relevant/not relevant documents and select a given fraction R% of them, ensuring that at least 1 relevant and 10 not relevant documents are in the pool. We used R% ,"" [90, 70, 50, 30, 10].""",0,,False
320,"As far as the calibration of time is concerned, we used click logs made available by Yandex [29] in the context of the Relevance Prediction Challenge2. The logs consist of 340,796,067 records with 30,717,251 unique queries, retrieving 10 URLs each. We used the training set where there are 5,191 assessed queries which correspond to 30,741,907 records and we selected those queries which appear at least in 100 sessions each to calibrate the time.",1,ad,True
321,The full source code of the software used to conduct the experiments is available for download3 in order to ease comparison and verification of the results.,1,ad,True
322,5.2 Correlation Analysis,0,,False
323,"Table 2 reports the Kendall  correlation [18] between AP and the other comparison measures, using complete judgements, for all the collections. Previous work [33, 34] considered correlations greater than 0.9 as equivalent rankings and correlations less than 0.8 as rankings containing noticeable differences. Table 2 is consistent with previous findings, with a high correlation between AP, Rprec, and bpref and lower correlation values for P@10 and RBP.",1,AP,True
324,"Table 3 reports the Kendall  correlation between the different models for MP, discussed in Section 4.3 and whose notation (GL/LO, AD/OR, ID/LID) is used here as well, and the performance measures of direct comparison, for all the considered collections4. For each variant of MP, the table reports its actual value and also a second row labelled with the suffix @Rec(T ) to indicate a rescaled version of",0,,False
325,"2http://imat-relpred.yandex.ru/en/ 3http://matters.dei.unipd.it/ 4The fact that the values for the LO AD ID and LO AD LID models are the same is not due to a copy&paste error but to the fact that the two chains, in the local model, are the same apart from a constant and so they produce equal rankings.",0,,False
326,"MP by recall. Indeed, this is the same operation needed to make MP equal to AP in the case of the model with constant transition probabilities discussed in Section 4.2 and corresponds to providing MP with the same level of information about the recall base that also AP uses. This has a twofold purpose: (i) to determine if there are other models beyond the ones of Section 4.2 which can give us an additional interpretation of AP; (ii) to get a general feeling of what is the impact of injecting information about the recall into an evaluation measure. In the table, we have marked high correlations, those above 0.90, with a star and we have marked extremely high correlations, those above 0.97, with two stars.",1,AP,True
327,"As a general trend MP tends not to have high correlations with the other evaluation measures, indicating that it takes a different angle from them. This can be accounted for by the effect of the user model explicitly embedded in MP which, for example, allows the user to move forward and backward in the result list while other measures allow only for sequential scans. On the other hand, the proposed models keep it not too far away from the other measures, especially those around precision (AP, P@10, Rprec), since the correlation never drops below 0.70. This is coherent with the fact that both MP and the other measures (AP, P@10, Rprec) are all around the concept of precision and so they have a common denominator.",1,AP,True
328,"Moreover, it can be noted that MP tends to be more correlated with P@10 and then with Rprec and AP. This is consistent with the fact that MP does not depend on the recall base, as P@10 does, while Rprec implicitly and AP explicitly depend on it.",1,AP,True
329,"Finally, the results show a moderate correlation with bpref and a slightly lower one with RBP, whose only common denominator is to not depend on the recall base.",0,,False
330,"Whit regard to @Rec(T ), we can note how they greatly boost the correlation with AP in almost all cases, often moving MP from low to high correlations, and, in turn, increase the correlation with Rprec and bpref (more correlated by themselves to AP) with respect to the one with RBP which tends to decrease.",1,AP,True
331,"In particular, there are some cases, like MP GL AD LID or MP LO AD ID, where it jumps between 0.97 and 1.00. We consider this a case in which MP is providing us with an alternative interpretation of AP, in the sense discussed in Section 4.2. For example, MP GL AD LID provided with information about recall tells us that we can look at AP as a measure that also models a user who can move backward and forward among all the documents in the list and who prefers smaller jumps to bigger ones. The fact that we have found a few models so highly correlated with AP suggests that AP has become a gold standard also because it represents some articulated user models.",1,AP,True
332,5.3 Effect of Incompleteness on Absolute Performances,0,,False
333,"Figure 3 shows the effect of reducing the pool size on the absolute average performances, over all the topics and runs. For space reasons, we do not report figures for all the possible combinations reported in Table 3 but just some to give the reader an idea of the behavior of MP; the considerations made here are however valid also for the not reported figures.",1,ad,True
334,It can be noted how MP shows consistent behavior over all the collections and for various models: its absolute aver-,0,,False
335,603,0,,False
336,Table 3: Kendall  correlation between different instantiations of MP and the other comparison measures,0,,False
337,using complete judgments (high correlations marked with *; extremely high correlations marked with **).,0,,False
338,MP GL AD ID MP GL AD ID@Rec(T ) MP GL AD LID MP GL AD LID@Rec(T ) MP GL OR ID MP GL OR ID@Rec(T ) MP GL OR LID MP GL OR LID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO OR ID MP LO OR ID@Rec(T ) MP LO OR LID MP LO OR LID@Rec(T ),0,,False
339,AP 0.7381 0.9823** 0.7378 0.9954** 0.7322 0.9117* 0.7379 0.9726** 0.7435 0.9946** 0.7435 0.9946** 0.7271 0.9130* 0.7386 0.9552*,1,AP,True
340,TREC 7 P@10 Rprec 0.7522 0.7703 0.7916 0.9243* 0.7638 0.7712 0.7994 0.9252* 0.8311 0.7797 0.8316 0.8937 0.7853 0.7782 0.8158 0.9238* 0.7706 0.7706 0.7994 0.9225* 0.7706 0.7706 0.7994 0.9225* 0.8229 0.7754 0.8283 0.8958 0.8065 0.7826 0.8278 0.9166*,1,TREC,True
341,bpref 0.7827 0.9322* 0.7802 0.9277* 0.7689 0.8848 0.7788 0.9232* 0.7874 0.9265* 0.7874 0.9265* 0.7634 0.8853 0.7787 0.9142*,0,,False
342,RBP 0.7490 0.7799 0.7632 0.7858 0.7689 0.8243 0.7858 0.8029 0.7685 0.7858 0.7685 0.7858 0.8393 0.8211 0.8058 0.8164,0,,False
343,AP 0.8997 0.9815** 0.8912 0.9953** 0.8162 0.9208* 0.8664 0.9722** 0.8931 0.9953** 0.8931 0.9953** 0.8138 0.9195* 0.8534 0.9506*,1,AP,True
344,P@10 0.8510 0.8128 0.8641 0.8221 0.9081* 0.8756 0.8884 0.8477 0.8642 0.8248 0.8642 0.8248 0.9013* 0.9195* 0.8982 0.8623,0,,False
345,TREC 8 Rprec 0.9074* 0.9217* 0.9033* 0.9209* 0.8349 0.9024* 0.8853 0.9281* 0.9011* 0.9219* 0.9011* 0.9219* 0.8305 0.8714 0.8708 0.9186*,1,TREC,True
346,bpref 0.9222* 0.9299* 0.9173* 0.9337* 0.8402 0.9145* 0.8947 0.9390* 0.9174* 0.9343* 0.9174* 0.9343* 0.8354 0.8987 0.8810 0.9319*,0,,False
347,RBP 0.8382 0.7938 0.8551 0.8041 0.9152* 0.8637 0.8858 0.8324 0.8537 0.8066 0.8537 0.8066 0.9176* 0.9127* 0.8995 0.8466,0,,False
348,MP GL AD ID MP GL AD ID@Rec(T ) MP GL AD LID MP GL AD LID@Rec(T ) MP GL OR ID MP GL OR ID@Rec(T ) MP GL OR LID MP GL OR LID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO OR ID MP LO OR ID@Rec(T ) MP LO OR LID MP LO OR LID@Rec(T ),0,,False
349,AP 0.7264 0.9726** 0.7125 0.9941** 0.7034 0.9117* 0.7052 0.9738** 0.7240 0.9742** 0.7240 0.9742** 0.7035 0.9326* 0.7114 0.9579*,1,AP,True
350,TREC 10 P@10 Rprec 0.7832 0.7727 0.7340 0.8631 0.7971 0.7633 0.7512 0.8707 0.8269 0.7663 0.8316 0.8937 0.8077 0.7672 0.7575 0.8740 0.7969 0.7703 0.7376 0.8654 0.7969 0.7703 0.7376 0.8654 0.8300 0.7646 0.7726 0.8767 0.8172 0.7676 0.7601 0.8747,1,TREC,True
351,bpref 0.7611 0.8771 0.7494 0.8878 0.7470 0.8848 0.7466 0.8916 0.7614 0.8802 0.7614 0.8802 0.7449 0.8960 0.7533 0.8949,0,,False
352,RBP 0.8013 0.8771 0.8187 0.7360 0.8590 0.8243 0.8396 0.7448 0.8159 0.7218 0.8159 0.7218 0.8618 0.7618 0.8472 0.7477,0,,False
353,AP 0.8351 0.9896** 0.8294 0.9977** 0.7968 0.9601* 0.8140 0.9924** 0.8297 0.9970** 0.8297 0.9970** 0.7997 0.9674* 0.8084 0.9877**,1,AP,True
354,TREC 14 P@10 Rprec 0.8078 0.8566 0.7221 0.9333* 0.8185 0.8501 0.7303 0.9385 0.8461 0.8206 0.7526 0.9327* 0.8291 0.8348 0.7375 0.9398* 0.8180 0.8504 0.7295 0.9363* 0.8180 0.8504 0.7295 0.9363* 0.8348 0.8234 0.7429* 0.9348* 0.8324 0.8306 0.7372 0.9381*,1,TREC,True
355,bpref 0.7778 0.8360 0.7751 0.8397 0.7677 0.8650 0.7716 0.8432 0.7783 0.8405 0.7783 0.8405 0.7714 0.8597 0.7689 0.8489,0,,False
356,RBP 0.7980 0.7140 0.8071 0.8397 0.8302 0.7444 0.8155 0.7293 0.8089 0.7214 0.8089 0.7214 0.8220 0.7377 0.8180 0.7306,0,,False
357,"age values decrease as the pool reduction rate increases in a manner similare to AP and Rprec. Consistently with previous results, P@10 and RBP exhibit a more marked decrease while bpref tends to stay constant. This positive property of bpref is an indicator that it is not very sensible or it does not fully exploit the additional information which is provided when the pool increases.",1,AP,True
358,5.4 Effect of Incompleteness on Rank Correlation,0,,False
359,"Figure 4 shows the effect of reducing the pool size on the Kendall  correlation between each measure on the full pool and the pool at a given reduction rate. The results shown are consistent with previous findings as far as the measures of direct comparison are concerned, showing that bpref is almost always the more robust measure to pool reduction. It is indeed plausible that, keeping bpref the absolute average performances almost constant, also the ranking of the systems does not change much.",0,,False
360,"As far as MP is concerned, we can note that global models [GL], shown in the case of TREC 7, 8 and 10, tend to perform comparably to AP and, when provided with the same information about the recall base, which both AP and bpref exploit, they consistently improve their performances and, in the case of TREC 8, they outperform AP and perform closely to bpref. This is an interesting result since, unlike",1,TREC,True
361,"bpref, the absolute average performances of MP vary at different pool reduction rates, indicating that MP is able to exploit the variable amount of information available at different pool reduction rates, still not affecting too much the overall ranking of the systems.",0,,False
362,"The global models [GL] on only relevant documents [OR] behave consistently with the global ones on all documents [AD], shown in the case of TREC 7 and TREC 10, even if they are a little bit more resilient to the pool reduction. This is consistent with the fact that they use less information than the AD ones and so they are less sensitive to the pool size. The TREC 7 also shows the effect of using the inverse of the distance [ID] or the log of the inverse of the distance [LID], which provides more robustness to pool reduction.",1,TREC,True
363,"When it comes to local models [LO], these tend to behave comparably to the global ones in the case of all documents [AD], as can be noted in the case of TREC 8, while they are more affected by the pool reduction in the case of only relevant documents [OR], as can be noted in the case of TREC 14.",1,TREC,True
364,5.5 Time Calibration,0,,False
365,"On the basis of the click logs, 21% of the observed transitions are backward, a fact that validates our assumption that a user moves forward and backward along the ranked list.",0,,False
366,604,0,,False
367,Performances averaged over topics and runs,0,,False
368,0.45 0.4,0,,False
369,0.35 0.3,0,,False
370,0.25 0.2,0,,False
371,0.15 0.1,0,,False
372,0.05 0,0,,False
373,100%,0,,False
374,90%,0,,False
375,"TREC 07, 1998, Ad Hoc",1,TREC,True
376,GL_OR_ID GL_OR_ID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
377,70%,0,,False
378,50%,0,,False
379,Pool reduction rate,0,,False
380,30%,0,,False
381,10%,0,,False
382,Performances averaged over topics and runs,0,,False
383,0.45 0.4,0,,False
384,0.35 0.3,0,,False
385,0.25 0.2,0,,False
386,0.15 0.1,0,,False
387,0.05 0,0,,False
388,100%,0,,False
389,90%,0,,False
390,"TREC 08, 1999, Ad Hoc",1,TREC,True
391,70%,0,,False
392,50%,0,,False
393,Pool reduction rate,0,,False
394,GL_AD_ID GL_AD_ID@Rec(T) LO_AD_ID LO_AD_ID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
395,30%,0,,False
396,10%,0,,False
397,Performances averaged over topics and runs,0,,False
398,0.35 0.3,0,,False
399,0.25 0.2,0,,False
400,0.15 0.1,0,,False
401,0.05 0,0,,False
402,100%,0,,False
403,90%,0,,False
404,"TREC 10, 2001, Web",1,TREC,True
405,70%,0,,False
406,50%,0,,False
407,Pool reduction rate,0,,False
408,GL_AD_LID GL_AD_LID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
409,30%,0,,False
410,10%,0,,False
411,Performances averaged over topics and runs,0,,False
412,0.45 0.4,0,,False
413,0.35 0.3,0,,False
414,0.25 0.2,0,,False
415,0.15 0.1,0,,False
416,0.05 0,0,,False
417,100%,0,,False
418,90%,0,,False
419,"TREC 14, 2005, Robust",1,TREC,True
420,LO_AD_ID LO_AD_ID@Rec(T) LO_OR_ID LO_OR_ID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
421,70%,0,,False
422,50%,0,,False
423,Pool reduction rate,0,,False
424,30%,0,,False
425,10%,0,,False
426,Figure 3: Pool reduction rate (x axis) vs. performance averaged over topics and runs (y axis),0,,False
427,"TREC 07, 1998, Ad Hoc 1",1,TREC,True
428,0.9,0,,False
429,0.8,0,,False
430,0.7,0,,False
431,0.6 0.5 0.4 100%,0,,False
432,GL_OR_ID GL_OR_ID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
433,90%,0,,False
434,70%,0,,False
435,50%,0,,False
436,Pool reduction rate,0,,False
437,30%,0,,False
438,10%,0,,False
439,Kendalls  correlation,0,,False
440,1,0,,False
441,0.95,0,,False
442,0.9,0,,False
443,0.85,0,,False
444,0.8,0,,False
445,0.75,0,,False
446,0.7 0.65,0,,False
447,0.6 0.55,0,,False
448,0.5 100%,0,,False
449,GL_AD_ID GL_AD_ID@Rec(T) LO_AD_ID LO_AD_ID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
450,90%,0,,False
451,"TREC 08, 1999, Ad Hoc",1,TREC,True
452,70%,0,,False
453,50%,0,,False
454,Pool reduction rate,0,,False
455,30%,0,,False
456,10%,0,,False
457,Kendalls  correlation,0,,False
458,"TREC 10, 2001, Web 1",1,TREC,True
459,0.9,0,,False
460,0.8,0,,False
461,0.7,0,,False
462,0.6 0.5 0.4 100%,0,,False
463,GL_AD_LID GL_AD_LID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
464,90%,0,,False
465,70%,0,,False
466,50%,0,,False
467,Pool reduction rate,0,,False
468,30%,0,,False
469,10%,0,,False
470,Kendalls  correlation,0,,False
471,"TREC 14, 2005, Robust 1",1,TREC,True
472,0.9,0,,False
473,0.8,0,,False
474,0.7,0,,False
475,0.6 0.5 0.4 100%,0,,False
476,LO_AD_ID LO_AD_ID@Rec(T) LO_OR_ID LO_OR_ID@Rec(T) AP P@10 Rprec bpref RBP,1,AP,True
477,90%,0,,False
478,70%,0,,False
479,50%,0,,False
480,Pool reduction rate,0,,False
481,30%,0,,False
482,10%,0,,False
483,Figure 4: Pool reduction rate (x axis) vs. Kendall's rank correlation (y axis),0,,False
484,Kendalls  correlation,0,,False
485,"To compare the discrete-time version of MP with the continuous-time one, we have considered 3 runs with 5 relevant documents and estimated the parameters of the exponential holding times by the inverse of the sample mean of the time spent by the users visiting these states, multiplied by (n - 1)/n. We used the GL AD ID model and the values of discrete-time MP and continuous-time MP are reported in Table 4.",0,,False
486,"Note that the precisions at each fixed rank n of the first, second and third runs are decreasing and as one expects MP of the three runs is decreasing. However, since the (estimated) holding times of the first documents in the first run are very low, continuos-time MP is smaller for the first run. This clearly shows that the use of continuous-time MP depends heavily on the calibration of the holding times.",0,,False
487,6. CONCLUSIONS AND FUTURE WORK,0,,False
488,"We introduced a new family of measures, called MP, which exploit Markov chains in order to inject different user models and time into precision and which is not dependent on the recall base. This permitted us to overcome some of the traditional criticisms of AP (lack of a clear user model, dependence on the recall base) while still offering a measure which is AP when provided with the same amount of information about the recall base that AP exploits. Moreover, MP goes beyond almost all the evaluation measures allowing for non sequential scanning of the result lists.",1,ad,True
489,"We have proposed some basic user interaction models and validated their properties, in terms of correlation to other measures and robustness to pool reduction, thus showing it is as reliable as them. We have also found that some of these models have an extremely high correlation with AP and this can help in providing alternative interpretations of AP in the light of more complex user models and in explaining why AP is a ""gold standard"" in IR.",1,AP,True
490,"MP also bridges the gap between ""rank-oriented""and ""timeoriented"" measures, providing a single unified framework where both viewpoints can co-exist and allowing for direct",0,,False
491,"comparison among the values of the ""rank-oriented""(discretetime Markov chain) and ""time-oriented"" (continuous-time Markov chain) versions. We have also provided an example of how time can be calibrated using click logs from Yandex.",0,,False
492,"Future works concern the investigation of alternative user models able to account also for the number of relevant/not relevant documents visited so far ­ a kind of information which is actually available to a real user ­ by employing a multidimensional Markov chains to not violate the memoryless assumption. A further interesting option would also be to investigate whether click model-based IR measures [9] can be represented via the Markov chain and thus embedded in MP, i.e. whether the transition probabilities of the Markov chain can be learned directly from click-logs, thus leveraging models fully induced by user behaviour.",0,,False
493,"Another area of interest concerns how to calibrate time into MP: work on click model-based measures can shed some light in this respect and the techniques proposed by [30, 31] for calibrating time with respect to document length can link MP not only to click logs but also to document collections.",0,,False
494,"An interesting question for the future is whether MP could fit search tasks other than informational ones, such as fact, entity, or attributes focused searches or whether it could also work with other kinds of test collections, such as nuggetbased ones [24].",0,,False
495,"Finally, the robustness of MP could be further investigated, for example evaluating how it performs on condensedlists [27].",0,,False
496,Acknowledgements,0,,False
497,We wish to thank the anonymous reviewers and meta-reviewers whose comments and discussions helped us in improving the paper and better clarifying some angles of it.,0,,False
498,"The PREFORMA project5 (contract no. 619568), as part of the 7th Framework Program of the European Commission, has partially supported the reported work.",0,,False
499,5http://www.preforma-project.eu/,0,,False
500,605,0,,False
501,Table 4: Estimated parameters of the exponential holding times for three runs and values of the discrete-time,0,,False
502,and continuous-time MP.,0,,False
503,Run,0,,False
504,µ1,0,,False
505,µ2,0,,False
506,µ3,0,,False
507,µ4,0,,False
508,µ5,0,,False
509,µ6,0,,False
510,µ7,0,,False
511,µ8,0,,False
512,µ9,0,,False
513,µ10 disc MP cont MP,0,,False
514,"(1,1,1,1,0,0,0,1,0,0) 0.2000 0.0357 0.2000 0.0400 0.0056 0.0005 0.0035 0.0017 0.0034 0.0024 0.9205 0.6603",0,,False
515,"(1,1,1,0,1,0,0,0,1,0) 0.0177 0.0047 0.0037 0.0015 0.0041 0.0031 0.0057 0.0022 0.0061 0.0045 0.8668 0.8710",0,,False
516,"(1,1,0,1,1,0,0,0,0,1) 0.0056 0.0051 0.0062 0.0031 0.0046 0.0025 0.005 0.0022 0.007 0.005 0.8120 0.8001",0,,False
517,7. REFERENCES,0,,False
518,"[1] J. A. Aslam, E. Yilmaz, and V. Pavlu. The Maximum Entropy Method for Analyzing Retrieval Measures. In SIGIR, pages 27­34, ACM, 2005.",0,,False
519,"[2] A. Broder. A Taxonomy of Web Search. SIGIR Forum, 36(2):3­10, 2002.",0,,False
520,"[3] C. Buckley and E. M. Voorhees. Evaluating Evaluation Measure Stability. In SIGIR, pages 33­40, ACM, 2000.",0,,False
521,"[4] C. Buckley and E. M. Voorhees. Retrieval Evaluation with Incomplete Information. In SIGIR, pages 25­32. ACM, 2004.",0,,False
522,"[5] C. Buckley and E. M. Voorhees. Retrieval System Evaluation. In TREC. Experiment and Evaluation in Information Retrieval, pages 53­78. MIT Press, USA, 2005.",1,TREC,True
523,"[6] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected Reciprocal Rank for Graded Relevance. In CIKM, pages 621­630. ACM, 2009.",1,ad,True
524,"[7] B. Carterette. System Effectiveness, User Models, and User Utility: A Conceptual Framework for Investigation. In SIGIR, pages 903­912. ACM, 2011.",0,,False
525,"[8] F. Chierichetti, R. Kumar, and P. Raghavan. Optimizing Two-Dimensional Search Results Presentation. In WSDM, pages 257­266, ACM, 2011.",0,,False
526,"[9] A. Chuklin, P. Serdyukov, and M. de Rijke. Click Model-Based Information Retrieval Metrics. In SIGIR, pages 493­502, ACM, 2013.",0,,False
527,"[10] C. L. A. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. A Comparative Analysis of Cascade Measures for Novelty and Diversity. In WSDM, pages 84­75, ACM 2011.",1,ad,True
528,"[11] C. W. Cleverdon. The Cranfield Tests on Index Languages Devices. In Readings in Information Retrieval, pages 47­60. Morgan Kaufmann Publisher, Inc., USA, 1997.",1,ad,True
529,"[12] K. Collins-Thompson and J. Callan. Query Expansion Using Random Walk Models. In CIKM, pages 704­711. ACM, 2005.",1,Query,True
530,"[13] C. Danilowicz and J. Balin´ski. Document ranking based upon Markov chains. IPM, 37(4):623--637, July 2001.",0,,False
531,"[14] D. K. Harman. Overview of the Third Text REtrieval Conference (TREC-3). In D. K. Harman, editor, Overview of the Third Text REtrieval Conference (TREC-3) , pages 1­19. NIST, Special Pubblication 500-225, Washington, USA., 1994.",1,TREC,True
532,"[15] D. K. Harman. Information Retrieval Evaluation. Morgan & Claypool Publishers, USA, 2011.",0,,False
533,"[16] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated Gain-Based Evaluation of IR Techniques. ACM TOIS, 20(4):422­446, 2002.",0,,False
534,"[17] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and G. Gay. Accurately Interpreting Clickthrough Data as",0,,False
535,"Implicit Feedback. In SIGIR, pages 154­161, ACM, 2005. [18] M. G. Kendall. The Treatment of Ties in Ranking Problems. Biometrika, 33(3):239­251, 1945. [19] J. Lafferty and C. Zhai. Document Language Models, Query Models, and Risk Minimization for Information Retrieval. In SIGIR, pages 111­119, ACM, 2001. [20] K. T. Maxwell and W. B. Croft. Compact Query Term Selection Using Topically Related Text. In SIGIR, pages 583­592, ACM 2013. [21] A. Moffat, P. Thomas, and F. Scholer. Users Versus Models: What Observation Tells Us About Effectiveness Metrics. In CIKM, pages 659­668. ACM, 2013. [22] A. Moffat and J. Zobel. Rank-biased Precision for Measurement of Retrieval Effectiveness. ACM TOIS, 27(1):2:1­2:27, 2008. [23] J. R. Norris. Markov chains. Cambridge University Press, UK, 1998. [24] V. Pavlu, S. Rajput, P. B. Golbus, and J. A. Aslam. IR System Evaluation using Nugget-based Test Collections. In WSDM, pages 393­402, ACM, 2012. [25] S. Robertson. A New Interpretation of Average Precision. In SIGIR, pages 689­690. ACM, 2008. [26] T. Sakai. Ranking the NTCIR Systems Based on Multigrade Relevance. In AIRS 2004, pages 251­262. LNCS 3411, Springer, 2005. [27] T. Sakai. Alternatives to Bpref. In SIGIR, pages 71­78, ACM, 2007. [28] T. Sakai and Z. Dou. Summaries, Ranked Retrieval and Sessions: A Unified Framework for Information Access Evaluation. In SIGIR, pages 473­482, ACM, 2013. [29] P. Serdyukov, N. Craswell, and G. Dupret. WSCD2012: Workshop on Web Search Click Data 2012. In WSDM, pages 771­772. ACM, 2012. [30] M. D. Smucker and C. L. A. Clarke. Stochastic Simulation of Time-Biased Gain. In CIKM, pages 2040­2044. ACM, 2012. [31] M. D. Smucker and C. L. A. Clarke. Time-Based Calibration of Effectiveness Measures. In SIGIR, pages 95­104. ACM, 2012. [32] I. Soboroff. Dynamic Test Collections: Measuring Search Effectiveness on the Live Web. In SIGIR, pages 276­283. ACM, 2006. [33] E. Voorhees. Evaluation by Highly Relevant Documents. In SIGIR, pages 74­82, ACM, 2001. [34] E. M. Voorhees. Variations in relevance judgments and the measurement of retrieval effectiveness. IPM, 36(5):697­716, 2000. [35] E. Yilmaz and J. A. Aslam. Estimating Average Precision With Incomplete and Imperfect Judgments. In CIKM, pages 102­111. ACM, 2006.",1,Query,True
536,606,0,,False
537,,0,,False
