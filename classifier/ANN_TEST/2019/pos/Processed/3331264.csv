,sentence,label,data,regex
0,Session 9C: Learning to Rank 2,1,Session,True
1,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
2,Variance Reduction in Gradient Exploration for Online Learning to Rank,1,ad,True
3,"Huazheng Wang, Sonwoo Kim, Eric McCord-Snook, Qingyun Wu, Hongning Wang",0,,False
4,"Department of Computer Science, University of Virginia Charlottesville, VA 22904, USA",0,,False
5,"{hw7ww,sak2m,esm7ky,qw2ky,hw5x}@virginia.edu",0,,False
6,ABSTRACT,0,,False
7,"Online Learning to Rank (OL2R) algorithms learn from implicit user feedback on the fly. The key to such algorithms is an unbiased estimate of gradients, which is often (trivially) achieved by uniformly sampling from the entire parameter space. Unfortunately, this leads to high-variance in gradient estimation, resulting in high regret during model updates, especially when the dimension of the parameter space is large.",1,ad,True
8,"In this work, we aim at reducing the variance of gradient estimation in OL2R algorithms. We project the selected updating direction (i.e., the winning direction) into a space spanned by the feature vectors from examined documents under the current query (termed the ""document space"" for short), after an interleaved test. Our key insight is that the result of an interleaved test is solely governed by a user's relevance evaluation over the examined documents. Hence, the true gradient introduced by this test is only reflected in the constructed document space, and components of the proposed gradient which are orthogonal to the document space can be safely removed, for variance reduction purpose. We prove that this projected gradient is still an unbiased estimation of the true gradient, and show that this lower-variance gradient estimation results in significant regret reduction. Our proposed method is compatible with all existing OL2R algorithms which rank documents using a linear model. Extensive experimental comparisons with several state-of-the-art OL2R algorithms have confirmed the effectiveness of our proposed method in reducing the variance of gradient estimation and improving overall ranking performance.",1,ad,True
9,CCS CONCEPTS,0,,False
10,· Information systems  Learning to rank; · Theory of computation  Online learning algorithms;,0,,False
11,KEYWORDS,0,,False
12,Online learning to rank; Dueling bandit; Variance Reduction,0,,False
13,"ACM Reference Format: Huazheng Wang, Sonwoo Kim, Eric McCord-Snook, Qingyun Wu, Hongning Wang. 2019. Variance Reduction in Gradient Exploration for Online Learning to Rank . In Proceedings of the 42nd International ACM SIGIR",1,ad,True
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331264",1,ad,True
15,"Conference on Research and Development in Information Retrieval (SIGIR '19), July 21­25, 2019, Paris, France. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3331184.3331264",0,,False
16,1 INTRODUCTION,1,DUC,True
17,"Online Learning to Rank (OL2R) [6] is a family of online learning solutions, which exploit implicit feedback from users to directly optimize parameterized rankers on the fly. It has drawn increasing attention in research community in recent years due to its advantages over classical offline learning to rank algorithms [10]. First, it avoids the expensive and time consuming process of offline result relevance annotation. Second, as it directly learns from user feedback, it optimizes the ranking results to best reflect current user preferences [15]. Third, because the model is updated on the fly, there is no need to store user click history offline, which alleviates many privacy concerns [21].",1,ad,True
18,"One strain of OL2R algorithms, represented by Dueling Bandit Gradient Descent (DBGD) [24], optimize a linear scoring function by exploring the parameter space via interleaved test. Algorithms of this type first propose an exploratory direction as a tentative model update direction, and then update the current ranker if the proposed direction provides better ranking utility. In practice, result utility is usually inferred from user clicks on an interleaved list of ranking results from each ranker [23]. The key technical insight of DBGD-type algorithms is that the expectation of selected directions is an unbiased estimate of true gradient of the unknown loss function for ranking [5]. As a result, DBGD is essentially a stochastic online gradient descent algorithm. However, because the exploration directions are uniformly sampled from the entire parameter space, when the dimensionality of the space is high (which is usually the case in practice), the variance in gradient estimation becomes large. This directly slows down the learning convergence of the algorithm and inevitably increases sample complexity.",1,ad,True
19,"Recently, several works in OL2R have realized this deficiency of gradient exploration in DBGD, and propose various types of solutions to improve its learning efficiency. One type of studies explore multiple random directions in each iteration of model update. Unbiased estimate of gradient is maintained in this type of revisions of DBGD, as the directions are still uniformly sampled. Model estimation variance is expected to be reduced by testing more exploratory directions; but, in practice, as the users would only examine a finite number of documents under each query (e.g., due to position bias [9]), the sensitivity of interleaved test drops as a result of more exploratory rankers having to be tested at once. This unfortunately introduces additional variance in model estimation. Another type of research constrains the sampling space for gradient exploration. However, this line of solutions cannot guarantee the",1,ad,True
20,835,0,,False
21,Session 9C: Learning to Rank 2,1,Session,True
22,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
23,"estimated gradient remains unbiased, and thus face high risk of converging towards a sub-optimal solution.",1,ad,True
24,"Although empirically effective, previous OL2R solutions neglect an important property of click-based result utility evaluation: users only perceive utility from the documents that they actually examine. As a result, the true gradient is only revealed by features playing an essential role in ranking those examined documents under this query. Here we define essential features in ranking a particular set of documents as those features with non-zero variance among the documents. Assume in an interleaved test, one ranking feature takes a constant value in all examined documents under this query, such that it has no effect in differentiating the quality of those documents. Then, the proposed exploratory direction's contribution to the ranker update on this particular dimension cannot be justified by this test result. Random gradient exploration hence introduces an arbitrary update on this dimension, which inevitably leads to high estimation variance over time. This example can be generalized to situations where multiple (even correlated) features have no effect in differentiating the utility of examined documents in the result of an interleaved test. Because in practice users usually only examine a handful of documents under each query [4, 9], but each document consists of hundreds or even thousands of ranking features, the variance introduced by random exploration on those non-essential features could be considerably large.",1,ad,True
25,"The above analysis suggests that an interleaved test only reveals the projection of true gradient in the spanned space of examined documents under a test query (termed the ""document space"" in this paper). With this as our motivation, we decide to project the winning direction back into the document space so as to reduce the variance introduced by random gradient exploration. We construct the document space from inferred users' result examinations [4], which are not observable in the user response but can be statistically modeled. Because this projection is independent from how the proposal directions are created, this solution can be directly applied to any DBGD-type OL2R algorithm. We theoretically prove that the projected direction is still an unbiased estimate of the true gradient, i.e., model convergence is guaranteed, and also prove the reduced variance directly leads to considerable regret reduction in online model update. We compare the proposed method with several stateof-the-art OL2R algorithms on a collection of large-scale learning to rank datasets and confirmed the effectiveness of our method.",1,ad,True
26,2 RELATED WORK,0,,False
27,"One key family of OL2R methods root in Dueling Bandit Gradient Descent (DBGD) [24], which uses online gradient descent to solve a bandit convex optimization problem [5]. In each iteration, DBGD uniformly samples a random direction from the entire parameter space to create an exploratory ranker, and uses an interleaved test [15] to compare the current ranker with the exploratory one. If the exploratory ranker is preferred, the proposed direction is used as the gradient to update the model. This procedure yields an unbiased estimate of the true gradient [22]. However, the variance of DBGD's gradient estimation is high due to the nature of uniform exploration of the entire parameter space, which limits its learning efficiency.",1,ad,True
28,"Recently, attempts have been made to improve the learning efficiency of DBGD-type algorithms. Schuth et al. [17] proposed a",1,ad,True
29,"Multileave Gradient Descent (MGD) algorithm to explore multiple stochastic directions in each iteration with multi-interleaving comparison [18]. Zhao and King [25] developed a Dual-Point Dueling Bandit Gradient Descent algorithm to sample two stochastic vectors with opposite directions as the candidate gradients. The basic idea of this line of solutions is to test more exploratory directions at once so as to obtain the true gradient estimate sooner. However, their gradient exploration is still within the entire feature space. As users often only examine a small number of documents under each query, the sensitivity of interleaved test drops due to more exploratory rankers needing to be tested. In a different direction of solutions, researchers proposed to constrain the sampling space for gradient exploration. Hofmann et al. chose to filter the stochastic directions by historical comparisons before an interleaved test [7]. Oosterhuis et. al [12] proposed exploring gradients in a subspace constructed by a set of preselected reference documents from an offline training corpus. Wang et al. [20] proposed using historical interactions to avoid repeatedly exploring less promising directions, which also reduces gradient exploration to a subspace. However, the variance of gradient exploration is reduced at a cost of introducing bias into gradient approximation, so that such algorithms have a risk of converging to sub-optimal results.",1,ad,True
30,"Our solution falls into this second category of variance reduction for DBGD-type algorithms. Distinct from previous attempts to restrict gradient exploration before an interleaved test, we instead modify the selected direction after the test. As users' result examination is affected by the ranked results, which are in turn determined by the proposed exploratory directions, restricting the exploration space before the interleaved test potentially introduces bias in the subsequent interleaved test and model update. Our solution is based on the insight that only the projected true gradient in the document space can be revealed by an interleaved test. Hence, we decide to project the selected direction after each interleaved test, and thus guarantee an unbiased estimate of true gradient. Since the document space is expected to be smaller than the entire parameter space (as it is constructed only by the examined documents), the projected gradient enjoys low variance and leads to faster model convergence in online update.",1,ad,True
31,3 METHOD,0,,False
32,"In this section we describe our proposed document space gradient projection method for online learning to rank. We first describe the problem setup in Section 3.1. And then we describe Document Space Projected Dueling Bandit Gradient Descent (DBGD-DSP) algorithm as an example of our proposed general solution in Section 3.2. Our gradient projection method is independent from how the exploratory gradient is proposed, and thus can be directly applied to any existing DBGD-type algorithm to reduce its variance of gradient estimation. We rigorously prove the unbiasedness of our gradient estimation in Section 3.3 and analyze the regret of DBGDDSP in Section 3.4. The same procedure and conclusions can be applied to any DBGD-type algorithm of interest.",1,ad,True
33,3.1 Problem Setup,0,,False
34,"The estimation of OL2R models can be formalized as a dueling bandit problem [24]. In iteration t, an OL2R algorithm receives a",0,,False
35,836,0,,False
36,Session 9C: Learning to Rank 2,1,Session,True
37,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
38,"query and associated candidate documents, which are represented as a set of d-dimensional query-document pair feature vectors Xt ,"" {x1, x2, ..., xs }. The algorithm takes two actions: first, it proposes two rankers, whose parameters are denoted as w, w ;""",0,,False
39,"second, it ranks the given documents with these two rankers ac-",0,,False
40,"cordingly. An oracle (i.e., user) compares (duels) the two rankers'",0,,False
41,"results and provides feedback. In practice, an interleaving method",0,,False
42,[15] is applied to merge the ranking lists of the two rankers and,0,,False
43,display the resulting ranked list to the user. User preference is in-,0,,False
44,"ferred from the click feedback. Thus, the ranker that contributes more clicked documents is preferred. We denote w  w  for the event that w is preferred over w . The comparison between two",0,,False
45,"individual rankers is determined independently of other comparisons performed before with a probability P (w  w |Xt ), such that P (w  w |Xt ) , Pt (w  w ) ,"" ft (w, w ). ft (w, w ) can be viewed as the distinguishability of the two rankers w and w  by an interleave comparison under query Xt .""",0,,False
46,We quantify the performance of an online learning algorithm,0,,False
47,using cumulative regret defined as follows:,0,,False
48,T,0,,False
49,"R(T ) ,"" ft (w, wt ) + ft (w, wt),""",0,,False
50,(1),0,,False
51,"t ,1",0,,False
52,"where wt and wt are rankers compared at time t, and w is the best",0,,False
53,"ranker in ground-truth. As a result, the distinguishability measure",0,,False
54,"ft (w, w) indicates the loss of proposing a sub-optimal ranker w. We denote ft (wt , w) as ft (w) for simplicity. The goal of an OL2R algorithm is to optimize its parameter towards w according to loss",0,,False
55,"ft (w). A desired OL2R algorithm should have a sublinear regret in a finitie time horizon T , so that the one-step regret is quickly",0,,False
56,decreasing to zero over time.,0,,False
57,"In this work, we make the following assumptions similar to [24].",0,,False
58,"We assume an unknown utility function vt (w) that quantifies the quality of a ranker w over query Xt . The utility function vt is assumed to be differentiable, strongly concave and Lv -Lipschitz, which means |vt (x) - vt (y)|  Lv |x - y|.",0,,False
59,A link function  describes the probabilistic comparison of utili-,0,,False
60,"ties of two rankers as,",0,,False
61,"Pt w  w  ,"" ft (w, w ) "",  vt (w) - vt (w ) .",0,,False
62,"The link function should be rotation-symmetric, which means",0,,False
63," (x) , 1 -  (-x). We assume the link function is L -Lipschitz and second order L2-Lipschitz. The link function behaves like a",0,,False
64,"cumulative probability distribution function. For example, a com-",0,,False
65,"mon choice of link function is the standard logistic function  (x) ,",0,,False
66,1,0,,False
67,"1+exp(-x) , which satisfies all the assumptions.",0,,False
68,3.2 Document Space Projected Dueling Bandit Gradient Descent,1,ad,True
69,We describe our proposed Document Space Projected Dueling Ban-,0,,False
70,"dit Gradient Descent (DBGD-DSP) in Algorithm 1. We should note it fits all OL2R algorithm settings. At the beginning of iteration t, user initiates a query Xt . We denote wt as the parameter of the current ranker. DBGD-DSP first uniformly samples a vector ut from d dimensional unit sphere Sd-1 (i.e., |ut |2 ,"" 1) as an exploratory direction, and proposes a candidate ranker wt "","" wt + ut , where  is the step size of exploration. The algorithm then uses the two""",1,ad,True
71,Algorithm 1 Document Space Projected Dueling Bandit Gradient,1,ad,True
72,Descent (DBGD-DSP),0,,False
73,"1: Inputs:  , ",0,,False
74,"2: Initiate w1 , sample_unit_vector() 3: for t , 1 to T do",0,,False
75,"4: Receive query Xt ,"" {x1, x2, ..., xs } 5: ut "", sample_unit_vector() 6: wt ,"" wt + ut 7: Generate ranked lists l(Xt , wt ), l(Xt , wt) 8: Set Lt "","" Interleave {l(Xt , wt ), l(Xt , wt)} , and present Lt""",0,,False
76,to user,0,,False
77,"9: Receive click positions Ct on Lt , and infer click credits",0,,False
78,10:,0,,False
79,"{ct , ct } if ct",0,,False
80, ct,0,,False
81,then,0,,False
82,11:,0,,False
83,"wt +1 , wt",0,,False
84,12: else,0,,False
85,13:,0,,False
86,"Based on Ct , infer user examined top mt documents in",0,,False
87,Lt .,0,,False
88,14:,0,,False
89,Solve the orthogonal projection matrix At for document,0,,False
90,"space St ,"" span({xLt,1, xLt,2, ..., xLt,mt }).""",0,,False
91,15:,0,,False
92,"Project ut onto St by t , Atut",0,,False
93,16:,0,,False
94,"wt +1 , wt + t",0,,False
95,17: end if,0,,False
96,18: end for,0,,False
97,"rankers (wt and wt) to generate ranking lists l(Xt , wt ) and l(Xt , wt) accordingly, and combines them with an interleaving method, such",0,,False
98,as Team Draft Interleaving [15] or Probabilistic Interleaving [8]. The,0,,False
99,user examines the result list and provides implicit click feedback,0,,False
100,to indicate their relevance evaluation of the results. The interleav-,0,,False
101,ing method uses this implicit feedback to infer which ranker is,0,,False
102,"preferred by the user. If the exploratory ranker is preferred (i.e.,",0,,False
103,"wins the duel), previous DBGD-style algorithms update the current ranker by wt+1 ,"" wt + ut , where  is the learning rate; otherwise the current ranker stays intact. This gradient exploration strategy""",1,ad,True
104,"yields an unbiased estimate of the true gradient [5], in terms of",1,ad,True
105,"expectation. However, since the exploratory gradient ut is required to be uni-",1,ad,True
106,"formly sampled from the entire d dimensional unit sphere Sd-1, the model update suffers from high variance in its gradient estimation, especially when d is large, as in practice. Various improvements to this issue have been proposed in the past, but they still introduce",1,ad,True
107,"other difficulties, such as variance and bias trade-off [7, 12, 20], and",1,ad,True
108,"test sensitivity and efficiency [18, 25].",0,,False
109,Unlike previous works that reduce the sampling space of gradi-,1,ad,True
110,"ent exploration before the interleaved test [7, 12, 20], we change",0,,False
111,"the winning direction after the test. The key insight is that only the projected true gradient in the spanned space of examined documents under query Xt (denoted as document space St ) can be revealed by an interleaved test. For example, as shown in Figure 1, a DBGD-style algorithm is comparing the current ranker wt and wt ,"" wt + ut with a uniformly sampled exploration direction ut . The user examines top m documents, e.g., {x1, ..xm }, of the interleaved ranking list (of course m is unknown to the algorithm) and wt wins the duel. The estimated gradient ut can therefore be separated into two components, one component t that belongs to""",1,ad,True
112,837,0,,False
113,Session 9C: Learning to Rank 2,1,Session,True
114,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
115,ut gt,0,,False
116,S t',0,,False
117,gt',0,,False
118,w tS,0,,False
119,t,0,,False
120,w t',0,,False
121,w*,0,,False
122,u t',0,,False
123,w,0,,False
124,w,0,,False
125,Figure 1: Illustration of model update for DBGD-DSP in a,0,,False
126,"three dimensional space. Dashed lines represent the trajectory of DBGD following different update directions. ut is the selected direction by DBGD, which is in the 3-d space. Red bases present the document space St on a 2-d plane. ut is projected onto St to become t for model update.",0,,False
127,"the document space St ,"" span{x1, ..xm } and the other component ut - t that is orthogonal to document space St . The orthogonal component ut -t does not affect the ranking among the examined documents, i.e. (wt + ut )T xi "","" (wt + t )T xi , and thus does not contribute to the loss function and true gradient estimation. Intuitively, ut - t is not supported by the observed interleaved test, as anything sampled from the complement of St cannot be verified by the examined documents. As a result, it is safe to exclude the direction ut -t from model update, which we later prove maintains the unbiasedness of the original DBGD-type gradient estimation, and reduces the variance. As illustrated in Figure 1, although ut will eventually lead to the same model estimation, as it is unbiased, this""",1,ad,True
128,guarantee is only obtained in expectation. The variance could po-,0,,False
129,"tentially be large: for example, the blue and purple updating traces",0,,False
130,"slow down model convergence, when the number of observations",0,,False
131,is finite.,0,,False
132,"As shown in line 14 to 16 of Algorithm 1, we solve for the orthogonal projection matrix At of document space St , and project the selected direction ut onto the document space St after each interleaved test. We leave the detailed design of constructing document space and solving projection matrix At in Section 3.5. Before that, we first rigorously prove the projection maintains an unbiased",0,,False
133,estimate of true gradient in Section 3.3. Since the document space is,1,ad,True
134,"constructed only by the examined documents, the rank of document",0,,False
135,space is expected to be smaller than the entire parameter space.,0,,False
136,This directly leads to lower variance and faster model convergence.,1,ad,True
137,"We show that our document space projection reduces the variance of gradient estimation from d to Rank(At ) in Section 3.4, and then analyze its benefit for regret reduction from low-variance gradient",1,ad,True
138,estimation.,0,,False
139,3.3 Unbiasedness of Gradient Estimation,1,ad,True
140,We now prove that our document space projected gradient is an,1,ad,True
141,"unbiased estimate of true gradient in the sense of expectation [24]. We define Zt (w) as the event of w winning the duel with wt ,",1,ad,True
142,"Zt (w) ,",0,,False
143,1 w.p. 1 - Pt (wt  w) 0 w.p. Pt (wt  w),0,,False
144,"Then the gradient used for model update in DBGD-DSP (as described in Algorithm 1) can be described as,",1,ad,True
145,"ht , -Zt (wt + ut )t .",0,,False
146,(2),0,,False
147,"Note that by adding a negative sign we view our model update as online gradient descent wt +1 , wt - t .",1,ad,True
148,We now show in the following theorem that this is an unbiased,0,,False
149,"gradient estimation of true gradient. By defining a smoothed version of ft as f^t (w) ,"" Eu B[ft (w + u)], we have:""",1,ad,True
150,"Theorem 3.1. The projected gradient t in DBGD-DSP is an unbiased estimate of true gradient, i.e.,",1,ad,True
151,E[ht ],0,,False
152,",",0,,False
153, d,0,,False
154,f^t,0,,False
155,(w,0,,False
156,),0,,False
157,(3),0,,False
158,over random unit vector ut .,0,,False
159,"Proof. Based on the Lemma 1 of [24], we have",0,,False
160,"E [ht ] , E [-Zt (wt + ut )At ut ] , Eut Sd-1 [ft (w +  At ut )ut ] Define Ft (w) ,"" ft (At w), we have""",0,,False
161,"E[ht ] , Eut Sd-1 [ft (wt +  At ut )ut ]",0,,False
162,", Eut Sd-1 [Ft (At-1wt + ut )ut ]",0,,False
163,",",0,,False
164, d,0,,False
165,Eut Bd [Ft (At-1wt,0,,False
166,+ ut )ut ],0,,False
167,",",0,,False
168, d,0,,False
169,F^t (At-1wt ),0,,False
170,",",0,,False
171, d,0,,False
172,At f^t (wt ),0,,False
173,",",0,,False
174, d,0,,False
175,f^t (wt ),0,,False
176,where the fourth equality is based on Stokes' Theorem. The last,0,,False
177,equality holds because gradient f^t (wt ) belongs to document space,1,ad,True
178,"St , and thus projecting it by At maps back to itself.",0,,False
179,"The guarantee of unbiased gradient estimation is a major advantage of our proposed document space gradient projection method, compared with previous attempts to reduce the gradient exploration space, such as Oosterhuis et. al [12] and Wang et al. [20]. Our method enjoys reduced variance of gradient estimate (which will be proved next), without the risk of converging towards a suboptimal solution. We should note that the above is independent from the mechanism of how the proposal directions are generated, as shown in the first four steps of proof above. As a result, if the input direction to our projection procedure is unbiased, the resulting update direction is also unbiased. This enables our solution's generalization to other types of DBGD algorithms.",1,ad,True
180,3.4 Regret Analysis of DBGD-DSP,0,,False
181,"We now analyze the regret of our proposed DBGD-DSP algorithm, starting with its variance of gradient update.",1,ad,True
182,Lemma 3.2. The variance of gradient update in DBGD-DSP is bounded by,1,ad,True
183,"E[|ht |2] , Eut Sd-1",0,,False
184,| - Zt (wt + ut )Atut |2,0,,False
185, Rank(At ) . d,0,,False
186,838,0,,False
187,Session 9C: Learning to Rank 2,1,Session,True
188,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
189,Proof.,0,,False
190,"E[|ht |2] , Eut | - Zt (wt + ut )Atut |2",0,,False
191," Eut |At ut |2 , Eut (At ut )(At ut ) , tr Eut AtututAt //apply the trace trick , tr At Eut ut ut At",0,,False
192,", tr",0,,False
193,At,0,,False
194,1 d,0,,False
195,I,0,,False
196,At,0,,False
197,",",0,,False
198,1 tr,0,,False
199,d,0,,False
200,At At,0,,False
201,"1 , d tr (At ) //a projection matrix is idempotent",0,,False
202,",",0,,False
203,Rank(At ) d,0,,False
204,where tr(·) denotes the matrix trace operation. The sixth equality,0,,False
205,"holds because ut is uniformly sampled from a unit sphere, and",0,,False
206,its covariance matrix Eut,0,,False
207,ut ut,0,,False
208,is,0,,False
209,1 d,0,,False
210,I,0,,False
211,.,0,,False
212,Since,0,,False
213,At,0,,False
214,is,0,,False
215,an,0,,False
216,orthogonal,0,,False
217,"projection matrix, the eighth equality holds for At At , At . ",0,,False
218,Remark. The variance of gradient update in DBGD [24] is bounded by Eut | - Zt (wt + ut )ut |2  1.,1,ad,True
219,Comparing the variance of gradient update in DBGD-DSP with,1,ad,True
220,"DBGD,",0,,False
221,our,0,,False
222,method,0,,False
223,reduces,0,,False
224,the,0,,False
225,variance,0,,False
226,from,0,,False
227,1,0,,False
228,to,0,,False
229,Rank(At d,0,,False
230,),0,,False
231,.,0,,False
232,Since,0,,False
233,"the dimension of projection matrix At is d-by-d, we have Rank(At ) ",0,,False
234,"d, which guarantees the reduction of variance in DBGD-DSP com-",0,,False
235,"paring to that in DBGD. The rank of At is also bounded by the number of examined documents mt , since document space St is constructed by these mt examined documents. In practice, users",0,,False
236,"would only examine a handful of documents [4, 9], while the rank-",0,,False
237,"ing feature dimension is expected to be much larger. We argue that mt  d, such that our document space projection achieves considerable variance reduction.",0,,False
238,The significance of this variance reduction can be intuitively,0,,False
239,understood from Figure 1: though different traces of model update,0,,False
240,"would eventually lead to the same converged model, if one has a",1,ad,True
241,"sufficiently large amount of interactions with users, the one with",0,,False
242,lower variance would always require less observations. A faster,0,,False
243,"converging algorithm leads to user satisfaction earlier. Next, we",1,ad,True
244,verify this benefit by proving the reduction of regret introduced by,0,,False
245,the reduced variance in gradient estimation.,1,ad,True
246,Theorem 3.3. By setting,0,,False
247,m,0,,False
248,",",0,,False
249,max,0,,False
250,t,0,,False
251,mt,0,,False
252,",",0,,False
253,",",0,,False
254," 2Rm ,  13LT 1/4",0,,False
255,",",0,,False
256,Rm ,0,,False
257,",",0,,False
258,T,0,,False
259,the expected regret of DBGD-DSP as defined in Eq (1) is upper bounded,0,,False
260,"by,",0,,False
261,"E[Re]  2T T 3/426RmL,",0,,False
262,(4),0,,False
263,where,0,,False
264,T,0,,False
265,",",0,,False
266,L,0,,False
267, 13LT,0,,False
268,1/4,0,,False
269,L 13LT 1/4 - Lv L2 2Rm,0,,False
270,"The proof is obtained by extending Theorem 2 in [24]. We omit the details due to space limit, and emphasize that the key difference is introduced by replacing variance of gradient estimation from",1,ad,True
271,Eut | - Zt (wt + ut )ut |2 to Eut | - Zt (wt + ut )Atut |2 . Since,0,,False
272,the the,0,,False
273,variance regret of,0,,False
274,of gradient estimation is reduced ,1,ad,True
275,DBGD can be reduced from O( dT,0,,False
276,from 1 3/4) to,0,,False
277,"Oto(RmanTkd(3A/t4)),,",0,,False
278,where m is the maximum number of documents included in a docu-,0,,False
279,"ment space under a single query. Again, as the number of included",0,,False
280,ranking features is oftentimes much larger than the number of doc-,0,,False
281,"uments a user would examine under a single query, the reduction of",0,,False
282,"regret is considerable. Moreover, as the reduction of variance from",0,,False
283,our project-based method is independent from the way about how,0,,False
284,"the proposal directions are generated, our method can be generally",0,,False
285,applied to most existing DBGD-type OL2R algorithms to improve,0,,False
286,their learning convergence.,0,,False
287,3.5 Practical Treatments of Document Space Projection,0,,False
288,Now we discuss several practical treatments of our proposed Docu-,0,,False
289,"ment Space Projection method, including the construction of docu-",0,,False
290,ment space and orthogonal projection matrix.,0,,False
291,"In our theoretical analysis, we have assumed the knowledge of",0,,False
292,users' examined documents and corresponding projection matrix.,0,,False
293,"However, in practice, a user's result examination is unobserved.",0,,False
294,A rich body of research has been developed to perform statistical,0,,False
295,"inference of it, collectively known as click modeling [3, 4]. Any",0,,False
296,of these existing click modeling solutions can be plugged into our,0,,False
297,"solution framework, i.e., line 13 of Algorithm 1. In this work, we",0,,False
298,"simply follow [9] to infer user examination by the last clicked position: given the click position list Ct , we use the last clicked position cl,t to approximate the last examined position Mt by setting Mt ,"" cl,t + k, where k is a hyper-parameter. Based on sequential examination hypothesis of click modeling, every document before the last clicked position is examined, and we use k to approximate the number of positions following the last clicked position that""",0,,False
299,was still examined. We leave more comprehensive study of click,0,,False
300,modeling in our solution as future work.,0,,False
301,"The above treatment provides a reasonable inference of examined documents. However, it requires a careful choice of k for each query (preferably). If k is set too large, variance of gradient estimate will increase (as proved in Lemma 3.2). If k is too small, the document space may not include all examined documents, and it is",1,ad,True
302,at risk of introducing bias in gradient projection. To avoid bias in,1,ad,True
303,"constructing the document space, we also consider adding histori-",1,ad,True
304,"cally examined documents to the current query's document space. Specifically, we add r recently examined documents to the current document space St to compensate the potentially overlooked examined documents in the current query.",1,ad,True
305,"In line 14 of Algorithm 1, we solve the orthogonal projection matrix At of document space St . At could be computed by several methods. Denote Dt as a d-by-mt matrix where each column is the feature vector for an examined document. One can use QR decom-",0,,False
306,"position or Singular Value Decomposition (SVD) to solve for its orthonormal basis Vt , and projection matrix can then be constructed by At ,"" VtVtT . In our experiments, we chose SVD for constructing the basis of document space, because of its widely available and""",0,,False
307,efficient large-scale implementation. But the choice for the con-,0,,False
308,struction of this project matrix does not affect the convergence nor,0,,False
309,unbiasedness of our proposed solution.,0,,False
310,839,0,,False
311,Session 9C: Learning to Rank 2,1,Session,True
312,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
313,4 EXPERIMENTS,0,,False
314,"To demonstrate our proposed Document Space Projection method's empirical efficacy, we compare the performance of several state-ofthe-art OL2R algorithms on five public learning to rank datasets, with and without our document space projection method applied.",0,,False
315,4.1 Experiment Setup,0,,False
316,"· Datasets. We tested our algorithms and the baselines on five benchmark datasets: including MQ2007, MQ2008, NP2003 [11], MSLR-WEB10K [14], and the Yahoo! Learning to Rank Challenge dataset [2]. In each of the five datasets, each query-document pair is encoded as a vector of ranking features. These features include PageRank, TF.IDF, Okapi-BM25, URL length, language model score, and many more varied by dataset.",1,MQ,True
317,"The MQ2007 and MQ2008 datasets are collected from the 2007 and 2008 Million Query track at TREC [19]. MQ2007 contains about 1700 queries, and MQ2008 contains about 800 queries, which represent a mix of informational and navigational search intents. They both have 46-dimensional feature vectors to represent querydocument pairs, and the document relevance are labeled in three grades: 0 (not relevant), 1 (relevant), and 2 (most relevant).",1,MQ,True
318,"The NP2003 dataset also comes from the TREC Web track, consisting of queries crawled from the .gov domain. It is comprised of about 150 navigational-focused queries, with over 1000 document relevance assessments per query. It uses 64 ranking features, and the document relevance labels are binary (0 and 1 only).",1,NP,True
319,"The MSLR-WEB10K dataset was released by Microsoft in 2010, and consists of 10,000 queries with relevance assessments coming from a labeling set from the Microsoft Bing search engine. It has 136 ranking features, and the relevance judgments range from 0 (not relevant) to 4 (most relevant).",1,MSLR,True
320,"The Yahoo! Learning to Rank Challenge dataset was also released in 2010, as an effort on part of Yahoo! to promote the dataset as well as research into better learning to rank algorithms. The dataset contains about 36,000 queries, 883,000 assessed documents, and 700 ranking featuress. Again, the relevance judgments range from 0 (not relevant) to 4 (most relevant)",1,Yahoo,True
321,"This diversity in the structure of the datasets that we chose to test on helps us to evaluate our algorithms more holistically. While small, the MQ2007 and MQ2008 sets have been around for a long time and have a good mix of query types. NP2003 gives us insight into how the algorithms perform on navigational search intents specifically, which are markedly different in nature from informational search intents. MSLR-WEB10K and the Yahoo! dataset are large-scale datasets used by actual commercial search engines, which give us a better understanding of how the algorithms perform in practice. Since each dataset was split into training, testing, and validation subsets, we used the training sets for online experiments to measure cumulative performance, and used the testing sets for evaluating offline performance. · Simulated User Interactions. Based on an online learning to rank framework proposed in [13], we use the standard setup to simulate user interactions. Within this framework, we used the Cascade Click Model to simulate user click behavior. This model assumes that a user interacts with a set of search results by linearly scanning the list from top and making a decision for each document",1,MQ,True
322,Table 1: Configurations of simulation click models.,0,,False
323,Click Probability,0,,False
324,Stop Probability,0,,False
325,R 0 123 4 01234,0,,False
326,Per 0.0 0.2 0.4 0.8 1.0 0.0 0.0 0.0 0.0 0.0,0,,False
327,Nav 0.05 0.3 0.5 0.7 0.95 0.2 0.3 0.5 0.7 0.9,0,,False
328,Inf 0.4 0.6 0.7 0.8 0.9 0.1 0.2 0.3 0.4 0.5,0,,False
329,"as to whether or not to click. In the model, the probability of a click for a given document is conditioned on the relevance label of that document, as a user is expected to be more likely to click on relevant documents. After evaluating each document, the user must decide whether or not to continue perusing the list. This decision's probability distribution is again conditioned on the relevance of the current document, as a user is more likely to stop looking through the results if he/she has already satisfied their information need. These aforementioned probabilities can be altered to simulate different types of users and interactions.",1,ad,True
330,"As illustrated in Table 1, we use three different click model probability configurations to represent three different types of users. First, we have the perfect user, who clicks on all relevant documents and does not stop browsing until they have visited all of the documents. This type of users contribute the least noise, as they make no mistakes and the feedback is entirely accurate. Second, we have the navigational user, who is very likely to click on the first highly relevant document that he/she sees and stops there. Third, we have the informational user, who, in his/her search for information, sometimes clicks on irrelevant documents, and as such contributes a significant amount of noise in click feedback. · Evaluation Metrics. As set forth in [16], cumulative (online) Normalized Discounted Cumulative Gain (NDCG) and offline NDCG are commonly used metrics for evaluating OL2R algorithms. Cumulative NDCG is calculated by summing NDCG scores from successive iterations with a discount factor  set to 0.995. We assess our model's estimation convergence via cosine similarity between the current weight vector and a reference weight vector (considered to be the optimal vector) as estimated by an offline learning-to-rank algorithm trained with the complete true relevance judgment labels. Due to its superior empirical performance, we used LambdaRank [1] with no hidden layer in our experiments to estimate this reference weight vector. In each experiment, the number of iterations T was set to 10,000, and the current query Xt was randomly sampled from the dataset in each iteration. We execute all the experiments 15 times with different random seeds, and report and compare the average performance in all experiments. · Evaluation Questions. To better understand the advantages of our proposed algorithms, we aim to answer the following evaluation questions through the course of our experiments.",1,ad,True
331,Q1: Can our proposed Document Space Projection method consistently improve the performance of state-of-the-art OL2R algorithms?,0,,False
332,Q2: Do gradients rectified by our document space projection explore the gradient space more efficiently?,1,ad,True
333,Q3: How do different hyper-parameter settings alter the performance of our document space projection?,0,,False
334,· Baseline Algorithms. We choose the following three state-ofthe-art OL2R algorithms as our baselines for comparison:,0,,False
335,840,0,,False
336,Session 9C: Learning to Rank 2,1,Session,True
337,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
338,NDCG NDCG NDCG,0,,False
339,0.72 perfect,0,,False
340,0.70,0,,False
341,0.68,0,,False
342,0.66,0,,False
343,0.64,0,,False
344,0.62 0,0,,False
345,2000,0,,False
346,4000,0,,False
347,6000,0,,False
348,Impressions,0,,False
349,(a) Perfect,0,,False
350,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
351,8000,0,,False
352,10000,0,,False
353,0.72 navigational,0,,False
354,0.70,0,,False
355,0.68,0,,False
356,0.66,0,,False
357,0.64,0,,False
358,0.62,0,,False
359,0.60,0,,False
360,0.58 0,0,,False
361,2000,0,,False
362,4000,0,,False
363,6000,0,,False
364,Impressions,0,,False
365,8000,0,,False
366,(b) Navigational,0,,False
367,10000,0,,False
368,0.70 informational,0,,False
369,0.68,0,,False
370,0.66,0,,False
371,0.64,0,,False
372,0.62,0,,False
373,0.60,0,,False
374,0.58,0,,False
375,0.56 0,0,,False
376,2000,0,,False
377,4000,0,,False
378,6000,0,,False
379,Impressions,0,,False
380,8000,0,,False
381,(c) Informational,0,,False
382,10000,0,,False
383,Figure 2: Offline NDCG@10 on Yahoo! dataset.,1,Yahoo,True
384,- DBGD [24]: A single direction uniformly sampled from the whole parameter space is explored.,0,,False
385,"- MGD [17]: Multiple directions are explored in one iteration to reduce the gradient estimation variance. Multileaving is used to compare multiple rankers. If there is a tie, the model updates towards the mean of all winners.",1,ad,True
386,- NSGD[20]: Multiple directions are sampled from the null space of previously poorly performing gradients. Ties are broken by evaluating the tied candidate rankers on a recent set of difficult queries.,1,ad,True
387,"We apply our proposed Document Space Projection to the baseline algorithms, and compare them with DBGD-DSP, MGD-DSP and NSGD-DSP, respectively.",0,,False
388,4.2 Performance of Document Space Projection,0,,False
389,"We begin our experimental analysis by answering our first evaluation question. We compared all algorithms over 3 click models and 5 datasets. We set the hyper-parameters of DBGD, MGD and NSGD according to their original papers. Following [17, 24], we set the exploration step size  to 1 and learning rate  to 0.1. Both MGD and NSGD explore 9 proposal directions in one iteration. For our document space projection method, we consider k ,"" 3 documents following the last clicked position as examined documents, and add r "","" 10 recently examined documents into document space St . We use SVD to solve for orthonormal basis Vt of the document space St , and compute the projection matrix by At "", VtVt.",1,ad,True
390,"We reported the offline NDCG@10 and online cumulative NDCG @10 after 10,000 iterations in Table 2 and Table 3. Due to space limit, we only reported the offline performance during the 10,000 iterations over 3 click models on Yahoo dataset, a large-scale realworld L2R dataset with 700 ranking features, in Figure 2. MGD improves the online performance over DBGD by exploring multiple rankers simultaneously, and NSGD further improves over MGD by exploring gradients in a constrained subspace, as shown in Table 2. We observe that our proposed document space projection method consistently improves the online performance of all baseline algorithms. Recall that in Section 3.4 our theoretical analysis suggested that document space projection reduces the gradient estimation variance and improves the regret (online performance) with respect to the ratio between the rank of document space and feature dimension. Correspondingly, we observe that indeed we improved the OL2R models' ranking performance significantly over MSLR-WEB10K and Yahoo datasets, which are collected from realworld commerical search engines and have much higher feature",1,Yahoo,True
391,"dimensions (130 and 700 respectively). This result demonstrates the potential of document space projection to improve large-scale realworld OL2R applications with high-dimension ranking features, as our algorithm attains satisfactory performance earlier than other OL2R algorithms measured by online NDCG@10. We also notice that the standard deviation of those models' ranking performance is reduced when applying document space projection, which confirms our analysis of variance reduction in Lemma 3.2.",0,,False
392,"From Figure 2 and Table 3 we notice that document space projection mostly improves offline performance over baseline algorithms. Figure 2 shows that document space projection significantly accelerates the convergence rate over the baseline algorithms, because of the reduced variance in gradient estimation. We also observe that applying document space projection under the perfect click model may lead to degraded performance, for example DBGD on MQ2007 and Yahoo dataset. This is because document space projection guarantees an unbiased gradient estimation under the assumption of known result examinations, as discussed in Section 3.3. However, since in practice a user's result examination is unobserved, we approximated the examined documents by including all documents before the last clicked position and k additional documents after the last clicked position. The perfect click model is an ideal case that users' stop probability is set to 0.0 (see Table 1) and every document is examined. Here, the document space needs to include all displayed documents to guarantee the unbiasedness, which requires a significantly larger k compared to the k used for navigational and informational click models. We argue that in practice since users only examine a handful of documents, we could well-approximate the examined documents with a reasonable choice of k. More sophisticated click models can also be introduced. We will analyze the effect of k in Section 4.3. In addition, we also observe that under informational click model the performance of NSGD-DSP is slightly decreased compared with original NSGD over three datasets. Note that since NSGD does not guarantee its gradient exploration is unbiased, further projecting its gradient may also lead to a biased gradient update and thus a sub-optimal model.",1,ad,True
393,4.3 Analysis of Document Space Projection,0,,False
394,"To answer the second evaluation question, we design two experiments to show the effectiveness of document space projected gradient. In the first experiment, we study the utility of document space projected gradient. We compare the ranking performance of linearly interpolating the unrectified direction ut and its document space projected version t , i.e., t + (1 - )ut , based on the MGD",1,ad,True
395,841,0,,False
396,Session 9C: Learning to Rank 2,1,Session,True
397,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
398,"Table 2: Online NDCG@10, standard deviation and relative improvement of document space projection of each algorithm after 10,000 queries.",0,,False
399,Click Model Algorithm MQ2007,1,MQ,True
400,MQ2008,1,MQ,True
401,MSLR-WEB10K,1,MSLR,True
402,NP2003,1,NP,True
403,Yahoo,1,Yahoo,True
404,Perfect,0,,False
405,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
406,679.3 (21.6) 689.1 (19.5)(+1.44%) 689.1 (14.6) 757.3 (16.2)(+9.90%) 684.4 (20.5) 732.5 (20.0)(+7.03%),0,,False
407,847.1 (38.4) 858.0 (39.2)(+1.29%) 859.4 (38.1) 919.5 (42.2)(+6.99%) 867.5 (40.3) 904.3 (38.0)(+4.24%),0,,False
408,532.2 (15.3) 553.6 (13.1)(+4.02%) 558.3 (7.0) 626.4 (9.6)(+12.20%) 589.5 (14.2) 635.6 (12.8)(+7.82%),0,,False
409,1130.2 (43.3) 1198.8 (40.0) (+6.07%) 1192.9 (44.6) 1335.3 (39.1)(+11.94%) 1274.9 (47.4) 1368.5 (41.1)(+7.34%),0,,False
410,1165.5 (22.6) 1198.8 (33.5)(+2.86%) 1201.9 (16.3) 1309.4 (10.6) (+8.94%) 1162.3 (12.9) 1270.1 (2.5)(+9.27%),0,,False
411,Navigational,0,,False
412,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
413,646.1 (23.4) 664.9 (26.9)(+2.91%) 632.7 (15.5) 694.5 (15.7)(+9.77%) 660.1 (24.5) 724.6 (24.5)(+9.77%),0,,False
414,817.9 (45.5) 830.3 (44.1)(+1.52%) 827.5 (35.5) 882.3 (40.0)(+6.62%) 849.1 (36.6) 895.8 (34.2)(+5.50%),0,,False
415,517.5 (20.9) 543.1 (14.8)(+4.95%) 538.2 (7.2) 586.9 (9.5)(+9.05%) 562.1 (18.8) 608.3 (12.1) (+8.22%),0,,False
416,1062.3 (55.4) 1140.1 (52.5)(+7.32%) 1115.4 (44.6) 1300.9 (39.6)(+16.63%) 1211.1 (66.5) 1296.2 (24.3) (+7.03%),0,,False
417,1133.3 (40.8) 1199.4 (34.6)(+5.83%) 1171.3 (20.4) 1290.2 (15.3) (+10.15%) 1186.2 (16.8) 1283.4 (7.2)(+8.19%),0,,False
418,Informational,0,,False
419,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
420,583.4 (46.0) 620.1 (40.8)(+6.29%) 621.2 (18.2) 671.4 (18.9)(+8.08%) 629.7 (25.3) 703.6 (29.2)(+11.74%),0,,False
421,763.9 (55.1) 782.4 (51.8) (+2.42%) 817.5 (45.3) 865.9 (37.7)(+5.92%) 814.9 (37.1) 871.3 (48.3)(+6.92%),0,,False
422,472.4 (34.6) 522.1 (18.6) (+10.52%) 538.3 (10.8) 580.5 (10.4)(+7.84%) 532.9 (15.2) 597.9 (14.1)(+12.20%),0,,False
423,849.8 (144.5) 992.5 (81.1)(+16.79%) 1107.9 (46.2) 1274.5 (42.9)(+15.04%) 1123.5 (59.8) 1222.8 (43.8)(+9.03%),0,,False
424,1107.3 (46.6) 1158.5 (22.0)(+4.62%) 1146.6 (37.5) 1268.1 (16.4)(+10.60%) 1110.5 (10.9) 1204.7 (9.6)(+8.48%),0,,False
425,"Table 3: Offline NDCG@10, standard deviation and relative improvement of document space projection of each algorithm after 10,000 queries.",0,,False
426,Click Model Algorithm MQ2007,1,MQ,True
427,MQ2008,1,MQ,True
428,MSLR-WEB10K,1,MSLR,True
429,NP2003,1,NP,True
430,Yahoo,1,Yahoo,True
431,Perfect,0,,False
432,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
433,0.484 (0.023) 0.480 (0.020) (-0.83%) 0.495 (0.022) 0.501 (0.021)(+1.21%) 0.488 (0.019) 0.491 (0.022)(+0.61%),0,,False
434,0.683 (0.023) 0.685 (0.024) (+0.29%) 0.691 (0.020) 0.695 (0.022)(+0.58%) 0.689 (0.024) 0.691 (0.025)(+0.29%),0,,False
435,0.331 (0.009) 0.333 (0.011) (+0.6%) 0.334 (0.003) 0.409 (0.006)(+22.46%) 0.397 (0.012) 0.398 (0.008) (+0.25%),0,,False
436,0.737 (0.056) 0.738 (0.059) (+0.14%) 0.746 (0.048) 0.748 (0.055)(+0.27%) 0.743 (0.050) 0.750 (0.042) (+0.94%),0,,False
437,0.688 (0.011) 0.681 (0.013) (-1.02%) 0.715 (0.002) 0.725 (0.003)(+1.40%) 0.691 (0.005) 0.717 (0.004)(+3.76%),0,,False
438,Navigational,0,,False
439,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
440,0.463 (0.028) 0.465 (0.024)(+0.43%) 0.426 (0.019) 0.467 (0.021)(+9.62%) 0.473 (0.022) 0.478 (0.020)(+1.06%),0,,False
441,0.667 (0.021) 0.668 (0.023)(+0.15%) 0.664 (0.016) 0.684 (0.017)(+3.01%) 0.676 (0.024) 0.683 (0.026)(+1.04%),0,,False
442,0.320 (0.012) 0.327 (0.011)(+2.19%) 0.321 (0.003) 0.331 (0.005)(+3.12%) 0.389 (0.013) 0.376 (0.014)(-3.34%),0,,False
443,0.728 (0.054) 0.734 (0.052)(+0.82%) 0.740 (0.048) 0.744 (0.053)(+0.54%) 0.732 (0.053) 0.788 (0.006)(+7.65%),0,,False
444,0.663 (0.020) 0.656 (0.013)(-1.06%) 0.703 (0.010) 0.714 (0.006)(+1.56%) 0.686 (0.008) 0.711 (0.001)(+3.64%),0,,False
445,Informational,0,,False
446,DBGD DBGD-DSP MGD MGD-DSP NSGD NSGD-DSP,0,,False
447,0.410 (0.034) 0.427 (0.027)(+4.15%) 0.406 (0.020) 0.444 (0.025)(+0.44%) 0.469 (0.018) 0.466 (0.019)(-0.64%),0,,False
448,0.641 (0.031) 0.632 (0.031)(-1.4%) 0.651 (0.020) 0.669 (0.018)(+0.67%) 0.674 (0.023) 0.668 (0.026)(-0.89%),0,,False
449,0.294 (0.022) 0.309 (0.011)(+32.65%) 0.317 (0.003) 0.325 (0.004)(+0.33%) 0.360 (0.013) 0.340 (0.018)(-5.56%),0,,False
450,0.699 (0.063) 0.692 (0.062)(-1.00%) 0.726 (0.050) 0.738 (0.054)(+0.74%) 0.733 (0.056) 0.789 (0.013)(+7.64%),0,,False
451,0.623 (0.037) 0.63 (0.030)(1.12%) 0.668 (0.044) 0.701 (0.005)(+4.94%) 0.663 (0.015) 0.685 (0.004)(+3.32%),0,,False
452,"algorithm on MSLR-WEB10K dataset. Similar observations were obtained on other datasets, but due to space limit we have to omit those detailed results. We report the online and offline performance by varying  from 0 (which is equivalent to the original MGD algorithm) and 1 (which is MGD-DSP) in Figure 3 (a) and (b). We can clearly observe a trend of increasing online performance over all",1,MSLR,True
453,"three click models when we increase , i.e., trust more on the projected direction t for model update. This confirms the effectiveness of the projected direction t within document space comparing with the unrectified direction ut from the entire parameter space. The offline performance is generally robust to the setting of  for",0,,False
454,navigational and information click models. This is expected since,0,,False
455,842,0,,False
456,Session 9C: Learning to Rank 2,1,Session,True
457,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
458,(a) Online performance of,0,,False
459,linearly interpolating ut and its projection t,0,,False
460,Cosine Similarity to w*,0,,False
461,NDCG,0,,False
462,0.5 informational,0,,False
463,0.4,0,,False
464,0.3,0,,False
465,0.75 perfect,0,,False
466,0.70,0,,False
467,0.65,0,,False
468,(b) Offline performance of,0,,False
469,linearly interpolating ut and its projection t,0,,False
470,0.2,0,,False
471,0.1,0,,False
472,0.0 0,0,,False
473,MGD MGD-DSP,0,,False
474,1000,0,,False
475,2000,0,,False
476,3000,0,,False
477,Impressions,0,,False
478,4000,0,,False
479,5000,0,,False
480,0.60,0,,False
481,0.55,0,,False
482,0.50 0,0,,False
483,DBGD-DSP-GT DBGD-DSP MGD-DSP-GT MGD-DSP,0,,False
484,1000,0,,False
485,2000,0,,False
486,3000,0,,False
487,4000,0,,False
488,5000,0,,False
489,Impressions,0,,False
490,(c) Cosine similarity between offline best model w and online (d) Comparing with ground-truth,0,,False
491,document space model,0,,False
492,Figure 3: Analyzing Document Space Projection.,0,,False
493,(a) Including k documents following last clicked position,0,,False
494,(b) Including r recently examined documents,0,,False
495,Figure 4: Hyper-parameter tuning for Document Space Projection.,0,,False
496,"both MGD and MGD-DSP are unbiased and will eventually converge to similar offline performance after sufficiently large number of iterations (we had 10,000 iterations in our experiments).",1,ad,True
497,"In the second experiment, we trained an offline LambdaRank model [1] using the complete annotated relevance labels in the largescale MSLR-WEB10K dataset. Then given this w, we compared cosine similarity between the online estimated model parameters with and without DSP in each iteration using MGD as the baseline. We show the result of first 5,000 iterations. In Figure 3 (c) we can observe that MGD-DSP converges faster and better to w than MGD. This suggests the rectified gradient is more effective than the original one. We also compared with an oracle algorithm that knows the ground-truth examined documents, denoted as DSP-GT, to validate the effectiveness of our approximated document space. We show the result on DBGD and MGD under the perfect click model in Figure 3(d). We notice that oracle algorithms performed similar to our proposed algorithm with an approximated document space, which confirms the effectiveness of the approximation heuristics.",1,MSLR,True
498,"To answer the third evaluation question, we compare different hyper-parameters used for constructing the document space on MSLR-WEB10K dataset. We vary k from 0 to 7 and report the result in Figure4 (a). We notice that for navigational and informational click models, a relatively small k achieved the best performance, i.e., k ,"" 3. This corresponds to the observation that users do not continue to examine many documents after their last click under these two click models. However, under perfect click model the models' performance increases with a larger k. This aligns with the conclusions from our discussion in Section 4.2 that under the perfect click model, we need to set a much larger k to accurately""",1,MSLR,True
499,construct the document space and guarantee an unbiased gradient estimate.,1,ad,True
500,"In Figure 4(b), we vary r . As we discussed in Section 3.5, we are motivated to add recently examined documents to compensate for potentially overlooked examined documents in the current query. The effect of different choices of r is more noticeable under the perfect click model. This echoes our analysis above that under perfect click model some examined documents may be overlooked when k is not large enough. Thus correctly setting up r could reduce the bias in document space construction and compensate the final performance. From the result figure, we notice that setting r ,"" 20 provides the best result. Under navigational and informational click models, the algorithm is generally robust to the choice of r . This is because the approximations of examined documents are already accurate with a reasonable setting of k.""",1,ad,True
501,5 CONCLUSION,0,,False
502,"In this paper, we propose and develop the Document Space Projection (DSP) method for reducing variance in gradient estimation and improving online learning to rank performance. The key insight of DSP is to recognize that the interleaved test only reveals the projection of true gradient on the spanned space of examined documents. Including anything beyond this space for model update only introduces noise. Thus our method projects the selected model update direction back to the document space to reduce its variance. We proved that DSP maintains an unbiased gradient estimate, and it can substantially improve the regret bound for DBGD-style algorithms via the reduced variance. Through our extensive experiments, we found that DSP is able to provide statistically significant improvements to several state-of-the-art OL2R models, both in terms of variance reduction and overall performance, especially when the number of ranking features is large.",1,ad,True
503,"Currently, we are using a heuristic method to construct the document space. However, we did observe that the performance of DSP varies under different click models for simulated user click feedback, i.e., different underlying examination behaviors. As for our future work, we plan to incorporate different click modeling solutions for more accurate document space construction. It would also be meaningful to study how to perform document space based exploratory direction generation, before the interleaved test. Exploratory direction pre-selection is expected to further accelerate the gradient exploration and improve user satisfaction during online learning, but we also need to ensure it is unbiased.",1,corpora,True
504,843,0,,False
505,Session 9C: Learning to Rank 2,1,Session,True
506,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
507,ACKNOWLEDGMENTS,0,,False
508,We thank the anonymous reviewers for their insightful comments.,0,,False
509,This work was supported in part by National Science Foundation,0,,False
510,Grant IIS-1553568 and IIS-1618948 and Bloomberg Data Science,0,,False
511,Ph.D. Fellowship.,0,,False
512,REFERENCES,0,,False
513,"[1] Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: An overview. Learning 11, 23-581 (2010), 81.",0,,False
514,[2] Olivier Chapelle and Yi Chang. 2011. Yahoo! learning to rank challenge overview. In Proceedings of the Learning to Rank Challenge. 1­24.,1,Yahoo,True
515,"[3] Olivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th international conference on World wide web. ACM, 1­10.",0,,False
516,"[4] Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In Proceedings of the 2008 international conference on web search and data mining. ACM, 87­94.",0,,False
517,"[5] Abraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. 2005.",0,,False
518,"Online convex optimization in the bandit setting: gradient descent without a gradient. In Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics, 385­394. [6] Artem Grotov and Maarten de Rijke. 2016. Online learning to rank for information retrieval: SIGIR 2016 Tutorial. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 1215­ 1218.",1,ad,True
519,"[7] Katja Hofmann, Anne Schuth, Shimon Whiteson, and Maarten de Rijke. 2013.",0,,False
520,"Reusing historical interaction data for faster online learning to rank for IR. In Proceedings of the sixth ACM international conference on WSDM. ACM, 183­192. [8] Katja Hofmann, Shimon Whiteson, and Maarten De Rijke. 2011. A probabilistic method for inferring preferences from clicks. In Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 249­ 258.",0,,False
521,"[9] Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2017. Accurately interpreting clickthrough data as implicit feedback. In ACM SIGIR Forum, Vol. 51. Acm, 4­11.",0,,False
522,"[10] Tie-Yan Liu et al. 2009. Learning to rank for information retrieval. Foundations and Trends® in Information Retrieval 3, 3 (2009), 225­331.",0,,False
523,"[11] Tie-Yan Liu, Jun Xu, Tao Qin, Wenying Xiong, and Hang Li. 2007. Letor: Benchmark dataset for research on learning to rank for information retrieval. In Proceedings of SIGIR 2007 workshop on learning to rank for information retrieval, Vol. 310.",0,,False
524,"[12] Harrie Oosterhuis and Maarten de Rijke. 2017. Balancing Speed and Quality in Online Learning to Rank for Information Retrieval. In Proceedings of the 2017 ACM CIKM. ACM, 277­286.",0,,False
525,[13] Harrie Oosterhuis and Maarten de Rijke. 2018. Differentiable Unbiased Online Learning to Rank. Proceedings of the 27th ACM International Conference on Information and Knowledge Management - CIKM '18 (2018). https://doi.org/10. 1145/3269206.3271686,0,,False
526,[14] Tao Qin and Tie-Yan Liu. 2013. Introducing LETOR 4.0 Datasets.,0,,False
527,arXiv:cs.IR/1306.2597,0,,False
528,"[15] Filip Radlinski, Madhu Kurup, and Thorsten Joachims. 2008. How does clickthrough data reflect retrieval quality?. In Proceedings of the 17th ACM CIKM. ACM, 43­52.",1,ad,True
529,"[16] Anne Schuth, Katja Hofmann, Shimon Whiteson, and Maarten de Rijke. 2013. Lerot: An online learning to rank framework. In Proceedings of the 2013 workshop on Living labs for information retrieval evaluation. ACM, 23­26.",0,,False
530,"[17] Anne Schuth, Harrie Oosterhuis, Shimon Whiteson, and Maarten de Rijke. 2016. Multileave gradient descent for fast online learning to rank. In Proceedings of the Ninth ACM International Conference on WSDM. ACM, 457­466.",1,ad,True
531,"[18] Anne Schuth, Floor Sietsma, Shimon Whiteson, Damien Lefortier, and Maarten de Rijke. 2014. Multileaved comparisons for fast online evaluation. In Proceedings of the 23rd ACM CIKM. ACM, 71­80.",0,,False
532,"[19] Ellen M Voorhees, Donna K Harman, et al. 2005. TREC: Experiment and evaluation in information retrieval. Vol. 1. MIT press Cambridge.",1,TREC,True
533,"[20] Huazheng Wang, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, and Hongn-",0,,False
534,"ing Wang. 2018. Efficient exploration of gradient space for online learning to rank. In The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 145­154. [21] Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to rank with selection bias in personal search. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 115­124. [22] Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims. 2012. The k-armed dueling bandits problem. J. Comput. System Sci. 78, 5 (2012), 1538­1556. [23] Yisong Yue, Yue Gao, Oliver Chapelle, Ya Zhang, and Thorsten Joachims. 2010.",1,ad,True
535,"Learning more powerful test statistics for click-based retrieval evaluation. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval. ACM, 507­514. [24] Yisong Yue and Thorsten Joachims. 2009. Interactively optimizing information retrieval systems as a dueling bandits problem. In Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 1201­1208. [25] Tong Zhao and Irwin King. 2016. Constructing reliable gradient exploration for online learning to rank. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 1643­1652.",1,ad,True
536,844,0,,False
537,,0,,False
