,sentence,label,data,regex
0,"Short Research Papers 1A: AI, Mining, and others",0,,False
1,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
2,Learning More From Less,0,,False
3,Towards Strengthening Weak Supervision for Ad-Hoc Retrieval,0,,False
4,Dany Haddad,1,ad,True
5,danyhaddad@utexas.edu The University of Texas at Austin,1,ad,True
6,ABSTRACT,0,,False
7,"The limited availability of ground truth relevance labels has been a major impediment to the application of supervised methods to ad-hoc retrieval. As a result, unsupervised scoring methods, such as BM25, remain strong competitors to deep learning techniques which have brought on dramatic improvements in other domains, such as computer vision and natural language processing. Recent works have shown that it is possible to take advantage of the performance of these unsupervised methods to generate training data for learning-to-rank models. The key limitation to this line of work is the size of the training set required to surpass the performance of the original unsupervised method, which can be as large as 1013 training examples. Building on these insights, we propose two methods to reduce the amount of training data required. The first method takes inspiration from crowdsourcing, and leverages multiple unsupervised rankers to generate soft, or noise-aware, training labels. The second identifies harmful, or mislabeled, training examples and removes them from the training set. We show that our methods allow us to surpass the performance of the unsupervised baseline with far fewer training examples than previous works.",1,ad-hoc,True
8,CCS CONCEPTS,0,,False
9,· Information systems  Retrieval models and ranking.,0,,False
10,KEYWORDS,0,,False
11,"Information retrieval, Noisy Labels, Weak Supervision, Neural Network, Deep Learning",0,,False
12,"ACM Reference Format: Dany Haddad and Joydeep Ghosh. 2019. Learning More From Less: Towards Strengthening Weak Supervision for Ad-Hoc Retrieval. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19), July 21­25, 2019, Paris, France. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3331184.3331272",1,ad,True
13,1 INTRODUCTION,1,DUC,True
14,"Classical ad-hoc retrieval methods have relied primarily on unsupervised signals such as BM25, TF-IDF, and PageRank as inputs",1,ad-hoc,True
15,Work done while interning at CognitiveScale.,0,,False
16,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331272",1,ad,True
17,Joydeep Ghosh,0,,False
18,ghosh@ece.utexas.edu The University of Texas at Austin,0,,False
19,"to learning-to-rank (LeToR) models. Supervision for these models is often supplied in the form of click-stream logs or hand-curated rankings, both of which come with their issues and limitations. First, both sources are typically limited in availability and are often proprietary company resources. Second, click-stream data is typically biased towards the first few elements in the ranking presented to the user [2] and are noisy in general. Finally, such logs are only available after the fact, leading to a cold start problem. These issues motivate the search for an alternate source of ""ground truth"" ranked lists to train our LeToR model on.",1,ad,True
20,"In [7], Dehghani et al. show that the output of an unsupervised document retrieval method can be used to train a supervised ranking model that outperforms the original unsupervised ranker. More recently, [13] proposed a hierarchical interaction based model that is trained on a similarly generated training set. These works have shown the potential of leveraging unsupervised methods as sources of weak supervision for the retrieval task. However, they require training on as many as 1013 training examples to surpass the performance of the unsupervised baseline [7, 13].",0,,False
21,"In this work, we substantially reduce this number by making more effective use of the generated training data. We present two methods that make improvements in this direction, and beat the unsupervised method using fewer than 10% of the training rankings compared to previous techniques.",0,,False
22,"In the first method, we take a crowdsourcing approach and collect the output of multiple unsupervised retrieval models. Following [19], we learn a joint distribution over the outputs of said retrieval models and generate a new training set of soft labels. We call this the noise-aware model. The noise-aware model does not require access to any gold labels1.",0,,False
23,Our second method builds on the idea of dataset debugging and identifies training examples with the most harmful influence [10] (the labels most likely to be incorrect) and drops them from the training set. We call this the influence-aware model.,0,,False
24,2 RELATED WORK,0,,False
25,"Much of the prior work in handling noisy datasets has been in the context of a classifier from noisy labels. In the binary classification context, noise is seen as a class-conditional probability that an observed label is the opposite of the true label [8, 14]. In the ranking context, we typically expect that models trained using pairwise or listwise loss functions will far outperform pointwise approaches [11]. Since the label of a pair is determined by the ordering of the documents within the pair, it is not immediately obvious how the class-conditional flip probabilities translate to this formulation. The relationship to listwise objectives is not straightforward either.",0,,False
26,"1To differentiate them from labels originating from weak supervision sources, we refer to relevance scores assigned by a human as ""gold"" labels",0,,False
27,857,0,,False
28,"Short Research Papers 1A: AI, Mining, and others",0,,False
29,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
30,"In [5] and [6], Dehghani et al. introduce two semi-supervised student-teacher models where the teacher weights the contribution of each sample in the student model's training loss based on its confidence in the quality of the label. They train the teacher on a small subset of gold labels and use the model's output as confidence weights for the student model. [5] shows that using this approach, they can beat the unsupervised ranker using ~75% of the data required when training directly on the noisy data. They train a cluster of 50 gaussian processes to form the teacher annotations which are used to generate soft labels to fine-tune the student model.",0,,False
31,"In [19], Ratner et al. transform a set of weak supervision sources, that may disagree with each other, into soft labels used to train a discriminative model. They show experimentally that this approach outperforms the naïve majority voting strategy for generating the target labels. This inspires our noise-aware approach.",0,,False
32,"In [10], Koh et al. apply classical results from regression analysis to approximate the change in loss at a test point caused by removing a specific point from the training set. They show experimentally that their method approximates this change in loss well, even for highly non-linear models, such as GoogLeNet. They also apply their method to prioritize training examples to check for labeling errors. Our influence-aware approach uses influence functions [10] to identify mislabeled training examples.",0,,False
33,3 PROPOSED METHODS,0,,False
34,3.1 Model Architecture,0,,False
35,"In this work, we only explore pairwise loss functions since they typi-",0,,False
36,cally lead to better performing models than the pointwise approach.,1,ad,True
37,"Listwise approaches, although typically the most effective, tend to",0,,False
38,have high training and inference time computational complexity,0,,False
39,due to their inherently permutation based formulations [11].,0,,False
40,We consider a slight variant of the Rank model proposed in [7] as our baseline model. We represent the tokens in the ith query as tiq and the tokens in the ith document as tid . We embed these tokens in a low dimensional space with a mapping E : V  Rl,0,,False
41,where V is the vocabulary and l is the embedding dimension. We,0,,False
42,also learn token dependent weights W : V  R. Our final repre-,0,,False
43,sentation for a query q is a weighted sum of the word embeddings:,0,,False
44,"vq ,",0,,False
45,t,0,,False
46,q j,0,,False
47,t,0,,False
48,q,0,,False
49,W~ q,0,,False
50,(t,0,,False
51,q j,0,,False
52,)E(t,0,,False
53,q j,0,,False
54,),0,,False
55,where W~ q,0,,False
56,indicates,0,,False
57,that,0,,False
58,the,0,,False
59,weights,0,,False
60,are,0,,False
61,normalized to sum to 1 across tokens in the query q using a soft-,0,,False
62,max operation. The vector representation for documents is defined,0,,False
63,similarly.,0,,False
64,"In addition, we take the difference and elementwise products",1,ad,True
65,of the document and query vectors and concatenate them into a,0,,False
66,"single vector vq,d ,"" [vq , vd , vq - vd , vq  vd ]. We compute the relevance score of a document, d, to a query, q by passing vq,d through a feed-forward network with ReLU activations and scalar output. We use a tanh at the output of the rank model and use the""",0,,False
67,raw logit scores otherwise. We represent the output of our model,0,,False
68,"parameterized by  as f (x;  ). Our training set Z is a set of tuples z ,"" (q, d1, d2, sq,d1 , sq,d2 )""",0,,False
69,"where sq,di is the relevance score of di to q given by the unsupervised ranker. The pairwise objective function we minimize is given",0,,False
70,by:,0,,False
71,"L(Z;  ) ,"" L(f (vq,d1 ;  ) - f (vq,d2 ;  ), relq,(d1,d2)) (1)""",0,,False
72,z Z,0,,False
73,"Lce (x, y) , y · log( (x)) + (1 - y) · log(1 -  (x))",0,,False
74,(2),0,,False
75,"Lhine (x, y) ,"" max{0,  - sign(y) · x }""",0,,False
76,(3),0,,False
77,"Where relq,(d1,d2)  [0, 1] gives the relative relevance of d1 and d2 to q. L is either Lce or Lhine for cross-entropy or hinge loss, respectively. The key difference between the rank and noise-aware",0,,False
78,"models is how relq,(d1,d2) is determined. As in [7], we train the rank model by minimizing the max-margin loss and compute relq,(d1,d2) as sign(sq,d1 - sq,d2 ).",0,,False
79,Despite the results in [21] showing that the max-margin loss,0,,False
80,exhibits stronger empirical risk guarantees for ranking tasks using,0,,False
81,"noisy training data, we minimize the cross-entropy loss in each of",0,,False
82,"our proposed models for the following reasons: in the case of the noise-aware model, each of our soft training labels are a distribution",0,,False
83,"over {0, 1}, so we seek to learn a calibrated model rather than",0,,False
84,"one which maximizes the margin (as would be achieved using a hinge loss objective). For the influence-aware model, we minimize",0,,False
85,the cross-entropy rather than the hinge loss since the method of,0,,False
86,influence functions relies on having a twice differentiable objective.,0,,False
87,3.2 Noise-aware model,0,,False
88,"In this approach, relq,(di,dj )  [0, 1] are soft relevance labels. For each of the queries in the training set, we rank the top documents by relevance using k unsupervised rankers. Considering ordered pairs of these documents, each ranker gives a value of 1 if it agrees with the order, -1 if it disagrees and 0 if neither document appears",0,,False
89,"in the top 10 positions of the ranking. We collect these values into a matrix   {-1, 0, 1}m×k for m document pairs. The joint distribution over these pairwise preferences and the true pairwise orderings y is given by:",0,,False
90,m,0,,False
91,"1 Pw (, y) , Z (w) exp( i",0,,False
92,"wT (i , yi ))",0,,False
93,(4),0,,False
94,Where w is a vector of learned parameters and Z (w) is the par-,0,,False
95,tition function. A natural choice for  is to model the accuracy,0,,False
96,"of each individual ranker in addition to the pairwise correlations between each of the rankers. So for the ith document pair, we have the following expression for i (i , yi ):",1,ad,True
97,"i , [{i j , yi }1j k ||{i j , il 0}j l ]",0,,False
98,"Since the true relevance preferences are unknown, we treat them",0,,False
99,as latent. We learn the parameters for this model without any gold relevance labels y by maximizing the marginal likelihood (as in,0,,False
100,[19]) given by:,0,,False
101,max log,0,,False
102,w,0,,False
103,y,0,,False
104,"Pw (, y)",0,,False
105,(5),0,,False
106,We use the Snorkel library2 to optimize equation 5 by stochastic,0,,False
107,"gradient descent, where we perform Gibbs sampling to estimate",1,ad,True
108,"the gradient at each step. Once we have determined the parameters of the model, we can evaluate the posterior probabilities Pw (yi |i ) which we use as our soft training labels.",1,ad,True
109,2,0,,False
110,https://github.com/HazyResearch/snorkel,0,,False
111,858,0,,False
112,"Short Research Papers 1A: AI, Mining, and others",0,,False
113,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
114,3.3 Influence Aware Model,0,,False
115,"In this approach, we identify training examples that hurt the generalization performance of the trained model. We expect that many of these will be incorrectly labeled, and that our model will perform better if we drop them from the training set. The influence of removing a training example zi ,"" (xi , yi ) on the trained model's loss at a test point ztest is computed as [10]:""",0,,False
116,Table 1: Results comparison with smoothing.,0,,False
117,Noise- Influence-,0,,False
118,Rank Model,0,,False
119,QL,0,,False
120,Aware Aware,0,,False
121,NDCG@10 Prec@10 MAP,1,MAP,True
122,0.3881  0.3952 0.3535  0.3621 0.2675  0.2774,0,,False
123,0.4008 0.3843 0.3657 0.3515 0.2792 0.2676,0,,False
124,"L(ztext ;  )  Idr op (zi , ztest )",0,,False
125,(6),0,,False
126,",",0,,False
127,1 n,0,,False
128,L(zt,0,,False
129,es,0,,False
130,t,0,,False
131,;,0,,False
132,)T,0,,False
133,H-1 ,0,,False
134,L(zi,0,,False
135,;,0,,False
136,),0,,False
137,(7),0,,False
138,"where H is the Hessian of the objective function. If Idrop (zi , ztest ) is negative, then zi is a harmful training example for ztest since it's inclusion in the training set causes an increase in the loss at that point. Summing this value over the entire test set gives us Idrop (zi ). We compute Idrop (zi ) for each training example zi , expecting it to represent zi 's impact on the model's performance at test time. In our setup, we know that some of our training examples are",0,,False
139,"mislabeled; we expect that these points will have a large negative value for Idrop . Of course, for a fair evaluation, the ztest points are taken from the development set used for hyperparameter tuning",0,,False
140,(see section 4).,0,,False
141,We address the computational constraints of computing (7) by,1,ad,True
142,treating our trained model as a logistic regression on the bottle-,0,,False
143,neck features. We freeze all model parameters except the last layer,0,,False
144,of the feed-forward network and compute the gradient with re-,1,ad,True
145,spect to these parameters only. This gradients can be computed in,1,ad,True
146,"closed form in an easily parallelizable way, allowing us to avoid",0,,False
147,techniques that rely on autodifferentiation operations [16]. We compute H-1 L(ztest ;  ) for every ztest using the method of conjugate gradients following [20]. We also add a small damping term,1,ad,True
148,to the diagonal of the Hessian to ensure that it is positive definite,0,,False
149,[12].,0,,False
150,4 DATA PREPROCESSING AND MODEL TRAINING,0,,False
151,"We evaluate the application of our methods to ad-hoc retrieval on the Robust04 corpus with the associated test queries and relevance labels. As in [7], our training data comes from the AOL query logs [15] on which we perform similar preprocessing. We use the Indri3 search engine to conduct indexing and retrieval and use the default parameters for the query likelihood (QL) retrieval model [18] which we use as the weak supervision source. We fetch only the top 10 documents from each ranking in comparison to previous works which trained on as many as the top 1000 documents for each query. To compensate for this difference, we randomly sample nne additional documents from the rest of the corpus for each of these 10 documents. We train our model on a random subset of 100k rankings generated by this process. This is fewer than 10% the number of rankings used in previous works [7, 13], each of which contains far fewer document pairs.",1,ad-hoc,True
152,3,0,,False
153,https://www.lemurproject.org/indri.php,0,,False
154,"For the word embedding representations,W , we use the 840B.300d GloVe [17] pretrained word embedding set4. The feed-forward net-",0,,False
155,"work hidden layer sizes are chosen from {512, 256, 128, 64} with up",0,,False
156,to 5 layers. We use the first 50 queries in the Robust04 dataset as,1,Robust,True
157,"our development set for hyperparameter selection, computation of Idrop and early stopping. The remaining 200 queries are used for evaluation.",0,,False
158,"During inference, we rank documents by the output of the feed-",0,,False
159,forward network. Since it is not feasible to rank all the documents,0,,False
160,"in the corpus, we fetch the top 100 documents using the QL retrieval",0,,False
161,model and then rerank using the trained model's scores.,0,,False
162,4.1 Model Specific Details,0,,False
163,"For the noise-aware model, we generate separate rankings for each query using the following retrieval methods: Okapi BM25, TF-IDF,",0,,False
164,"QL, QL+RM3 [1] using Indri with the default parameters. For the influence-aware model, we train the model once on the",0,,False
165,full dataset and then compute Idrop (zi ) for each training point dropping all training examples with a negative value for Idrop (zi ) which we find to typically be around half of the original training,0,,False
166,"set. We then retrain the model on this subset. Interestingly, we find that using a smaller margin, , in the train-",0,,False
167,ing loss of the rank model leads to improved performance. Using a smaller margin incurs 0 loss for a smaller difference in the model's,1,ad,True
168,"relative preference between the two documents. Intuitively, this",0,,False
169,allows for less overfitting to the noisy data. We use a margin of 0.1,0,,False
170,chosen by cross-validation. The noise-aware and influence-aware models train end-to-end in,0,,False
171,around 12 and 15 hours respectively on a single NVIDIA Titan Xp.,1,VID,True
172,5 EXPERIMENTAL RESULTS,0,,False
173,"We compare our two methods against two baselines, the unsupervised ranker (QL) and the rank model. Compared to the other unsupervised rankers (see section 4.1) used as input to the noise-aware model, the QL ranker performs the best on all metrics. Training the rank model on the results of the majority vote of the set of unsupervised rankers used for the noise-aware model performed very similarly to the rank model, so we only report results of the rank model. We also compare the results after smoothing with the normalized QL document scores by linear interpolation.",0,,False
174,"The results in tables 1 and 2 show that the noise-aware and influence-aware models perform similarly, with both outperforming the unsupervised baseline. Bold items are the largest in their row",0,,False
175,and daggers indicate statistically significant improvements over the rank model at a level of 0.05 using Bonferroni correction. Figure 1 shows that the rank model quickly starts to overfit. This does,0,,False
176,4,0,,False
177,https://nlp.stanford.edu/projects/glove/,0,,False
178,859,0,,False
179,"Short Research Papers 1A: AI, Mining, and others",0,,False
180,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
181,Table 2: Results comparison without smoothing.,0,,False
182,Rank Model Noise-Aware Influence-Aware,0,,False
183,NDCG@10 Prec@10 MAP,1,MAP,True
184,0.2610 0.2399 0.1566,0,,False
185, 0.2886 0.2773  0.1831,0,,False
186,0.2966  0.2742 0.1839,0,,False
187,Figure 1: Test NDCG@10 during training,0,,False
188,"not contradict the results in [7] since in our setup we train on far fewer pairs of documents for each query, so each relevance label error has much greater impact. For each query, our distribution over documents is uniform outside the results from the weak supervision source, so we expect to perform worse than if we had a more faithful relevance distribution. Our proposed approaches use an improved estimate of the relevance distribution at the most important positions in the ranking, allowing them to perform well.",1,ad,True
189,We now present two representative training examples showing how our methods overcome the limitations of the rank model.,0,,False
190,"Example 5.1. The method in section 3.2 used to create labels for the noise-aware model gives the following training example an unconfident label (~0.5) rather than a relevance label of 1 or 0: (q,""town of davie post office, (d1"",""FBIS3-25584, d2"",""FT933-13328)) where d1 is ranked above d2. Both of these documents are about people named """"Davie"""" rather than about a town or a post office, so it is reasonable to avoid specifying a hard label indicating which one is explicitly more relevant.""",0,,False
191,"Example 5.2. One of the most harmful training points as determined by the method described in section 3.3 is the pair (q,""pictures of easter mice, (d1"",""FT932-15650, d2"",LA041590-0059)) where d1 is ranked above d2. d1 discusses the computer input device and d2 is about pictures that are reminiscent of the holiday. The incorrect relevance label explains why the method identifies this as a harmful training example.",0,,False
192,6 CONCLUSIONS AND FUTURE WORK,0,,False
193,"We have presented two approaches to reduce the amount of weak data needed to surpass the performance of the unsupervised method that generates the training data. The noise-aware model does not require ground truth labels, but has an additional data dependency on multiple unsupervised rankers. The influence-aware model requires a small set of gold-labels in addition to a re-train of the model,",1,ad,True
194,"although empirically, only around half the dataset is used when",0,,False
195,training the second time around.,0,,False
196,Interesting paths for future work involve learning a better joint distribution for training the noise-aware model or leveraging ideas from [22] to construct soft training labels rather than for the query,0,,False
197,"performance prediction task. Similarly, we could apply ideas from",0,,False
198,"unsupervised LeToR [4] to form better noise-aware labels. For the influence-aware model, we could use the softrank loss [3] rather than cross-entropy and instead compute set influence rather than",1,ad,True
199,the influence of a single training example [9].,0,,False
200,REFERENCES,0,,False
201,"[1] Nasreen Abdul-Jaleel, James Allan, Bruce Croft, Fernando Diaz, Leah Larkey,",0,,False
202,"Xiaoyan Li, Donald Metzler, Mark D. Smucker, Trevor Strohman, Howard Turtle, and Courtney Wade. 2004. Umass at trec 2004: Notebook. academia.edu (2004). [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased Learning to Rank with Unbiased Propensity Estimation. In The 41st International ACM SIGIR Conference. ACM Press, New York, New York, USA, 385­394. https://doi.org/10.1145/3209978.3209986",1,ad,True
203,"[3] Ricardo Baeza-Yates, Berthier de Araújo Neto Ribeiro, et al. 2007. Learning to rank with nonsmooth cost functions. NIPS (2007).",0,,False
204,"[4] Avradeep Bhowmik and Joydeep Ghosh. 2017. LETOR Methods for Unsupervised Rank Aggregation. In the 26th International Conference. ACM Press, New York, New York, USA, 1331­1340. https://doi.org/10.1145/3038912.3052689",1,ad,True
205,"[5] Mostafa Dehghani, Arash Mehrjou, Stephan Gouws, Jaap Kamps, and Bernhard Schölkopf. 2017. Fidelity-Weighted Learning. arXiv.org (Nov. 2017). arXiv:cs.LG/1711.02799v2",0,,False
206,"[6] Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, and Jaap Kamps. 2017. Learning to Learn from Weak Supervision by Full Supervision. arXiv.org (Nov. 2017), 1­8. arXiv:1711.11383",0,,False
207,"[7] Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, and W Bruce Croft. 2017. Neural Ranking Models with Weak Supervision. In the 40th International ACM SIGIR Conference. ACM Press, New York, New York, USA, 65­74. https://doi.org/10.1145/3077136.3080832",0,,False
208,"[8] Xinxin Jiang, Shirui Pan, Guodong Long, Fei Xiong, Jing Jiang, and Chengqi Zhang. 2017. Cost-sensitive learning with noisy labels. JMLR (2017).",0,,False
209,"[9] Rajiv Khanna, Been Kim, Joydeep Ghosh, and Oluwasanmi Koyejo. 2018. Interpreting Black Box Predictions using Fisher Kernels. arXiv.org (Oct. 2018). arXiv:cs.LG/1810.10118v1",0,,False
210,"[10] Pang Wei Koh and Percy Liang. 2017. Understanding Black-box Predictions via Influence Functions. arXiv.org (March 2017), 1­11. arXiv:1703.04730",0,,False
211,"[11] Tie-Yan Liu. 2009. Learning to Rank for Information Retrieval. Foundations and Trends® in Information Retrieval 3, 3 (2009), 225­331. https://doi.org/10.1561/ 1500000016",0,,False
212,[12] James Martens. 2010. Deep learning via Hessian-free optimization. (2010).,0,,False
213,"[13] Yifan Nie, Alessandro Sordoni, and Jian-Yun Nie. 2018. Multi-level Abstraction Convolutional Model with Weak Supervision for Information Retrieval. In The 41st International ACM SIGIR Conference. ACM Press, New York, New York, USA, 985­988. https://doi.org/10.1145/3209978.3210123",0,,False
214,"[14] Curtis G Northcutt, Tailin Wu, and Isaac L Chuang. 2017. Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels. arXiv.org (May 2017). arXiv:1705.01936",1,Robust,True
215,"[15] Greg Pass, Abdur Chowdhury, and Cayley Torgeson. 2006. A Picture of Search. Infoscale (2006), 1­es. https://doi.org/10.1145/1146847.1146848",0,,False
216,"[16] Barak Pearlmutter. 1994. Fast exact multiplication by the Hessian. MIT Press 6, 1 (Jan. 1994), 147­160. https://doi.org/10.1162/neco.1994.6.1.147",0,,False
217,"[17] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2015. GloVe:",0,,False
218,Global Vectors for Word Representation.,0,,False
219,"[18] Jay M Ponte and W Bruce Croft. 1998. A Language Modeling Approach to Information Retrieval. SIGIR (1998), 275­281. https://doi.org/10.1145/290941. 291008",0,,False
220,"[19] Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. 2017. Snorkel. Proceedings of the VLDB Endowment 11, 3 (Nov. 2017), 269­282. https://doi.org/10.14778/3157794.3157797",0,,False
221,[20] Jonathan R Shewchuk. 1994. An introduction to the conjugate gradient method,1,ad,True
222,without the agonizing pain. (1994). [21] Hamed Zamani and W Bruce Croft. 2018. On the Theory of Weak Supervision for,0,,False
223,"Information Retrieval. ACM, New York, New York, USA. https://doi.org/10.1145/ 3234944.3234968",0,,False
224,"[22] Hamed Zamani, W Bruce Croft, and J Shane Culpepper. 2018. Neural Query Performance Prediction using Weak Supervision from Multiple Signals. In The 41st International ACM SIGIR Conference. ACM Press, New York, New York, USA, 105­114. https://doi.org/10.1145/3209978.3210041",1,Query,True
225,860,0,,False
226,,0,,False
