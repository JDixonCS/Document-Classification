,sentence,label,data,regex
0,Short Research Papers 3C: Search,0,,False
1,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
2,ery Performance Prediction for Pseudo-Feedback-Based Retrieval,0,,False
3,Haggai Roitman,0,,False
4,IBM Research ­ Haifa haggai@il.ibm.com,0,,False
5,ABSTRACT,0,,False
6,"The query performance prediction task (QPP) is estimating retrieval e ectiveness in the absence of relevance judgments. Prior work has focused on prediction for retrieval methods based on surface level query-document similarities (e.g., query likelihood). We address the prediction challenge for pseudo-feedback-based retrieval methods which utilize an initial retrieval to induce a new query model; the query model is then used for a second ( nal) retrieval. Our suggested approach accounts for the presumed e ectiveness of the initially retrieved list, its similarity with the nal retrieved list and properties of the latter. Empirical evaluation demonstrates the clear merits of our approach.",1,ad,True
7,"ACM Reference Format: Haggai Roitman and Oren Kurland. 2019. Query Performance Prediction for Pseudo-Feedback-Based Retrieval. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19), July 21­25, 2019, Paris, France. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3331184.3331369",1,Query,True
8,1 INTRODUCTION,1,DUC,True
9,"The query performance prediction task (QPP) has attracted much research attention [2]. The goal is to evaluate search e ectiveness with no relevance judgments. Almost all existing QPP methods are (implicitly or explicitly) based on the assumption that retrieval is performed using (only) document-query surface-level similarities [2]; e.g., standard language-model-based retrieval or Okapi BM25.",0,,False
10,"We address the QPP challenge for a di erent, common, retrieval paradigm: pseudo-feedback-based retrieval [3]. That is, an initial search is performed for a query. Then, top-retrieved documents, considered pseudo relevant, are utilized to induce a query model (e.g., expanded query form) that is used for a second ( nal) retrieval.",1,ad,True
11,"Thus, in contrast to the single-retrieval setting addressed in almost all prior work on QPP, here the e ectiveness of the nal result list presented to the user depends not only on the retrieval used to produce it (e.g., properties of the induced query model), but also on the initial retrieval using which the query model was induced. A case in point, if the initial retrieval is poor, it is highly unlikely",1,ad,True
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331369",1,ad,True
13,Oren Kurland,0,,False
14,Technion ­ Israel Institute of Technology kurland@ie.technion.ac.il,0,,False
15,"that the nal result list will be e ective regardless of the querymodel induction approach employed. Accordingly, our novel approach for QPP for pseudo-feedback-based retrieval accounts for the presumed e ectiveness of the initially retrieved list, its association with the nal retrieved list and properties of the latter.",0,,False
16,"Empirical evaluation shows that the prediction quality of our approach substantially transcends that of state-of-the-art prediction methods adopted for the pseudo-feedback-based retrieval setting -- the practice in prior work on QPP for pseudo-feedback-based retrieval [6, 14, 15].",1,ad,True
17,2 RELATED WORK,0,,False
18,"In prior work on QPP for pseudo-feedback-based retrieval, existing predictors were applied either to the nal retrieved list [6, 14] or to the initially retrieved list [15]. We show that our prediction model, which incorporates prediction for both lists and accounts for their association, substantially outperforms these prior approaches.",1,corpora,True
19,"The selective query expansion task (e.g., [1, 5, 13]) is to decide whether to use the pseudo-feedback-based query model, or stick to the original query. In contrast, we predict performance for a list retrieved using the query model.",0,,False
20,"In several prediction methods, a result list retrieved using a pseudofeedback-based query model is used to predict the performance of the initially retrieved list [15, 20]. In contrast, our goal is to predict the e ectiveness of the nal result list; to that end, we also use prediction performed for the initial list.",0,,False
21,3 PREDICTION FRAMEWORK,0,,False
22,"Suppose that some initial search is applied in response to a query q over a document corpus D. Let Dinit be the list of the k most highly ranked documents. Information induced from the top documents in Dinit is used for creating a new query model (e.g., expanded query) used for a second retrieval; i.e., these documents are treated as pseudo relevant. We use Dscnd to denote the result list, presented to the user who issued q, of the k documents most highly ranked in the second retrieval.",0,,False
23,"Our goal is to predict the e ectiveness of Dscnd . To this end, we appeal to a recently proposed query performance prediction (QPP) framework [16]. Speci cally, the prediction task amounts to estimating the relevance likelihood of Dscnd , p(Dscnd |q, r ), where r is a relevance event1.",0,,False
24,"We can use reference document lists to derive an estimate for p(Dscnd |q, r ) [16]:",0,,False
25,"1This is post-retrieval prediction which relies on analyzing the retrieved list. The relevance of a retrieved list is a notion that generalizes that for a single document [16]. At the operational level, a binary relevance judgment for a list can be obtained by thresholding any list-based evaluation measure.",0,,False
26,1261,0,,False
27,Short Research Papers 3C: Search,0,,False
28,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
29,p^(Dsc,0,,False
30,nd,0,,False
31,"|q,",0,,False
32,r,0,,False
33,),0,,False
34,def,0,,False
35,",",0,,False
36,"p^(Dscnd |q, L, r )p^(L|q, r );",0,,False
37,(1),0,,False
38,L,0,,False
39,"L is a document list retrieved for q; herein, p^ is an estimate for p. The underlying idea is that strong association (e.g., similarity) of Dscnd with reference lists L (i.e., high p^(Dscnd |q, L, r )) which are presumably e ective (i.e., high p^(L|q, r )) attests to retrieval e ectiveness.",0,,False
40,"It was shown that numerous existing post-retrieval prediction methods can be instantiated from Equation 1 where a single reference list is used. Similarly, here we use Dinit as a reference list:",0,,False
41,"p^(Dscnd |q, r )  p^(Dscnd |q, Dinit , r )p^(Dinit |q, r ).",0,,False
42,(2),0,,False
43,"That is, by the virtue of the way Dscnd is created -- i.e., using information induced from Dinit -- we assume that Dinit is the",0,,False
44,"most informative reference list with respect to Dscnd 's e ectiveness. A case in point, an expanded query constructed from a poor",0,,False
45,"initial list (i.e., which mostly contains non-relevant documents) is",0,,False
46,not likely to result in e ective retrieval.,0,,False
47,3.1 Instantiating Predictors,0,,False
48,"Equation 2 can be instantiated in various ways, based on the choice",0,,False
49,"of estimates, to yield a speci c prediction method. To begin with,",0,,False
50,"any post-retrieval predictor, P, can be used to derive p^(Dinit |q, r )",0,,False
51,[16].,0,,False
52,"For p^(Dscnd |q, Dinit , r ) in Equation 2, we use logarithmic inter-",0,,False
53,polation:,0,,False
54,p^(D s c n d,0,,False
55,"|q,",0,,False
56,Dini,0,,False
57,"t,",0,,False
58,r,0,,False
59,),0,,False
60,def,0,,False
61,",",0,,False
62,"p^[P](Dscnd |q, r ) p^(Dscnd |Dinit , r )(1- );",0,,False
63,(3),0,,False
64," ( [0, 1]) is a free parameter. The estimate p^[P](Dscnd |q, r ) corre-",0,,False
65,"sponds to the predicted e ectiveness of Dscnd , where the predic-",0,,False
66,"tion, performed using the post-retrieval predictor P, ignores the",0,,False
67,knowledge that Dscnd was produced using information induced from Dinit .,0,,False
68,"The estimate p^(Dscnd |Dinit , r ) from Equation 3, of the association between Dscnd and Dinit , is usually devised based on some symmetric inter-list similarity measure sim(Dscnd , Dinit ) [16]. However, as Roitman [11] has recently suggested, a more e ective esti-",0,,False
69,mate can be derived by exploiting the asymmetric co-relevance rela-,0,,False
70,"tionship between the two lists (cf., [10]); that is, p^(Dscnd |Dinit , r )",0,,False
71,is the likelihood of Dscnd given that a relevance event has hap-,0,,False
72,pened and Dinit was observed:,0,,False
73,p^(D s c nd,0,,False
74,|Dinit,0,,False
75,",",0,,False
76,r,0,,False
77,),0,,False
78,def,0,,False
79,",",0,,False
80,p^(D s c nd,0,,False
81,|Dinit,0,,False
82,),0,,False
83,d,0,,False
84,Dscnd,0,,False
85,p^(d,0,,False
86,|Dscnd,0,,False
87,) p^(d,0,,False
88,"p^(d, r |Dinit",0,,False
89,|Dinit ) )p^(r |Dinit,0,,False
90,),0,,False
91,;,0,,False
92,(4),0,,False
93,d,0,,False
94,is,0,,False
95,a,0,,False
96,document.,0,,False
97,Following,0,,False
98,Roitman,0,,False
99,"[11],",0,,False
100,we,0,,False
101,use,0,,False
102,p^(D s c nd,0,,False
103,|Dinit,0,,False
104,),0,,False
105,def,0,,False
106,",",0,,False
107,"sim(Dscnd , Dinit ). Similarly to some prior work [7, 11], for p^(r |Dinit )",0,,False
108,"we use the entropy of the centroid (i.e., the arithmetic mean) of the",0,,False
109,"language models of documents in Dinit . We further assume that p^(d |Dscnd ) and p^(d |Dinit ) are uniformly distributed over Dscnd and Dinit , respectively. Finally, to derive p^(d, r |Dinit ), we follow",0,,False
110,Roitman [11] and use the corpus-based regularized cross entropy,0,,False
111,"(CE) between a relevance model, R [Dinit ], induced from Dinit , and",0,,False
112,"a language model, pd (·), induced from d:",0,,False
113,"p^(d, r |Dinit )",0,,False
114,def,0,,False
115,",",0,,False
116,CE(R [Dinit ] ||pd (·)) - CE(R [Dinit ] ||p D (·));,0,,False
117,(5),0,,False
118,p^D (·) is a language model induced from the corpus. Further details about language model induction are provided in Section 4.1.,0,,False
119,4 EVALUATION,0,,False
120,4.1 Experimental setup,0,,False
121,"4.1.1 Datasets. We used for evaluation the following TREC corpora and topics: WT10g (451-550), GOV2 (701-850), ROBUST (301450, 601-700) and AP (51-150). These datasets are commonly used in work on QPP [2]. Titles of TREC topics were used as queries. We used the Apache Lucene2 open source search library for indexing and retrieval. Documents and queries were processed using Lucene's English text analysis (i.e., tokenization, lowercasing, Porter stemming and stopping). For the retrieval method -- both the initial retrieval and the second one using the induced query model -- we use the language-model-based cross-entropy scoring (Lucene's implementation) with Dirichlet smoothed document language models where the smoothing parameter was set to 1000.",1,TREC,True
122,4.1.2 Pseudo-feedback based retrieval. Let cx (w) denote the oc-,0,,False
123,currence,0,,False
124,count,0,,False
125,of,0,,False
126,a,0,,False
127,term,0,,False
128,w,0,,False
129,in,0,,False
130,a,0,,False
131,text,0,,False
132,(or,0,,False
133,text,0,,False
134,collection),0,,False
135,x,0,,False
136,;,0,,False
137,let,0,,False
138,|x,0,,False
139,|,0,,False
140,def,0,,False
141,",",0,,False
142,w x,0,,False
143,cx (w),0,,False
144,denote,0,,False
145,x 's,0,,False
146,length.,0,,False
147,Let,0,,False
148,px[µ ] (w ),0,,False
149,def,0,,False
150,",",0,,False
151,cx (w )+µpD (w ) |x |+µ,0,,False
152,de-,0,,False
153,note,0,,False
154,x 's,0,,False
155,Dirichlet-smoothed,0,,False
156,language,0,,False
157,"model,",0,,False
158,where pD (w),0,,False
159,def,0,,False
160,",",0,,False
161,c,0,,False
162,D (w |D|,0,,False
163,),0,,False
164,.,0,,False
165,For,0,,False
166,a,0,,False
167,query q,0,,False
168,and a,0,,False
169,set of,0,,False
170,pseudo-relevant,0,,False
171,documents F,0,,False
172,"Dinit , pF (·) denotes a pseudo-feedback-based query model.",0,,False
173,We use three state-of-the-art pseudo-feedback-based (PRF) query-,0,,False
174,model induction methods. All three incorporate query anchoring,1,corpora,True
175,as described below. The rst is the Relevance Model [8] (RM):,0,,False
176,pF,0,,False
177,(w,0,,False
178,),0,,False
179,def,0,,False
180,",",0,,False
181,"pd[0] (w )pq[µ ] (d ),",0,,False
182,(6),0,,False
183,d F,0,,False
184,where,0,,False
185,pq[µ,0,,False
186,],0,,False
187,(d,0,,False
188,),0,,False
189,def,0,,False
190,",",0,,False
191,pd[µ ] (q ) dF p^d[µ](q),0,,False
192,and,0,,False
193,pd[µ ] (q ),0,,False
194,def,0,,False
195,",",0,,False
196,w q cd (w) log pd[µ](w).,0,,False
197,The second is the Generative Mixed Model [19] (GMM) which is,0,,False
198,estimated using the following EM algorithm iterative update rules:,0,,False
199,t,0,,False
200,(n)(w,0,,False
201,),0,,False
202,def,0,,False
203,",",0,,False
204,(1-,0,,False
205,)p,0,,False
206,(n-1) F,0,,False
207,(w,0,,False
208,),0,,False
209,(1-,0,,False
210,)p,0,,False
211,(n-1) F,0,,False
212,(w,0,,False
213,)+,0,,False
214,pD,0,,False
215,(w,0,,False
216,),0,,False
217,",",0,,False
218,pF(n)(w ),0,,False
219,def,0,,False
220,",",0,,False
221,d F cd (w )t (n)(w ),0,,False
222,wV d F cd (w )t (n)(w ) .,0,,False
223,The third is the Maximum-Entropy Divergence Minimization Model [9],0,,False
224,(MEDMM): pF (w)  exp,0,,False
225,1 ,0,,False
226,d F p^q[µ](d) log pd[0](w) -,0,,False
227,p,0,,False
228,D,0,,False
229,(w,0,,False
230,),0,,False
231,.,0,,False
232,We,0,,False
233,applied,0,,False
234,query,0,,False
235,anchoring,0,,False
236,"[8,",0,,False
237,"9,",0,,False
238,19],0,,False
239,to,0,,False
240,all,0,,False
241,three,0,,False
242,models:,0,,False
243,pF,0,,False
244,",",0,,False
245,(w,0,,False
246,),0,,False
247,def,0,,False
248,",",0,,False
249,pqMLE (w) + (1 - )pF (w); pqMLE (w) is the maximum likelihood es-,0,,False
250,"timate of w with respect to q and   [0, 1].",0,,False
251,We used the n most highly ranked documents in the initial re-,0,,False
252,"trieval for query-model induction (i.e., inducing pF (·)). Then, a sec-",0,,False
253,ond query qf was formed using the l terms w assigned the highest pF (w). We resubmitted qf to Lucene3 to obtain Dscnd .,0,,False
254,"4.1.3 Baseline predictors. As a rst line of baselines, we use Clarity [4], WIG [20] and NQC [17], which are commonly used post-retrieval QPP methods [2]. These baselines are also used for P in Eq. 3. Clarity [4] is the divergence between a language model induced from a retrieved list and that induced from the corpus.",1,WIG,True
255,2 http://lucene.apache.org 3Expressed in Lucene's query parser syntax as: w1^pF (w1) w2^pF (w2) . . . wl^pF (wl ).,0,,False
256,1262,0,,False
257,Short Research Papers 3C: Search,0,,False
258,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
259,Table 1: Prediction quality. Boldface: best results per basic QPP method and query-model induction method. Underlined: best results per query-model induction method. '' marks a statistically signi cant di erence between PFR-QPP and either the second best predictor (in case PFR-QPP is the best) or the best predictor (in case PFR-QPP is not).,0,,False
260,Method,0,,False
261,ListSim,0,,False
262,NQC(Dscnd |qf ) NQC(Dscnd |q) NQC(Dinit |q) RefList(NQC) PFR-QPP(NQC),0,,False
263,Clarity(Dscnd |qf ) Clarity(Dscnd |q) Clarity(Dinit |q) RefList(Clarity) PFR-QPP(Clarity),0,,False
264,WIG(Dscnd |qf ) WIG(Dscnd |q) WIG(Dinit |q) RefList(WIG) PFR-QPP(WIG),1,WIG,True
265,WEG(Dscnd |qf ) WEG(Dscnd |q) WEG(Dinit |q) RefList(WEG) PFR-QPP(WEG),0,,False
266,RM,0,,False
267,.442,0,,False
268,.293 .071 .483 .535 .513,0,,False
269,.292 .327 .363 .481 .408,0,,False
270,.270 .253 .237 .338 .370,0,,False
271,.231 .141 .353 .443 .456,0,,False
272,WT10g,1,WT,True
273,GMM MEDMM,0,,False
274,.532,0,,False
275,.337,0,,False
276,.228,0,,False
277,.182,0,,False
278,.051,0,,False
279,.092,0,,False
280,.397,0,,False
281,.424,0,,False
282,.531,0,,False
283,.415,0,,False
284,.557,0,,False
285,.410,0,,False
286,.325,0,,False
287,.316,0,,False
288,.227,0,,False
289,.368,0,,False
290,.350,0,,False
291,.314,0,,False
292,.567 .557,0,,False
293,.388 .398,0,,False
294,.307,0,,False
295,.388,0,,False
296,.105,0,,False
297,.153,0,,False
298,.221,0,,False
299,.224,0,,False
300,.384 .466,0,,False
301,.311 .353,0,,False
302,.205,0,,False
303,.331,0,,False
304,.134,0,,False
305,.239,0,,False
306,.311,0,,False
307,.313,0,,False
308,.483 .575,0,,False
309,.371 .436,0,,False
310,RM,0,,False
311,.490,0,,False
312,.599 .437 .486 .517 .596,0,,False
313,.230 .278 .282 .480 .615,0,,False
314,.263 .583 .562 .581 .630,0,,False
315,.585 .513 .532 .527 .660,0,,False
316,GOV2,0,,False
317,GMM MEDMM,0,,False
318,.432,0,,False
319,.410,0,,False
320,.545,0,,False
321,.353,0,,False
322,.418,0,,False
323,.283,0,,False
324,.414,0,,False
325,.414,0,,False
326,.486,0,,False
327,.457,0,,False
328,.549 .550,0,,False
329,.157,0,,False
330,.130,0,,False
331,.200,0,,False
332,.084,0,,False
333,.261,0,,False
334,.264,0,,False
335,.469 .497,0,,False
336,.414 .490,0,,False
337,.301,0,,False
338,.448,0,,False
339,.424,0,,False
340,.276,0,,False
341,.498,0,,False
342,.498,0,,False
343,.562 .603,0,,False
344,.480 .575,0,,False
345,.548,0,,False
346,.432,0,,False
347,.504,0,,False
348,.390,0,,False
349,.470,0,,False
350,.409,0,,False
351,.481 .562,0,,False
352,.427 .481,0,,False
353,RM,0,,False
354,.543,0,,False
355,.653 .475 .635 .654 .671,0,,False
356,.450 .412 .452 .582 .589,0,,False
357,.424 .651 .649 .660 .665,0,,False
358,.661 .566 .635 .654 .688,0,,False
359,ROBUST,0,,False
360,GMM MEDMM,0,,False
361,.528,0,,False
362,.436,0,,False
363,.637,0,,False
364,.622,0,,False
365,.492,0,,False
366,.620,0,,False
367,.605,0,,False
368,.602,0,,False
369,.631 .661,0,,False
370,.621 .642,0,,False
371,.393,0,,False
372,.409,0,,False
373,.350,0,,False
374,.349,0,,False
375,.441,0,,False
376,.401,0,,False
377,.575 .607,0,,False
378,.535 .566,0,,False
379,.361,0,,False
380,.381,0,,False
381,.455,0,,False
382,.430,0,,False
383,.618,0,,False
384,.578,0,,False
385,.638 .682,0,,False
386,.637 .648,0,,False
387,.656,0,,False
388,.693,0,,False
389,.571,0,,False
390,.674,0,,False
391,.619,0,,False
392,.616,0,,False
393,.633 .664,0,,False
394,.632 .688,0,,False
395,RM,0,,False
396,.537,0,,False
397,.655 .574 .550 .607 .670,0,,False
398,.313 .236 .320 .589 .652,0,,False
399,.159 .414 .554 .639 .650,0,,False
400,.627 .560 .526 .580 .675,0,,False
401,AP GMM,1,AP,True
402,.343,0,,False
403,.617 .479 .536 .530 .640,0,,False
404,.408 .350 .456 .519 .585,0,,False
405,.281 .281 .614 .580 .634,0,,False
406,.562 .491 .474 .467 .552,0,,False
407,MEDMM,0,,False
408,.407,0,,False
409,.454 .530 .502 .572 .650,0,,False
410,.339 .270 .308 .511 .651,0,,False
411,.285 .226 .505 .608 .643,0,,False
412,.575 .575 .518 .555 .664,0,,False
413,WIG [20] and NQC [17] are the corpus-regularized4 mean and,1,WIG,True
414,"standard deviation of retrieval scores in the list, respectively. We",0,,False
415,further compare with the Weighted Expansion Gain (WEG) [6] method,0,,False
416,­ a WIG alternative which regularizes with the mean score of doc-,1,WIG,True
417,uments at low ranks of the retrieved list instead of the corpus.,1,ad,True
418,We use three variants of each of the four predictors described,0,,False
419,above. The rst two directly predict the e ectiveness of the nal,0,,False
420,"retrieved list Dscnd using either (i) the original query q (denoted P(Dscnd |q)), or (ii) the query qf (denoted P(Dscnd |qf )) which was induced from Dinit as described above (cf., [15, 20]). The third variant (denoted P(Dinit |q)) is based on predicting the performance of Dscnd by applying the predictor to Dinit as was the case in [15].",0,,False
421,To evaluate the impact of our inter-list association measure in,0,,False
422,"Eq. 4, we use two additional baselines. The rst, denoted ListSim",1,ad,True
423,"[16], uses sim(Dscnd , Dinit ) to predict the performance of Dscnd . The second, denoted RefList(P) [7, 16], treats Dinit as a pseudoe ective list of Dscnd and estimates Dscnd 's performance by:",0,,False
424,p^Re,0,,False
425,f,0,,False
426,Li,0,,False
427,st,0,,False
428,(r,0,,False
429,|Dscnd,0,,False
430,",",0,,False
431,q),0,,False
432,def,0,,False
433,",",0,,False
434,"sim(Dscnd , Dinit )p^[P](Dinit |q, r ),",0,,False
435,"where P is one of the four basic QPP methods described above. There are two important di erences between our proposed method and RefList. First, we use the query q in the list association measure in Eq. 3. Second, we use an asymmetric co-relevance measure between the two lists in Eq. 4 compared to the symmetric one used in RefList.",0,,False
436,"4.1.4 Setup. Hereinafter, we refer to our proposed QPP method from Eq. 2 as PFR-QPP: Pseudo-Feedback based Retrieval QPP.",0,,False
437,"4To this end, the corpus is treated as one large document.",0,,False
438,"PFR-QPP(P) is a speci c predictor instantiated using the base predictor P. We predict for each query the e ectiveness of the 1000 documents (i.e., k , 1000) most highly ranked in the nal result list Dscnd . Prediction quality is measured using the Pearson correlation between the ground truth AP@1000 (according to TREC's relevance judgments) and the values assigned to the queries by a prediction method.",1,AP,True
439,"Most prediction methods described above incorporate free parameters. Following the common practice [2], we set m  k ­ the number of documents in a given list (i.e., either Dscnd or Dinit ) used for calculating a given predictor's value; with m  {5, 10, 20, 50, 100, 150, 200, 500, 1000}. We applied term clipping with l terms (l  {10, 20, 50, 100}) to the relevance model used in Clarity and PFRQPP. Following [16], we realized the ListSim, RefList and PFRQPP baselines using Rank-Biased Overlap (RBO(p)) [18] as our listsimilarity measure sim(·) (with p ,"" 0.95, further following [16]). For our PFR-QPP method, we set   {0, 0.1, 0.2, . . . , 0.9, 1.0}. Query models are induced from the n "","" 50 top documents. For the GMM and MEDMM models, we set their free-parameters to previously recommended values, i.e., GMM ( "", 0.5) [19] and MEDMM ( ,"" 1.2,  "","" 0.1) [9]. Unless stated otherwise, the query anchoring and clip-size parameters in all models were xed to  "", 0.9 and l ,"" 20, respectively. The prediction quality for other (, l) settings is studied in Section 4.2.""",1,corpora,True
440,"Following [12, 17], we trained and tested all methods using a 2-fold cross validation approach. Speci cally, in each dataset, we generated 30 random splits of the query set; each split had two folds. We used the rst fold as the (query) train set. We kept the second fold for testing. We recorded the average prediction quality",1,ad,True
441,1263,0,,False
442,Short Research Papers 3C: Search,0,,False
443,"SIGIR '19, July 21­25, 2019, Paris, France",0,,False
444,Pearson,0,,False
445,NQC,0,,False
446,0.7,0,,False
447,0.6,0,,False
448,0.5,0,,False
449,0.4,0,,False
450,0.3 0,0,,False
451,0.2 0.4 0.6 0.8 ,0,,False
452,WIG,1,WIG,True
453,0.7,0,,False
454,0.6,0,,False
455,0.5,0,,False
456,0.4,0,,False
457,0.3 0,0,,False
458,0.2 0.4 0.6 0.8 ,0,,False
459,Pearson,0,,False
460,Pearson,0,,False
461,0.7 0.6 0.5 0.4 0.3,0,,False
462,0,0,,False
463,0.7 0.6 0.5 0.4 0.3,0,,False
464,0,0,,False
465,Clarity,0,,False
466,0.2 0.4 0.6 0.8 ,0,,False
467,WEG,0,,False
468,0.2 0.4 0.6 0.8 ,0,,False
469,Pearson,0,,False
470,Pearson,0,,False
471,NQC,0,,False
472,0.7 0.6 0.5 0.4 0.3,0,,False
473,10 30 50 70 90 l,0,,False
474,WIG,1,WIG,True
475,0.7 0.6 0.5 0.4 0.3,0,,False
476,10 30 50 70 90 l,0,,False
477,Pearson,0,,False
478,Pearson,0,,False
479,Clarity,0,,False
480,0.7,0,,False
481,0.6,0,,False
482,0.5,0,,False
483,0.4,0,,False
484,0.3 10 30 50 70 90 l,0,,False
485,WEG,0,,False
486,0.7,0,,False
487,0.6,0,,False
488,0.5,0,,False
489,0.4,0,,False
490,0.3 10 30 50 70 90 l,0,,False
491,Pearson,0,,False
492,(a) Query anchoring ().,1,Query,True
493,(b) Number of terms (l ).,0,,False
494,Figure 1: Sensitivity to free-parameter values of the relevance model used for query-model induction.,0,,False
495,"over the 30 splits. Finally, we measured statistically signi cant differences of prediction quality using a two-tailed paired t-test with p < 0.05 computed over all 30 splits.",0,,False
496,4.2 Results,0,,False
497,"Table 1 reports the prediction quality of our method and the baselines. We can see that in the vast majority of cases, our PFR-QPP approach statistically signi cantly outperforms the baselines.",0,,False
498,"Applying basic QPP methods. We rst compare the three variants of the four basic QPP methods. We observe that, in most cases, utilizing the PRF-induced query qf for predicting the performance of the nal list Dscnd (P(Dscnd |qf )), yields better prediction quality than using the original query q (P(Dscnd |q)). In addition, predicting the performance of Dscnd by applying the base predictor to the initially retrieved list Dinit (P(Dinit |q)) yields high prediction quality -- sometimes even higher than applying the predictor to Dscnd . These ndings provide further support the motivation behind PFR-QPP: integrating prediction for the initially retrieved list and the nal retrieved list and accounting for their asymmetric co-relevance relation.",1,ad,True
499,"PFR-QPP vs. reference-list based alternatives. First, in line with previous work [7, 15, 16], the high prediction quality of ListSim and RefList in our setting shows that the similarity between the two lists is an e ective performance indicator. Moreover, combining prediction for the performance of the initial list with its similarity with the nal list (i.e., RefList) yields prediction quality that transcends in most cases that of using only the similarity (i.e., ListSim). Finally, our PFR-QPP method which uses prediction for both the initial and nal lists, and accounts for their asymmetric co-relevance relationship, outperforms both ListSim and RefList in most cases, and often to a statistically signi cant degree.",0,,False
500,"Sensitivity to query-model induction tuning. Using the ROBUST dataset and the relevance model (RM), Figure 1 reports the e ect on prediction quality of varying the value of the query anchoring parameter (; while xing l , 20) and the number of terms used after clipping (l; while xing  ,"" 0) in the query model, and hence, in qf . As can be seen, decreasing  or increasing l decreases the prediction quality of all methods. With reduced query anchoring or when using more terms, the induced queries (qf ) tend to become""",0,,False
501,"more ""verbose"", with less emphasis on the original query q. Indeed, a recent study showed that existing QPP methods are less robust for long queries [12]. Finally, we see that for any value of  and l, PFR-QPP outperforms the baselines.",0,,False
502,5 CONCLUSIONS,0,,False
503,"We addressed the QPP task for pseudo-feedback-based retrieval, where the nal retrieved list depends on an initially retrieved list ­ e.g., via a query model induced from the latter and used to produce the former. Our approach accounts for the predicted e ectiveness of each of the two lists as well as to their asymmetric co-relevance relation. Empirical evaluation showed that our approach signi cantly outperforms a variety of strong baselines.",1,ad,True
504,ACKNOWLEDGEMENT,0,,False
505,We thank the reviewers for their comments. This work was supported in part by the Israel Science Foundation (grant no. 1136/17),0,,False
506,REFERENCES,0,,False
507,"[1] Giambattista Amati, Claudio Carpineto, and Giovanni Romano. Query di culty, robustness, and selective application of query expansion. In Proceedings of ECIR, pages 127­137, 2004.",1,Query,True
508,"[2] David Carmel and Oren Kurland. Query performance prediction for ir. In Proceedings of SIGIR, pages 1196­1197, New York, NY, USA, 2012. ACM.",1,Query,True
509,"[3] Claudio Carpineto and Giovanni Romano. A survey of automatic query expansion in information retrieval. ACM Comput. Surv., 44(1):1:1­1:50, January 2012.",0,,False
510,"[4] Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. Predicting query performance. In Proceedings of SIGIR, pages 299­306, New York, NY, USA, 2002. ACM.",0,,False
511,"[5] Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. A framework for selective query expansion. In Proceedings of CIKM, pages 236­237, New York, NY, USA, 2004. ACM.",0,,False
512,"[6] Ahmad Khwileh, Andy Way, and Gareth J. F. Jones. Improving the reliability of query expansion for user-generated speech retrieval using query performance prediction. In CLEF, 2017.",1,ad,True
513,"[7] Oren Kurland, Anna Shtok, Shay Hummel, Fiana Raiber, David Carmel, and Ofri Rom. Back to the roots: A probabilistic framework for query-performance prediction. In Proceedings of CIKM, pages 823­832, New York, NY, USA, 2012. ACM.",0,,False
514,[8] Victor Lavrenko and W. Bruce Croft. Relevance based language models. In Proceedings of SIGIR.,0,,False
515,[9] Yuanhua Lv and ChengXiang Zhai. Revisiting the divergence minimization feedback model. In CIKM '14.,0,,False
516,"[10] Fiana Raiber, Oren Kurland, Filip Radlinski, and Milad Shokouhi. Learning asymmetric co-relevance. In Proceedings of ICTIR, pages 281­290, 2015.",1,ad,True
517,"[11] Haggai Roitman. Enhanced performance prediction of fusion-based retrieval. In Proceedings of ICTIR, pages 195­198, New York, NY, USA, 2018. ACM.",0,,False
518,"[12] Haggai Roitman. An extended query performance prediction framework utilizing passage-level information. In Proceedings of ICTIR, pages 35­42, New York, NY, USA, 2018. ACM.",0,,False
519,"[13] Haggai Roitman, Ella Rabinovich, and Oren Sar Shalom. As stable as you are: Re-ranking search results using query-drift analysis. In Proceedings of HT, pages 33­37, New York, NY, USA, 2018. ACM.",0,,False
520,"[14] Harrisen Scells, Leif Azzopardi, Guido Zuccon, and Bevan Koopman. Query variation performance prediction for systematic reviews. In Proceedings of SIGIR, pages 1089­1092, New York, NY, USA, 2018. ACM.",1,Query,True
521,"[15] Anna Shtok, Oren Kurland, and David Carmel. Using statistical decision theory and relevance models for query-performance prediction. In Proceedings of SIGIR, pages 259­266, New York, NY, USA, 2010. ACM.",0,,False
522,"[16] Anna Shtok, Oren Kurland, and David Carmel. Query performance prediction using reference lists. ACM Trans. Inf. Syst., 34(4):19:1­19:34, June 2016.",1,Query,True
523,"[17] Anna Shtok, Oren Kurland, David Carmel, Fiana Raiber, and Gad Markovits. Predicting query performance by query-drift estimation. ACM Trans. Inf. Syst., 30(2):11:1­11:35, May 2012.",1,ad,True
524,"[18] William Webber, Alistair Mo at, and Justin Zobel. A similarity measure for inde nite rankings. ACM Trans. Inf. Syst., 28(4):20:1­20:38, November 2010.",0,,False
525,[19] Chengxiang Zhai and John La erty. Model-based feedback in the language modeling approach to information retrieval. In CIKM '01.,0,,False
526,"[20] Yun Zhou and W. Bruce Croft. Query performance prediction in web search environments. In Proceedings of SIGIR, pages 543­550, New York, NY, USA, 2007. ACM.",1,Query,True
527,1264,0,,False
528,,0,,False
