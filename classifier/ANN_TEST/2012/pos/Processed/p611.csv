,sentence,label,data,regex
0,A Generalized Hidden Markov Model with Discriminative Training for Query Spelling Correction,1,Query,True
1,"Yanen Li, Huizhong Duan and ChengXiang Zhai",0,,False
2,"Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801",0,,False
3,"{yanenli2, duan9, czhai}@illinois.edu",0,,False
4,ABSTRACT,0,,False
5,"Query spelling correction is a crucial component of modern search engines. Existing methods in the literature for search query spelling correction have two major drawbacks. First, they are unable to handle certain important types of spelling errors, such as concatenation and splitting. Second, they cannot efficiently evaluate all the candidate corrections due to the complex form of their scoring functions, and a heuristic filtering step must be applied to select a working set of top-K most promising candidates for final scoring, leading to non-optimal predictions. In this paper we address both limitations and propose a novel generalized Hidden Markov Model with discriminative training that can not only handle all the major types of spelling errors, including splitting and concatenation errors, in a single unified framework, but also efficiently evaluate all the candidate corrections to ensure the finding of a globally optimal correction. Experiments on two query spelling correction datasets demonstrate that the proposed generalized HMM is effective for correcting multiple types of spelling errors. The results also show that it significantly outperforms the current approach for generating top-K candidate corrections, making it a better firststage filter to enable any other complex spelling correction algorithm to have access to a better working set of candidate corrections as well as to cover splitting and concatenation errors, which few existing method in academic literature can correct.",1,Query,True
6,Categories and Subject Descriptors,0,,False
7,H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval--Query Alteration,1,Query,True
8,Keywords,0,,False
9,"Query Spelling Correction, Generalized Hidden Markov Models, Discriminative Training for HMMs",1,Query,True
10,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'12, August 12­16, 2012, Portland, Oregon, USA. Copyright 2012 ACM 978-1-4503-0757-4/11/07 ...$15.00.",1,ad,True
11,1. INTRODUCTION,1,DUC,True
12,"The ability to automatically correct potentially misspelled queries has become an indispensable component of modern search engines. People make errors in spelling frequently. Particularly, search engine users are more likely to commit misspellings in their queries as they are in most scenarios exploring unfamiliar contents. Automatic spelling correction for queries helps the search engine to better understand the users' intents and can therefore improve the quality of search experience. However, query spelling is not an easy task, especially under the strict efficiency constraint. In Table 1 we summarize major types of misspellings in real search engine queries. Users not only make typos on single words, (insertion, deletion and substitution), but can also easily mess up with word boundaries (concatenation and splitting). Moreover, different types of misspelling could be committed in the same query, making it even harder to correct. Unfortunately,",0,,False
13,Table 1: Major Types of Query Spelling Errors,1,Query,True
14,Type,0,,False
15,Example,0,,False
16,Correction,0,,False
17,Insertion In-Word Deletion,0,,False
18,esspresso vollyball,0,,False
19,espresso volleyball,0,,False
20,Substitution Mis-use,0,,False
21,comtemplate contemplate capital hill capitol hill,0,,False
22,Cross-Word,0,,False
23,Concatenation Splitting,0,,False
24,intermilan power point,0,,False
25,inter milan powerpoint,0,,False
26,"no existing query spelling correction approaches in the literature are able to correct all major types of errors, especially for correcting splitting and concatenation errors. To the best of my knowledge, the only work that can potentially address this problem is [24] in which a Conditional Random Field (CRF) model is proposed to handle a broad set of query refinements. However, this work considers query correction and splitting/merging as different tasks, hence it is unable to correct queries with mixed types of errors, such as substitution and splitting errors in one query. In fact splitting and merging are two important error types in query spelling correction, and a major research challenge of query spelling correction is to accurately correct all major types of errors simultaneously. On the other hand, while modern industrial systems such as Google can handle this problem relatively well, it's unclear what they have done, especially what resources they have employed in order to solve the challenges.",1,ad,True
27,"Another major difficulty in automatic query spelling correction is the huge search space. Theoretically, any sequence",0,,False
28,611,0,,False
29,"of characters could potentially be the correction of a misspelled query. It is clearly intractable to enumerate and evaluate all possible sequences for the purpose of finding the correct query. Thus a more feasible strategy is to search in a space of all combinations of candidate words that are in a neighborhood of each query word based on editing distance. The assumption is that a user's spelling error of each single word is unlikely too dramatic, thus the correction is most likely in the neighborhood by editing distance. Unfortunately, even in this restricted space, the current approaches still cannot enumerate and evaluate all the candidates because their scoring functions involve complex features that are expensive to compute. As a result, a separate filtering step must first be used to prune the search space so that the final scoring can be done on a small working set of candidates. Take [7] as a two-stage method example, in the first stage, a Viterbi or A* search algorithm is used to generate a small set of most promising candidates, and in the second stage different types of features of the candidates are computed and a ranker is employed to score the candidates. However, this two-stage strategy has a major drawback in computing the complete working set. Since the filtering stage uses a non-optimal objective function to ensure efficiency, it is quite possible that the best candidate is filtered out in the first stage, especially because we cannot afford a large working set since the correction must be done online while a user is entering a query. The inability of searching the complete space of candidates leads to non-optimal correction accuracy.",1,ad,True
30,"In this paper, we propose a generalized Hidden Markov Model (gHMM) for query spelling correction that can address deficiencies of the existing approaches discussed above. The proposed gHMM can model all major types of spelling errors, thus enabling consideration of multiple types of errors in query spelling correction. In the proposed gHMM, the hidden states represent the correct forms of words, and the outcomes are the observed (potentially) misspelled terms. In addition, each state is associated with a type, indicating merging, splitting or in-word transformation operation. The proposed HMM is generalized in the sense that it would allow adjustment of both emission probabilities and transition probabilities to accommodate the non-optimal parameter estimation. Unfortunately, such an extension of HMM makes it impossible to use a standard EM algorithm for parameter estimation. To solve this problem, we propose a perceptron-based discriminative training method to train the parameters in the HMM.",1,ad,True
31,"Moreover, a Viterbi-like search algorithm for top-K paths is designed to efficiently obtain a small number of highly confident correction candidates. This algorithm can handle splitting/merging of multiple words. It takes into account major types of local features such as error model, language model, and state type information. The error model is trained on a large set of query correction pairs from the web. And web scale language model is obtained by leveraging the Microsoft Web N-gram service [1].",0,,False
32,"We conducted extensive evaluation on our proposed gHMM. For this purpose, we have constructed a query correction dataset from real search logs, which has been made publicly available. Experimental results verify that the gHMM can effectively correct all major types of query spelling errors. It also reveal that the gHMM can run as efficient as the common used noisy channel model, while it achieves much",1,ad,True
33,"better results for obtaining the candidate space of query corrections. Therefore, in addition to being used as standing alone query correction module, the proposed gHMM can also be used as a more effective first-stage filtering module to more effectively support any other complicated scoring functions such as those using complex global features.",1,ad,True
34,2. RELATED WORK,0,,False
35,"Spelling correction has a long history [8]. Traditional spellers focused on dealing with non-word errors caused by misspelling a known word as an invalid word form. A common strategy at that time was to utilize a trusted lexicon and certain distance measures, such as Levenshtein distance [13]. The size of lexicon in traditional spellers is usually small due to the high cost of manual construction of lexicon. Consequently, many valid word forms such as human names and neologisms are rarely included in the lexicon. Later, statistical generative models were introduced for spelling correction, in which the error model and n-gram language model are identified as two critical components. Brill and Moore demonstrated that a better statistical error model is crucial for improving a speller's accuracy [3]. But building such an error model requires a large set of manually annotated word correction pairs, which is expensive to obtain. Whitelaw et al. alleviated this problem by leveraging the Web to automatically discover the misspelled/corrected word pairs [12].",1,ad,True
36,"With the advent of the Web, the research on spelling correction has received much more attention, particularly on the correction of search engine queries. Many research challenges are raised, which are non-existent in traditional settings of spelling correction. More specifically, there are many more types of spelling errors in search queries, such as misspelling, concatenation/splitting of query words, and misuse of legitimate yet inappropriate words. Research in this direction includes utilizing large web corpora and query log [4, 5, 2], training phrase-based error model from clickthrough data [10] and developing additional features [7]. However, two important challenges are under addressed in these approaches, i.e., correcting splitting and concatenation errors, and ensuring complete search in the candidate space to evaluate an effective scoring function.",1,ad,True
37,"Query alteration/refinement is a broader topic which naturally subsumes query spelling correction. Beside correcting the misspelled query, query alteration/refinement also need to modify the ineffective query so that it could be more suitable for the search intent. For this purpose, many research topics have been studied. Query expansion expands the query with additional terms to enrich the query formulation [14, 15, 16]. Query segmentation divides a query into semantically meaningful sub-units [17, 18]. Other query reformulation methods intend to replace the inappropriate query terms with effective keywords to bridge the vocabulary gaps [19]. Particularly, there is research attempt [24] to use a unified model to do a broad set of query refinements such as correction, segmentation and even stemming. However, it treats query correction and splitting/merging as separate tasks, which is not true for real world queries. Also, it has very limited ability for query correction. For example, it only allows one letter difference in deletion/insertion/substitution errors.",1,Query,True
38,"Query spelling correction also shares similarities with many other NLP tasks, such as speech recognition and machine translation. In many of these applications, HMM has been",1,Query,True
39,612,0,,False
40,"found very useful [21, 20]. Our generalized HMM model for query spelling correction is novel in that it models all the major types of misspellings in a unified framework. A discrete training method is also proposed to train the parameters in the model. It is demonstrated that the gHMM model we use is very effective for the task of query spelling correction.",0,,False
41,3. PROBLEM SETUP AND CHALLENGES,0,,False
42,"Formally, let  be the alphabet of a language and L  + be a large lexicon of the language. We define the query spelling correction problem as:",0,,False
43,"Given a query q  +, generate top-K most effective corrections Y ,"" (y1, y2, ..., yk) where yi  L+ is a candidate correction, and Y is sorted according to the probability of yi being the correct spelling of the target query.""",0,,False
44,"It is worth noting that from a search engine perspective, the ideal output Y should be sorted according to the probability of yi retrieving the most satisfying results in search. However, in practice it is very difficult to measure the satisfaction as unlike in ad hoc retrieval where the query is given in its correct form, here the real query is unknown. As a result, different corrections could simply lead to queries with different meanings and it would be very subjective to determine which query actually satisfies the user. In this paper, we are mostly concerned with the lexical and semantic correctness of queries with the assumption that correction of mis-spelled query terms most likely would lead to improved retrieval accuracy.",1,ad,True
45,"The problem of query spelling correction is significantly harder than the traditional spelling correction. Previous researches show that approximately 10-15% of search queries contain spelling errors [5]. First, it is difficult to cover all the different types of errors. The spelling errors generally fall into one of the following four categories: (1) in-word transformation, e.g. insertion, deletion, misspelling of characters. This type of error is most frequent in web queries, and it is not uncommon that up to 3 or 4 letters are misspelled; (2) mis-use of valid word, e.g. ""persian golf""  ""persian gulf"". It is also a type of in-word tranformation errors; (3) concatenation of multiple words, e.g. ""unitedstatesofamerica""  ""united states of america""; (4) splitting a word into parts, e.g. ""power point slides""  ""powerpoint slides"". Among all these types, the splitting and concatenation errors are especially challenging to correct. Indeed, no existing approaches in the academic literature can correct these two types of errors. Yet, it's important to correct all types of errors because users might commit different types of errors or even commit these errors at the same time. A main goal of this work is to develop a new HMM framework that can model and correct all major types of errors including splitting and concatenation.",1,ad,True
46,"Second, it is difficult to ensure complete search of all the candidate space because the candidate space is very large. The existing work addresses this challenge by using a twostage method, which searches for a small set of candidates with simple scoring functions and do re-ranking on top of these candidates. Unfortunately, the simple scoring function used in the first stage cannot ensure that the nominated candidate corrections in the first stage always contain the best correction, thus no matter how effective the final scoring function is, we may miss the best correction simply because of the use of two separate stages. In this paper, we address",1,ad,True
47,this challenge by developing a generalized HMM that can both be efficiently scored to ensure complete search in the candidate space and accurately correct all types of errors in a unified way.,0,,False
48,4. A GENERALIZED HMM FOR QUERY SPELLING CORRECTION,0,,False
49,"Our algorithm accepts a query as input, and then generates a small list of ranked corrections as output by a generalized Hidden Markov Model (gHMM). It is trained by a discriminative method with labeled spelling examples. Given a query, it scores candidate spelling corrections in a one-stage fashion and outputs the top-K corrections, without using a re-ranking strategy. Other components of our algorithm include a large clean lexicon, the error model and the language model. In this section we will focus on the gHMM model structure, the discriminative training of it, as well as the efficient computation of spelling corrections.",0,,False
50,4.1 The gHMM Model Structure,0,,False
51,"We propose a generalized HMM Model to model the spelling correction problem. We call it a generalized HMM because there are several important differences between it and the standard HMM model which will be explained later. Without loss of generality, let an input query be q , q[1:n] and a corresponding correction be y ,"" y[1:m] where n, m are the length of the query and correction, which might or might not be equal. Here we introduce hidden state sequence z "", z[1:n] ,"" (s1, s2, ..., sn) in which z and q have the same length. An individual state si is represented by a phrase corresponding to one or more terms in correction y[1:m]. Together the phrase representing z is equal to y. Therefore, finding best-K corrections Y "","" (y1, y2, ..., yk) is equivalent to finding best-K state sequences Z "","" (z1, z2, ..., zk). In addition, there is a type t associated with each state, indicating the operation such as substitution, splitting, merging etc. Also, in order to facilitate the merging state we introduce a NULL state. The NULL state is represented by an empty string, and it doesn't emit any phrase. There can be multiple consecutive NULL states followed by a merging state. Table 2 summarizes the state types and the spelling errors they correspond to. Having the hidden states defined, the hypothesized process of observing a mis-spelled query is as follows:""",1,ad,True
52,1. sample a state s1 and state type t1 from the state space  and the type set T ;,0,,False
53,"2. emit a word in q1, or empty string if the s1 is a NULL state according to the type specific error model;",0,,False
54,"3. transit to s2 with type t2 according to the state transition distribution, and emit another word, or multiple words in q[1:n] if s2 is a merging state;",0,,False
55,4. continue until the whole (potentially) mis-spelled query q is observed.,0,,False
56,"Figure 1 illustrates our gHMM model with a concrete example. In this example, there are three potential errors with different error types, e.g. ""goverment""  ""government"" (substitution), ""home page""  ""homepage"" (splitting), ""illinoisstate""  ""illinois state"" (concatenation). The state path shown in Figure 1 is one of the state sequences",0,,False
57,613,0,,False
58,Table 2: State Types in gHMM,0,,False
59,State Type,0,,False
60,In-word Transformation,0,,False
61,Mis-use,0,,False
62,Operation Deletion Insertion Substitution Transformation,0,,False
63,Spelling Errors Insertion Deletion Substitution Word Mis-use,0,,False
64,Merging,0,,False
65,Merge Multiple Words,0,,False
66,Splitting,0,,False
67,Splitting,0,,False
68,Split one Word,0,,False
69,Concatenation,0,,False
70,to Multiple Words,0,,False
71,"that can generate the query. Take state s3 for example, s3 is represented by phrase homepage. Since s3 is a merging state, it emits a phrase home page with probability P (home page|homepage). And s3 is transited from state s2 with probability P (s3|s2). With this model, we are able to come up with arbitrary corrections instead of limiting ourselves to an incomprehensive set of queries from query log. By simultaneously modeling the misspellings on word boundaries, we are able to correct the query in a more integrated manner.",1,ad,True
72,query:,0,,False
73,goverment,0,,False
74,home,0,,False
75,page,0,,False
76,of,0,,False
77,illinoisstate,0,,False
78,emission: goverment,0,,False
79,home page,0,,False
80,of,0,,False
81,illinoistate,0,,False
82,state,0,,False
83,sequence: government,0,,False
84,,0,,False
85,homepage,0,,False
86,of,0,,False
87,illinois state,0,,False
88,s1,0,,False
89,type: in-word transformation,0,,False
90,s2,0,,False
91,type: NULL,0,,False
92,s3,0,,False
93,type: merging,0,,False
94,s4,0,,False
95,type: in-word transformation,0,,False
96,s5,0,,False
97,type: splitting,0,,False
98,Figure 1: Illustration of the gHMM Model,0,,False
99,4.2 Generalization of HMM Scoring Function,0,,False
100,"For a standard HMM [23], let  ,"" {A, B, } be the model parameters of the HMM, representing the transition probability, emission probabilities and initial state probabilities respectively. Given a list of query words q[1:n] (obtained by splitting empty spaces), the state sequence z "","" (s1, s2, ..., sn) that best explains q[1:n] can be calculated by:""",0,,False
101,z,0,,False
102,",",0,,False
103,arg,0,,False
104,max z,0,,False
105,"P (z|q[1:n],",0,,False
106,"A,",0,,False
107,"B,",0,,False
108,),0,,False
109,(1),0,,False
110,"However, theoretically the phrase in a state can be chosen arbitrarily, so estimating {A, B, } is such a large space is almost impossible in the standard HMM framework. In order to overcome this difficulty, the generalized Hidden Markov Model proposed in this work generalizes the standard HMM as follows: (1) gHMM introduces state type for each state, which indicates the correction operations and can reduce the search space effectively; (2) it adopts feature functions to parameterize the measurement of probability of a state sequence given a query. Such treatment can not only map the transition and emission probabilities to feature functions with a small set of parameters, but can also add additional feature functions such as the ones incorporating state type information. Another important benefit of the feature function representation is that we can use discriminative training",1,ad,True
111,"on the model with labeled spelling corrections, which will lead to a more accurate estimation of the parameters.",1,ad,True
112,"Formally, in our gHMM model, there is an one-to-one relationship between states in a state sequence and words in the original query. For a given query q , q[1:n] and the sequence of states z ,"" (s1, s2, ..., sn), we define a context hi for every state in which an individual correction decision is made. The context is defined as hi "",""< si-1, ti-1, si, ti, q[1:n] > where si-1, ti-1, si, ti are the previous and current state and type decisions and q[1:n] are all query words.""",1,ad,True
113,"The generalized HMM model measures the probability of a state sequence by defining feature vectors on the contextstate pairs. A feature vector is a function that maps a context-state pair to a d-dimensional vector. Each component of the feature vector is an arbitrary function operated on (h, z). Particularly, in this study we define 2 kinds of feature vectors, one is j(si-1, ti-1, si, ti), j ,"" 1...d, which measures the interdependency of adjacent states. We can map this function to a kind of transition probability measurement. The other kind of feature function, fk(si, ti, q[1:n]), k "", 1...d measures the dependency of the state and its observation. We can consider it as a kind of emission probability in the standard HMM point of view. Such feature vector representation of HMM is introduced by Collins [22] and successfully applied to the POS tagging problem.",1,ad,True
114,"Specifically, we have designed several feature functions as follows: we define a function of (si-1, ti-1, si, ti) as",0,,False
115,"1(si-1, ti-1, si, ti) ,"" logPLM (si|si-1, ti-1, ti) (2)""",1,LM,True
116,"to measure the language model probabilities of two consecutive states. Where PLM (si|si-1) is the bigram probability calculated by using Microsoft Web N-gram Service [1]. The computation of PLM (si|si-1) may depend on the state types, such as in a merging state.",1,LM,True
117,"We have also defined a set of functions in the form of fk(si, ti, q[1:n]), which are dependent on the query words and state type, measuring the emission probability of a state. For example, we define",0,,False
118,8,0,,False
119,"<logPerr(si, qi)",0,,False
120,"f1(si, ti, q[1:n]) , :",0,,False
121,0,0,,False
122,if qi is in-word transformed to si and qi / Lexicon L otherwise,0,,False
123,(3),0,,False
124,"as a function measuring the emission probability given the state type is in-word transformation and qi is out of dictionary. e.g. ""goverment""  ""government"". Perr(si, qi) is the emission probability computed by an error model which measures the probability of mis-typing ""government"" to ""goverment"". (see Section 5.2).",0,,False
125,8,0,,False
126,"<logPerr(si, qi)",0,,False
127,"f2(si, ti, q[1:n]) , :",0,,False
128,0,0,,False
129,if ti is splitting and qi  Lexicon L,0,,False
130,otherwise,0,,False
131,(4),0,,False
132,"to capture the emission probability if the state is of splitting type and qi is in dictionary. e.g. ""homepage""  ""home page"".",0,,False
133,614,0,,False
134,"8 <logPerr(s, qi)",0,,False
135,"f3(si, ti, q[1:n]) , :",0,,False
136,0,0,,False
137,if ti is Mis-use and qi  Lexicon L,0,,False
138,otherwise,0,,False
139,(5),0,,False
140,to get the emission probability if a valid word is transformed to another valid word.,0,,False
141,"Note that in Equation (3), (4), and (5), we use the same error model Perr(si, qi) (see Section 5.2 for detail) to model the emission probabilities from merging, splitting errors etc. in the same way as in-word transformation errors. However we assign different weights to the transformation probabilities resulted from different error types via discriminative training on a set of labeled query-correction pairs.",0,,False
142,"Overall, we have designed a set of feature functions that are all relied on local dependencies, ensuring that the topK state sequences can be computed efficiently by Dynamic Programming.",0,,False
143,"After establishing the feature vector representation, the log-probability of a state sequence and its corresponding types logP (z, t|q[1:n]) is proportional to:",0,,False
144,X n Xd,0,,False
145,"Score(z, t) ,",0,,False
146,"j j (si-1, ti-1, si, ti)",0,,False
147,(6),0,,False
148,"i,1 j,1",0,,False
149,X n X d,0,,False
150,+,0,,False
151,"µkfk(si, ti, q[1:n])",0,,False
152,"i,1 k,1",0,,False
153,"where j , µk are the component coefficients needed to be estimated. And the best state sequence can be found by:",0,,False
154,"zt ,"" arg max Score(z, t)""",0,,False
155,(7),0,,False
156,"z,t",0,,False
157,"Note that the form of Score(z, t) is similar to the objective function of a Conditional Random Field model [26], but with an important difference that there is no normalization terms in our model. Such difference also enables the efficient search of top-K state sequences (equivalent to top-K corrections) using Dynamic Programming, which will be introduced shortly.",0,,False
158,4.3 Discriminative Training,0,,False
159,"Motivated by ideas introduced in [22], we propose a perceptron algorithm to train the gHMM model. To the best of our knowledge, this is the first attempt to use discriminative approach to train a HMM on the problem of query spelling correction. Now we describe how to estimate the parameters j , µk from a set of <query, spelling correction> pairs. The estimation procedure follows the perceptron learning framework. Take the j for example. We first set all the j at random. For each query q, we search for the most likely state sequence with types z[i1:ni], ti[1:ni] using the current parameter settings. Such search process is described in Algorithm 2 by setting K ,"" 1. After that, if the best decoded sequence is not correct, we update j by simple addition: we promote the amount of j by adding up j values computed between the query and labeled correction y , and demote the amount of j by the sum of all j values computed between the""",1,ad,True
160,query and the top-ranked predictions. We repeat this pro-,0,,False
161,"cess for several iterations until converge. Finally in step 11 and 12, we average all oj,i in each iteration to get the final estimate of j, where oj,i is the stored value for the parameter j after i's training example is processed in iteration",0,,False
162,o. Similar procedures can apply to µk. The detailed steps,0,,False
163,"are listed in Algorithm 1. Note that in step 7 and 8 the feature functions j(qi, y i, t i) and fk(qi, y i, t i) depend on unknown types t i that are inferred by computing the best word-level alignment between qi and y i.",0,,False
164,Algorithm 1: Discriminative Training of gHMM,0,,False
165,"input : A set of <query, spelling correction> pairs q[i1:ni], y[1i:mi] for i , 1...n",0,,False
166,"output: Optimal estimate of ^j, µ^k, where",0,,False
167,"j  {1, ..., d}, k  {1, ..., d }",0,,False
168,"1 Init Set ^j, µ^k to random numbers; 2 for o  1 to O do",0,,False
169,3 for i  1 to n do,0,,False
170,/* identify the best state sequence and the,0,,False
171,associated types of the i'th query with the,0,,False
172,current parameters via Algorithm 2:,0,,False
173,*/,0,,False
174,4,0,,False
175,"z[i1:ni], ti[1:ni] ,"" arg maxu[1:ni],t[1:ni] Score(u, t)""",0,,False
176,"/* where u[1:ni]  Sni , Sni is all possible state",0,,False
177,sequences given q[i1:ni],0,,False
178,*/,0,,False
179,5,0,,False
180,"if z[i1:ni] , y[1i:mi] then",0,,False
181,6,0,,False
182,"update and store every j, µk according to:",0,,False
183,7 8,0,,False
184,j µk,0,,False
185,", ,",0,,False
186,"µjk++PPnini,,ii11",0,,False
187,"j (qi, fk (q i ,",0,,False
188,y y,0,,False
189,"i, i,",0,,False
190,t t,0,,False
191,"ii))--P Pnini,,ii 11",0,,False
192,"j (qi, fk (q i ,",0,,False
193,"zi, zi,",0,,False
194,ti ti,0,,False
195,) ),0,,False
196,9,0,,False
197,else,0,,False
198,10,0,,False
199,Do nothing,0,,False
200,/* Average the final parameters by:,0,,False
201,*/,0,,False
202,11 12,0,,False
203,^j µ^k,0,,False
204,", ,",0,,False
205,"PO PoO,1",0,,False
206,"o,1",0,,False
207,"Pn Pin,1",0,,False
208,"i,1",0,,False
209,"oj ,i /nO, µok,i/nO,",0,,False
210,where where,0,,False
211,j k,0,,False
212,"{1, ..., d} {1, ..., d }",0,,False
213,"13 return parameters ^j, µ^k;",0,,False
214,This discriminative training algorithm will converge after several iterations. Here we state the following theorem on its convergence:,0,,False
215,"Theorem 1: For any training example (qi, y i) which is separable with margin , then for Algorithm 1:",0,,False
216,Number,0,,False
217,of,0,,False
218,mistakes,0,,False
219,R2 2,0,,False
220,where R is a constant satisfying,0,,False
221,"i, z  {G(qi) - {y i}} : ||(qi, y i, t i) - (qi, zi, ti)|| R,",0,,False
222,"where G(qi) is a set of predictions generated by Algorithm 2, and the  functions can be calculated from Eq. (6) by ignoring  and µ. The proof of Theorem 1 is not shown due to the space limitation.",0,,False
223,4.4 Query Correction Computation,1,Query,True
224,"Once the optimal parameters are obtained by the discriminative training procedure introduced above, the final top-K corrections can be directly computed, avoiding the need for a",0,,False
225,615,0,,False
226,"separate stage of candidate re-ranking. Because the feature functions are only relied on local dependencies, it enables the efficient search of top-K corrections via Dynamic Programming. This procedure involves three major steps: (1) candidate states generation; (2) score function evaluation; (3) filtering.",0,,False
227,"At the first step, for each word in query q, we generate a set of state candidates with types. The phrase representations in such states are in Lexicon L and within editing distance  from the query word. Then a set of state sequences are created by combining these states. In addition, for each state sequence we have created, we also create another state sequence by adding a NULL state at the end, facilitating a (potential) following merging state. It is important to note that if the  is too small, it will compromise the final results due to the premature pruning of state sequences. In this work  , 3 is chosen in order to introduce adequate possible state sequences.",1,ad,True
228,"At the score function evaluation step, we update the scores for each state sequence according to Eq. (6). The evaluation is different for sequence with different ending state types. Firstly, for a sequence ending with a NULL state, we don't evaluate the scoring function. Instead, we only need to keep track of the state representation of its previous state. Secondly, for a sequence ending with a merging state, it merges the previous one or more consecutive NULL states. And the scoring function takes into account the information stored in the previous NULL states. For instance, to 1(si-1, ti-1 ,"" N U LL, si, ti "","" merging), we have""",1,ad,True
229,"1(si-1, NULL, si, merging) , logPLM (si-2|si) (8)",1,LM,True
230,"i.e. skipping the NULL state and pass the previous state representation to the merging state. In this way, we can evaluate the scoring function in multiple consecutive NULL states followed by a merging state, which enables the correction by merging multiple query words. Thirdly, for a sequence ending with a splitting state, the score is accumulated by all bigrams within the splitting state. For example,",0,,False
231,"1(si-1, ti-1, si, ti , splitting)",0,,False
232,(9),0,,False
233,"kX -1 , logPLM (w1|si-1) + logPLM (wi+1|wi)",1,LM,True
234,"j,1",0,,False
235,"where si ,"" w1w2...wk. On the other hand, the evaluation of fk(si, ti, q[1:n]) is easier because it is not related to previous states. The error model from the state representation to the query word is used to calculate these functions.""",0,,False
236,"At the final step, we filter most of the state sequences and only keep top-K best state sequences in each position corresponding to each query word. In sum, we have proposed and implemented an algorithm via Dynamic Programming (see Algorithm 2) for efficiently computing top-K state sequences (corrections). If there are n words in a query, and the maximum number of candidate states for each query word is M , the computational complexity for finding top-K corrections is O(n · K · M 2).",0,,False
237,5. OTHER COMPONENTS,0,,False
238,"Besides the gHMM model and its discriminative training, our spelling correction algorithm also relies on other important components, such as a large trusted lexicon, the error model, and the language model. In this section we will describe these components.",0,,False
239,Algorithm 2: Decoding Top-K Corrections,0,,False
240,"input : A query q[1:n], parameters , µ output: top K state sequences with highest likelihood",0,,False
241,"/* Z[i, si]: top K state sequences for sub-query q[1:i] that ending with state si. For each z  Z[i, si], phrase denotes the representation and score",0,,False
242,denotes the likelihood of z given q[1:i].,0,,False
243,*/,0,,False
244,"/* Z[i]: top state sequences for all Z[i, si].",0,,False
245,*/,0,,False
246,"1 Init Z[0] , {}",0,,False
247,2 for i  1 to n do,0,,False
248,"/* for term qi, get all candidate states",0,,False
249,*/,0,,False
250,"3 S  si, si : edit dist(si, qi)  , si has type si.type",0,,False
251,4 for si  S do,0,,False
252,5,0,,False
253,for z  Z[i - 1] do,0,,False
254,6,0,,False
255,a  new state sequence,0,,False
256,7,0,,False
257,a.phrase  z.phrase  {si},0,,False
258,8,0,,False
259,update a.score according to si.type and Eq.,0,,False
260,"(6), Eq. (8) and Eq. (9)",0,,False
261,9,0,,False
262,"Z[i, si]  a",0,,False
263,/* delay truncation for N U LL states,0,,False
264,*/,0,,False
265,10,0,,False
266,"if si.type , N U LL and i , n then",0,,False
267,11,0,,False
268,"sort Z[i, si] by score",0,,False
269,12,0,,False
270,"truncate Z[i, si] to size K",0,,False
271,13 sort Z[n] by score 14 truncate Z[n] to size K 15 return Z[n];,0,,False
272,5.1 A Large-scale Trusted Lexicon,0,,False
273,"As mentioned in Section 3, how to define a proper lexicon L is important to a successful speller. We find that with a clean vocabulary, it will significantly improve the performance of spelling correction. However, to obtain such a clean vocabulary is usually difficult in practice. To do this, we make use of the Wikipedia data. Particularly, we select the top 2 million words from Wikipedia by their word frequencies, and automatically curate the obtained words by removing those frequent but illegitimate words from the vocabulary. This curate process involves checking if the word appears in the title of a Wikipedia article, comparing the bigram probability of other words etc. Finally we obtained 1.2 million highly reliable words in the vocabulary. Please note that all words in this vocabulary are unigrams; numbers and punctuations are not included. And no stemming and other forms of modification are conducted.",1,Wiki,True
274,5.2 Error Model Training,0,,False
275,"Error Model. The feature functions fk() depend on an error model, which measures the probability that one word is misspelled into another. Previous studies have shown that a weighted editing distance model trained with a sufficient large set of correction pairs could achieve a comparable performance with a sophisticated n-gram model [6]. Meanwhile, a higher order model has greater tendency to overfit if the training data is not large enough. Given these considerations, we adopt the Weighted Edit Distance (WED) to estimate the error model. More specifically, we first compute the best character-level alignment of two words, and the WED between these two words is the summation of the WED of all aligned character pairs. We model the character-level WED",1,ad,True
276,616,0,,False
277,"as the character transformation probability. In addition, null character is included in the vocabulary to accomodate the insertion and deletion operations. In order to compute such a probability, a large set of query-correction pairs is obtained by leveraging the spelling services from Google and Bing; and then this probability is estimated as the expected number of transformation from one character to another in these aligned pairs. The training queries are from the MSN search query log released by the Microsoft Live Labs in 2006 (6.5 million queries). They are submitted to the spelling ser- vices, and the corrections are recorded once consensus is reached.",1,ad,True
278,5.3 Use of Web N-gram Model,0,,False
279,"Another important factor in selecting and ranking the correction candidates is the prior probability of a correction phrase. It represents our prior belief about how likely a query will be chosen by the user without seeing any input from the user. In this work we make use of the Web n-gram service provided by Microsoft [1]. Web n-gram model intends to model the n-gram probability of English phrases with the parameters estimated from the entire Web data. It also differentiates the sources of the data to build different language models from the title, anchor text and body of Web pages, as well as the queries from query log. In our study, we find the title model is the most effective for query spelling correction. We hypothesize that this may be because the training data for query model is much noisier. Particularly, misspelled queries may be included in the training data, which makes it less effective for the task of spelling correction. Despite trained with the Web data, Web n-gram model may also suffer from data sparseness in higher order models. To avoid this issue, we make use of the bigram model in building our spelling system.",0,,False
280,6. EXPERIMENTS AND RESULTS,0,,False
281,"In order to test the effectiveness and efficiency of our proposed gHMM model, in this section we conduct extensive experiments on two web query spelling datasets. We first introduce the datasets, and describe the evaluation metrics we use for evaluation. Then we compare our model with other baselines in terms of accuracy and runtime.",0,,False
282,6.1 Dataset Preparation,0,,False
283,The experiments are conducted on two query spelling correction datasets. One is the TREC dataset based on the publicly available TREC queries (2008 Million Query Track). This dataset contains 5892 queries and the corresponding corrections annotated by the MSR Speller Challenge 1 organizers. There could be more than one plausible corrections for a query. In this dataset only 5.3% of queries are judged as misspelled.,1,TREC,True
284,"We have also annotated another dataset that contains 4926 MSN queries, where for each query there is at most one correction. Three experts are involved in the annotation process. For each query, we consult the speller from two major search engines (i.e. Google and Bing). If they agree on the returned results (including the case if the query is just unchanged), we take it as the corrected form of the input query. If the results are not the same from the two, as least one human expert will manually annotate the most likely",0,,False
285,1http://web-ngram.research.microsoft.com/spellerchallenge/,0,,False
286,"corrected form of the query. Finally, about 13% of queries are judged as misspelled in this dataset, which is close to the error rate of real web queries. This dataset is publicly available to all researchers.",0,,False
287,We divide the TREC and MSN datasets into training and test sets evenly. Our gHMM model as well as the baselines are trained on the training sets and finally evaluated on the TREC test set containing 2947 queries and MSN test set containing 2421 queries.,1,TREC,True
288,6.2 Evaluation Metrics,0,,False
289,We evaluate our system based on the evaluation metrics,0,,False
290,"proposed in Microsoft Speller Challenge [1], including ex-",0,,False
291,"pected precision, expected recall and expected F1 measure.",0,,False
292,"As used in previous discussions, q is a user query and Y (q) ,"" (y1, y2, , yk) is the set of system output with posterior probabilities P (yi|q). Let S(q) denote the set of plausi-""",0,,False
293,ble spelling variations annotated by the human experts for,0,,False
294,q. Expected Precision is computed as:,0,,False
295,"precision , 1 X |Q|",0,,False
296,X,0,,False
297,"Ip(y, q)P (y|q)",0,,False
298,(10),0,,False
299,qQ yY (q),0,,False
300,"where Ip(y, q) ,"" 1 if y  S(q), and 0 otherwise. And expected recall is defined as:""",0,,False
301,"recall , 1 X |Q|",0,,False
302,X,0,,False
303,"Ir(Y (q), a)/|S(q)|",0,,False
304,(11),0,,False
305,qQ aS(q),0,,False
306,"where Ir(Y (q), a) ,"" 1 if a  Y (q) for a  S(q), and 0 otherwise. Expected F1 measure can be computed as:""",0,,False
307,F1,0,,False
308,",",0,,False
309,2 · precision · recall precision + recall,0,,False
310,(12),0,,False
311,6.3 Overall Effectiveness,0,,False
312,"We first investigate the overall effectiveness of the gHMM model. For suitable query spelling correction baselines, especially approaches that can handle all types of query spelling errors, we first considered using the CRF model proposed in [24]. This method aims at a broad range of query refinements and hence might be also applicable to query correction. However, we decided not to compare this model for the following reasons. Firstly, we communicated with the authors of [24] and knew that the program is un-reusable. Secondly, as mentioned in Section 1 this work suffers from several drawbacks for query spelling correction: (1) it is unable to correct queries with mixed types of errors, such as substitution and splitting errors in one query, because the model treats query correction and splitting/merging as different tasks; (2) this model only allows 1 character error for substitution/insertion/deletion. And the error model is trained on the <query, correction> examples that only contain 1 character error. Such design is over simplified for real-world queries, in which more than 1 character errors are quite common. In fact, within the queries that contain spelling errors in the MSN dataset, there are about 40.6% of them contain more than 1 character errors. Therefore it is expected model in [24] will have in inferior performance",1,ad,True
313,"Because of the reasons stated above, the best baseline method that we can possibly compare with is the system",0,,False
314,617,0,,False
315,"that achieved the best performance in Microsoft Speller Challenge [25] (we call it Lueck-2011). This system relies on candidate corrections from third-party toolkits such as hunspell and Microsoft Wrod Breaker Service [11] , and it re-ranks the candidates by a simple noisy channel model. We communicated with the author and obtained the corrections by running the Web API of this baseline approach. We also include a simple baseline called Echo, which is just echoing the original query as the correction response with posterior probability 1. It reflects the basic performance for a naive method. Experiments are conducted on TREC and MSN datasets.",1,AP,True
316,"We report the results of all methods in Table 3. In this experiment up to top 10 corrections are used in all approaches. The results in Table 3 indicate that gHMM outperforms Lueck-2011 significantly on recall and F1 on the TREC dataset. Lueck-2011 has a small advantage on precision, possibly due to the better handling the unchanged queries. On the MSN dataset which is considered harder since it has more misspelled queries, gHMM also achieves high precision of 0.910 and recall of 0.966, which are both significantly better than that of the Lueck-2011 (0.896 and 0.921). On another important performance metric, which measures the F1 on misspelled queries (F1 Mis), gHMM outperforms Lueck-2011 by a large margin (0.550 vs. 0.391 on TREC and 0.566 vs. 0.363 on MSN). These results demonstrate that gHMM is very effective for handling all types of spelling errors in search queries overall.",1,TREC,True
317,Table 3: gHMM Compared to Baselines,0,,False
318,Dataset Method Precision Recall F1,0,,False
319,F1,0,,False
320,Mis,0,,False
321,TREC,1,TREC,True
322,Echo,0,,False
323,0.949,0,,False
324,Lueck-2011 0.963,0,,False
325,gHMM,0,,False
326,0.960,0,,False
327,0.876 0.911 N/A 0.932 0.947 0.391 0.976 0.968 0.550,0,,False
328,MSN,0,,False
329,Echo,0,,False
330,0.869,0,,False
331,Lueck-2011 0.896,0,,False
332,gHMM,0,,False
333,0.910,0,,False
334,0.869 0.869 N/A 0.921 0.908 0.363 0.966 0.937 0.566,0,,False
335,6.4 Results by Error Types,0,,False
336,"Further, we also break down the results by error types that are manually classified so that we can see more clearly the distribution of types of spelling errors and how well our gHMM model addressing each type of errors. We present the results of this analysis in Table 4, only with our model on both datasets. Top 40 corrections are used since it achieves the best results. The breakdown results show that most queries are in the group of ""no error"", which are easier to handle than the other three types. As a result, the overall excellent performance was mostly because the system performed very well on the ""no error"" group. Indeed, the system has substantially lower precision on the queries with the other three types of errors. The concatenation errors seem to be the hardest to correct, followed by the splitting errors, and the in-word transformation errors (insertion, deletion and substitution, word mis-use) seem to be relatively easier.",1,ad,True
337,6.5 gHMM for Working Set Construction,0,,False
338,Since the gHMM can efficiently search in the complete,0,,False
339,Table 4: Results by Spelling Error Type,0,,False
340,Dataset Error Type % Queries Precision Recall,0,,False
341,TREC,1,TREC,True
342,no error transformation concatenation splitting,0,,False
343,94.9 3.3 1.3 0.5,0,,False
344,0.990 0.388 0.348 0.500,0,,False
345,0.982 0.840 0.877 0.792,0,,False
346,MSN,0,,False
347,no error transformation concatenation splitting,0,,False
348,86.9 11.1 1.7 0.6,0,,False
349,0.978 0.493 0.150 0.429,0,,False
350,1.0 0.762 0.600 0.571,0,,False
351,F1 0.986 0.531 0.498 0.613 0.989 0.599 0.240 0.490,0,,False
352,Note: % of queries might sum up to more than 100% since there might be multiple types of errors in one query.,0,,False
353,"candidate space and compute the top-K spelling corrections in a one-stage manner, it is very interesting to test its effectiveness for constructing a working set of candidate corrections to enable more complex scoring functions to be used for spelling correction. For this purpose, we compare gHMM with the common used noisy channel model, whose parameters, namely error model probabilities and bigram language probabilities are estimated by the procedure mentioned in previous sections. We use recall to measure the completeness of the constructed working set, because it represents the percentage of true corrections given the number of predicted corrections. Table 5 shows the recall according to different number of outputs. It indicates that the recall of gHMM is steadily increasing by a larger number of outputs. By only outputting top-5 corrections, gHMM reaches recall of 0.969 in TREC and 0.964 in MSN. In contrast, the noisy channel model has a substantial gap in term of recall compared to gHMM. This result strongly demonstrates the superior effectiveness of gHMM in constructing a more complete working set of candidate corrections, which can be utilized by other re-ranking approaches which could further improve the correction accuracy.",1,ad,True
354,Table 5: gHMM vs. Noisy Channel Model on Recall,0,,False
355,Dataset TREC,1,TREC,True
356,MSN,0,,False
357,Method N-C gHMM N-C gHMM,0,,False
358,1 0.869 0.887 0.866 0.920,0,,False
359,5 0.896 0.969 0.870 0.964,0,,False
360,10 0.899 0.976 0.873 0.966,0,,False
361,20 0.901 0.981 0.876 0.9667,0,,False
362,40 0.902 0.983 0.886 0.967,0,,False
363,Note: N-C refers to the noisy channel model,0,,False
364,6.6 Efficiency,0,,False
365,"The runtime requirement of query correction is very stringent. Theoretically, the gHMM with local feature functions can search top-K corrections efficiently by our proposed tokK Viterbi algorithm. Here we make a directly comparison between the runtime of gHMM and a basic noisy channel that only needs to compute the error model probabilities and bigram language probabilities. Such a basic model is also implemented with Viterbi algorithm. It is run on a Windows server equipped with 2 Quad-core 64 bit 2.4 GHz CPUs and 8 GB RAM. All necessary bigram language probabilities are crawled from Microsoft Web N-gram Service and cached in local memory. We plot the runtime per query (in milliseconds) according to the number of predicted correc-",1,ad,True
366,618,0,,False
367,"tions in Figure 2. According to Figure 2, the computation of top-1 correction by gHMM is fast (34 ms) if the number of output is set to 1. It increases as the number of output increases because the search space is increased. Interestingly, the runtime of gHMM and the noisy channel model is of the same order of magnitude. This empirical evidence confirms the theoretical result that top-K spelling corrections can be computed efficiently via our proposed top-K Viterbi algorithm.",0,,False
368,increases as the lexicon size increases. However the recall is not sensitive to the lexicon size.,0,,False
369,Figure 4: Correction Results by Lexicion Size,0,,False
370,Figure 2: Runtime Comparison,0,,False
371,7. DISCUSSION,0,,False
372,Finally we discuss how the proposed gHMM model behaves according to the variation of important factors. Such as the number of spelling corrections in the output and the size of lexicon L etc.,0,,False
373,7.1 Number of Predicted Corrections,0,,False
374,"Our datasets include all plausible corrections for a query. However it's unknown that how many corrections an algorithm should output to achieve a perfect recall. In this section we investigate how the number of predicted spelling corrections affects the precision and recall. We have carried out experiments on five correction sizes (1,5,10,20,40) on both datasets. Figure 3 summarizes the results. As expected, a bigger number of corrections leads to higher recall, and the most drastical increase of recall lies from 1 correction to 5.",1,ad,True
375,Figure 3: Results by Number of Corrections,0,,False
376,7.2 Effect of the Lexicon Size,0,,False
377,"The size of the trusted lexicon is an important factor influencing the speller correction result. In order to investigate the effect of lexicon size, we conducted a set of experiments on both datasets using different lexicon sizes (ranging from 100,000 to 900,000). Results in Figure 4 show that the effect of lexicon size is significant on precision: the precision",0,,False
378,7.3 Clean vs. Noisy Lexicon,0,,False
379,"In Table 6, we show the effects of using a clean lexicon for improving the precision and recall of the spelling system. We can see that for both test sets, there is noticeable improvement in precision. By removing the noise in the automatically constructed lexicon, our system is able to find matches for candidate queries more precisely.",0,,False
380,Table 6: Clean vs. Noisy Lexicon Dataset Lexicon Type Precision Recall F1 TREC clean lexicon 0.960 0.983 0.971,1,TREC,True
381,noisy lexicon 0.950 0.984 0.966 MSN clean lexicon 0.910 0.967 0.938,0,,False
382,noisy lexicon 0.896 0.967 0.930,0,,False
383,Note: maximum corrections are set to 40 in this experiment,0,,False
384,8. CONCLUSIONS AND FUTURE WORKS,0,,False
385,"In this paper, we presented a novel generalized hidden Markov model (gHMM) for query spelling correction that can address two major deficiencies of previous approaches to query spelling correction, i.e., inability of handling all the major types of spelling errors, and inability of searching efficiently in the complete candidate space. We have also proposed a novel discriminative training method for the gHMM model which enables us to go beyond regular HMM to incorporate useful local features for more effective query spelling correction. Experiment results on two query correction datasets show that gHMM can effectively handle all the major types of spelling errors and outperforms a stateof-the-art baseline by a large margin.",1,ad,True
386,"Moreover, our generalized HMM, equipped with the discriminative training, scores the query corrections directly and output a final ranked list of spelling corrections, without needing a filtering stage to prune the candidate space as typically required by an existing method. We have demonstrated that as an efficient one-stage approach, the proposed gHMM can also be used as a filter to construct a more complete working set than the existing noisy channel filter, making it possible to combine it with any complicated spelling correction methods to further improve accuracy. In other words, the proposed gHMM model can serve as a better candidate generation method in a two-stage framework where any sophisticated and potentially more effective spelling correction method can be applied to re-rank the generated candidates",0,,False
387,619,0,,False
388,"for more accurate corrections. In addition, we have also curated a large spelling correction dataset from real-world queries and made it available to the research community.",1,ad,True
389,"In this work, we only focused on local feature functions in order to ensure efficient evaluation of all the candidates in the search space. However, some global features, such as the overall editing distance, frequency of the query in a query log can be potentially utilized to further improve the correction accuracy. How to add the global features to the gHMM model, while still ensuring efficient search and evaluation of all the candidates in the search space, is an interesting direction for future work.",1,ad,True
390,9. ACKNOWLEDGMENTS,0,,False
391,"This paper is based upon work supported in part by a Microsoft grant, the National Science Foundation under grant CNS-1027965, and MIAS - the Multimodal Information Access and Synthesis center at UIUC, part of CCICADA, and a DHS Center of Excellence.",0,,False
392,10. REFERENCES,0,,False
393,[1] http://research.microsoft.com/enus/collaboration/focus/cs/web-ngram.aspx.,0,,False
394,"[2] F. Ahmad and G. Kondrak. Learning a spelling error model from search query logs. In HLT/EMNLP. The Association for Computational Linguistics, 2005.",1,ad,True
395,"[3] E. Brill and R. Moore. An improved error model for noisy channel spelling correction. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong, 2000.",0,,False
396,"[4] Q. Chen, M. Li, and M. Zhou. Improving query spelling correction using web search results. In EMNLP-CoNLL, pages 181­189. ACL, 2007.",0,,False
397,"[5] S. Cucerzan and E. Brill. Spelling correction as an iterative process that exploits the collective knowledge of web users. In EMNLP, 2004.",0,,False
398,"[6] H. Duan and B.-J. P. Hsu. Online spelling correction for query completion. In Proceedings of the 20th international conference on World wide web, WWW '11, pages 117­126. 2011, ACM.",0,,False
399,"[7] J. Gao, X. Li, D. Micol, C. Quirk, and X. Sun. A large scale ranker-based system for search query spelling correction. In C.-R. Huang and D. Jurafsky, editors, COLING, pages 358­366. 2010.",0,,False
400,"[8] K. Kukich. Techniques for automatically correcting words in text. ACM computing surveys, 24(4), 1992.",0,,False
401,"[9] M. J. D. Powell. An efficient method for finding the minimum of a function of several variables without calculating derivatives. The Computer Journal, 7(2):155­162, 1964.",0,,False
402,"[10] X. Sun, J. Gao, D. Micol, and C. Quirk. Learning phrase-based spelling error models from clickthrough data. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL '10, pages 266­274, Stroudsburg, PA, USA, 2010.",0,,False
403,"[11] K. Wang, C. Thrasher, and B.-J. P. Hsu. Web scale nlp: a case study on url word breaking. In Proceedings of the 20th international conference on World wide web, WWW '11, pages 357­366, New York, NY, USA, 2011. ACM.",0,,False
404,"[12] C. Whitelaw, B. Hutchinson, G. Chung, and G. Ellis.",0,,False
405,"Using the web for language independent spellchecking and autocorrection. In EMNLP, 890­899. ACL, 2009.",0,,False
406,"[13] Levenshtein, V I. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet Physics Doklady, 10(8), 707-710, 1966.",1,ad,True
407,"[14] Jinxi Xu and W. Bruce Croft. Query expansion using local and global document analysis. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR '96. ACM, New York, NY.",1,Query,True
408,"[15] Yonggang Qiu and Hans-Peter Frei. Concept based query expansion. In Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR '93. ACM, New York, NY, USA, 160-169.",0,,False
409,"[16] Mandar Mitra, Amit Singhal, and Chris Buckley. Improving automatic query expansion. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR '98.",0,,False
410,"[17] B. Tan and F. Peng. Unsupervised query segmentation using generative language models and wikipedia. In Proceeding of the 17th international conference on World Wide Web, WWW '08, pages 347­356. 2008.",1,wiki,True
411,"[18] Y. Li, B.-J. P. Hsu, C. Zhai, and K. Wang. Unsupervised query segmentation using clickthrough for information retrieval. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, SIGIR '11, pages 285­294. 2011.",0,,False
412,"[19] Xuanhui Wang, ChengXiang Zhai. Mining Term Association Patterns from Search Logs for Effective Query Reformulation. In CIKM'08. 479-488.",1,Query,True
413,"[20] Stephan Vogel, Hermann Ney, and Christoph Tillmann. HMM-based word alignment in statistical translation. In Proceedings of the 16th conference on Computational linguistics, Volume 2 (COLING '96). Stroudsburg, PA, USA, 836-841.",0,,False
414,"[21] B.H. Juang. Hidden Markov models for speech recognition. In Technometrics, Vol. 33, No. 3, 1991.",0,,False
415,"[22] M. Collins. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In EMNLP '02, pages 1-8, Stroudsburg, PA, USA, 2002.",0,,False
416,"[23] L. R. Rabiner. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings of the IEEE, pages 257­286, 1989.",0,,False
417,"[24] J. Guo, G. Xu, H. Li, and X. Cheng. A unified and discriminative model for query refinement. In Proceedings of the 31st annual international ACM SIGIR, SIGIR '08, pages 379­386. 2008.",0,,False
418,"[25] G. Luec. A data-driven approach for correcting search quaries. In Spelling Alteration for Web Search Workshop, July 2011.",0,,False
419,"[26] J. Lafferty, A. McCallum, and F. Pereira. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning, pages 282­289, San Fransisco, 2001. Morgan Kaufmann.",0,,False
420,620,0,,False
421,,0,,False
