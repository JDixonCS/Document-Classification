,sentence,label,data,regex
0,Reactive Index Replication for Distributed Search Engines,0,,False
1,Flavio P. Junqueira,0,,False
2,"Yahoo! Research Barcelona, Spain",1,Yahoo,True
3,fpj@yahoo-inc.com,0,,False
4,Vincent Leroy,0,,False
5,"Yahoo! Research Barcelona, Spain",1,Yahoo,True
6,leroy@yahoo-inc.com,0,,False
7,Matthieu Morel,0,,False
8,"Yahoo! Research Barcelona, Spain",1,Yahoo,True
9,matthieu@yahoo-inc.com,0,,False
10,ABSTRACT,0,,False
11,"Distributed search engines comprise multiple sites deployed across geographically distant regions, each site being specialized to serve the queries of local users. When a search site cannot accurately compute the results of a query, it must forward the query to other sites. This paper considers the problem of selecting the documents indexed by each site focusing on replication to increase the fraction of queries processed locally. We propose RIP, an algorithm for replicating documents and posting lists that is practical and has two important features. RIP evaluates user interests in an online fashion and uses only local data of a site. Being an online approach simplifies the operational complexity, while locality enables higher performance when processing queries and documents. The decision procedure, on top of being online and local, incorporates document popularity and user queries, which is critical when assuming a replication budget for each site. Having a replication budget reflects the hardware constraints of any given site. We evaluate RIP against the approach of replicating popular documents statically, and show that we achieve significant gains, while having the additional benefit of supporting incremental indexes.",1,corpora,True
12,Categories and Subject Descriptors,0,,False
13,H.3.3 [Information Storage Systems]: Information Retrieval Systems,0,,False
14,General Terms,0,,False
15,"Design, Experimentation, Performance",0,,False
16,Keywords,0,,False
17,"Multi-site web search engine, distributed index, replication",0,,False
18,1. INTRODUCTION,1,DUC,True
19,"Distributed search engines aim at horizontal scalability for Web search [2, 6]. The search engine is distributed over",0,,False
20,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'12, August 12­16, 2012, Portland, Oregon, USA. Copyright 2012 ACM 978-1-4503-1472-5/12/08 ...$10.00.",1,ad,True
21,"several search sites deployed in (smaller) data centers spread across the world. Each search site only indexes a fraction of the documents, and receives the queries of the users in its region. When a query cannot be answered locally, it is forwarded to the other sites in order to compute accurate responses [2, 8]. Distributed search engines share the workload among several sites. Thus, deploying an extra site in a new data center increases the capacity of the search engine.",1,ad,True
22,"Designing an efficient distributed search engine is a challenging task. Traditional search engine algorithms rely on all the resources being accessed within a single data center. However, in the case of distributed search, the index is split among several distant locations. Accessing data in another search site translates into a higher response time due to network latency. Ideally, a site processes most queries locally to offer low response time and avoid the cost of processing the query in several sites. To enable this property, a careful selection of the documents to index on each site becomes necessary to guarantee that most frequently requested documents can be retrieved locally. A trivial solution is of course to replicate all documents across all sites. This solution, however desirable from a latency perspective, induces a high utilization of computer resources. Consequently, an important goal is to reduce resource utilization while providing low latency to end users through local query processing.",1,ad,True
23,"Brefeld et al. use machine-learning techniques to assign each document to one or multiple sites [4]. Their approach, however, does not consider the popularity of documents or a resource budget for each site. The popularity of documents becomes important when having to selectively drop documents due to resource constraints. Following a different approach, Blanco et al. propose to assign each document to a single site, and later rely on user activity to proceed to documents replication [3]. Their method relies on terms distribution and cache invalidations of a document to predict at which search site it is most likely to be requested. However, they do not propose any replication strategy.",0,,False
24,"Upon receiving a query, a search site processes it against its local index and then estimates whether other sites may have better documents, in which case the query is forwarded. Several heuristics have been developed for estimating the quality of documents in different sites. They rely on some partial knowledge of the content of the other search sites, either per-term score thresholds [2], or the scores of previously processed queries [8]. These algorithms are conservative: they can generate false positives, but no false negatives. Hence, the results computed by the distributed search engines are always the same as the ones generated by a single-",0,,False
25,831,0,,False
26,Site Si,0,,False
27,Crawler,0,,False
28,MIi,0,,False
29,SIi,0,,False
30,FIi,0,,False
31,Local query processing,0,,False
32,Query,1,Query,True
33,Master site,0,,False
34,selection,0,,False
35,full replication,0,,False
36,Index replication service,0,,False
37,partial replication,0,,False
38,Distributed query processing,0,,False
39,Query forwarding heuristic,1,Query,True
40,Results,0,,False
41,MIj,0,,False
42,SIj,0,,False
43,FIj,0,,False
44,User,0,,False
45,Site Sj,0,,False
46,Figure 1: Architecture of a distributed search engine,0,,False
47,"site search engine. While these two approaches achieve a reasonable precision, they only target static indexes and require offline computation.",0,,False
48,Contributions. We make the following contributions in this paper:,0,,False
49,"· We propose RIP (Reactive Indexing Protocol), a practical algorithm to selectively replicate documents and posting lists across sites in a distributed search engine. The algorithm makes decisions online and locally;",0,,False
50,· RIP uses document popularity and user queries to select documents to replicate. Such information is important to ensure locality while respecting resource constraints;,0,,False
51,"· We evaluate the algorithm and compare it against a baseline that replicates documents statically, as well as a reactive documents replication algorithm. We show that RIP increases query locality by 23% while only increasing the index size of each site by 14%.",0,,False
52,"Roadmap. The remainder of this paper is organized as follows. We describe the architecture of the distributed search engine in Section 2. In Section 3 we present RIP, and evaluate its performance in Section 4. Finally, we review related work in Section 5 and conclude with Section 6.",1,ad,True
53,2. ARCHITECTURE,0,,False
54,"We consider a distributed search engine comprising a set of search sites S deployed across geographically different regions. The collective of the sites forming the search engine indexes a document collection D. We present a global view of the architecture of the distributed search engine in Figure 1, and describe the elements composing it throughout this section.",0,,False
55,2.1 Traditional search engine architecture,1,ad,True
56,"The architecture of a search engine is typically divided into three components. The crawler fetches documents from the Web and discovers new content by following hypertext links. The indexer processes D, the collection of documents, to generate an inverted index. For each term t present in the collection, the inverted index contains a posting list, i.e., a list of the documents that contain t. A popular technique for implementing an index is incremental indexing. Incremental indexing enables the addition, deletion, or update of indexed documents without fully regenerating the index. This fea-",1,ad,True
57,"ture is particularly important in the case of large scale Web search engines where the cost of regenerating the full index to update frequently modified Web pages (e.g. news) is prohibitive. Incremental indexes offer a good trade-off between the freshness of the documents and the processing performance. Hence, in this paper, we consider the case of an incremental indexer. The query processor receives user queries and processes them against the index. Historically, commercial Web search engines have preferred conjunctive query processing [14]: a document has to contain all the terms in the query to be in the result set. To obtain the result set, the query processor computes the intersection of the posting lists of the query terms, evaluating the scores of the documents using a ranking function. The k (typically 10) results with the highest scores are returned to the user.",1,ad,True
58,2.2 Assignment of documents to sites,0,,False
59,"In a distributed search engine, each search site has its own index and processes the queries of the users in its region. It is therefore important to carefully select documents to index in each site to tailor the data structures of the sites for their users. For a short response time, a search site must be able to process most of the queries it receives using its local index alone. Indexing documents that are popular in a region enables locality. However, it is also important to limit the number of documents indexed at each site. The query processing latency in fact increases with the size of the index [5]. Furthermore, replicating a large fraction of the documents at each site limits the scalability of the search engine. In this work, we assume that each search site has a fixed index capacity, either due to limited resources, or arbitrarily chosen to reduce the processing time. We express this limit using number of postings, i.e., the sum of the length of all the posting lists in the index.",0,,False
60,"To the extent of our knowledge, two approaches have been developed to compute an assignment of documents to search sites. The first one relies on machine learning algorithms to analyze new documents upon their discovery and assigns them to one or more search sites [4]. The second one assigns each document to a single master site [3]. This assignment results in a minimal index, with each document indexed in a single location. The master site of a document is responsible for maintaining it in its index, which guarantees that the distributed search engine has the same recall as a centralized implementation. Our work builds up on the master selection approach [3]. We assume the existence of an algorithm that assigns each document to a single search site. Hence, the search site Si has a master index MIi which indexes all the documents Si is the master of. Typically, this index represents the majority of Si's index capacity.",0,,False
61,"The popularity of Web pages typically follows a power law: while most of the Web pages are unpopular, a few of them are requested very frequently. A Web page might present high locality, being popular in a single region, or be popular across many regions. Distributed search engines work better in a context where documents have a strong locality. Indeed, this means that each document only needs to be indexed by the search site located in the region where it is popular. Fortunately, a large fraction of the popular Web pages exhibit a high divergence in their popularity across regions [3]. Nevertheless, there are still documents which are popular across region boundaries and are requested by users",0,,False
62,832,0,,False
63,"of different search sites. The master selection algorithm, ensures that each document is indexed by its master site.",0,,False
64,"In this paper, we propose RIP, a Reactive Indexing Protocol. RIP uses part of the remaining index capacity of each search site to replicate documents that are frequently requested locally, but were assigned to a different search site by the master selection algorithm. Contrary to the master selection algorithm, which only relies on the content of the document, RIP is reactive: it analyzes the behavior of the users at each site to dynamically adjust replication decisions. These fully replicated documents form the shadow index, denoted SIi for the site Si.",1,ad,True
65,2.3 Distributed query processing,0,,False
66,"In a distributed search engine, a search site indexes locally only a fraction of the documents. To preserve the quality of results, a distributed search engine must generate the same results as a centralized implementation. A query submitted to a site Si must be evaluated on the full set of documents D, whether they are indexed locally (MIi and SIi) or not. So far, the main approach to executing queries in a distributed search engine relies upon query forwarding [2, 8]. When processing a query, a search site first computes results using its local index, and then relies on a forwarding heuristic to determine whether another site may be able to provide higher quality results. If there are such sites according to the evaluation of the heuristic, then the query is forwarded to the relevant search sites for further processing. Finally, the results are then merged and returned to the user.",0,,False
67,"The forwarding heuristic is conservative with respect to query forwarding, and it can generate false positives, but no false negatives. As already mentioned in Section 2.2, it is preferable to answer a query locally, since it reduces the response time. It is therefore important to devise an accurate forwarding heuristic to reduce the forwarding rate.",1,ad,True
68,"Existing forwarding heuristics [2, 8] leverage properties of the search engine ranking function to compute an upper bound on the score of documents which are not indexed locally. This ranking function s(d|q), presented on Figure 2, was introduced by Baeza-Yates et al. [2]. The score of a document d is computed by averaging partial scores over the terms of the query q. A document d has a quality score, expressed by f (d), and a relevance score for a term t, computed by g(d|t). The parameters wf and wg weight quality and relevance respectively. The partial score of a document d for a term t, expressed as r(d|t), is typically maintained in the posting lists of the index to improve query evaluation performance. Note that distributed search engines are compatible with more complex ranking functions, including positional features, machine learning and diversification. In these cases, the s(d|q) ranking function is used in the first phase of a two-phase ranking [9], which ensures that relevant documents will be known locally before the execution of the second phase of the ranking.",0,,False
69,"The heuristic we propose here supports the same ranking function. A site Si may partially replicate the posting lists of the master indexes of other sites in order to estimate the need to forward queries. This forwarding index is designated as FIi. The posting lists of forwarding indexes are ordered by partial score. For a given term t, Si replicates the list of documents that have the highest partial score r(d|t). A document whose master is Sj and that contains several",0,,False
70,|q|,0,,False
71,s(d|q),0,,False
72,",",0,,False
73,wf f (d),0,,False
74,+,0,,False
75,wg |q|,0,,False
76,g(d|ti),0,,False
77,"i,1",0,,False
78,"r (d |t) , wf f (d) + wgg(d|t)",0,,False
79,|q|,0,,False
80,1,0,,False
81,"s(d|q) , |q|",0,,False
82,r(d|ti),0,,False
83,"i,1",0,,False
84,Figure 2: Ranking function,0,,False
85,"terms may only be indexed in one of the posting lists of FIi, provided its other partial scores are low.",0,,False
86,2.4 Index structure,0,,False
87,"In this section, we summarize the different elements of the index of a search site. The index of a site Si is logically divided into three components: Master index MIi: It contains the documents that were assigned to Si by the master selection algorithm. Shadow index SIi: It contains documents that are fully replicated by Si. They were assigned to one of the other search sites by the master selection algorithm, but are replicated to improve the query processing locality. Forwarding index FIi: It contains partial information about documents assigned to the other search sites. For a given term t, the posting list associated to t in FIi contains the list of documents that have the highest partial scores for t. Documents having high partial scores are also likely to have a high popularity. Hence, SIi and FIi may overlap.",1,ad,True
88,"These logical indexes represent the data available to Si for processing queries. The posting lists of search engines are, in most cases, ordered by document ID. This allows high compression rates, and is particularly efficient for conjunctive query processing [14]. In this work, we do not make any assumption on the layout of MIi and SIi. However, we present FIi as an index sorted by impact. This means that the postings are ordered by partial scores. This assumption simplifies the description of the algorithm, but there is, in practice, no reason not to implement these three indexes as a single incremental index relying on document ID ordered posting lists.",0,,False
89,3. REACTIVE INDEXING PROTOCOL,0,,False
90,3.1 Problem definition,0,,False
91,"We consider the following problem. In a distributed search engine, each search site is assigned an index budget expressed as the maximum number of posting lists entries a site can accomodate. The collection of documents D is split across the search sites through an initial master index selection algorithm. The remaining index capacity of each site is freely used to replicate documents and posting lists of the other sites. A sequence of queries is submitted to each search site and the goal is to maximize the amount of queries that are answered locally, without query forwarding. Consequently, a search site updates its index as it processes queries. A search site modifies its index only between query executions, and it does so for a given query only after its results are returned to the user.",0,,False
92,Let res(q) be the set of the k documents obtaining the highest scores for the query q according the the search en-,0,,False
93,833,0,,False
94,"gine's ranking function s(d|q). A site Si has to fulfill two conditions to answer q locally. First, the documents of res(q) must all be indexed and copied locally. The search site needs a copy of the document data to generate the snippet presented on the results page, and also in the case that it uses using a two-phase ranking [9]. The search site also needs to be able to compute accurate scores for all the top-k results to display them properly ranked. This requirement can be expressed as follows:",0,,False
95,"d  res(q), d  MIi  d  SIi .",0,,False
96,"Second, Si should be able to determine, using local data structures, that no other document could potentially score higher than the lowest score of the results:",0,,False
97,"d  (D - res(q)), e  res(q), scBound (d |q)  s(e|q) ;",0,,False
98,where scBound (d |q) is the function that computes an upper,0,,False
99,bound on the score of the document d for the query q using,0,,False
100,"only local information, i.e. the information from MIi, SIi",0,,False
101,"and FIi. We estimate the future queries Qfi of Si using Qi, a recent",0,,False
102,"query stream received by Si. Thus, at any given point, we",0,,False
103,are trying to maximize the locality of the queries in Qi to,0,,False
104,increase the probability that future queries will be answered,0,,False
105,locally. Let us focus on the first locality condition. The cost,0,,False
106,of replicating a document is equivalent to the number of,0,,False
107,posting list entries it requires in the index. To simplify the,0,,False
108,"problem, suppose that all documents contain the same num-",0,,False
109,ber of terms and therefore have the same cost. The problem,0,,False
110,we are trying to solve is a particular form of the knapsack,0,,False
111,problem. The objects we are selecting are queries. The util-,0,,False
112,"ity of selecting a query is proportional to its frequency, while",0,,False
113,"its cost is equal to the indexing of the results, as well as the",0,,False
114,partial information ensuring the quality of results.,0,,False
115,Given that the search engine aims at serving the k best,0,,False
116,"results for each query, we could make the simplifying as-",0,,False
117,sumption that all queries have the same cost: indexing k,0,,False
118,"documents. However, even in this case, the complexity of",0,,False
119,the problem arises from the fact that many queries share re-,0,,False
120,"sults. Hence, the cost of a selection is not equal to the cost",0,,False
121,"of each query, as some documents would be counted several",0,,False
122,"times. The knapsack problem is N P -hard, but has greedy",0,,False
123,"heuristics that perform reasonably well. In particular, the",0,,False
124,most common approach consists of selecting the objects in,0,,False
125,a,0,,False
126,decreasing,0,,False
127,order,0,,False
128,of,0,,False
129,value cost,0,,False
130,.,0,,False
131,In,0,,False
132,our,0,,False
133,"case,",0,,False
134,the,0,,False
135,cost,0,,False
136,of,0,,False
137,selecting,0,,False
138,a query depends on the previously selected ones; hence the,0,,False
139,costs should be re-evaluated at each step of the algorithm.,0,,False
140,3.2 Practical approach,0,,False
141,"As presented in Section 3.1, a search site has to satisfy two conditions to answer a query locally. The first one is that the results should be indexed locally, and the second one is that the search site should have enough information to guarantee that no other document in D can score higher. The computation of an exact optimal solution is NP-hard, which leads us towards heuristic solutions. Moreover, we need to consider practical implementation constraints in the design of our algorithm.",1,NP,True
142,"This work targets search engines performing incremental indexing. The index of the search engine is regularly updated, and the algorithm must account for the presence of new documents. This eliminates the possibility of relying solely on an offline algorithm executed during the initial in-",0,,False
143,"dex generation. A practical solution should also use a minimal amount of computation and memory, so as to ensure that as many resources as possible are dedicated to query processing. Part of the computational cost of the problem presented in Section 3.1 arises from the fact that the benefit of replicating a document cannot be simply evaluated, it depends on the full selection of replicated documents. From this consideration, it would be tempting to devise a solution based on hypergraphs of documents and queries to model replication dependencies. However, given the scale of the document collections we consider, such data structures do not scale, both with respect to their memory consumption and the processing cost required to exploit them.",0,,False
144,"Inspired by previous work in Web caches [13], we propose a Reactive Indexing Protocol (RIP). Each search site engine monitors the queries of its users to gather local statistics about the frequency of terms and documents. Based on these observations, our algorithm evaluates the utility of replicating information. A search site Si may either replicate documents, to ensure that the results are copied locally, or fragments of the posting lists of other sites, to increase its knowledge of their document collection and make more accurate query forwarding predictions by computing tighter score bounds. As introduced in Section 2.4, Si indexes fully replicated documents in SIi, while the replicated fragments of posting lists form FIi.",0,,False
145,3.3 Algorithm,0,,False
146,"Distributed search engines rely on query forwarding heuristics to determine whether a given query q should be evaluated on other search sites to improve the quality of the results. The role of the forwarding heuristic is to compute, for all documents d  D, a score upper bound scBound (d |q). If the top-k documents are either not fully replicated locally, or cannot be clearly identified, the search engine decides to forward the query to the other sites to guarantee the quality of results. In this work, we introduce a new query forwarding heuristic and RIP, its associated index replication algorithm.",0,,False
147,3.3.1 Forwarding heuristic,0,,False
148,"The forwarding heuristic we propose stems from the NRA top-k processing algorithms [11], with a few adaptations to deal with incomplete posting lists. In NRA, posting lists are sorted by impact and processed from top to bottom. NRA maintains a sorted heap of potential top-k results with upper and lower bounds on their scores. These bounds are updated as the processing progresses down the posting lists. As soon as the upper bound of the (k + 1)th document is lower than the lower bound of the kth document, the topk results are identified and the algorithm terminates. In the worst case, NRA has to process the full posting lists, but, in most situations, it achieves significant performance gains and only processes a small fraction of the index. The forwarding heuristic performs a similar computation. It processes the query over the forwarding index FIi and computes upper bounds on scores. The posting lists of the forwarding index are only partial, but they are continuous. A posting list replicated by Si for a term t down to the score value v contains all the documents of D whose master is different from Si and whose partial score r(d|t) is higher than v. Therefore, for a given term, FIi provides either an exact partial score, or an upper bound equal to the score of the last posting list entry. While processing, the forwarding heuristic",1,ad,True
149,834,0,,False
150,t1,0,,False
151,d238 - 24.5 d789 - 24.2 d555 - 23.1 d358 - 22.8,0,,False
152,t2,0,,False
153,d657 - 18.3 d745 - 17.9 d555 - 17.3 d618 - 17.0 d194 - 16.7,0,,False
154,t3,0,,False
155,d675 - 17.1 d348 - 16.2 d135 - 14.9,0,,False
156,Figure 3: Forwarding heuristic on FIi,0,,False
157,"ignores the documents present in the shadow index SIi, as they are already evaluated by traditional query evaluation and are assigned a precise score.",1,ad,True
158,"We illustrate the forwarding algorithm with the example of Figure 3. The query of the user is ""t1, t2, t3"", and the figure displays the posting lists of FIi corresponding to those terms which the forwarding heuristic evaluates to decide whether the query should be forwarded. The top documents for t1 are replicated in SIi (in bold), so they do not need to be considered. The following document is d555, so we know its exact partial score for this term. This document is also present in the posting list of t2, so we will also find its exact partial score for t2 as the top-k execution progresses. However, d555 is not represented in the posting list of t3. The last known document of this posting list is d135. As a consequence, we use its partial score as an upper bound of d555's partial score for t3. Hence, the upper bound score computed for d555 is (23.1+17.3+14.9)/3,""18.4. We can also compute a bound on the score of any document absent from these posting lists using the scores of the last entries (22.8, 16.7 and 14.9 in this example). Using FIi, the forwarding heuristic computes the highest possible score for a document that is not indexed locally and compares it with the score of local documents (MIi and SIi).""",0,,False
159,"As an optimization, when a posting list is fully replicated (i.e. replicated down to the 0 score), the forwarding heuristic leverages the conjunctive properties of the ranking function. Any document that is absent from this posting list can be ignored, as it cannot be part of the results.",0,,False
160,3.3.2 Replication principle,0,,False
161,"The replication algorithm works as follows. For each term t, a site maintains two replication thresholds, expressed in partial score values: the document replication threshold tdt and the postings replication threshold tpt. RIP reactively adjusts these thresholds using the activity of the local users to determine which documents and postings are replicated.",1,ad,True
162,"d  D, r(d|t)  tdt  master (d ) , i  d  SIi",0,,False
163,"d  D, r(d|t)  tpt  master (d ) , i  d  FIi",0,,False
164,"For the example described on Figure 3, tdt1 is 24.2, while tpt1 is 22.8. By lowering tdt, RIP decreases the highest scores associated to t for a non local document. Lowering tpt decreases the lowest score associated to t in FIi. Both these actions increase the information related to the term t and decrease the amount of query forwarding. However, their impact and cost can vary significantly. Fully replicating a document is costly, as it generates one posting entry per unique term in the document. On average, a Web page contains 250 unique terms [15], therefore replicating a document",0,,False
165,"is 250 times more costly than replicating a posting entry. Given that the differences in partial scores between entries are, in most cases, higher among high quality documents, fully replicating a document often has a higher positive impact on query forwarding. RIP's objective is to achieve a good balance between documents and postings replication to use the replication budget as efficiently as possible.",0,,False
166,"After each query execution, RIP analyses the query results to determine which data should be replicated to ensure that, in the future, this query could be processed locally. Let w be the lowest score of the last document returned as a result for the query t1. . . t|q|. If the query only contains one term, then the replication operation is trivial, and the algorithm determines that tdt1 should be w. However, if the query contains several terms, then the algorithm has to decide whether it should replicate documents or posting lists. The algorithm we propose relies on a parameter  to balance the replication between documents and postings.",0,,False
167,"tdt ,  × |q| × w",0,,False
168,(1 - )|q| × w,0,,False
169,"tpt ,",0,,False
170,|q| - 1,0,,False
171,"Using the scoring function s(d|q), it is possible to verify that for all the documents present in a single posting list of FIi, the forwarding heuristic has enough data to compute a score upper bound at most equal to w:",0,,False
172,1,0,,False
173,"t  q, |q| tdt +",0,,False
174,"tpu , w",0,,False
175,uq-{t},0,,False
176,"By definition, replicating document provides the corresponding postings, so tdt  tpt. As a consequence, given that |q|  2,   0.5. When  is low, RIP favors replicating documents, which increases the probability of having query results in the local index. However, the forwarding heuristic has less information to ensure that these local results are optimal. On the contrary, a high value of  provides a very accurate forwarding heuristic, but fewer replicated documents.",0,,False
177,"In practice, some of the documents are present in several posting lists. Hence, they have precise values for several terms, and their score estimations may exceed w. The results of the query, for instance, will be present in all the posting lists matching the query, and will generate scores higher than w. Similarly, other documents present in at least 2 posting lists, such as d555 in Figure 3, may have high upper bounds on their score and could trigger the query forwarding mechanism. When these documents are not part of the query results, query forwarding is unnecessary. In order to avoid these cases of false positives, RIP identifies these documents and fully indexes them in SIi.",0,,False
178,3.3.3 Practical algorithm using blocks,0,,False
179,"RIP needs to estimate the amount of documents or postings a replication decision represents before deciding whether it should be applied or not. Furthermore, taking replication decisions at the level of a single posting may lead to unstable results and generate a high overhead.",1,ad,True
180,"Each search site estimates loosely the score distribution for each term by regularly probing the other search sites. This data structure is comprised of blocks, and is illustrated in Figure 4. A block constitutes a unit of replication identified by its index as well as its score bounds. This information",0,,False
181,835,0,,False
182,block index/size,0,,False
183,t4,0,,False
184,"0/10 Upper ,"" 15.7, Lower "", 12.7",0,,False
185,"1/20 Upper ,"" 12.7, Lower "", 9.8",0,,False
186,2/40,0,,False
187,"Upper ,"" 9.8, Lower "", 7.3",0,,False
188,3/80,0,,False
189,"Upper ,"" 7.3, Lower "", 4.8",0,,False
190,"t5 Upper ,"" 17.1, Lower "", 15.3 Upper ,"" 15.3, Lower "", 13.7 Upper ,"" 13.7, Lower "", 6.4",0,,False
191,"Upper ,"" 6.4, Lower "", 1.8",0,,False
192,"Figure 4: Blocks replication (k , 10)",0,,False
193,"is not required to be perfect, and can be obtained through sampling. The first block has size k, and the size of the following blocks increases exponentially, using a power of 2.",0,,False
194,"We adapt RIP to apply the replication thresholds tdt and tpt on blocks of documents and postings instead of single elements. Figure 4 presents the computation of the thresholds for the query ""t4, t5"". The lowest score w ,"" 8.5, and  "", 0.6. RIP determines that tdt4 should be 0.6 × 2 × 8.5 ,"" 10.2. Therefore, the first 2 blocks of documents should be replicated (in bold), and dtt4 becomes 9.8, once adjusted to the block limit. tpt5 is evaluated to be (1-0.6)×2×8.5/(2-1) "","" 6.8, which means that 3 blocks of postings should be replicated (in italics) and tpt5 is adjusted to 6.4. This operation is then repeated for tdt5 and tpt4 .""",1,ad,True
195,"The usage of blocks brings several benefits to RIP. It materializes a small number of well defined replication bounds, which favors clear replication decisions while lowering the amount of memory required to maintain them. In addition, it ensures the continuity of replicated data. A replication decision caused by a given query may, as a side effect, trigger the replication of blocks that contain documents useful for other future queries.",1,ad,True
196,3.3.4 Space management,0,,False
197,"RIP does not directly proceed to the replication of data. Instead, it maintains counters about the number of times a particular piece of information was determined to be useful. We refer to these counters as the temperature of the data. The higher the temperature, the more useful it is. The temperature values are used to determine which data should be replicated within the budget constraint. As explained previously, depending on the data type, the cost of the replication varies. Given that a document has on average 250 distinct terms, the cost of replicating a document is on average 250, the cost of replicating the documents of a block of size n is on average 250n, and the cost of replicating only the postings of this block is exactly n.",1,ad,True
198,"We rely on the cubic selection scheme [13] to decide which elements are selected for replication. This approach was initially designed to cache Web objects. Hence, in this context, the size of an object is always precisely known, and there are no dependencies between objects. In our case, the size of an object is first estimated, and then corrected when a replication decision is actually taken. For instance, RIP first assigns a cost of 250 to a document, and then corrects it upon receiving the content of the document. Similarly, evicting a block whose documents are replicated does not necessarily free 250n, as some of the documents may remain replicated due to other decisions (e.g. replicated blocks of other terms). We also ensure that the continuity of block replication is maintained. It is impossible to evict a block without evicting all the following blocks.",0,,False
199,3.3.5 Dealing with incremental indexing,0,,False
200,"Web search engines are often designed to support incremental indexing. This feature is particularly used for popular Web pages that are frequently modified, such as news Websites. Replicating information in several locations poses the problem of data consistency. If a search site does not take into account a new version of a Web page, it will serve stale results to its users.",0,,False
201,"To ensure that index updates are propagated, a search site keeps track of which other sites replicate the documents it is the master of. In addition, for each term, it maintains the documents and postings replication thresholds of each one of the other sites. When the crawler sends a new version of a document to its master site Si, MIi is updated and all the sites replicating any stale data are notified.",1,ad,True
202,4. EVALUATION,0,,False
203,"To evaluate RIP's efficiency, we simulate a distributed search engine configuration consisting of five search sites S ,"" {S1 . . . S5}. We first compute optimal query results through a centralized search engine indexing all documents, and then evaluate each site's ability to generate these results using its master index and the data it replicates. Each search site is associated with a query log originating from neighboring countries and collected from the front-end of a commercial search engine. In total, we sample 7, 023, 102 consecutive queries, and split them chronologically into a training set and a testing set of equal size. The collection of documents consists of 31, 599, 910 Web pages randomly sampled from the index of the same search engine.""",0,,False
204,"We rely on the distribution of terms in queries and documents to assign each document to a master site (KL-q feature), as in the work of Blanco et al. [3]. This process creates, for each site, the master index MI, and represents the initial assignment of documents to sites in our evaluation. In this work, the master index creation process is fixed, and these indexes remain constant throughout the experiments. We evaluate RIP's ability to generate SI and FI, and to reduce the query forwarding rate.",0,,False
205,"Commercial search engines often cache query results to avoid re-evaluating repeated queries. To make our experiment more realistic, we assume that the search engine implements a results cache with a Time-To-Live (TTL): cached results are only served if their TTL has not expired. We use a TTL value of 2 hours. For incremental indexes, it is possible for a results cache to return stale results, which happens when the result set does not reflect accurately the current state of the index. In our setup, the TTL of the cache is 2 hours. Such a TTL value is moderately aggressive: the staleness of the results will never exceed 2 hours.",0,,False
206,4.1 Search results diversity,0,,False
207,"Blanco et al. [3] observe that most documents exhibit a high divergence of popularity among the different search sites. They are very popular in a given region, but are rarely requested at other search sites. We confirm this observation by evaluating how the popularity ranking of documents differs across search sites. We execute the training queries on the search engine and count how often each document is returned as part of the top-10 results.",0,,False
208,"In Figure 5, we present the similarity between the list of documents that are most popular at each individual search site, and the documents that are globally popular, among",0,,False
209,836,0,,False
210,Overlap,0,,False
211,0.6 0.55,0,,False
212,0.5,0,,False
213,SSSSS23451,0,,False
214,0.45,0,,False
215,0.4,0,,False
216,0.35,0,,False
217,0.3,0,,False
218,0.25,0,,False
219,0.2,0,,False
220,0,0,,False
221,20,0,,False
222,40,0,,False
223,60,0,,False
224,80,0,,False
225,100,0,,False
226,"Popularity of documents (in %, from most popular to least popular)",0,,False
227,Figure 5: Similarity between documents locally popular and documents globally popular,0,,False
228,Proportion,0,,False
229,1,0,,False
230,query length before cache,0,,False
231,query length after cache,0,,False
232,0.8,0,,False
233,cache hit rate,0,,False
234,0.6,0,,False
235,0.4,0,,False
236,0.2,0,,False
237,0,0,,False
238,1,0,,False
239,2,0,,False
240,3,0,,False
241,4,0,,False
242,5+,0,,False
243,Query length,1,Query,True
244,Figure 7: Queries distribution and cache efficiency,0,,False
245,Overlap,0,,False
246,0.4 0.35,0,,False
247,0.3 0.25,0,,False
248,0.2,0,,False
249,SSSSSSSSSS1112223341,0,,False
250,/ / / / / / / / / /,0,,False
251,SSSSSSSSSS3453454552,0,,False
252,0.15,0,,False
253,0.1,0,,False
254,0.05,0,,False
255,0,0,,False
256,0,0,,False
257,20,0,,False
258,40,0,,False
259,60,0,,False
260,80,0,,False
261,100,0,,False
262,"Popularity of documents (in %, from most popular to least popular)",0,,False
263,Figure 6: Similarity between locally popular documents at 2 sites,0,,False
264,"all the search sites taken together. On average, the set of the x documents most popular at a given site and the set of the x documents most popular considering the activity of all sites globally only overlap by 40%. This observation clearly illustrates how users from different regions have diverse interests. This argues in favor of an index replication policy that relies on local user activity and optimizes the replicated data for each site individually.",0,,False
265,"The comparison of popular documents between pairs of sites, presented in Figure 6, shows even more differences. The pair of sites exhibiting the highest similarity is under 40%. This similarity is due to the language used in queries, as those two regions share the same regional language. Note that the similarity of the very few most popular documents is typically higher. This is due to very few documents being popular across different regions.",0,,False
266,4.2 Cache impact,0,,False
267,"The results cache generates a hit when identical queries are submitted to the search engine within its TTL interval. Longer queries typically present lower frequency compared to short ones [1], and therefore the results cache affects them differently. In our experiments, the average hit rate of the results cache is 48.4%. Figure 7 illustrates the distribution of queries depending on their length. Queries of length 2 represent the largest fraction of the workload, followed by single term queries. As expected, the hit rate of the cache drops",1,ad,True
268,"as we increase the length of queries; long queries are more likely to be unique. Hence, the workload of a search engine is often dominated by the processing of longer queries. This observation significantly hardens the task of the forwarding heuristic. Indeed, long queries involve more posting lists, and generally have results whose partial scores are lower: they require more replicated data to be indexed locally.",1,ad,True
269,4.3 Replication and query forwarding,0,,False
270,"We evaluate RIP and its query forwarding heuristic by running queries in our logs against the collection of documents. First, we warm up the replication algorithm and the cache using the training queries. Next, we process the testing queries to evaluate the amount of query forwarding. For these experiments, we use the forwarding heuristic of Section 3.3.1 and one of the following replication schemes: Static global documents replication (SDR): Using the training queries, we determine which documents are globally popular and replicate this static set across all sites [2, 8]. In this case, FI contains an upper bound per term for non replicated documents, which corresponds to the thresholds of Baeza-Yates et al. [2]. Reactive documents replication (RDR): Each search site reactively determines which documents are most frequently part of the results of their users and replicate the most popular ones. This setup computes a different set of replicated documents for each site to match the activities of their users. As with SDR, FI contains one bound per term, dynamically adjusted to reflect document replication. Reactive Indexing Protocol (RIP): Each site reactively replicates blocks of documents and posting lists, as well as individual documents when they generate false positives. This is the approach we describe in Section 3.3.3. Each site replicates data matching the needs of its users, while preserving the continuity of information in posting lists.",1,ad,True
271,Overall performance.,0,,False
272,"We evaluate the three different replication schemes using different replication budgets and present the results in Figure 8. The budget is represented as the maximum number of documents replicated, and we assume, as explained in Section 3.3.2, that 250 individual posting list entries use the same space as a fully indexed document. The results clearly indicate that the two algorithms based on local information outperform the static documents replication us-",0,,False
273,837,0,,False
274,Proportion of queries executed locally,0,,False
275,0.61 0.6,0,,False
276,0.59 0.58 0.57 0.56 0.55 0.54 0.53 0.52 0.51,0,,False
277,0.5 100,0,,False
278,SDR RDR RIP,0,,False
279,1000,0,,False
280,10000,0,,False
281,100000,0,,False
282,Replication budget (in documents),0,,False
283,1e+06,0,,False
284,Figure 8: Query locality wrt replication budget,1,Query,True
285,"Prop. ans. locally, ignoring cache hits",0,,False
286,0.6 0.5 0.4 0.3 0.2 0.1,0,,False
287,0 1,0,,False
288,"RDR (budget,""10,000) RIP (budget"",""10,000) RDR (budget"",""1,000,000) RIP (budget"",""1,000,000)""",0,,False
289,2,0,,False
290,3,0,,False
291,4,0,,False
292,5+,0,,False
293,Query length,1,Query,True
294,Figure 9: Query locality wrt query length,1,Query,True
295,"ing global statistics. Indeed, as observed in Section 4.1, the users of each site are interested in different documents.",0,,False
296,"For a low replication budget, below 100,000, we observe that simply replicating the results of the queries is more efficient than replicating blocks of documents and posting lists. However, as the budget increases, the blocks replication scheme clearly outperforms the replication of individual documents. This difference grows with the amount of space dedicated to replication. With a replication budget of 1,000,000 documents, each search site has an average indexing capacity of 7,119,982 documents (22.5% of the total collection), which represents an overhead of 14% over a setup without any replication. In this configuration, RIP raises the amount of queries processed locally by 23%, while RDR raises it by 13%. Note that the  parameter of RIP, used to compute replication thresholds, is set to 0.6. In practice, any value between 0.55 and 0.65 obtains good performance, above 59.7% with a budget of 1,000,000.",1,ad,True
297,Detailed performance analysis.,0,,False
298,"We detail the performance of RDR and RIP in Figure 9. With a small replication budget, it is most efficient to focus replication on single term queries. They only require little replicated data to be answered locally, as the results are simply the documents with the highest scores for the query term. RDR performs well for these easy queries. Given that one-term queries are less likely to be unique, the temperature of their results increases over time and they are replicated. However, when the replication budget increases, it becomes more interesting to also replicate data for longer queries. The results show that RDR is unable to answer these queries, even with a large budget. The documents that are part of the results may be replicated. However, given that the corresponding posting lists are not replicated, the search engine is unable to ensure that the query results are optimal, and the forwarding heuristic returns a false positive. RIP can compute low thresholds, even for longer queries, and is able to answer locally over 10% of long queries by replicating continuous blocks of documents and postings.",0,,False
299,Query replication cost analysis.,1,Query,True
300,"Figure 10 presents the position of the query results in the posting list blocks of RIP's forwarding index, depending on the query length. For a one term query, the result set comprises the documents with the highest partial scores for",0,,False
301,Proportion of results (cdf),0,,False
302,1,0,,False
303,0.9,0,,False
304,"query length , 2 query length , 3",0,,False
305,0.8,0,,False
306,"query length , 4",0,,False
307,"query length , 5+",0,,False
308,0.7,0,,False
309,0.6,0,,False
310,0.5,0,,False
311,0.4,0,,False
312,0.3,0,,False
313,0.2,0,,False
314,0.1,0,,False
315,0,0,,False
316,1,0,,False
317,2,0,,False
318,3,0,,False
319,4,0,,False
320,5,0,,False
321,6,0,,False
322,7,0,,False
323,8,0,,False
324,9 10,0,,False
325,Posting list block number,0,,False
326,Figure 10: Depth of results in posting lists,0,,False
327,"the term. Hence, they are all located in the first posting list block, which is a small amount of information for RIP to replicate to answer these queries correctly. However, as the length of the query increases, the matching documents are less frequent, due to the conjunctive nature of the query processing. As a consequence, they are located in deeper blocks, and require more replicated information to enable local processing. For example, 67% of the results of 5-term queries are located in the 10th block. Given that the size of blocks is a power of two, this data is costly to replicate, making forwarding more frequent for long queries.",0,,False
328,New queries.,0,,False
329,"The replication algorithms rely on previous queries to compute a replication scheme and increase the probability of answering future queries locally. When a query is repeated, it can be answered by the results cache, if it falls within the TTL, or by the data replicated upon the first occurrence of the query. New queries however are more challenging. We examine the query processing locality for new queries on Figure 11, with a replication budget of 1,000,000.",0,,False
330,"SDR is particularly efficient at processing new one-term queries locally, since it benefits from document popularity information from all search sites. A query that is processed for the first time in a site might have been present at another site during the training period. Consequently, the static replication has included it in the computation of the list of replicated documents.",0,,False
331,838,0,,False
332,Proportion answered locally True Positives,0,,False
333,0.5 0.45,0,,False
334,0.4 0.35,0,,False
335,0.3 0.25,0,,False
336,0.2 0.15,0,,False
337,0.1 0.05,0,,False
338,0 1,0,,False
339,SDR RDR RIP,0,,False
340,1 SDR RDR,0,,False
341,0.8 RIP,0,,False
342,0.6,0,,False
343,0.4,0,,False
344,0.2,0,,False
345,2,0,,False
346,3,0,,False
347,4,0,,False
348,Query length,1,Query,True
349,0,0,,False
350,5+,0,,False
351,0,0,,False
352,0.2,0,,False
353,0.4,0,,False
354,0.6,0,,False
355,0.8,0,,False
356,1,0,,False
357,False Positives,0,,False
358,Figure 11: Query forwarding rate for new queries,1,Query,True
359,Figure 12: Forwarding ROC curve,0,,False
360,"RDR has higher overall performance than SDR, since it targets the set of replicated documents for each site. However, since it only relies on the queries processed at a given site to build the list of replicated documents, the performance for new queries is low. New queries can only be processed locally if their data has been replicated due to previous distinct queries executed at this site. As RDR only replicates the documents in result sets, it is unlikely that the site has replicated all the results of the new query and the data necessary to ensure that local results are sufficient.",0,,False
361,"RIP performs well for new queries. Although it only relies on local knowledge, as it is the case for RDR, the block replication pattern favors new queries. Instead of precisely replicating the documents answering a particular query, RIP transfers blocks of data, which contain additional documents and postings related to the query terms. When a new query arrives, the algorithm is more likely to have replicated a sufficient amount of information for each of the query terms, which increases the probability of processing it locally.",1,ad,True
362,False positives analysis.,0,,False
363,"Our forwarding heuristic always forwards a query if there another search site may improve its results. As a consequence, the forwarding heuristic does not generate false negatives. For some queries, the search site has the query results in its index but forwards the query nevertheless, because it cannot prove that those are the best results. These cases constitute false positives, as forwarding the query does not modify its results. Considering a setup with a replication budget of 1,000,000, the proportion of false positives among the forwarding decisions is 51%, 53% and 46% for SDR, RDR, and RIP respectively.",0,,False
364,"Allowing the search engine to return non-optimal results by allowing false negatives reduces the query forwarding rate. The forwarding heuristic computes a score that corresponds to the limits of its knowledge. We use this score, as well as the fact that long queries are more difficult to predict, to rank forwarding decisions. We display, on Figure 12, the distribution of true and false positives (ROC curve [12]). As one-term queries only involve one posting list, making it impossible to generate a false positive, we ignore them in this experiment. The remaining query lengths generate distinctive curve fragments. These fragments remain relatively close to a diagonal, which means that separating true and false positives using solely the knowledge score and query",0,,False
365,"length is difficult. Indeed, scores can vary significantly depending on the query term, and cannot be easily compared. Note that the curve representing RIP is bellow the one of the other algorithms. This is because RIP presents an overall higher performance, and therefore forwards fewer queries. The remaining false positives are therefore harder to detect.",0,,False
366,5. RELATED WORK,0,,False
367,"The problem of assigning documents to sites in distributed search engine has been studied in previous work, and two main approaches have been developed to assign documents to sites. Baeza-Yates et al. propose to replicate a set of global, high quality documents to all search sites [2]; Cambazoglu et al. follow the same approach [8]. As shown in Section 4.2, the documents users are interested in significantly differ across regions. Thus, it is more efficient to perform fine grain replication, and select different replicated documents for each search site. Our experiments presented in Section 4.3 show that per-site replication algorithms systematically outperform global replication decisions.",0,,False
368,"Brefeld et al. propose to use machine-learning techniques to statically assign documents to search sites [4]. This approach optimizes the replication of documents for each site, but it relies on attributes, such as the language of the document, which are weakly correlated with its popularity. Contrary to this approach, the algorithm we propose is reactive, and only replicates documents when it observes that users actually request them. The algorithm we propose also explicitly prioritizes pieces of replicated data depending on their size and temperature. The approach of Brefeld et al. relies on an algorithm that simply assigns documents to search sites, and it does not enable an operator to vary the indexing capacity.",0,,False
369,"Existing query forwarding algorithms rely on the computation of upper bounds to estimate the score of documents that are not indexed locally. Baeza-Yates et al. [2] compute a bound for each term and each search site. Cambazoglu et al. [8] refine this approach and show that maintaining bounds on pairs of terms more precise estimates of scores and can reduce the amount of query forwarding. In the case of a static index, these bounds can easily be computed during the generation of the index, and do not vary at runtime. However, when the index and the set of replicated documents are dynamically selected, these bounds need to be updated. This process can become particularly costly when",0,,False
370,839,0,,False
371,"each site keeps track of many bounds, which is the case in the algorithm of Cambazoglu et al. [8]. In that case, one possibility is to maintain these bounds lazily using a sliding window scheme. Yet, it reduces the effectiveness of the results cache, since results computed using these bounds will be time-stamped with the oldest bound used during their computation. The approach we propose explicitly maintains two bounds per term, which is a reasonable trade-off between their accuracy and the maintenance cost.",1,ad,True
372,"The main difference between the algorithms we propose and previous work [7, 8] is the interaction between the replication algorithm and the forwarding heuristic. While other algorithms focus on replicating popular documents, our approach also maintains single posting lists elements to ensure the continuity of the information on the scores for a given term. As there is no ""hole"" in the forwarding index, the upper bounds for each term are lower. In addition, by replicating postings further, we efficiently lower the bounds computed for longer queries. Overall, this significantly reduces the amount of query forwarding.",1,ad,True
373,"Ding and Suel [10] developed an algorithm for fast top-k processing on document ID-ordered posting lists. By maintaining upper bounds on the partial scores of compressed posting list segments, they significantly reduce both the amount of computation and the processing time. Our approach for block replication could be adapted to replicate document ID-ordered blocks using these thresholds. However, this would lead to a significant overhead for storing the index, since documents obtaining low scores would also be replicated if they belong to a segment with a high threshold. Consequently, we opted for strictly following the order of partial scores to replicate information.",1,ad,True
374,6. CONCLUSION,0,,False
375,"We propose RIP, a Reactive Indexing Protocol for distributed search engines. With RIP, the search engine initially indexes each document on a single master site, and monitors the local user activity of each site to generate an index replication scheme. Our scheme replicates documents and fragments of posting lists. RIP enables a significant reduction of the amount of query forwarding between search sites, and consequently, of query processing latency. We show experimentally that, by making local decisions, RIP significantly outperforms previous replication strategies based on global information: in a 5-site setup, when each site has an index capacity of 22.5% of the documents collection, 60% of the queries are processed locally. We also show that replicating fragments of posting lists allows the query forwarding heuristic to compute lower score thresholds on unknown documents, which increases performance. Finally, RIP has by design the additional benefit of being an online approach, supporting both incremental indexing and a precise index capacity configuration, which simplifies operations in a production environment.",1,ad,True
376,Acknowledgments,0,,False
377,"This work has been partially supported by the COAST project (ICT-248036), funded by the European Community. The authors have been also supported by the INNCORPORA Torres Quevedo Program from the Spanish Ministry of Science and Innovation, co-funded by the European Social Fund.",0,,False
378,7. REFERENCES,0,,False
379,"[1] R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. The impact of caching on search engines. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 183­190, 2007.",0,,False
380,"[2] R. Baeza-Yates, A. Gionis, F. Junqueira, V. Plachouras, and L. Telloli. On the feasibility of multi-site web search engines. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, pages 425­434, 2009.",0,,False
381,"[3] R. Blanco, B. B. Cambazoglu, F. P. Junqueira, I. Kelly, and V. Leroy. Assigning documents to master sites in distributed search. In Proceedings of the 20th ACM Conference on Information and Knowledge Management, pages 67­76, 2011.",0,,False
382,"[4] U. Brefeld, B. B. Cambazoglu, and F. P. Junqueira. Document assignment in multi-site search engines. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, pages 575­584, 2011.",0,,False
383,"[5] E. Brewer. Lessons from giant-scale services. Internet Computing, IEEE, 5(4):46­55, 2001.",0,,False
384,"[6] B. B. Cambazoglu, V. Plachouras, and R. Baeza-Yates. Quantifying performance and quality gains in distributed web search engines. In Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 411­418, 2009.",0,,False
385,"[7] B. B. Cambazoglu, V. Plachouras, F. Junqueira, and L. Telloli. On the feasibility of geographically distributed web crawling. In Proceedings of the 3rd International Conference on Scalable Information Systems, pages 31:1­31:10, 2008.",0,,False
386,"[8] B. B. Cambazoglu, E. Varol, E. Kayaaslan, C. Aykanat, and R. Baeza-Yates. Query forwarding in geographically distributed search engines. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 90­97, 2010.",1,Query,True
387,"[9] B. B. Cambazoglu, H. Zaragoza, O. Chapelle, J. Chen, C. Liao, Z. Zheng, and J. Degenhardt. Early exit optimizations for additive machine learned ranking systems. In Proceedings of the third ACM international conference on Web search and data mining, pages 411­420, 2010.",1,ad,True
388,"[10] S. Ding and T. Suel. Faster top-k document retrieval using block-max indexes. In Proceedings of the 34nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 993­1002, 2011.",0,,False
389,"[11] I. Ilyas, G. Beskales, and M. Soliman. A survey of top-k query processing techniques in relational database systems. ACM Computing Surveys (CSUR), 40(4):11, 2008.",0,,False
390,"[12] F. J. Provost, T. Fawcett, and R. Kohavi. The case against accuracy estimation for comparing induction algorithms. In ICML, pages 445­453, 1998.",0,,False
391,"[13] I. Tatarinov. An efficient LFU-like policy for Web caches. Technical report, Computer Science Department, North Dakota State University, 1998.",0,,False
392,"[14] S. Tatikonda, B. Cambazoglu, and F. Junqueira. Posting list intersection on multicore architectures. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information, pages 963­972, 2011.",0,,False
393,"[15] J. Zhang and T. Suel. Optimized inverted list assignment in distributed search engine architectures. In Parallel and Distributed Processing Symposium, 2007. IPDPS 2007. IEEE International, pages 1­10. IEEE, 2007.",0,,False
394,840,0,,False
395,,0,,False
