,sentence,label,data,regex
0,Dual Role Model for Question Recommendation in Community Question Answering,0,,False
1,"Fei Xu1,2, Zongcheng Ji1,2, Bin Wang1,3",0,,False
2,"1Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China 2Graduate University of Chinese Academy of Sciences, Beijing, China",1,ad,True
3,"2{feixu1966, jizongcheng}@gmail.com 3wangbin@ict.ac.cn",0,,False
4,ABSTRACT,0,,False
5,"Question recommendation that automatically recommends a new question to suitable users to answer is an appealing and challenging problem in the research area of Community Question Answering (CQA). Unlike in general recommender systems where a user has only a single role, each user in CQA can play two different roles (dual roles) simultaneously: as an asker and as an answerer. To the best of our knowledge, this paper is the first to systematically investigate the distinctions between the two roles and their different influences on the performance of question recommendation in CQA. Moreover, we propose a Dual Role Model (DRM) to model the dual roles of users effectively. With different independence assumptions, two variants of DRM are achieved. Finally, we present the DRM based approach to question recommendation which provides a mechanism for naturally integrating the user relation between the answerer and the asker with the content relevance between the answerer and the question into a unified probabilistic framework. Experiments using a real-world data crawled from Yahoo! Answers show that: (1) there are evident distinctions between the two roles of users in CQA. Additionally, the answerer role is more effective than the asker role for modeling candidate users in question recommendation; (2) compared with baselines utilizing a single role or blended roles based methods, our DRM based approach consistently and significantly improves the performance of question recommendation, demonstrating that our approach can model the user in CQA more reasonably and precisely.",1,Yahoo,True
6,Categories and Subject Descriptors,0,,False
7,H.3.3 [Information Search and Retrieval]: Information Filtering,0,,False
8,General Terms,0,,False
9,"Algorithms, Design, Experimentation",0,,False
10,Keywords,0,,False
11,"Community Question Answering, Role Analysis, Question Reommendation, Dual Role Model, PLSA",0,,False
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'12, August 12­16, 2012, Portland, Oregon, USA. Copyright 2012 ACM 978-1-4503-1472-5/12/08 ...$15.00.",1,ad,True
13,1. INTRODUCTION,1,DUC,True
14,"Community Question Aswering (CQA) is a web service where people can seek information (posting a question and getting the answer of it from others) and share knowledge (answering a question). Yahoo! Answers1 and Baidu Zhidao2 are two typical examples of CQA system. Compared with the traditional information retrieval, CQA bases on the community, which is a form of social network, so it can make best of user's collective wisdom to meet the information needs of users more easily and accurately.",1,Yahoo,True
15,"In CQA system, there are a large number of questions posted every day. Take Yahoo! Answers for example, there are about 207 thousands new questions asked daily [1]. If we can automatically recommend the new question to appropriate users to answer, it will help the question be resolved as soon as possible, which will improve the CQA system's performance. In addition, it will meet the answerers' needs to answer questions. As we can see, question recommendation is a very important component in a CQA system.",1,Yahoo,True
16,"The core issue of question recommendation is how to represent the users' interests (profile) and the questions, which is called the representation model. Based on that, we can assess the match between a question and each user, and then recommend the question to top N users who are the most consistent with it. Of course, we can solve question recommendation from another perspective, which is matching a user with each question and recommending the appropriate questions to him. Both of these types of recommendation tasks aim to make new questions answered as early as possible and satisfy the user better. Essentially, the key issues of both of them are the representation models for users and questions. As our target is recommending a new question to the appropriate users to answer, this paper focuses on the first type of recommendation task. At present, a lot of representation models have been proposed. Dror et al [5] represented the user and question as vectors consisting of multi-channel features and casted question recommendation as a classification problem. Other methods [2, 4, 6] utilized latent semantic models (PLSA, LDA, etc.) to model the user and question as the distribution of several topics.",0,,False
17,"As we can see, each user in CQA plays two different roles (dual roles) simultaneously: the asker and the answerer. That is, a user not only posts his questions, but also is able to answer someone else's questions. Intuitively, the profiles of the two roles of users are different from each other, which existing methods have not paid attention to. For example, a piano teacher wants to learn some computer knowledge which he is not familiar with. Thus he is most likely to ask lots of questions related to computer, and answer many piano-related questions based on his specialty. As an asker, a user may post some questions in",0,,False
18,1 http://answers.yahoo.com/,0,,False
19,2 http://zhidao.baidu.com/,0,,False
20,771,0,,False
21,"the field that he is not familiar with. In contrast, as an answer, the user will solve the question which he is good at and interested in.",0,,False
22,"Are there distinctions between users' roles? How do different roles affect the performance of question recommendation? Whether we can legitimately combine the characteristics of different roles to improve the effectiveness of the recommendation system? All of these important issues are worthy of our concern. However, current recommendation methods have not in-depth studied the different characteristics of users' roles and their different influences on question recommendation. All of previous methods only modeled the user using a single role, or simply mixed the two roles together to represent the user without considering the distinctions between roles.",0,,False
23,"This paper systematically investigates the distinctions between users' dual roles and how they affect the performance of question recommendation differently. To the best of our knowledge, this is the first work on studying these important issues. While Nam et al. [30] observed that users in CQA are divided into askers and answerers and only a few of them both ask and answer in the same category through statistics, they have not theoretically analyzed the distinctions between users' different roles and their different influences on question recommendation. Moreover, we propose the Dual Role Model (DRM) to model the dual roles of users effectively. Finally, we present the DRM based approach to question recommendation, which takes full advantage of users' different roles to improve the effect of question recommendation. There are three primary contributions of our work.",1,ad,True
24,"First, DRM which considers the two different roles of users separately provides a more precise and appropriate user representation model for question recommendation in CQA. Specifically, we utilize DRM to analyze the latent topic information of different roles for modeling the user. According to different independence assumptions, two variants of DRM are achieved: (1) independent DRM that assumes that users are independent of each other and models each user individually; (2) dependent DRM which considers the dependence between users.",0,,False
25,"Next, we carried out systematic experiments on a real-world data to explore the distinctions between users' roles and compare the effects of recommendation methods that are based on asker role, answerer role or blending both of these roles. The results show that not only the two roles but also their influences on question recommendation are different from each other distinctly. In addition, simply mixing the roles together will impair the performance of recommender methods.",1,ad,True
26,"Finally, our DRM based recommendation approach allows us to naturally integrate the user relation between the answerer and the asker with the content relevance between the answerer and the question into a unified probabilistic framework, which is more interpretable. Most previous methods only consider the content relevance. There have been several approaches that make use of the user relation [3, 5], however in these approaches, the user relation is either obtained through somewhat heuristic statistics outside of the model or combined with the content relevance by a linear interpolation.",0,,False
27,"The remainder of this paper is organized as follows: Section 2 introduces some prior work related to our approach. Section 3 is the preliminary description of question recommendation in CQA. Section 4 discusses our dual role model and how to use it in question recommendation. Experimental results are presented in Section 5. At last, we conclude the paper and discuss about the future work in Section 6.",0,,False
28,2. RELATED WORK,0,,False
29,"In this part, we review previous work which is related to our approach: recommender system, question recommendation.",0,,False
30,2.1 Recommender System,0,,False
31,"Because question recommendation is a type of recommender system, we first review general recommender systems. Recommender systems can be divided into three stages based on how recommendations are made: content-based recommendations, collaborative filtering and hybrid approaches [18]. In contentbased recommendations, the user will be recommended items similar to the ones the user preferred in the past. In collaborative filtering, the user will be recommended items that people with the similar tastes and preferences liked in the past, that is, user will help each other find what they may like. In order to combine the advantage of both previous methods together, hybrid approaches are proposed. All these recommender systems firstly attempt to profile user preferences based on his history logs, and then recommend items according to the relevancy between him and items. Different kinds of methods are used to capture the model of users, such as classifying [24, 28], PLSA [13], matrix factorization [29], and ranking-oriented approach [17]. However, the user in these general recommender systems only plays one single role, which is significantly different from question recommendation. Therefore, we should pay close attention to this difference as we have mentioned in the above section.",1,ad,True
32,2.2 Question Recommendation,0,,False
33,"With CQA system becoming popular in recent years, many people turn their attention to question recommendation in CQA, e.g., [2, 3, 4, 5, 6, 16]. Overall, there are two main lines to solve this problem in previous work.",0,,False
34,"On one hand, question recommendation is consider as a classifier problem which is similar to [5]. In [5], Dror et al. proposed a representation model based on multi-channel vector space model, where the user and question are represented as the vector with multiple dimension features from multi-channel data. Then, the matching degree between a user and a question is learned from their respective features using a binary classifier. Although this model treats user attributes in the answered-channel and askedchannel as two groups of features respectively, all the features are integrated into a single vector space model to represent the user's dual roles without considering the distinctions between user's different roles and their different influences on question recommendation.",0,,False
35,"On the other hand, we can learn a ranking model to generate a recommendation list for question recommendation. In these earlier works, various extensions of Probabilistic Latent Semantic Analysis (PLSA) or other topic models are developed. Wu et al. [2] presented an incremental automatic question recommendation framework based on PLSA. Question recommendation in their work considered both the users' interests and feedback. Guo et al. [4] developed a general generative model based on basic Latent Dirichlet Allocation (LDA) model for questions and answers in CQA. In this approach, they combined topic-level information about questions and users with word-level information to improve question recommendation. In order to deal with the data sparsity, Qu et al. [6] used a user-word aspect model instead of direct aspect model [9] to model user preferences. However, all of these methods have used a single role, or simply blended roles to represent the user, which have not distinguished user's different roles and considered how they affect the performance of question recommendation differently.",1,ad,True
36,772,0,,False
37,3. PRELIMINARIES,0,,False
38,Given the question set,0,,False
39,... | | and the user set,0,,False
40,"... | | , where | | is the number of questions and | | is the",0,,False
41,number of users. Each question in Q is denoted as a triple,0,,False
42,",,",0,,False
43,". The is the text content of the question. For instance,",0,,False
44,may include the title or the detailed description of the question.,0,,False
45,"If we assume that words are independent, can be denoted as a",0,,False
46,"bag of words ... | | , where | | is the number of words in .",0,,False
47,The denotes the answerer of the question (it is also the an-,0,,False
48,swerer role of user ). The denotes the asker of the question (it,0,,False
49,is also the asker role of user ). If there are multiple answerers in,0,,False
50,"the question, all answerers will be separated. If the question is not",0,,False
51,"answered, is null.",0,,False
52,"Based on the previous discussion in the section of related work,",0,,False
53,we choose the idea of ranking to solve the problem of question,0,,False
54,"recommendation. For a new posted question, the question an-",0,,False
55,swerer recommendation task is to suggest a ranked list of users,0,,False
56,"who are suitable to answer it. To tackle with this problem, we",0,,False
57,need to resolve the two sub-problems: question and user represen-,0,,False
58,"tation, the method of ranking recommendation candidates.",0,,False
59,Since Probabilistic Latent Semantic Analysis (PLSA) [20],0,,False
60,can effectively mines the latent semantic information of users and,0,,False
61,"questions, it has been widely used to obtain the question and user",0,,False
62,"representation in question recommendation, e.g., [2, 3, 4, 6].",0,,False
63,PLSA assumes that users and questions are generated from a mix-,0,,False
64,ture of some latent topics. We can compute the consisten-,0,,False
65,cy between the distribution on topics of a user and a question to,0,,False
66,determine whether to recommend the question to the user.,0,,False
67,We summarized the previous PLSA based methods for question,0,,False
68,recommendation and discovered that they can be divided into two,0,,False
69,main categories: (1) methods that model the user indirectly. Simi-,0,,False
70,"larly to [2], it takes a question as one document and use PLSA to",0,,False
71,model the question to gain its distribution on topics at first. Then,0,,False
72,the user can be represented as the average of topic distributions of,0,,False
73,all the questions that he accesses; (2) methods that obtain the,0,,False
74,"model of the user directly. In these methods, all the questions that",0,,False
75,a user accesses are treated as one document. Then PLSA is used,0,,False
76,directly to get the topic information of the user. A typical ap-,0,,False
77,proach is the user-word aspect model applied by Qu et al. [6].,0,,False
78,"This model is proposed by Popescul et al. [7], which improves",0,,False
79,Hofmann's aspect model [9] for collaborative filtering.,0,,False
80,"However, when these PLSA based methods modeling the user,",0,,False
81,they did not pay attention to the user's dual roles and their distinc-,0,,False
82,tions. In order to effectively analyze characteristics of different,0,,False
83,roles and make use of both of user roles to improve the perfor-,0,,False
84,"mance of question recommendation, we propose a Du-",0,,False
85,al Role Model (DRM) based on PLSA to model the user in CQA,0,,False
86,"precisely. According to different independence assumptions, we",0,,False
87,"implement two variants of DRM. In the next section, we will de-",0,,False
88,tail generation processes of these variants and describe the DRM,0,,False
89,based method for question recommendation.,0,,False
90,4. MODEL DESCRIPTION,0,,False
91,4.1 Independent DRM,0,,False
92,"With the assumption that all users are independent of each other in independent DRM (IDRM), we separately model the dual roles of each user. As Figure 1 illustrates, the IDRM can be divided into two steps. First, we employ the PLSA to analyze the topic information of all the questions, and then model the answerer role and asker role of each user based on questions which he answers or asks.",0,,False
93,z,0,,False
94,q |t| |Q|,0,,False
95,Figure 1: Independent DRM.,0,,False
96,We introduce the latent variable,0,,False
97,to indicate each,0,,False
98,topic under users and questions. The model of user's answerer,0,,False
99,"role can be represented as its topic distribution | . Similarly,",0,,False
100,the asker role is characterized by,0,,False
101,| and the latent topic,0,,False
102,information of the question is | . According to the first step,0,,False
103,"of IDRM in the Figure 1, the generative model for question/word",0,,False
104,co-occurrences is defined as: a latent topic is obtained with,0,,False
105,"probability , and then a question q is generated with probabil-",0,,False
106,ity | and a word is generated with probability | .,0,,False
107,"Therefore, we can compute the joint probability , of ob-",0,,False
108,serving a question together with a word based on topic varia-,0,,False
109,ble as follows:,0,,False
110,",",0,,False
111,|,0,,False
112,|,0,,False
113,"Then considering all question/word pairs , set , the log likelihood is",0,,False
114,in question,0,,False
115,",",0,,False
116,",",0,,False
117,",",0,,False
118,"where q, w is the frequency of word in the question . We use the Expectation Maximization (EM) method to learn",0,,False
119,"the model parameters , | and | : E-Step,",0,,False
120,"|,",0,,False
121,|,0,,False
122,|,0,,False
123,|,0,,False
124,|,0,,False
125,"M-Step,",0,,False
126,",",0,,False
127,"|,",0,,False
128,",",0,,False
129,|,0,,False
130,",",0,,False
131,"|,",0,,False
132,|,0,,False
133,",",0,,False
134,"|,",0,,False
135,"After obtaining all questions' representations, we perform the second step to get the representations of users' different roles. The user's answerer role is defined as the combination of topic distributions of all questions that he answers, and the modeling method is similar for the asker role. Intuitively, we can give an example to illustrate the feasibility of this approach. For example, if a user answers lots of questions related to using computer, so the profile",0,,False
136,773,0,,False
137,"of his answerer role is very likely to be related to this topic. Specifically, the role models | and | are estimated as:",0,,False
138,|,0,,False
139,| |,0,,False
140,|,0,,False
141,| |,0,,False
142,"where, and",0,,False
143,"is the set of questions that the user answers, is the set of question he asks.",0,,False
144,4.2 Dependent DRM,0,,False
145,"Different from the IDRM, the assumption made in dependent",1,ad,True
146,DRM (DDRM) is that there is dependence between users. As we,0,,False
147,"can see in Figure 2, DDRM assumes that the answer and the asker",0,,False
148,are dependent on each other when not observing the latent varia-,0,,False
149,ble. The assumed generative model is as follows. We first pick a,0,,False
150,"latent topic to some prior . We then generate the answerer ,",0,,False
151,"the asker , and the content",0,,False
152,of question with corre-,0,,False
153,"sponding probability | , | , and ",0,,False
154,|,0,,False
155,",.",0,,False
156,"Thus, the joint probability distribution of a triple , ,",0,,False
157,of,0,,False
158,question is defined as:,0,,False
159,",,",0,,False
160,|,0,,False
161,|,0,,False
162,|,0,,False
163,",",0,,False
164,"In the above equation, , is the frequency of word in the content .",0,,False
165,"Accordingly, the log likelihood in DDRM is",0,,False
166,"log , ,",0,,False
167,",,",0,,False
168,"and we can also train the model using EM method as follows: E-step,",0,,False
169,"|, ,",0,,False
170,|,0,,False
171,|,0,,False
172,|,0,,False
173,",",0,,False
174,|,0,,False
175,|,0,,False
176,|,0,,False
177,",",0,,False
178,"M-step,",0,,False
179,"|, ,",0,,False
180,",,",0,,False
181,|,0,,False
182,",",0,,False
183,"|, ,",0,,False
184,",,",0,,False
185,|,0,,False
186,"|, ,",0,,False
187,",",0,,False
188,|,0,,False
189,"|, ,",0,,False
190,",",0,,False
191,"The IDRM and the DDRM respectively model the user's dual roles from different perspectives. Compared with previous models that do not take the dual roles and their distinctions into account, DRM provides a more precise and appropriate user representation model for question recommendation. Apart from different independence assumptions between users, we can see that the IDRM is a type of method modeling user role indirectly while the DDRM is a method which learns the role model directly.",0,,False
192,4.3 Question Recommendation,0,,False
193,"Based on any one of the above DRM variants, we build the",0,,False
194,DRM based method for question recommendation that takes full,0,,False
195,"advantage the characteristics of different user roles. When a new question arriving, we compute posterior probability | for",1,ad,True
196,z,0,,False
197,|t|,0,,False
198,q,0,,False
199,|Q|,0,,False
200,Figure 2: Dependent DRM.,0,,False
201,"each candidate user , and then recommend this question to the top N users. | is obtained by:",0,,False
202,|,0,,False
203,",",0,,False
204,",,",0,,False
205,|,0,,False
206,||,0,,False
207,|,0,,False
208,|,0,,False
209,/| |,0,,False
210,|,0,,False
211,",",0,,False
212,"where, the first step uses the Bayesian formula for an equivalent",0,,False
213,"transformation. In the second step, the question is decomposed",0,,False
214,"into its content and its asker . In addition, we only need to",1,ad,True
215,consider the candidate's answerer role when we evaluate whether,0,,False
216,"he is suitable to answer this question. Therefore, the is repre-",0,,False
217,sented as his answerer role . The third step and fourth step,0,,False
218,is based on the role models and the question model obtained in,0,,False
219,"DRM, where the generation probability | is normalized by",0,,False
220,the length of question content | |.,0,,False
221,"In this recommendation approach, |",0,,False
222,| denotes the,0,,False
223,"consistency of the answerer and the asker over topics, which",0,,False
224,models the user relation between the answerer and the asker. Cor-,0,,False
225,"respondingly,",0,,False
226,|,0,,False
227,"| , measures the con-",0,,False
228,"sistency of the answerer and the question content over topics,",0,,False
229,which models the content relevance between the answerer and the,0,,False
230,"question. As we can see, our DRM based method takes full ad-",1,ad,True
231,vantage of users' dual roles to improve the performance of ques-,0,,False
232,"tion recommendation. Moreover, this method utilizes a unified",0,,False
233,probabilistic framework to naturally associate the user relation,0,,False
234,"with the content relevance together, which is more interpretable.",0,,False
235,"Compared with the DRM, both the methods described in [2]",0,,False
236,and [6] employed a single role model to represent the user and,0,,False
237,ignored the user relation when recommending question to users.,0,,False
238,"In the next section, these methods will be used as two groups of",0,,False
239,baselines in our experiments.,0,,False
240,5. EXPERIMENTS,0,,False
241,We evaluate the proposed approach using a real-world data from Yahoo! Answers and conduct different experiments to address the following questions: (1) Are there any distinctions between users' dual roles and how they affect the result of question recommendation? (2) Does the proposed DRM improve the effectiveness of question recommendation compared with other base-,1,Yahoo,True
242,774,0,,False
243,"line methods? (3) Which of the two variants of DRM for question recommendation, namely IDRM and DDRM, is more effective?",0,,False
244,5.1 Data Sets,0,,False
245,"In order to obtain the data sets for experiments, we used Yahoo! Answers API3 to crawl 246490 resolved questions posted in 2011 from Yahoo! Answers. All the questions are lowercased and all stop words are removed from questions using a standard list of 418 common terms before further experiments.",1,Yahoo,True
246,"In our question set , we divide the whole question set and user set , into three subsets according to the user participation degree. For each subset, we split it into the training set and the testing set based on the asked time of questions. The training set is used solely for parameter estimation and the test set is used for evaluation purposes. In each subset, we take about 9/10 of questions as training set, and the rest as testing set. The data set statistics of all subsets are listed in Table 1. Each dataset contains a question set and a user set. For instance, the question set and user set of User-10 are and . We selected users who asked or answered more than 10 questions as the user set and then collected questions which were asked or answered by users in as the question set . Other subsets are similar to User-10.",0,,False
247,User-10 User-15 User-20,0,,False
248,Question Number,0,,False
249,32009,0,,False
250,28404,0,,False
251,25690,0,,False
252,Answer Number,0,,False
253,97911,0,,False
254,89144,0,,False
255,80677,0,,False
256,User Number 2515,0,,False
257,1339,0,,False
258,870,0,,False
259,Table 1: Statistic of Yahoo! Answers data set.,1,Yahoo,True
260,5.2 Evaluation Metric,0,,False
261,"In traditional recommender systems, precision is a commonly used measure to evaluate the performance. However, precision is not suitable in the CQA context. There are so many questions asked in a CQA community every day [1] that the user can only access a very small portion of all questions. While the questions one accessed are those he is interested in, we can not guarantee that the remaining unaccessed questions are those he does not like. That is, in some cases, a user did not access a question just because he had no chance to see the question in CQA system. Therefore, we employ a new metric proposed in [6] to evaluate the effectiveness of question recommendation in CQA.",1,ad,True
262,"For a question in testing set, the user who provides the best answer (named the best answerer, Adamic et al. [27] have verified that answers selected as the best ones are mostly indeed the most suitable for the questions.) of this question is seemlier to answer it compared with other answerers, so it is more reasonable to recommend this question to the best answerer than other answerers. Based on this intuition, we only recommend the question to the users who actually answered it instead of all possible users in the whole dataset. Then the recommendation accuracy for this question is defined according to the rank of the user who provides the best answer. (We only keep the questions which have more than one answer and are already labeled with the best answers in the testing set.) Therefore, according to the evaluation metric applied",1,ad,True
263,3 http://developer.yahoo.com/answers,0,,False
264,"in [6], we utilize the best answerer's rank as the ground truth of",0,,False
265,our evaluation metric:,0,,False
266,||,0,,False
267,1,0,,False
268,|| 1,0,,False
269,"where | | is the length of recommending list, which is equally the",0,,False
270,"number of answers, and",0,,False
271,is the rank of the best answerer.,0,,False
272,5.3 Role Analysis,0,,False
273,"We first discuss an interesting subject: the distinction between the user's two roles. Based on latent topic analysis of user roles in DRM, the distinction between the answer role and the asker role is defined as the difference between their topic distributions. The larger the difference between the topic distributions is, the greater the distinction between roles is. In information theory, the Kullback-Leibler divergence (KL divergence) is a commonly used non-symmetric measure of the difference between two probability distributions. We apply the KL divergence to assess the distinction between user roles. According to the modeling results of user roles in DRM, we obtain the latent topic distributions of each user role:",0,,False
274,|,0,,False
275,|,0,,False
276,|,0,,False
277,|,0,,False
278,|,0,,False
279,|,0,,False
280,|,0,,False
281,|,0,,False
282,"Based on the above two equations, the distinction between answer role and asker role of the user is",0,,False
283,||,0,,False
284,|,0,,False
285,log,0,,False
286,| |,0,,False
287,"In DRM, the number of topics is a parameter that has siginificant impact on the performance. We utilize crossvalidation to estimate the parameters. Based on experiments of tuning parameter, we empirically set topic number to 70 to train our DRM.",0,,False
288,"First, we analyze the average of KL divergence of all users in the user set of each subset to measure the overall distinction between user roles. The results are summarized in Table 2. Across",0,,False
289,data subsetsthe overall role distinction in IDRM is about 1.3 to,0,,False
290,"1.5, and that in DDRM is about 2.4. Compared with IDRM, the role distinction in DDRM is greater and relatively more stable over different data subsets.",0,,False
291,IDRM DDRM,0,,False
292,User-10 1.349 2.440,0,,False
293,User-15 1.379 2.467,0,,False
294,User-20 1.502 2.441,0,,False
295,Table 2: The overall distinction between user roles.,0,,False
296,"Furthermore, we take User-10 as an example to detail the distribution of role distinction, which is illustrated in Figure 3. For the DDRM, role distinction of 65.5% of users is more than 1.0, and most of them is in the range of [0.5, 3.5]. For the DDRM, role distinction of 74.3% of users is more than 2, most of which is in the range of [1.5, 4.5]. This shows that there are clear differences between different roles of most of users in CQA.",0,,False
297,"Another important result to note is that the role distinction in DDRM is more obvious and relatively more stable than that in IDRM, which can be observed in both of overall and detailed role analysis. This result may be due to that DDRM models the depen-",0,,False
298,775,0,,False
299,Figure 3: Distribution of the role distinction.,0,,False
300,User Ro1e Answerer,0,,False
301,Asker,0,,False
302,Topic ID 41 (using computer),0,,False
303,30 (programming),0,,False
304,Top Words,0,,False
305,"free, best, windows, antivirus, virus, anti, software, spyware, download, program, xp, vista, hard, drive",1,ad,True
306,"c, program, file, java, programming, write, language, convert, system, net, code, array, php, number",0,,False
307,Table 3: An example of the difference between user roles.,0,,False
308,Role,0,,False
309,Answerer Role Asker Role,0,,False
310,Blended Roles,0,,False
311,VSM VSM-an VSM-as VSM-bl,0,,False
312,PLSA1 (modeling user indi-,0,,False
313,rectly),0,,False
314,PLSA2 (modeling user directly),0,,False
315,PLSA1-an,0,,False
316,PLSA2-an,0,,False
317,PLSA1-as,0,,False
318,PLSA2-as,0,,False
319,PLSA1-bl,0,,False
320,PLSA2-bl,0,,False
321,Table 4: All versions of baselines considering users' different roles.,0,,False
322,dence between users which is more effective to capture the peculiarities of different user roles.,0,,False
323,"After discussing the role analysis of all users, we take a typical user in DDRM as an illustrative example to show the modeling results of user roles. Table 3 lists the topic with maximum probability and corresponding top words of the topic for both of user roles. As the result shows, this user is most likely to be a junior programmer (such as junior college students from school of computer science). He has some basic knowledge of computer and is familiar with using computer, so he solved many questions about that topic. While he may be just getting started with computer programming, a lot of questions he asked are related to programming.",0,,False
324,5.4 Question Recommendation,0,,False
325,5.4.1 Result Comparison,0,,False
326,"In this section, we explored how different roles of users affect the result of question recommendation. Moreover, we compared our DRM-based question recommendation method with other methods.",0,,False
327,"The models proposed in previous work are classified into two main categories. The first one is the word-level Vector Space Model (VSM) which is directly used to compute the similarity between users and questions. VSM only make use of word-level information to model users and questions. For example, the user and question are represented as vectors with tf.idf word weights, and then cosine similarity between them is defined as:",0,,False
328,",",0,,False
329,· || || · || ||,0,,False
330,.,0,,False
331,",.",0,,False
332,",",0,,False
333,.,0,,False
334,",",0,,False
335,.,0,,False
336,",",0,,False
337,where .,0,,False
338,", is the word 's tf.idf weight in question ,",0,,False
339,and .,0,,False
340,", is the sum of 's tf.idf weights in questions that",0,,False
341,asks or answers.,0,,False
342,The second one is PLSA based methods. As we have specified,0,,False
343,"in section 3, these methods model the user either indirectly or",0,,False
344,"directly. For the former, we took the model in [2] (PLSA1) as",0,,False
345,776,0,,False
346,VSM PLSA1 PLSA2 DRM,0,,False
347,VSM-an VSM-as VSM-bl PLSA1-an PLSA1-as PLSA1-bl PLSA2-an PLSA2-as PLSA2-bl IDRM DDRM,0,,False
348,User-10 0.555 0.456 0.541 0.639 0.445 0.622 0.638 0.447 0.619 0.669* 0.685* 7.2%,0,,False
349,User-15 0.600 0.492 0.591 0.650 0.482 0.642 0.651 0.485 0.647 0.675* 0.690* 6%,0,,False
350,User-20 0.612 0.466 0.581 0.671 0.448 0.628 0.674 0.441 0.622 0.683* 0.697* 3.4%,0,,False
351,Table 5: Recommendation accuracies of different methods for question recommendation. Each underlined value means the best result for each baseline group. `*' means the corresponding improvement over all baselines is statistically significant.,0,,False
352,"baseline. For the latter, we implemented the ""user-word aspect model"" presented in [6] (PLSA2) as another baseline. The details of PLSA1 and PLSA2 have been described in section 3.",0,,False
353,"In order to explore the impact of different user roles on question recommendation, we implemented the different versions of the three groups of baselines. These versions are based on the answerer role, the asker role, or the blended roles. Table 4 shows the labels of all baseline methods. Each version of a baseline is trained on the question set that users access under the corresponding role. Specifically, the blended roles mean all the question that each user answers or asks are simply mixed together as one set.",0,,False
354,"Based on cross-validation, we selected the best topic number for PLSA1 and PLSA2. The recommendation results of baselines and our DRM are summarized in Table 5, where the best result for each baseline group is underlined and the best result in each data subset is highlighted.",0,,False
355,"We first compare the performances of different roles in each baseline group. From Table 5, we observe that the answerer role always wins the best result in all baseline groups across data subsets. Especially, the answerer role is obviously better than the asker role over all the recommendation results. When data sets become denser and denser from User-10 to User-20, the effect of the answerer role becomes better and better as we expect. On the contrary, the result of the asker role appears an unexpected decrease in User-20. Furthermore, we examine the recommendation results of blended roles. As we can see, simply mixing the asker role into the answerer role not only fails to improve but worsens recommendation results of answerer role instead. According to above experiments, we conclude that different user roles reflect the different aspects of the user, moreover, there are clear distinctions between their influences on question recommendation. When modeling the user in CQA, we must distinguish the different user roles. When recommending new questions to users, it would be more appropriate to use the answerer role model to represent the candidate users.",1,ad,True
356,"Since the recommendation methods based on blended roles do not work well, whether our DRM based method can make full use of user's dual roles to improve the recommendation result? Tested",0,,False
357,"on each data subset, our model exhibits good performance, significantly outperforming all baselines. The relative improvement of DDRM over the best baseline result is 7.2% for User-10, 6% for User-15, and 3.4% for User-20. In addition, DDRM is significantly better than IDRM across data sets, which means considering the dependence between uses is more effective to model user roles. This result is also consistent with the above role analysis.",1,ad,True
358,"Another interesting result to note is that the PLSA1 which models the user indirectly is almost equivalent to PLSA2 which models the user directly on three data subsets, suggesting that it is feasible to model the user indirectly by combining the topic information questions that he accesses. Additionally, it is clear that all methods based on latent topic analysis (PLSA1, PLSA2, and DRM) always perform better than word-level VSM, which demonstrates that the latent topic based model can be more effective to represent the profile of user. And this result also verifies the conclusion drew in [6]. Moreover, it is part of the reason for that Guo et al. [4] introduced topic-level model to improve heuristic word-level methods.",0,,False
359,5.4.2 Parameter Sensitivity,0,,False
360,"We note that the topic number K is an important parameter in our proposed DRM. Therefore, we are interested in analyzing the sensitivity of the recommendation performance of DRM with respect to the topic number. We tested these two DRM variants with 8 different values of K, which is illustrated in Figure 4. Like previous role analysis, we only present the final results in data subset User-10. The results for other subsets are similar. As we can see from Figure 4, the recommendation accuracy gradually increases when the topic number varies from 10 to 40. Then we observe that the effectiveness of both DRM based recommendation approaches begins to be relatively stable when topic number is more than 40.",1,ad,True
361,6. CONCLUSION & FUTURE WORK,0,,False
362,"The user in CQA plays two different roles (dual roles) simultaneously, which is different from the user in a general recommender system. In this paper, we have systematically investigated the",0,,False
363,777,0,,False
364,Figure 4: Sensitivity to the topic number of DRM.,0,,False
365,"distinctions between users' dual roles and how they affect the performance of question recommendation differently. Moreover, in order to represent the user in CQA with dual roles more reasonably and precisely, we proposed a Dual Role Model (DRM) to model the user's different roles. With different independence assumptions, two variants of DRM were achieved, which were independent DRM (IDRM) and dependent DRM (DDRM). Finally, we presented the DRM based approach to question recommendation which can take full advantage of the particularities of users' different roles. Based on a unified probabilistic framework, our DRM based method naturally combines the user relation between the answerer and the asker with the content relevance between the answerer and the question.",1,ad,True
366,"Our experiments were carried out on a real-world data crawled from Yahoo! Answers. First, the results of user role analysis showed that there are evident differences between the answerer role and asker role of users in CQA. Comparing the effects of the two roles on question recommendation, we discovered that the answerer role model is more appropriate to represent the candidate users when recommending new questions to users. Additionally, an interesting result was that simply mixing the asker role into the answerer role not only failed to improve but impaired recommendation results of answerer role instead. Furthermore, we compared our DRM based recommendation methods with baseline methods based on a single role or blended roles. Experiment results on three data subsets showed our DRM significantly outperforms all baselines, where the relative improvement of DRM over the best baseline result is 7.2% for User-10, 6% for User-15, and 3.4% for User-20. In addition, DDRM is more effective than IDRM across data subsets, suggesting it is more effective to model users' dual roles. Finally, the parameter sensitivity analysis showed our DRM approach is robust.",1,Yahoo,True
367,"There are two interesting future research directions to explore. One of the most interesting directions is to further study how the roles of users will vary over time, and whether that will have influence on question recommendation. The other interesting direction is how to diversify the recommendation results to satisfy users better.",0,,False
368,7. ACKNOWLEDGMENTS,0,,False
369,We thank the anonymous reviewers for their useful comments. This work is supported by the National Science Foundation of China under Grant No. 61070111.,0,,False
370,8. REFERENCES,0,,False
371,"[1] L. Rao. Yahoo mail and im users update their status 800 million times a month. TechCrunch, Oct282009. http://techcrunch.com/2009/10/28/yahoo-mail-and-imusersupdate-their-status-800-million-times-a-month/.",1,Yahoo,True
372,"[2] Hu Wu, Yongji Wang and Xiang Cheng. Incremental Probabilistic Latent Semantic Analysis for automatic question recommendation. In RecSys'08, pages 99-106, 2008.",0,,False
373,"[3] Damon Horowitz and Sepandar D. Kamvar. The anatomy of a large-scale social search engine. In WWW'10, pages 431440, 2010.",0,,False
374,"[4] Jinwen Guo, Shengliang Xu, Shenghua Bao, and Yong Yu. Tapping on the potential of Q&A community by recommending answer providers. In CIKM'08, pages 921-930, 2008.",0,,False
375,"[5] Gideon Dror, Yehuda Koren, Yoelle Maarek and Idan Szpektor. I want to answer, who has a question? Yahoo! Answers recommender system. In SIGKDD'11, pages 11091117, 2011.",1,Yahoo,True
376,"[6] Mingcheng Qu, Guang Qiu, Xiaofei He, Cheng Zhang, Hao Wu, Jiajun Bu, and Chun Chen. Probabilistic question recommendation for question answering communities. In WWW'09, pages 1229-1230, 2009.",0,,False
377,"[7] Alexandrin Popescul, Lyle H. Ungar, David M. Pennock and Steve Lawrence. Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments. In UAI'01, pages 437-444, 2001.",0,,False
378,"[8] Baichuan Li, Irwin King and Michael R. Lyu. Question routing in community question answering- putting category in its place. In CIKM'11, pages 2041-2044, 2011.",0,,False
379,[9] Thomas Hofmann and Jan Puzicha. Latent class models for,0,,False
380,"collaborative filtering. In IJCAI'99, pages 688­693. 1999.",0,,False
381,"[10] Thomas Hofmann. Probabilistic latent semantic indexing. In SIGIR'99, pages 50-57, 1999.",0,,False
382,"[11] Luo Si and Rong Jin. Flexible mixture model for collaborative filtering. In ICML'03, 2003.",0,,False
383,"[12] David M. Blei , Andrew Y. Ng and Michael I. Jordan. Latent dirichlet allocation. In Journal of Machine Learning Research, pages 993-1022, 2003.",0,,False
384,"[13] Thomas Hofmann. Collaborative filtering via gaussian probabilistic latent semantic analysis. In SIGIR'03, pages 259-266, 2003.",0,,False
385,"[14] Tom Chao Zhou, Chin-Yew Lin, IrwinKing, Michael R. Lyu, Young-In Song and Yunbo Cao. Learning to suggest questions in online forums. In AAAI'11, pages 1298-1303, 2011.",0,,False
386,"[15] Qiaoling Liu and Eugene Agichtein. Modeling answerer behavior in collaborative question answering systems. In ECIR'11, pages 67-79, 2011.",0,,False
387,"[16] Ke Sun, Yunbo Cao, Xinying Song, Young-In Song, Xiaolong Wang and Chin-Yew Lin. Learning to recommend questions based on user rating. In CIKM'09, pages 751-758, 2009.",0,,False
388,"[17] Nathan N. Liu and Qiang Yang. EigenRank: A rankingoriented approach to collaborative filtering. In SIGIR'08, pages 83-90, 2008.",0,,False
389,778,0,,False
390,"[18] Adomavicius G., and Tuzhilin A. Toward the next generation of recommender systems: A survey of the state-of-theart and possible extensions. In IEEE Trans. on Knowledge and Data Engineering, 17(6), 2005.",0,,False
391,"[19] P. Kantor, F. Ricci, L. Rokach, and B. Shapira. Recommender Systems Handbook: A complete guide for research scientists and practitioners. Springer, 2010.",0,,False
392,"[20] Thomas Hofmann. Unsupervised learning by probabilistic latent semantic analysis. Maching Learning Journal, Vol. 42, No. 1-2, pages. 177-196, 2001.",0,,False
393,"[21] Jiwoon Jeon, W. Bruce Croft, Joon Ho Lee and Soyeon Park. A framework to predict the quality of answers with non-textual features. In SIGIR'06, pages 228-235, 2006.",0,,False
394,"[22] Jiwoon Jeon, W. Bruce Croft and Joon Ho Lee. Finding semantically similar questions based on their answers. In SIGIR'05, pages 617-618, 2005.",0,,False
395,"[23] G. Linden, B. Smith, and J. York. Amazon.com recommendations: Item-to-item collaborative filtering. In IEEE Internet Computing, 07(1):76-80, 2003.",0,,False
396,"[24] Jiahui Liu, Peter Dolan, Elin Rønby Pedersen. Personalized news recommendation based on click behavior. In IUI'10, pages 31-40, 2010.",0,,False
397,"[25] Y. Cao, H. Duan, Chin-Yew Lin, Y. Yu and Hsiao-Wuen Hon. Recommending questions using the MDL-based tree cut model. In WWW'08, pages 81-90, 2008.",0,,False
398,"[26] S. Deerwester, S. Dumais, T. Landauer, G. Furnas, and R. Harshman. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391407, 1990.",0,,False
399,"[27] J. Zhang, L. A. Adamic, E. Bakshy and Mark S. Ackerman. Every-one knows something: Examining knowledge sharing on Yahoo! Answers. In WWW'08, pages 665-674, 2008.",1,Yahoo,True
400,"[28] M. Pazzani and D. Billsus. Learning and revising user profiles: The identification of interesting web sites. Machine Learning. vol. 27, pages 313-331, 1997.",0,,False
401,"[29] Y. Koren, R. M. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Journal of Computer, 42(8):30-37, 2009.",0,,False
402,"[30] Kevin K. Nam, Mark S. Ackerman, Lada A. Adamic. Questions in, knowledge in? A study of Naver's question answering community. In CHI'09, pages 779-788, 2009.",1,ad,True
403,"[31] Pawel Jurczyk, Eugene Agichtein. Discovering authorities in question answer communities by using link analysis. In CIKM'07, pages 919-922, 2007.",0,,False
404,779,0,,False
405,,0,,False
