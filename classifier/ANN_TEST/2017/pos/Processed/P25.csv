,sentence,label,data,regex
0,Session 1A: Evaluation 1,1,Session,True
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
2,"The Probability That Your Hypothesis Is Correct, Credible Intervals, and E ect Sizes for IR Evaluation",0,,False
3,Tetsuya Sakai,0,,False
4,"Waseda University, Tokyo, Japan tetsuyasakai@acm.org",0,,False
5,ABSTRACT,0,,False
6,"Using classical statistical signi cance tests, researchers can only discuss P(D+|H ), the probability of observing the data D at hand or something more extreme, under the assumption that the hypothesis H is true (i.e., the p-value). But what we usually want is P(H |D), the probability that a hypothesis is true, given the data. If we use Bayesian statistics with state-of-the-art Markov Chain Monte Carlo (MCMC) methods for obtaining posterior distributions, this is no longer a problem. at is, instead of the classical p-values and 95% con dence intervals, which are o en misinterpreted respectively as ""probability that the hypothesis is (in)correct"" and ""probability that the true parameter value drops within the interval is 95%,"" we can easily obtain P(H |D) and credible intervals which represent exactly the above. Moreover, with Bayesian tests, we can easily handle virtually any hypothesis, not just ""equality of means,"" and obtain an Expected A Posteriori (EAP) value of any statistic that we are interested in. We provide simple tools to encourage the IR community to take up paired and unpaired Bayesian tests for comparing two systems. Using a variety of TREC and NTCIR data, we compare P(H |D) with p-values, credible intervals with con dence intervals, and Bayesian EAP e ect sizes with classical ones. Our results show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for the e ect size in terms of Glass's .",1,ad,True
7,CCS CONCEPTS,0,,False
8,·Information systems  Retrieval e ectiveness; Presentation of retrieval results;,0,,False
9,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan. © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080766",1,ad,True
10,KEYWORDS,0,,False
11,Bayesian hypothesis tests; con dence intervals; credible intervals; e ect sizes; Hamiltonian Monte Carlo; Markov Chain Monte Carlo; p-values; statistical signi cance,0,,False
12,1 INTRODUCTION,1,DUC,True
13,"In March 2016, the American Statistical Association (ASA) published an o cial statement about the limitations of classical significance tests and p-values, in response to their continued misuse and misinterpretations [33]. While ASA's main statement does not contain anything new (e.g., ""A p-value, or statistical signi cance, does not measure the size of an e ect or the importance of a result""), the document mentions some alternatives to classical signi cance tests, including Bayesian methods. It goes on to say: ""All these [alternative] measures and approaches rely on further assumptions, but they may more directly address the size of an e ect (and its associated uncertainty) or whether the hypothesis is correct."" In the IR community, similar warnings against classical signi cance tests have been given by Cartere e [4] and Sakai [22], amongst others.",1,ad,True
14,"e above quotations from the ASA statement may be paraphrased as follows. Classical signi cance tests can only give us P(D+|H ), the probability of observing the data D at hand or something more extreme under the assumption that the hypothesis H is true (i.e., the p-value). But what we usually want is P(H |D), the probability that a hypothesis is true, given the data. eoretically, the Bayesian framework proposed in the 18th century [2] can give us exactly this, but it was heavily criticised during the 19th and 20th centuries (See Section 2.1). However, with the recent advent of e ective and e cient sampling algorithms for obtaining posterior distributions known as Markov Chain Monte Carlo (MCMC) methods [15], Bayesian approaches to statistical testing are rapidly gaining popularity among statisticians [30, 31]. us, as alternatives to the classical p-values and 95% con dence intervals which are o en misinterpreted respectively as ""probability that the hypothesis is (in)correct"" and ""probability that the true parameter value drops within the interval is 95%,"" we can employ Bayesian tests to easily obtain P(H |D) and credible intervals, which represent exactly the above. Moreover, with Bayesian tests, we can easily handle virtually any hypothesis, not just ""equality of means,"" as we shall demonstrate later.",1,ad,True
15,We provide simple tools to encourage the IR community to take up paired and unpaired Bayesian tests for comparing two systems; our tools are based on a state-of-the-art MCMC method called Hamiltonian Monte Carlo and a recently-proposed variant called No-U-Turn Sampler [13]. Using a variety of TREC1 and NTCIR2,1,TREC,True
16,1h p://trec.nist.gov/ 2h p://research.nii.ac.jp/ntcir/,1,trec,True
17,25,0,,False
18,Session 1A: Evaluation 1,1,Session,True
19,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
20,"data, we compare P(H |D) with p-values, credible intervals with con dence intervals, and Bayesian EAP e ect sizes with classical ones. Our results show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for the e ect size in terms of Glass's .",1,AP,True
21,2 RELATED WORK,0,,False
22,2.1 Frequentists Versus Bayesians,0,,False
23,"It is well known that Ronald A. Fisher heavily and persistently criticised the Bayesian statistics since the 1960s: ""the theory of inverse probability [i.e., Bayesian statistics] is founded upon an error, and must be wholly rejected"" [9] (p.9). During the 20th century, the de facto standard in statistical analysis was indeed the ""frequentist"" approach founded upon Fisher's views, and the Bayesian approach was largely neglected.",0,,False
24,"e Bayesian approach had two weaknesses. e rst, which has not been resolved completely even to this day, is the fact that it relies on prior probabilities which nobody knows and therefore must be set based on researchers' subjective decisions or beliefs. However, given the lack of knowledge about priors, noninformative priors such as those that obey a uniform distribution can always be used, although this too is a subjective decision which may or may not re ect the true nature of the phenomenon under study3. In the present study, we simply follow the standard Bayesian practice of employing uniform distributions for obtaining priors.",1,ad,True
25,"e second weakness in the original Bayesian approach was that, despite the theoretical beauty of Bayes' eorem, it was o en di cult to obtain the posterior distributions as this o en involves computationally infeasible integrations. However, this second problem has actually been solved, with the recent advent of e ective and e cient sampling algorithms known as Markov Chain Monte Carlo (MCMC) methods [15]. Because of this, Bayesian statistics is now gaining popularity rapidly: for example, according to Toyoda [30], over one-half of Biometrika4 papers published in 2014 utilised Bayesian statistics. In the present study, we utilise a stateof-the-art MCMC method called Hamiltonian Monte Carlo [17] and a recently-proposed variant called No-U-Turn Sampler [13], which come with easy-to-use implementations.",1,ad,True
26,"Meanwhile, the classical signi cance testing approach of the frequentists have also received many criticisms over the past decades (e.g. [12]). Some even consider signi cance tests to be harmful. First, the practice of using the signi cance criterion  instead of the p-value o en leads to dichotomous thinking: ""Is the di erence statistically signi cant, or not?"" Ziliak and McCloskey [35] hold",1,ad,True
27,"3 In 2005, Efron remarked: ""What looks uninformative enough o en turns out to subtly force answers in one direction or another"" while arguing that a combination of Bayesian and frequentist ideas is needed to handle modern problems [8]. 4 is is the journal in which William S. Gosset (or ""Student"") published the famous paper on the t -test in 1908 [29]. h p://biomet.oxfordjournals.org/",0,,False
28,"Fisher responsible for this5. Second, even if the p-value is reported, this is a function not only of the e ect size (the magnitude of the di erence that we are interested in; See Section 3.6) but also the sample size. at is, a small p-value (i.e., a statistically highly signi cant result) may just re ect a large sample size (e.g., number of topics used for computing mean retrieval e ectiveness scores) rather than a large e ect size [22]. Moreover, as was mentioned in Section 1, the outcomes of classical signi cance tests are o en misinterpreted. We believe that it is time for the IR community to start using Bayesian statistics regularly, perhaps along with classical signi cance tests if the community feels reluctant to let the la er go. Since the Bayesian approach is not only highly intuitive and exible but now also computationally feasible, there really is no reason to reject it.",0,,False
29,"In the eld of psychology, Kruschke [14] argues that the Bayesian approach is superior to the (unpaired) t-test: ""Some people may wonder which approach, Bayesian or NHST,6 is more o en correct.",0,,False
30,"is question has limited applicability because in real research we never know the ground truth; all we have is a sample of data. [. . .] the relevant question is asking which method provides the richest, most informative, and meaningful results for any set of data. e answer is always Bayesian estimation."" In the present study, we empirically demonstrate the relationships between paired/unpaired t-tests and the corresponding state-of-the-art Bayesian methods using a variety of real IR evaluation data.",0,,False
31,2.2 Classical Signi cance Tests in IR,0,,False
32,"e limitations of classical signi cance tests have been pointed out in the eld of IR as well. Cartere e argues: ""we still believe p-values from paired t-tests provide a decent rough indicator that is useful for many of the purposes they are currently used for. We only argue that p-values and signi cance test results in general should be taken with a very large grain of salt, and in particular have an extremely limited e ect on publication decisions and community-wide decisions about ""interesting"" research directions."" Sakai [22] encourages IR researchers to report not only the p-values but also e ect sizes and con dence intervals. However, Sakai's more recent examination of over 1,000 SIGIR and TOIS papers [23] shows that about 30% of the entire papers lack signi cance testing, while about 65% of the papers with signi cance testing neither report p-values nor test statistics.",0,,False
33,"While computer-based, distribution-free alternatives to classical signi cance tests, namely, the bootstrap [20] and the randomisation test [27], have been advocated for IR evaluation, they have not been used as widely as the classical tests [23]. Moreover, these tests address the same limited question as the classical tests: what is the p-value?",1,ad,True
34,2.3 Bayesian Inferences for IR,0,,False
35,"We are already beginning to see Bayesian approaches to IR evaluation. Cartere e [3, 5] have proposed to evaluate IR systems by modelling binary and graded relevance judgments directly instead",1,ad,True
36,"5 ""Ronald A. Fisher would say, "" e potash manures are not statistically signi cant. Disregard them. [. . .] William S. Gosset would say, ""[. . .] If you want to know about the potash manures you have to consider their pecuniary value compared to the barley you're trying to make money with"" [35]. 6Null Hypothesis Signi cance Testing",0,,False
37,26,0,,False
38,Session 1A: Evaluation 1,1,Session,True
39,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
40,"of using evaluation measure scores as the atomic unit. Using three di erent TREC data sets, he compared t-test p-values with the posterior probabilities of his four Bayesian models to argue the advantages of the la er. Cartere e uses JAGS (Just Another Gibbs Sampler), an open-source implementation of BUGS (Bayesian inference Using Gibbs Sampling) and its R interface rjags to conduct MCMC simulations.",1,TREC,True
41,"Our present work is in a sense less ambitious than that of Cartere e in that we are adhering to using evaluation measure scores as the atomic unit (just like Cartere e's ""Model 2""): we would like the IR community to take up the habit of using Bayesian approaches, and to do that, we believe that we need to move cautiously while clarifying how the transition from classical signi cance testing will a ect our research ndings. Cartere e demonstrates that the t-test (i.e., his ""Model 1"") p-values and his Model 2 posterior probabilities are strinkingly similar; we generalise this in several ways, by using diverse data sets from NTCIR and TREC, and by comparing con dence intervals with credible intervals, and classical sample e ect sizes with their Bayesian counterparts.",1,ad,True
42,"Zhang et al. [34] propose to replace the use of classical signi cance tests with Bayesian tests with probabilistic graphical models tailored to a speci c problem in information retrieval, namely, text classi cation. Following Kruschke [14, 15], they propose to make a decision about two text classifers by comparing the High Density Interval (HDI) and the Region of Practical Importance (ROPE) of the performance di erence  . Zhang et al. use Metropolis-Hastings (MH) sampling for their MCMC simulations.",0,,False
43,"Regarding the implementation of MCMC, we employ the stateof-the-art Hamiltonian Monte Carlo (HMC) [17] and its variant NoU-Turn Sampler (NUTS) [13] using stan and its R interface rstan, which are gaining popularity. According to Ho man and Gelman [13], HMC's features ""allow it to converge to high-dimentional",0,,False
44,"target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling""; NUTS automatically sets a required parameter for HMC, namely the number of steps L for the leap-frog method (See Section 3.2). Also, according to Kruschke [15] (pp.399-400), ""HMC can be more e ective than the",0,,False
45,"various samplers in JAGS and BUGS, especially for large complex models. [. . .] However, Stan is not universally faster or be er (at this stage in its development).""",0,,False
46,3 BAYESIAN TESTS 3.1 Bayesian Basics,0,,False
47,"To discuss Bayesian tests, let us start with the famous Bayes' rule:",0,,False
48,"f ( |x) ,",0,,False
49,f (x | )f ( ) f (x),0,,False
50,",",0,,False
51,f (x | )f ( ),0,,False
52, +,0,,False
53,-,0,,False
54,f,0,,False
55,(x,0,,False
56,| )f,0,,False
57,(,0,,False
58,)d,0,,False
59,",",0,,False
60,(1),0,,False
61,"where f ( ) is the prior probability distribution of a random variable  (e.g., a population mean), f (x | ) is the likelihood of data x given  , and f ( |x) is the posterior probability distribution of  having observed x. Note that this view is already strikingly di erent from that of classical statistics: in classical signi cance testing, population parameters ( 's) are constants; in Bayesian statistics, they are random variables that form distributions. Since f ( |x) is a probability distribution, f (x) can be viewed as a normalising constant that",1,ad,True
62,ensures:,0,,False
63, +,0,,False
64,-,0,,False
65,f ( |x)d,0,,False
66,",",0,,False
67,1 f (x),0,,False
68, +,0,,False
69,-,0,,False
70,f (x | )f ( )d,0,,False
71,",1.",0,,False
72,(2),0,,False
73,"Hence, Eq. 1 implies that the property of the posterior distribution",0,,False
74,"f ( |x) is governed by f (x | )f ( ), i.e., the kernel.",0,,False
75,"If somehow the posterior distribution f ( |x) has been obtained,",0,,False
76,a point estimate of the population parameter  can be obtained as an expected a posteriori (EAP)7:,1,AP,True
77," ^EAP , E[ |x] ,",1,AP,True
78,"  f ( |x)d ,",0,,False
79,f,0,,False
80,(x | )f f (x),0,,False
81,(,0,,False
82,),0,,False
83,d,0,,False
84,.,0,,False
85,(3),0,,False
86,"Moreover, how the random variable  moves around ^EAP can be quanti ed by the posterior variance (or its square root, posterior",1,AP,True
87,standard deviation):,0,,False
88," V [ |x] , E[( - ^EAP )2|x] , ( - ^EAP )2 f ( |x)d . (4)",1,AP,True
89,"We can also obtain an interval estimate of  by removing an /2% area from either side of f ( |x). is is the 100(1 - )% credible interval (or Bayesian con dence interval), which is highly intuitive: the probability that the random variable  lies within the interval is 100(1 - )%. Recall that con dence intervals (CIs) used in classical statistics do not represent this probability: in the classical paradigm,  is a constant, and when (say) 100 CIs are created from 100 di erent samples, 100(1 -)% of them are expected to contain that particular .",1,ad,True
90,"As we do not know f ( ), we employ a non-informative prior distribution to avoid subjectivity to the best of our ability. Our choice is to use a uniform distribution, in which case f ( |x) is governed solely by the likelihood f (x | ) in Eq. 1 and therefore the EAP reduces to the maximum likelihood estimate (MLE). at is, in our se ing, the EAP of any parameter  is not directly a ected by our subjective choice of f ( ).",1,AP,True
91,3.2 HMC and NUTS,0,,False
92,"In the above discussion, we assumed that f ( |x) can be computed as de ned in Eq. 1. However, in practice, it is usually not feasible to do this analytically. at is where MCMC methods, which try to sample  repeatedly according to f ( |x), come into play. MCMC methods construct Markov Chains of parameter values so that the underlying distribution eventually reaches a stationary distribution: a er a burn-in period (B), all of the values in the chain obey the target distribution f ( |x). us, if we collect T values sequentially and throw away the intial B values, the remaining T , T -B values can be regarded as realisations of  that obey f ( |x). Suppose that we managed to obtain T ,"" 100, 000 realisations of  ; then, ^EAP (Eq. 3) can be obtained by simply averaging the T values. Similarly, the posterior variance (Eq. 4) can be obtained by averaging8 the squared di erence from ^EAP . A 95% credible interval for  can be obtained by sorting the T values in ascending order and then taking the 2,500th and 97,500th values as the lower and upper limits. e EAP values of other statistics such as e ect sizes (See Section 3.6) can be computed similarly. Moreover, for virtually any hypothesis H (e.g., """"mean 1 is higher than mean 2,"""" """"mean 1 is at least 0.2 points""",1,AP,True
93,"7 Alternatives would be a maximum a posteriori or a posterior median. ese three estimates represent the mean, mode and median of the posterior distribution, respectively. 8 Dividing by T su ces since T is large; there is no need for bias correction.",0,,False
94,27,0,,False
95,Session 1A: Evaluation 1,1,Session,True
96,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
97,"higher than mean 2,"" or ""the e ect size is greater than 0.5""), the probability that H is correct can be obtained by just counting the instances in which H holds among the T realisations. It is clear that this approach is more versatile than classical signi cance tests.",0,,False
98,"Hamiltonian Monte Carlo (HMC) [17] and its variant No U-Turn Sampler (NUTS) [13] are state-of-the-art MCMC methods which we utilise for obtaining realisations of  from f ( |x). For details of HMC, we refer the reader to recent books on this topic [15, 17]. However, it would help for us IR researchers to have a general idea about its basic principles. In physics, Hamiltonian is the sum of potential energy and kinetic energy; given a curved surface in an ideal physical world, any object would move on the surface while keeping the Hamiltonian constant. e path of the moving object is governed by Hamilton's equations of motion, which can be solved by the leap-frog method with parameters  (stepsize) and L (leapfrog steps). To achieve sampling from a posterior distribution (which is our ""curved surface""), an intuitive explanation of what HMC does is as follows: put an object somewhere on the surface and give it a push; a er L units of time, let it halt and record its position; give it another push, and so on, until we have recorded T positions.",1,ad,True
99,"Brie y, for a set of d parameters  ,"" (1, 2, . . . , d ), the HMC algorithm looks like this:""",0,,False
100,"(1) Set  (1), , L,T , B (where T , T - B); Let t , 1; (2) Generate d independent values p(t ) ,"" (p1t , p2t , . . . , pdt ) from""",0,,False
101,"a standard normal distribution; (3) Obtain candidates  (a), p(a) using the leap-frog method; (4) Let  (t +1) ,""  (a) (i.e., accept the transition candidate) with""",0,,False
102,"probability min(1, r ); otherwise  (t +1) ,""  (t ) (i.e., reject the candidate and stay at the current position); (5) End if T "", t; otherwise let t , t + 1 and go to Step 2.",0,,False
103,"e r in Step 4, which governs how o en we can accept new candidates, is given by [30]:",0,,False
104,r,0,,False
105,",",0,,False
106,"f ( (a), p(a) |x) f ( (t ), p(t ) |x)",0,,False
107,",",0,,False
108,(5),0,,False
109,"where f (, p|x) is a joint distribution of f ( |x) and an independent standard normal distribution f (p). One strength of HMC is that r is o en close to one, and therefore we can achieve e cient sampling through many successful transitions in Step 4 while preserving the Hamiltonian.",0,,False
110,"NUTS is a variant of HMC that automatically determines an appropriate value of L [13]; both HMC and NUTS utilise an algorithm called dual averaging to automatically set  [18]; hence, from the viewpoint of the users of HMC and NUTS for Bayesian tests, we do not have to worry about se ing these parameters ourselves.",0,,False
111,3.3 R^ and E ective Sample Size,0,,False
112,"For MCMC algorithms, methods for checking whether the values have converged to a stationary distribution and for measuring the sampling e ciency are available.",0,,False
113,"R^, a measure for checking convergence, assumes that the MCMC algorithm produces multiple Markov Chains, and compares the variance across the multiple chains with the variance within the chains9. According to Gelman [10], if R^ is less than 1.1 or 1.2, we",0,,False
114,"9Zhang et al. [34] remark that ""it is perfectly right to do a single long sampling run and keep all samples."" However, it is very easy to throw away burn-in's that may not yet",0,,False
115,"can be assured that the chains have reached stationary distributions. MCMC produces Markov Chains and therefore the values in them are correlated to one another. If the chains produce very similar values repeatedly, then that is highly ine cient from the sampling point of view. E ective Sample Size (Ne ) is a measure available in stan for quantifying sampling e ciency, which means ""you have obtained a sample of size T , but that is worth a sample of size (approximately) Ne obtained when there is zero correlation within the chain."" Hence, we should also check that Ne is a large value. Both of the above measures are computed a er removing the burn-in's from the chains. As our Bayesian test tools that we introduce in Section 3.7 rely on stan and its R interface rstan, the tools output R^ and Ne on the R console. Since all experiments reported in the paper use su ciently large sample sizes, namely T ,"" 100, 000, we do not discuss these indicators henceforth.""",0,,False
116,3.4 Classical versus Bayesian Tests for Comparing Two Means,0,,False
117,"As was discussed in Section 3.2, Bayesian tests are versatile. However, the present study focusses on the problems of comparing two means from paired and unpaired data, since these are the most common and basic problems in IR evaluation. While two-sided tests that ask ""are the two systems equally e ective or not?"" are o en recommended in classical signi cance tests given lack of prior knowledge as to which system might be be er, this is not a very useful question from the Bayesian point of view, as two di erent systems are, by de nition, di erent. What is more practical to consider is the probability that System 1 is be er than System 2, P(S1 > S2|D) (or, alternatively, P(S1 < S2|D) ,"" 1 - P(S1 > S2|D)). Hence we compare Bayesian tests with classical one-sided tests. To be more speci c, given two systems, we let S2 be the less e ective system according to the sample data and consider P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) based on the Bayesian test, while se ing the classical null and alternative hypotheses as H0 : S1 "","" S2 and H1 : S1 > S2 so that the p-value represents """"P(D+|S1 "","" S2).""""""",0,,False
118,3.5 Statistical Models,0,,False
119,"For unpaired data, we assume that S1's scores obey N (µ1, 12), while S2's scores obey N (µ2, 22), for both Bayesian and classical tests. Hence, the classical test we employ is the Welch's t-test, which does not assume homoscedasticity (i.e., equal variances). It is known that Student's and Welch's t-tests yield virtually identical p-values when the two sample sizes are equal [16, 24]; the experiments reported in this paper satisifes this condition and therefore our classical test results can be regarded as representing both types of unpaired t -test.",0,,False
120,"For paired data, the classical test we apply is the paired t-test, which relies on the same normal assumptions as described above and therefore the score di erences obey N (µ1 - µ2, 12 + 22). As for the Bayesian test, we can easily consider a bivariate normal",0,,False
121,"obey the desired distribution and we prefer to do so. As for the number of chains, since R^ can be computed even for a single chain, by breaking it into multiple chains, we provide sample scripts for handling both multiple and single chains. e Bayesian test results are almost the same either way, but we report those based on multiple chains.",0,,False
122,28,0,,False
123,Session 1A: Evaluation 1,1,Session,True
124,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
125,distribution [31]:,0,,False
126,f,0,,False
127,"(x1, x2 |µ1, µ2, 12, 22, )",0,,False
128,",",0,,False
129,1 2 12 (1,0,,False
130,-,0,,False
131,) e-q/2,0,,False
132,",",0,,False
133,(6),0,,False
134,where,0,,False
135,"q,",0,,False
136,1,0,,False
137,1 -,0,,False
138,2,0,,False
139,[(,0,,False
140,x1,0,,False
141,- 1,0,,False
142,µ1,0,,False
143,)2,0,,False
144,-,0,,False
145,2,0,,False
146,(,0,,False
147,x1,0,,False
148,- 1,0,,False
149,µ1,0,,False
150,)(,0,,False
151,x2,0,,False
152,- 2,0,,False
153,µ2,0,,False
154,),0,,False
155,+,0,,False
156,(,0,,False
157,x,0,,False
158,2,0,,False
159,- 2,0,,False
160,µ2,0,,False
161,)2],0,,False
162,.,0,,False
163,(7),0,,False
164,"Here,  is the population correlation coe cient for x1's and x2's. us, for paired data, we can discuss hypotheses about the corre-",0,,False
165,lation between the two systems just as well as those about means and e ect sizes if we are interested in that aspect.,0,,False
166,3.6 E ect Sizes,0,,False
167,Sakai [22] stresses the importance of reporting e ect sizes and,0,,False
168,con dence intervals in the context of classical signi cance testing as,0,,False
169,a small p-value may just re ect a large sample size (See Section 2.2).,0,,False
170,"When comparing two means, the e ect size is usually given as",0,,False
171,the di erence between the two measured in standard deviation,0,,False
172,units. We argue that Bayesian test results in IR should also be,0,,False
173,accompanied with e ect sizes as well as credible intervals.,0,,False
174,While there are several choices of e ect sizes for comparing,0,,False
175,"two means, we choose to avoid relying on the homoscedasticity",0,,False
176,"assumption, to be consistent with the statistical models described in",0,,False
177,Section 3.5. One of the simplest e ect size in such a case is Glass's,0,,False
178," [19]. at is, if System 1 is taken as the baseline run (or ""control",0,,False
179,"group,"") then its standard deviation is probably representative of",0,,False
180,"an ""ordinary world"" before the advent of System 2, and therefore:",1,ad,True
181,Gl ass 1,0,,False
182,",",0,,False
183,µ1 - µ2 1,0,,False
184,.,0,,False
185,(8),0,,False
186,"us, Glass's  measures the absolute di erence in ""ordinary"" stan-",0,,False
187,"dard deviation units. Alternatively, if System 2 is taken as the",0,,False
188,baseline:,0,,False
189,Gl ass 2,0,,False
190,",",0,,False
191,µ1 - µ2 2,0,,False
192,.,0,,False
193,(9),0,,False
194,"In our experiments, we focus on Eq. 9 since the second system is",0,,False
195,"the less e ective one (i.e., ""baseline"") according to the sample data.",0,,False
196,"For convenience, we will herea er refer to this version of e ect",0,,False
197,"size simply as ""Glass2.""",0,,False
198,"We can easily obtain the EAP and credible intervals for Glass2,",1,AP,True
199,as well as the probability of a hypothesis about the e ect size,0,,False
200,"being true, in exactly the same way as described in Section 3.2.",0,,False
201,"For example, the EAP for Glass2 can be obtained by computing",1,AP,True
202,"Eq. 9 T times using T realisations of µ1, µ2, 2 and then averaging them. Hence we propose that the IR community report the EAP,",1,AP,True
203,the credible interval and the probablity of hypothesis being true,0,,False
204,not only for the raw di erence in means but also for e ect sizes.,0,,False
205,Note that this is applicable to both paired and unpaired tests.,0,,False
206,3.7 Implementation,0,,False
207,"Here, we brie y describe our Bayesian test tools for comparing two means. e sample R scripts are based on those developed by Hideki Toyoda [30]10. We have sample scripts for generating both multiple and single chains but discuss only the former here. We have added a few shell scripts for postprocessing the Bayesian",1,ad,True
208,"10 Toyoda's original scripts are available from h p://www.asakura.co.jp/G 27 2.php? id,200. e present author is solely responsible for the modi cations and any errors introduced thereby.",0,,False
209,"realisations, to encourage researchers to use credibile intervals not only for the raw di erence in means but also for e ect sizes. e scripts and sample data are available from our website11. R with the rstan package12 and Rtools13 must be installed rst in order to use these scripts.",0,,False
210,"Figure 1 shows our sample R script for comparing paired data. It reads a stan le which describes the aforementioned bivariate normal distribution as well as generated quantities (the absolute di erence and Glass's 's), and a system score le wri en in R, and generates ve csv les that correspond to ve Markov chains.",1,ad,True
211,"Figure 2 shows an output of our UNIX shell script that summarises the Bayesian test results by reading the csv les. Here, the",1,ad,True
212,"rst argument is ""1032"" because this is the line number in each csv le where the realisations start a er the burn-in; the second argument is the number of realisations contained in the le (excluding the burn-in's); the third argument is the number of chains (i.e., number of csv les); the remaining arguments are the aforementioned Markov chain csv les. is script works for both multiple and single chains, by se ing the arguments appropriately14. e screenshot provides the following information about the paired data from run1 and run2:",0,,False
213,"· e EAP for the di erence in means is 0.042, and the 95% credibile interval is [0.009, 0.074]. e probability that µ1 - µ2 is greater than the speci ed threshold (which is set to 0 by default within the script) is 99.4%;",1,AP,True
214,"· e EAP for Glass2 (with run2 taken as the baseline) is 0.189 (i.e., about 19% of run2's standard deviation), and the 95% credible interval is [0.043, 0.345]. e probability that this e ect size is greater than the speci ed threshold (which is set to 0.2 by default) is 43.3%. Similar results with run1 taken as the baseline are also presented.",1,AP,True
215,"· e EAP for the correlation (i.e.,  in Eq. 6) between the scores of run1 and run2 is 0.857, and the 95% credible interval is [0.767, 0.920]. e probability that the correlation is greater than the speci ed threshold (which is set to 0.9 by default) is 12.2%.",1,AP,True
216,Note that thresholds can be altered arbitrarily within the shell script according to researchers' practical needs.,0,,False
217,Figures 3 and 4 provide similar screenshots of our scripts for comparing unpaired data.,0,,False
218,4 EXPERIMENTS,0,,False
219,"To encourage IR researchers to transition comfortably from the classical signi cance test paradigm to the Bayesian one for comparison of means, we now report on experiments that compare Bayesian results against classi cal test results using actual IR data. More speci cally, we compare the probability that System X is be er than System Y with p-values; credible intervals with classical con dence intervals, as well as e ect sizes computed based on both approaches. We show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect",1,ad,True
220,"11 h p://www.f.waseda.jp/tetsuya/tools.html 12 h ps://cran.r-project.org/ 13 h ps://cran.r-project.org/bin/windows/Rtools/ 14By typing the command without arguments, suggested sets of arguments are displayed.",0,,False
221,29,0,,False
222,Session 1A: Evaluation 1,1,Session,True
223,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
224,Table 1: IR data sets and evaluation measures used in this study,0,,False
225,Data set name NTCIR7IR4QA NTCIR9INTENT NTCIR12STC TREC03robust TREC11webD TREC15TS,1,INTENT,True
226,year track/task,0,,False
227,language measure,0,,False
228,tool,0,,False
229,#teams #runs #topics,0,,False
230,2008 IR for question answering [25],0,,False
231,Chinese Q-measure,0,,False
232,NTCIREVAL,0,,False
233,9 40 (20),0,,False
234,97,0,,False
235,2011 INTENT [28] (web diversity task),1,INTENT,True
236,Chinese D -nDCG@10 NTCIREVAL,0,,False
237,7 24 (20),0,,False
238,100,0,,False
239,2016 short text conversation [26] (tweet retrieval) Chinese nERR@10,0,,False
240,NTCIREVAL,0,,False
241,16 44 (20),0,,False
242,100,0,,False
243,2003 robust track [32],0,,False
244,English nDCG@1000 NTCIREVAL,0,,False
245,16 78 (20),0,,False
246,50,0,,False
247,2011 web track diversity task [7],0,,False
248,English  -nDCG@10 ndeval,0,,False
249,9 25 (20),0,,False
250,50,0,,False
251,"2015 temporal summarisation track, task 2 [1]",0,,False
252,English H,0,,False
253,-,0,,False
254,9 22 (20),0,,False
255,21,0,,False
256,Figure 1: A sample R script for comparing paired data.,0,,False
257,Figure 3: A sample R script for comparing unpaired data.,0,,False
258,"Figure 2: A shell script for obtaining the EAP, credible intervals, and the probability that the hypothesis is correct (paired data) for the absolute di erence, Glass's , and correlation coe cient (paired data).",1,AP,True
259,"sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes.",1,AP,True
260,"Table 1 provides a brief summary of the six data sets we used for our experiments. To strengthen the generalisability of our experimental results, we tried to cover diverse IR tasks from both TREC and NTCIR. For each data set (i.e., test collection with its submi ed runs), we chose one particular commonly-used evaluation measure: with the exception of TREC03robust15, we chose from one of the",1,TREC,True
261,15 We chose nDCG rather than Average Precision (AP) for TREC03robust as AP cannot handle graded relevance even though the data set comes with graded relevance assessments.,1,AP,True
262,"Figure 4: A shell script for obtaining the EAP, credible intervals, and the probability that the hypothesis is correct (paired data) for the absolute di erence, and Glass's  (unpaired data).",1,AP,True
263,"o cial measures of that track/task. Also, for each data set, we considered only the top 20 runs for pairwise comparisons as measured by that particular evaluation measure, which gives us 190 run pairs. For TREC11webD, -nDCG was computed using their o cial evaluation script ndeval16; For TREC15TS, the values of H (which is basically like a nugget-based F-measure de ned over a timeline [1]) were obtained from the o cial results of the track; other evaluation measures were computed using NTCIREVAL17, with the exponential gain value se ing (See, for example, [26]).",1,TREC,True
264,"For each data set, we conducted Bayesian and classical tests for every system pair (where System 1 outperforms System 2 for the sample data), using both paired and unpaired tests. For classical paired and unpaired tests, common sample e ect sizes were obtained by substituting sample means and System 2's sample standard deviations into Eq. 9. For Bayesian paired and unpaired tests, the EAP values of µ1, µ2, 2 were used with Eq. 9, under the two models described in Section 3.5, respectively.",1,AP,True
265,16 h p://trec.nist.gov/data/web/11/ndeval.c 17 h p://research.nii.ac.jp/ntcir/tools/ntcireval-en.html,1,trec,True
266,30,0,,False
267,Session 1A: Evaluation 1,1,Session,True
268,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
269,Figure 5: Paired Bayesian vs classical tests: comparisons with NTCIR data.,0,,False
270,4.1 Paired Test Results,0,,False
271,"Here we compare the paired Bayesian test (based on NUTS) with the classical paired t-test. We compare: (I) the paired Bayesian P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) with the classical one-sided paired p-value (See Section 3.4); (II) the paired 95% credible interval with the classical paired 95% con dence interval; (III) the paired Bayesian EAP Glass2 with the classical Glass2 based on sample statistics. e margin of error for the classical paired 95% con dence interval is given by t(n - 1; 0.05) V /n, where n is the sample size, V is the sample variance of the score di erences, and t(; ) is the two-sided critical t value18.",1,AP,True
272,"Figure 5 visualises the results of comparing the Bayesian and classical paradigms for paired data with NTCIR7IR4QA (graphs (A)(D)), NTCIR9INTENT (graphs (E)-(H)), and NTCIR12STC (graphs (I)(L)). Graphs (A), (E) and (I) (i.e., the le most column) compare the Bayesian P(S1 < S2|D) with the p-value; graphs (B), (F), and (J) compare the Bayesian EAP Glass2 with the sample Glass2; graphs (C), (G) and (K) compare the Bayesian credible interval lower limit with the con dence interval lower limit; and graphs (D), (H) and",1,ad,True
273,"18 T.INV.2T(P,  ) with Microso Excel.",0,,False
274,"(L) (i.e., the rightmost column) compare the Bayesian credible interval upper limit with the con dence interval upper limit. Figure 6 provides similar information for TREC03robust, TREC11webD, and TREC15TS.",1,TREC,True
275,"With the exception of Figure 6(J), i.e., the e ect size results for TREC15TS which we shall discuss in Section 4.3, the results in Figures 5 and 6 are highly consistent across the diverse NTCIR and TREC data sets and the messages are clear:",1,TREC,True
276,"(1) Graphs (A), (E), and (I) in Figures 5 and 6 show that the Bayesian P(S1 < S2|D) and the classical p-values are very highly correlated, echoing an earlier observation by Cartere e [5] (See Section 2.3). us, while P(S1 < S2|D) is what we usually want, it appears that the one-sided pvalue, which represents P(D+|S1 ,"" S2), can be considered as a reasonable approximation of P(S1 < S2|D).""",0,,False
277,"(2) Graphs (C), (D), (G), (H), (K), (L) in Figures 5 and 6 show that the Bayesian 95% credible intervals and the classical 95% con dence intervals are also very similar, despite the fundamental di erences in what they represent. us, the con dence interval can be considered as an approximation to the credible interval, which is what we really want.",0,,False
278,31,0,,False
279,Session 1A: Evaluation 1,1,Session,True
280,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
281,Figure 6: Paired Bayesian vs classical tests: comparisons with TREC data.,1,TREC,True
282,"(3) Graphs (B) and (F) in Figures 5 and 6 suggest that, while the Bayesian EAP e ect sizes generally align with the sample e ect sizes (Glass2), if the sample e ect size is small (e.g., less than 0.2), that may be an underestimation of the population e ect size. For example, Figure 6(B) indicates an instance (with a baloon) where the sample e ect size is 0.070 even though the Bayesian EAP e ect size, which we believe to be more accurate, is 0.113.",1,AP,True
283,"Observations (1) and (2) suggest that, even though the IR community may have relied on p-values and con dence intervals for decades, sometimes with incorrect interpretations, switching to Bayesian approaches would not turn all the experimental results in the literature upside down. As for Observation 3, even though we lack the ground truth for population e ect sizes, we would like to repeat Kruschke's argument [14]: ""the relevant question is asking which method provides the richest, most informative, and meaningful results for any set of data [. . .]"" (See Section 2.1).",1,ad,True
284,4.2 Unpaired Test Results,0,,False
285,Here we compare the unpaired Bayesian test (based on NUTS) with the classical Welch's t-test. We compare: (I) the unpaired Bayesian,0,,False
286,"P(S1 < S2|D) (i.e., the probability of the less likely hypothesis)",0,,False
287,with the classical one-sided unpaired p-value (See Section 3.4);,0,,False
288,(II) the unpaired 95% credible interval with the classical unpaired,0,,False
289,95% con dence interval; (III) the unpaired Bayesian EAP Glass2,1,AP,True
290,with the classical Glass2 based on sample statistics. e margin of,0,,False
291,"error for the classical unpaired 95% con dence interval is given by t(; 0.05) V1/n1 + V2/n2, where n1, n2 are the sample sizes, V1, V2 are the sample variances, and the approximated degrees of freedom  is given by [24]:",0,,False
292,",",0,,False
293,( V1 n1,0,,False
294,+,0,,False
295,V2 )2/{ (V1/n1)2,0,,False
296,n2,0,,False
297,n1 - 1,0,,False
298,+,0,,False
299,(V2/n2)2 } n2 - 1,0,,False
300,.,0,,False
301,(10),0,,False
302,"In fact, since our unpaired test experiments merely regard the paired data from NTCIR and TREC (i.e., two systems evaluated with a common topic set) as unpaired data, n1 , n2 holds in our case.",1,TREC,True
303,"Figure 7 visualises the results of comparing the Bayesian and classical paradigms for unpaired TREC data, similarly to Figure 6.",1,ad,True
304,"e unpaired results with the NTCIR data, which look very much like the corresponding paired test results with the NTCIR data shown in Figure 5, are omi ed in this paper due to lack of space.",0,,False
305,32,0,,False
306,Session 1A: Evaluation 1,1,Session,True
307,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
308,Figure 7: Unpaired Bayesian vs classical tests: comparisons with TREC data.,1,TREC,True
309,"Note that the classical sample e ect sizes used in Graphs (B), (F), and (J) are the same as the ones used in Figure 6. For example, we have observed from Figure 6(B) that while the sample e ect size for a system pair was 0.070, the Bayesian paired model gives us an EAP Glass2 of 0.113; in contrast, Figure 7(B) indicates that the Bayesian unpaired model gives us an EAP Glass2 of 0.161 for the same system pair.",1,AP,True
310,"It is clear that Observations 1-3 listed up in Section 4.1 also hold for the unpaired tests as well, which further strengthens our",0,,False
311,"ndings. However, just like Figure 6(J), Figure 7(J) shows and anomalous result for TREC15TS: we therefore discuss these results separately in the next section.",1,TREC,True
312,4.3 On the Anomalous Behaviour of H,0,,False
313,"e nugget-based H measure, the primary measure from the TREC 2015 Temporal Summarisation track, demonstrates a strange behaviour in Figure 6(J) and Figure 7(J), where the Bayesian EAP e ect sizes and sample e ect sizes are compared. e graphs look quite di erent from Graphs (B) and (F) of Figures 5-7. More specifically, for a small set of system pairs, EAP values are larger than sample e ect sizes; for a few others, sample e ect sizes are larger",1,TREC,True
314,"than EAPs. For example, for a system pair whose sample e ect size is 11.39, the paired Bayesian EAP is 12.10 (Figure 6(J)), while the unpaired Bayesian EAP is 12.37 (Figure 7(J)), as indicated by baloons. Similarly, for a system pair whose sample e ect size is 16.19, the paired Bayesian EAP is 12.55, while the unpaired Bayesian EAP is 12.76. is is in contrast to the aforementioned Obsevation 3 (Section 4.1) for the other data sets.",1,AP,True
315,"While the other evaluation measures used in our experiments have been studied quite extensively (e.g., [6, 20, 21]), we are not aware of any work in the literature that validated H in a similar way, and we believe that an investigation is in order. For example, while the actual nDCG scores from our TREC03robust data range between 0 and 0.9816 (i.e., almost fully covering the theoretical range of [0, 1]), the actual H scores from TREC15TS range between 0 and 0.4021: that is, the actual range width is about 0.4 rather than 1. Moreover, the standard deviations of H for each system are very low compared to the other measures, causing very large e ect sizes (See Eq. 9): hence, note that the axis scales of Figure 6(J) and 7(J) are very di erent from the other e ect size graphs. While studying the properties of a new measure is not the focus of this",1,TREC,True
316,33,0,,False
317,Session 1A: Evaluation 1,1,Session,True
318,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
319,"study, these anomalous results with H may deserve a ention from other researchers such as the TREC track coordinators.",1,TREC,True
320,5 CONCLUSIONS AND FUTURE WORK,0,,False
321,"Using diverse data sets from TREC and NTCIR, we compared, under both paired and unpaired data se ings, (I) the Bayesian P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) with the classical one-sided p-value; (II) the 95% credible interval with the classical 95% con dence interval; (III) the Bayesian EAP Glass2 with the classical Glass2 based on sample statistics. Our results showed that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. Fortunately, our results suggest that Bayesian statistics will not turn all experimental results in the IR literature upside down; however, we hope that these results, as well as our tools, will help IR researchers to take up Bayesian hypothesis testing approaches. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for Glass's .",1,TREC,True
322,"e present study focussed on the problem of comparing two systems, and did not address the multiple comparison and familywise error rate problems [11]. If a researcher is interested in the p-value of every system pair, one e ective way to obtain them would be to employ the randomised Tukey HSD test [4, 22], which is completely distribution-free. In future work, we would like to explore Bayesian alternatives to this test and validate them.",1,ad,True
323,ACKNOWLEDGEMENTS,0,,False
324,"We thank Professor Hideki Toyoda (Waseda University) for le ing us modify his R code and distribute it, and Dr. Ma hew EkstrandAbueg (Google) for providing the TREC temporal summarisation track results.",1,TREC,True
325,REFERENCES,0,,False
326,"[1] Javed Aslam, Fernando Diaz, Ma hew Ekstrand-Abueg, Richard McCreadie, Virgil Pavlu, and Tetsuya Sakai. 2016. TREC 2015 Temporal Summarization Track. In Proceedings of TREC 2015.",1,ad,True
327,"[2] omas Bayes. 1763. An Essay towards Solving a Problem in the Doctrine of Chances. Philosophical Transactions of the Royal Society of London 53 (1763), 370­418.",0,,False
328,[3] Ben Cartere e. 2011. Model-Based Inference About IR Systems. In Proceedings of ICTIR 2011 (LNCS 6931). 101­112.,0,,False
329,"[4] Ben Cartere e. 2012. Multiple testing in statistical analysis of systems-based information retrieval experiments. ACM TOIS 30, 1 (2012).",0,,False
330,[5] Ben Cartere e. 2015. Bayesian Inference for Information Retrieval Evaluation. In Proceedings of ACM ICTIR 2015. 31­40.,0,,False
331,"[6] Charles L.A. Clarke, Nick Craswell, Ian Soboro , and Azin Ashkan. 2011. A Comparative Analysis of Cascade Measures for Novelty and Diversity. In Proceedings",1,ad,True
332,"of ACM WSDM 2011. 75­84. [7] Clarles L. A. Clarke, Nick Craswell, Ian Soboro , and Ellen M. Voorhees. 2012.",0,,False
333,"Overview of the TREC 2011 Web Track. In Proceedings of TREC 2011. [8] Bradley Efron. 2005. Bayesians, Frequentists, and Scientists. J. Amer. Statist.",1,TREC,True
334,"Assoc. 100, 469 (2005), 1­5. [9] Ronald A. Fisher. 1970. Statistical Methods for Research Workers (14th Edition).",0,,False
335,Oliver & Boyd. [10] Andrew Gelman. 1996. Inference and Monitoring Convergence. In Markov Chan,0,,False
336,"Monte Carlo in Practice, W. R. Gilks, S. Richardson, and D. J. Spiegelhalter (Eds.). Chapman & Hall/CRC, Chapter 8. [11] Andrew Gelman, Jennifer Hill, and Masanao Yajima. 2008. Why We (Usually) Don't Have to Worry about Multiple Comparisons. Technical Report. [12] Lisa L. Harlow, Stanley A. Mulaik, and James H. Steiger (Eds.). 2016. What If",0,,False
337,ere Were No Signi cance Tests (Classic Edition). Routledge. [13] Ma hew D. Ho man and Andrew Gelman. 2014. e No-U-Turn Sampler:,0,,False
338,"Adaptively Se ing Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research 15 (2014), 1351­1381. [14] John K. Kruschke. 2013. Bayesian Estimation Supersedes the t test. Journal of Experimental Psychology: General 142, 2 (2013), 573­603. [15] John K. Kruschke. 2015. Doing Bayesian Data Analysis (Second Edition). Elsevier. [16] Yasushi Nagata. 1996. How to Understand Statistical Methods (in Japanese). Nikkagiren. [17] Radford M. Neal. 2011. MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo, Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng (Eds.). 113­162. [18] Yurii Nesterov. 2009. Primal-Dual Subgradient Methods for Convex Problems. Mathematical Programming 120 (2009), 221­259. [19] Matia Okubo and Kensuke Okada. 2012. Psychological Statistics to Tell Your Story: E ect Size, Con dence Interval, and Power. Keiso Shobo. [20] Tetsuya Sakai. 2006. Evaluating Evaluation Metrics based on the Bootstrap. In Proceedings of ACM SIGIR 2006. 525­532. [21] Tetsuya Sakai. 2011. Evaluating Diversi ed Search Results Using Per-Intent Graded Relevance. In Proceedings of ACM SIGIR 2011. 1043­1052. [22] Tetsuya Sakai. 2014. Statistical Reform in Information Retrieval? SIGIR Forum 48, 1 (2014), 3­12. [23] Tetsuya Sakai. 2016. Statistical Signi cance, Power, and Sample Sizes: A Systematic Review of SIGIR and TOIS, 2006-2015. Proceedings of ACM SIGIR 2016 (2016), 5­14. [24] Tetsuya Sakai. 2016. Two Sample T-tests for IR Evaluation: Student or Welch?. In Proceedings of ACM SIGIR 2016. 1045­1048. [25] Tetsuya Sakai, Noriko Kando, Chuan-Jie Lin, Teruko Mitamura, Hideki Shima, Donghong Ji, Kuang-Hua Chen, and Eric Nyberg. 2008. Overview of the NTCIR-7 ACLIA IR4QA Task. In Proceedings of NTCIR-7. 77­114. [26] Lifeng Shang, Tetsuya Sakai, Zhengdong Lu, Hang Li, Ryuichiro Higashinaka, and Yusuke Miyao. 2016. Overview of the NTCIR-12 Short Text Conversation Task. In Proceedings of NTCIR-12. 473­484. [27] Mark D. Smucker, James Allan, and Ben Cartere e. 2007. A Comparison of Statistical Signi cance Tests for Information Retrieval Evaluation. In Proceedings of ACM CIKM 2007. 623­632. [28] Ruihua Song, Min Zhang, Tetsuya Sakai, Makoto P. Kato, Yiqun Liu, Miho Sugimoto, Qinglei Wang, and Naoki Orii. 2011. Overview of the NTCIR-9 INTENT Task. In Proceedings of NTCIR-9. 82­105. [29] Student. 1908. e Probable Error of a Mean. Biometrika 6, 1 (1908), 1­25. [30] Hideki Toyoda (Ed.). 2015. Fundamentals of Bayesian statistics: Practical Ge ing Started by Hamiltonian Monte Carlo Method (in Japanese). Asakura Shoten. [31] Hideki Toyoda. 2016. An Introduction to Statistical Data Analysis: Bayesian Statistics for `post p-value era' (in Japanese). Asakuha Shoten. [32] Ellen M. Voorhees. 2004. Overview of the TREC 2003 Robust Retrieval Track. In Proceedings of TREC 2003. [33] Ronald L. Wasserstein and Nicole A. Lazar. 2016. e ASA's Statement on P-values: Context, Process, and Purpose. e American Statistician (2016). [34] Dell Zhang, Jun Wang, Emine Yilmaz, Xiaoling Wang, and Yuxin Zhou. 2016. Bayesian Performance Comparison of Text Classi ers. In Proceedings of ACM SIGIR 2016. 15­24. [35] Stephen T. Ziliak and Deirdre N. McCloskey. 2008. e Cult of Statistical Signi cance: How the Standard Error Costs Us Jobs, Justice, and Lives. e University of Michigan Press.",1,ad,True
339,34,0,,False
340,,0,,False
