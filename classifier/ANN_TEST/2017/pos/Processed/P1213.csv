,sentence,label,data,regex
0,Short Research Paper,0,,False
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
2,Embedding-based ery Expansion for Weighted Sequential Dependence Retrieval Model,0,,False
3,Saeid Balaneshin-kordan,0,,False
4,Wayne State University saeid@wayne.edu,0,,False
5,ABSTRACT,0,,False
6,"Although information retrieval models based on Markov Random Fields (MRF), such as Sequential Dependence Model and Weighted Sequential Dependence Model (WSDM), have been shown to outperform bag-of-words probabilistic and language modeling retrieval models by taking into account term dependencies, it is not known how to e ectively account for term dependencies in query expansion methods based on pseudo-relevance feedback (PRF) for retrieval models of this type. In this paper, we propose Semantic Weighted Dependence Model (SWDM), a PRF based query expansion method for WSDM, which utilizes distributed low-dimensional word representations (i.e., word embeddings). Our method nds the closest unigrams to each query term in the embedding space and top retrieved documents and directly incorporates them into the retrieval function of WSDM. Experiments on TREC datasets indicate statistically signi cant improvement of SWDM over stateof-the-art MRF retrieval models, PRF methods for MRF retrieval models and embedding based query expansion methods for bagof-words retrieval models.",1,corpora,True
7,CCS CONCEPTS,0,,False
8,·Information systems  ery reformulation;,0,,False
9,KEYWORDS,0,,False
10,Weighted Sequential Dependence Model; Term Dependencies; Word Embeddings; ery Expansion; Pseudo-Relevance Feedback,0,,False
11,1 INTRODUCTION,1,DUC,True
12,"Designing retrieval models and addressing the problem of vocabulary mismatch via query and document expansion have traditionally been two orthogonal directions of information retrieval (IR) research. In particular, separate methods for query [4] or document [3] expansion are typically employed in conjunction with bag-of-words probabilistic, such as BM25 [15], and language modeling based, such as ery Likelihood [14], retrieval models. ese methods typically identify query expansion terms in the collection itself using statistical measures of semantic similarity between pairs of terms pre-computed in advance [2, 9], top-retrieved documents [11], external resources [10] or their combination [1].",1,ad,True
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR 17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978­1­4503­5022­8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080764",1,ad,True
14,Alexander Kotov,0,,False
15,Wayne State University kotov@wayne.edu,0,,False
16,"Markov Random Fields (MRF) retrieval models [12], such as Sequential Dependence Model (SDM) and Weighted Sequential Dependence Model (WSDM), consider retrieval function as a graph of dependencies between the query terms and a document and calculate document retrieval score as a linear combination of the potential functions de ned on the cliques in this graph. Although these retrieval models have been shown to outperform probabilistic and language modeling retrieval models by going beyond bagof-words assumption and taking into account term dependencies, it is not known how to e ectively incorporate term dependencies into query expansion methods based on pseudo-relevance feedback (PRF) for this type of retrieval models. Due to sparsity of n-grams, accounting for term dependencies in query expansion based only on term co-occurrence statistics within the collection itself is quite challenging. For this reason, only unigrams have been utilized for query expansion in Latent Concept Expansion (LCE) [13] and Parameterized ery Expansion (PQE) [6], state-ofthe-art PRF methods for SDM and WSDM, respectively.",1,corpora,True
17,"Word embeddings are distributed low-dimensional vector representations, which have been successfully utilized in di erent IR contexts, such as estimation of translation models [3, 21] and query expansion for bag-of-words retrieval models [19], as well as in retrieval models based on neural architectures [7, 16] and proximity search [8]. Since n-grams typically appear in a limited number of contexts in a collection, the utility of n-gram embeddings for IR is limited. For example, based on the word embeddings trained on a Google News corpus with 100 billion words1, the most semantically similar words to ""human"" are ""humankind"", ""mankind"" and ""humanity"", all of which can be good query expansion terms.",0,,False
18,"e most semantically similar n-grams to ""human"", however, are ""human beings"", ""impertinent amboyant endearingly"", ""employee Laura Althouse"", and ""Christine Gaugler head""2. It is obvious that these n-grams would only cause topic dri and degrade the retrieval results, if used for query expansion. Furthermore, due to sparsity, bigram embeddings are also ine ective for computing their importance weight in SDM [20].",1,ad,True
19,"Our proposed model, Semantic Weighted Dependence Model (SWDM), mitigates the potential vocabulary mismatch between queries and documents in WSDM via query expansion. Similar to SDM and WSDM, the retrieval score of a document, according to SWDM, depends on the matching query unigrams, ordered and unordered bigrams. However, unlike SDM, SWDM nds the closest unigrams and bigrams to query terms in embedding space and directly incorporates them into the retrieval function of WSDM.",1,corpora,True
20,"1h ps://drive.google.com/ le/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/ 2 e similarity of trigrams ""employee Laura Althouse"" and ""Christine Gaugler head"" was deduced from the fragments "". . . said Christine Gaugler, head of human resources . . . "" and "". . . and human resources employee Laura Althouse . . . "", which appear in multiple places within this corpus.",1,ad,True
21,1213,0,,False
22,Short Research Paper,0,,False
23,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
24,"To overcome the n-gram sparsity problem, SWDM takes into account only the dependencies between those pairs of terms, in which at least one term is semantically similar to one of the query terms and both terms have appeared within multiple windows in the collection and top retrieved documents. For example, for the query ""human smuggling"", SWDM identi es ""tra cking"" as one of the expansion unigrams and ""human tra cking"" as one of the expansion bigrams, since the unigram ""tra cking"" is semantically similar to ""smuggling"". Proximity to query terms in the embedding space as well as their frequency in the collection and top-retrieved documents are used as features for weighting the importance of original and expansion concepts (unigrams or bigrams).",0,,False
25,2 RELATED WORK,0,,False
26,"Word embeddings are typically utilized in retrieval models to calculate distributional similarity between terms, quantify relevance of documents to queries or as an input to neural architectures for relevance matching.",0,,False
27,"Calculation of distributional similarity: cosine similarity between word embeddings is used in two scenarios. In the rst scenario, distributional similarity between word vectors is used to",0,,False
28,"nd semantically similar words to expand queries [19] or documents [3, 21]. Components of a di erence vector between embeddings of query unigrams and embeddings of the entire query have been utilized as features to estimate the weights of query unigrams in SDM [20]. Relevance of documents to queries can be quanti ed by aggregating cosine similarity scores between pairs of the most similar query and document term embedding vectors [8]. An alternative approach to quantifying relevance of documents to queries involves aggregating the embeddings of all document and query words into a single embedding vector for the entire document and a single embedding vector for the entire query and calculating their relevance score as a cosine similarity between these vectors [17].",0,,False
29,"e proposed method also falls into this category, since it relies on cosine similarity between word embeddings to nd the most semantically similar unigrams to query terms and uses these unigrams for query expansion.",0,,False
30,"Input to neural architectures: distributed representations of query and document terms have also been used as input to neural architectures based on Convolutional Neural Network [16] or Recurrent Neural Network [18], which directly calculate the relevance score of documents to queries. In [7], a histogram of cosine similarities between embeddings of a query and documents terms is used an input to a feed-forward neural network with term gating, which directly computes the relevance score.",0,,False
31,3 METHOD,0,,False
32,Retrieval function of SDM calculates the relevance score of document D to query Q as follows:,0,,False
33,P,0,,False
34,(D,0,,False
35,|Q,0,,False
36,),0,,False
37,r,0,,False
38,ank,0,,False
39,",",0,,False
40,"T fT (qi , D) +",0,,False
41,"B fB (qiqi+1, D)+",0,,False
42,qi Q,0,,False
43,"qi ,qi+1 Q",0,,False
44,"U fU (qiqi+1, D)",0,,False
45,(1),0,,False
46,"qi ,qi+1 Q",0,,False
47,"where qi is a query unigram and qiqi+1 is a query bigram, and fT (qi , D), fB (qiqi+1, D) and fU (qiqi+1, D) are the potential (i.e.,",0,,False
48,"Figure 1: Graphical representation of SWDM. q1, q2 and q3 are the query terms and D is a collection document. e words in dashed circles are the nearest neighbors of the query terms in the embedding space (only two most semantically similar words to each query term are shown for illustration).",0,,False
49,"matching) functions for query concept types (unigrams, ordered",0,,False
50,"and unordered bigrams), respectively, and T , B and U are the weights of these potential functions, which determine the relative",0,,False
51,"importance of query concept types. e potential function fT (qi , D) for unigrams is de ned as:",0,,False
52,fT,0,,False
53,"(qi ,",0,,False
54,D),0,,False
55,",",0,,False
56,n(qi,0,,False
57,",",0,,False
58,D),0,,False
59,+,0,,False
60,µ,0,,False
61,"n (qi , C |C |",0,,False
62,),0,,False
63,|D| + µ,0,,False
64,(2),0,,False
65,"where n(qi , D) and n(qi , C) are the counts of unigram qi in D and collection C, |D| and |C | are the numbers of words in document and",0,,False
66,"collection, and µ is the Dirichlet smoothing prior. fB (qiqi+1, D) and fU (qiqi+1, D) are obtained in a similar way by counting cooccurrences of qi and qi+1 in D and C in sequential order or within a window of a given size.",0,,False
67,WSDM provides a more exible parametrization of relevance,0,,False
68,than SDM by calculating the importance weight of each individual,0,,False
69,query concept rather than a concept type. e importance weight,0,,False
70,of each unigram and bigram is calculated as a linear combination,0,,False
71,of ku unigram feature functions,0,,False
72,u j,0,,False
73,(qi,0,,False
74,),0,,False
75,and,0,,False
76,kb,0,,False
77,bigram,0,,False
78,feature,0,,False
79,func-,0,,False
80,tions,0,,False
81,b j,0,,False
82,(qi,0,,False
83,",",0,,False
84,qi,0,,False
85,+1,0,,False
86,),0,,False
87,as,0,,False
88,follows:,0,,False
89,P,0,,False
90,(D,0,,False
91,|Q,0,,False
92,),0,,False
93,r,0,,False
94,ank,0,,False
95,",",0,,False
96,ku,0,,False
97,wuj,0,,False
98,u j,0,,False
99,(qi,0,,False
100,),0,,False
101,fT,0,,False
102,(qi,0,,False
103,",",0,,False
104,D,0,,False
105,)+,0,,False
106,"qi Q j,1",0,,False
107,kb,0,,False
108,w,0,,False
109,b j,0,,False
110,b j,0,,False
111,(qi,0,,False
112,",",0,,False
113,qi,0,,False
114,+1),0,,False
115,fB,0,,False
116,(qi,0,,False
117,qi,0,,False
118,"+1,",0,,False
119,D,0,,False
120,)+,0,,False
121,"qi ,qi+1 Q j,1",0,,False
122,kb,0,,False
123,w,0,,False
124,b j,0,,False
125,b j,0,,False
126,(qi,0,,False
127,",",0,,False
128,qi,0,,False
129,+1),0,,False
130,fU,0,,False
131,(qi,0,,False
132,qi +1,0,,False
133,",",0,,False
134,D),0,,False
135,(3),0,,False
136,"qi ,qi+1 Q j,1",0,,False
137,3.1 Semantic Weighted Dependence Model,0,,False
138,"In SWDM, the relevance score of D to Q also takes into account the words that are semantically similar to query terms in the embedding space. We de ne qij as the jth most similar term to qi in the embedding space, according to cosine similarity. We also de ne Eqi ,"" {qi0, qi1, qi2, · · · } as a set of words, whose cosine similarity with qi in the embedding space exceeds a threshold s (including qi0 "","" qi itself). Unlike SDM and WSDM, the potential functions""",0,,False
139,1214,0,,False
140,Short Research Paper,0,,False
141,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
142,"Table 1: Performance of the proposed method with and without unigrams from the top retrieved documents and the baselines. 1 and 2 indicate statistically signi cant improvements of SWDM over WSDM and EQE1, respectively, while 3, 4 and 5 indicate statistically signi cant improvements of SWDM+ over EQE1+RM1, PQE, and SWDM+RM1, respectively, according to the Fisher's randomization test (p < 0.05). Percentage improvements of SWDM over WSDM and EQE1 as well as percentage improvements of SWDM+ over PQE and SWM+RM1 are shown in parenthesis.",0,,False
143,Method,0,,False
144,SDM WSDM EQE1,0,,False
145,SWDM,0,,False
146,LCE PQE EQE1+RM1 SWDM+RM1,0,,False
147,SWDM+,0,,False
148,ROBUST04,0,,False
149,MAP,1,MAP,True
150,P@10,0,,False
151,0.2583,0,,False
152,0.4278,0,,False
153,0.2689,0,,False
154,0.4563,0,,False
155,"0.2597 0.28021, 2",0,,False
156,"0.4336 0.46761, 2",0,,False
157,(+4.20%/+7.89%) (+2.48%/+7.84%),0,,False
158,0.2886,0,,False
159,0.4697,0,,False
160,0.2921,0,,False
161,0.4726,0,,False
162,0.2872,0,,False
163,0.4672,0,,False
164,"0.2991 0.30343, 4, 5",0,,False
165,"0.4828 0.49093, 4, 5",0,,False
166,(+3.87%/+1.44%) (+3.87%/+1.68%),0,,False
167,GOV2,0,,False
168,MAP,1,MAP,True
169,P@10,0,,False
170,0.3156,0,,False
171,0.5457,0,,False
172,0.3232,0,,False
173,0.5533,0,,False
174,"0.3172 0.33191, 2",0,,False
175,"0.5466 0.55981, 2",0,,False
176,(+2.69%/+4.63%) (+1.17%/+2.41%),0,,False
177,0.3408,0,,False
178,0.5667,0,,False
179,0.3526,0,,False
180,0.5858,0,,False
181,0.3315,0,,False
182,0.5459,0,,False
183,"0.3557 0.36863, 4",0,,False
184,"0.5872 0.59973, 4",0,,False
185,(+4.54%/+3.63%) (+2.37%/+2.13%),0,,False
186,ClueWeb09B,1,ClueWeb,True
187,MAP,1,MAP,True
188,P@10,0,,False
189,0.0783,0,,False
190,0.2777,0,,False
191,0.0762,0,,False
192,0.2797,0,,False
193,"0.0742 0.08271, 2",0,,False
194,"0.2778 0.28121, 2",0,,False
195,(+8.53%/+11.46%) (+0.54%/+1.22%),0,,False
196,0.0738,0,,False
197,0.2693,0,,False
198,0.0749,0,,False
199,0.2751,0,,False
200,0.0731,0,,False
201,0.2695,0,,False
202,0.0756,0,,False
203,0.2716,0,,False
204,0.0787,0,,False
205,0.2778,0,,False
206,(+5.07%/+4.10%) (+0.98%/+2.28%),0,,False
207,"fT (qi , D), fB (qiqi+1, D) and fU (qiqi+1, D) in SWDM are calculated using all the terms in E and not just the query terms:",0,,False
208,ku,0,,False
209,P (D |Q ),0,,False
210,r ank,0,,False
211,",",0,,False
212,w,0,,False
213,u j,0,,False
214,u j,0,,False
215,(qmi,0,,False
216,),0,,False
217,fT,0,,False
218,(qmi,0,,False
219,",",0,,False
220,D)+,0,,False
221,"qim  Eqi j,1",0,,False
222,kb,0,,False
223,w,0,,False
224,b j,0,,False
225,b j,0,,False
226,(qmi,0,,False
227,",",0,,False
228,qmi +1 ),0,,False
229,fB,0,,False
230,"(qmi qmi+1,",0,,False
231,D,0,,False
232,)+,0,,False
233,"qim,qim+1  Eqi , Eqi+1 j ,1",0,,False
234,kb,0,,False
235,w,0,,False
236,b j,0,,False
237,b j,0,,False
238,(qmi,0,,False
239,",",0,,False
240,qmi +1 ),0,,False
241,fU,0,,False
242,"(qmi qmi+1,",0,,False
243,D,0,,False
244,),0,,False
245,"qim,qim+1  Eqi , Eqi+1 j ,1",0,,False
246,(4),0,,False
247,"erefore, besides pair-wise dependencies between adjacent query",1,ad,True
248,"terms, SWDM also captures pair-wise dependencies between query",0,,False
249,terms and the words semantically similar to them in the embed-,0,,False
250,"ding space. For an example query in Figure 1, besides the query",0,,False
251,"unigram q1, retrieval score of D, according to SWDM, also includes the weighted matching scores for unigrams q11 and q12 that are semantically similar to q1. Similarly, besides the query bigram q1q2, SWDM also includes the weighted matching scores for: (1) the bigrams q1q21, q1q22, q11q2, and q12q2, which have only one of their constituent terms not from the original query (2) the bigrams q11q21, q11q22, q12q21, and q12q22, in which both constituent terms are not from the original query. If Eqi , {qi0} ,"" {qi } (i.e., in the case when no semantically similar unigrams are in the neighborhood of orig-""",0,,False
252,"inal query terms), SWDM only takes into account the unigrams and",0,,False
253,bigrams in the original query (i.e. is identical to WSDM).,0,,False
254,"e importance weight of each query concept is computed based on several features. For an expansion unigram qij , we use its cosine similarity with qi , frequency in the collection and top retrieved documents, document frequency in the collection and top documents as features. For an expansion bigram qijqij+1, we use an average cosine similarity of the terms qij and qij+1, sequential and window based co-occurrence frequency in the collection and top",0,,False
255,"Figure 2: Graphical representation of SWDM+, a variant of SWDM, which besides the neighbors of the query terms in the embedding space (q11, . . . , q32), also incorporates the unigrams from the top retrieved documents ranked by RM1 [11] (q^11, . . . , q31).",1,corpora,True
256,documents as well as sequential and window based document frequency in the collection and top documents.,0,,False
257,4 EXPERIMENTS,0,,False
258,"Experimental results reported below were obtained using word2vec word embeddings with 300 dimensions that were pre-trained on the Google News corpus3, Indri-5.10 IR toolkit4 and GenSim library5 for all word embedding computations.",0,,False
259,"Retrieval accuracy of SWDM was evaluated with respect to Mean Average Precision (MAP) and Precision@10 (P@10) on ROBUST04, GOV2 and ClueWeb09B (excluding the documents for which Waterloo Fusion spam score was greater than 70) collections and compared with the state-of-the-art MRF retrieval models (SDM [12] and WSDM [5]), PRF methods for MRF retrieval models (LCE [13] and",1,MAP,True
260,3h ps://drive.google.com/ le/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/ 4h ps://www.lemurproject.org/indri/ 5h ps://radimrehurek.com/gensim/,1,ad,True
261,1215,0,,False
262,Short Research Paper,0,,False
263,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
264,PQE [6]) and embedding based query expansion method for bag-ofwords retrieval models (EEQ1 [19]). Collection and document frequencies were used as features to calculate the weights of query concepts in WSDM and PQE.,0,,False
265,"We also experimented with SWDM+, a variant of SWDM, which, besides the neighbors of query terms in the embedding space, also incorporates E^Q ,"" {q^1, q^2, . . . , q^k }, top k unigrams from the top retrieved documents according to the relevance model (RM1) [11] scores, as illustrated in Figure 2. SWDM+ uses the same set of features for weighting query concepts as SWDM. e similarity features to determine the importance of query concepts involving unigrams from top retrieved documents are calculated with respect to the closest query term in the embedding space. SWDM+RM1 and EEQ1+RM1 are a linear interpolation of RM1 with SWDM and EEQ1, respectively. Unigrams from the top retrieved documents in SWDM+RM1, EEQ1+RM1 and SWDM+ are ranked using RM1 and the top k are selected to be incorporated into the query.""",1,corpora,True
266,"e parameters of all models have been optimized using threefold cross-validation and coordinate ascent to maximize MAP. e range of continuous and discrete model parameters has been examined with the step sizes of 0.02 and 1, respectively.",1,MAP,True
267,4.1 Results,0,,False
268,"Table 1 provides a summary of retrieval accuracy for SWDM, its variants and the baselines6. As follows from the rst half of Table 1, SWDM outperforms SDM, WSDM and EQE1 in terms of both MAP and P@10, which indicates the utility of incorporating semantically related terms into WSDM. It also follows from Table 1 that the retrieval accuracy of EQE1 is close to that of SDM, which indicates that utilizing word embeddings for query expansion in conjunction with bag-of-words retrieval model results in similar improvements of retrieval accuracy as accounting for sequential dependencies between query terms. Our results also indicate that SWDM has be er retrieval accuracy than EQE1, since besides incorporating similar words from the embedding space into a query, it also takes into account the dependencies between the expansion terms as well as between the expansion terms and the query terms.",1,MAP,True
269,"e results in the second half of Table 1 indicate that incorporating unigrams from the top retrieved documents translates into a signi cant increase in retrieval accuracy of SWDM on ROBUST04 and GOV2 collections. In particular, SWDM+ outperforms both LCE and PQE, state-of-the-art PRF methods for MRF retrieval models, which include a separate potential function for expansion terms, but do not take into account neither dependencies between the expansion terms nor between the expansion terms and the original query terms, and EQE1+RM1, which is designed for bag-of-words retrieval models. SWDM+, however, has inferior performance to both SWDM and SWDM+RM1 on ClueWeb09B, which is due to relatively low accuracy of all retrieval models on this collection and, as a result, noisy unigrams from the top retrieved documents that are used for query expansion. is result suggests that the relative in uence of query term neighbors and the expansion terms from the top retrieved documents on retrieval accuracy depends on a collection and the quality of the initial retrieval results. SWDM+ also demonstrated a signi cantly statistical improvement in retrieval",1,corpora,True
270,6code and runs are available at h p://github.com/teanalab/SWDM,0,,False
271,"accuracy over SWDM+RM1 on ROBUST04 and GOV2 collections, in-",0,,False
272,dicating that the features based on similarity of expansion and the,0,,False
273,original query terms in the embedding space have a positive e ect,0,,False
274,on retrieval accuracy.,0,,False
275,5 CONCLUSION,0,,False
276,"In this paper, we proposed Semantic Weighted Dependence Model,",0,,False
277,which allows to address the vocabulary gap in Weighted Sequen-,1,ad,True
278,"tial Dependence Model, by leveraging distributed word represen-",0,,False
279,"tations (i.e. word embeddings) in two di erent ways. On one hand,",0,,False
280,word embeddings are used for calculating distributional similarity,0,,False
281,to nd the terms that are semantically similar to query terms for,0,,False
282,"query expansion. On the other hand, they are used as features",0,,False
283,to calculate the importance of query concepts. We also proposed,0,,False
284,"an extension of SWDM, which besides semantically similar terms,",0,,False
285,also incorporates the terms from the top retrieved documents.,1,corpora,True
286,REFERENCES,0,,False
287,[1] Saeid Balaneshin-kordan and Alexander Kotov. 2016. Optimization method for weighting explicit and latent concepts in clinical decision support queries. In Proceedings of ACM ICTIR. 241­250.,0,,False
288,[2] Saeid Balaneshin-kordan and Alexander Kotov. 2016. Sequential query expansion using concept graph. In Proceedings of ACM CIKM. 155­164.,0,,False
289,[3] Saeid Balaneshin-kordan and Alexander Kotov. 2016. A study of document expansion using translation models and dimensionality reduction methods. In Proceedings of ACM ICTIR. 233­236.,0,,False
290,[4] Saeid Balaneshinkordan and Alexander Kotov. 2016. An Empirical comparison of term association and knowledge graphs for query expansion. In Proceedings of ECIR. 761­767.,0,,False
291,"[5] Michael Bendersky, Donald Metzler, and W Bruce Cro . 2010. Learning concept importance using a weighted dependence model. In Proceedings of ACM WSDM. 31­40.",0,,False
292,"[6] Michael Bendersky, Donald Metzler, and W Bruce Cro . 2011. Parameterized concept weighting in verbose queries. In Proceedings of ACM SIGIR. 605­614.",0,,False
293,"[7] Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Cro . 2016. A Deep Relevance Matching Model for Ad-hoc Retrieval. In Proceedings of ACM CIKM. 55­ 64.",1,hoc,True
294,"[8] Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Cro . 2016. Semantic Matching by Non-Linear Word Transportation for Information Retrieval. In Proceedings of ACM CIKM. 701­710.",0,,False
295,[9] Alexander Kotov and ChengXiang Zhai. 2011. Interactive sense feedback for di cult queries. In Proceedings of ACM CIKM. 163­172.,0,,False
296,[10] Alexander Kotov and ChengXiang Zhai. 2012. Tapping into knowledge base for concept feedback: leveraging conceptnet to improve search results for di cult queries. In Proceedings of ACM WSDM. 403­412.,0,,False
297,[11] Victor Lavrenko and W Bruce Cro . 2001. Relevance based language models. In Proceedings of ACM SIGIR. 120­127.,0,,False
298,[12] Donald Metzler and W Bruce Cro . 2005. A Markov random eld model for term dependencies. In Proceedings of ACM SIGIR. 472­479.,0,,False
299,[13] Donald Metzler and W Bruce Cro . 2007. Latent concept expansion using markov random elds. In Proceedings of ACM SIGIR. 311­318.,0,,False
300,[14] Jay M Ponte and W Bruce Cro . 1998. A language modeling approach to information retrieval. In Proceedings of ACM SIGIR. 275­281.,0,,False
301,"[15] Stephen E Robertson, Steve Walker, Susan Jones, Micheline M HancockBeaulieu, Mike Gatford, and others. 1995. Okapi at TREC-3. NIST 109 (1995).",1,TREC,True
302,[16] Aliaksei Severyn and Alessandro Moschi i. 2015. Learning to rank short text pairs with convolutional deep neural networks. In Proceedings of ACM SIGIR. 373­382.,0,,False
303,[17] Ivan Vulic´ and Marie-Francine Moens. 2015. Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings. In Proceedings of ACM SIGIR. 363­372.,0,,False
304,"[18] Di Wang and Eric Nyberg. 2015. A long short-term memory model for answer sentence selection in question answering. Proceedings of ACL (2015), 707­712.",0,,False
305,[19] Hamed Zamani and W Bruce Cro . 2016. Embedding-based ery Language Models. In Proceedings of ACM ICTIR. 147­156.,0,,False
306,[20] Guoqing Zheng and Jamie Callan. 2015. Learning to reweight terms with distributed representations. In Proceedings of ACM SIGIR. 575­584.,0,,False
307,"[21] Guido Zuccon, Bevan Koopman, Peter Bruza, and Leif Azzopardi. 2015. Integrating and evaluating neural word embeddings in information retrieval. In Proceedings of ADCS. 12.",0,,False
308,1216,0,,False
309,,0,,False
