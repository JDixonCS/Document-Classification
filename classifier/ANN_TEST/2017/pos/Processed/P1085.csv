,sentence,label,data,regex
0,Short Research Paper,0,,False
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
2,Term Proximity Constraints for Pseudo-Relevance Feedback,0,,False
3,Ali Montazeralghaem,0,,False
4,"School of ECE, College of Engineering University of Tehran, Iran ali.montazer@ut.ac.ir",0,,False
5,Hamed Zamani,0,,False
6,"Center for Intelligent Information Retrieval,",0,,False
7,University of Massachuse s Amherst zamani@cs.umass.edu,0,,False
8,Azadeh Shakery,1,ad,True
9,"School of ECE, College of Engineering University of Tehran, Iran",0,,False
10,"School of Computer Science, Institute for Research in Fundamental Sciences",0,,False
11,shakery@ut.ac.ir,0,,False
12,ABSTRACT,0,,False
13,"Pseudo-relevance feedback (PRF) refers to a query expansion strategy based on top-retrieved documents, which has been shown to be highly e ective in many retrieval models. Previous work has introduced a set of constraints (axioms) that should be satis ed by any PRF model. In this paper, we propose three additional constraints based on the proximity of feedback terms to the query terms in the feedback documents. As a case study, we consider the log-logistic model, a state-of-the-art PRF model that has been proven to be a successful method in satisfying the existing PRF constraints, and show that it does not satisfy the proposed constraints. We further modify the log-logistic model based on the proposed proximity-based constraints. Experiments on four TREC collections demonstrate the e ectiveness of the proposed constraints. Our modi cation to the log-logistic model leads to signi cant and substantial (up to 15%) improvements. Furthermore, we show that the proposed proximity-based function outperforms the well-known Gaussian kernel which does not satisfy all the proposed constraints.",1,ad,True
14,KEYWORDS,0,,False
15,"Term proximity, term position, axiomatic analysis, pseudo-relevance feedback, query expansion",0,,False
16,"ACM Reference format: Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Term Proximity Constraints for Pseudo-Relevance Feedback. In Proceedings of SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages. DOI: 10.1145/3077136.3080728",1,ad,True
17,1 INTRODUCTION,1,DUC,True
18,"Pseudo-relevance feedback (PRF) is a query expansion strategy to address the vocabulary mismatch problem in information retrieval (IR). In PRF, a small set of top-retrieved documents (i.e., pseudo-relevant documents) are assumed to be relevant to the initial query. ese pseudo-relevant documents are further used for updating the query model in order to improve the retrieval performance. PRF has been proven to be highly e ective in many retrieval models [2, 10, 13, 14].",1,ad,True
19,eoretical analysis of PRF models has shown that there are several constraints (axioms) that every PRF model should satisfy. Based,0,,False
20,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: 10.1145/3077136.3080728",1,ad,True
21,"on these theoretical studies, several modi cations, e.g., [1, 3, 9, 10], have been made to the existing PRF models which lead to signi cant improvements in the retrieval performance. Although term proximity has been shown to be a strong evidence for improving the retrieval performance [5, 12], especially in the PRF task [6­8], none of the existing constraints for PRF takes term proximity into account.1",1,ad,True
22,"In this paper, we provide a theoretical analysis for the use of term proximity in PRF models. To do so, we introduce three PRF constraints based on the proximity of candidate feedback terms and the query terms in the feedback documents. According to the rst constraint (""proximity e ect""), the candidate feedback terms that are positionally closer to the query terms in the feedback documents should be given higher weights in the feedback model. e second constraint (""convexity e ect"") decreases the e ect of term proximity when the distance between terms increases. e third constraint indicates that proximity to the less common query terms is more important than proximity to the query terms that are general.",0,,False
23,"Furthermore, previous work on leveraging term proximity for IR tasks, including the positional relevance model, showed that the Gaussian kernel is an e ective way for enhancing IR models with term proximity information [5, 6, 8]. In this paper, we show that the Gaussian kernel does not satisfy all the proposed constraints, and thus it could not be the best way for applying term proximity to PRF models.",0,,False
24,e primary contributions of this work can be summarized as follows:,0,,False
25,· Introducing three proximity-based constraints for theoretical analysis of PRF models.,0,,False
26,"· Studying and modifying the log-logistic feedback model [2], a state-of-the-art PRF model that outperforms many existing models, including the mixture model [14] and the geometric relevance model [11] (see [3] for more details).",0,,False
27,· Introducing a variant of the Exponential kernel that satis es all the proposed constraints.,0,,False
28,"· Evaluating our models using four TREC collections which demonstrates signi cant improvements over the original log-logistic model as well as the model enriched with the Gaussian kernel, a widely used weighting function for enhancing IR models using term proximity [5, 6, 8].",1,TREC,True
29,2 METHODOLOGY,0,,False
30,"In this section, we rst introduce three proximity-based constraints that (pseudo-) relevance feedback methods should satisfy. We further analyze the log-logistic model [2], and show that this model",0,,False
31,"1Tao and Zhai [12] proposed two proximity-based constraints for retrieval models, but not for PRF models.",0,,False
32,1085,0,,False
33,Short Research Paper,0,,False
34,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
35,does not satisfy the proposed constraints. We nally modify the log-logistic feedback model in order to satisfy all the constraints.,0,,False
36,"We rst introduce our notation. Let FW (w; F , Pw , Q) denote the feedback weight function that assigns a real-valued weight to each feedback term w for a given query Q based on the feedback document set F . Pw is a set of term-dependent parameters. For simplicity, FW (w) is henceforth used as the feedback weight function. In the following equations, T F and I DF are term frequency and inverse document frequency, respectively. | · | represents the size of the given set.",0,,False
37,2.1 Constraints,0,,False
38,"In this subsection, we introduce three proximity-based constraints for PRF methods.",0,,False
39,"[Proximity e ect] Let d(w, q, D) denote the proximity weight of a candidate feedback term w and a given query term q in a feedback document D. en, the following constraint should hold:",0,,False
40,"FW (w) d(w, q, D)",0,,False
41,<,0,,False
42,0,0,,False
43,"According to this constraint, the candidate feedback terms that are closer to the query terms in the feedback documents should have higher weights. Intuitively, the closer terms to the query terms are more likely to be relevant to the query.",0,,False
44,[Convexity e ect] e feedback weight function should be convex with respect to the distance of candidate feedback terms from the query terms. We can formalize this constraint as follows:,0,,False
45,"2FW (w) d(w, q, D)2",0,,False
46,>0,0,,False
47,e intuition behind this constraint is that decreasing the e ect of,0,,False
48,the proximity e ect should be less marked in high distance ranges.,0,,False
49,"[ ery IDF e ect] Let Q ,"" {q1, q2} be a query with two query terms q1 and q2. Let D1 and D2 denote two feedback documents with equal length, such that q1 only appears in D1, and q2 only appears in D2. Let w1 and w2 be two candidate feedback terms, such that T F (w1, D1) "","" T F (w2, D2), and w1 and w2 only appear in D1 and D2 in the feedback set, respectively. Also assume that d(w1, q1, D1) "","" d(w2, q2, D2) where d is the function to compute the proximity between two terms in a given document. We can say""",0,,False
50,"if I DF (q1) > I DF (q2), then we should have:",0,,False
51,FW (w1) > FW (w2),0,,False
52,"Intuitively, this constraint indicates that proximity to the query terms that are general is less important than proximity to the uncommon query terms. For instance, if a query contains a general term (let say a stopword) then proximity to this term should be less important than the discriminative terms that occur in the query.",0,,False
53,2.2 Modifying the Log-Logistic Model,0,,False
54,"As a case study, we analyze and modify the log-logistic feedback model [2]. e reason is that this method has been shown to outperform many strong baselines, including the mixture model [14] and the geometric relevance model [11]. It has been also shown that this method successfully satis es all the PRF constraints proposed in [3]. e log-logistic feedback weight function for each term w is",0,,False
55,computed as:,0,,False
56,FW (w),0,,False
57,",",0,,False
58,1 |F |,0,,False
59,D F,0,,False
60,log(1 +,0,,False
61,"t(w, D) ) w",0,,False
62,(1),0,,False
63,where,0,,False
64,t,0,,False
65,"(w ,",0,,False
66,d,0,,False
67,),0,,False
68,",",0,,False
69,T,0,,False
70,F,0,,False
71,"(w,",0,,False
72,D),0,,False
73,log(1,0,,False
74,+,0,,False
75,c,0,,False
76,a |D,0,,False
77,l,0,,False
78,|,0,,False
79,),0,,False
80,(a,0,,False
81,l denotes the average,0,,False
82,document length and c is a free hyper-parameter that controls,0,,False
83,the document length e ect). e document frequency term w is calculated as:,0,,False
84,"w , Nw /N",0,,False
85,(2),0,,False
86,"where Nw and N denote the number of documents in the collection that contain w and the total number of documents in the collection,",0,,False
87,respectively. FW (w) is then interpolated with the original query,0,,False
88,based on a free parameter (feedback coe cient)[2].,0,,False
89,It can be easily shown that the log-logistic feedback model does,0,,False
90,"not satisfy the proximity-based constraints, since its formulation",0,,False
91,does not contain any proximity-based component. To the best of,0,,False
92,"our knowledge, this is the rst a empt to enrich the log-logistic",0,,False
93,feedback model using term proximity information.,0,,False
94,"Regarding the query term independence assumption, we propose",0,,False
95,to modify the log-logistic model as follows to satisfy the proximity-,0,,False
96,based constraints:,0,,False
97,"FWprox (w) , FW (w) ",0,,False
98," (w, q, D)",0,,False
99,(3),0,,False
100,D F q Q,0,,False
101,"where q is a query term and  (w, q, D) is a function that computes the proximity of w and q in document D.",0,,False
102,"To de ne the function  , we propose to use the Exponential kernel that satis es the ""proximity e ect"" and the ""convexity e ect"" constraints. We modify the Exponential kernel by adding an IDF term to satisfy the "" ery IDF e ect"" constraint, as well. e function  can be computed as follows:",1,ad,True
103," (w, q, D) , exp",0,,False
104,"-d(w, q, D) ",0,,False
105,. log 1 q,0,,False
106,(4),0,,False
107,"where d(w, q, D) denotes the distance function for two given terms w and q in document D. q is the document frequency component for the query term q (see Equation (2)) and  is a free parameter. Several approaches have been proposed to compute d(w, q, D), such as average, minimum, and maximum distances. Tao and Zhai [12] showed that using the minimum distance between the term w and the query term q in the feedback document outperforms other distance functions. We also use the minimum distance as follows:",0,,False
108,"d(w, q, D) , min |wi - qj |",0,,False
109,(5),0,,False
110,wi wì & qj qì,0,,False
111,"where wì and qì are two vectors containing the positions of term w and query term q in document D, respectively.",0,,False
112,3 EXPERIMENTS,0,,False
113,3.1 Experimental Setup,0,,False
114,"We used four standard TREC collections in our experiments: AP (Associated Press 1988-89), Robust (TREC Robust Track 2004 collection), WT2g (TREC Web Track 2000 collection), and WT10g (TREC Web Track 2001-2002 collection). e rst two are newswire collections, while the next two are web collections containing more noisy documents. e statistics of these collections are reported in Table 1. We considered the title of topics as queries. All documents",1,TREC,True
115,1086,0,,False
116,Short Research Paper,0,,False
117,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
118,Table 1: Collections statistics.,0,,False
119,Collection AP,1,AP,True
120,Robust WT2g WT10g,1,Robust,True
121,TREC topics 51-200,1,TREC,True
122,301-450 & 601-700 401-450 451-550,0,,False
123,#docs 165k 528k 247k 1692k,0,,False
124,doc length 287 254 645 399,0,,False
125,#qrels 15838 17412 2279 5931,0,,False
126,were stemmed using the Porter stemmer and stopped using the standard INQUERY stopword list. We carried out the experiments using the Lemur toolkit2.,0,,False
127,"3.1.1 Parameter Se ing. e number of feedback documents, the feedback term count, and the feedback coe cient were set using 2-fold cross validation over the queries of each collection. We swept the number of feedback documents between {10, 25, 50, 75, 100}, the feedback term count between {10, 25, 50, 75, 100}, and the feedback coe cient between {0, 0.1, · · · , 1}. e parameters c and  were also selected using the same procedure from {2, 4, · · · , 10} and {25, 50, · · · , 500}, respectively. e parameter  in the Gaussian kernel is also set similarly.",0,,False
128,"3.1.2 Evaluation Metrics. To evaluate retrieval e ectiveness, we use mean average precision (MAP) of the top-ranked 1000 documents as the main evaluation metric. In addition, we also report the precision of the top 10 retrieved documents (P@10). Statistically signi cant di erences of average precisions are determined using the two-tailed paired t-test computed at a 95% con dence level. To evaluate robustness of methods, we consider the robustness index (RI) introduced in [4].",1,MAP,True
129,3.2 Results and Discussion,0,,False
130,"In this subsection, we rst empirically show that satisfying each of the introduced constraints improves the retrieval performance. Our experiments also demonstrate that the Gaussian kernel that has previously been used in the literature [5, 6, 8] is not as e ective as the proposed proximity weighting function, since the Gaussian kernel does not satisfy all the constraints.",0,,False
131,"3.2.1 Analysis of the Proximity-based Constraints. We consider two baselines: (1) the document retrieval method without feedback (NoPRF), and (2) the original log-logistic feedback model (LL). Although there are several e ective PRF methods, since in this paper we study the e ect of the proposed constraints in the log-logistic model, we do not consider other existing PRF methods.",0,,False
132,"To study the in uence of each of the proposed constraints on the retrieval performance, we consider three di erent proximity functions: (1) the quadratic function ( ad) that only satis es the ""proximity e ect"" constraint, (2) the exponential function (Exp) that satis es both ""proximity e ect"" and ""convexity e ect"" constraints, and (3) a modi ed version of the exponential function (Exp*) that satis es all three constraints. More detail is reported Table 2.",1,ad,True
133,"e results of the baselines and the aforementioned methods are reported in Table 3. According to this table, modifying the loglogistic method using each of the proximity functions improves the retrieval performance, in all collections. e MAP improvements are statistically signi cant in nearly all cases. is indicates the necessity of taking term proximity into account for the PRF task.",1,MAP,True
134,2h p://lemurproject.org/,0,,False
135,"Table 2: Summary of di erent proximity functions with respect to the proximity-based constraints (x ,"" d(w, q, D)).""",0,,False
136,"Func.  (w, q, D)",0,,False
137,Gaus,0,,False
138,exp[,0,,False
139,-x 2,0,,False
140,2 2,0,,False
141,],0,,False
142,ad,1,ad,True
143,-(,0,,False
144,x ,0,,False
145,)2,0,,False
146,+,0,,False
147,1,0,,False
148,Exp,0,,False
149,exp[,0,,False
150,-x ,0,,False
151,],0,,False
152,Exp*,0,,False
153,exp[,0,,False
154,-x ,0,,False
155,].,0,,False
156,log,0,,False
157,N Nq,0,,False
158,Proximity Convexity e ect e ect,0,,False
159,Yes Partially,0,,False
160,Yes,0,,False
161,No,0,,False
162,Yes,0,,False
163,Yes,0,,False
164,Yes,0,,False
165,Yes,0,,False
166,ery IDF e ect,0,,False
167,No,0,,False
168,No,0,,False
169,No,0,,False
170,Yes,0,,False
171,"e results demonstrate that LL+Exp outperforms LL+ ad and LL+Exp* outperforms LL+Exp, in all collections. e improvements in the web collections are higher than those in the newswire collections. e reason is that these two collections are web crawls and contain more noisy documents compared to the newswire collections. e other reason is that the WT2g and WT10g documents are much longer than the AP and Robust documents on average (see Table 1). e in uence of proximity-based constraints can be highlighted in longer documents. Besides that, in terms of RI, LL+Exp* outperforms all the baselines in AP, WT2g and WT10g which shows the importance and robustness of ery IDF e ect and these improvements are impressive in WT2g and WT10g which shows that this e ect is important in noisy (web) collections.",1,ad,True
172,"3.2.2 Analysis of the Gaussian Kernel. In this set of experiments, we study the Gaussian kernel for computing the proximity weight, which has been shown to be the most e ective proximity function among the existing ones [5]. As reported in Table 2, employing the Gaussian kernel for PRF satis es the ""proximity e ect"" constraint. e ""convexity e ect"" constraint is only satis ed when d(w, q, D) >  . erefore, it does not satisfy the ""convexity e ect"" for the candidate feedback terms that are close to the query terms. We evaluate the Gaussian kernel by considering it as a term proximity weight function (LL+Gaus). According to the results reported in Table 3, LL+Exp and LL+Gaus perform comparably in the newswire collections, but LL+Exp outperforms LL+Gaus in the web collections (WT2g and WT10g). LL+Exp* also outperforms LL+Gaus in all collections. e improvements in the web collections are statistically signi cant.",1,WT,True
173,"3.2.3 Parameter Sensitivity. In the last set of experiments, we study the sensitivity of the proposed method to the following hyperparameters: the number of feedback terms added to the query, (2) the feedback interpolation coe cient, and (3) the parameter  (see Equation (4)). To do so, we sweep one of the parameters and x the other ones to their default values: 50 for feedback term count, 0.5 for feedback coe cient, and 25 for . In these experiments, we report the result for LL+Exp* that achieves the best performance in Table 3.",1,ad,True
174,"e results are plo ed in Figure 1, in terms of MAP. In this gure, the rst plot shows that the performance of LL+Exp* is stable with respect to the changes in the number of feedback terms, when more than 25 terms are added to the query. In other words, 25 terms are enough for expanding the query in most collections. e second plot in Figure 1 demonstrates that the behaviour of LL+Exp* in newswire collections is similar to each other. LL+Exp* also behaves similarly in the web collections. Interestingly, the feedback model estimated by LL+Exp* does not need to be interpolated with the original query",1,MAP,True
175,1087,0,,False
176,Short Research Paper,0,,False
177,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
178,Table 3: Performance of di erent proximity functions applied to the log-logistic model. Superscripts 0/1/2 denote that the MAP improvements over NoPRF/LL/LL+Gaus are statistically signi cant. e highest value in each column is marked in bold.,1,MAP,True
179,Method,0,,False
180,AP MAP P@10 RI,1,AP,True
181,Robust MAP P@10 RI,1,Robust,True
182,WT2g MAP P@10 RI,1,WT,True
183,WT10g MAP P@10 RI,1,WT,True
184,NoPRF LL,0,,False
185,LL+Gaus,0,,False
186,LL+ ad LL+Exp LL+Exp*,1,ad,True
187,0.2642 0.4260 ­,0,,False
188,0.3385 0.4622 0.15,0,,False
189,0.347101 0.4695 0.19,0,,False
190,0.344101 0.4682 0.18 0.346801 0.4688 0.19 0.347501 0.4702 0.21,0,,False
191,0.2490 0.4237 ­,0,,False
192,0.2829 0.4393 0.33,0,,False
193,0.292601 0.4454 0.27,0,,False
194,0.292001 0.4530 0.30 0.293601 0.4442 0.28 0.295001 0.4430 0.30,0,,False
195,0.3033 0.4480 ­,0,,False
196,0.3276 0.4820 0.36,0,,False
197,0.33510 0.4920 0.38,0,,False
198,0.33090 0.4920 0.34 0.3418012 0.4840 0.38 0.3449012 0.4820 0.47,0,,False
199,0.2080 0.3030 ­,0,,False
200,0.2127 0.3187 0.08,0,,False
201,0.239301 0.3157 0.16,0,,False
202,0.21950 0.3075 0.02 0.243501 0.3247 0.19 0.2461012 0.3278 0.24,0,,False
203,0.35,0,,False
204,0.30,0,,False
205,0.25,0,,False
206, AP Robust,1,AP,True
207,WT2g WT10g,1,WT,True
208,0.35,0,,False
209, AP Robust,1,AP,True
210,WT2g WT10g,1,WT,True
211,0.30,0,,False
212,0.25,0,,False
213, AP Robust,1,AP,True
214,WT2g WT10g,1,WT,True
215,0.35    ,0,,False
216,0.30,0,,False
217,0.25,0,,False
218,MAP MAP MAP,1,MAP,True
219,0.20 0,0,,False
220,25,0,,False
221,50,0,,False
222,75,0,,False
223,100,0,,False
224,0.20,0,,False
225,0.0,0,,False
226,0.2,0,,False
227,0.4,0,,False
228,0.6,0,,False
229,0.8,0,,False
230,1.0,0,,False
231,0.20 25 75 150,0,,False
232,300,0,,False
233,400,0,,False
234,500,0,,False
235,# of feedback terms,0,,False
236,feedback coefficient,0,,False
237,"Figure 1: Sensitivity of LL+Exp* to the number of feedback terms, the feedback coe cient, and the parameter .",0,,False
238,"model in the newswire collections. In the web collections (WT2g and WT10g), giving a small weight (i.e., 0.2) to the original query model can help to improve the retrieval performance. e reason could be related to the noisy nature of the web collections compared to the newswire collections. e last plot in Figure 1 shows that the proposed method is not highly sensitive to the parameter  when it is higher than 100. e results indicate that 25 and 50 would be proper values for this parameter. e results on the web collections are more sensitive to this parameter. e reason is that the documents in the web collections are much longer than those in the newswire collections (see Table 1).",1,WT,True
239,4 CONCLUSIONS AND FUTURE WORK,0,,False
240,"In this paper, we proposed three constraints for the pseudo-relevance feedback models, that focus on the proximity of the candidate feedback terms and the query terms in the feedback documents. To show the e ectiveness of the proposed constraints, we considered the log-logistic model, a state-of-the-art feedback model, as a case study. We rst showed that the log-logistic model does not satisfy the proximity-based constraints. We further modi ed it based on the proposed constraints. Our experiments on four standard TREC newswire and web collections demonstrated the e ectiveness of the proposed constraints for the PRF task. e modi ed log-logistic model signi cantly outperforms the original log-logistic model, in all collections. We also showed that the Gaussian kernel that has been used in previous proximity-based methods does not satisfy all the constraints. We show that the performance of the proposed variant of the exponential kernel is superior to those obtained by employing the Gaussian kernel. As a future direction, the other existing PRF models could be analyzed and modi ed based on the introduced constraints.",1,TREC,True
241,Acknowledgements. is work was supported in part by the Center for,0,,False
242,Intelligent Information Retrieval and in part by a grant from the Institute,0,,False
243,"for Research in Fundamental Sciences (No. CS1396-4-51). Any opinions,",0,,False
244,ndings and conclusions or recommendations expressed in this material,0,,False
245,are those of the authors and do not necessarily re ect those of the sponsors.,0,,False
246,REFERENCES,0,,False
247,"[1] Mozhdeh Ariannezhad, Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Iterative Estimation of Document Relevance Score for PseudoRelevance Feedback. In ECIR '17. 676­683.",1,ad,True
248,[2] Ste´phane Clinchant and Eric Gaussier. 2010. Information-based Models for Ad Hoc IR. In SIGIR '10. 234­241.,0,,False
249,[3] Ste´phane Clinchant and Eric Gaussier. 2013. A eoretical Analysis of PseudoRelevance Feedback Models. In ICTIR '13. 6­13.,0,,False
250,[4] Kevyn Collins- ompson. 2009. Reducing the Risk of ery Expansion via Robust Constrained Optimization. In CIKM '09. 837­846.,1,Robust,True
251,[5] Yuanhua Lv and ChengXiang Zhai. 2009. Positional Language Models for Information Retrieval. In SIGIR '09. 299­306.,0,,False
252,[6] Yuanhua Lv and ChengXiang Zhai. 2010. Positional Relevance Model for Pseudorelevance Feedback. In SIGIR '10. 579­586.,0,,False
253,"[7] Yuanhua Lv, ChengXiang Zhai, and Wan Chen. 2011. A Boosting Approach to Improving Pseudo-relevance Feedback. In SIGIR '11. 165­174.",0,,False
254,"[8] Jun Miao, Jimmy Xiangji Huang, and Zheng Ye. 2012. Proximity-based Rocchio's Model for Pseudo Relevance. In SIGIR '12. 535­544.",0,,False
255,"[9] Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2016. Axiomatic Analysis for Improving the Log-Logistic Feedback Model. In SIGIR '16. 765­768.",1,ad,True
256,"[10] Dipasree Pal, Mandar Mitra, and Samar Bha acharya. 2015. Improving Pseudo Relevance Feedback in the Divergence from Randomness Model. In ICTIR '15. 325­328.",0,,False
257,[11] Jangwon Seo and W. Bruce Cro . 2010. Geometric Representations for Multiple Documents. In SIGIR '10. 251­258.,0,,False
258,[12] Tao Tao and ChengXiang Zhai. 2007. An Exploration of Proximity Measures in Information Retrieval. In SIGIR '07. 295­302.,0,,False
259,"[13] Hamed Zamani, Javid Dadashkarimi, Azadeh Shakery, and W. Bruce Cro . 2016. Pseudo-Relevance Feedback Based on Matrix Factorization. In CIKM '16. 1483­ 1492.",1,ad,True
260,[14] Chengxiang Zhai and John La erty. 2001. Model-based Feedback in the Language Modeling Approach to Information Retrieval. In CIKM '01. 403­410.,0,,False
261,1088,0,,False
262,,0,,False
