,sentence,label,data,regex
0,Session 3A: Search Interaction 2,1,Session,True
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
2,Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach,0,,False
3,Rishabh Mehrotra and Emine Yilmaz,0,,False
4,"University College London, London, United Kingdom  e Alan Turing Institute, British Library, London, United Kingdom",0,,False
5,"{r.mehrotra,e.yilmaz}@cs.ucl.ac.uk",0,,False
6,ABSTRACT,0,,False
7,"A signi cant amount of search queries originate from some real world information need or tasks [13]. In order to improve the search experience of the end users, it is important to have accurate representations of tasks. As a result, signi cant amount of research has been devoted to extracting proper representations of tasks in order to enable search systems to help users complete their tasks, as well as providing the end user with be er query suggestions [9], for be er recommendations [41], for satisfaction prediction [36] and for improved personalization in terms of tasks [24, 38]. Most existing task extraction methodologies focus on representing tasks as at structures. However, tasks o en tend to have multiple subtasks associated with them and a more naturalistic representation of tasks would be in terms of a hierarchy, where each task can be composed of multiple (sub)tasks. To this end, we propose an e cient Bayesian nonparametric model for extracting hierarchies of such tasks & subtasks. We evaluate our method based on real world query log data both through quantitative and crowdsourced experiments and highlight the importance of considering task/subtask hierarchies.",0,,False
8,KEYWORDS,0,,False
9,search tasks; bayesian non-parametrics; hierarchical model,0,,False
10,"ACM Reference format: Rishabh Mehrotra and Emine Yilmaz. 2017. Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach. In Proceedings of SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan, , 10 pages. DOI: h p://dx.doi.org/10.1145/3077136.3080823",0,,False
11,1 INTRODUCTION,1,DUC,True
12,"e need for search o en arises from a person's need to achieve a goal, or a task such as booking travels, buying a house, etc., which would lead to search processes that are o en lengthy, iterative, and are characterized by distinct stages and shi ing goals. [13].",1,ad,True
13,"us, identifying and representing these tasks properly is highly important for devising search systems that can help end users complete their tasks. It has previously been shown that these task representations can be used to provide users with be er query",0,,False
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. ISBN 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080823",1,ad,True
15,"suggestions [9], o er improved personalization [24, 38], provide be er recommendations [41], help in satisfaction prediction [36] and search result re-ranking. Moreover, accurate representations of tasks could also be highly useful in aptly placing the user in the task-subtask space to contextually target the user in terms of be er recommendations and advertisements, developing task speci c ranking of documents, and developing task based evaluation metrics to model user satisfaction. Given the wide range of applications these tasks representations can be used for, signi cant amount of research has been devoted to task extraction and representation [12, 13, 15, 17, 21].",1,ad,True
16,"Task extraction is quite a challenging problem as search engines can be used to achieve very di erent tasks, and each task can be de ned at di erent levels of granularity. A major limitation in existing task-extraction methods lies in their treatment of search tasks as at structure-less clusters which inherently lack insights about the presence or demarcation of subtasks associated with individual search tasks. In reality, o en search tasks tend to be hierarchical in nature. For example, a search task like planning a wedding involves subtasks like searching for dresses, browsing di erent hairstyles, looking for invitation card templates, nding planners, among others. Each of these subtasks (1) could themselves be composed of multiple subtasks, and (2) would warrant issuing di erent queries by users to accomplish them. Hence, in order to obtain more accurate representations of tasks, new methodologies for constructing hierarchies of tasks are needed.",0,,False
17,"As part of the proposed research, we consider the challenge of extracting hierarchies of search tasks and their associated subtasks from a search log given just the log data without the need of any manual annotation of any sort. In a recent poster we showed that Bayesian nonparametrics have the potential to extract a hierarchical representation of tasks [25]; we extend this model further to form more accurate representations of tasks.",0,,False
18,"We present an e cient Bayesian nonparametric model for discovering hierarchies and propose a tree based nonparametric model to discover this rich hierarchical structure of tasks/subtasks embedded in search logs. Most existing hierarchical clustering techniques result in binary tree structures with each node decomposed into two child nodes. Given that a complex task could be composed of an arbitrary number of subtasks, these techniques cannot directly be used to construct accurate representations of tasks. In contrast, our model is capable of identifying task structures that can be composed of an arbitrary number of children. We make use of a number of evaluation methodologies to evaluate the e cacy of the proposed task extraction methodology, including quantitative and qualitative analyses along with crowdsourced judgment studies",0,,False
19,285,0,,False
20,Session 3A: Search Interaction 2,1,Session,True
21,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
22,speci cally catered to evaluating the quality of the extracted task hierarchies. We contend that the techniques presented expand the scope for be er recommendations and search personalization and opens up new avenues for recommendations speci cally targeting users based on the tasks they involve in.,0,,False
23,2 RELATED WORK,0,,False
24,Web search logs provide explicit clues about the information seeking behavior of users and have been extensively studied to improve search experiences of users. We cover several areas of related work and discuss how our work relates to and extends prior work.,0,,False
25,2.1 Task Extraction,0,,False
26,"ere has been a large body of work focused on the problem of segmenting and organizing query logs into semantically coherent structures. Many such methods use the idea of a timeout cuto between queries, where two consecutive queries are considered as two di erent sessions or tasks if the time interval between them exceeds a certain threshold [6, 10, 33]. O en a 30-minute timeout is used to segment sessions. However, experimental results of these methods indicate that the timeouts are of limited utility in predicting whether two queries belong to the same task, and unsuitable for identifying session boundaries.",0,,False
27,"More recent studies suggest that users o en seek to complete multiple search tasks within a single search session [20, 23] with over 50% of search sessions having more than 2 tasks [23]. At the same time, certain tasks require signi cantly more e ort, time and sessions to complete with almost 60% of complex information gathering tasks continued across sessions [1, 22]. ere have been a empts to extract in-session tasks [13, 20, 35], and cross-session tasks [15, 37] from query sequences based on classi cation and clustering methods, as well as supporting users in accomplishing these tasks [9]. Prior work on identifying search-tasks focuses on task extraction from search sessions with the objective of segmenting a search session into disjoint sets of queries where each set represents a di erent task [12, 21].",0,,False
28,"Kotov et al. [15] and Agichtein et al. [1] studied the problem of cross-session task extraction via binary same-task classi cation, and found di erent types of tasks demonstrate di erent life spans. While such task extraction methods are good at linking a new query to an on-going task, o en these query links form long chains which result in a task cluster containing queries from many potentially di erent tasks. With the realization that sessions are not enough to represent tasks, recent work has started exploring cross-section task extraction, which o en results in complex non-homogeneous clusters of queries solving a number of related yet di erent tasks. Unfortunately, pairwise predictions alone cannot generate the partition of tasks e ciently and even with post-processing, the nal task partitions obtained are not expressive enough to demarcate subtasks [18]. Finally, authors in [17] model query temporal pa erns using a special class of point process called Hawkes processes, and combine topic model with Hawkes processes for simultaneously identifying and labeling search tasks.",0,,False
29,Jones et al. [13] was the rst work to consider the fact that there may be multiple subtasks associated with a user's information need and that these subtasks could be interleaved across di erent,0,,False
30,"sessions. However, their method only focuses on the queries submi ed by a single user and a empts to segment them based on whether they fall under the same information need. Hence, they only consider solving the task boundary identi cation and same task identi cation problem and cannot be used directly for task extraction. Our work alleviates the same user assumption and considers queries across di erent users for task extraction. Finally, in a recent poster [25], we proposed the idea of extracting task hierarchies and presented a basic tree extraction algorithm. Our current work extends the preliminary model in a number of dimensions including novel model of query a nities and task coherence based pruning strategy, which we observe gives substantial improvement in results. Unlike past work, we also present detailed derivation and evaluation of the extracted hierarchy and application on task extraction.",0,,False
31,2.2 Supporting Complex Search Tasks,0,,False
32,"ere has been a signi cant amount of work on task continuation assistance [1, 28], building task tours and trails [30, 34], query suggestions [2, 14, 27], predicting next search action [5] and notes taking when accomplishing complex tasks [8]. e quality of most of these methods depends on forming accurate representations of tasks, which is the problem we are addressing in this paper.",1,ad,True
33,2.3 Hierarchical Models,0,,False
34,"Rich hierarchies are common in data across many domains, hence quite a few hierarchical clustering techniques have been proposed.",0,,False
35,"e traditional methods for hierarchically clustering data are bo omup agglomerative algorithms. Probabilistic methods of learning hierarchies have also been proposed [3, 19] along with hierarchical clustering based methods [7, 11]. Most algorithms for hierarchical clustering construct binary tree representations of data, where leaf nodes correspond to data points and internal nodes correspond to clusters. ere are several limitations to existing hierarchy construction algorithms. e algorithms provide no guide to choosing the correct number of clusters or the level at which to prune the tree. It is o en di cult to know which distance metric to choose. Additionally and more importantly, restriction of the hypothesis space to binary trees alone is undesirable in many situations - indeed, a task can have any number of subtasks, not necessarily two. Past work has also considered constructing task-speci c taxonomies from document collections [39], browsing hierarchy construction [40], generating hierarchical summaries [16]. While most of these techniques work in supervised se ings on document collections, our work instead focused on short text queries and o ers an unsupervised method of constructing task hierarchies.",1,ad,True
36,"Finally, Bayesian Rose Trees and their extensions have been proposed [3, 4, 32] to model arbitrary branching trees. ese algorithms naively cast relationships between objects as binary (0-1) associations while the query-query relationships in general are much richer in content and structure.",0,,False
37,"We consider a number of such existing methods as baselines and the various advantages of the proposed approach is highlighted in the evaluation section wherein the proposed approach in addition to being more expressive, performs be er than state-of-the-art task extraction and hierarchical methods.",1,ad,True
38,286,0,,False
39,Session 3A: Search Interaction 2,1,Session,True
40,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
41,Symbol,0,,False
42,nT ab |c,0,,False
43,ch(T),0,,False
44,(T ),0,,False
45,p(Dm |Tm ) Tm f (Dm ) H(T ),0,,False
46,"f (Q) rqki , q j",0,,False
47,"Description number of children of tree T partition of set {a, b, c} into disjoint sets {a, b},{c} children of T partition of tree T likelihood of data Dm given the tree Tm mixing proportions of partition of tree T marginal probability of the data Dm set of all partitions of queries Q , lea es(T ) task a nity function for set of queries Q",0,,False
48,the k-th inter-query a nity between qi & qj,0,,False
49,Table 1: Table of symbols,0,,False
50,3 DEFINING SEARCH TASKS,0,,False
51,"Jones et al. [13] was one of the rst papers to point out the importance of task representations, where they de ned a search task as:",0,,False
52,De nition 3.1. A search task is an atomic information need resulting in one or more queries.,0,,False
53,"Ahmed et al. [9] later extended this de nition to a more generic one, which can also capture task structures that could possibly consist of related subtasks, each of which could be complex tasks themselves or may nally split down into simpler tasks or atomic informational needs. Following Ahmed et al. [9], a complex search task can then be de ned as:",0,,False
54,"De nition 3.2. A complex search task is a multi-aspect or a multistep information need consisting of a set of related subtasks, each of which might recursively be complex.",0,,False
55,"e de nition of complex tasks is much more generic, and captures all possible search tasks, that can be either complex or atomic (non-complex). roughout this paper we adopt the de nition provided in De nition 3.2 as the de nition for a search task.",1,ad,True
56,"Hence, by de nition a search task has a hierarchical nature, where each task can consist of an arbitrary number of, possibly complex subtasks. An e ective task extraction system should be capable of accurately identifying and representing such hierarchical structures.",0,,False
57,4 CONSTRUCTING TASK HIERARCHIES,0,,False
58,"While hierarchical clustering are widely used for clustering, they construct binary trees which may not be the best model to describe data's intrinsic structure in many applications, for example, the task-subtask structure in our case. To remedy this, multi-branch trees are developed. Currently there are few algorithms which generate multi-branch hierarchies. Blundel et al. [3, 4] adopt a simple, deterministic, agglomerative approach called BRTs (Bayesian Rose Trees) for constructing multi-branch hierarchies. In this work, we adapt BRT as a basic algorithm and extend it for constructing task hierarchies. We next describe the major steps of BRT approach.",1,ad,True
59,4.1 Bayesian Rose Trees,0,,False
60,"BRTs [3, 4] are based on a greedy probabilistic agglomerative approach to construct multi-branch hierarchies. In the beginning,",0,,False
61,Figure 1: e di erent ways of merging trees which allows us to obtain tree structures which best explain the tasksubtask structure.,0,,False
62,"each data point is regarded as a tree on its own: Ti ,"" {xi } where xi is the feature vector of i-th data. For each step, the algorithm selects two trees Ti and Tj and merges them into a new tree Tm . Unlike binary hierarchical clustering, BRT uses three possible merging operations, as shown in Figure 1:""",0,,False
63,"· Join: Tm ,"" Ti ,Tj , such that the tree Tm has two children now""",0,,False
64,"· Absorb: Tm ,"" children(Ti )  Tj , i.e., the children of one tree gets absorbed into the other tree forming an absorbed tree with >2 children""",0,,False
65,"· Collapse: Tm ,"" children(Ti )  children(Tj ), all the children of both the subtrees get combined together at the same level.""",0,,False
66,"Speci cally, in each step, the algorithm greedily nds two trees Ti and Tj to merge which maximize the ratio of probability:",0,,False
67,p(Dm |Tm ) p(Di |Ti )p(Dj |Tj ),0,,False
68,(1),0,,False
69,"where p(Dm |Tm ) is the likelihood of data Dm given the tree Tm , Dm is all the leaf data of Tm , and Dm , Di  Dj . e probability p(Dm |Tm ) is recursively de ned on the children of Tm :",0,,False
70,"p(Dm |Tm ) , Tm f (Dm ) + (1 - Tm )",0,,False
71,p(Di |Ti ) (2),0,,False
72,Ti ch(Tm ),0,,False
73,"where f (Dm ) is the marginal probability of the data Dm and Tm is the ""mixing proportion"". Intuitively, Tm is the prior probability that all the data in Tm is kept in one cluster instead of partitioned",1,ad,True
74,"into sub-trees. In BRT[4], Tm is de ned as:",0,,False
75,"Tm , 1 - (1 -  )nTm -1",0,,False
76,(3),0,,False
77,"where nTm is the number of children of Tm , and 0    1 is the hyperparameter to control the model. A larger  leads to coarser",1,ad,True
78,287,0,,False
79,Session 3A: Search Interaction 2,1,Session,True
80,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
81,cosine edit Jac Term,0,,False
82,Min-edit-U Avg-edit-U Jac-U-min Jac-U-avg,0,,False
83,Same-U Same-S,0,,False
84,Embedding,0,,False
85,ery-Term Based A nity (r 1) cosine similarity between the term sets of the queries,0,,False
86,norm edit distance between query strings Jaccard coe between the term sets of the queries proportion of common terms between the queries,0,,False
87,URL Based A nity (r 2) Minimum edit distance between all URL pairs from the queries Average edit distance between all URL pairs from the queries Minimum Jaccard coe cient between all URL pairs from the queries Average Jaccard coe cient between all URL pairs from the queries,0,,False
88,Session/User Based A nity (r 3) if the two queries belong to the same user,1,Session,True
89,if the two queries belong to the same session Embedding Based A nity (r 4) cosine distance between embedding vectors of the two queries,0,,False
90,Table 2: ery- ery A nities.,0,,False
91,partitions and a smaller  leads to ner partitions. Table 1 provides an overview of notations & symbols used throughout the paper.,1,ad,True
92,4.2 Building Task Hierarchies,0,,False
93,"We next describe our task hierarchy construction approach built on top of Bayesian Rose Trees. A tree node in our se ing is comprised of a group of queries which potentially compose a search task, i.e. these are the set of queries that people tend to issue in order to achieve the task represented in the tree node.",0,,False
94,"We de ne the task-subtask hierarchy recursively: T is a task if either T contains all the queries at its node (an atomic search task) or if T splits into children trees as T ,"" {T1,T2, ...,TnT } where each of the children trees (Ti ) are disjoint set of queries corresponding to the nT subtasks associated with task T . is allows us to consider trees as a nested collection of sets of queries de ning our tasksubtask hierarchical relation.""",0,,False
95,"To form nested hierarchies, we rst need to model the query data. is corresponds to de ning the marginal distribution of the data f (Dm ) as de ned in Equation 2. e marginal distribution of the query data (f (Dm )) helps us encapsulate insights about task level interdependencies among queries, which aid in constructing be er task representations. e original BRT approach [4] assumes that the data can be modeled by a set of binary features that follow the Bernoulli distribution. In other words, features (that represent the relationship/similarities between data points) are not weighted and can only be binary. Binary (0/1) relationships are too simplistic to model inter-query relationships; as a result, this major assumption fails to capture the semantic relationships between queries and is not suited for modeling query-task relations. To this end, we propose a novel query a nity model and to alleviate the binary feature assumption imposed by BRT, we propose a conjugate model of query a nities, which we describe next.",0,,False
96,4.3 Conjugate Model of ery A nities,0,,False
97,A tree node in our se ing is comprised of a group of queries which potentially belong to the same search task. e likelihood of a tree should encapsulate information about the di erent relationships,0,,False
98,"which exists between queries. Our goal here is to make use of the rich information associated with queries and their result set available to compute the likelihood of a set of queries to belong to the same task. In order to do so, we propose a query a nity model which makes use of a number of di erent inter-query a nities to determine the tree likelihood function.",0,,False
99,We next describe the technique used to compute four broad categories of inter-query a nity and later describe the Gamma-Poisson conjugate model which makes use of these a nities to compute the marginal distribution of the data.,1,ad,True
100,"ery-term based A nity (r 1): Search queries catering to the same or similar informational needs tend to have similar query terms. We make use of this insight and capture query level a nities between a pair of queries. We make use of cosine similarity between the query term sets, the normalized edit distances between queries and the Jaccard Coe cient between query term sets.",0,,False
101,"URL-based A nity (r 2): Users tackling similar tasks tend to issue queries (possibly di erent) which return similar URLs, thus encoding the URL level similarity between pairs of queries into the query a nity model helps in capturing another task-speci c similarity between queries. Any query pair having high URL level similarity increase the possibility of the query pair originating from similar informational needs. We capture a number of URL-based signals including minimum and average edit distances between URL domains and jaccard coe cient between URLs.",0,,False
102,User/Session based A nity (r 3): It is o en the case that users issue related queries within a session so as to satisfy their informational need. We leverage this insight by making use of session level information (as a 0/1 binary feature) and user-level information (as a 0/1 binary feature) in our a nity model to identify queries issued in the same session and by the same user accordingly.,1,Session,True
103,288,0,,False
104,Session 3A: Search Interaction 2,1,Session,True
105,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
106,"ery Embedding based A nity (r 4): Word embeddings capture lexico-semantic regularities in language, such that words with similar syntactic and semantic properties are found to be close to each other in the embedding space. We leverage this insight and propose a query-query a nity metric based on such embeddings. We train a skip-gram word embeddings model where a query term is used as an input to a log-linear classi er with continuous projection layer and words within a certain window before and a er the words are predicted. To obtain a query's vector representation, we average the vector representations of each of its query terms and compute the cosine similarity between two queries' vector representations to quantify the embedding based a nity (r 4).",0,,False
107,"Table 2 summarizes all features considered to compute these a nities. Our goal is to capture information from all four a nities when de ning the likelihood of the tree. We assume that the global a nity among a group of queries can be decomposed into a product of independent terms, each of which represent one of the four a nities from the query-group. For each query group Q, we take the normalized sum of the a nities from all pairs of queries in the group Q to form each of the a nity component (rk , k,""1,2,3,4).""",0,,False
108,"Poisson models have been shown as e ective query generation models for information retrieval tasks [26]. While these a nities could be used with a lot of distributions, in the interest of computational e ciency and to avoid approximate solutions, our model will use a hierarchical Gamma-Poisson distribution to encode the query-query a nities. We incorporate the gamma-Poisson conjugate distribution in our model under the assumptions that the query a nities are discretized and for a group of queries Q, the a nities can be decomposed to a product of independent terms, each of which represents contributions from the four di erent a nity types. Finally, for a tree (Tm ) consisting of the data (Dm ), i.e. the set of queries Q, we de ne the marginal likelihood as:",1,corpora,True
109,"k ,4",0,,False
110,"f (Dm ) , f (Q) , p",0,,False
111,"rqki,qj |k , k (4)",0,,False
112,"k ,1 i 1··· |Q | j 1··· |Q |",0,,False
113,where k & k are respectively the shape parameter & the rate parameter of the four di erent a nities. Making use of the Poisson-,0,,False
114,"Gamma conjugacy, the probability term in the above product can",0,,False
115,be wri en as:,0,,False
116,"p(r |, ) ,"" p(r |)p(|, )d""",0,,False
117,(5),0,,False
118,r,0,,False
119,",",0,,False
120,( + r )  r ! ()  + 1,0,,False
121,1  +1,0,,False
122,(6),0,,False
123,"where  is the Poisson mean rate parameter which gets eliminated from computations because of the Gamma-Poisson conjugacy and where r ,  &  get replaced by a nity class speci c values.",0,,False
124,4.4 Task Coherence based Pruning,0,,False
125,"e search task extraction algorithm described above provides us a way of constructing a task hierarchy wherein as we go down the tree, nodes comprising of complex multi-aspect tasks split up to provide ner tasks which ideally should model user's ne grained information needs. One key problem with the hierarchy construction algorithm is the continuous spli ing of nodes which results",0,,False
126,"in singleton queries occupying the leave nodes. While spli ing of nodes which represent complex tasks is important, the nodes representing simple search task queries corresponding to atomic informational needs should not be further split into children nodes. Our goal in this section is to provide a way of quantifying the task complexity of a particular node so as to prevent spli ing up nodes representing atomic search task into further subsets of query nodes.",0,,False
127,"4.4.1 Identifying Atomic Tasks. We wish to identify nodes capturing search subtasks which represent atomic informational need. In order to do so, we introduce the notion of Task Coherence:",0,,False
128,De nition 4.1. Task Coherence is a measure indicating the atomicity of the information need associated with the task. It is captured by the semantic closeness of the queries associated with the task.,0,,False
129,"By measuring Task Coherence, we intend to capture the semantic variability of queries within this task in an a empt to identify how complex or atomic a task is. For example, a tree node corresponding to a complex task like planning a vacation would involve queries from varied informational needs including ights, hotels, getaways, etc; while a tree node corresponding to a ner task representing an atomic informational need like nding discount coupons would involve less varied queries - all of which would be about discount coupons. Traditional research in topic modelling has looked into automatic evaluation of topic coherence [29] via Pointwise Mutual Information. We leverage the same insights to capture task coherence.",1,ad,True
130,"4.4.2 Pointwise Mutual Information. PMI has been studied variously in the context of collocation extraction [31] and is one measure of the statistical independence of observing two words in close proximity. We wish to compute PMI scores for each node of the tree. A tree node in our discussion so far has been represented by a collection of search queries. We split queries into terms and obtain a set of terms corresponding to each node, and calculate a node's PMI scores using the node's set of query terms.",0,,False
131,"More speci cally, the PMI of a given pair of query terms (w1 & w2) is given by:",0,,False
132,"PMI (w1, w2) , lo",0,,False
133,"p(w1, w2) p(w1)p(w2)",0,,False
134,(7),0,,False
135,where the probabilities are determined from the empirical statistics of some full standard collection. We employ the AOL log query set for this and treat two query terms as co-occurring if both terms,0,,False
136,"occur in the same session. For a given task node (Q), we measure task coherence as the average of PMI scores for all pairs of the search terms associated with the task node:",0,,False
137,PMI,0,,False
138,- Score(Q),0,,False
139,",",0,,False
140,1 |w |,0,,False
141,"|w | i ,1",0,,False
142,|w |,0,,False
143,"PMI (wi , wj )",0,,False
144,"j ,1",0,,False
145,(8),0,,False
146,where |w | represents the total number of unique search terms associated with task node Q. e node's PMI-Score is used as the,0,,False
147,nal measure of task coherence for the task represented via the corresponding node.,0,,False
148,"4.4.3 Tree Pruning. We use the task coherence score associated with each node of the task hierarchy constructed, and prune lower level nodes of the tree to avoid aggressive node spli ing. e",0,,False
149,289,0,,False
150,Session 3A: Search Interaction 2,1,Session,True
151,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
152,"overall motivation here is to avoid spli ing nodes which represent simple search tasks associated with atomic informational needs. We scan through all levels of the search task hierarchy obtained by the algorithm described above and for each node compute its task coherence score. If the task coherence score exceeds a speci c threshold, it implies that all the queries in this particular node are aimed at solving the same or very similar informational need and hence, we prune o the sub-tree rooted at this particular node and ignore all further splits of this node.",0,,False
153,4.5 Algorithmic Overview,0,,False
154,"We summarize the overall algorithm to construct the hierarchy by outlining the steps. e problem is treated as one of greedy model selection: each tree T is a di erent model, and we wish to nd the model that best explains the search log data in terms of task-subtask structure.",0,,False
155,"Step 1: Forrest Initialization: e tree is built in a bo om-up greedy agglomerative fashion, start-",0,,False
156,"ing from a forest consisting of n (,""|Q |) trivial trees, each corresponding to exactly one vertex. e algorithm maintains a forest F of trees, the likelihood p(i) "","" p(Di |Ti ) of each tree Ti  F and the di erent query a nities. Each iteration then merges two of the trees in the forest. At each iteration, each vertex in the network is a leaf of exactly one tree in the forest. At each iteration a pair of trees in the forest F is chosen to be merged, resulting in forest F .""",0,,False
157,"Step 2: Merging Trees: At each iteration, the best potential merge, say of trees X and Y resulting in tree I, is picked o the heap. Binary trees do not t into representing search tasks since a task is likely to be composed of more than two subtasks. As a result, following [3] we consider three possible mergers of two trees Ti and Tj into Tm . Tm may be formed by joining Ti and Tj together using a new node, giving Tm ,"" {Ti ,Tj }. Alternatively Tm may be formed by absorbing Ti as a child of Tj , yielding Tm "","" {Tj } ch(Ti ), or vice-versa, Tm "", {Ti } ch(Tj ). We explain the di erent possible merge operations in Figure 1. We obtain arbitrary shaped sub-trees (without restricting to binary tress) which are be er at representing the varied task-subtask structures as observed in search logs with the structures themselves learnt from log data. Such expressive nature of our approach di erentiates it from traditional agglomerative clustering approaches which necessarily result in binary trees.",1,ad,True
158,"Step 3: Model Selection: Which pair of trees to merge, and how to merge these trees, is determined by considering which pair and type of merger yields the largest Bayes factor improvement over the current model. If the trees Ti and Tj are merged to form the tree M, then the Bayes factor score is:",0,,False
159,"SCORE(M; I,",0,,False
160,),0,,False
161,",",0,,False
162,p(DM |F ) p(DM |F ),0,,False
163,(9),0,,False
164,",",0,,False
165,p(DM |M) p(Di |Ti )p(Dj |Tj ),0,,False
166,(10),0,,False
167,"where p(Di |Ti ) and p(Dj |Tj ) are given by the dynamic programming equation mentioned above. A er a successful merge, the",0,,False
168,"statistics associated with the new tree are updated. Finally, potential mergers of the new tree with other trees in the forest are considered and added onto the heap.",1,ad,True
169,"e algorithm nishes when no further merging results in improvement in the Bayes Factor score. Note that the Bayes factor score is based on data local to the merge - i.e., by considering the probability of the connectivity data only among the leaves of the newly merged tree. is permits e cient local computations and makes the assumption that local community structure should depend only on the local connectivity structure.",0,,False
170,"Step 4: Tree Pruning: A er constructing the entire hierarchy, we perform the post-hoc tree pruning procedure described in Section 4.4 wherein we identify atomic task nodes via their task coherence estimates and prune all child nodes of the identi ed atomic nodes.",1,hoc,True
171,5 EXPERIMENTAL EVALUATION,0,,False
172,"We perform a number of experiments to evaluate the proposed task-subtask extraction method. First, we compare its performance with existing state-of-the-art task extraction systems on a manually labelled ground-truth dataset and report superior performance (5.1). Second, we perform a detailed crowd-sourced evaluation of extracted tasks and additionally validate the hierarchy using human labeled judgments (5.2). ird, we show a direct application of the extracted tasks by using the task hierarchy constructed for term prediction (5.3).",1,ad,True
173,"Parameter Setting: Unless stated otherwise, we made use of the best performing hyperparameters for the baselines as reported by the authors. e query a nities in the proposed approach were computed from the speci c query collection used in the dataset used for each of the three experiments reported below. While hyperparmeter optimization is beyond the scope of this work, we experimented with a range of the shape and inverse scale hyperparameters (, ) used for the Poison Gamma conjugate model and used the ones which performed best on the validation set for the search task identi cation results reported in the next section. Additionally, for the tree pruning threshold, we empirically found that a threshold of 0.8 gave the best performance on our toy hierarchies, and was used for all future experiments.",1,ad,True
174,5.1 Search Task Identi cation,0,,False
175,"To justify the e ectiveness of the proposed model in identifying search tasks in query logs, we employ a commonly used AOL data subset with search tasks annotated which is a standard test dataset for evaluating task extraction systems. We used the task extraction dataset as provided by Lucchese et al.[20]. e dataset comprises of a sample of 1000 user sessions for which human assessors were asked to manually identify the optimal task-based query sessions, thus producing a ground-truth that can be used for evaluating automatic task-based session discovery methods. For further details on the dataset and the dataset access links, readers are directed to Lucchese et al.[20].",1,ad,True
176,290,0,,False
177,Session 3A: Search Interaction 2,1,Session,True
178,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
179,We compare our performance with a number of search task identi cation approaches:,0,,False
180,· Bestlink-SVM [37]: is method identi ed search task using a semi-supervised clustering model based on the latent structural SVM framework.,0,,False
181,"· QC-HTC/QC-WCC [20]: is series of methods viewed search task identi cation as the problem of best approximating the manually annotated tasks, and proposed both clustering and heuristic algorithms to solve the problem.",0,,False
182,"· LDA-Hawkes [17]: a probabilistic method for identifying and labeling search tasks that model query temporal patterns using a special class of point process called Hawkes processes, and combine topic model with Hawkes processes for simultaneously identifying and labeling search tasks.",0,,False
183,"· LDA Time-Window(TW): is model assumes queries belong to the same search task only if they lie in a xed or exible time window, and uses LDA to cluster queries into topics based on the query co-occurrences within the same time window. We tested time windows of various sizes and report results on the best performing window size.",0,,False
184,"5.1.1 Metrics. A commonly used evaluation metric for search task extraction is the pairwise F-measure computed based on pairwise precision/recall [13, 15] de ned as,",0,,False
185,ppair,0,,False
186,",",0,,False
187,i j (,0,,False
188,"(qi ), (qj )) ( ^(qi ),  ( ^(qi ), ^(qj ))",0,,False
189,^(qj )),0,,False
190,(11),0,,False
191,rpair,0,,False
192,",",0,,False
193,i j (,0,,False
194,"(qi ), (qj )) ( ^(qi ), ^(qj ))  ( (qi ), (qj ))",0,,False
195,(12),0,,False
196,where ppair evaluates how many pairs of queries predicted in the,0,,False
197,"same task, i.e.,  ( ^(qi ), ^(qj ) ,"" 1, are actually annotated as in the""",0,,False
198,"same task, i.e.,  ( (qi ), (qj )) , 1 and rpair evaluates how many",0,,False
199,pairs annotated as in the same task are recovered by the algorithm.,0,,False
200,"us, globally F-measure evaluates the extent to which a task con-",0,,False
201,tains only queries of a particular annotated task and all queries,0,,False
202,"of that task. Given ppair and rpair , the F-measure is computed",0,,False
203,as:F1,0,,False
204,",",0,,False
205,2×ppair ×rpair ppair +rpair,0,,False
206,.,0,,False
207,"5.1.2 Results & Discussion. Figure 2 compares the proposed model with alternative probabilistic models and state-of-the-art task identi cation approaches by F1 score. To make fair comparisons, we consider the last level of the pruned tree constructed as task clusters when computing pairwise precision/recall values. It is important to note that the labelled dataset has only at tasks extracted on a per user basis; as a result, this dataset is not ideal for making fair comparisons of the proposed hierarchy extraction method with baselines. Nevertheless, the proposed approach manages to outperform existing task extraction baselines while having much greater expressive powers and providing the subdivision of tasks into subtasks. LDA-TW performs the worst since its assumptions on query relationship within the same search task are too strong. e advantage over QC-HTC and QC-WCC demonstrates that appropriate usage of query a nity information can even better re ect the semantic relationship between queries, rather than exploiting it in some collaborative knowledge.",1,ad,True
208,F Score,0,,False
209,0.85 0.84 0.83 0.82 0.81,0,,False
210,0.8 0.79 0.78 0.77 0.76 0.75,0,,False
211,Proposed,0,,False
212,LDA-TW,0,,False
213,Bestlink-SVM,0,,False
214,LDA-Hawkes,0,,False
215,QC-HTC,0,,False
216,QC-WCC,0,,False
217,Figure 2: F1 score results on AOL tagged dataset,0,,False
218,5.2 Evaluating the Hierarchy,0,,False
219,"While there are no gold standard datasets for evaluating hierarchies of tasks, we performed crowd-sourced assessments to assess the performance of our hierarchy extraction method. We separately evaluated the coherence and quality of the extracted hierarchies via two di erent set of judgements obtained via crowdsourcing.",0,,False
220,"Evaluation Setup For the judgment study, we make use of the AOL search logs and randomly sampled entire query history of frequent users who had more than 1000 search queries. e AOL log is a very large and long-term collection consisting of about 20 million of Web queries issued by more than 657000 users over 3 months. We run the task extraction algorithms on the entire set of queries of the sampled users and collect judgments to assess the quality of the tasks extracted. Judgments were provided by over 40 judges who were recruited from the Amazon Mechanical Turk crowdsourcing service. We restricted annotators to those based in the US because the logs came from searchers based in the US. We also used hidden quality control questions to lter out poor-quality judges. e judges were provided with detailed guidelines describing the notion of search tasks and subtasks and were provided with several examples to help them be er understand the judgement task.",1,ad,True
221,"Evaluating Task Coherence In the rst study, we evaluated the quality of the tasks extracted by the task extraction algorithms. In an ideal task extraction system, all the queries belonging to the same task cluster should ideally belong to the same task and hence have be er task coherence. To this end, we evaluate the task coherence property of the tasks extracted by the di erent algorithms. For each of the baselines and the proposed algorithm, we select a task at random from the set of tasks extracted and randomly pick up two queries from the selected task. We then ask the human judges the following question:",0,,False
222,291,0,,False
223,Session 3A: Search Interaction 2,1,Session,True
224,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
225,Task Relatedness,0,,False
226,Proposed LDA-TW QC-WCC LDA-Hawkes QC-HTC,0,,False
227,Task Related,0,,False
228,72%*,0,,False
229,47%,0,,False
230,60%,0,,False
231,67%,0,,False
232,61%,0,,False
233,Somewhat Related 20%,0,,False
234,14%,0,,False
235,15%,0,,False
236,13%,0,,False
237,5%,0,,False
238,Unrelated,0,,False
239,10%,0,,False
240,23%,0,,False
241,25%,0,,False
242,20%,0,,False
243,34%,0,,False
244,Table 3: Performance on Task Relatedness. e results highlighted with * signify statistically signi cant di erence between the proposed approach and best performing baseline using  2 test with p  0.05.,0,,False
245,Subtask Validity,0,,False
246,Valid,0,,False
247,Proposed Jones BHCD BAC,0,,False
248,81%*,0,,False
249,69% 51% 49%,0,,False
250,Somewhat Valid,0,,False
251,8%,0,,False
252,19% 17% 21%,0,,False
253,Not Valid,0,,False
254,11%,0,,False
255,12% 32% 30%,0,,False
256,Subtask Usefulness,0,,False
257,Useful,0,,False
258,67%*,0,,False
259,52% 41% 43%,0,,False
260,Somewhat Useful,0,,False
261,8%,0,,False
262,17% 19% 20%,0,,False
263,Not Useful,0,,False
264,25%,0,,False
265,31% 40% 37%,0,,False
266,Table 4: Performance on Subtask Validity and Subtask Use-,0,,False
267,fulness. Results highlighted with * signify statistically sig-,0,,False
268,ni cant di erence between the proposed framework and best performing baseline using  2 test with p  0.05.,0,,False
269,"RQ1: Task Relatedness: Are the given pairs of queries related to the same task? e possible options include (i) Task Related, (ii) Somewhat Task Related and (iii) Unrelated.",0,,False
270,"e task relatedness score provides an estimate of how coherent tasks are. Indeed, a task cluster containing queries from di erent tasks would score less in Task Relatedness score since if the task cluster is impure, there is a greater chance that the 2 randomly picked queries belong to di erent tasks and hence get judged Unrelated.",0,,False
271,"Evaluating the hierarchy While there are no gold standard dataset to evaluate hierarchies, in our second crowd-sourced judgment study, we evaluate the quality of the hierarchy extracted. A valid task-subtask hierarchy would have the parent task representing a higher level task with its children tasks representing more focused subtasks, each of which help the user achieve the overall task identi ed by the parent task.",0,,False
272,"We evaluate the correctness of the hierarchy by validating parentchild task-subtask relationships. More speci cally, we randomly select a parent node from the hierarchy and then randomly select a child node from the set of its immediate child nodes. Given such parent-child node pairs, we randomly pick 5 queries from the parent node and randomly pick 2 queries from the child node. We then show the human judges these parent and child queries and ask the following questions:",0,,False
273,RQ2: Subtask Validity: Consider the set of queries representing the search task and the pair of queries representing the subtask.,0,,False
274,How valid is this subtask given the overall task?,0,,False
275,"e possible judge options include (i) Valid Subtask, (ii) Somewhat valid and (iii) Invalid. Answering this question helps us in analyzing the correctness of the parent-child task-subtask pairs.",0,,False
276,RQ3: Subtask Usefulness: Consider the set of queries representing the search task and the pair of queries representing the subtask. Is the subtask useful in completing the overall search task?,0,,False
277,"e possible judge options include (i) Useful, (ii) Somewhat Useful and (iii) Not Useful. is helps us in evaluating the usefulness of task-subtask pairs by nding the proportion of subtasks which help users in completing the overall task described by the parent node. Overall, the RQ2 and RQ3 help in evaluating the correctness and usefulness of the hierarchy extracted.",0,,False
278,"Baselines Since RQ1 evaluates task coherence without any notion of tasksubtask structure, we compare against the top performing baselines from the task extraction setup described in section 5.1. On the other hand, RQ2 & RQ3 help in answering questions about the quality of hierarchy constructed. To make fair comparisons while evaluating the hierarchies, we introduce additional hierarchy extraction baselines:",1,ad,True
279,· Jones Hierarchies [13]: A supervised learning approach for task boundary detection and same task identi cation. We train the classi er using the supervised Lucchese AOL task dataset and use it to extract tasks on the current dataset used in the judgment study.,0,,False
280,· BHCD [3]: A state-of-the-art bayesian hierarchical community detection algorithm based on stochastic blockmodels and makes use of Beta-Bernoulli conjugate priors to de ne a network. We build a network of queries and apply BHCD algorithm to extract hierarchies of query communities.,0,,False
281,· Bayesian Agglomerative Clustering (BAC) [11]: A standard agglomerative hierarchical clustering model based on Dirichlet process mixtures.,0,,False
282,"Results & Discussion For the rst judgment study, each HIT is composed of 20 query pairs per approach being judged for task relatedness. We had three judges work on every HIT. Overall, per method we obtained judgments for 60 query pairs to evaluate the performance on task-relatedness. From among the three judges judging each query-pair, we followed majority voting mechanism to nalize the label for the instance.",1,ad,True
283,292,0,,False
284,Session 3A: Search Interaction 2,1,Session,True
285,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
286,avg no of query terms predicted per session,0,,False
287,1.2,0,,False
288,QC-WCC Proposed BHCD LDA-TW LDA-Hawkes,0,,False
289,1.1,0,,False
290,1,0,,False
291,0.9,0,,False
292,0.8,0,,False
293,0.7,0,,False
294,0.6,0,,False
295,0.5,0,,False
296,0.4,0,,False
297,0.3 50,0,,False
298,66,0,,False
299,75,0,,False
300,80,0,,False
301,90,0,,False
302,% age of user session data tested on,0,,False
303,Figure 3: Term Prediction performance,0,,False
304,"Table 3 presents the proportions of query pairs judged as related. About 72% of query pairs were judged task-related for the proposed approach with LDA-Hawkes performing second best with 67%. Task relatedness measures how pure the task clusters obtained are, a higher score indicates that the queries belonging to the same task are indeed used for solving the same search task. e overall results indicate that the tasks extracted by the proposed task-subtask extraction algorithm are indeed be er than those extracted by the baselines.",0,,False
305,"For the second judgment study used for evaluating the quality of the hierarchy, we show 10 pairs of parent-child questions in each HIT and ask the human annotators to judge the subtask validity and usefulness. Overall, per method we evaluate 300 such judgments resulting in over 1200 judgments and used maximum voting criterion from among the 3 judges to decide the nal label for each instance. Table 4 compares the performance of the proposed hierarchy extraction method against other hierarchical baselines.",0,,False
306,"e identi ed subtask was found useful in 67% cases with the best performing baseline being useful in 52% of judged instances. is highlights that the extracted hierarchy is indeed composed of be er subtasks which are found to be useful in completing the overall task depicted by the parent task. It is interesting to note that for BHCD and BAC baselines, most o en the subtasks were found to be invalid and not useful.",0,,False
307,"Since the same parent-child task-subtask was judged for validity and usefulness, it is expected that the proportion of task-subtasks judged useful would be less than the ones judged valid. Indeed, as can be seen from the Table 4, the relative proportions of taskssubtasks found useful is much less than those found valid.",0,,False
308,5.3 Term Prediction,0,,False
309,"In addition to task extraction and user study based evaluation, we chose to follow an indirect evaluation approach based on ery Term Prediction wherein given an initial set of queries, we predict future query terms the user may issue later in the session. is is in line with our goal of supporting users tackling complex search tasks since a task identi cation system which is capable of identifying",1,ad,True
310,good search tasks will indeed perform be er in predicting the set of future query terms.,0,,False
311,"To evaluate the performance of the proposed task extraction method, we primarily work with the TREC Session Track 2014 [? ] and AOL log data and constructed a new dataset consisting of user sessions from AOL logs concerned with Session Track queries.",1,TREC,True
312,e session track data consists of over 1200 sessions while AOL logs consists of 20M search queries issued by over 657K users. We,0,,False
313,"nd the intersection of queries between the Session Track data and AOL logs to identify user sessions in AOL data trying to achieve similar task objectives. e Session Track dataset consists of 60 di erent topics. For each of these 60 topics, we separately nd user sessions from the entire AOL logs which contain query overlaps with these topics. For each topic, we iterate through the entire AOL logs and select any user session which contains query overlap with the current topic. As a result, we obtain a total of 14030 user sessions which contain around 6.4M queries.",1,Session,True
314,"Given the initial queries from a user session and a set of tasks extracted from Session Track data, we leverage queries from the identi ed task to predict future query terms. For each Session Track topic, we construct a task hierarchy and use the constructed task hierarchy to predict future query terms in the associated user sessions. More speci cally, for each topic, we split each user session into two parts: (i) task matching and (ii) held-out evaluation part. We use queries from the task matching part of user sessions to obtain the right node in the task hierarchy from which we then recommend query terms. We pick the tree node which has the highest cosine similarity score based on all the query terms under consideration. We evaluate based on the absolute recall scores - the average number of recommended query terms which match with the query terms in the held-out evaluation part of user sessions.",1,Session,True
315,"We baseline against the top performing task extraction baselines from Section 5.1 as well as the top performing hierarchical algorithms from Section 5.2. To make fair comparisons, we consider nodes at the bo om most level of the pruned tree for task matching and term recommendation.",0,,False
316,Figure 3 compares the performance on term prediction against the considered baselines. We plot the average number of query terms predicted against the proportion of user session data used.,0,,False
317,e proposed method is able to be er predict future query terms than a standard task extraction baseline as well as a very recent hierarchy construction algorithm.,0,,False
318,6 CONCLUSION,0,,False
319,"Search task hierarchies provide us with a more naturalistic view of considering complex tasks and representing the embedded tasksubtask relationships. In this paper we rst motivated the need for considering hierarchies of search tasks & subtasks and presented a novel bayesian nonparametric approach which extracts such hierarchies. We introduced a conjugate query a nity model to capture query a nities to help in task extraction. Finally, we propose the idea of Task Coherence and use it to identify atomic tasks. Our experiments demonstrated the bene ts of considering search task hierarchies. Importantly, we were able to demonstrate competitive performance while at the same time outpu ing a richer and more",0,,False
320,293,0,,False
321,Session 3A: Search Interaction 2,1,Session,True
322,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",0,,False
323,expressive model of search tasks. is expands the scope for bet-,0,,False
324,"ter task recommendation, be er search personalization and opens",0,,False
325,up new avenues for recommendations speci cally targeting users,0,,False
326,based on the tasks they are involved in.,0,,False
327,REFERENCES,0,,False
328,"[1] Eugene Agichtein, Ryen W White, Susan T Dumais, and Paul N Bennet. 2012. Search, interrupted: understanding and predicting search task continuation. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval. ACM, 315­324.",0,,False
329,"[2] Ricardo Baeza-Yates, Carlos Hurtado, and Marcelo Mendoza. 2004. ery recommendation using query logs in search engines. In International Conference on Extending Database Technology. Springer, 588­596.",1,ad,True
330,[3] Charles Blundell and Yee Whye Teh. 2013. Bayesian hierarchical community discovery. In Advances in Neural Information Processing Systems. 1601­1609.,0,,False
331,"[4] Charles Blundell, Yee Whye Teh, and Katherine A Heller. 2012. Bayesian rose trees. arXiv preprint arXiv:1203.3468 (2012).",0,,False
332,"[5] Huanhuan Cao, Daxin Jiang, Jian Pei, Enhong Chen, and Hang Li. 2009. Towards context-aware search by learning a very large variable length hidden markov model from search logs. In Proceedings of the 18th international conference on World wide web. ACM, 191­200.",0,,False
333,"[6] Lara D Catledge and James E Pitkow. 1995. Characterizing browsing strategies in the World-Wide Web. Computer Networks and ISDN systems 27, 6 (1995), 1065­1073.",0,,False
334,"[7] Shui-Lung Chuang and Lee-Feng Chien. 2002. Towards automatic generation of query taxonomy: A hierarchical query clustering approach. In Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on. IEEE, 75­82.",0,,False
335,"[8] Debora Donato, Francesco Bonchi, Tom Chi, and Yoelle Maarek. 2010. Do you want to take notes?: identifying research missions in Yahoo! search pad. In Proceedings of the 19th international conference on World wide web. ACM, 321­ 330.",1,Yahoo,True
336,"[9] Ahmed Hassan Awadallah, Ryen W White, Patrick Pantel, Susan T Dumais, and Yi-Min Wang. 2014. Supporting complex search tasks. In Proceedings of the",1,ad,True
337,"23rd ACM International Conference on Conference on Information and Knowledge Management. ACM, 829­838. [10] Daqing He, Ay¸se Go¨ker, and David J Harper. 2002. Combining evidence for automatic web session identi cation. Information Processing & Management 38, 5 (2002), 727­742. [11] Katherine A Heller and Zoubin Ghahramani. 2005. Bayesian hierarchical clustering. In Proceedings of the 22nd international conference on Machine learning. ACM, 297­304. [12] Wen Hua, Yangqiu Song, Haixun Wang, and Xiaofang Zhou. 2013. Identifying users' topical tasks in web search. In Proceedings of the sixth ACM international conference on Web search and data mining. ACM, 93­102. [13] Rosie Jones and Kristina Lisa Klinkner. 2008. Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs. In Proceedings of the 17th ACM conference on Information and knowledge management. ACM, 699­708. [14] Rosie Jones, Benjamin Rey, Omid Madani, and Wiley Greiner. 2006. Generating query substitutions. In Proceedings of the 15th international conference on World Wide Web. ACM, 387­396. [15] Alexander Kotov, Paul N Benne , Ryen W White, Susan T Dumais, and Jaime Teevan. 2011. Modeling and analysis of cross-session search tasks. In Proceedings",1,ad,True
338,"of the 34th international ACM SIGIR conference on Research and development in Information Retrieval. ACM, 5­14. [16] Dawn J Lawrie and W Bruce Cro . 2003. Generating hierarchical summaries for web searches. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 457­458. [17] Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, and Hongyuan Zha. 2014. Identifying and labeling search tasks via query-based hawkes processes. In",0,,False
339,"Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 731­740. [18] Zhen Liao, Yang Song, Li-wei He, and Yalou Huang. 2012. Evaluating the e ectiveness of search task trails. In Proceedings of the 21st international conference on World Wide Web. ACM, 489­498. [19] Xueqing Liu, Yangqiu Song, Shixia Liu, and Haixun Wang. 2012. Automatic taxonomy construction from keywords. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1433­ 1441. [20] Claudio Lucchese, Salvatore Orlando, Ra aele Perego, Fabrizio Silvestri, and Gabriele Tolomei. 2011. Identifying task-based sessions in search engine query logs. In Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 277­286. [21] Claudio Lucchese, Salvatore Orlando, Ra aele Perego, Fabrizio Silvestri, and Gabriele Tolomei. 2013. Discovering tasks from search engine query logs. ACM Transactions on Information Systems (TOIS) 31, 3 (2013), 14.",0,,False
340,"[22] Bonnie Ma Kay and Carolyn Wa ers. 2008. Exploring multi-session web tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1187­1196.",0,,False
341,"[23] Rishabh Mehrotra, Prasanta Bha acharya, and Emine Yilmaz. 2016. Characterizing users' multi-tasking behavior in web search. In Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval. ACM, 297­300.",0,,False
342,"[24] Rishabh Mehrotra and Emine Yilmaz. 2015. Terms, topics & tasks: Enhanced user modelling for be er personalization. In Proceedings of the 2015 International Conference on e eory of Information Retrieval. ACM, 131­140.",0,,False
343,"[25] Rishabh Mehrotra and Emine Yilmaz. 2015. Towards hierarchies of search tasks & subtasks. In Proceedings of the 24th International Conference on World Wide Web. ACM, 73­74.",0,,False
344,"[26] Qiaozhu Mei, Hui Fang, and ChengXiang Zhai. 2007. A study of Poisson query generation model for information retrieval. In Proceedings of the 30th annual",0,,False
345,"international ACM SIGIR conference on Research and development in information retrieval. ACM, 319­326. [27] Qiaozhu Mei, Dengyong Zhou, and Kenneth Church. 2008. ery suggestion using hi ing time. In Proceedings of the 17th ACM conference on Information and knowledge management. ACM, 469­478. [28] Dan Morris, Meredith Ringel Morris, and Gina Venolia. 2008. SearchBar: a search-centric web history for task resumption and information re- nding. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1207­1216. [29] David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: e",0,,False
346,"2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 100­108. [30] Brendan O'Connor, Michel Krieger, and David Ahn. 2010. TweetMotif: Exploratory Search and Topic Summarization for Twi er.. In ICWSM. 384­385. [31] Pavel Pecina. 2010. Lexical association measures and collocation extraction. Language resources and evaluation 44, 1-2 (2010), 137­158. [32] Eran Segal and Daphne Koller. 2002. Probabilistic hierarchical clustering for biological data. In Proceedings of the sixth annual international conference on Computational biology. ACM, 273­280. [33] Craig Silverstein, Hannes Marais, Monika Henzinger, and Michael Moricz. 1999. Analysis of a very large web search engine query log. In ACm SIGIR Forum, Vol. 33. ACM, 6­12. [34] Adish Singla, Ryen White, and Je Huang. 2010. Studying trail nding algorithms for enhanced web search. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval. ACM, 443­450. [35] Amanda Spink, Sherry Koshman, Minsoo Park, Chris Field, and Bernard J Jansen. 2005. Multitasking web search on vivisimo. com. In Information Technology: Coding and Computing, 2005. ITCC 2005. International Conference on, Vol. 2. IEEE, 486­490. [36] Hongning Wang, Yang Song, Ming-Wei Chang, Xiaodong He, Ahmed Hassan, and Ryen W White. 2014. Modeling action-level satisfaction for search task satisfaction prediction. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval. ACM, 123­132. [37] Hongning Wang, Yang Song, Ming-Wei Chang, Xiaodong He, Ryen W White, and Wei Chu. 2013. Learning to extract cross-session search tasks. In Proceedings of the 22nd international conference on World Wide Web. ACM, 1353­1364. [38] Ryen W White, Wei Chu, Ahmed Hassan, Xiaodong He, Yang Song, and Hongning Wang. 2013. Enhancing personalized search by mining and modeling task behavior. In Proceedings of the 22nd international conference on World Wide Web. ACM, 1411­1420. [39] Hui Yang. 2012. Constructing task-speci c taxonomies for document collection browsing. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics, 1278­1289. [40] Hui Yang. 2015. Browsing hierarchy construction by minimum evolution. ACM Transactions on Information Systems (TOIS) 33, 3 (2015), 13. [41] Yongfeng Zhang, Min Zhang, Yiqun Liu, Chua Tat-Seng, Yi Zhang, and Shaoping Ma. 2015. Task-based recommendation on a web-scale. In Big Data (Big Data), 2015 IEEE International Conference on. IEEE, 827­836.",1,Tweet,True
347,294,0,,False
348,,0,,False
