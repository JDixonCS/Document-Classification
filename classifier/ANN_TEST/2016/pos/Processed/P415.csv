,sentence,label,data,regex
0,Evaluating Search Result Diversity using Intent Hierarchies,0,,False
1,"Xiaojie Wang1,2, Zhicheng Dou,1,2, Tetsuya Sakai3, and Ji-Rong Wen1,2,4 1School of Information, Renmin University of China",0,,False
2,"2Beijing Key Laboratory of Big Data Management and Analysis Methods, China 3Department of Computer Science and Engineering, Waseda University",0,,False
3,"4Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China 2{wangxiaojie,dou}@ruc.edu.cn, 3tetsuyasakai@acm.org, 4jirong.wen@gmail.com",0,,False
4,ABSTRACT,0,,False
5,"Search result diversification aims at returning diversified document lists to cover different user intents for ambiguous or broad queries. Existing diversity measures assume that user intents are independent or exclusive, and do not consider the relationships among the intents. In this paper, we introduce intent hierarchies to model the relationships among intents. Based on intent hierarchies, we propose several hierarchical measures that can consider the relationships among intents. We demonstrate the feasibility of hierarchical measures by using a new test collection based on TREC Web Track 2009-2013 diversity test collections. Our main experimental findings are: (1) Hierarchical measures are generally more discriminative and intuitive than existing measures using flat lists of intents; (2) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more improvement in discriminative power; (3) Hierarchical measures are more intuitive in terms of diversity or relevance. The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.",1,ad,True
6,Keywords,0,,False
7,Ambiguity; Diversity; Evaluation; Novelty; Hierarchy,1,Novelty,True
8,1. INTRODUCTION,1,DUC,True
9,"Nowadays, people tend to meet their daily information needs by typing keywords into search engines like Google and Bing. However, these keywords, also known as queries, are often ambiguous or broad [14, 15, 28, 10]. The queries usually have several interpretations or aspects, also known as subtopics or user intents. When users submit the same query to retrieval systems, they may want different information returned to fulfill their information needs. This poses",1,ad,True
10,Corresponding author,0,,False
11,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17 - 21, 2016, Pisa, Italy c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2911497",1,ad,True
12,a challenge to search engines when the targeted user intent cannot be known in advance.,1,ad,True
13,"To tackle this problem, a wide range of search result diversification algorithms ([1, 2, 5, 13, 18, 26, 27, 31, 25, 12, 11]) have been proposed over the past years. They aim at returning a diversified ranked document list that covers different intents of the queries. In the meantime, some researchers have introduced a variety of diversity measures, such as I-rec [22], -nDCG [9], Intent-Aware measures [1], D-measures [24], etc. These measures evaluate ranked lists in terms of both diversity and relevance, and indicate which diversification algorithms are better to use. Existing diversity measures assume that the users' information need could be represented by a single layer of intents and these intents are either independent or exclusive. However, some of the intents are not independent and are related to each other.",0,,False
14,"We use the query ""bobcat"", which is a topic (No. 77) in Text Retrieval Conference(TREC) 2010 Web Track [8], as an example. This query is ambiguous because of the polysemy of ""bobcat"": one interpretation is a company called ""bobcat company"" whose core business is about tractors; another interpretation is a kind of wild animals called ""wild bobcat."" We show its official intents, marked by i1-i4, in Figure 1(a). The figure shows that except intent i2 that is about ""wild bobcat,"" the remaining ones, i1, i3, and i4, are all about ""bobcat company."" This indicates that i1, i3, and i4 are more related to each other, but are less related to i2. Even within the three intents about ""bobcat company,"" i1 and i3 are closer because they are about the trade involving tractors of the company, whereas i4 is about homepage the company. We argue that this kind of relationships among intents should be modeled when evaluating search result diversity. However, none of existing measures considers this.",1,TREC,True
15,"Specifically, we find two submitted runs for the query, cmuFuTop10D and THUIR10DvNov, in TREC Web Track 2010 diversity task. cmuFuTop10D covers i1, i3, and i4, while THUIR10DvNov covers i1, i2, and i4 in their top ten ranks. Since i1, i3, and i4 are all about ""bobcat company,"" cmuFuTop10D misses another interpretation of bobcat, i.e. ""wild bobcat,"" but THUIR10DvNov covers both interpretations. In this sense, the latter is more diversified but I-rec [22] treats them as equally good because they cover the same number of intents. Some other existing measures also have similar problems, which will be illustrated in Section 3.3.1. We think that this is due to their lack of recognition of the relationships among intents.",1,TREC,True
16,"In light of the above observation, we introduce intent hierarchies to represent the relationships among intents. We",0,,False
17,415,0,,False
18,"(a) Official intents of the query ""bobcat"".",0,,False
19,"(b) LEFT: Intent Hierarchies OIH and EIH. OIH is comprised of the solid boxes, whereas EIH includes both solid",0,,False
20,and dashed nodes. RIGHT: An example showing relevance assessments for the added nodes (under R in red) derived from relevance assessments for the official intents (under R in blue).,1,ad,True
21,"Figure 1: The official intents, original intent hierarchy (OIH), and extended intent hierarchy (EIH) of No. 77 query ""bobcat"" in TREC Web Track 2010.",1,TREC,True
22,design hierarchical measures using the intent hierarchies to solve the problems mentioned above. The main contributions of this paper are:,0,,False
23,"(1) To the best of our knowledge, this is the first work on modeling user intents as intent hierarchies and using the intent hierarchies for evaluating search result diversity.",0,,False
24,"(2) We propose hierarchical measures using intent hierarchies, including Layer-Aware measures, N-rec, LD-measures, LAD-measures, and HD-measures. We show several cases where hierarchical measures outperform existing measures in terms of discriminative power and intuitiveness.",0,,False
25,"(3) We present a method for creating intent hierarchies from existing diversity test collections, and reusing the relevance assessments. We create a new dataset based on the TREC Web Track 2009-2013 diversity test collections. The new dataset can be assessed online 1.",1,TREC,True
26,"(4) We compare our measures with existing measures. We find that (i) Hierarchical measures are generally more discriminative and intuitive than existing measures, especially when using the intent hierarchies whose leaf nodes have the same depth; (ii) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more improvement in discriminative power; (iii) The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.",0,,False
27,"The remainder of this paper is organized as follows. Section 2 describes some existing diversity measures and the methods for testing evaluation measures. In Section 3, we introduce intent hierarchies, and our method for creating a new test collection based on TREC Web Track 2009-2013 diversity test collections. We then propose several new diversity measures that can utilize the intent hierarchies. Section 4 describes experimental results and analysis. We conclude our work in Section 5.",1,TREC,True
28,2. RELATED WORK,0,,False
29,"Given a query q, most existing measures evaluate a ranked document list by modeling users' information need as a flat list of intents {i}. Some measures can handle intent probability P r(i|q) and graded relevance assessments but some cannot. In this section, we briefly summarize the previous work on designing and testing diversity measures.",1,ad,True
30,1http://www.playbigdata.com/dou/heval/,0,,False
31,2.1 Diversity Measures,0,,False
32,2.1.1 Intent Recall,0,,False
33,"Intent recall(I-rec) [22], also known as subtopic recall [30]",0,,False
34,"is the proportion of intents covered by a ranking list. Let dr denote the document at rank r, and let I(dr) denote the set of intents to which document dr is relevant. Then, I-rec for a certain cutoff K can be expressed as:",0,,False
35,I -rec@K,0,,False
36,",",0,,False
37,|,0,,False
38,K,0,,False
39,"r,1",0,,False
40,I (dr )|,0,,False
41,(1),0,,False
42,|{i}|,0,,False
43,"Note that I-rec does not take the positions of relevant documents into account, and cannot handle intent probability and graded relevance assessments.",1,ad,True
44,2.1.2 -nDCG,0,,False
45,"In order to balance both relevance and diversity of ranked lists, -nDCG [9] is defined as:",0,,False
46,"-nDCG@K ,  K rK r,,11NNGG((rr))//lloogg((rr++11))",0,,False
47,(2),0,,False
48,"N G(r) ,",0,,False
49,Ji(r)(1 - )Ci(r-1),0,,False
50,i{i},0,,False
51,where N G(r) is N G(r) in the ideal ranked list; Ji(r) is,0,,False
52,"1othifertwheised;ocCuim(re)nt,atrrka,n1kJri",0,,False
53,is (k),0,,False
54,relevant to intent is the number of,0,,False
55,"i, and 0 relevant",0,,False
56,documents to intent i within top r; and  is a parameter.,0,,False
57,-nDCG tends to disregard unpopular intents and hence can,0,,False
58,be counterintuitive sometimes [24].,0,,False
59,2.1.3 Intent-Aware measures,0,,False
60,"Intent-Aware measures (IA measures) [1] is a general framework to evaluate ranked document lists. Assuming that i{i} P r(i|q) ,"" 1, M -IA can be computed as:""",0,,False
61,"M -IA@K ,",0,,False
62,P r(i|q)Mi@K,0,,False
63,(3),0,,False
64,i{i},0,,False
65,"where Mi is the per-intent version of measure M. Measure M can be nDCG [16], ERR [4], nERR [7], etc.",0,,False
66,2.1.4 D-measures,0,,False
67,"D-measures [24] aim to boost intent recall, and to reward documents that are highly relevant to more popular intents. Assume that gi(r) is the gain value of the document at rank",0,,False
68,416,0,,False
69,"r for intent i, and gi(r) is calculated based on per-intent",0,,False
70,relevance assessments. Then the global gain at rank r is,0,,False
71,given by:,0,,False
72,"GG(r) ,",0,,False
73,P r(i|q)gi(r),0,,False
74,(4),0,,False
75,i{i},0,,False
76,Let global,0,,False
77,CGG(r) gain at,0,,False
78,",",0,,False
79,r,0,,False
80,"k,1",0,,False
81,"GG(k),",0,,False
82,"rank r. Further,",0,,False
83,which is the cumulative let GG(r) and CGG(r),0,,False
84,denote the global gain and the cumulative global gain re-,0,,False
85,spectively at rank r in the ideal ranked list. The ideal list is,0,,False
86,obtained by listing up all relevant documents in descending,0,,False
87,"order of global gains. Let J(r) , 1 if the document at rank r",0,,False
88,"iLserteCle(vra)nt,toarkn,y1",0,,False
89,"of the J (k),",0,,False
90,"intents {i}, which is the",0,,False
91,"and J(r) , 0 otherwise. number of relevant doc-",0,,False
92,uments within top r. D-nDCG and D-Q at document cutoff,0,,False
93,K are defined as:,0,,False
94,"D-nDCG@K , K rK r,,11GGGG((rr))//lloogg((rr++11))",0,,False
95,(5),0,,False
96,1,0,,False
97, K,0,,False
98,C(r) + CGG(r),0,,False
99,"D-Q@K ,",0,,False
100,J (r),0,,False
101,(6),0,,False
102,"min(K, R)",0,,False
103,r + CGG(r),0,,False
104,"r,1",0,,False
105,where R is the number of judged relevant documents. Then D-measure is defined as:,0,,False
106,"D-measure@K , I-rec@K + (1 - )D-measure@K (7)",0,,False
107,"where D-measure can be D-nDCG or D-Q, and  is a parameter controlling the tradeoff between diversity and relevance. D-measures are free of the under-normalization problem of -nDCG and IA measures.",1,ad,True
108,"The diversity measures mentioned above are widely used in several tasks of TREC Web Track 2 or NII Testbeds and Community for Information access Research (NTCIR) 3, but they do not take the relationships among intents into consideration, which is what we aim to deal with in this paper.",1,TREC,True
109,2.2 Measure Evaluation,0,,False
110,"Given a certain significance level, discriminative power measures the stability of measures across queries and experiments based on significance tests, e.g. paired bootstrap test [20], Tukey's Honestly Significant Differences(HSD) [3] test, etc. Discriminative power can be used to estimate the performance difference required to achieve statistical significance between two retrieval systems [21].",0,,False
111,"Concordance test [21] is proposed to quantify the intuitiveness of diversity measures. In concordance test, one or more gold standard measures are chosen and assumed to truly represent intuitiveness. Given two diversity measures M1 and M2, the relative intuitiveness of M1 (or M2) is measured in terms of preference agreement with the gold standard measures. The preference agreement is that M1 (or M2) agrees with the gold standard measure(s) about which one of two ranked lists should be preferred.",0,,False
112,"Rank correlation compares two rankings, which are two ranked system lists in our case. Kendall's  [17] is a widelyused statistic to measure rank correlation. However  lacks the property of top heaviness, which means the exchanges near the top of a ranked list and those near the bottom are treated equally, even though the swaps near the top is generally more important in the context of IR evaluation. ap [29] is proposed to deal with the problem. Note that  is symmetric but ap is not. However, a symmetric ap can",0,,False
113,2http://plg.uwaterloo.ca/~trecweb/ 3http://research.nii.ac.jp/ntcir/index-en.html,1,trec,True
114,"be obtained by averaging two ap values when each list is treated as the former one. Both  and ap range from -1, which implies two ranked lists perfectly disagree, to 1, which implies two ranked lists are identical.",0,,False
115,"In this paper, we use discriminative power, concordance test, and rank correlation to evaluate diversity measures.",0,,False
116,3. PROPOSED METHODS,0,,False
117,"In this section, we define two types of intent hierarchies to represent the relationships among user intents and discuss their properties. We then introduce our method for creating such intent hierarchies and obtaining relevance assessments for the intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Last, we propose several diversity measures based on intent hierarchies, and demonstrate that in some cases, the new measures outperform their corresponding existing measures.",1,TREC,True
118,3.1 Intent Hierarchies,0,,False
119,"Given a query q, the users' information need is represented as a set of intents {i}. We assume these intents cannot be further subdivided, and refer to them as atomic intents. We aim to build an intent hierarchy based on the semantic similarity or relatedness of the intents. The intent hierarchy should possess some basic properties as follows:",0,,False
120,"Property 1. The intent hierarchy is in a tree structure, where every child has only one parent.",0,,False
121,"Property 2. The root of intent hierarchy is denoted by q itself, which stands for the user's information need as a whole. The root is a dummy node only for the completeness of the tree, and is not considered in our measures.",0,,False
122,"Property 3. When q is broad, the intent hierarchy is built in such a way that a parent node refers to a more general concept than its children, and a child node refers to one aspect of its parent. When q is ambiguous, each child node of the root is one interpretation of the query, and each of its subtrees is built in the same way as a broad query.",1,ad,True
123,"Property 4. These atomic intents, i.e. {i}, correspond one to one with leaves of the intent hierarchy. This means the number of leaves in the intent hierarchy is the same as the number of the atomic intents.",0,,False
124,We call an intent hierarchy that satisfies the properties specified above is called an original intent hierarchy (OIH). OIH can be extended so as to satisfy an extra property as:,0,,False
125,"Property 5. These atomic intents are in the same layer of the intent hierarchy. In other words, all leaf nodes of the intent hierarchy have the same depth because the atomic intents correspond to leaves of the intent hierarchy (see Property 4).",0,,False
126,"An intent hierarchies that satisfies all five properties are called an extended intent hierarchy (EIH). If a query's OIH satisfies Property 5, then its EIH is the same as the OIH.",0,,False
127,"We consider the root of an intent hierarchy as the zeroth layer, the child nodes of the root as the first layer and so forth. If an intent hierarchy only has the zeroth layer and the first layer, the height of the intent hierarchy is one. In the paper, a single-layer intent hierarchy refers to an intent hierarchy whose height is one, while a multilayer intent hierarchy refers to that whose height is greater than one.",0,,False
128,417,0,,False
129,3.2 Creating Intent Hierarchies,0,,False
130,"In this paper, we create intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Note that for each query in TREC Web Track 2010-2013, the description of its first intent is the same as the description of the query itself. We find that although the descriptions are the same, if a query has several different interpretations, the first intent is just one of these interpretations. A query's first intent does not refer to a more general concept than the other intents. So we do not treat the first intent differently.",1,TREC,True
131,"We use the official intents as atomic intents to avoid reassessing relevance of the documents. First we create original intent hierarchies (OIH) by manually grouping the official intents based on their semantic similarity or relatedness. Then, we extend them to extended intent hierarchies (EIH). Figure 1 illustrates how we create OIH and EIH for the query ""bobcat"" in TREC 2010 Web Track. It can be seen from Figure 1(a) that this query has four official intents and intent i1 and i3 are related to the trade involving tractors of the ""bobcat company."" So we create a new node n1 that stands for ""bobcat tractors"" as their parent node. Similarly, n1 and i4 are related to ""bobcat company,"" hence we create another new node n2 representing ""bobcat company"" as their parent. Finally, since n2 (""bobcat company"") and i2 (""wild bobcat"") are two distinct interpretations of query ""bobcat,"" they are considered as the child nodes of the root node. The resultant OIH is shown in solid boxes in the left of Figure 1(b). Further, we extend the OIH by adding more child nodes to i2 and i4 to make sure that all the leaf nodes have the same height. The resultant EIH is shown in solid boxes plus dashed boxes in the left of Figure 1(b).",1,TREC,True
132,"For a leaf node, we use its original weight of the corresponding official intent as its initial weight. For an intermediate node, we set its original weight to the sum of its child node weights. We then normalize the weights for each layer to make sure that these weights sum to 1. For TREC Web Track 2009-2013 test collections, because of the lack of official intent weights, we assume that each official intent for a query is equally important.",1,TREC,True
133,"As for the OIH or EIH shown in Figure 1(b): (1) It is in a tree structure (Property 1); (2) Its root is query ""bobcat"" itself (Property 2); (3) The query is ambiguous, so the child nodes of root are its two different interpretations, i.e. ""bobcat company"" and ""wild bobcat."" A parent node refers to a more general concept than its children (Property 3), e.g. ""bobcat company"" is more general than ""bobcat company homepage;"" (4) The leaf nodes are exactly the official intents of query ""bobcat"" (Property 4). Further, the depth of all the leaf nodes in EIH is three (Property 5).",0,,False
134,"Note that we only have document relevance assessments for the original intents appeared in TREC Web Track diversity test collections. In other words, for the intent hierarchies we create, document relevance judgments are just available for their leaf intents. We do not have document relevance assessments for intermediate intents. As assessing document relevance is usually very time-consuming, it is not desirable to reassess the documents for intermediate nodes of the intent hierarchies. Fortunately, according to Property 3, a parent node of an intent hierarchy stands for a more general concept than its child nodes. Hence it is reasonable to assume that if a document is relevant to a node, it would be relevant to the node's parent. This means that we can derive relevance assessments for the intermediate nodes",1,TREC,True
135,"starting from the leaves. In this paper, we simply let:",0,,False
136,"Ld(n) , max Ld(c)",0,,False
137,(8),0,,False
138,cC(n),0,,False
139,"where Ld(n) is the relevance rating assigned to document d for node n, and C(n) is the set of child nodes of n.",0,,False
140,"We show an actual document (denoted by d in the following) from TREC Web Track 2010 diversity test collection in Figure 1(b). In the table, the officially provided relevance assessments are marked in blue, e.g. the relevance rating of d for i1 is 1. Firstly, node n1 has two child nodes, i1 and i3, and the relevance ratings of d for them are 1 and 0. According to Equation (8), the relevance rating of d for n1 is 1. Similarly, we can derive the relevance rating for n2 based on its child node i4 and n1. These derived relevance assessments are shown in red in the table of Figure 1(b).",1,TREC,True
141,"To conclude, we create a new dataset containing intent hierarchies by manually grouping the official intents from TREC Web track test collections. The good news is that we do not need to reassess document relevance with regards to the intent hierarchies. We directly leverage document relevance assessments for the leaf intents, and automatically assign relevance ratings for the intermediate intents. This also implies that when we want to create hierarchical intents for evaluating diversity, we just need to assess document relevance for the leaf nodes or atomic intents.",1,TREC,True
142,"The new test collection has 250 queries, and 105 topics have multilayer intent hierarchies. Most of the time of creating the new dataset is spent on grouping the original intents. On average, we spend about three minutes per query mainly in understanding the original intents with the assistance of search engines such as Bing and Google.",0,,False
143,3.3 Hierarchical Measures,0,,False
144,3.3.1 Layer-Aware measures,0,,False
145,"Given a query q and its intent hierarchy, our first proposal",0,,False
146,for evaluating a ranked list is to first evaluate the ranked,0,,False
147,"list for each layer using existing measures, then combine the",0,,False
148,"evaluation scores. Let H denote the height of the intent hierarchy, and let",0,,False
149,"L ,"" {l1, l2, ..., lH } denote its first layer to the last layer. We define Layer-Aware measures (LA measures) at document cutoff K as the follows.""",0,,False
150, H,0,,False
151,"M -LA@K , wi  Mi@K",0,,False
152,(9),0,,False
153,"i,1",0,,False
154,"Here,",0,,False
155,wi,0,,False
156,is,0,,False
157,the,0,,False
158,weight,0,,False
159,of,0,,False
160,layer,0,,False
161,"li,",0,,False
162,where,0,,False
163,H,0,,False
164,"i,1",0,,False
165,wi,0,,False
166,",",0,,False
167,"1,",0,,False
168,and Mi is the evaluation score of measure M by using the,0,,False
169,"intents of layer li. For example, ERR-IA-LA is computed as",0,,False
170,"follows: (1) For each layer, compute the per-layer scores of",0,,False
171,ERR-IA; (2) Compute the weighted average of the per-layer,0,,False
172,scores using Equation (9).,0,,False
173,We find that the combination of measures over layers of,0,,False
174,intent hierarchies could outperform the original measures,0,,False
175,"using a flat list of intents. We use the query ""defender"",",0,,False
176,"which is a topic (No. 20) in TREC Web Track 2009 [6], as",1,TREC,True
177,an example. We choose this query because it has a relatively,0,,False
178,simple intent hierarchy. Its extended intent hierarchy (EIH),0,,False
179,is shown in the left of Figure 2(b). Suppose we have three,0,,False
180,"documents, d1-d3, and each of them can be viewed as a",0,,False
181,ranked list containing only one document. Their relevance,0,,False
182,assessments for the EIH are displayed in blue in the right of,0,,False
183,418,0,,False
184,"(a) Official intents of the query ""defender"".",0,,False
185,"(b) LEFT: Intent Hierarchies OIH and EIH. OIH is comprised of the solid boxes, whereas EIH includes both solid and dashed nodes. RIGHT: 1st column: document IDs (d: the ideal one), each document is equal to a ranked list of length 1. 2nd to",0,,False
186,5th column (R and R ): relevance assessments for the official intents (in red) and derived relevance assessments for added,1,ad,True
187,"nodes (in blue). 6th to 12th column (S): the measures are computed at rank 1 (subscript 1 means only using the first layer of EIH and subscript 2 means only using the second layer. subscript O means using OIH and subscript E means using EIH.), e.g. d2 get 0.35 when using D-nDCG on the first layer of EIH. Note that the original D-nDCG is equal to D-nDCG2 and the original I-rec is equal to I-rec2.",0,,False
188,"Figure 2: The official intents, original intent hierarchy (OIH), and extended intent hierarchy (EIH) of No. 20 query ""defender"" in TREC Web Track 2009. In the right table, if two documents have the same scores under a measure (in green below), it means that this measure cannot tell which one is better, e.g. D-nDCG1@1 treats d2 and d3 as equally good, but d3 is better because of its relevance to an extra intent i5.",1,TREC,True
189,"Figure 2(b). Note that the nodes that receive no relevant documents within the documents are not displayed to save space. Assume d is the first document within the ideal rank list and it is relevant to every node displayed. In the right of Figure 2(b), D-nDCG1@1 is the evaluation score when only using the first layer of the EIH, D-nDCG2@1 means only using the second layer, and D-nDCG-LAE@1 is the average of D-nDCG1@1 and D-nDCG2@1. Note that the original D-nDCG is equal to D-nDCG2. We use the measures to score d1 to d3, which is equivalent of evaluating at document cutoff 1. We show the evaluation results in Figure 2(b), e.g. d2 gets 0.35 when using D-nDCG1@1.",0,,False
190,"We find that d1>d2,""d3 in terms of D-nDCG1@1, d1"",""d2>d3 in terms of D-nDCG2@1, whereas d1>d2>d3 in terms of D-nDCG-LAE@1. Here, """">"""" means the former document is preferred compared with the latter when evaluating them at rank 1, and """""","" means neither is preferred. The real preference should be d1>d2>d3. This is because (1) d1 is more diversified than d2 because d1 refers to two interpretations of query defender"""", i.e. """"windows defender"""" and """"defender arcade game online,"""" while d2 only refers to the former; (2) d2 is more diversified than d3 because d2 refers to two aspects of """"windows defender"""", i.e. """"windows defender homepage"""" and """"windows defender reports"""" while d3 just refers to the former. Here, only D-nDCG-LAE@1 is consistent with the real preference. D-nDCG1@1 fails to tell the difference between d2 and d3, whereas D-nDCG2@1 fails to tell the difference between d1 and d2. This indicates that the combination over layers has higher potential to reflect real user satisfaction than the use of a flat list of intents in some cases.""",1,ad,True
191,3.3.2 Node Recall,0,,False
192,"Given a query q, let V denote the nodes in its intent hierarchy except for its root. Let dr denote the document at",0,,False
193,"rank r, and let N (dr) denote the set of nodes in V to which dr is relevant. Given a document cutoff K, we define node recall (N -rec) as:",0,,False
194,N -rec@K,0,,False
195,",",0,,False
196,|,0,,False
197,K,0,,False
198,"r,1",0,,False
199,N,0,,False
200,(dr,0,,False
201,)|,0,,False
202,|V |,0,,False
203,(10),0,,False
204,which is the proportion of nodes in the hierarchy covered by the top K documents. N-rec is a natural generalization of I-rec when using the intent hierarchy rather than a flat list of intents. They both are rank-insensitive and cannot handle graded relevance assessments.,1,ad,True
205,"We use an example to show that N-rec is able to outperform I-rec in terms of discriminative power. In the right of Figure 2(b), I-rec1@1 means only using the first layer, I-rec2@1 means only using the second layer, and N-recE@1 means using the extended intent hierarchy (EIH) when computing N-rec. These measures are computed at rank 1. Note that the original I-rec is equal to I-rec2. We find that d1>d2,""d3 according to I-rec1@1, d1"",""d2>d3 according to I-rec2@1, whereas d1>d2>d3 according to N-recE@1. As we discussed in Section 3.3.1, The real preference should be d1>d2>d3. I-rec1@1 fails to tell the difference between d2 and d3, while I-rec2@1 fails to distinguish between d1 and d2. Only N-recE@1 can tell the difference between the three documents, and thus is more discriminative than I-rec.""",0,,False
206,"Another point worth noting is that the types of intent hierarchies are crucial to N-rec. In the right of Figure 2(b), N-recO@1 means using the original intent hierarchy (OIH) instead of EIH. We find that N-recO@1 cannot determine which one of d1 and d2 is better because they have exactly the same score. This indicates that using EIH has higher discriminative power than using OIH.",1,ad,True
207,"We aim to retrieve documents that cover as many nodes of intent hierarchies as possible. At the same time, we pre-",0,,False
208,419,0,,False
209,"fer the documents that are highly relevant to more popular nodes and layers. N-rec mainly rewards wide coverage of different nodes of intent hierarchies in the top ranks. In the following, we discuss some measures to complement N-rec.",0,,False
210,3.3.3 LD-measures,0,,False
211,"We use the leaf nodes of intent hierarchies to compute D-measures. Then, LD-measure is defined as:",0,,False
212,"LD-measure@K , N -rec@K + (1 - )D-measure@K (11)",0,,False
213,"where  is a parameter controlling the tradeoff between diversity and relevance. Since D-measures only use the leaves of intent hierarchies, LD-measures reward high relevance with more popular leaves, but do not reward high relevance with more popular intermediate nodes. Also, LD-measures cannot handle the weights of layers. To tackle these, we propose HD-measures and LAD-measures in the next section.",1,ad,True
214,3.3.4 HD-measures and LAD-measures,0,,False
215,"Inspired by D-measures, we define the global gain for an intent hierarchy at rank r as:",0,,False
216," H GGh(r) , wi  GGi(r)",0,,False
217,"i,1",0,,False
218,(12),0,,False
219,where wi is the gain for layer li,0,,False
220,weight of layer at rank r. Let,0,,False
221,li C,0,,False
222,and GGh,0,,False
223,"(Gr)G,i(r) irks,""t1hGeGghlo(bka),l""",0,,False
224,which is the cumulative global gain for the intent hierarchy,0,,False
225,"at rank r. Further, let GGh(r) and CGGh(r) denote the global gain and the cumulative global gain for the intent",0,,False
226,hierarchy at rank r in the ideal ranked list. The ideal list,0,,False
227,is obtained by listing up all the judged documents in de-,0,,False
228,scending order of global gains for the intent hierarchy. Let,0,,False
229,"J(r) ,"" 1 if the hierarchy, and""",0,,False
230,"document at rank r J(r) , 0 otherwise.",0,,False
231,"iLserteClev(ra)nt,totrkh,e1inJt(ekn)t.",0,,False
232,We define HD-nDCG and HD-Q at document cutoff K as:,0,,False
233,H D-nDC G@K,0,,False
234,",",0,,False
235,"K K r,1",0,,False
236,"r,1",0,,False
237,GGh(r)/ GGh(r)/,0,,False
238,log(r log(r,0,,False
239,+ +,0,,False
240,1) 1),0,,False
241,(13),0,,False
242,H D-Q@K,0,,False
243,",",0,,False
244,"1 min(K, R)",0,,False
245, K,0,,False
246,"r,1",0,,False
247,J,0,,False
248,(r),0,,False
249,C,0,,False
250,(r) + CGGh(r) r + CGGh(r),0,,False
251,(14),0,,False
252,where R is the number of judged documents relevant to the,0,,False
253,intent hierarchy. We define HD-measure as:,0,,False
254,"HD-measure@K , N -rec@K +(1-)HD-measure@K (15)",0,,False
255,"where HD-measure can be HD-nDCG or HD-Q, and  is a parameter controlling the tradeoff between diversity and relevance. Besides, We define LAD-measure as:",1,ad,True
256,"LAD-measure@K , N -rec@K + (1 - )D-measure-LA@K",0,,False
257,(16),0,,False
258,"where  is a parameter balancing diversity with relevance,",0,,False
259,and D-measure-LA is the LA version of D-measure.,0,,False
260,"To measure the relevance of ranked lists, HD-measures",0,,False
261,"use HD-measures, while LAD-measures use D-measures-LA.",0,,False
262,HD-measures and D-measures-LA reward high relevance to,0,,False
263,"more popular nodes, and can handle layer weights. The",0,,False
264,difference between them is what to combine over layers:,0,,False
265,HD-measures combine the global gain for each layer while,0,,False
266,D-measures-LA combine D-measures for each layer. Take,0,,False
267,HD-nDCG and D-nDCG-LA as an example:,0,,False
268,H D-nDC G@K,0,,False
269,",",0,,False
270,"K Kr,1",0,,False
271,"r,1",0,,False
272,"[[ HiHi,,11",0,,False
273,wi wi,0,,False
274, GGi(r)]/ log2 (r + 1)  GGi (r)]/ log2 (r + 1),0,,False
275," H D-nDCG-LA@K , wi  D-nDCGi@K",0,,False
276,"i,1",0,,False
277,"where GGi(r) is the global gain for layer li at rank r, and D-nDCGi means only using the nodes of layer li.",0,,False
278,Figure 3:,0,,False
279,"Relationships of D-measures,",0,,False
280,"LD-measures, HD-measures, and LAD-measures.",0,,False
281,3.3.5 Summarization,0,,False
282,"Since our measures use intent hierarchies, we call them hierarchical measures. Each of D-measures, LD-measures, HD-measures and LAD-measures is a linear combination of two measures: one measure mainly rewards the diversity of ranked lists, whereas another measure mainly rewards the relevance. We show their relationships in Figure 3. It can be seen that (1) To reward the diversity, LD-measures, HD-measures and LAD-measures use the whole intent hierarchy, whereas D-measures only use the leaf nodes; (2) To reward the relevance, HD-measures and LAD-measures use the whole intent hierarchy, whereas D-measures and LD-measures only use the leaf nodes.",0,,False
283,4. EXPERIMENTS,0,,False
284,4.1 Settings,0,,False
285,"We experiment with the proposed measures on the TREC Web Track 2009-2013 diversity test collections and the new test collection mentioned in Section 3.2. The new test collection has two types of intent hierarchies, i.e. the original intent hierarchies (OIH), and the extended intent hierarchies (EIH). The results of our measures using OIH are different from those using EIH. In the following, subscript O means using the OIH, while subscript E means using the EIH.",1,TREC,True
286,"We use uniform probabilities for official intents like in TREC Web Track 2009-2013 diversity task. We use uniform layer weights when computing our measures, and leave the investigation of nonuniform weights to future. Unless stated otherwise, we use document cutoff K ,"" 20 for all measures, and  "","" 0.5 in Equation (7, 11, 15, and 16).""",1,TREC,True
287,4.2 Discriminative Power Results,0,,False
288,"Following the previous work [19, 20, 23, 24, 21], we use the paired bootstrap test and set B ,"" 1, 000 (B is the number of bootstrap samples). When the queries have single-layer intent hierarchies: (1) LA measures are reduced to their corresponding existing measures. For example, D-measures-LA are reduced to D-measures; (2) LD-measures, HD-measures, and LAD-measures are reduced to D-measures. We conduct the experiments as follows: (1) Sampling 20 submitted runs every year (2009-2013), which produces 950 pairs of""",0,,False
289,420,0,,False
290,Table 1: Discriminative power and performance  of diversity measures based on the paired bootstrap test at,0,,False
291," , 0.05. The leftmost column shows existing measures' results; the middle column shows their corresponding",0,,False
292,LA measures' results using original intent hierarchies (denoted by subscript O); the rightmost column shows,0,,False
293,their corresponding LA measures' results using extended intent hierarchies (denoted by subscript E). For,0,,False
294,"each row, the greatest value is in bold.",0,,False
295,(a) 250 queries in TREC Web Track 2009-2013,1,TREC,True
296,existing measures,0,,False
297,measures based on OIH,0,,False
298,measures based on EIH,0,,False
299,measure disc.power required ,0,,False
300,measure disc.power required ,0,,False
301,measure disc.power required ,0,,False
302,I-rec -nDCG ERR-IA nDCG-IA,0,,False
303,Q-IA D-nDCG,0,,False
304,D-Q,0,,False
305,49.1% 56.8% 52.0% 53.4% 43.1% 55.1% 52.7%,0,,False
306,0.14,0,,False
307,I-rec-LAO,0,,False
308,48.5%,0,,False
309,0.13,0,,False
310,I-rec-LAE,0,,False
311,0.11,0,,False
312,-nDCG-LAO,0,,False
313,56.4%,0,,False
314,0.12,0,,False
315,-nDCG-LAE,0,,False
316,0.12,0,,False
317,ERR-IA-LAO,0,,False
318,51.1%,0,,False
319,0.14,0,,False
320,ERR-IA-LAE,0,,False
321,0.07,0,,False
322,nDCG-IA-LAO,0,,False
323,52.4%,0,,False
324,0.06,0,,False
325,nDCG-IA-LAE,0,,False
326,0.06,0,,False
327,Q-IA-LAO,0,,False
328,42.7%,0,,False
329,0.06,0,,False
330,Q-IA-LAE,0,,False
331,0.09,0,,False
332,D-nDCG-LAO,0,,False
333,54.4%,0,,False
334,0.10,0,,False
335,D-nDCG-LAE,0,,False
336,0.09,0,,False
337,D-Q-LAO,0,,False
338,52.7%,0,,False
339,0.09,0,,False
340,D-Q-LAE,0,,False
341,(b) 105 queries that have multilayer intent hierarchies (out of 250),0,,False
342,49.7% 56.0% 52.1% 53.5% 43.5% 55.3% 53.7%,0,,False
343,0.13 0.11 0.14 0.06 0.06 0.09 0.08,0,,False
344,I-rec -nDCG ERR-IA nDCG-IA,0,,False
345,Q-IA D-nDCG,0,,False
346,D-Q,0,,False
347,36.4% 38.7% 31.9% 29.9% 20.2% 38.9% 38.7%,0,,False
348,0.23 0.22 0.19 0.11 0.14 0.17 0.17,0,,False
349,I-rec-LAO -nDCG-LAO ERR-IA-LAO nDCG-IA-LAO,0,,False
350,Q-IA-LAO D-nDCG-LAO,0,,False
351,D-Q-LAO,0,,False
352,33.4% 37.8% 31.2% 29.2% 20.3% 36.4% 36.3%,0,,False
353,0.26 0.26 0.23 0.13 0.13 0.19 0.16,0,,False
354,I-rec-LAE -nDCG-LAE ERR-IA-LAE nDCG-IA-LAE,0,,False
355,Q-IA-LAE D-nDCG-LAE,0,,False
356,D-Q-LAE,0,,False
357,36.6% 37.9% 32.9% 32.3% 22.4% 39.7% 39.3%,0,,False
358,0.26 0.18 0.21 0.13 0.14 0.18 0.16,0,,False
359,Table 2: Discriminative power (shown in columns A),0,,False
360,and performance  (shown in columns B) of diver-,0,,False
361,sity measures ranked by their discriminative power,0,,False
362,"based on the paired bootstrap test at  , 0.05. Baseline measures are marked by .",0,,False
363,(a) 250 queries in TREC Web Track 2009-2013,1,TREC,True
364,measure A,0,,False
365,B,0,,False
366,measure A,0,,False
367,B,0,,False
368,HD-nDCGE 55.9% 0.11 HD-QE 53.4%,0,,False
369,0.09,0,,False
370,LD-nDCGO 55.5% 0.10 LAD-QO 53.4%,0,,False
371,0.09,0,,False
372,LD-nDCGE 55.3% 0.09 LD-QO 53.3%,0,,False
373,0.09,0,,False
374,LAD-nDCGE 55.2% 0.10 HD-QO 53.1% D-nDCG 55.1% 0.09 LAD-QE 52.9%,0,,False
375,0.09 0.10,0,,False
376,HD-nDCGO 54.7% 0.10 LAD-nDCGO 54.5% 0.10,0,,False
377,LD-QE 52.7% D-Q 52.7%,0,,False
378,0.09 0.09,0,,False
379,(b) 105 queries that have multilayer intent hierarchies (out of 250),0,,False
380,HD-nDCGE LD-nDCGE LAD-nDCGE,0,,False
381, D-nDCG,0,,False
382,LD-nDCGO LAD-nDCGO,0,,False
383,HD-nDCGO,0,,False
384,40.5% 40.0% 39.1% 38.9% 38.1% 36.8% 36.5%,0,,False
385,0.16 0.17 0.19 0.17 0.19 0.21 0.17,0,,False
386,LD-QE LAD-QE,0,,False
387,HD-QE  D-Q,0,,False
388,HD-QO LD-QO LAD-QO,0,,False
389,39.4% 39.4% 38.9% 38.7% 38.1% 37.3% 37.1%,0,,False
390,0.19 0.19 0.17 0.17 0.17 0.19 0.15,0,,False
391,"sampled runs in total; (2) With the 950 pairs of sampled runs, computing the discriminative power and performance  using all 250 queries in TREC Web Track 2009-2013 diversity test collections; (3) With the 950 pairs of sampled runs, computing the discriminative power and performance  using the 105 queries that have multilayer intent hierarchies. Performance  is the required value to achieve statistical significance, and is computed following [21]. The results are shown in Table 1 and Table 2.",1,TREC,True
392,"By comparing the discriminative power scores of existing measures and their corresponding LA measures based on OIH or EIH in each row of Table 1, we find that: (1) Except -nDCG-LA, LA measures using EIH are more discriminative than their corresponding existing measures, especially in the case of IA measures. For example, when experimenting with 105 queries that have multilayer intent hierarchies, Q-IA-LAE (22.4%) outperforms Q-IA (20.2%) in terms of discriminative power; (2) The measures using OIH are less discriminative than the measures using EIH. For example, nDCG-IA-LAO is 29.2% while nDCG-IA-LAE is 32.3% when experimenting with 105 queries that have multilayer intent hierarchies.",0,,False
393,"By comparing the discriminative power results of D-measures, LD-measures, HD-measures, and LAD-measures (each block in Table 2), we find that: (1) The measures using EIH are generally more discriminative than the measures using OIH; (2) When using EIH, LD-measures, HD-measures and LAD-measures are better than (or at least as good as) D-measures in terms of discriminative power.",0,,False
394,"By comparing the results using all 250 queries in TREC Web Track 2009-2013 (shown in Table 1(a) or Table 2(a)) and the results only using the queries that have multilayer intent hierarchies (shown in Table 1(b) or Table 2(b)), we find that hierarchical measures have greater improvement of discriminative power than existing measures for queries that have multilayer intent hierarchies. This is reasonable because our measures have potential to recognize the difference between ranked lists by utilizing the hierarchies whereas existing measures cannot. Another justification is that our measures are equivalent to existing measures when the queries only have single-layer intent hierarchies.",1,TREC,True
395,"The above observations suggest that it is preferable to use EIH when computing hierarchical measures. We think that the hierarchical measures using EIH have higher discriminative power than the hierarchical measures using OIH. For example, Figure 2(b) shows that d1 is more diversified than d2 because d1 refers to two interpretations of the query, while d2 only refers to one of them. N-recE agrees with this but N-recO cannot tell which one is more diversified.",0,,False
396,4.3 Intuitiveness,0,,False
397,4.3.1 Difference between using OIH and EIH,0,,False
398,"The hierarchical measures using EIH are more intuitive than using OIH in terms of diversity. Following the previous work [21], we use I-rec as the gold standard measure for the diversity because it does not depend on intent hierarchies OIH and EIH. Table 3 shows the intuitiveness when using all the queries in TREC Web Track 2009-2013 diversity test collections. We find that for a document cutoff K ,"" 10, the hierarchical measures using EIH are more intuitive than using OIH. For a document cutoff K "","" 20, there is only one exception (LD-nDCG@20).""",1,TREC,True
399,"This is because the hierarchical measures using OIH may reward high relevance to some official intents, and fail to",0,,False
400,421,0,,False
401,Table 3: Intuitiveness based on preference agree-,0,,False
402,ment with I-rec. For each measure pair (using OIH,0,,False
403,"or EIH), the higher score is shown in bold and",0,,False
404,the numbers of disagreements between this pair are,0,,False
405,shown in parentheses below.,0,,False
406,"(a) Document cutoff K , 10. Gold standard measure: I-rec",0,,False
407,ERR-,0,,False
408,nDCG-,0,,False
409,Q-,0,,False
410,LD-,0,,False
411,HD-,0,,False
412,IA-LA,0,,False
413,IA-LA,0,,False
414,IA-LA,0,,False
415,nDCG,0,,False
416,nDCG,0,,False
417,OIH .663,0,,False
418,.624,0,,False
419,.653,0,,False
420,.802,0,,False
421,.025,0,,False
422,EIH .724,0,,False
423,.748,0,,False
424,.696,0,,False
425,.841,0,,False
426,.999,0,,False
427,(4973),0,,False
428,(5492),0,,False
429,(4660),0,,False
430,(2601),0,,False
431,(3421),0,,False
432,"(b) Document cutoff K , 20. Gold standard measure: I-rec",0,,False
433,OIH .692,0,,False
434,.656,0,,False
435,.677,0,,False
436,.821,0,,False
437,.823,0,,False
438,EIH .732,0,,False
439,.748,0,,False
440,.729,0,,False
441,.739,0,,False
442,.837,0,,False
443,(5362),0,,False
444,(6688),0,,False
445,(5273),0,,False
446,(2511),0,,False
447,(5329),0,,False
448,LADnDCG .753 .886 (4948),0,,False
449,.827 .840 (5645),0,,False
450,"reward wide coverage of the official intents. Take the OIH in Figure 2 as an example. Since we assume that the documents that are relevant to a node are relevant to its parent node, the relevance assessments for intent i1 or i5 are reflected in the relevance assessments for their parent node n1. Though the first layer of the OIH excludes i1 or i5, it indirectly considers them through their parent node n1. By including the other four intents, the first layer considers all six official intents, but the second layer of the OIH only has i1 or i5. When combining the two layers, the relevance assessments for i1 or i5 are considered twice, once in the first layer and again in the second layer. However, the relevance assessments for the other four intents are only considered once in the first layer. This means that when using the OIH, hierarchical measures mainly reward higher relevance to i1 and i5 than other intents. The EIH in Figure 2 solves this problem by extending i2, i3, i4, and i6 to the second layer so that every official intent can be considered in each layer when evaluating the ranking quality.",0,,False
451,"In the remaining part of the section, we will only report experimental results using EIH due to space limitation. In most experiments, using EIH yields higher discriminative power and intuitiveness than OIH.",0,,False
452,4.3.2 Intuitiveness of Hierarchical Measures,0,,False
453,"In Section 4.2, we show that LD-nDCGE, HD-nDCGE, and LAD-nDCGE are highly discriminative among hierarchical measures. In this section, we further compare their intuitiveness with some existing measures, including -nDCG, ERR-IA, and D-nDCG. We do the concordance test based on all the queries in TREC Web Track 2009-2013 diversity test collections, and show the results in Table 4. In Table 4(a) and Table 4(b), we use N-recE and Precision as the gold standard measure respectively, whereas in Table 4(c), both N-recE and Precision are used as the gold standard measures. We use N-recE as a gold standard measure in terms of the diversity because: (1) It is a simple binary measures; (2) It measures diversity better than I-rec, which is traditionally used as the gold standard measure for diversity.",1,TREC,True
454,"Table 4 shows that (1) In terms of the diversity, LD-nDCGE, HD-nDCGE, and LAD-nDCGE are more intuitive than existing measures. This is expected because these hierarchical measures directly depend on N-recE by means of Equation (11) and the like; (2) In terms of diversity, LD-nDCGE is most intuitive; (3) In terms of relevance, HD-nDCGE is most intuitive; (4) In terms of both diversity and relevance, LAD-nDCGE is the most intuitive measure.",0,,False
455,Table 4 shows that using the whole intent hierarchies instead of only using the leaf nodes can improve the intuitiveness of measures. HD-nDCGE and LAD-nDCGE use the,1,ad,True
456,Table 4: Intuitiveness based on preference agree-,0,,False
457,ment with gold standard measures. For each mea-,0,,False
458,"sure pair, the higher score is shown in bold and",0,,False
459,the numbers of disagreements between this pair are,0,,False
460,shown in parentheses below.,0,,False
461,"(a) Gold standard measure: N-recE (""diversity"")",0,,False
462,ERR-,0,,False
463,D-,0,,False
464,LD-,0,,False
465,-nDCG,0,,False
466,IA,0,,False
467,nDCG,0,,False
468,nDCGE,0,,False
469,.988/.362 .661/.983 .656/.986,0,,False
470,(14215),0,,False
471,(43908),0,,False
472,(44098),0,,False
473,ERR-IA,0,,False
474,-,0,,False
475,.577/.987 .573/.991,0,,False
476,-,0,,False
477,(56060),0,,False
478,(56011),0,,False
479,D-nDCG,0,,False
480,-,0,,False
481,-,0,,False
482,.428/.612,0,,False
483,-,0,,False
484,-,0,,False
485,(2124),0,,False
486,LD-nDCGE,0,,False
487,-,0,,False
488,-,0,,False
489,-,0,,False
490,-,0,,False
491,-,0,,False
492,-,0,,False
493,HD-nDCGE -,0,,False
494,-,0,,False
495,-,0,,False
496,-,0,,False
497,-,0,,False
498,-,0,,False
499,"(b) Gold standard measure: Precision (""relevance"")",0,,False
500,ERR-,0,,False
501,D-,0,,False
502,LD-,0,,False
503,-nDCG,0,,False
504,IA,0,,False
505,nDCG,0,,False
506,nDCGE,0,,False
507,.749/.345 .359/.746 .358/.749,0,,False
508,(14215),0,,False
509,(43908),0,,False
510,(44098),0,,False
511,ERR-IA,0,,False
512,-,0,,False
513,.348/.754 .346/.756,0,,False
514,-,0,,False
515,(56060),0,,False
516,(56011),0,,False
517,D-nDCG,0,,False
518,-,0,,False
519,-,0,,False
520,.488/.592,0,,False
521,-,0,,False
522,-,0,,False
523,(2124),0,,False
524,LD-nDCGE,0,,False
525,-,0,,False
526,-,0,,False
527,-,0,,False
528,-,0,,False
529,-,0,,False
530,-,0,,False
531,HD-nDCGE -,0,,False
532,-,0,,False
533,-,0,,False
534,-,0,,False
535,-,0,,False
536,-,0,,False
537,(c) Gold standard measures: N-recE and Precision,0,,False
538,ERR-,0,,False
539,D-,0,,False
540,LD-,0,,False
541,-nDCG,0,,False
542,IA,0,,False
543,nDCG,0,,False
544,nDCGE,0,,False
545,.738/.085 .156/.731 .154/.735,0,,False
546,(14215),0,,False
547,(43908),0,,False
548,(44098),0,,False
549,ERR-IA,0,,False
550,-,0,,False
551,.126/.742 .124/.747,0,,False
552,-,0,,False
553,(56060),0,,False
554,(56011),0,,False
555,D-nDCG,0,,False
556,-,0,,False
557,-,0,,False
558,.036/.217,0,,False
559,-,0,,False
560,-,0,,False
561,(2124),0,,False
562,LD-nDCGE,0,,False
563,-,0,,False
564,-,0,,False
565,-,0,,False
566,-,0,,False
567,-,0,,False
568,-,0,,False
569,HD-nDCGE -,0,,False
570,-,0,,False
571,-,0,,False
572,-,0,,False
573,-,0,,False
574,-,0,,False
575,HDnDCGE .663/.984 (44522) .578/.990 (56245) .700/.741 (3822) .898/.799 (2356) -,0,,False
576,HDnDCGE .358/.751 (44522) .345/.758 (56245) .502/.625 (3822) .523/.629 (2356) -,0,,False
577,HDnDCGE .159/.734 (44522) .127/.748 (56245) .267/.371 (3822) .432/.438 (2356) -,0,,False
578,LADnDCGE .661/.984 (44444) .577/.990 (56209) .677/.738 (3586) .895/.811 (2026) .724/.915 (330),0,,False
579,LADnDCGE .357/.751 (44444) .345/.758 (56209) .499/.625 (3586) .518/.633 (2026) .603/.552 (330),0,,False
580,LADnDCGE .157/.735 (44444) .127/.749 (56209) .247/.368 (3586) .424/.449 (2026) .370/.476 (330),0,,False
581,"whole intent hierarchy to measure both diversity and relevance of ranked lists. LD-nDCGE uses the whole intent hierarchy to measure the diversity but only uses the leaf nodes to measure the relevance. D-nDCG only uses the leaf nodes to measure the diversity and relevance. Table 4 shows that LD-nDCGE, HD-nDCGE and LAD-nDCGE are more intuitive than D-nDCG in terms of diversity. HD-nDCGE and LAD-nDCGE are more intuitive than D-nDCG and LD-nDCGE in terms of relevance. We get the same result when both diversity and relevance are considered.",0,,False
582,4.3.3 Case Studies,0,,False
583,"D-nDCG, LD-nDCGE, HD-nDCGE, and LAD-nDCGE are closely related (shown in Section 3.3.5 and Section 4.4). We examine their differences in terms of intuitiveness by looking at some real examples from the submitted runs in TREC Web Track 2009-2013 diversity task.",1,TREC,True
584,"Specifically, we select five pairs of real ranked lists from TREC Web Track diversity runs in Table 5, and refer to them as Case A-E. For example, Case A stands for two runs cmuFuTop10D and THUIR10DvNov for No. 77 query; The middle column shows the relevance assessments of the top ten documents in each run (e.g. the first document retrieved by cmuFuTop10D is relevant to intent i4 with a relevance rating 1); The last four columns show the 's for each query (e.g. score of cmuFuTop10D minus that of THUIR10DvNov) where arrows indicate which run has higher score under each measure. Note that in this section, the measures are computed for a document cutoff K , 10 because we only have space to show top 10 documents in Table 5. We categorize five cases into two classes from the viewpoint of diversity (Case A-C) or relevance (Case D-E).",1,TREC,True
585,422,0,,False
586,"Table 5: Five ranked list pairs from TREC Web Track 2009-2013 diversity test collections, document cutoff",1,TREC,True
587,"K , 10. 1st column: case IDs (query IDs). 2nd column: run IDs. 3rd column: number of official intents",0,,False
588,covered by each run. 4th column: number of nodes in extended intent hierarchies covered by each run. 5th,0,,False
589,column: relevance ratings for each intent at ranks 1-10. The rightmost column: performance differences,0,,False
590,using each measure and arrows point to its preferred run.,0,,False
591,A (77) B (77) C (77),0,,False
592,cmuFuTop10D THUIR10DvNov THUIR10DvQEW UAMSD10aSRfu msrsv2div qirdcsuog3,0,,False
593,D,0,,False
594,qutir11a,0,,False
595,(117),0,,False
596,uwBBadhoc,1,adhoc,True
597,E,0,,False
598,2011SiftR2,0,,False
599,(128),0,,False
600,UWatMDSdm,0,,False
601,1,0,,False
602,3 6 i4L1 3 8 i4L1 2 5 i4L1 26,0,,False
603,3 8 i4L1 3 7 i3L1,0,,False
604,3 5 i1L1 i2 L1,0,,False
605,3 5 i1L3 i2 L2 i3 L3,0,,False
606,3 5 i1L2 i2 L2 i3 L1,0,,False
607,3 5 i1L1 i2 L1,0,,False
608,2,0,,False
609,i2 L1 i3 L1 i1 L1,0,,False
610,3,0,,False
611,i2 L1 i3 L1,0,,False
612,Document rank,0,,False
613,(i: official intents),0,,False
614,4,0,,False
615,5,0,,False
616,6,0,,False
617,7,0,,False
618,i2 L1 i1 L1 i3 L1,0,,False
619,i1 L1 i3 L1,0,,False
620,i3 L1,0,,False
621,i2 L1 i1 L1,0,,False
622,i1 L2 i2 L1 i3 L1,0,,False
623,i1 L1 i3 L1 i4 L1 i2 L1,0,,False
624,i2 L1,0,,False
625,i1 L1 i3 L1,0,,False
626,i1 L2 i2 L2,0,,False
627,i1 L2 i3 L2,0,,False
628,i1 L1 i3 L1,0,,False
629,i1 L1,0,,False
630,i1 L2 i2 L2,0,,False
631,8,0,,False
632,i1 L1 i1 L3 i2 L1,0,,False
633,9,0,,False
634,i2 L1 i3 L1 i2 L1 i2 L1,0,,False
635,10 i1 L1 i2 L1,0,,False
636,i2 L1,0,,False
637,i2 L1,0,,False
638,i1 L1 i2 L2 i3 L1,0,,False
639,i1 L2 i2 L2,0,,False
640, in DnDCG 0.0013  0.0300  -0.0329 ,0,,False
641,-0.0030 ,0,,False
642,0.0087 ,0,,False
643, in LDnDCGE,0,,False
644,-0.1098  -0.0256  0.0226 ,0,,False
645, in HDnDCGE,0,,False
646,-0.0977  0.0011  -0.0115 ,0,,False
647, in LADnDCGE,0,,False
648,-0.0988  -0.0019  -0.0085 ,0,,False
649,-0.0030 ,0,,False
650,0.0171 ,0,,False
651,0.0148 ,0,,False
652,0.0087 ,0,,False
653,-0.0005 ,0,,False
654,0.0004 ,0,,False
655,"In Case A, we argue that D-nDCG is less intuitive than the other three. THUIR10DvNov covers both ""bobcat company"" and ""wild bobcat"" while cmuFuTop10D only covers the former (Please refer to the detailed description for the official intents of No. 77 query shown in Figure 1) although both runs cover three leaf intents. In this sense, THUIR10DvNov is more diversified than cmuFuTop10D and should be preferred. Note that this is also a case where I-rec cannot tell which run is better but N-recE can. The rightmost column of Table 5 shows that only D-nDCG disagrees with this intuition. In Case B, we argue that D-nDCG and HD-nDCGE are less intuitive than the other two. Similar to Case A, UAMSD10aSRfu covers both ""bobcat company"" and ""wild bobcat,"" whereas THUIR10DvQEW fails to cover the latter. So UAMSD10aSRfu should be preferred, and only LAD-nDCGE and LD-nDCGE agree with this. In Case C, we argue that LD-nDCGE is the most intuitive among the four measures. In this case, both msrsv2div and qirdcsuog3 cover ""bobcat company"" and ""wild bobcat"". However, Figure 1 shows that msrsv2div covers both ""bobcat tractors"" and ""bobcat company homepage,"" which are sub intents of ""bobcat company,"" while qirdcsuog3 does not cover ""bobcat company homepage."" Because of this, msrsv2div should be preferred and only LD-nDCGE agrees with this.",0,,False
656,"In summary, from the viewpoint of diversity, LD-nDCGE is the most intuitive measure. HD-nDCGE is less intuitive than LAD-nDCGE, but is more intuitive than D-nDCG.",0,,False
657,"The two runs in Case D and in Case E have the same I-rec and N-recE, hence the measures' preference is determined by their Precision part (e.g. D-nDCG if it is D-nDCG, and HD-nDCGE if it is HD-nDCGE). In Case D, we argue that D-nDCG and LD-nDCGE are less intuitive than the other two. No matter whether measuring by I-rec or by N-recE, qutir11a and uwBBadhoc are equally good in terms of diversity. However, qutir11a should be preferred because its top ten documents are all relevant, whereas uwBBadhoc only has three. From the rightmost column of Table 5, we find that D-nDCG and LD-nDCGE fail to reflect this. In Case E, we argue that HD-nDCGE is the most intuitive among the four measures. UWatMDSdm should be preferred because it returns much more relevant documents than 2011SiftR2. In this case, only HD-nDCGE successfully recognizes this.",1,adhoc,True
658,Table 6: Kendall's  / Symmetric ap by averaging over TREC Web track 2009-2013. Values greater,1,TREC,True
659,than .950 are shown in bold.,0,,False
660,(a) 250 queries in TREC Web Track 2009-2013,1,TREC,True
661,ERR-,0,,False
662,D-,0,,False
663,LD-,0,,False
664,HD-,0,,False
665,LAD-,0,,False
666,-nDCG,0,,False
667,IA,0,,False
668,nDCG,0,,False
669,nDCGE,0,,False
670,nDCGE,0,,False
671,nDCGE,0,,False
672,.923/.870 .840/.796 .845/.796 .843/.792 .844/.793,0,,False
673,ERR-IA,0,,False
674,-,0,,False
675,.772/.699 .780/.706 .779/.704 .779/.706,0,,False
676,D-nDCG,0,,False
677,-,0,,False
678,-,0,,False
679,.976/.959 .976/.957 .977/.960,0,,False
680,LD-nDCGE,0,,False
681,-,0,,False
682,-,0,,False
683,-,0,,False
684,.991/.988 .995/.993,0,,False
685,HD-nDCGE -,0,,False
686,-,0,,False
687,-,0,,False
688,-,0,,False
689,.995/.994,0,,False
690,(b) 105 queries that have multilayer intent hierarchies (out of 250),0,,False
691,ERR-,0,,False
692,D-,0,,False
693,LD-,0,,False
694,HD-,0,,False
695,LAD-,0,,False
696,-nDCG,0,,False
697,IA,0,,False
698,nDCG,0,,False
699,nDCGE,0,,False
700,nDCGE,0,,False
701,nDCGE,0,,False
702,.872/.802 .812/.747 .821/.755 .821/.758 .822/.759,0,,False
703,ERR-IA,0,,False
704,-,0,,False
705,.701/.609 .714/.624 .712/.626 .714/.628,0,,False
706,D-nDCG,0,,False
707,-,0,,False
708,-,0,,False
709,.964/.941 .959/.933 .958/.932,0,,False
710,LD-nDCGE,0,,False
711,-,0,,False
712,-,0,,False
713,-,0,,False
714,.984/.977 .986/.981,0,,False
715,HD-nDCGE -,0,,False
716,-,0,,False
717,-,0,,False
718,-,0,,False
719,.996/.995,0,,False
720,"Generally, from the viewpoint of relevance, LAD-nDCGE is more intuitive than LD-nDCGE. LAD-nDCGE is able to measure the relevance of ranked lists more accurately by considering the whole intent hierarchy, and thus make the measures more consistent with Precision than LD-nDCGE.",0,,False
721,4.4 Rank Correlation Results,0,,False
722,"We compute Kendall's  and ap for different pairs of measures to check the correlation between these measures. Results are shown in Table 6. The table shows that: (1) LD-nDCGE, HD-nDCGE and LAD-nDCGE are less correlated to existing measures, especially when only using the queries that have multilayer intent hierarchies. This is because our measures are able to recognize the subtle difference between ranked lists when multilayer intent hierarchies are used, whereas the existing measures may not. This indicates that our measures are useful and could be supplementary to the existing measures; (2) LD-nDCGE, HD-nDCGE, as well as LAD-nDCGE are more correlated to D-nDCG than -nDCG and ERR-IA. This is because they are different kinds of extensions of D-nDCG. Similar to D-nDCG, they model diversity and relevance in different components separately. They yield the same evaluation results when the queries only have single-layer intent hierarchies. (3) LD-nDCGE and HD-nDCGE are less correlated. As discussed in 4.3, LD-nDCGE prefers highly diversified ranked lists, whereas HD-nDCGE prefers highly relevant ranked lists.",0,,False
723,423,0,,False
724,5. CONCLUSIONS AND FUTURE WORK,0,,False
725,"In this paper, we argued that user intents of a query could be hierarchical. We described the concept of hierarchical intents and proposed hierarchical measures that could work with intent hierarchies. We created a new test collection containing intent hierarchies based on the existing TREC Web Track 2009-2013 diversity test collections by grouping the official intents into original intent hierarchies and extending them to extended intent hierarchies. Our experimental results showed that our proposed hierarchical measures can be more discriminative than existing measures which use a flat list of intents and assume the independence among intents. We revealed that LD-nDCG should be used when the diversity of search results is more valued than the relevance, whereas HD-nDCG should be used when the relevance is more important. LAD-nDCG is a better choice when both diversity and relevance are important.",1,TREC,True
726,"In this paper, we simply assume that the official intents provided in TREC Web Track 2009-2013 diversity test collections are atomic intents. It is possible that some of these intents can be further divided into sub intents. We will investigate this in the future.",1,TREC,True
727,6. ACKNOWLEDGMENTS,0,,False
728,"This work was supported by the National Key Basic Research Program (973 Program) of China under grant No. 2014CB340403, and the Fundamental Research Funds for the Central Universities, the Research Funds of Renmin University of China No. 15XNLF03, the National Natural Science Foundation of China (Grant No. 61502501, 61502502, and 61502503)",0,,False
729,7. REFERENCES,0,,False
730,"[1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, 2009.",0,,False
731,"[2] J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR, 1998.",0,,False
732,"[3] B. A. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. TOIS, 2012.",0,,False
733,"[4] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In CIKM, 2009.",1,ad,True
734,"[5] H. Chen and D. R. Karger. Less is more: probabilistic models for retrieving fewer relevant documents. In SIGIR, 2006.",0,,False
735,"[6] C. L. Clarke, N. Craswell, and I. Soboroff. Overview of the trec 2009 web track. In TREC, 2009.",1,trec,True
736,"[7] C. L. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. A comparative analysis of cascade measures for novelty and diversity. In WSDM, 2011.",1,ad,True
737,"[8] C. L. Clarke, N. Craswell, I. Soboroff, and G. V. Cormack. Overview of the trec 2010 web track. In TREC, 2010.",1,trec,True
738,"[9] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Buttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In SIGIR, 2008.",1,Novelty,True
739,"[10] C. L. Clarke, M. Kolla, and O. Vechtomova. An effectiveness measure for ambiguous and underspecified queries. In ICTIR, 2009.",0,,False
740,"[11] V. Dang and B. W. Croft. Term level search result diversification. In SIGIR, 2013.",0,,False
741,"[12] V. Dang and W. B. Croft. Diversity by proportionality: an election-based approach to search result diversification. In SIGIR, 2012.",0,,False
742,"[13] Z. Dou, S. Hu, K. Chen, R. Song, and J.-R. Wen. Multi-dimensional search result diversification. In WSDM, 2011.",0,,False
743,"[14] Z. Dou, R. Song, and J.-R. Wen. A large-scale evaluation and analysis of personalized search strategies. In WWW, 2007.",0,,False
744,"[15] B. J. Jansen, A. Spink, and T. Saracevic. Real life, real users, and real needs: a study and analysis of user queries on the web. Information Processing & Management, 2000.",0,,False
745,"[16] K. Jarvelin and J. Kekalainen. Ir evaluation methods for retrieving highly relevant documents. In SIGIR, 2000.",0,,False
746,"[17] M. G. Kendall. A new measure of rank correlation. Biometrika, 1938.",0,,False
747,"[18] F. Radlinski and S. Dumais. Improving personalized web search using result diversification. In SIGIR, 2006.",1,ad,True
748,"[19] T. Sakai. Bootstrap-based comparisons of ir metrics for finding one relevant document. In AIRS, 2006.",0,,False
749,"[20] T. Sakai. Evaluating evaluation metrics based on the bootstrap. In SIGIR, 2006.",0,,False
750,"[21] T. Sakai. Evaluation with informational and navigational intents. In WWW, 2012.",0,,False
751,"[22] T. Sakai, N. Craswell, R. Song, S. Robertson, Z. Dou, and C.-Y. Lin. Simple evaluation metrics for diversified search results. In EVIA, 2010.",0,,False
752,"[23] T. Sakai and S. Robertson. Modelling a user population for designing information retrieval metrics. In EVIA, 2008.",0,,False
753,"[24] T. Sakai and R. Song. Evaluating diversified search results using per-intent graded relevance. In SIGIR, 2011.",1,ad,True
754,"[25] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting query reformulations for web search result diversification. In WWW, 2010.",0,,False
755,"[26] R. L. Santos, C. Macdonald, and I. Ounis. Selectively diversifying web search results. In CIKM, 2010.",0,,False
756,"[27] R. L. Santos, C. Macdonald, and I. Ounis. Intent-aware search result diversification. In SIGIR, 2011.",0,,False
757,"[28] C. Silverstein, H. Marais, M. Henzinger, and M. Moricz. Analysis of a very large web search engine query log. SIGIR Forum, 1999.",0,,False
758,"[29] E. Yilmaz, J. A. Aslam, and S. Robertson. A new rank correlation coefficient for information retrieval. In SIGIR, 2008.",0,,False
759,"[30] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond independent relevance: methods and evaluation metrics for subtopic retrieval. In SIGIR, 2003.",0,,False
760,"[31] X. Zhu, A. B. Goldberg, J. Van Gael, and D. Andrzejewski. Improving diversity in ranking using absorbing random walks. In HLT-NAACL, 2007.",0,,False
761,424,0,,False
762,,0,,False
