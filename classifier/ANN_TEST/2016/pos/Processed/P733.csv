,sentence,label,data,regex
0,A Simple Enhancement for Ad-hoc Information Retrieval via Topic Modelling,1,hoc,True
1,"Fanghong Jian1, Jimmy Xiangji Huang, Jiashu Zhao2, Tingting He3 and Po Hu3",0,,False
2,"Information Retrieval and Knowledge Management Research Lab 1National Engineering Research Center for E-Learning, 3School of Computer Science, Central China Normal University, Wuhan, China; 2School of Information Technology, York University, Toronto, Canada",1,ad,True
3,"jhuang@yorku.ca, jfhrecoba@mails.ccnu.edu.cn, jessie@cse.yorku.ca",0,,False
4,ABSTRACT,0,,False
5,"Traditional information retrieval (IR) models, in which a document is normally represented as a bag of words and their frequencies, capture the term-level and document-level information. Topic models, on the other hand, discover semantic topic-based information among words. In this paper, we consider term-based information and semantic information as two features of query terms and propose a simple enhancement for ad-hoc IR via topic modeling. In particular, three topic-based hybrid models, LDA-BM25, LDA-MATF and LDA-LM, are proposed. A series of experiments on eight standard datasets show that our proposed models can always outperform significantly the corresponding strong baselines over all datasets in terms of MAP and most of datasets in terms of P@5 and P@20. A direct comparison on eight standard datasets also indicates our proposed models are at least comparable to the state-of-the-art approaches.",1,ad,True
6,Keywords,0,,False
7,Probabilistic Model; Dirichlet Language Model; LDA,0,,False
8,1. INTRODUCTION,1,DUC,True
9,"Many traditional IR models are based on the assumption that query terms are independent of each other, where a document is represented as a bag of words. Nevertheless this assumption may not hold in practice. Each document may contain several different topics and terms appeared in the document might belong to different topics, which represent different semantic information. Many researchers have been working on term topic information in IR [1, 10, 15, 16]. However, the nature of the associations among query terms still awaits further study. Some cluster-based approaches consider each document has only one topic [10], which is not reasonable to model large collection of documents. Topicbased document representation is effective in the language modeling (LM) framework [1, 15, 16]. But there is no generality in BM25 [2, 6, 20] and MATF (Multi Aspect TF) [13] based frameworks.",1,ad,True
10,"In this paper, we present three hybrid models for enhanc-",0,,False
11,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",1,ad,True
12,"SIGIR '16, July 17-21, 2016, Pisa, Italy",0,,False
13,c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00,0,,False
14,DOI: http://dx.doi.org/10.1145/2911451.2914750,0,,False
15,"ing traditional IR model via topic modelling. In our proposed approach, term-based information and semantic information are considered as two features of query terms. Latent Dirichlet Allocation (LDA) [3] is utilized to combine these two features and enhance three well-known traditional IR models BM25 [2], MATF [13] and Dirichlet LM [18]. In particular, three hybrid models, denoted as LDA-BM25, LDA-MATF and LDA-LM, are proposed respectively. The main contributions of this paper are as follows. First we propose three simple but effective IR models by combining traditional IR models with topic model. Second we conduct extensive experiments to confirm the effectiveness of our proposed models.",1,ad,True
16,"The remainder of this paper is organized as follows. We describe the related work and propose three topic-based hybrid models for ad-hoc IR in Section 2 and 3 respectively. In Section 4, we set up our experimental environment on eight TREC collections. In Section 5, the experimental results are presented and discussed. Finally, we conclude our work briefly and present future research directions in Section 6.",1,ad-hoc,True
17,2. RELATED WORK,0,,False
18,"Since the 1990s, researchers started to investigate how to integrate term association into IR models [8, 12, 16, 19, 20]. The query-term associations have been modeled by different approaches according to the distance of the query terms in documents. For example, Buttcher et al. (2006) [4] used a proximity accumulator to associate each query term. Lv and Zhai (2009) [11] proposed a positional language model (PLM) that incorporated the term proximity in a modelbased approach using term-propagation functions. Metzler et al. (2005) [12] proposed a Markov Random Fields (MRF) model which modeled the joint distribution over queries and documents. Song et al. (2011) [14] proposed Proximity Probabilistic Model (PPM) which used a position-dependent term count to represent both the number of occurrences of a term and the term counts propagated from other terms. Recently, topic models have been widely used to explore latent term association in knowledge discovery and other related area. Liu and Croft (2004) [10] proposed cluster-based retrieval models under the language modeling framework, which were used to smooth the probabilities in the document model. In their approach, a document is supposed to contain only one topic, which is not reasonable to model large collection of documents. Azzopardi et al. (2004) [1] showed that it was effective to use the LDA model [3] to smooth the probabilities in the document model on several small collections. Wei and Croft (2006) [15] also discussed the applications of LDA in large collections, and presented a detailed evalua-",1,LM,True
19,733,0,,False
20,"tion of the effectiveness. Yi and Allan (2009) [17] explored the utility of Mixture of Unigrams (MU) model, LDA and Pachinko Allocation Model (PAM) [9] for IR. They showed that topic models were effective for document smoothing. More rigorous topic models like LDA provided gains over cluster-based models and more elaborate topic models that capture topic dependencies provided no additional gains. Although it is effective to integrate topic models into the language modeling framework, how to integrate topical information into other traditional IR models is not clear.",1,ad,True
21,3. OUR APPROACH,1,AP,True
22,"For enhancing performance, topic model is integrated into",0,,False
23,"traditional retrieval models. First, the latent semantic in-",1,ad,True
24,formation of query terms in a document is extracted via,0,,False
25,"topic modeling. Then, the term-based information is ob-",0,,False
26,tained through traditional retrieval models. The documents,1,ad,True
27,that are more related to the query according to both seman-,0,,False
28,tic topic-based information and term-based information are,0,,False
29,"boosted in the ranking process. For clarification, Table 1",0,,False
30,outlines the notations used throughout the paper.,0,,False
31,Notations,0,,False
32,c,0,,False
33,d,0,,False
34,q,0,,False
35,qi dl,0,,False
36,avdl,0,,False
37,N,0,,False
38,n,0,,False
39,tf,0,,False
40,qtf,0,,False
41,z,0,,False
42,Kt,0,,False
43,"p, w ,",0,,False
44,"wpm  ,l",0,,False
45,w,0,,False
46,"b, k1 , k3 µ",0,,False
47,", ",0,,False
48,Table 1: Notations,0,,False
49,Description,0,,False
50,collection document query query term length of document average document length number of indexed documents in collection number of indexed documents containing a term within-document term frequency within-query term frequency topic number of topics probability function,0,,False
51,weighting function parameter in BM25 Dirichlet prior in Dirichlet LM hyperparameter in LDA,1,LM,True
52,3.1 Topic-based Hybrid Model,0,,False
53,Traditional retrieval models only capture term-based in-,1,ad,True
54,"formation. On the other hand, topic models acquire seman-",0,,False
55,"tic information between words. In this paper, we propose",0,,False
56,enhanced retrieval models that consider not only term fre-,0,,False
57,"quency, document frequency and document length, but also",0,,False
58,term topics information. We treat term-based information,0,,False
59,and semantic topic-based information as two features for,0,,False
60,query terms. The enhanced retrieval models combine these,0,,False
61,two features.,0,,False
62,"Given a query q, for each term qi in query q, w(qi, d) is the",0,,False
63,enhanced weight for document d. In order to capture the two,0,,False
64,"kinds of information, we use a parameter  to balance their",0,,False
65,importance. So the weight of a query term for a document,0,,False
66,is as follows.,0,,False
67,"w(qi, d) ,"" (1 - ) · w(qi, d) +  · w(qi, d)""",0,,False
68,(1),0,,False
69,"where w(qi, d) represents the explicit term-based related information in traditional retrieval model for document d, w(qi, d) is the implicit semantic information in topic model. Finally, a document's weight for a query is given by the sum of its weight for each term in the query. When  equals to 0, the hybrid models become traditional IR models such as BM25 and LM. When  equals to 1, the hybrid models become topic models. Because traditional IR models and topic models are normalized independently, the value of  changes with different combinations. It is well known that BM25, MATF and Dirichlet LM are the state-of-the-art traditional IR models and LDA is a simple but effective topic model. Therefore, we use BM25, MATF and Dirichlet LM as the traditional models and we use LDA as the topic model.",1,ad,True
70,3.2 Topic Model,0,,False
71,"In general, topic model is used to capture latent seman-",0,,False
72,tic information of terms in document. There are a lot of,0,,False
73,"topic models, such as probabilistic Latent Semantic Index-",0,,False
74,"ing (pLSI) [7], LDA [3] and PAM [9]. LDA is a simple and",0,,False
75,"effective topic model, and is broadly used. In this paper, we",1,ad,True
76,use LDA as our topic model.,0,,False
77,LDA model can generate the probability of topics in a doc-,0,,False
78,"ument and the probability of words in a topic, which can ob-",0,,False
79,tain the generated probability of words in a document. We,0,,False
80,take the probability of a query term in a document as its,0,,False
81,implicit semantic information in the document. The proba-,0,,False
82,"bility is larger, the term is more related with the document.",0,,False
83,In order to be the same magnitude with weights in tradi-,1,ad,True
84,"tional models, the weight of a query term for a document in",0,,False
85,LDA uses log value of the generated probability as follows.,0,,False
86, Kt,0,,False
87,"w(qi, d) , log p(qi|d) , log  p(qi|z)p(z|d)",0,,False
88,(2),0,,False
89,"z,1",0,,False
90,The LDA model can not be solved by exact inference and use Gibbs Sampling for parameter estimation like in [5].,0,,False
91,3.3 Traditional Information Retrieval Models,1,ad,True
92,"Traditional information retrieval models are mainly classified into classic probabilistic model, vector space model and statistical language model. There are several well-known strong baselines in each class, considering BM25, MATF and Dirichlet LM respectively.",1,ad,True
93,"In BM25, the weight of a query term is related to its within-document term frequency and query term frequency. The corresponding weighting function is as follows.",0,,False
94,"w(qi, d) ,",0,,False
95,(k1 + 1)  tf K + tf,0,,False
96, log (N - n + 0.5)  (k3 + 1 )  qtf,0,,False
97,(n - 0.5),0,,False
98,k3 + qtf,0,,False
99,(3),0,,False
100,"where w is the weight of a query term, the kis are tuning constants and K equals to k1  ((1 - b) + b  dl/avdl).",0,,False
101,"In 2013, Jiaul H. Paik [13] proposed a novel TF-IDF term weighting scheme MATF that employed two different within document term frequency normalizations to capture two different aspects of term saliency. One component of the term frequency is effective for short queries, while the other performs better on long queries. The final weight is measured by taking a weighted combination of these components, which is determined on the basis of the length of the corresponding query. Experiments carried out on a set of news and web datasets show that MATF outperforms several wellknown state-of-the-art TF-IDF baselines with significantly large margin.",0,,False
102,"Dirichlet LM presented by Zhai and Lafferty in 2001 [18] used the likelihood probability of query terms in a document to rank relevance between query and document. In order to better computing, the weight of a query term uses the log value of the probability as follows.",1,LM,True
103,"w (qi , d) , log p(qi |d), log",0,,False
104,dl,0,,False
105,µ,0,,False
106,dl + µ pml (qi |d) + dl + µ pml (qi |c),0,,False
107,(4),0,,False
108,4. EXPERIMENTAL SETTING,0,,False
109,"We conduct experiments on eight standard collections, which include AP88-89 with queries 51-100, AP88-90 with queries 51-150, FBIS with queries 351-450, FT(91-94) with queries 301-400, LA with queries 301-400, SJMN(1991) with queries 51-150, WSJ(87-92) with queries 151-200 and WT2G with queries 401-450. These datasets are different in size and genre [15, 19]. Queries without judgments are removed.",1,AP,True
110,734,0,,False
111,BM25 LDA-BM25,0,,False
112,MATF LDA-MATF,0,,False
113,LM LDA-LM,1,LM,True
114,Eval Metric MAP P@5 P@20 MAP,1,MAP,True
115,P@5,0,,False
116,P@20,0,,False
117,MAP P@5 P@20 MAP,1,MAP,True
118,P@5,0,,False
119,P@20,0,,False
120,MAP P@5 P@20 MAP,1,MAP,True
121,P@5,0,,False
122,P@20,0,,False
123,AP88-89,1,AP,True
124,0.2710 0.4360 0.3860 0.3021* (+11.476%) 0.5020 (+15.138%) 0.4388* (+13.679%) 0.2771 0.4531 0.3980 0.3041* (+9.744%) 0.4898 (+8.100%) 0.4378* (+10.000%) 0.2672 0.4571 0.4041 0.2980* (+11.527%) 0.5102* (+11.617%) 0.4276* (+5.815%),0,,False
125,AP88-90,1,AP,True
126,0.2198 0.4566 0.3894 0.2617* (+19.064%) 0.5232* (+14.595%) 0.4505* (+15.693%) 0.2238 0.4707 0.4086 0.2617* (+16.935%) 0.5131 (+9.008%) 0.4465* (+9.276%) 0.2157 0.4465 0.4146 0.2560* (+18.683%) 0.5010* (+12.206%) 0.4414* (+6.464%),0,,False
127,FBIS,0,,False
128,0.2606 0.3735,0,,False
129,0.2685,0,,False
130,0.2661,0,,False
131,(+2.111%) 0.3679,0,,False
132,(-1.499%) 0.2691,0,,False
133,(+0.223%) 0.2553 0.3605 0.2673 0.2634*,0,,False
134,(+3.173%) 0.3580,0,,False
135,(-0.693%) 0.2784,0,,False
136,(+4.153%) 0.2525 0.3506 0.2500 0.2628*,0,,False
137,(+4.079%) 0.3630,0,,False
138,(+3.537%) 0.2599*,0,,False
139,(+3.960%),0,,False
140,FT,0,,False
141,0.2600 0.3726 0.2389 0.2769* (+6.500%) 0.3621 (-2.818%) 0.2416 (+1.130%) 0.2660 0.3789,0,,False
142,0.2426 0.2781* (+4.549%),0,,False
143,0.3621 (-4.434%),0,,False
144,0.2453,0,,False
145,(+1.113%) 0.2571 0.3684 0.2311 0.2774*,0,,False
146,(+7.896%) 0.3600,0,,False
147,(-2.280%) 0.2426*,0,,False
148,(+4.976%),0,,False
149,LA,0,,False
150,0.2490 0.3571 0.2194 0.2592* (+4.96%) 0.3673 (+2.856%) 0.2291* (+5.105%) 0.2502 0.3571 0.2240 0.2586* (+3.357%) 0.3694,0,,False
151,(+3.444%) 0.2337*,0,,False
152,(+4.330%) 0.2427 0.3429 0.2235,0,,False
153,0.2603* (+7.252%),0,,False
154,0.3694* (+7.728%),0,,False
155,0.2286 (+2.282%),0,,False
156,SJMN,1,SJMN,True
157,0.1965 0.3404 0.2564 0.2297* (+16.902%) 0.3809 (+11.889%) 0.2915 (+13.697%) 0.2095 0.3723 0.2809 0.2309* (+10.215%) 0.3915,0,,False
158,(+5.157%) 0.2989,0,,False
159,(+6.408%) 0.2009 0.3532 0.2697 0.2254*,0,,False
160,(+12.195%) 0.3830*,0,,False
161,(+8.437%) 0.2904*,0,,False
162,(+7.675%),0,,False
163,WSJ,0,,False
164,0.3156 0.5240 0.4410 0.3471* (+9.981%) 0.5520,0,,False
165,(+5.344%) 0.4640*,0,,False
166,(+5.215%) 0.3029 0.5240 0.3950 0.3343*,0,,False
167,(+10.366%) 0.5200,0,,False
168,(-0.763%) 0.4300*,0,,False
169,(+8.861%) 0.3047 0.5120 0.3910 0.3344*,0,,False
170,(+9.747%) 0.5200,0,,False
171,(+1.563%) 0.4320*,0,,False
172,(+10.486%),0,,False
173,WT2G,1,WT,True
174,0.3156 0.5280 0.3930 0.3230 (+2.345%) 0.5360,0,,False
175,(+1.515%) 0.4030,0,,False
176,(+2.545%) 0.3340 0.5240 0.4110 0.3393,0,,False
177,(+1.587%) 0.5360,0,,False
178,(+2.290%) 0.4150,0,,False
179,(+0.973%) 0.3118 0.5000 0.3920 0.3165*,0,,False
180,(+1.507%) 0.5080,0,,False
181,(+1.600%) 0.3950,0,,False
182,(+0.765%),0,,False
183,"Table 2: Comparison with baselines. The best result obtained on each dataset is in bold. ""*"" denotes statistically significant improvements over corresponding baselines (Wilcoxon signed-rank test with p < 0.05). The percentages below are the percentage improvement of proposed models over corresponding baselines.",0,,False
184,"For all test collections used, each term is stemmed by using Porter's English stemmer. Standard English stopwords are removed. The official TREC evaluation measure is used in our experiments, namely Mean Average Precision (MAP). To investigate top retrieved documents, P@5 and P@20 are also used for evaluation. All statistical tests are based on Wilcoxon Matched-pairs Signed-rank test.",1,TREC,True
185,"For fair comparisons, we use the following parameter settings for both the baselines and our proposed models, which are popular in the IR domain for building strong baselines. First, in BM25, setting k1, k3 and b to 1.2, 8 and 0.35 respectively gave the best MAP for most datasets in [20]. Second, in Dirichlet LM, µ ,"" 1000 was shown in [15] to achieve best MAP for most datasets. Finally, in LDA model, we use symmetric Dirichlet priors with  "", 50/Kt and  ,"" 0.01, which are common settings in the literature and shown in [15] that retrieval results were not very sensitive to the values of these parameters. The number of topics Kt is set to be 400 as recommended in [15].""",1,MAP,True
186,5. EXPERIMENTAL RESULTS,0,,False
187,5.1 Comparison with Baselines,0,,False
188,"We first investigate the performance of our proposed topicbased models compared with the corresponding strong baselines BM25, MATF and Dirichlet LM. The experimental results are presented in Table 2. As shown by the results, our proposed models outperform the corresponding baselines on almost all datasets in terms of MAP, P@5 and P@20. Statistically significant improvement can be observed on most of datasets in terms of MAP and P@20. According to the results in Table 2, each hybrid model has its advantage on some aspects. However, there is no single hybird model that can achieve the best performance on all the datasets.",1,LM,True
189,5.2 Parameter Sensitivity,0,,False
190,"An important issue that may affect the robustness of our proposed models is the sensitivity of their parameter  to retrieval performance. Since the weights of query terms in traditional retrieval models and topic model are normalized independently, the value of  reflects the influence of using topic-based model. Figure 1 plots the evaluation metrics MAP obtained by the proposed hybrid models over  values ranging from 0 to 1 on all the datasets. It is clear that hybrid models perform better than either traditional models",1,ad,True
191,"or topic model on all data sets. As we can see from Figure 1, our proposed models LDA-BM25, LDA-MATF and LDALM generally perform well over different datasets when  has a smaller value.",1,LM,True
192,"We also study the performance of our proposed topicbased models with different number of topics compared with the corresponding baselines in terms of MAP. In Figure 2, the traditional models are shown as straight lines since the performance does not change over the number of topics. All the results are presented in Figure 2, which shows that our proposed models with different number of topics outperform corresponding baselines in terms of MAP over all datasets. Figure 2 shows that the proposed hybrid models tend to perform better when the number of topics increases. When the number of topics reaches a certain value, the retrieval performance tends to become more stable. The performance tendency of our proposed models with different number of topics is surprisingly consistent on all the datasets. Similar trends for  and with different number of topics can also be observed in terms of P@5 and P@20.",1,MAP,True
193,5.3 Comparison with CRTER2 and LBDM,0,,False
194,"In addition, we compare our proposed models with two",1,ad,True
195,"state-of-the-art approaches. Zhao etc. [19, 20] showed that",0,,False
196,bigram cross term model (CRTER2) is at least comparable to,0,,False
197,major probabilistic proximity models PPM [14] and BM25TP,0,,False
198,"[4] in BM25-based framework. Xing and Allan [17], which",0,,False
199,"is most close to our proposed model LDA-LM, showed their",1,LM,True
200,LDA-based model (LBDM) [15] achieved the best performance,0,,False
201,in topic-based LM framework. So we make a direct compar-,1,LM,True
202,ison with CRTER2 and LBDM. The results in terms of MAP,1,MAP,True
203,"are presented in Table 3. """" denotes LDA-BM25 outper-",0,,False
204,"forms CRTER2, while """" denotes LDA-LM outperforms LBDM.",1,LM,True
205,"Among eight datasets, LDA-BM25 wins five times and LDA-",0,,False
206,"LM wins four times. By comparison, we can conclude that",1,LM,True
207,our proposed models LDA-BM25 and LDA-LM are at least,1,LM,True
208,comparable to the state-of-the-art models CRTER2 and LBDM.,0,,False
209,Table 3: Comparison with CRTER2 and LBDM,0,,False
210,AP88-89 AP88-90,1,AP,True
211,FBIS FT LA,0,,False
212,SJMN WSJ WT2G,1,SJMN,True
213,CRTER2 0.2789 0.2268 0.2738 0.2717 0.2604 0.2095 0.3406 0.3359,0,,False
214,LDA-BM25 0.3021 0.2617 0.2661 0.2769 0.2592 0.2297 0.3471 0.3230,0,,False
215,LBDM 0.3051 0.2535 0.2636 0.2750 0.2630 0.2234 0.3359 0.3108,0,,False
216,LDA-LM 0.2980 0.2560 0.2628 0.2774 0.2603 0.2254 0.3344 0.3165,1,LM,True
217,735,0,,False
218,MAP,1,MAP,True
219,MAP,1,MAP,True
220,0.32,0,,False
221,AP88-89,1,AP,True
222,0.3,0,,False
223,0.28,0,,False
224,0.26,0,,False
225,0.24,0,,False
226,0.22 0.2,0,,False
227,0.18 0,0,,False
228,0.28,0,,False
229,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
230,0.1,0,,False
231,0.2,0,,False
232,0.3,0,,False
233,0.4,0,,False
234,0.5,0,,False
235,0.6,0,,False
236,0.7,0,,False
237,0.8,0,,False
238,0.9,0,,False
239,1.0,0,,False
240,LA,0,,False
241,0.26,0,,False
242,0.24,0,,False
243,0.22,0,,False
244,0.2,0,,False
245,0.18,0,,False
246,0.16 0.14 0.12,0,,False
247,0,0,,False
248,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
249,0.1,0,,False
250,0.2,0,,False
251,0.3,0,,False
252,0.4,0,,False
253,0.5,0,,False
254,0.6,0,,False
255,0.7,0,,False
256,0.8,0,,False
257,0.9,0,,False
258,1.0,0,,False
259,MAP,1,MAP,True
260,MAP,1,MAP,True
261,0.28,0,,False
262,AP88-90,1,AP,True
263,0.26,0,,False
264,0.24,0,,False
265,0.22,0,,False
266,0.2,0,,False
267,0.18,0,,False
268,0.16 0,0,,False
269,0.24 0.23 0.22 0.21,0,,False
270,0.2 0.19 0.18 0.17 0.16 0.15,0,,False
271,0,0,,False
272,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
273,0.1,0,,False
274,0.2,0,,False
275,0.3,0,,False
276,0.4,0,,False
277,0.5,0,,False
278,0.6,0,,False
279,0.7,0,,False
280,0.8,0,,False
281,0.9,0,,False
282,1.0,0,,False
283,SJMN,1,SJMN,True
284,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
285,0.1,0,,False
286,0.2,0,,False
287,0.3,0,,False
288,0.4,0,,False
289,0.5,0,,False
290,0.6,0,,False
291,0.7,0,,False
292,0.8,0,,False
293,0.9,0,,False
294,1.0,0,,False
295,MAP,1,MAP,True
296,MAP,1,MAP,True
297,0.28 0.26 0.24 0.22,0,,False
298,0.2 0.18 0.16 0.14 0.12,0,,False
299,0.1 0.08,0,,False
300,0,0,,False
301,0.34 0.32,0,,False
302,0.3 0.28 0.26 0.24 0.22,0,,False
303,0.2 0.18 0.16,0,,False
304,0,0,,False
305,FBIS,0,,False
306,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
307,0.1,0,,False
308,0.2,0,,False
309,0.3,0,,False
310,0.4,0,,False
311,0.5,0,,False
312,0.6,0,,False
313,0.7,0,,False
314,0.8,0,,False
315,0.9,0,,False
316,1.0,0,,False
317,WSJ,0,,False
318,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
319,0.1,0,,False
320,0.2,0,,False
321,0.3,0,,False
322,0.4,0,,False
323,0.5,0,,False
324,0.6,0,,False
325,0.7,0,,False
326,0.8,0,,False
327,0.9,0,,False
328,1.0,0,,False
329,MAP,1,MAP,True
330,MAP,1,MAP,True
331,0.28 0.26 0.24 0.22,0,,False
332,0.2 0.18 0.16 0.14 0.12,0,,False
333,0.1 0,0,,False
334,FT,0,,False
335,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
336,0.1,0,,False
337,0.2,0,,False
338,0.3,0,,False
339,0.4,0,,False
340,0.5,0,,False
341,0.6,0,,False
342,0.7,0,,False
343,0.8,0,,False
344,0.9,0,,False
345,1.0,0,,False
346,WT2G,1,WT,True
347,0.3,0,,False
348,0.25,0,,False
349,0.2,0,,False
350,0.15 0.1,0,,False
351,0.05 0,0,,False
352,LDA-BM25 LDA-MATF LDA-LM,1,LM,True
353,0.1,0,,False
354,0.2,0,,False
355,0.3,0,,False
356,0.4,0,,False
357,0.5,0,,False
358,0.6,0,,False
359,0.7,0,,False
360,0.8,0,,False
361,0.9,0,,False
362,1.0,0,,False
363,Figure 1: Parameter sensitivity of  on all data sets,0,,False
364,0.315 0.31,0,,False
365,0.305 0.3,0,,False
366,0.295 0.29,0,,False
367,0.285 0.28,0,,False
368,0.275 0.27,0,,False
369,0.265 100,0,,False
370,200,0,,False
371,300,0,,False
372,0.265 0.26,0,,False
373,0.255,0,,False
374,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
375,AP88-89,1,AP,True
376,400,0,,False
377,500,0,,False
378,Number of topics,0,,False
379,LA,0,,False
380,600,0,,False
381,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
382,700,0,,False
383,800,0,,False
384,0.25,0,,False
385,0.245,0,,False
386,0.24 100,0,,False
387,200,0,,False
388,300,0,,False
389,400,0,,False
390,500,0,,False
391,Number of topics,0,,False
392,600,0,,False
393,700,0,,False
394,800,0,,False
395,MAP,1,MAP,True
396,MAP,1,MAP,True
397,0.27,0,,False
398,AP88-90,1,AP,True
399,0.26,0,,False
400,0.25 0.24 0.23,0,,False
401,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
402,0.22,0,,False
403,0.21 100,0,,False
404,0.245 0.24,0,,False
405,0.235 0.23,0,,False
406,0.225 0.22,0,,False
407,0.215 0.21,0,,False
408,0.205 0.2,0,,False
409,0.195 100,0,,False
410,200,0,,False
411,300,0,,False
412,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
413,200,0,,False
414,300,0,,False
415,400,0,,False
416,500,0,,False
417,Number of topics,0,,False
418,SJMN,1,SJMN,True
419,600,0,,False
420,400,0,,False
421,500,0,,False
422,Number of topics,0,,False
423,600,0,,False
424,700 700,0,,False
425,800 800,0,,False
426,MAP,1,MAP,True
427,MAP,1,MAP,True
428,0.275,0,,False
429,0.27,0,,False
430,0.265,0,,False
431,0.26,0,,False
432,0.255,0,,False
433,0.25 100,0,,False
434,0.35 0.345,0,,False
435,0.34 0.335,0,,False
436,0.33 0.325,0,,False
437,0.32 0.315,0,,False
438,0.31 0.305,0,,False
439,0.3 100,0,,False
440,200 200,0,,False
441,FBIS,0,,False
442,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
443,300,0,,False
444,400,0,,False
445,500,0,,False
446,Number of topics,0,,False
447,WSJ,0,,False
448,600,0,,False
449,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
450,300,0,,False
451,400,0,,False
452,500,0,,False
453,Number of topics,0,,False
454,600,0,,False
455,700 700,0,,False
456,800 800,0,,False
457,MAP,1,MAP,True
458,MAP,1,MAP,True
459,0.285 0.28,0,,False
460,0.275 0.27,0,,False
461,0.265 0.26,0,,False
462,0.255 100,0,,False
463,0.345 0.34,0,,False
464,0.335 0.33,0,,False
465,0.325 0.32,0,,False
466,0.315 0.31 100,0,,False
467,FT,0,,False
468,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
469,200,0,,False
470,300,0,,False
471,400,0,,False
472,500,0,,False
473,Number of topics,0,,False
474,WT2G,1,WT,True
475,600,0,,False
476,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,1,LM,True
477,200,0,,False
478,300,0,,False
479,400,0,,False
480,500,0,,False
481,Number of topics,0,,False
482,600,0,,False
483,700 700,0,,False
484,800 800,0,,False
485,Figure 2: Parameter sensitivity of the number of topics on all data sets,0,,False
486,MAP,1,MAP,True
487,MAP,1,MAP,True
488,6. CONCLUSIONS AND FUTURE WORK,0,,False
489,"In this paper, a simple enhancement for ad-hoc IR is proposed by combining traditional retrieval model and topic model. Specifically, we present three hybrid models LDABM25, LDA-MATF and LDA-LM for enhancing traditional IR models via topic modeling. These three models capture both term-based information and latent semantic topicbased information at the same time. Experimental results on eight standard datasets show that the proposed models are effective, and outperform the corresponding strong baselines on most of datasets in terms of MAP, P@5 and P@20. Meanwhile, our proposed models are at least comparable to the state-of-the-art CRTER2 and topic-based model LBDM. Additionally, we carefully analyze the influence of  to our proposed models and the performance of our proposed models with different number of topics.",1,ad-hoc,True
490,There are several interesting future research directions to further explore. We would like to study the optimal topic number on each dataset. It is also interesting to conduct an in-depth study on the combination traditional IR model with topic model and find the best combination. We also plan to evaluate our models on more datasets including some real datasets and apply our models into real world applications.,1,ad,True
491,7. ACKNOWLEDGMENTS,0,,False
492,"This research is supported by a Discovery grant from the Natural Sciences & Engineering Research Council (NSERC) of Canada, an NSERC CREATE award and also supported by the National Natural Science Foundation of China. We thank anonymous reviewers for their thorough comments.",1,ad,True
493,8. REFERENCES,0,,False
494,[1],0,,False
495,[2] [3] [4],0,,False
496,[5] [6],0,,False
497,[7] [8],0,,False
498,[9] [10] [11] [12] [13] [14] [15] [16],0,,False
499,[17],0,,False
500,[18] [19] [20],0,,False
501,"L. Azzopardi, M. Girolami, and C. J. Van Rijsbergen. Topic Based Language Models for ad hoc Information Retrieval. In Proceedings of the International Joint Conference on Neural Networks, pages 3281­3286, 2004.",1,ad,True
502,"M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker, and P. Williams. Okapi at TREC-5. In Proc. of TREC, pages 143­166, 1996.",1,TREC,True
503,"D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993­1022, 2003.",0,,False
504,"S. Buttcher, C. L. A. Clarke, and B. Lushman. Term Proximity Scoring for Ad-hoc Retrieval on Very Large Text Collections. In Proceedings of the 29th ACM SIGIR, pages 621 ­ 622, 2006.",1,hoc,True
505,"T. L. Griffiths and M. Steyvers. Finding Scientific Topics. In Proceeding of the National Academy of Sciences, pages 5228­5235, 2004.",1,ad,True
506,"B. He, J. X. Huang, and X. Zhou. Modeling term proximity for probabilistic information retrieval models. Information Sciences, 181(14):3017­3031, 2011.",0,,False
507,"T. Hofmann. Probabilistic Latent Semantic Indexing. In Proceedings of the 22nd ACM SIGIR, pages 50­57, 1999.",0,,False
508,"Q. Hu, J. X. Huang, and X. Hu. Modeling and Mining Term Association for Improving Biomedical Information Retrieval Performance. BMC Bioinformatics, 13(2):18 pages, 2012.",0,,False
509,"W. Li and A. McCallum. Pachinko Allocation: DAG-Structured Mixture Models of Topic Correlations. In Proc. of ICML, pages 577­584, 2006.",0,,False
510,"X. Liu and W. B. Croft. Cluster-Based Retrieval Using Language Models. In Proceedings of the 27th ACM SIGIR, pages 186­193, 2004.",0,,False
511,"Y. Lv and C. Zhai. Positional Language Models for Information Retrieval. In Proceedings of the 32nd ACM SIGIR, pages 299­306, 2009.",0,,False
512,"D. Metzler and W. B. Croft. A Markov Random Field Model for Term Dependencies. In Proceedings of the 28th ACM SIGIR, pages 472­479, 2005.",0,,False
513,"J. H. Paik. A Novel TF-IDF Weighting Scheme for Effective Ranking. In Proc. of the 36th ACM SIGIR, pages 343­352, 2013.",0,,False
514,"R. Song, L. Yu, J. R. Wen, and H. W. Hon. A Proximity Probabilistic Model for Information Retrieval. Tech. Rep., Microsoft Research, 2011.",0,,False
515,"X. Wei and W. B. Croft. LDA-Based Document Models for Ad-hoc Retrieval. In Proc. of the 29th ACM SIGIR, pages 178­185, 2006.",1,hoc,True
516,"X. Wei and W. B. Croft. Modeling Term Associations for Ad-Hoc Retrieval Performance within Language Modeling Framework. In Proceedings of the 29th European Conference on IR research, pages 52­63, 2007.",0,,False
517,"X. Yi and J. Allan. A Comparative Study of Utilizing Topic Models for Information Retrieval. In Proceedings of the 31st European Conference on IR Research on Advances in Information Retrieval (ECIR'09), pages 29­41, 2009.",0,,False
518,"C. Zhai and J. Lafferty. A Study of Smoothing Methods for Language Models Applied to Information Retrieval. ACM TOIS, 22(2):179­214, 2004.",0,,False
519,"J. Zhao, J. X. Huang, and B. He. CRTER: Using Cross Terms to Enhance Probabilistic IR. In Proc. of the 34th ACM SIGIR, pages 155­164, 2011.",0,,False
520,"J. Zhao, J. X. Huang, and Z. Ye. Modeling Term Associations for Probabilistic Information Retrieval. ACM Trans. Inf. Syst., 32(2):1­47, 2014.",0,,False
521,736,0,,False
522,,0,,False
