,sentence,label,data,regex
0,Toward Estimating the Rank Correlation between the Test Collection Results and the True System Performance,0,,False
1,Julián Urbano,0,,False
2,"Universitat Pompeu Fabra Barcelona, Spain",0,,False
3,urbano.julian@gmail.com,0,,False
4,Mónica Marrero,0,,False
5,"National Supercomputing Center Barcelona, Spain",0,,False
6,monica.marrero@bsc.es,0,,False
7,ABSTRACT,0,,False
8,"The Kendall  and AP rank correlation coefficients have become mainstream in Information Retrieval research for comparing the rankings of systems produced by two different evaluation conditions, such as different effectiveness measures or pool depths. However, in this paper we focus on the expected rank correlation between the mean scores observed with a test collection and the true, unobservable means under the same conditions. In particular, we propose statistical estimators of  and AP correlations following both parametric and non-parametric approaches, and with special emphasis on small topic sets. Through large scale simulation with TREC data, we study the error and bias of the estimators. In general, such estimates of expected correlation with the true ranking may accompany the results reported from an evaluation experiment, as an easy to understand figure of reliability. All the results in this paper are fully reproducible with data and code available online.",1,AP,True
9,Keywords,0,,False
10,Evaluation; Test Collection; Correlation; Kendall; Average Precision; Estimation,0,,False
11,1. INTRODUCTION,1,DUC,True
12,"The Kendall  [3] and AP [8] rank correlation coefficients are widely used in Information Retrieval to compare rankings of systems produced by different evaluation conditions, such as different assessors [6], effectiveness measures [4] or topic sets [1]. One reason for this success is their simplicity: they provide a single score that is easy to understand.",1,AP,True
13,"In this paper we tackle the problem of estimating the correlation between the ranking of systems obtained with a test collection and the true ranking under the same conditions. Such estimates can make a nice companion to a set of evaluation results, as a single figure of the reliability of the experiment. Voorhees and Buckley [7] proposed to report a similar figure in terms of sensitivity, that is, the minimum",0,,False
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",1,ad,True
15,"SIGIR '16, July 17 - 21, 2016, Pisa, Italy",0,,False
16,c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00,0,,False
17,DOI: http://dx.doi.org/10.1145/2911451.2914752,0,,False
18,"difference required between two systems to ensure a maximum error rate in relative comparisons. Common practice nowadays is to report the p-value of a statistical significance test run either for each pair of systems (e.g. t-test) or for the whole set (e.g. ANOVA and F -test). They provide a sense of confidence about individual pairs of systems or about a swap somewhere in the ranking, but they do not give a general idea of how similar the observed ranking is to the truth.",1,ad,True
19,"We propose parametric and non-parametric approaches to estimate the  and AP correlations. Through large scale simulation with TREC data, we show that they have very low bias and small error even for mid-sized collections.",1,AP,True
20,2. CORRELATION BETWEEN,0,,False
21,TWO RANKINGS,0,,False
22,"Let A ,"" a1, . . . , am and B "","" b1, . . . , bm be the mean scores of the same set of m systems as observed under two different evaluation conditions, such that ai and bi refer to the i-th system. In many situations we are interested in the distance between the two rankings. Considering systems in pairs, a distance can be computed by counting how many pairs are concordant or discordant between the two rankings: a pair is concordant if their relative order is the same in both rankings, and discordant if it is the opposite. Kendall [3] followed this idea to define his  correlation coefficient""",0,,False
23," , #concordants-#discordants ,"" 1-2 #discordants , (1)""",0,,False
24,total,0,,False
25,total,0,,False
26,"which evaluates to -1 when the rankings are reversed, +1 when they are the same, and 0 when there are as many concordant pairs as there are discordant. Note that the term #discordants/total can be interpreted as the expected value of a random experiment: pick two arbitrary systems and return 1 if they are discordant, or 0 if they are concordant. The Kendall  coefficient can thus be interpreted in terms of the probability of discordance.",0,,False
27,"Yilmaz et al. [8] followed this idea to define a correlation coefficient with the same rationale as Average Precision. It is similar to Kendall  , but it penalizes more if swaps occur between systems at the top of the ranking, much like AP penalizes more if the non-relevant documents appear at the top of the results. In particular, they considered that one of the rankings, say B, is the true ranking and the other one is an estimate of it. The random experiment is now as follows: pick one system at random from A and another one ranked above it, and return 1 if they are discordant, or 0 if they are concordant. Their AP correlation coefficient can then be defined just as in (1) as follows:",1,AP,True
28,1033,0,,False
29,AP,1,AP,True
30,",",0,,False
31,1,0,,False
32,-,0,,False
33,2 m-,0,,False
34,1,0,,False
35,m,0,,False
36,#discordants above i i-1,0,,False
37,.,0,,False
38,(2),0,,False
39,"i,2",0,,False
40,Note that AP also ranges between -1 and +1.,1,AP,True
41,3. EXPECTED CORRELATION,0,,False
42,WITH THE TRUE RANKING,0,,False
43,"The previous section contemplated the case where we compute the correlation between two given rankings A and B. In this section we study the case where we are given a ranking A obtained with the sample of topics in the test collection, and want to estimate its correlation with the true ranking B over the population of topics, which is of course unknown. For simplicity, let us first assume that the systems are already sorted in descending order by their mean score. Let us further define Dij as the random variable that equals 1 if systems i and j are discordant and 0 otherwise, that is, whether they are swapped in the true ranking. Both  and AP can be re-defined from (1) and (2) in terms of Dij alone:",1,ad,True
44,",",0,,False
45,1,0,,False
46,-,0,,False
47,4 m(m -,0,,False
48,1),0,,False
49,m-1,0,,False
50,m,0,,False
51,"Dij ,",0,,False
52,(3),0,,False
53,"i,1 j,i+1",0,,False
54,AP,1,AP,True
55,",",0,,False
56,1,0,,False
57,-,0,,False
58,2 m-1,0,,False
59,m-1,0,,False
60,i-1,0,,False
61,Dij i-1,0,,False
62,.,0,,False
63,(4),0,,False
64,"i,1 j,1",0,,False
65,"Since they are just a linear combination of random variables, their expectations are as in (3) and (4) but replacing Dij with E[Dij]. Note that each Dij is a Bernoulli random variable, so its expectation is just the probability of discordance E[Dij] , P (µi - µj < 0) , pij. The problem of estimating the correlation with the true ranking thus boils down to estimating the probability that any two systems are swapped. The next subsection presents four ways of achieving this.",0,,False
66,3.1 Estimating the Probability of Discordance,0,,False
67,"Since each pij is estimated independently from the other systems, let us simplify notation here to just p. In addition, let X1, . . . , Xn be the differences in effectiveness between the two systems and for each of the n topics in the collection. The problem is therefore to estimate p ,"" P (µ < 0) from these n observations. Recall that systems are assumed to be ranked by mean observed scores, so X > 0.""",1,ad,True
68,In the following we present two parametric estimators based on the Central Limit Theorem (CLT) and then two non-parametric estimators based on resampling.,0,,False
69,3.1.1 Maximum Likelihood (ML),0,,False
70,"The CLT tells us that X is approximately normally distributed with mean µ and variance 2/n as n  . Using the cdf of the normal distribution we can therefore estimate the probability of discordance. However, our estimates are likely off with small samples (see Section 3.1.2), so we assume Xi  N (µ, 2) and employ the t distribution to account for the uncertainty in estimating 2. Standardizing, we have that n(X - µ)/  t(n - 1), so",0,,False
71,"p , P (µ < 0)  Tn-1",0,,False
72, -n,0,,False
73,µ^ ^,0,,False
74,",",0,,False
75,(5),0,,False
76,where Tn-1 is the cdf of the t distribution with n - 1 degrees of freedom. The estimates µ^ and ^ are computed via Maximum Likelihood as,0,,False
77,"µ^ ,",0,,False
78,X,0,,False
79,",",0,,False
80,1 n,0,,False
81,"Xi,",0,,False
82,(6),0,,False
83,"^ ,"" s · Cn,""",0,,False
84,(7),0,,False
85,"s,",0,,False
86,1 n-1,0,,False
87,"(Xi - X)2,",0,,False
88,"Cn ,",0,,False
89,n,0,,False
90,- 2,0,,False
91,1,0,,False
92,((n - 1)/2) (n/2),0,,False
93,",",0,,False
94,where s is the sample standard deviation. The Cn factor [2],0,,False
95,"ensures that E[^] ,"" . This bias correction is applied because, even though s2 is an unbiased estimator of 2, by""",0,,False
96,Jensen's inequality s is not an unbiased estimator of .,0,,False
97,3.1.2 Minimum Squared Quantile Deviation (MSQD),0,,False
98,The problem when estimating  from a small sample is,0,,False
99,that the observations are likely to be concentrated around,0,,False
100,"the mean and seldom occur near the tails. As a consequence,",0,,False
101,(7) is likely to underestimate the true dispersion in the pop-,0,,False
102,ulation. If the sample contains a few dozen observations this,0,,False
103,"is not expected to be a problem, but with very small samples",0,,False
104,"of, say, just 10 topics, it might be.",0,,False
105,We propose a new and generic estimator to avoid this,0,,False
106,problem. Let us consider a distribution function F with,0,,False
107,parameter . A random sample from this distribution is,0,,False
108,"expected to uniformly cover the quantile space, that is, all",0,,False
109,"quantiles are equally likely to appear in the sample. Thus,",0,,False
110,when we are given a sample we may force them to uniformly,0,,False
111,cover the quantile space and then select the  that minimizes,0,,False
112,"the observed deviations. For instance, if our sample contains",0,,False
113,"only one observation, we force it to correspond to the quan-",0,,False
114,tile 1/2; if we have two observations then we force them to,0,,False
115,"be the quantiles 1/3 and 2/3. In general, if Ri is the rank of",0,,False
116,"Xi within the sample, it will correspond to the Ri/(n + 1)",0,,False
117,"quantile, which is F -1",0,,False
118,Ri n+1,0,,False
119,;,0,,False
120,. The squared quantile devi-,0,,False
121,ation of an observation Xi is therefore,0,,False
122,"SQD(Xi; ) ,",0,,False
123,F -1,0,,False
124,Ri n+,0,,False
125,1,0,,False
126,;,0,,False
127,2,0,,False
128,- Xi .,0,,False
129,The Minimum Squared Quantile Deviation estimator is then the one that minimizes the sum of squared deviations:,0,,False
130,"^MSQD , arg min SQD (Xi; ).",0,,False
131,"Let us assume again a normal distribution, so that",0,,False
132,F -1,0,,False
133,Ri n+,0,,False
134,1,0,,False
135,;,0,,False
136,"µ,",0,,False
137," ,"" µ +  2ei,""",0,,False
138,"ei , erf-1",0,,False
139,2,0,,False
140,Ri n+,0,,False
141,1,0,,False
142,-,0,,False
143,1,0,,False
144,.,0,,False
145,The sum of squared deviations is thus,0,,False
146,µ2,0,,False
147,-,0,,False
148,2µ2e i,0,,False
149,0,0,,False
150,+,0,,False
151,22e2i,0,,False
152,-,0,,False
153,2Xiµ,0,,False
154,-,0,,False
155, 2Xi 2ei,0,,False
156,+,0,,False
157,"Xi2,",0,,False
158,"and the second term cancels out because ei ,"" 0. To find the µ and  that minimize this expression, we simply differentiate, equal to 0, and solve. The partial derivatives are""",0,,False
159,dSQD dµ,0,,False
160,",",0,,False
161,dSQD d,0,,False
162,",",0,,False
163,"2µ - 2Xi , 2nµ - 2",0,,False
164,4e2i,0,,False
165,-,0,,False
166," 2 2Xiei,",0,,False
167,Xi and,0,,False
168,"and therefore, the estimators are",0,,False
169,1034,0,,False
170,µ^,0,,False
171,",",0,,False
172,1 n,0,,False
173,2,0,,False
174,"^ ,",0,,False
175,2,0,,False
176,"Xi ,"" X,""",0,,False
177,Xi · erf-1,0,,False
178,2,0,,False
179,Ri n+1,0,,False
180,-,0,,False
181,1,0,,False
182,erf -1,0,,False
183,2,0,,False
184,Ri n+1,0,,False
185,-,0,,False
186,1,0,,False
187,2,0,,False
188,.,0,,False
189,(8) (9),0,,False
190,"As above, the probability of discordance is estimated with the cdf of the t distribution as in (5), but using estimators (8) and (9) instead of (6) and (7).",1,ad,True
191,3.1.3 Resampling (RES),0,,False
192,In both the ML and MSQD estimators above we assumed,0,,False
193,"that scores are normally distributed, but this is clearly not",0,,False
194,strictly true. A non-parametric alternative is the use of re-,0,,False
195,sampling to estimate the sampling distribution of the mean,0,,False
196,and from there the probability of discordance.,0,,False
197,"Suppose we draw a random sample X1, . . . , Xn with re-",0,,False
198,"placement from our original observations, and compute their",0,,False
199,"sample mean X. This experiment is replicated T ,"" 1, 000""",0,,False
200,"times,",0,,False
201,yielding,0,,False
202,sample,0,,False
203,means,0,,False
204,X,0,,False
205,"1 ,",0,,False
206,.,0,,False
207,.,0,,False
208,.,0,,False
209,",",0,,False
210,X,0,,False
211, T,0,,False
212,.,0,,False
213,By the law of,0,,False
214,"large numbers, the distribution of these sample means con-",0,,False
215,verges to the sampling distribution of X as T  . The,0,,False
216,probability of discordance can thus be estimated as the frac-,0,,False
217,tion,0,,False
218,of,0,,False
219,times,0,,False
220,that,0,,False
221,X,0,,False
222, i,0,,False
223,is,0,,False
224,negative:,0,,False
225,p,0,,False
226,",",0,,False
227,P (µ,0,,False
228,<,0,,False
229,0),0,,False
230,1 T,0,,False
231,I,0,,False
232,X,0,,False
233, i,0,,False
234,<,0,,False
235,0,0,,False
236,.,0,,False
237,(10),0,,False
238,3.1.4 Kernel Density (KD),0,,False
239,"A potential problem with resampling from the original observations is again that estimates from very small samples are likely off. An alternative is to approximate the true pdf via Kernel Density Estimation, and use it to estimate the probability of discordance. The estimated pdf has the form",0,,False
240,"f^(x) ,",0,,False
241,1 nh,0,,False
242,k,0,,False
243,x - Xi h,0,,False
244,",",0,,False
245,"where k is the pdf of the kernel and h is the bandwidth. Next, we need to estimate the sampling distribution of the mean, which is basically the distribution of the sum of n variables drawn from f^. For n , 2 this requires the evaluation of the self-convolution of f^ as follows:",0,,False
246,f^X+X (x),0,,False
247,",",0,,False
248,1 n2h2,0,,False
249,ij,0,,False
250,k,0,,False
251,x-z -Xi h,0,,False
252,k,0,,False
253,z -Xj h,0,,False
254,"dz,",0,,False
255,"which involves the sum of n2 terms. In general, for n vari-",0,,False
256,"ables this requires the evaluation of nn terms, which is clearly",0,,False
257,"unfeasible even for small samples, so instead we resort to",1,ad,True
258,"Monte Carlo methods. As with the RES estimator, we gen-",0,,False
259,erate mean,0,,False
260,"aXra.ndAomftesramT prleepXlic1a, t.i.o.n,sX, nthferopmrof^baabnidlitcyomofpudtiesctohre-",0,,False
261,dance,0,,False
262,is,0,,False
263,estimated,0,,False
264,as,0,,False
265,the,0,,False
266,fraction,0,,False
267,of,0,,False
268,times,0,,False
269,that,0,,False
270,X,0,,False
271, i,0,,False
272,is,0,,False
273,nega-,0,,False
274,"tive. We set T ,"" 1, 000 replications and use gaussian kernels.""",0,,False
275,4. EVALUATION,0,,False
276,4.1 Criteria,0,,False
277,"There are two properties of the correlation estimators that we are interested in, namely error and bias. Error refers to the expected difference between the estimate and the truth. Here we measure absolute error, thus quantifying the expected magnitude of the error when estimating the correlation of a given collection:",0,,False
278,"error ,"" E |^(A) -  (A, µ)| .""",0,,False
279,"Even if the error is small, it could tend to be in the same direction, that is, over- or underestimating the correlation. Bias refers to this tendency, measured as the expected difference between the estimated and the true correlation:",0,,False
280,"bias ,"" E ^(A) -  (A, µ) .""",0,,False
281,"If the bias is positive it means that the estimator tends to overestimate the correlations. In general, we seek estimators with small error and zero bias.",0,,False
282,"4.2 Methods, Data and Baselines",0,,False
283,"From the above definitions it is evident that we need to know the true ranking of systems µ, but this is of course unknown. To solve this problem we resort to the simulation method proposed by Urbano [5]. Given the topic-by-system matrix of scores B from an existing collection, it generates a new matrix A with the scores by the same set of systems over a new and random set of topics. There are two important characteristics of this method that are appealing for us. First, the simulated scores are realistic, as they maintain the same distributions and correlations among systems as in the original collection. Second, it is designed to ensure that the expected mean score of a system is equal to the mean score in the original collection, that is, E As ,"" Bs. For us, this means that the true mean scores are fixed to be the mean scores in the original collection, that is, µs :"","" Bs. This allows us to analyze the error and bias of the estimators with a large number of simulated, yet realistic test collections.""",0,,False
284,"We use the TREC 6, 7 and 8 ad hoc collections as evaluated with Average Precision. As is common practice, we first drop the bottom 25% of results to avoid effects of possibly buggy systems. From each original collection, we simulate 1, 000 new collections of sizes n ,"" 10, 20, . . . , 100 topics, leading to a total of 30, 000 simulated collections. For each of them, we estimate  and AP using each of the estimators defined above, and also compute the true correlations (recall that this is possible because the true system scores are fixed upfront when simulating new collections). Finally, for each correlation coefficient, original collection, topic set size and estimator, we compute expected error and bias.""",1,TREC,True
285,"Two baselines are used to compare our estimators to. They are based on a split-half method that randomly splits the available topic set in two subsets, and then computes the correlations as if one was the truth and the other one the estimate. This is replicated a number of times for different subset sizes, up to a maximum of n/2 topics. The observations are then used to fit a model and extrapolate the expected correlation with n topics. This simple estimator is found for instance in [7, 4]. Here we run 2, 000 replicates to fit the model y ,"" a·eb·x, and sample topics with and without replacement, leading to baselines SH(w) and SH(w/o).""",1,ad,True
286,4.3 Results,0,,False
287,"Figure 1 shows that the error of the estimators is larger with small collections. This is somewhat expected, because collections with too few topics are unstable and the rankings of systems vary too much to begin with. The error seems to plateau at about 0.025 in all our estimators, though with small collections of just 10 topics they are expected to be off by about 0.065. With the usual 50 topics, the expected error is 0.035. We can finally observe that the typical SH",0,,False
288,1035,0,,False
289,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
290,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
291,tau - adhoc6,1,adhoc,True
292,ML,0,,False
293,RES,0,,False
294,MSQD KD,0,,False
295,SH(w/o) SH(w),0,,False
296,tauAP - adhoc6,1,AP,True
297,topic set size tau - adhoc7,1,adhoc,True
298,topic set size tauAP - adhoc7,1,AP,True
299,Bias,0,,False
300,0.00,0,,False
301,0.04,0,,False
302,0.08,0,,False
303,10,0,,False
304,20,0,,False
305,30,0,,False
306,tau - adhoc6,1,adhoc,True
307,ML,0,,False
308,RES,0,,False
309,MSQD KD,0,,False
310,SH(w/o) SH(w),0,,False
311,0.08,0,,False
312,tauAP - adhoc6,1,AP,True
313,0.04,0,,False
314,Bias,0,,False
315,0.00,0,,False
316,70,0,,False
317,60,0,,False
318,50,0,,False
319,40,0,,False
320,30,0,,False
321,20,0,,False
322,10,0,,False
323,100,0,,False
324,90,0,,False
325,80,0,,False
326,70,0,,False
327,60,0,,False
328,50,0,,False
329,40,0,,False
330,topic set size tau - adhoc7,1,adhoc,True
331,topic set size tauAP - adhoc7,1,AP,True
332,100,0,,False
333,90,0,,False
334,80,0,,False
335,0.08,0,,False
336,0.08,0,,False
337,0.04,0,,False
338,Bias,0,,False
339,0.04,0,,False
340,Bias,0,,False
341,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
342,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
343,0.00,0,,False
344,0.00,0,,False
345,100,0,,False
346,90,0,,False
347,80,0,,False
348,70,0,,False
349,60,0,,False
350,50,0,,False
351,40,0,,False
352,30,0,,False
353,20,0,,False
354,10,0,,False
355,100,0,,False
356,90,0,,False
357,80,0,,False
358,70,0,,False
359,60,0,,False
360,50,0,,False
361,40,0,,False
362,30,0,,False
363,20,0,,False
364,10,0,,False
365,topic set size tau - adhoc8,1,adhoc,True
366,topic set size tauAP - adhoc8,1,AP,True
367,topic set size tau - adhoc8,1,adhoc,True
368,topic set size tauAP - adhoc8,1,AP,True
369,0.08,0,,False
370,0.08,0,,False
371,0.04,0,,False
372,Bias,0,,False
373,0.04,0,,False
374,Bias,0,,False
375,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
376,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,0,,False
377,0.00,0,,False
378,0.00,0,,False
379,100,0,,False
380,90,0,,False
381,80,0,,False
382,70,0,,False
383,60,0,,False
384,50,0,,False
385,40,0,,False
386,30,0,,False
387,20,0,,False
388,10,0,,False
389,100,0,,False
390,90,0,,False
391,80,0,,False
392,70,0,,False
393,60,0,,False
394,50,0,,False
395,40,0,,False
396,30,0,,False
397,20,0,,False
398,10,0,,False
399,topic set size,0,,False
400,topic set size,0,,False
401,Figure 1: Error of the estimators of  (left) and AP (right) for each of the three original collections.,1,AP,True
402,"estimators are clearly outperformed by all our proposed estimators. In general, with 30­40 topics they behave almost the same, but with small samples MSQD is slightly better.",0,,False
403,"Figure 2 shows that the correlations tend to be overestimated, especially with small collections, but this time we see clear differences among estimators. MSQD behaves much better than the others, especially with very small collections. With only 10 topics ML outperforms KD because there is just too little data to properly approximate the pdf , but with 20 or more topics it does a very good job at approximating the true distribution. ML, on the other hand, assumes a normal distribution and can therefore be less faithful to the data. Even at around 40­50 topics KD gets to slightly outperform MSQD for the same reason. Overall, they seem to plateau at about 0.004, and RES always performs worse than the others. Finally, the SH estimator with replacement has a roughly constant bias of about 0.055. The SH estimator without replacement shows a clearly biased behavior probably due to the choice of model.",0,,False
404,5. CONCLUSION,0,,False
405,"In this paper we present two estimators of the Kendall  and AP rank correlation coefficients between the mean system scores produced by a test collection and the true, unobservable means. We proposed parametric and nonparametric alternatives, and through large scale simulation with realistic collections we showed that even with small topic sets the estimators have little bias and the errors are generally small with collections of medium size. These estimators may prove useful as an easy to understand indicator",1,AP,True
406,topic set size,0,,False
407,topic set size,0,,False
408,Figure 2: Bias of the estimators of  (left) and AP (right) for each of the three original collections.,1,AP,True
409,"of reliability in the results of an evaluation experiment. In light of the expected error with individual collections,",0,,False
410,our future work will mainly focus on the development of interval estimates. We also plan to study other estimators of discordance as well as the application of a fully bayesian approach to estimate correlations. All the results in this paper are fully reproducible with data and code available online at http://github.com/julian-urbano/sigir2016-correlation.,0,,False
411,"Acknowledgments. Work supported by the Spanish Government: JdC postdoctoral fellowship, and projects TIN201570816-R and MDM-2015-0502. Florentino dimisi´on.",1,Gov,True
412,References,0,,False
413,"[1] B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. If I Had a Million Queries. In ECIR, 2009.",1,ad,True
414,"[2] W. H. Holtzman. The Unbiased Estimate of the Population Variance and Standard Deviation. Am. J. Psychology, 1950.",0,,False
415,"[3] M. G. Kendall. A New Measure of Rank Correlation. Biometrika, 1938.",0,,False
416,"[4] T. Sakai. On the Reliability of Information Retrieval Metrics Based on Graded Relevance. Inf. Proc. & Mngmnt, 2007.",1,ad,True
417,"[5] J. Urbano. Test Collection Reliability: A Study of Bias and Robustness to Statistical Assumptions via Stochastic Simulation. Information Retrieval, 2016.",1,Robust,True
418,"[6] E. M. Voorhees. Variations in Relevance Judgments and the Measurement of Retrieval Effectiveness. In SIGIR, 1998.",0,,False
419,"[7] E. M. Voorhees and C. Buckley. The Effect of Topic Set Size on Retrieval Experiment Error. In SIGIR, 2002.",0,,False
420,"[8] E. Yilmaz, J. Aslam, and S. Robertson. A New Rank Correlation Coefficient for Information Retrieval. In SIGIR, 2008.",0,,False
421,1036,0,,False
422,,0,,False
