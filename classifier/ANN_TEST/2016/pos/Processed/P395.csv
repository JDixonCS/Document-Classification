,sentence,label,data,regex
0,Modeling Document Novelty with Neural Tensor Network for Search Result Diversification,1,Novelty,True
1,Long Xia Jun Xu Yanyan Lan Jiafeng Guo Xueqi Cheng,0,,False
2,"CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences",1,ad,True
3,"xialong@software.ict.ac.cn, {junxu, lanyanyan, guojiafeng, cxq}@ict.ac.cn",0,,False
4,ABSTRACT,0,,False
5,"Search result diversification has attracted considerable attention as a means to tackle the ambiguous or multi-faceted information needs of users. One of the key problems in search result diversification is novelty, that is, how to measure the novelty of a candidate document with respect to other documents. In the heuristic approaches, the predefined document similarity functions are directly utilized for defining the novelty. In the learning approaches, the novelty is characterized based on a set of handcrafted features. Both the similarity functions and the features are difficult to manually design in real world due to the complexity of modeling the document novelty. In this paper, we propose to model the novelty of a document with a neural tensor network. Instead of manually defining the similarity functions or features, the new method automatically learns a nonlinear novelty function based on the preliminary representation of the candidate document and other documents. New diverse learning to rank models can be derived under the relational learning to rank framework. To determine the model parameters, loss functions are constructed and optimized with stochastic gradient descent. Extensive experiments on three public TREC datasets show that the new derived algorithms can significantly outperform the baselines, including the state-of-the-art relational learning to rank models.",1,ad,True
6,Keywords,0,,False
7,search result diversification; neural tensor network; relational learning to rank,0,,False
8,1. INTRODUCTION,1,DUC,True
9,"In web search, it has been widely observed that a large fraction of queries are ambiguous or multi-faceted. Search result diversification has been proposed as a way to tackle this problem and diverse ranking is one of the central problems. The goal of diverse ranking is to develop a ranking",0,,False
10,Corresponding author: Jun Xu.,0,,False
11,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17­21, 2016, Pisa, Italy. c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2911498",1,ad,True
12,"model that can sort documents based on their relevance to the given query as well as the novelty of the information in the documents. Thus, how to measure the novelty of a candidate document with respect to other documents becomes a key problem in the designing of the diverse ranking models.",0,,False
13,"Methods for search result diversification can be categorized into heuristic approaches and learning approaches. The heuristic approaches construct diverse rankings with heuristic rules [3, 8, 14, 24, 25, 26]. As a representative model, the maximal marginal relevance (MMR) [3] formulates the construction of a diverse ranking as a process of sequential document selection. At each iteration the document with the highest marginal relevance is selected. The marginal relevance consists of the relevance score and novelty score. The novelty score is calculated based on a predefined document similarity function. Thus, the selection of the document similarity function becomes a critical issue for MMR. Different choices of the similarity functions result in different ranking lists. Usually it is difficult to define an appropriate similarity function in a real application.",0,,False
14,"Recently, machine learning models have been proposed and applied to the task of search result diversification [17, 20, 23, 28, 32]. The basic idea is to automatically learn a diverse ranking model from the labeled training data. Relational learning to rank is one of the representative framework in this field. In relational learning to rank, the novelty of a document with respect to the previously selected documents is encoded as a set of handcrafted novelty features. Several algorithms have been developed under the framework and state-of-the-art performances have been achieved [28, 32]. However, it is still an unsolved problem to define a set of novelty features which can effectively capture the complex document relationship. Unlike the designing of relevance features in conventional learning to rank, it is much more difficult to extract novelty features for search result diversification. Currently, a very limited number of novelty features can be utilized when constructing a diverse ranking model. For example, in R-LTR [32] and PAMM [28], the novelty of a document is characterized with only seven novelty features. Most of the features are based on the cosine similarities of two documents represented with tf-idf vectors or topic vectors. Thus, it is very difficult, if not impossible, for users to handcraft an optimal set of novelty features for search result diversification.",0,,False
15,"To address above problems and inspired by the neural models for relation classification [27], we propose to model the document novelty for search result diversification using a neural tensor network (NTN). Unlike existing methods",1,ad,True
16,395,0,,False
17,"which manually define the document similarity functions or novelty features, the method automatically learns a nonlinear document novelty function from the training data. It first generates the novelty signals with a nonlinear tensor layer, through interacting the candidate document with other documents. Then, a max-pooling operation is applied to select the most effective novelty signals. Finally, the selected signals are combined linearly to form the final document novelty score.",0,,False
18,"New diverse ranking models, then, can be proposed under the relational learning to rank framework. The marginal relevance in relational learning to rank, which is used for selecting the best document at each step, is calculated as a sum of the query-document relevance score and document novelty score. Modeling the document novelty score with the proposed neural tensor network, we can achieve new diverse ranking models. On the basis of existing relational learning to rank algorithms of R-LTR and PAMM, two new loss functions are constructed and optimized, achieving two novel diverse ranking algorithms of R-LTR-NTN and PAMM-NTN.",0,,False
19,"To evaluate the effectiveness of the proposed algorithms, we conducted extensive experiments on three public TREC benchmark datasets. The experimental results showed that our proposed algorithms, including R-LTR-NTN and PAMMNTN, can significantly outperform the state-of-the-art baselines including heuristic approaches of MMR, and learning approaches of SVM-DIV [29], R-LTR, and PAMM. Analysis showed that the proposed approaches achieved better results through learning better document dissimilarities in terms of distinguishing the documents with different subtopics. Thus, the proposed algorithms have the ability to improve the queries with high ambiguity.",1,TREC,True
20,"Contributions of the paper include: 1) We proposed to model the document novelty with a neural tensor network, which enables us to get rid of the manually defined similarity functions or handcrafted novelty features in search result diversification; 2) Based on the new document novelty model, two diverse ranking algorithms were derived under the framework of relational learning to rank; 3) The effectiveness of the proposed algorithms were verified based on public benchmark datasets.",0,,False
21,"The rest of the paper is organized as follows. After a summary of related work in Section 2, we present the neural tensor network model for measuring document novelty in Section 3. Section 4 presents the two derived diverse ranking algorithms under the relational learning to rank framework. Experimental results and discussions are given in Section 5. Section 6 concludes the paper and gives future directions.",0,,False
22,2. RELATED WORK,0,,False
23,"This paper concerns about the ranking models for search result diversification. Existing methods can be categorized into heuristic approaches and learning approaches. One of the central problems in both of these two approaches is novelty, that is, how to model the novelty information of a document with respect to other documents.",0,,False
24,2.1 Heuristic approaches,0,,False
25,"It is a common practice to use heuristic rules to construct a diverse ranking list in search. Usually, the rules are created based on the observation that in diverse ranking a document's novelty depends on not only the document itself but also the documents ranked in previous positions. Carbonell",0,,False
26,"and Goldstein [3] proposed the maximal marginal relevance criterion to guide the design of diverse ranking models. The criterion is implemented with a process of iteratively selecting the documents from the candidate document set. At each iteration, the document with the highest marginal relevance score is selected, where the score is a linear combination of the query-document relevance and the maximum distance of the document to the documents in current result set, in another word, novelty. The marginal relevance score is then updated in the next iteration as the number of documents in the result set increases by one. A number of methods have been developed under the criterion. PM-2 [8] treats the problem of finding a diverse search result as finding a proportional representation for the document ranking. xQuAD [26] directly models different aspects underlying the original query in the form of sub-queries, and estimates the relevance of the retrieved documents to each identified subquery. Hu et al. [14] proposed a diversification framework that explicitly leverages the hierarchical intents of queries and selects the documents that maximize diversity in the hierarchical structure. See also [2, 4, 10, 11, 12, 22]",0,,False
27,"All of these heuristic approaches rely on a predefined document similarity (or distance) function to measure the novelty of a document. Thus, the selection of the similarity function is critical for the ranking performances. Usually it is hard to design an optimal similarity function for a specific task. In this paper, we focus on the learning approaches to estimate the novelty scores of documents.",0,,False
28,2.2 Learning approaches,0,,False
29,"Machine learning techniques have been applied to construct ranking models for search result diversification. In these approaches, the relevance features and novelty features are extracted for characterizing the relevance and novelty information of a document, respectively. The ranking score is usually a linear combination of these features and the parameters can be automatically estimated from the training data. Some promising results have been obtained. For example, Zhu et al. [32] proposed the relational learning to rank framework in which the diverse ranking is constructed with a process of sequential document selection. The training of a relational learning to rank model thus amounts to optimizing the object function based on the ground-truth rankings. With different definitions of the object functions and optimization techniques, different diverse ranking algorithms have been derived [28, 32]. Radlinski et al. [23] proposed online learning algorithms that directly learn a diverse ranking of documents based on users' clicking behaviors. More works please refer to [17, 20, 30].",1,ad,True
30,"Most learning approaches depend on a set of handcrafted novelty features to represent the novelty of a document. Construction of such features is usually difficult and time consuming in real applications. In real world, we have a very limited number of novelty features, which greatly limits the usability of these diverse ranking models. In this paper, we propose to automatically learn the novelty with a neural tensor network and enhance the usability of the diverse ranking algorithms.",0,,False
31,3. MODELING DOCUMENT NOVELTY WITH NEURAL TENSOR NETWORK,0,,False
32,"Inspired by the neural models for relation classification, in",0,,False
33,396,0,,False
34,Tensor Layer,0,,False
35,Linear Layer,0,,False
36,µTR 2 Rz,0,,False
37,tanh,0,,False
38,+,0,,False
39,+,0,,False
40,tanh,0,,False
41,eT1 WR[1:z] e2 + VR,0,,False
42,e1 e2,0,,False
43,+ bR,0,,False
44,t 2 Rz,0,,False
45,"Figure 1: Visualization of the neural tensor network for relation classification. Each dashed box represents one slice of the tensor, in this case there are z , 2 slices.",0,,False
46,this paper we propose to use neural tensor network to model the novelty of a document w.r.t. a set of other documents.,0,,False
47,3.1 Neural tensor network,0,,False
48,"In deep learning literature, neural tensor networks (NTN) is originally proposed to reason the relationship between two entities in knowledge graph [27]. Given two entities (e1, e2) represented with le dimensional features, the goal of NTN is to predict whether they have a certain relationship R. Specifically, NTN computes a score of how likely it is that these two entities are in certain relationship R by the following function:",0,,False
49,"g(e1, R, e2) , µTR tanh eT1 WR[1:z]e2 + VR",0,,False
50,e1 e2,0,,False
51,"+ bR ,",0,,False
52,"where e1, e2  Rle are the vector representations of two entities, WR[1:z]  Rle×le×z is a tensor and the bilinear tensor product eT1 WR[1:z]e2 results in a vector h  Rz, where each entry of h is computed by one slice i (i ,"" 1, · · · , z) of the""",0,,False
53,"tensor: hi ,"" eT1 WR[i]e2. The other parameters for relation R are the standard form of a neural network: VR  Rz×2le , µR  Rz, and bR  Rz. Figure 1 illustrates the neural tensor network with two slices for entity relationship reasoning.""",0,,False
54,3.2 Modeling document novelty with neural tensor network,0,,False
55,"Intuitively, the neural tensor networks model the relationships between two entities with a bilinear tensor product. The idea can be naturally extended to model the novelty relation of a document with respect to other documents for search result diversification. That is, we can represent the novelty information of a candidate document as a bilinear tensor product of the document and other documents, as shown in Figure 2.",0,,False
56,"More specifically, suppose that we are given a set of M documents X , {dj}M j,""1, where each document dj can be characterized with its preliminary representation vj  Rlv , e.g., the topic distribution [9, 13] of dj or the document vector generated with a doc2vec [15] model. Given a candidate document d  X with its preliminary presentation v, and a set of documents S  X \ {d} with their preliminary representations {v1, · · · , v|S|}, the novelty score of d with respect to the documents in S can be defined as a neural tensor network with z hidden slices:""",0,,False
57,"gn(v, S) ,"" µT max tanh vT W[1:z] v1, . . . , v|S| ,""",0,,False
58,"where each column in matrix v1, . . . , v|S|  Rlv×|S| stands",0,,False
59,Tensor Layer,0,,False
60,Max-pooling Linear,0,,False
61,Layer,0,,False
62,Layer,0,,False
63,µT 2 Rz,0,,False
64,tanh,0,,False
65,tanh,0,,False
66,vT,0,,False
67,"W[1:z] v1, . . . , v|S|",0,,False
68,H 2 Rz|S|,0,,False
69,t 2 Rz,0,,False
70,"Figure 2: Visualization of the neural tensor network for modeling document novelty (z , 2).",0,,False
71,"for the preliminary representation vector of the corresponding document in S, W[1:z]  Rlv×lv×z is a tensor, and µ  Rz the weights correspond to the slices of the tensor. As shown in Figure 2, the neural tensor network consists of",0,,False
72,"a tensor layer, a max-pooling layer, and a linear layer.",0,,False
73,Tensor Layer: The tensor layer takes the preliminary,0,,False
74,representations of the documents as inputs. The interactions,0,,False
75,between the document d and documents in S are represented,0,,False
76,as a bilinear product followed by a nonlinear operation:,0,,False
77," hT1   tanh vT W[1] v1, . . . , v|S| ",0,,False
78,"H, ",0,,False
79,...,0,,False
80,",",0,,False
81,...,0,,False
82,",",0,,False
83,(1),0,,False
84,hTz,0,,False
85,"tanh vT W[z] v1, . . . , v|S|",0,,False
86,where hi  R|S| is computed by one slice of the tensor.,0,,False
87,Compared with the original neural tensor network in Sec-,0,,False
88,"tion 3.1, the tensor in Equation (1) models the relationship",0,,False
89,between one document and multiple documents simultane-,0,,False
90,"ously. Thus, the output of Equation (1) is a z × |S| matrix",0,,False
91,"rather than a z-dimensional vector. Also, since the number",0,,False
92,of documents in S varies in different document selection it-,0,,False
93,"erations, the term VR",0,,False
94,e1 e2,0,,False
95,in the original tensor neural,0,,False
96,"network is ignored. Moreover, in ranking we cares about",0,,False
97,the order of the documents rather than the ranking scores.,0,,False
98,"Thus, the bias term bR is also ignored.",0,,False
99,"Max-pooling Layer: In the max-pooling layer, the ma-",0,,False
100,trix outputted by the tensor layer is mapped to a z-dimensional,0,,False
101,vector with the max operation:,0,,False
102,"t ,"" max(hT1 ), · · · , max(hTz ) T .""",0,,False
103,(2),0,,False
104,"Intuitively, the pooling layer aggregates individual novelty signal learned at each tensor layer hTi . Max-pooling extracts the most significant signals among them. Thus, vector t can",0,,False
105,be considered as a the z-dimensional novelty features and,0,,False
106,each dimension is defined by one slice of the tensor.,0,,False
107,"Linear Layer: Finally, the novelty score of the document",0,,False
108,"is calculated as a linear combination of the novelty signals outputted by the max-pooling layer: µT t, where µ is an",0,,False
109,z-dimensional parameter vector.,0,,False
110,4. DIVERSE RANKING ALGORITHMS BASED ON NEURAL TENSOR NETWORK,0,,False
111,"New diverse ranking algorithms can be derived based on the proposed neural tensor network for modeling document novelty. In this paper, we propose two algorithms under the framework of relational learning to rank.",0,,False
112,397,0,,False
113,Algorithm 1 Ranking via maximizing marginal relevance,0,,False
114,"Input: documents X and novelty features R Output: ranking of documents Y 1: S0  empty set 2: for r ,"" 1, · · · , M do 3: Y (r)  arg maxj:xj X\Sr-1 f (xj , Rj , Sr-1) 4: Sr  Sr-1  {xY (r)} 5: end for 6: return Y""",0,,False
115,4.1 Relational learning to rank,0,,False
116,"The relational learning to rank framework [32] formalizes the ranking of documents as a process of sequential document selection and defines the marginal relevance as linear combination of the relevance score and the novelty score. Formally, let X ,"" {d1, · · · , dM } denotes the set of documents retrieved by a query q. For each query-document pair (q, di), relevance feature vector xi  Rlx is extracted. Let R  RM×M×K denotes a 3-way tensor representing relationships between the documents, where Rijk stands for the k-th feature of relationship between documents di and dj. Assuming that a set of documents S have been selected in the previous iterations, the marginal relevance of the i-th candidate document with respect to S, denoted as f (xi, Ri, S), is then defined as the combination of the relevance score and the novelty score:""",0,,False
117,"f (xi, Ri, S) ,"" rT xi + nT hS(Ri), xi  X\S, (3)""",0,,False
118,"where rT xi stands for the relevance score and r is the relevance weight vector, nT hS(Ri) stands for the novelty score of the document with respect to S and n is the diversity weight vector, Ri stands for the matrix of relationships between document xi and other documents, and hS(Ri) stands for the aggregation function on Ri which aggregates the matrix Ri into a novelty feature vector. Usually, hS can be one of the operations of max, min, or average.",0,,False
119,"According to the maximal marginal relevance criterion, sequential document selection process can be used to create a diverse ranking, as shown in Algorithm 1. The algorithm initializes S0 as an empty set, and then iteratively selects the documents from the candidate set. At iteration r (r ,"" 1, 2, · · · , M ), the document with the maximal marginal relevance score f (xj, Rj, Sr-1) is selected and ranked at position r. At the same time, the selected document is inserted into Sr-1.""",0,,False
120,"Given a set of training instances which consist of queries, documents, and their relevance labels, the model parameters can be learned from the training data. The process amounts to optimizing an objective function based on the training data. Different definitions of the objective functions and optimization techniques lead to different relational learning to rank algorithms. For example, in algorithm RLTR [32], the likelihood of the training queries is maximized using stochastic gradient descent. In algorithm PAMM [28], the loss function upper bounding the diversity evaluation measure is constructed and optimized with structured Perceptron.",1,ad,True
121,"Relational learning to rank models depend on a set of handcrafted features for characterizing the novelty of a document. However, how to design the features that can effectively capture the complex document relationship is still an unsolved problem. Unlike the conventional learning to",0,,False
122,Table 1: Novelty features used in R-LTR.,1,Novelty,True
123,Name,0,,False
124,Explanation,0,,False
125,Subtopic diversity Text diversity,0,,False
126,Title diversity Anchor text diversity ODP-Based diversity,1,ODP,True
127,Link-based diversity URL-based diversity,0,,False
128,document distance based on PLSA [13] one minus cosine similarity of the tf-idf vectors on body text text novelty feature based on title text novelty feature based on anchor categorical distance based on ODP1 taxomony link similarity based on inlink/outlink whether the two URLs belong to the same domain/site,1,ODP,True
129,"rank in which a large number effective relevance features have been developed [21], it is much harder to find novelty features for search result diversification. As a result, the relational learning to rank algorithms of R-LTR and PAMM utilized only seven features in their experiments, as have listed in Table 1. We can see that most of these features are calculated based on the predefined similarities of two documents (represented as tf-idf vectors or topic distributions), and respectively applied to the document fields of title, body, and anchor.",0,,False
130,"In real world applications, the performances of the ranking algorithms heavily depend on the effectiveness of these handcrafted features and different ranking tasks need different features. It is necessary to develop a method that can learn the document novelty automatically and release people from the handcrafted novelty features.",0,,False
131,4.2 Relational learning to rank algorithms based on neural tensor network,0,,False
132,"In this subsection, based on the technique of modeling the document novelty with neural tensor network, we develop two new relational learning to rank algorithms that can learn the document novelty function automatically.",0,,False
133,4.2.1 The ranking model,0,,False
134,"Following the notations used in Section 3.2 and Section 4.1,",0,,False
135,"let X ,"" {d1, · · · , dM } denotes the set of documents retrieved by a query q. Each query-document pair (q, d) is represented with the relevance feature vector x  Rlx . Each document d  X is characterized with its preliminary representation vector v  Rlv . Assuming that at one iteration of the sequential document selection, a set of documents S have been""",0,,False
136,selected. We define the marginal relevance score of a candi-,0,,False
137,date document d as:,0,,False
138,"f (d, S) ,""gr(x) + gn(v, S)""",0,,False
139,(4),0,,False
140,",""T x + µT max tanh vT W[1:z] v1, . . . , v|S| ,""",0,,False
141,"where gr(x) is the relevance of d w.r.t. query q, which is further defined as a linear combination of the relevance features; gn(v, S) is the novelty of d w.r.t. the documents in S, which is further defined as a neural tensor network, as have been shown in Section 3.2. The model parameters , µ, and W[1:z] can be learned with the training data.",0,,False
142,"In the online ranking, a diverse ranking can created with the sequential document selection process, similar to the procedure shown in Algorithm 1.",0,,False
143,1http://www.dmoz.org,0,,False
144,398,0,,False
145,"The main advantage of using neural tensor network to model document novelty is that the tensor can relate the candidate document and the selected documents multiplicatively, instead of only through a predefined similarity function (as that of in heuristic approaches) or through a linear combination of novelty features (as that of in learning approaches and shown in Equation (3)). Intuitively, the model can be explained that each slice of the tensor is responsible for one aspect or subtopic of a query. Each tensor slice settles the diversity relationship between the candidate document and the selected documents set differently. Thus, with multiple tensor slices, the model calculates the novelty scores based on multiple diversity aspects.",1,ad,True
146,4.2.2 General loss function,0,,False
147,The parameters of the ranking model can be determined,0,,False
148,"with supervised learning methods, which amounts to opti-",0,,False
149,mizing the objective function built upon the labeled training,0,,False
150,data.,0,,False
151,"In training procedure, given the labeled data with N queries as: (X(1), J (1)), (X(2), J (2)), · · · , (X(N), J (N)), where X(n) ,",0,,False
152,{dj(n),0,,False
153,}M (n),0,,False
154,"j,1",0,,False
155,",",0,,False
156,where,0,,False
157,M (n),0,,False
158,denotes,0,,False
159,the,0,,False
160,number,0,,False
161,of,0,,False
162,documents,0,,False
163,related with the n-th query. Let x(jn)  Rlx denote the rele-,0,,False
164,"vance feature vector for the n-th query and document d(jn),",0,,False
165,"vj(n)  Rlv the preliminary representation of document d(jn),",0,,False
166,and J(n) the human labels on documents which is in the,0,,False
167,"form of a binary matrix. Jj(sn) , 1 if document d(jn) con-",0,,False
168,tains the s-th subtopic of the query and 0 otherwise2. The,0,,False
169,learning process amounts to minimizing the total loss with,0,,False
170,respect to the given training data:,0,,False
171,N,0,,False
172,min,0,,False
173,"f F n,1",0,,False
174," X(n), f , J (n) ,",0,,False
175,"where  X(n), f denotes the ranking generated by the",0,,False
176,"ranking model f in Equation (4), for the documents in X(n). The generated ranking  is then compared with the human labels J(n) by the loss function . Intuitively, the learning process can be interpreted as finding an optimal ranking model f from some functional space F so that for each training query the difference between the generated permutation  and the human labels J is minimal.",0,,False
177,"Different objective functions and optimization techniques lead to different algorithms. In this section, based on the relational learning to rank algorithms of R-LTR [32] and PAMM [28], we construct two novel algorithms in which the document novelty is modeled with a neural tensor network, referred to as R-LTR-NTN and PAMM-NTN, respectively.",1,ad,True
178,4.2.3 R-LTR-NTN,0,,False
179,"Based on the loss function defined for R-LTR [32], we derive the loss function of R-LTR-NTN, which is a negative logarithm likelihood of the training queries:",0,,False
180,N,0,,False
181,"LR-LTR-NTN(f ) ,"" - log Pr Y (n)|X(n) ,""",0,,False
182,"n,1",0,,False
183,"where Y (n) is the ground-truth ranking generated from the human label J(n). For any query, the probability Pr(Y |X)",0,,False
184,2In this paper we assume that all labels are binary.,0,,False
185,Algorithm 2 The R-LTR-NTN Algorithm,0,,False
186,"Input: training data {(X(n), J(n))}Nn,""1 and learning rate  Output: model parameter (, µ, W[1:z])""",0,,False
187,"1: initialize {, µ, W[1:z]}  random values in [0, 1]",0,,False
188,2: repeat,0,,False
189,3: Shuffle the training data,0,,False
190,"4: for n ,"" 1, · · · , N do""",0,,False
191,5:,0,,False
192,"calculate (n), µ(n) and W[1:z](n)",0,,False
193,"{Equation (6), Equation (7), and Equation (8)}",0,,False
194,6:,0,,False
195,   -  × (n),0,,False
196,7:,0,,False
197,µ  µ -  × µ(n),0,,False
198,8:,0,,False
199,W[1:z]  W[1:z] -  × W[1:z](n),0,,False
200,9: end for,0,,False
201,10: until convergence,0,,False
202,"11: return (, µ, W[1:z])",0,,False
203,can be further defined as,0,,False
204,"Pr(Y |X) ,Pr(dY (1)dY (2) · · · dY (M)|X)",0,,False
205,M -1,0,,False
206,",",0,,False
207,"Pr(dY (r)|X, Sr-1)",0,,False
208,"r,1",0,,False
209,M -1,0,,False
210,",",0,,False
211,"r,1",0,,False
212,"exp{f (dY (r), Sr-1)}",0,,False
213,"M k,r",0,,False
214,exp{f,0,,False
215,(dY,0,,False
216,"(k) ,",0,,False
217,Sr-1,0,,False
218,)},0,,False
219,",",0,,False
220,(5),0,,False
221,"where Y (r) denotes the index of the document ranked at the r-th position in Y , Sr-1 , {dY (k)}rk-,""11 is the documents ranked at the top r - 1 positions in Y , f (dY (r), Sr-1) is the marginal relevance score of document dY (r) w.r.t. the selected documents in Sr-1, as defined in Equation (4), and""",0,,False
222,S0 is an empty set.,0,,False
223,Stochastic gradient descent is adopted to conduct the op-,1,ad,True
224,"timization. Given a query q, the retrieved documents X , {dj}M j,""1, and the ranking Y generated by the ground-truth labels, the gradient of the model parameters can be written""",1,ad,True
225,as,0,,False
226,M -1,0,,False
227," ,",0,,False
228,"r,1",0,,False
229,"M k,r",0,,False
230,exp,0,,False
231,f,0,,False
232,"dY (k), Sr-1",0,,False
233,xY (k),0,,False
234,"M k,r",0,,False
235,exp{f,0,,False
236,(dY,0,,False
237,"(k) ,",0,,False
238,Sr-1 )},0,,False
239,"- xY (r) , (6)",0,,False
240,M -1,0,,False
241,"µ ,",0,,False
242,"r,1",0,,False
243,"M k,r",0,,False
244,exp,0,,False
245,f,0,,False
246,"dY (k), Sr-1",0,,False
247,tY (k),0,,False
248,"M k,r",0,,False
249,exp{f,0,,False
250,(dY,0,,False
251,"(k) ,",0,,False
252,Sr-1)},0,,False
253,- tY (r),0,,False
254,", (7)",0,,False
255,M -1,0,,False
256,"W[i] ,",0,,False
257,"r,1",0,,False
258,"M k,r",0,,False
259,exp,0,,False
260,f,0,,False
261,"dY (k), Sr-1",0,,False
262,µiY (k),0,,False
263,"M k,r",0,,False
264,exp{f,0,,False
265,(dY,0,,False
266,"(k) ,",0,,False
267,Sr-1 )},0,,False
268,(8),0,,False
269,"-µiY (r) ,",0,,False
270,"where t is defined in Equation (2), and",0,,False
271,"Y (r) ,"" 1 - tanh2 vYT (r)W[i]vi vY (r)vTi , (9)""",0,,False
272,where   Rlv×lv and i(1  i  |S|) stands for the output of the max-pooling position for the i-th (1  i  z) tensor slice.,0,,False
273,Algorithm 2 shows the pseudo code of the R-LTR-NTN.,0,,False
274,4.2.4 PAMM-NTN,0,,False
275,"Based on the loss function defined for PAMM [28], we derive the loss function of PAMM-NTN, which is directly",0,,False
276,399,0,,False
277,defined over a diversity evaluation measure:,0,,False
278,Algorithm 3 The PAMM-NTN algorithm,0,,False
279,N,0,,False
280,"1 - E  X(n), f , J (n) ,",0,,False
281,(10),0,,False
282,"n,1",0,,False
283,"where E(·, ·)  [0, 1] is a diversity evaluation measure such as -NDCG or ERR-IA etc. It can be proved that the Equation (10) is upper bounded by",0,,False
284,N,0,,False
285,"LPAMM-NTN(f ) ,",0,,False
286,Pr(Y +|X(n)) - Pr(Y -|X(n)),0,,False
287,"n,1 Y +Y(n)+; Y - Y(n)-",0,,False
288," E(Y +,J (n))-E(Y -,J (n)) .",0,,False
289,where Y(n)+ and Y(n)- are the sets of positive and neg-,0,,False
290,"ative rankings generated from human labels J(n), respec-",0,,False
291,tively. · is one if the condition is satisfied otherwise zero.,0,,False
292,"Pr(·|·) stands for the probability of the ranking, as defined",0,,False
293,in Equation (5).,0,,False
294,"Also, stochastic gradient descent is adopted to conduct the",1,ad,True
295,"optimization. At each iteration, we are given a query q, the",0,,False
296,"retrieved documents X , {dj}M j,""1, a positive ranking Y +, and a negative ranking Y -. For convenience of calculation,""",0,,False
297,we,0,,False
298,resort,0,,False
299,to,0,,False
300,the,0,,False
301,optimization,0,,False
302,problem,0,,False
303,of,0,,False
304,max log,0,,False
305,Pr(Y Pr(Y,0,,False
306,+ |X ) - |X ),0,,False
307,.,0,,False
308,"Thus, the gradients of the parameters can be written as",1,ad,True
309,M -1,0,,False
310," ,",0,,False
311,"r,1",0,,False
312,-,0,,False
313,"M k,r",0,,False
314,exp,0,,False
315,"f (dY +(k), Sr-1)",0,,False
316,xY +(k),0,,False
317,"M k,r",0,,False
318,exp,0,,False
319,"f (dY +(k), Sr-1)",0,,False
320,"M k,r",0,,False
321,exp,0,,False
322,"f (dY -(k), Sr-1)",0,,False
323,xY -(k),0,,False
324,"M k,r",0,,False
325,exp,0,,False
326,"f (dY -(k), Sr-1)",0,,False
327,(11),0,,False
328,"-xY +(r) + xY -(r) ,",0,,False
329,M -1,0,,False
330,"µ ,",0,,False
331,"r,1",0,,False
332,-,0,,False
333,"M k,r",0,,False
334,exp,0,,False
335,"f (dY +(k), Sr-1)",0,,False
336,tY +(k),0,,False
337,"M k,r",0,,False
338,exp,0,,False
339,"f (dY +(k), Sr-1)",0,,False
340,"M k,r",0,,False
341,exp,0,,False
342,"f (dY -(k), Sr-1)",0,,False
343,tY -(k),0,,False
344,"M k,r",0,,False
345,exp,0,,False
346,"f (dY -(k), Sr-1)",0,,False
347,(12),0,,False
348,"Input: training data {(X(n), J (n))}Nn,""1, parameter: learning rate , diversity evaluation measure E,""",0,,False
349,number of positive/negative rankings per query  +/ -.,0,,False
350,"Output: model parameter (, µ, W[1:z])",0,,False
351,"1: for n , 1 to N do",0,,False
352,2: P R(n)  Sample positive rankings {[28]},0,,False
353,3: N R(n)  Sample negative rankings {[28]},0,,False
354,4: end for,0,,False
355,"5: initialize (, µ, W[1:z])  random values in [0, 1]",0,,False
356,6: repeat,0,,False
357,"7: for n , 1 to N do",0,,False
358,8:,0,,False
359,"for all {Y +, Y -}  P R(n) × N R(n) do",0,,False
360,9:,0,,False
361,P  Pr(Y +|X(n)) - Pr(Y -|X(n)),0,,False
362,{Pr(Y |X) is defined in Equation (5)},0,,False
363,10:,0,,False
364,"if P  E(Y +,J (n))-E(Y -,J (n)) then",0,,False
365,11:,0,,False
366,"calculate , µ and W[1:z]",0,,False
367,"{Equation (11), Equation (12), and Equation (13)}",0,,False
368,12:,0,,False
369,   +  × ,0,,False
370,13:,0,,False
371,µ  µ +  × µ,0,,False
372,14:,0,,False
373,W[1:z]  W[1:z] +  × W[1:z],0,,False
374,15:,0,,False
375,end if,0,,False
376,16:,0,,False
377,end for,0,,False
378,17: end for,0,,False
379,18: until convergence,0,,False
380,"19: return (, µ, W[1:z])",0,,False
381,"of order O(T ·N ·M 2 ·(lx +lv ·Z)), where T denotes the number of iterations, N the number of queries in training data, M the maximum number of documents per training query, lx the number of relevance features, lv the dimensions of the preliminary document representation, and Z the number of tensor slices. The learning process of PAMM-NTN (Algorithm 3) is of order O(T · N ·  + ·  - · M 2 · (lx + lv · Z)), where  + denotes the number of positive rankings per query and  - the number of negative rankings per query.The time complexity of online ranking prediction (Algorithm 1) is of order O(M · K · (lx + lv · Z)), where M is the number of candidate documents for the query and K denotes the number documents need to be ranked.",0,,False
382,5. EXPERIMENTS,0,,False
383,5.1 Experimental settings,0,,False
384,"-tY +(r) + tY -(r) ,",0,,False
385,M -1,0,,False
386,"W[i] ,",0,,False
387,"r,1",0,,False
388,-,0,,False
389,"M k,r",0,,False
390,exp,0,,False
391,"f (dY +(k), Sr-1)",0,,False
392,µiY +(k),0,,False
393,"M k,r",0,,False
394,exp,0,,False
395,"f (dY +(k), Sr-1)",0,,False
396,"M k,r",0,,False
397,exp,0,,False
398,"f (dY -(k), Sr-1)",0,,False
399,µiY -(k),0,,False
400,"M k,r",0,,False
401,exp,0,,False
402,"f (dY -(k), Sr-1)",0,,False
403,"-µiY +(r) + µiY -(r) ,",0,,False
404,"(13) where t is defined in Equation (2), and  is defined in Equation (9). Algorithm 3 shows the pseudo code of the PAMMNTN algorithm.",0,,False
405,4.2.5 Time complexities,0,,False
406,"We conducted experiments to test the performances of R-LTR-NTN and PAMM-NTN using three TREC benchmark datasets for diversity task: TREC 2009 Web Track (WT2009), TREC 2010 Web Track (WT2010), and TREC 2011 Web Track (WT2011). Each dataset consists of queries, corresponding retrieved documents, and human judged labels. Each query includes several subtopics identified by the TREC assessors. The document relevance labels were made at the subtopic level and the labels are binary3. Statistics on the datasets are given in Table 2.",1,TREC,True
407,"All the experiments were carried out on the ClueWeb09 Category B data collection4, which comprises of 50 million English web documents. Porter stemming, tokenization, and stop-words removal (using the INQUERY list) were applied to the documents as preprocessing. We conducted 5-fold cross-validation experiments on the three datasets. For each dataset, we randomly split the queries into five even subsets.",1,ClueWeb,True
408,We analyzed time complexities of R-LTR-NTN and PAMMNTN. The learning process of R-LTR-NTN (Algorithm 2) is,0,,False
409,3The graded judgements in WT2011 was treated as binary. 4http://boston.lti.cs.cmu.edu/data/clueweb09,1,ad,True
410,400,0,,False
411,"Table 2: Statistics on WT2009, WT2010 and WT2011. Dataset #queries #labeled docs #subtopics per query",1,WT,True
412,WT2009,1,WT,True
413,50,0,,False
414,WT2010,1,WT,True
415,48,0,,False
416,WT2011,1,WT,True
417,50,0,,False
418,5149 6554 5000,0,,False
419,38 37 26,0,,False
420,"At each fold three subsets were used for training, one was used for validation, and one was used for testing. The results reported were the average over the five trials.",0,,False
421,"The TREC official evaluation metrics for the diversity task were used in the experiments, including the ERR-IA [5], NDCG [6], and NRBP [7]. They measure the diversity of a result list by explicitly rewarding novelty and penalizing redundancy observed at every rank. Following the default settings in official TREC evaluation program, the parameters  and  in these evaluation measures are set to 0.5. We also used traditional diversity measures of Precision-IA (denoted as ""Pre-IA"") [1], and Subtopic Recall (denoted as ""Srecall"") [31]. All of the measures are computed over the top-k search results (k , 20).",1,TREC,True
422,We compared R-LTR-NTN and PAMM-NTN with several types of baselines. The baselines include three heuristic approaches to search result diversification.,0,,False
423,MMR [3] : a heuristic approach in which the document ranking is constructed via iteratively selecting the document with the maximal marginal relevance.,0,,False
424,xQuAD [26] : a representative heuristic approach to search result diversification which explicitly accounts for the various aspects associated to an under-specified query.,0,,False
425,PM-2 [8] : a method of optimizing proportionality for search result diversification.,0,,False
426,"Note that these baselines require a prior relevance function to implement their diversification steps. In our experiments, ListMLE [16, 18] was chosen as the relevance function.",0,,False
427,The baselines also include state-of-the-art learning approaches to search result diversification.,0,,False
428,SVM-DIV [29] : a learning approach in which structural SVMs was used to optimize the subtopic coverage.,0,,False
429,R-LTR [32] : a state-of-the-art learning approach developed in the relational learning to rank framework.,0,,False
430,PAMM [28] : another state-of-the-art learning algorithm that directly optimizes diversity evaluation measure.,0,,False
431,"Following the practice in [32], for the baseline of R-LTR, we used the results of R-LTRmin in which the relation function hS(R) was defined as the minimal distance of the candidate document to the selected documents.",0,,False
432,"For the baseline PAMM (and our approach PAMM-NTN), we configure them to directly optimize -NDCG@20 because it is one of the most widely used performance measures. Thus, the baseline of PAMM is denoted as PAMM(NDCG). Following the practice in [28], we set the number of sampled positive rankings per query  + , 5 and the number of sampled negative rankings per query  - , 20.",0,,False
433,5.2 Relevance features and preliminary document representations,0,,False
434,"As for the relevance features, we adopted the features used in R-LTR experiments [21], including the typical weighting",1,ad,True
435,Table 3: Relevance features used in the experiments.,0,,False
436,Each of the first 4 features is applied to the fields of,0,,False
437,"body, anchor, title, URL, and the whole documents. [32]",0,,False
438,Name Description,0,,False
439,# Features,0,,False
440,TF-IDF The tf-idf model,0,,False
441,5,0,,False
442,BM25 BM25 with default parameters,0,,False
443,5,0,,False
444,LMIR LMIR with Dirichlet smoothing,1,LM,True
445,5,0,,False
446,MRF [19] MRF with ordered/unordered phrase,0,,False
447,10,0,,False
448,PageRank PageRank score,0,,False
449,1,0,,False
450,#inlinks number of inlinks,0,,False
451,1,0,,False
452,#outlinks number of outlinks,0,,False
453,1,0,,False
454,"models (e.g., TF-IDF, BM25, LM) and term dependency model [19]. Table 3 summarized the relevance features. For all the query-document matching features, they were applied in five fields: body, anchor, title, URL, and the whole document, resulting in 5 features in total. Note that the MRF feature has two variations: ordered phrase and unordered phrase [19]. Thus the total number of MRF features becomes 10.",1,LM,True
455,"The neural tensor network need preliminary representations of the documents as its inputs. In the experiments, we used the document vector generated by the topic model of probabilistic latent semantic analysis (PLSA) [13] or the deep learning model of doc2vec [15], both are trained on all of the documents in ClueWeb09 Category B data collection and the number of latent dimensions are set to 100. For training the doc2vec model, we used the distributed bag of words (DBOW) model5. In all of the experiments, the learning rate is set to 0.025 and the window size is set to 8.",1,ClueWeb,True
456,"Our approaches (R-LTR-NTN and PAMM-NTN) with the settings of using the PLSA or doc2vec as document representations are denoted with the corresponding subscripts. For example, the R-LTR-NTN that using PLSA as document representations is denoted as R-LTR-NTNplsa. Thus, in all of the experiments, our approaches include R-LTRNTNplsa, R-LTR-NTNdoc2vec, PAMM-NTN(-NDCG)plsa, and PAMM-NTN(-NDCG)doc2vec. Please note in all of the experiments, PAMM-NTN was configured to direct optimize the evaluation measure of -NDCG@20.",0,,False
457,5.3 Experimental results,0,,False
458,"Table 4, Table 5, and Table 6 report the performances of the proposed methods and baselines in terms of 5 diversity metrics (ERR-IA@20, -NDCG@20, NRBP@20, PreIA@20, and S-recall@20) on the datasets of WT20096, WT2010, and WT2011, respectively. Boldface indicates the highest score among all runs. For all of our approaches, the number of tensor slices z is set to 7.",1,WT,True
459,"From the results we can see that, on all of the three datasets and in terms of the five diversity evaluation metrics, our approaches (R-LTR-NTNplsa, R-LTR-NTNdoc2vec, PAMM-NTN(-NDCG)plsa, and PAMM-NTN(-NDCG)doc2vec) can outperform all of the baselines. We conducted significant testing (t-test) on the improvements of our approaches over the baselines. The results indicate that the improvements of R-LTR-NTNplsa and R-LTR-NTNdoc2vec over RLTR are significant (p-value < 0.05), in terms of all of the",0,,False
460,5http://radimrehurek.com/gensim/models/doc2vec.html 6The performances of XQuAD reported in Table 4 are different to that of reported in [26]. It may caused by the different splitting of the dataset in cross validation.,1,ad,True
461,401,0,,False
462,Method,0,,False
463,Table 4: Performance comparison of all methods for WT2009.,1,WT,True
464,ERR-IA@20,0,,False
465,-NDCG@20 NRBP@20,0,,False
466,Pre-IA@20,0,,False
467,MMR xQuAD PM-2 SVM-DIV,0,,False
468,R-LTR,0,,False
469,R-LTR-NTNplsa R-LTR-NTNdoc2vec PAMM(-NDCG) PAMM-NTN(-NDCG)plsa PAMM-NTN(-NDCG)doc2vec,0,,False
470,0.2022 0.2316 0.2294 0.2408,0,,False
471,0.2714 0.3015 0.3117,0,,False
472,0.2842 0.3081 0.3135,0,,False
473,0.3083 0.3437 0.3369 0.3526,0,,False
474,0.3964 0.4444 0.4503,0,,False
475,0.4271 0.4377 0.4555,0,,False
476,0.1715 0.1956 0.1788 0.2073 0.2339 0.2563 0.2578 0.2411 0.2642 0.2626,0,,False
477,0.0918 0.0984 0.0949 0.1075,0,,False
478,0.1233 0.1588 0.1670,0,,False
479,0.1265 0.1661 0.1745,0,,False
480,S-recall@20,0,,False
481,0.4698 0.4931 0.4876 0.5101 0.5511 0.5743 0.5910,0,,False
482,0.5612 0.5755 0.5772,0,,False
483,Method,0,,False
484,Table 5: Performance comparison of all methods for WT2010.,1,WT,True
485,ERR-IA@20,0,,False
486,-NDCG@20 NRBP@20,0,,False
487,Pre-IA@20,0,,False
488,MMR xQuAD PM-2 SVM-DIV,0,,False
489,R-LTR,0,,False
490,R-LTR-NTNplsa R-LTR-NTNdoc2vec PAMM(-NDCG) PAMM-NTN(-NDCG)plsa PAMM-NTN(-NDCG)doc2vec,0,,False
491,0.2735 0.3278 0.3296 0.3331 0.3647 0.3876 0.3932,0,,False
492,0.3802 0.3898 0.3901,0,,False
493,0.4036 0.4445 0.4478 0.4593,0,,False
494,0.4924 0.5311 0.5376,0,,False
495,0.5249 0.5379 0.5407,0,,False
496,0.2252 0.2872 0.2901 0.2934 0.3293 0.3333 0.3623,0,,False
497,0.3431 0.3479 0.3553,0,,False
498,0.1722 0.1883 0.1885 0.1925 0.2042 0.2341 0.2418,0,,False
499,0.2111 0.2264 0.2386,0,,False
500,S-recall@20,0,,False
501,0.6444 0.6732 0.6749 0.6774 0.6893 0.6912 0.6994 0.6832 0.7006 0.7032,0,,False
502,Method,0,,False
503,Table 6: Performance comparison of all methods for WT2011.,1,WT,True
504,ERR-IA@20,0,,False
505,-NDCG@20 NRBP@20,0,,False
506,Pre-IA@20,0,,False
507,MMR xQuAD PM-2 SVM-DIV,0,,False
508,R-LTR,0,,False
509,R-LTR-NTNplsa R-LTR-NTNdoc2vec PAMM(-NDCG) PAMM-NTN(-NDCG)plsa PAMM-NTN(-NDCG)doc2vec,0,,False
510,0.4284 0.4753 0.4873 0.4898,0,,False
511,0.5389 0.5483 0.5538,0,,False
512,0.5417 0.5496 0.5554,0,,False
513,0.5302 0.5645 0.5786 0.5910,0,,False
514,0.6297 0.6537 0.6555,0,,False
515,0.6433 0.6469 0.6566,0,,False
516,0.3913 0.4274 0.4318 0.4475 0.4982 0.5050 0.5223,0,,False
517,0.5012 0.5111 0.5212,0,,False
518,0.3176 0.3299 0.3405 0.3468,0,,False
519,0.3921 0.4011 0.4125,0,,False
520,0.3955 0.4169 0.4177,0,,False
521,S-recall@20,0,,False
522,0.7567 0.7683 0.7743 0.7750 0.8512 0.8543 0.8590,0,,False
523,0.8518 0.8524 0.8533,0,,False
524,"performance measures. The results also indicate that the improvements of PAMM-NTN(-NDCG)plsa and PAMMNTN(-NDCG)doc2vec over all of the baselines are significant, in terms of all of the performance measures. The results indicate that the neural tensor network is effective for modeling the document novelty information, and thus can improve the performances.",0,,False
525,5.4 Discussions,0,,False
526,"We conducted experiments to show the reasons that our approaches outperformed the baselines and impacts of different parameter settings, using the results of R-LTR-NTNplsa and R-LTR-NTNdoc2vec on WT2009 dataset as examples.",1,WT,True
527,5.4.1 Ability to learn better document dissimilarities,0,,False
528,"We found that the learned neural tensor network can help to distinguish the relevant documents in terms of different subtopics, by learning a better dissimilarity (novelty) function for documents. That is one of the reasons why our approaches can outperform the baselines.",0,,False
529,"Specifically, the dissimilarities between two documents can be calculated based on the preliminary document representations, either using the Euclidean distance or using the learned neural tensor network (the novelty score of a document w.r.t. another document). That is, given two documents represented with the preliminary presentations vi and vj, the dissimilarity score can calculated either based",0,,False
530,on the Euclidean distance:,0,,False
531,"de(vi, vj ) ,"" vi - vj 2,""",0,,False
532,or based on the learned neural tensor network:,0,,False
533,"dn(vi, vj ) ,"" gn(vi, {vj }) "", µT tanh viT W[1:z]vj",0,,False
534,where µ and W[1:z] are learned with the R-LTR-NTN algorithms. Here we can ignore the max operation because there is only one document vj at the righthand of W[1:z].,0,,False
535,"Suppose we are given a set of queries and the associated relevant documents. For each query, the relevant documents can be grouped into several clusters, each corresponds a subtopic of the query. Thus, all of the associated documents from all queries are grouped into different clusters, each corresponds to a subtopic. We calculated the ratio of average inter-cluster documents dissimilarities to average intra-cluster document dissimilarities. It is obvious that in search result diversification, a good document dissimilarity function would get large inter-cluster document dissimilarities and small intra-cluster document dissimilarities (large ratio value). This is because such a dissimilarity function could discriminate the subtopics well.",0,,False
536,"Table 7 shows the ratios calculated based on different dissimilarity definitions and different preliminary document representations. From the results, we can see that the ratio of ""dn with PLSA"" (documents represented with PLSA topics and dissimilarities are calculated with neural tensor",0,,False
537,402,0,,False
538,Table 7: Ratio of average inter-cluster documents dis-,0,,False
539,similarities to average intra-cluster document dissimilar-,0,,False
540,ities. The documents are grouped according to their as-,0,,False
541,sociated subtopics. Method,0,,False
542,average dissimilarity ratio,0,,False
543,de with PLSA dn with PLSA de with doc2vec dn with doc2vec,0,,False
544,1.65 2.73 2.10 4.32,0,,False
545,"network) is larger than the ratio of ""de with PLSA"" (documents represented with PLSA topics and dissimilarities are calculated as Euclidean distance), and the ratio of ""dn with doc2vec"" is larger than the ratio of ""de with doc2vec"". The results indicates that the dissimilarity functions learned by the tensor neural network are better than the Euclidean distances, in terms of discriminating the query subtopics.",0,,False
546,"The conclusion is quite intuitive and nature because the parameters of neural tensor network are determined based on the labeled data and thus can be adapted to the specific dataset and task, while the Euclidean distance is a predefined function for all datasets and tasks. Therefore, we can conclude that R-LTR-NTN (and also PAMM-NTN) can improve the performances through learning a better document dissimilarity function which distinguishes the documents with different subtopics effectively.",1,ad,True
547,5.4.2 Ability to improve queries with high ambiguity,0,,False
548,"We also conducted experiments to show on which kinds of queries our approaches can perform well. Specifically, in each fold of the experiments on WT2009, we trained an R-LTR-NTNdoc2vec model, an R-LTR, and a PAMM(NDCG) model on the training data and tested them on the test data. We then grouped the queries in the test datasets according to the number of subtopics they associated. We compared the performances of these three models in terms of -NDCG@20 on each of the query groups and the results are shown in Figure 3. Boldface indicates the number of associated subtopics by the candidate documents, and the numbers in the parentheses indicate the proportion of queries in that group to the number of all queries. Please note that in Figure 3 some queries associated with only one or two subtopics while in Table 2 all queries have at least 3 subtopics associated. This is because we used the Indri7 toolkit to retrieve the top 1000 documents as the candidates. Some labeled documents may not be ranked at top 1000 and thus be eliminated from the candidate set.",1,WT,True
549,"From the results reported in Figure 3, we can see that for those queries that associated with only one or two subtopics, R-LTR-NTN performed worse than the baselines of R-LTR and PAMM(-NDCG). However, for those queries that associated with three or more subtopics (queries with high ambiguity), R-LTR-NTN outperformed the baselines. We also observed the trends that larger improvements R-LTRNTN can achieve on the queries with more subtopics. The results is also intuitive because the document relations are more complex for ambiguous queries and neural tensor network can model the complex document relationship better. Thus, we can conclude that R-LTR-NTN can improve the baselines through improving the high ambiguity queries.",0,,False
550,7http://lemurproject.org/indri,0,,False
551,0.44,0,,False
552,-NDCG@20,0,,False
553,0.42,0,,False
554,0.4,0,,False
555,R-LTR,0,,False
556,PAMM(-NDCG),0,,False
557,0.38,0,,False
558,R-LTR-NTNdoc2vec,0,,False
559,0.36,0,,False
560,0.34,0,,False
561,1(4%) 2(6%) 3(22%)4(34%)5(24%) 6(1%) query grouped by the number of subtopics,0,,False
562,Figure 3: Performances with respect to query groups with different number of subtopics. The numbers in the parentheses indicate the proportion of queries in that group to the number of all queries.,0,,False
563,0.46,0,,False
564,time (hours),0,,False
565,-NDCG@20,0,,False
566,20 0.45,0,,False
567,15,0,,False
568,0.44 10,0,,False
569,0.43 5,0,,False
570,R-LTR-NTNdoc2vec,0,,False
571,training time,0,,False
572,0.42,0,,False
573,0,0,,False
574,1 3 5 7 9 11 13 15 17 19,0,,False
575,the number of tensor slices z,0,,False
576,Figure 4: Ranking accuracies and training time with respect to the number of tensor slices z.,0,,False
577,5.4.3 Effects of the number of tensor slices,0,,False
578,"Finally, we conducted experiments to test if the proposed algorithms are sensitive to the model parameters. One of the most important parameters in the proposed method is the number of tensor slices z. Thus, in the experiments we tested if R-LTR-NTNdoc2vec is sensitive to different settings of z values. Specifically, we tuned z by varying the values of parameter z from 1 to 19, with step 2 and fixing other model parameters to the default or optimal values. Figure 4 shows the performances of R-LTR-NTNdoc2vec with respect to number of slices z, in terms of -NDCG@20. The training time (in hours) with respect to z are also shown in the figure.",0,,False
579,"From the results, we can see that the performances did not change much with different z values, which indicates R-LTR-NTNdoc2vec (and other proposed algorithms) are robust and not sensitive to the parameter settings. In all of the experiments the number of tensor slices was set to the optimal value 7.",0,,False
580,"One of the negative effects of increasing z values is that the training time increased dramatically with the creased z values, as shown in Figure 4. This is because much more operations are needed for training the model if z is increased. Please refer to Section 4.2.5 for the time complexities of the proposed algorithms.",0,,False
581,403,0,,False
582,6. CONCLUSIONS,0,,False
583,"How to model the novelty of a candidate document with respect to other documents is one of the key problems in search result diversification. Existing approaches have been hurt from the necessaries of predefining a document similarity function or a set of novelty features, which are usually hard in real applications. In this paper we proposed to model the novelty of a document with a neural tensor network, which enables us to automatically learns a nonlinear novelty function based on the preliminary representations of the candidate document and other documents. Under the framework of relational learning to rank, new diverse learning to rank models have been derived, by replacing the novelty term in the original objective function with the neural tensor network. Experimental results based on three benchmark datasets showed that the proposed models significantly outperformed the baseline methods, including the state-of-the-art relational learning to rank models. Experimental results also showed that the proposed algorithms can improve the baselines via learning a document dissimilarity function that matches well with the query subtopics. The results also showed that more improvements can be achieved on the queries with high ambiguity.",0,,False
584,"As future work, we would like to verify the effectiveness of the proposed algorithms on applications other than search result diversification such as multi-document summarization etc. We also want to study the approaches to learning the relevance features and novelty features simultaneously.",0,,False
585,7. ACKNOWLEDGMENTS,0,,False
586,"The work was funded by the 973 Program of China under Grants No. 2014CB340401 and 2012CB316303, the 863 Program of China under Grants No. 2014AA015204, the National Natural Science Foundation of China (NSFC) under Grants No. 61232010, 61472401, 61433014, 61425016, and 61203298, the Key Research Program of the Chinese Academy of Sciences under Grant No. KGZD-EW-T03-2, and the Youth Innovation Promotion Association CAS under Grants No. 20144310 and 2016102.",1,ad,True
587,8. REFERENCES,0,,False
588,"[1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of ACM WSDM '09, pages 5­14, 2009.",0,,False
589,"[2] S. Bhatia. Multidimensional search result diversification: Diverse search results for diverse users. In Proceedings of ACM SIGIR '11, pages 1331­1332, 2011.",0,,False
590,"[3] J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of ACM SIGIR '98, pages 335­336, 1998.",0,,False
591,"[4] B. Carterette and P. Chandar. Probabilistic models of ranking novel documents for faceted topic retrieval. In Proceedings of ACM CIKM '09 pages 1287­1296, 2009.",0,,False
592,"[5] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In Proceedings of ACM CIKM '09, pages 621­630, 2009.",1,ad,True
593,"[6] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Bu¨ttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In Proceedings of ACM SIGIR '08, pages 659­666, 2008.",1,Novelty,True
594,"[7] C. L. Clarke, M. Kolla, and O. Vechtomova. An effectiveness measure for ambiguous and underspecified queries. In Proceedings of ICTIR '09, pages 188­199, 2009.",0,,False
595,"[8] V. Dang and W. B. Croft. Diversity by proportionality: An election-based approach to search result diversification. In Proceedings of ACM SIGIR '12, pages 65­74, 2012.",0,,False
596,"[9] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. Indexing by latent semantic analysis. JASIS, 41(6):391­407, 1990.",0,,False
597,"[10] S. Gollapudi and A. Sharma. An axiomatic approach for result diversification. In Proceedings ofWWW '09, pages 381­390, 2009.",0,,False
598,"[11] S. Guo and S. Sanner. Probabilistic latent maximal marginal relevance. In Proceedings ofACM SIGIR '10, pages 833­834, 2010.",0,,False
599,"[12] J. He, V. Hollink, and A. de Vries. Combining implicit and explicit topic representations for result diversification. In Proceedings of ACM SIGIR '12, pages 851­860, 2012.",0,,False
600,"[13] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of ACM SIGIR '99, pages 50­57, 1999.",0,,False
601,"[14] S. Hu, Z. Dou, X. Wang, T. Sakai, and J.-R. Wen. Search result diversification based on hierarchical intents. In Proceedings of ACM CIKM '15, pages 63­72, 2015.",0,,False
602,"[15] Q. V. Le and T. Mikolov. Distributed Representations of Sentences and Documents. ArXiv e-prints, May 2014.",0,,False
603,"[16] H. Li. Learning to rank for information retrieval and natural language processing; 2nd ed. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publ., San Rafael, CA, 2014.",0,,False
604,"[17] L. Li, K. Zhou, G.-R. Xue, H. Zha, and Y. Yu. Enhancing diversity, coverage and balance for summarization through structure learning. In Proceedings of WWW '09, pages 71­80, 2009.",0,,False
605,"[18] T.-Y. Liu. Learning to rank for information retrieval. Found. Trends Inf. Retr., 3(3):225­331, Mar. 2009.",0,,False
606,"[19] D. Metzler and W. B. Croft. A markov random field model for term dependencies. In Proceedings of ACM SIGIR '05, pages 472­479, 2005.",0,,False
607,"[20] L. Mihalkova and R. Mooney. Learning to disambiguate search queries from short sessions. In W. Buntine, M. Grobelnik, D. MladeniA¨ G , and J. Shawe-Taylor, editors, Machine Learning and Knowledge Discovery in Databases, volume 5782 of Lecture Notes in Computer Science, pages 111­127. Springer Berlin Heidelberg, 2009.",1,ad,True
608,"[21] T. Qin, T.-Y. Liu, J. Xu, and H. Li. Letor: A benchmark collection for research on learning to rank for information retrieval. Inf. Retr., 13(4):346­374, Aug. 2010.",0,,False
609,"[22] F. Radlinski and S. Dumais. Improving personalized web search using result diversification. In Proceedings of ACM SIGIR '06, pages 691­692, 2006.",1,ad,True
610,"[23] F. Radlinski, R. Kleinberg, and T. Joachims. Learning diverse rankings with multi-armed bandits. In Proceedings of ACM ICML '08, pages 784­791, 2008.",1,ad,True
611,"[24] D. Rafiei, K. Bharat, and A. Shukla. Diversifying web search results. In Proceedings of WWW '10, pages 781­790, 2010.",0,,False
612,"[25] K. Raman, P. Shivaswamy, and T. Joachims. Online learning to diversify from implicit feedback. In Proceedings of ACM SIGKDD '12, pages 705­713, 2012.",0,,False
613,"[26] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting query reformulations for web search result diversification. In Proceedings of WWW '10, pages 881­890, 2010.",0,,False
614,"[27] R. Socher, D. Chen, C. D. Manning, and A. Ng. Reasoning with neural tensor networks for knowledge base completion. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 926­934. Curran Associates, Inc., 2013.",0,,False
615,"[28] L. Xia, J. Xu, Y. Lan, J. Guo, and X. Cheng. Learning maximal marginal relevance model via directly optimizing diversity evaluation measures. In Proceedings of ACM SIGIR '15, pages 113­122, 2015.",0,,False
616,"[29] Y. Yue and T. Joachims. Predicting diverse subsets using structural svms. In Proceedings of ACM ICML '08, pages 1224­1231, 2008.",0,,False
617,"[30] Y. Yue and T. Joachims. Interactively optimizing information retrieval systems as a dueling bandits problem. In Proceedings of ACM ICML '09, pages 1201­1208, 2009.",0,,False
618,"[31] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond independent relevance: Methods and evaluation metrics for subtopic retrieval. In Proceedings of ACM SIGIR '03, pages 10­17, 2003.",0,,False
619,"[32] Y. Zhu, Y. Lan, J. Guo, X. Cheng, and S. Niu. Learning for search result diversification. In Proceedings of ACM SIGIR '14, pages 293­302, 2014.",0,,False
620,404,0,,False
621,,0,,False
