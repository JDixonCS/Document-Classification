,sentence,label,data,regex
0,Two Sample T-tests for IR Evaluation: Student or Welch?,0,,False
1,Tetsuya Sakai,0,,False
2,"Waseda University, Japan.",0,,False
3,tetsuyasakai@acm.org,0,,False
4,ABSTRACT,0,,False
5,"There are two well-known versions of the t-test for comparing means from unpaired data: Student's t-test and Welch's t-test. While Welch's t-test does not assume homoscedasticity (i.e., equal variances), it involves approximations. A classical textbook recommendation would be to use Student's t-test if either the two sample sizes are similar or the two sample variances are similar, and to use Welch's t-test only when both of the above conditions are violated. However, a more recent recommendation seems to be to use Welch's t-test unconditionally. Using past data from both TREC and NTCIR, the present study demonstrates that the latter advice should not be followed blindly in the context of IR system evaluation. More specifically, our results suggest that if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's t-test may not be reliable.",1,TREC,True
6,Keywords,0,,False
7,statistical significance; test collections; topics; variances,0,,False
8,1. INTRODUCTION,1,DUC,True
9,"The present study concerns IR evaluation where two means from different samples need to be compared. The classical approach for this would be to employ a two-sample (i.e., unpaired) t-test to discuss whether, given the observed sample means, the population means may be different. There are two well-known versions of the two-sample t-test: Student's t-test and Welch's t-test. While Welch's t-test does not assume homoscedasticity (i.e., equal variances), it involves approximations. A classical textbook recommendation would be to use Student's t-test if either the two sample sizes n1, n2 are similar or the two sample variances V1, V2 are similar, and to use Welch's t-test only when both of the above conditions are violated [3]. However, a more recent recommendation seems to be to use Welch's t-test unconditionally. For example, Daniel Laken's blog posted on January 26, 2015 recommends researchers to ""Always use Welch's t-test instead of Student's t-test,"" while demonstrating the superiority of Welch's t-test using simu-",1,blog,True
10,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17 - 21, 2016, Pisa, Italy",1,ad,True
11,c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2914684,0,,False
12,"lated data1. The t.test function provided in the stats library of the R language uses Welch's t-test by default2; hence researchers who use this function as a black box may well be using Welch's t-test all the time. In fact, in as far back as 1981, Gans [1] recommended ""the automatic use of the Welch test alone"" as an option, based on simulations. The present study seeks to obtain the right recommendations for the purpose of IR system evaluation using real data from TREC and NTCIR.",1,TREC,True
13,2. PRIOR ART,0,,False
14,"In the IR evaluation literature, researchers have focussed mainly on the paired data setting, because the most basic method for comparing two IR systems is to use the same test collection with a single topic set to compare two systems. For example, Smucker et al. [7] compared the sign test, the Wilcoxon signed rank test, the paired t-test, the bootstrap test and the randomisation test from the viewpoint of how similar the p-values of different test types are to one another, and concluded that the use of the two nonparametric tests (sign and Wilcoxon) should be discontinued. Urbano et al. [8] conducted a follow-up study on the same set of paired significance tests, using repeated topic set splitting experiments in a way similar to earlier studies (e.g. [10]) to quantify the discrepancies across the pairs of topic sets for comparing two systems. Contrary to the recommendation by Smucker et al., Urbano et al. report that ""the permutation test is not optimal under any criterion.""",0,,False
15,"In contrast to the aforementioned studies, the present study concerns two-sample t-tests for comparing two means, with sample sizes n1, n2. Possible applications of two-sample tests in IR include comparing sets of clicks from two different search engines, between-subject design user experiments, and comparing the ""hardness"" of two test collections using the same IR system. Sakai [4] used the two-sample bootstrap test (in addition to the paired bootstrap test) for the purpose of comparing different evaluation measures in terms of ""discriminative power.""",1,ad,True
16,3. T-TEST: STUDENT'S AND WELCH'S,0,,False
17,The common assumptions are as follows. We have scores,0,,False
18,"x11, . . . , x1n1 that each obey N (1, 12), as well as x21, . . . , x2n1",0,,False
19,"that each obey N (2, 22). The population means and variances",0,,False
20,"(·'s and ·2's) are unknown, and we want to test if 1 ,"" 2,""",0,,False
21,given sample means x¯1,0,,False
22,",",0,,False
23,1 n1,0,,False
24,"n1 j,1",0,,False
25,x1j,0,,False
26,and x¯2,0,,False
27,",",0,,False
28,1 n2,0,,False
29,"n2 j,1",0,,False
30,x2j,0,,False
31,.,0,,False
32,"Let S1 ,",0,,False
33,"n1 j,1",0,,False
34,(x1j,0,,False
35,"- x¯1)2, S2",0,,False
36,",",0,,False
37,"n2 j,1",0,,False
38,(x2j,0,,False
39,-,0,,False
40,x¯2)2,0,,False
41,for,0,,False
42,later,0,,False
43,purposes.,0,,False
44,1http://daniellakens.blogspot.nl/2015/01/ always-use-welchs-t-test-instead-of.html 2http://127.0.0.1:27533/library/stats/html/t.test.html,1,blog,True
45,1045,0,,False
46,3.1 Student's t-test,0,,False
47,"Student's two-sample t-test further assumes homoscedasticity: 12 ,"" 22. While this is a strong assumption, it is also known that this test is quite robust to assumption violations. For this test, we""",0,,False
48,"first define a pooled variance V , (S1 + S2)/ where  is the degree of freedom for V given by  ,"" 1 +2, 1 "","" n1 -1, 2 "", n2 - 1. The test statistic is:",0,,False
49,"t0 ,",0,,False
50,x¯1 - x¯2 V (1/n1 + 1/n2),0,,False
51,(1),0,,False
52,"which is compared against t(; ), the critical t value for  , n1 + n2 - 2 degrees of freedom with the significance level of .",0,,False
53,3.2 Welch's t-test,0,,False
54,"The good news about Welch's t-test is that it does not assume homoscedasticity; the bad news is that it involves approximations [3], as briefly discussed below. Let V1 ,"" S1/1, V2 "","" S2/2. For this test, the test statistic is""",1,ad,True
55,"tw0 ,",0,,False
56,x¯1 - x¯2 V1/n1 + V2/n2,0,,False
57,(2),0,,False
58,"which is compared against t(; ), where",0,,False
59,",",0,,False
60,(,0,,False
61,V1 n1,0,,False
62,+,0,,False
63,V2 n2,0,,False
64,)2/{,0,,False
65,(V1/n1 1,0,,False
66,)2,0,,False
67,+,0,,False
68,(V2/n2 2,0,,False
69,)2,0,,False
70,},0,,False
71,.,0,,False
72,(3),0,,False
73,Welch's t-test approximates the distribution of the following statistic by a 2 distribution with 0 degrees of freedom:,0,,False
74,W,0,,False
75,",",0,,False
76,0(,0,,False
77,V1 n1,0,,False
78,+,0,,False
79,V2 n2,0,,False
80,)/(,0,,False
81,12 n1,0,,False
82,+,0,,False
83,22 n2,0,,False
84,),0,,False
85,.,0,,False
86,(4),0,,False
87,"Furthermore, it estimates 0 as ^0 ,  using Eq. 3. Do these approximations have any consequences for IR evaluation?",0,,False
88,3.3 Analytical Relationships,0,,False
89,"Nagata [3] clarifies the relationship between the above two ttests analytically. Let a ,"" n2/n1, b "", V2/V1. Then it is easy to derive that the ratio of the two test statictics tw0/t0 is given by:",0,,False
90,tw0 t0,0,,False
91,","" g(a, b) "",",0,,False
92,(a,0,,False
93,+ 1){n1(ab + 1) - (b + 1)} (a + b)(n1(a + 1) - 2),0,,False
94,.,0,,False
95,(5),0,,False
96,"Note that g(1, b) ,"" g(a, 1) "","" 1. Hence, if either n1 "", n2 or V1 ,"" V2 holds, then t0 "","" tw0 holds. In practice, if the larger sample is no larger than 1.5 times the other, or if the larger variance is no larger than 1.5 times the other, t0 and tw0 will differ by at most 20% or so [3]. As for the degrees of freedom, it can be shown that:""",0,,False
97,","" h(a, b)""",0,,False
98,",",0,,False
99,{a2(an1,0,,False
100,(a + b)2(n1 - 1)(an1 - 1) - 1) + b2(n1 - 1)}{(a + 1)n1,0,,False
101,- 2},0,,False
102,.,0,,False
103,(6),0,,False
104,"Since h(1, 1) ,"" 1 holds, having n1 "", n2 and V1 , V2 is a sufficient condition for obtaining  ,"" . Also, it can be verified that h(a, b) "", / is much smaller than one if b , V2/V1 is close to one and a ,"" n2/n1 is far from one. That is, Welch's t-test""",0,,False
105,has relatively low statistical power (due to its degree of freedom  being much smaller than Student's ) when the variances are,0,,False
106,roughly equal but the sample sizes are quite different.,0,,False
107,4. EXPERIMENTS,0,,False
108,"In order to compare Student's and Welch's t-tests in terms of reliability, we adopt a method similar to that of Webber et al. [11]: given a topic set of size n, with m runs that processed these topics,",1,ad,True
109,Table 1: Test collections and runs used in this study.,0,,False
110,TREC99,1,TREC,True
111,NTCIR97,0,,False
112,"Topics (n) 601-700 minus 672 (99) T41-385 minus 86, 331, 362 (97)",0,,False
113,Runs (m) TREC 2004 robust (110) NTCIR-7 IR4QA Chinese (40),1,TREC,True
114,Qrels,0,,False
115,L2: relevant; L1: partially relevant; L0: judged nonrelevant,0,,False
116,Table 2: Sample size ratios experimented in this study.,0,,False
117,Target ratio,0,,False
118,Actual ratio (TREC99) Actual ratio (NTCIR97),1,TREC,True
119,"50:50 (a , 1.0)",0,,False
120,50:49,0,,False
121,50:47,0,,False
122,"40:60 (a , 1.5)",0,,False
123,40:59,0,,False
124,40:57,0,,False
125,"30:70 (a , 2.3) 10:90 (a , 9.0)",0,,False
126,30:69 10:89,0,,False
127,30:67 10:87,0,,False
128,"randomly partition the topics into two sets of size n1 and n2, respectively. For each of the m runs and a given evaluation measure, conduct a two-sided, two-sample test to see if the two means for the same run are statistically significant. The ground truth is that they are not, since the scores actually come from the same system. The random partitioning is done B ,"" 1000 times, so a test collection with m runs will yield Bm "", 1000m p-values for each significance test type with a given evaluation measure.",0,,False
129,"Table 1 shows a summary of the two data sets used in this study. We chose them because (a) we wanted about n ,"" 100 topics (or more if available) with graded relevance assessments; (b) we wanted data (with many runs) from different evaluation conferences to ensure generalisability. """"TREC99"""" comprises 110 runs from the TREC 2004 robust track [9], with 99 robust track topics. While this data set has many runs, the 99 topics come from two robust track rounds: 50 from TREC 2003 and 49 from 2004. In contrast, """"NTCIR97,"""" which comprises 40 Simplified Chinese runs from the NTCIR-7 ACLIA IR4QA task [6], uses 97 topics that originate from a single round of the task.""",1,ad,True
130,"For each data set with a given evaluation measure, we experimented with four different sample size ratios a ,"" n2/n1 as shown in Table 2 to obtain a total of 4000m p-values. Recall that, according to Nagata [3], Student's and Welch's t statistics should not be vastly different for the a "", 1 (n1 : n2 , 50 : 50) and a , 1.5 (n1 : n2 ,"" 40 : 60) settings, regardless of how the two sample variances differ. We experimented with four evaluation measures: (binary) Average Precision (AP), Q-measure (Q), normalised Discounted Cumulative Gain (nDCG) and normalised Expected Reciprocal Rank (nERR). Unlike the other three measures, nERR is known to be suitable for navigational information needs due to its diminishing return property; for this very reason, it is known to be statistically less stable than the other measures [5].""",1,AP,True
131,5. RESULTS AND DISCUSSIONS,0,,False
132,"Figure 1 plots Welch's p-values against Student's p-values for the 110,000 two-sample t-tests conducted with the TREC99 data, for nDCG ((a)-(d)) and nERR ((e)-(h)) with different target sample size ratios. The graphs for TREC99 with AP and Q, as well all all graphs for NTCIR97, are omitted due to lack of space. However, the overall picture is the same for all evaluation measures and across the two data sets, and we believe that our findings are general. In each graph, the blue rectangle represents the situation where Student's t-test obtains a p-value smaller than  ,"" 0.05 (i.e., a false positive) while Welch's t-test does not; the red rectangle represents the opposite situation; the bottom left square represents the situation where both tests obtain a false alarm at  "", 0.05. It can be observed that when the target sample size ratio is a , 1 (n1 : n2 ,"" 50 : 50), the two tests are indeed virtually identical and false alarms are very rare; as we gradually increase the sample size ratio until it reaches a "", 9.0 (n1 : n2 ,"" 10 : 90), we obtain more and more false alarms on both sides of the diagonal.""",1,TREC,True
133,1046,0,,False
134,Figure 1: Welch's vs. Student's p-values: TREC99; 110 runs; nDCG (top) and nERR (bottom).,1,TREC,True
135,"Tables 3 and 4 show the false positive rates for all of our TREC99 and NTCIR97 experiments, respectively. Based on the discussion provided in Section 3.3, we categorised the observations into three classes: the first is for those where the variance ratio satisfies 2/3  b  3/2: recall that Student's and Welch's t statistics are expected to be similar to each other in this situation. The other two classes (b < 2/3 and b > 3/2) represent the situations where the sample variances are very different. For example, Table 3 Section (III) Column (d) provides the following information about our TREC99 experiments for nDCG with the sample size ratio a , 9.0 (with the actual sample sizes n1 ,"" 10, n2 "", 89 as shown in Table 1):",1,TREC,True
136,"· For 64,447 out of the 110,000 observations, the sample variance ratio b ,"" V2/V1 satisfied 2/3  b  3/2; for these observations, the false positive rate was 4.0% for Student's t-test and 2.6% for Welch's t-test;""",0,,False
137,"· For 16,614 out of the 110,000 observations, b < 2/3; for these observations, the false positive rate was 4.9% for Student's t-test and 0.7% for Welch's t-test;",0,,False
138,"· For 28,939 out of the 110,000 observations, b > 3/2; for these observations, the false positive rate was 5.6% for Student's t-test and 14.1% for Welch's t-test;",0,,False
139,"· Overall, for the 110,000 observations, the false positive rate was 4.6% for Student's t-test and 5.3% for Welch's t-test. Thus, Welch's t-test slightly underperforms Student's, due to its very high false positive rate for the b > 3/2 setting.",0,,False
140,"More generally, we can observe the following consistent trends from Tables 3 and 4:",0,,False
141,"· When the two sample sizes are equal (Column (a)), Student's and Welch's t-tests perform equally well, regardless of the range of b3. The overall false positive rates are 4.9-5.2%.",0,,False
142,"3When n1 ,"" n2, note that the variance ratio conditions b < 2/3""",0,,False
143,"· When the two variances are similar (2/3  b  3/2), the false positive rates of the two tests are very small (1.0-4.8%), although, as discussed immediately below, Student's t-test yields more false positive than Welch's when the sample size ratio a , n2/n1 is extreme (Column (d));",0,,False
144,"· As we increase the sample size ratio a ,"" n2/n1, Welch's ttest yields more and more false positives when b "","" V2/V1 > 3/2. That is, if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's ttest may not be reliable for two-sample IR evaluation. In particular, when a "", n2/n1 ,"" 9 (Column (d)), the false positive rates for Welch's t-test are 14.1-24.6% whereas those for Student's t-test are only 4.4-13.5%. Whereas, as we increase the sample size ratio a, Student's t-test yields more and more false positives when b  3/2 (i.e., 2/3  b  3/2 or b < 2/3), but this tendency is not as marked as Welch's for the b > 3/2 range. As a result, in terms of the overall false positive rates, Welch's t-test is actually slightly less reliable than the Student's t-test when a is very large.""",0,,False
145,"The above results, based on real IR system runs from both TREC and NTCIR, suggest that the advice ""Always use Welch's t-test instead of Student's t-test"" should not be followed blindly in IR system evaluation.",1,TREC,True
146,6. CONCLUSIONS,0,,False
147,"For the purpose of reliable IR system evaluation, we compared two versions of two-sample t-tests: Student's t-test (which assumes homoscedasticity) and Welch's t-test (which relies on approximated distributions). Our topic set splitting experiments with runs from",0,,False
148,"and b > 3/2 are equivalent: it is just a matter of swapping the two samples, since the two tests are symmetric with respect to the two samples. So we should expect similar results in Column (a) for these two ranges of b. The slight caveat is that we actually have n1 n2 rather than n1 ,"" n2, as n1 + n2 "", 99 or 97.",0,,False
149,1047,0,,False
150,"Table 3: TREC99 false positives at  , 0.05: Student/Welch.",1,TREC,True
151,The higher false positive rate in each condition is shown in,0,,False
152,bold. The total number of observations for each variance ra-,0,,False
153,tio is shown in parentheses.,0,,False
154,"(a) 50:50 a , 1.0",0,,False
155,"(b) 40:60 a , 1.5",0,,False
156,"(c) 30:70 a , 2.3",0,,False
157,"(d) 10:90 a , 9.0",0,,False
158,2/3  b  3/2 b < 2/3,0,,False
159,b > 3/2,0,,False
160,All,0,,False
161,2/3  b  3/2 b < 2/3,0,,False
162,b > 3/2,0,,False
163,All,0,,False
164,2/3  b  3/2 b < 2/3,0,,False
165,b > 3/2,0,,False
166,All,0,,False
167,2/3  b  3/2 b < 2/3,0,,False
168,b > 3/2,0,,False
169,All,0,,False
170,"3.5%/3.5% (91,286)",0,,False
171,"11.9%/12.0% (9,192)",0,,False
172,"15.0%/14.7% (9,522)",0,,False
173,"5.2%/5.2% (110,000)",0,,False
174,"3.7%/3.7% (90,299)",0,,False
175,"11.1%/11.1% (9,620)",0,,False
176,"13.3%/13.2% (10,081)",0,,False
177,"5.2%/5.2% (110,000)",0,,False
178,"4.4%/4.4% (94,936)",0,,False
179,"7.7%/7.7% (7,640)",0,,False
180,"8.4%/8.3% (7,424)",0,,False
181,"4.9%/4.9% (110,000)",0,,False
182,"4.8%/4.7% (107,590) 10.5%/10.8% (1,165) 13.9%/13.5% (1,245) 4.9%/4.9% (110,000)",0,,False
183,(I) AP 3.4%/3.4%,1,AP,True
184,"(90,405) 10.9%/8.5%",0,,False
185,"(8,887) 13.0%/15.7%",0,,False
186,"(10,708) 4.9%/5.0% (110,000)",0,,False
187,(II) Q 3.5%/3.5%,0,,False
188,"(89,563) 10.5%/7.9%",0,,False
189,"(9,252) 11.6%/14.3%",0,,False
190,"(11,185) 4.9%/5.0% (110,000)",0,,False
191,(III) nDCG 4.4%/4.4%,0,,False
192,"(94,480) 7.0%/5.4%",0,,False
193,"(7,076) 7.9%/9.5%",0,,False
194,"(8,444) 4.9%/4.9% (110,000)",0,,False
195,"(IV) nERR 4.4%/4.4% (107,161) 10.4%/8.3%",0,,False
196,"(1,126) 14.4%/16.8%",0,,False
197,"(1,713) 4.6%/4.7% (110,000)",0,,False
198,"3.2%/3.1% (87,833)",0,,False
199,"9.7%/5.7% (9,374)",0,,False
200,"9.9%/15.9% (12,793)",0,,False
201,"4.5%/4.8% (110,000)",0,,False
202,"3.5%/3.4% (86,872)",0,,False
203,"8.9%/4.9% (9,763)",0,,False
204,"8.5%/14.2% (13,365)",0,,False
205,"4.6%/4.8% (110,000)",0,,False
206,"4.2%/4.2% (90,837)",0,,False
207,"6.6%/4.0% (7,710)",0,,False
208,"7.6%/12.1% (11,453)",0,,False
209,"4.7%/5.0% (110,000)",0,,False
210,"4.3%/4.3% (105,953) 6.0%/3.1% (1,196) 14.1%/20.6% (2,851) 4.6%/4.7% (110,000)",0,,False
211,"2.8%/1.6% (62,674)",0,,False
212,"7.7%/0.7% (16,938)",0,,False
213,"6.0%/18.4% (30,388)",0,,False
214,"4.5%/6.1% (110,000)",0,,False
215,"3.2%/1.9% (61,402)",0,,False
216,"7.6%/0.7% (17,285)",0,,False
217,"5.5%/16.9% (31,313)",0,,False
218,"4.5%/6.0% (110,000)",0,,False
219,"4.0%/2.6% (64,447)",0,,False
220,"4.9%/0.7% (16,614)",0,,False
221,"5.6%/14.1% (28,939)",0,,False
222,"4.6%/5.3% (110,000)",0,,False
223,"3.0%/2.1% (87,017)",0,,False
224,"1.7%/0.1% (7,485)",0,,False
225,"13.5%/24.2% (15,498)",0,,False
226,"4.4%/5.1% (110,000)",0,,False
227,"both TREC and NTCIR are consistent across different evaluation measures and across these two different IR venues. While neither our equal variance settings nor our equal sample size settings do not demonstrate any advantages of Student's t-test over Welch's t-test, our results do suggest that if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's t-test may be less reliable. Hence we argue that the advice ""Always use Welch's t-test instead of Student's t-test"" should not be followed blindly in IR system evaluation.",1,TREC,True
228,"In practice, we recommend IR researchers to examine the sample sizes n1, n2 and the sample variances V1, V2 first and then make a conscious decision, rather than (say) relying on a default setting in the t.test function provided in R. We also recommend IR researchers to report explicitly which version of the two-sample ttest was used in their experiments, even if we may be able to spot a Welch's t-test when the degree of freedom reported is not an integer (Eq. 3).",0,,False
229,Acknowledgement,0,,False
230,I would like to thank Professor Yasushi Nagata for his helpful comments on my results.,0,,False
231,7. REFERENCES,0,,False
232,"[1] D. J. Gans. Use of a preliminary test in comparing two sample means. Communications in Statistics - Simuation and Computation, 10(2):163­174, 1981.",0,,False
233,"Table 4: NTCIR97 false positives at  , 0.05: Student/Welch.",0,,False
234,The higher false positive rate in each condition is shown in,0,,False
235,bold. The total number of observations for each variance ra-,0,,False
236,tio is shown in parentheses.,0,,False
237,"(a) 50:50 a , 1.0",0,,False
238,"(b) 40:60 a , 1.5",0,,False
239,"(c) 30:70 a , 2.3",0,,False
240,"(d) 10:90 a , 9.0",0,,False
241,2/3  b  3/2 b < 2/3,0,,False
242,b > 3/2,0,,False
243,All,0,,False
244,2/3  b  3/2 b < 2/3,0,,False
245,b > 3/2,0,,False
246,All,0,,False
247,2/3  b  3/2 b < 2/3,0,,False
248,b > 3/2,0,,False
249,All,0,,False
250,2/3  b  3/2 b < 2/3,0,,False
251,b > 3/2,0,,False
252,All,0,,False
253,"4.3%/4.3% (33,683) 8.8%/9.2% (3,233) 9.7%/8.9% (3,084) 5.1%/5.0% (40,000)",0,,False
254,"3.9%/3.9% (33,043) 9.0%/9.3% (3,575) 10.4%/9.9% (3,382) 4.9%/4.9% (40,000)",0,,False
255,"1.8%/1.8% (29,136) 12.9%/13.5% (5,578) 13.7%/13.0% (5,286) 4.9%/4.9% (40,000)",0,,False
256,"2.0%/2.0% (32,698) 17.9%/18.5% (3,715) 20.1%/19.2% (3,587) 5.1%/5.1% (40,000)",0,,False
257,(I) AP 4.3%/4.3%,1,AP,True
258,"(33,587) 9.3%/6.1%",0,,False
259,"(2,965) 9.0%/11.8%",0,,False
260,"(3,448) 5.0%/5.1%",0,,False
261,"(40,000) (II) Q",0,,False
262,"4.1%/4.1% (33,085)",0,,False
263,"10.3%/7.1% (3,203)",0,,False
264,"9.5%/11.9% (3,712)",0,,False
265,"5.1%/5.1% (40,000) (III) nDCG",0,,False
266,"1.8%/1.8% (29,193)",0,,False
267,"14.2%/11.1% (5,076)",0,,False
268,"12.6%/16.1% (5,731)",0,,False
269,"4.9%/5.0% (40,000) (IV) nERR",0,,False
270,"1.7%/1.7% (32,303)",0,,False
271,"18.0%/14.7% (3,498)",0,,False
272,"18.7%/23.2% (4,199)",0,,False
273,"4.9%/5.1% (40,000)",0,,False
274,"4.2%/4.2% (32,716)",0,,False
275,"10.7%/5.1% (2,949)",0,,False
276,"7.5%/14.8% (4,335)",0,,False
277,"5.0%/5.4% (40,000)",0,,False
278,"4.1%/4.0% (32,135)",0,,False
279,"10.7%/5.6% (3,300)",0,,False
280,"8.1%/15.4% (45,65)",0,,False
281,"5.1%/5.4% (40,000)",0,,False
282,"1.8%/1.7% (27,739)",0,,False
283,"14.9%/8.2% (5,318)",0,,False
284,"9.9%/17.7% (6,943)",0,,False
285,"4.9%/5.3% (40,000)",0,,False
286,"1.5%/1.4% (31,171)",0,,False
287,"18.2%/10.7% (3,625)",0,,False
288,"15.1%/24.5% (5,204)",0,,False
289,"4.8%/5.3% (40,000)",0,,False
290,"3.6%/2.3% (24,263)",0,,False
291,"7.2%/0.4% (6,277)",0,,False
292,"6.8%/23.4% (9,460)",0,,False
293,"4.9%/7.0% (40,000)",0,,False
294,"3.5%/2.2% (23,172)",0,,False
295,"7.6%/0.4% (6,766)",0,,False
296,"6.4%/23.2% (10,062)",0,,False
297,"4.9%/7.2% (40,000)",0,,False
298,"2.2%/1.1% (18,548)",0,,False
299,"11.7%/1.1% (8,533)",0,,False
300,"4.4%/22.4% (12,919)",0,,False
301,"4.9%/8.0% (40,000)",0,,False
302,"2.2%/1.0% (21,570)",0,,False
303,"12.4%/1.7% (7,159)",0,,False
304,"5.0%/24.6% (11,270)",0,,False
305,"4.9%/7.8% (40,000)",0,,False
306,"[2] D. Hawking and N. Craswell. The very large collection and web tracks. In E. M. Voorhees and D. K. Harman, editors, TREC: Experiment and Evaluation in Information Retrieval, chapter 9. The MIT Press, 2005.",1,TREC,True
307,"[3] Y. Nagata. How to Understand Statistical Methods (in Japanese). Nikkagiren, 1996.",0,,False
308,"[4] T. Sakai. Evaluating evaluation metrics based on the bootstrap. In Proceedings of ACM SIGIR 2006, pages 525­532, 2006.",0,,False
309,"[5] T. Sakai. Metrics, statistics, tests. In PROMISE Winter School 2013: Bridging between Information Retrieval and Databases (LNCS 8173), pages 116­163, 2014.",0,,False
310,"[6] T. Sakai, N. Kando, C.-J. Lin, T. Mitamura, H. Shima, D. Ji, K.-H. Chen, and E. Nyberg. Overview of the NTCIR-7 ACLIA IR4QA task. In Proceedings of NTCIR-7, pages 77­114, 2008.",0,,False
311,"[7] M. D. Smucker, J. Allan, and B. Carterette. A comparison of statistical significance tests for information retrieval evaluation. In Proceedings of ACM CIKM 2007, pages 623­632, 2007.",0,,False
312,"[8] J. Urbano, M. Marrero, and D. Martín. A comparison of the optimality of statistical significance tests for information retrieval evaluation. In Proceedings of ACM SIGIR 2013, pages 925­928, 2013.",0,,False
313,"[9] E. M. Voorhees. Overview of the TREC 2004 robust retrieval track. In Proceedings of TREC 2004, 2005.",1,TREC,True
314,"[10] E. M. Voorhees. Topic set size redux. In Proceedings of ACM SIGIR 2009, pages 806­807, 2009.",0,,False
315,"[11] W. Webber, A. Moffat, and J. Zobel. Score standardization for inter-collection comparison of retrieval systems. In Proceedings of ACM SIGIR 2008, pages 51­58, 2008.",0,,False
316,1048,0,,False
317,,0,,False
