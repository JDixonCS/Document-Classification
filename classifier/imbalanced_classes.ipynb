{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Imbalanced_Classes.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1GTN2Q9XyFLIyex-nmuU7PB8k4tUmSW-q\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import csv\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import os\n",
        "# print(os.listdir(\"../input\"))\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "raw = open(r\"C:\\\\Users\\\\z3696\\\\Documents\\\\Document-Classification\\\\classifier\\\\NIST_FULL\\\\2019-neg.txt\", encoding=\"ISO-8859-1\")\n",
        "lines = raw.readlines()\n",
        "raw.close()\n",
        "\n",
        "# remove /n at the end of each line\n",
        "for index, line in enumerate(lines):\n",
        "    lines[index] = line.strip()\n",
        "    print(lines[index])\n",
        "\n",
        "neg_2019_df = pd.DataFrame(columns=['sentence'])\n",
        "i = 0\n",
        "first_col = \"\"\n",
        "for line in lines:\n",
        "    first_col = re.sub(r' \\(.*', \"\", line)\n",
        "    neg_2019_df.loc[i] = [first_col]\n",
        "    i = i+1\n",
        "\n",
        "neg_2019_df.head()\n",
        "neg_2019_df['label'] = 0\n",
        "#print(neg_2019_df)\n",
        "\n",
        "raw1 = open(r\"C:\\\\Users\\\\z3696\\\\Documents\\\\Document-Classification\\\\classifier\\\\NIST_FULL\\\\2019-pos.txt\", encoding=\"ISO-8859-1\")\n",
        "lines1 = raw1.readlines()\n",
        "raw1.close()\n",
        "\n",
        "# remove /n at the end of each line\n",
        "for index, line in enumerate(lines1):\n",
        "    lines1[index] = line.strip()\n",
        "    print(lines1[index])\n",
        "\n",
        "pos_2019_df = pd.DataFrame(columns=['sentence'])\n",
        "i = 0\n",
        "first_col = \"\"\n",
        "for line in lines1:\n",
        "    first_col = re.sub(r' \\(.*', \"\", line)\n",
        "    pos_2019_df.loc[i] = [first_col]\n",
        "    i = i+1\n",
        "\n",
        "pos_2019_df.head()\n",
        "pos_2019_df['label'] = 1\n",
        "#print(pos_2019_df)\n",
        "\n",
        "df = df.append(pos_2019_df)\n",
        "df = df.append(neg_2019_df)\n",
        "print(df)\n",
        "df.shape\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support as score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stopwords.words('english')\n",
        "\n",
        "#Removing punctuations from entire dataset\n",
        "punc_set = string.punctuation\n",
        "punc_set\n",
        "\n",
        "#Function for removing punctions\n",
        "def remove_punc(text):\n",
        "    clean = \"\".join([x.lower() for x in text if x not in punc_set])\n",
        "    return clean\n",
        "\n",
        "#Applying the 'remove_punc' function to entire dataset\n",
        "df['no_punc'] = df['sentence'].apply(lambda z:remove_punc(z))\n",
        "\n",
        "#Function for Tokenizing entire data for representing every word as datapoint\n",
        "def tokenize(text):\n",
        "    tokens = re.split(\"\\W+\",text)\n",
        "    return tokens\n",
        "\n",
        "#Applying the 'tokenize' function to entire dataset\n",
        "df['tokenized_Data'] = df['no_punc'].apply(lambda z:tokenize(z))\n",
        "\n",
        "#Importing stopwords from NLTK Library to remove stopwords now that we have tokenized it\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "#Function for removing stopwords from single row\n",
        "def remove_stopwords(tokenized_words):\n",
        "    Ligit_text=[word for word in tokenized_words if word not in stopwords]\n",
        "    return Ligit_text\n",
        "\n",
        "#Applying the function 'remove_stopwords' from the entire dataset\n",
        "df[\"no_stop\"] = df[\"tokenized_Data\"].apply(lambda z:remove_stopwords(z))\n",
        "\n",
        "#Importing 'WordNetLemmatizer' as lemmatizing function to find lemma's of words\n",
        "wnl = nltk.wordnet.WordNetLemmatizer()\n",
        "\n",
        "#Function for lemmatizing the tokenzied text\n",
        "def lemmatizing(tokenized_text):\n",
        "    lemma = [wnl.lemmatize(word) for word in tokenized_text]\n",
        "    return lemma\n",
        "\n",
        "#Applying the 'lemmatizing' function to entire dataset\n",
        "df['lemmatized'] = df['no_stop'].apply(lambda z:lemmatizing(z))\n",
        "\n",
        "# #Importing the 'SnowballStemmer' and declaring variable 'sno' to save the stemmer in.\n",
        "# #This Stemmer gives slightly better results as compared to 'PorterStemmer'\n",
        "# sno = nltk.SnowballStemmer('english')\n",
        "\n",
        "# #Function for applying stemming to find stem roots of all words\n",
        "# def stemming(tokenized_text):\n",
        "#     text= [sno.stem(word) for word in tokenized_text]\n",
        "#     return text\n",
        "\n",
        "# #Applying the 'stemming' function to entire dataset\n",
        "# data['ss_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))\n",
        "\n",
        "\n",
        "# ps = nltk.PorterStemmer()\n",
        "\n",
        "# def stemming(tokenized_text):\n",
        "#     text= [ps.stem(word) for word in tokenized_text]\n",
        "#     return text\n",
        "\n",
        "# data['ps_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))\n",
        "\n",
        "#This step is done here because, the 'lemmatized' column is a list of tokenized words and when we apply vectorization\n",
        "#techniques such as count vectorizer or TFIDF, they require string input. Hence convert all tokenzied words to string\n",
        "df['lemmatized'] = [\" \".join(review) for review in df['lemmatized'].values]\n",
        "\n",
        "df.head()\n",
        "\n",
        "#Splitting data into smaller dataframes for the purpose of Training and Testing\n",
        "x1 = df.iloc[1:47990,5]\n",
        "x2 = df.iloc[47991:95980,5]\n",
        "y1 = df.iloc[1:47990,1]\n",
        "y2 = df.iloc[47991:95980,1]\n",
        "#x_seg = df.iloc[0:5,5]\n",
        "#y_seg = df.iloc[0:5,1]\n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(y1.shape)\n",
        "print(y2.shape)\n",
        "\n",
        "'''\n",
        "x = df['lemmatized'].values\n",
        "y = df['label'].values\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "'''\n",
        "\n",
        "#Declaring and applying TFIDF functions to train and test data\n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
        "tfidf_train = tfidf_vect.fit_transform(x1.values)\n",
        "tfidf_test=tfidf_vect.transform(x2.values)\n",
        "print(tfidf_train.shape)\n",
        "print(tfidf_test.shape)\n",
        "#tfidf_train.toarray()\n",
        "\n",
        "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "x_tfidf = tfidf_vect.fit_transform(df[\"lemmatized\"])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_tfidf,df[\"label\"],test_size=0.5)\n",
        "\n",
        "log = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)\n",
        "model_lr = log.fit(x_train,y_train)\n",
        "probs_lr = model_lr.predict_proba(x_test)[:, 1]\n",
        "ly_prediction = log.predict(x_test)\n",
        "fly = f1_score(ly_prediction,y_test)\n",
        "print(\"===Logistic Regression with TfidfVectorizer Imbalanced - 2019===\")\n",
        "print('Logistic F1-score',fly*100)\n",
        "print('Logistic ROCAUC score:',roc_auc_score(y_test, ly_prediction)*100)\n",
        "print('Logistic Recall score:', recall_score(y_test, ly_prediction)*100)\n",
        "print('Logistic Precision Score:', precision_score(y_test, ly_prediction)*100)\n",
        "print('Logistic Confusion Matrix', confusion_matrix(y_test,ly_prediction), \"\\n\")\n",
        "print('Logistic Classification', classification_report(y_test,ly_prediction), \"\\n\")\n",
        "print('Logistic Accuracy Score', accuracy_score(y_test, ly_prediction)*100)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DCT = DecisionTreeClassifier()\n",
        "model_dt = DCT.fit(x_train, y_train)\n",
        "probs_dt = model_dt.predict_proba(x_test)[:, 1]\n",
        "dct_pred = DCT.predict(x_test)\n",
        "fdct = f1_score(dct_pred,y_test)\n",
        "print(\"===DecisionTreeClassifier with TfidfVectorizer Imbalanced - 2019===\")\n",
        "print('DCT F1-score',fdct*100)\n",
        "print('DCT ROCAUC score:',roc_auc_score(y_test, dct_pred)*100)\n",
        "print('DCT Recall score:', recall_score(y_test, dct_pred)*100)\n",
        "print('DCT Precision Score:', precision_score(y_test, dct_pred)*100)\n",
        "print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), \"\\n\")\n",
        "print('DCT Classification', classification_report(y_test, dct_pred), \"\\n\")\n",
        "print('DCT Accuracy Score', accuracy_score(y_test, dct_pred)*100)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "Naive = MultinomialNB()\n",
        "model_nb = Naive.fit(x_train,y_train)\n",
        "probs_nb = model_nb.predict_proba(x_test)[:, 1]\n",
        "# predict the labels on validation dataset\n",
        "ny_pred = Naive.predict(x_test)\n",
        "fna = f1_score(ny_pred,y_test)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"===Naive Bayes with TfidfVectorizer Imabalanced - 2019 ===\")\n",
        "print('Naive F1-score',fna*100)\n",
        "print('Naive ROCAUC score:',roc_auc_score(y_test, ny_pred)*100)\n",
        "print('Naive Recall score:', recall_score(y_test, ny_pred)*100)\n",
        "print('Naive Precision Score:', precision_score(y_test, ny_pred)*100)\n",
        "print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), \"\\n\")\n",
        "print('Naive Classification', classification_report(y_test, ny_pred), \"\\n\")\n",
        "print('Naive Accuracy Score', accuracy_score(y_test, ny_pred)*100)\n",
        "\n",
        "# XGBoost Classifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "xgb_model = XGBClassifier().fit(x_train, y_train)\n",
        "probs_xg = xgb_model.predict_proba(x_test)[:, 1]\n",
        "# predict\n",
        "xgb_y_predict = xgb_model.predict(x_test)\n",
        "fxg = f1_score(xgb_y_predict,y_test)\n",
        "print(\"===XGB with TfidfVectorizer Imbalanced - 2019===\")\n",
        "print('XGB F1-Score', fxg*100)\n",
        "print('XGB ROCAUC Score:', roc_auc_score(xgb_y_predict, y_test)*100)\n",
        "print('XGB Recall score:', recall_score(xgb_y_predict, y_test)*100)\n",
        "print('XGB Precision Score:', precision_score(xgb_y_predict, y_test)*100)\n",
        "print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), \"\\n\")\n",
        "print('XGB Classification', classification_report(xgb_y_predict, y_test), \"\\n\")\n",
        "print('XGB Accuracy Score', accuracy_score(xgb_y_predict, y_test)*100)\n",
        "'''\n",
        "# Support Vector Machine Classifier\n",
        "from sklearn.svm import SVC\n",
        "csvm_model = SVC(C=1.0, kernel='linear', degree=3, gamma='auto').fit(x_train,y_train)\n",
        "probs_cs = csvm_model.predict_proba(x_test)[:, 1]\n",
        "# predict the labels on validation dataset\n",
        "csvy_pred = csvm_model.predict(x_test)\n",
        "fcsvm = f1_score(csvy_pred,y_test)\n",
        "print(\"===C-SVM with TfidfVectorizer Imbalanced - 2019===\")\n",
        "print('C-SVM F1-score',fcsvm*100)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print('C-SVM ROCAUC score:',roc_auc_score(y_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Recall score:', recall_score(y_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Precision Score:', precision_score(y_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Confusion Matrix', confusion_matrix(y_test, csvy_pred), \"\\n\")\n",
        "print('C-SVM Classification', classification_report(y_test, csvy_pred), \"\\n\")\n",
        "print('C-SVM Accuracy Score', accuracy_score(y_test, csvy_pred)*100, \"\\n\")\n",
        "'''\n",
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train,y_train)\n",
        "probs_rf = rfc_model.predict_proba(x_test)[:, 1]\n",
        "rfc_pred = rfc_model.predict(x_test)\n",
        "frfc = f1_score(rfc_pred,y_test)\n",
        "print(\"====RandomForest with Tfidf Imbalanced 2019====\")\n",
        "print('RFC F1 score', frfc*100)\n",
        "print('RFC ROCAUC Score:', roc_auc_score(y_test, rfc_pred)*100)\n",
        "print('RFC Recall score:', recall_score(y_test, rfc_pred)*100)\n",
        "print('RFC Precision Score:', precision_score(y_test, rfc_pred)*100)\n",
        "print('RFC Confusion Matrix', confusion_matrix(y_test,rfc_pred), \"\\n\")\n",
        "print('RFC Classification', classification_report(y_test,rfc_pred), \"\\n\")\n",
        "print('RFC Accuracy Score', accuracy_score(y_test,rfc_pred)*100)\n",
        "\n",
        "\n",
        "from sklearn.metrics import auc, precision_recall_curve\n",
        "\n",
        "y_test_int = y_test.replace({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "baseline_model = sum(y_test_int == 1) / len(y_test_int)\n",
        "\n",
        "precision_lr, recall_lr, _ = precision_recall_curve(y_test_int, probs_lr)\n",
        "auc_lr = auc(recall_lr, precision_lr)\n",
        "\n",
        "precision_dt, recall_dt, _ = precision_recall_curve(y_test_int, probs_dt)\n",
        "auc_dt = auc(recall_dt, precision_dt)\n",
        "\n",
        "precision_nb, recall_nb, _ = precision_recall_curve(y_test_int, probs_nb)\n",
        "auc_nb = auc(recall_nb, precision_nb)\n",
        "\n",
        "precision_xg, recall_xg, _ = precision_recall_curve(y_test_int, probs_xg)\n",
        "auc_xg = auc(recall_xg, precision_xg)\n",
        "'''\n",
        "precision_cs, recall_cs, _ = precision_recall_curve(y_test_int, probs_cs)\n",
        "auc_cs = auc(recall_cs, precision_cs)\n",
        "'''\n",
        "precision_rf, recall_rf, _ = precision_recall_curve(y_test_int, probs_rf)\n",
        "auc_rf  = auc(recall_rf, precision_rf)\n",
        "'''\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot([0, 1], [baseline_model, baseline_model], linestyle='--', label='Baseline model')\n",
        "plt.plot(recall_lr, precision_lr, label=f'AUC Log. Reg. Imb.) = {auc_lr:.2f}')\n",
        "plt.plot(recall_dt, precision_dt, label=f'AUC Dec. Tree Imb.) = {auc_dt:.2f}')\n",
        "plt.plot(recall_nb, precision_nb, label=f'AUC Nai Bay. Imb.) = {auc_rf:.2f}')\n",
        "plt.plot(recall_xg, precision_xg, label=f'AUC XGB Imb.) = {auc_xg:.2f}')\n",
        "'''\n",
        "'''\n",
        "plt.plot(recall_lr1, precision_lr1, label=f'AUC Log. Reg. ROS) = {auc_lr:.2f}')\n",
        "plt.plot(recall_dt1, precision_dt1, label=f'AUC Dec. Tree ROS) = {auc_dt:.2f}')\n",
        "plt.plot(recall_nb1, precision_nb1, label=f'AUC Nai Bay. ROS) = {auc_rf:.2f}')\n",
        "plt.plot(recall_xg1, precision_xg1, label=f'AUC XGB ROS) = {auc_xg:.2f}')\n",
        "plt.plot(recall_lr2, precision_lr2, label=f'AUC Log. Reg. ROS) = {auc_lr2:.2f}')\n",
        "plt.plot(recall_dt2, precision_dt2, label=f'AUC Dec. Tree ROS) = {auc_dt2:.2f}')\n",
        "plt.plot(recall_nb2, precision_nb2, label=f'AUC Nai Bay. ROS) = {auc_rf2:.2f}')\n",
        "plt.plot(recall_xg2, precision_xg2, label=f'AUC XGB ROS) = {auc_xg2:.2f}')\n",
        "\n",
        "plt.title('Precision-Recall Curves 2019: Imbalanced', size=20)\n",
        "plt.xlabel('Recall', size=14)\n",
        "plt.ylabel('Precision', size=14)\n",
        "plt.legend()\n",
        "plt.show();\n",
        "'''\n",
        "df['label'].value_counts()\n",
        "\n",
        "import seaborn as sns\n",
        "g = sns.countplot(df['label'])\n",
        "g.set_xticklabels(['Negative','Positive'])\n",
        "plt.show()\n",
        "\n",
        "# class count\n",
        "label_count_neg, label_count_pos = df['label'].value_counts()\n",
        "\n",
        "# Separate class\n",
        "label_neg = df[df['label'] == 0]\n",
        "label_pos = df[df['label'] == 1]# print the shape of the class\n",
        "print('Label Negative:', label_neg.shape)\n",
        "print('Label Positive:', label_pos.shape)\n",
        "\n",
        "label_neg_under = label_neg.sample(label_count_pos)\n",
        "\n",
        "test_under = pd.concat([label_neg_under, label_pos], axis=0)\n",
        "\n",
        "print(\"total class of pos and neg :\",test_under['label'].value_counts())# plot the count after under-sampeling\n",
        "test_under['label'].value_counts().plot(kind='bar', title='label (target)')\n",
        "\n",
        "label_pos_over = label_pos.sample(label_count_neg, replace=True)\n",
        "\n",
        "test_over = pd.concat([label_pos_over, label_neg], axis=0)\n",
        "\n",
        "print(\"total class of pos and neg:\",test_under['label'].value_counts())# plot the count after under-sampeling\n",
        "test_over['label'].value_counts().plot(kind='bar', title='label (target)')\n",
        "\n",
        "import imblearn\n",
        "\n",
        "# import library\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "x = x_tfidf\n",
        "y = df['label']\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\n",
        "x_rus, y_rus = rus.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_rus))\n",
        "\n",
        "# import library\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "x =x_tfidf\n",
        "y = df[\"label\"]\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "#RUS = RandomOverSampler(random_state=42)\n",
        "#Random over-sampling with imblearn\n",
        "# fit predictor and target variable\n",
        "x_rus, y_rus = rus.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_rus))\n",
        "#Random over-sampling with imblearn\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_ros, y_ros = ros.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "# import library\n",
        "\n",
        "# Under-sampling: Tomek links\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "tl = RandomOverSampler(sampling_strategy='majority')\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_tl, y_tl = ros.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "\n",
        "# import library\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import NearMiss\n",
        "\n",
        "nm = NearMiss()\n",
        "\n",
        "x_nm, y_nm = nm.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape:', Counter(y_nm))\n",
        "\n",
        "#====RandomUnderSampler=====\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x_tl,y_tl,test_size=0.5)\n",
        "\n",
        "log = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)\n",
        "model_lr1 = log.fit(x1_train,y1_train)\n",
        "probs_lr1 = model_lr1.predict_proba(x1_test)[:, 1]\n",
        "ly_prediction = log.predict(x1_test)\n",
        "fly = f1_score(ly_prediction,y1_test)\n",
        "print(\"===Logistic Regression with TfidfVectorizer Tomelinks - 2019===\")\n",
        "print('Logistic F1-score',fly*100)\n",
        "print('Logistic ROCAUC score:',roc_auc_score(y1_test, ly_prediction)*100)\n",
        "print('Logistic Recall score:', recall_score(y1_test, ly_prediction)*100)\n",
        "print('Logistic Precision Score:', precision_score(y1_test, ly_prediction)*100)\n",
        "print('Logistic Confusion Matrix', confusion_matrix(y1_test,ly_prediction), \"\\n\")\n",
        "print('Logistic Classification', classification_report(y1_test,ly_prediction), \"\\n\")\n",
        "print('Logistic Accuracy Score', accuracy_score(y1_test, ly_prediction)*100)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DCT = DecisionTreeClassifier()\n",
        "model_dt1 = DCT.fit(x1_train, y1_train)\n",
        "probs_dt1 = model_dt1.predict_proba(x1_test)[:, 1]\n",
        "dct_pred = DCT.predict(x1_test)\n",
        "fdct = f1_score(dct_pred,y1_test)\n",
        "print(\"===DecisionTreeClassifier with TfidfVectorizer Tomelinks - 2019===\")\n",
        "print('DCT F1-score',fdct*100)\n",
        "print('DCT ROCAUC score:',roc_auc_score(y1_test, dct_pred)*100)\n",
        "print('DCT Recall score:', recall_score(y1_test, dct_pred)*100)\n",
        "print('DCT Precision Score:', precision_score(y1_test, dct_pred)*100)\n",
        "print('DCT Confusion Matrix', confusion_matrix(y1_test, dct_pred), \"\\n\")\n",
        "print('DCT Classification', classification_report(y1_test, dct_pred), \"\\n\")\n",
        "print('DCT Accuracy Score', accuracy_score(y1_test, dct_pred)*100)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "Naive = MultinomialNB()\n",
        "model_nb1 = Naive.fit(x1_train,y1_train)\n",
        "probs_nb1 = model_nb1.predict_proba(x1_test)[:, 1]\n",
        "# predict the labels on validation dataset\n",
        "ny_pred = Naive.predict(x1_test)\n",
        "fna = f1_score(ny_pred,y1_test)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"===Naive Bayes with TfidfVectorizer Tomelinks - 2019 ===\")\n",
        "print('Naive F1-score',fna*100)\n",
        "print('Naive ROCAUC score:',roc_auc_score(y1_test, ny_pred)*100)\n",
        "print('Naive Recall score:', recall_score(y1_test, ny_pred)*100)\n",
        "print('Naive Precision Score:', precision_score(y1_test, ny_pred)*100)\n",
        "print('Naive Confusion Matrix', confusion_matrix(y1_test, ny_pred), \"\\n\")\n",
        "print('Naive Classification', classification_report(y1_test, ny_pred), \"\\n\")\n",
        "print('Naive Accuracy Score', accuracy_score(y1_test, ny_pred)*100)\n",
        "\n",
        "# XGBoost Classifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "XGB = XGBClassifier()\n",
        "xgb_model1 = XGB.fit(x1_train,y1_train)\n",
        "probs_xg1 = xgb_model1.predict_proba(x1_test)[:, 1]\n",
        "# predict\n",
        "xgb_y_predict = xgb_model1.predict(x1_test)\n",
        "fxg = f1_score(xgb_y_predict,y1_test)\n",
        "print(\"===XGB with TfidfVectorizer Tomelinks- 2019===\")\n",
        "print('XGB F1-Score', fxg*100)\n",
        "print('XGB ROCAUC Score:', roc_auc_score(xgb_y_predict, y1_test)*100)\n",
        "print('XGB Recall score:', recall_score(xgb_y_predict, y1_test)*100)\n",
        "print('XGB Precision Score:', precision_score(xgb_y_predict, y1_test)*100)\n",
        "print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y1_test), \"\\n\")\n",
        "print('XGB Classification', classification_report(xgb_y_predict, y1_test), \"\\n\")\n",
        "print('XGB Accuracy Score', accuracy_score(xgb_y_predict, y1_test)*100)\n",
        "'''\n",
        "# Support Vector Machine Classifier\n",
        "from sklearn.svm import SVC\n",
        "csvm_model1 = SVC(C=1.0, kernel='linear', degree=3, gamma='auto').fit(x_train,y_train)\n",
        "probs_cs1 = csvm_model1.predict_proba(x1_test)[:, 1]\n",
        "# predict the labels on validation dataset\n",
        "csvy_pred = csvm_model1.predict(x1_test)\n",
        "fcsvm = f1_score(csvy_pred,y1_test)\n",
        "print(\"===C-SVM with TfidfVectorizer Tomelinks - 2019===\")\n",
        "print('C-SVM F1-score',fcsvm*100)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print('C-SVM ROCAUC score:',roc_auc_score(y1_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Recall score:', recall_score(y1_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Precision Score:', precision_score(y1_test, csvy_pred)*100, \"\\n\")\n",
        "print('C-SVM Confusion Matrix', confusion_matrix(y1_test, csvy_pred), \"\\n\")\n",
        "print('C-SVM Classification', classification_report(y1_test, csvy_pred), \"\\n\")\n",
        "print('C-SVM Accuracy Score', accuracy_score(y1_test, csvy_pred)*100, \"\\n\")\n",
        "'''\n",
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_model1 = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train,y_train)\n",
        "probs_rf1 = rfc_model.predict_proba(x1_test)[:, 1]\n",
        "rfc_pred = rfc_model.predict(x1_test)\n",
        "frfc = f1_score(rfc_pred,y1_test)\n",
        "print(\"====RandomForest with Tfidf Tomelinks-  2019====\")\n",
        "print('RFC F1 score', frfc*100)\n",
        "print('RFC ROCAUC Score:', roc_auc_score(y1_test, rfc_pred)*100)\n",
        "print('RFC Recall score:', recall_score(y1_test, rfc_pred)*100)\n",
        "print('RFC Precision Score:', precision_score(y1_test, rfc_pred)*100)\n",
        "print('RFC Confusion Matrix', confusion_matrix(y1,rfc_pred), \"\\n\")\n",
        "print('RFC Classification', classification_report(y1_test,rfc_pred), \"\\n\")\n",
        "print('RFC Accuracy Score', accuracy_score(y1_test,rfc_pred)*100)\n",
        "\n",
        "y_test_int1 = y1_test.replace({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "precision_lr1, recall_lr1, _ = precision_recall_curve(y_test_int1, probs_lr1)\n",
        "auc_lr1 = auc(recall_lr1, precision_lr1)\n",
        "\n",
        "precision_dt1, recall_dt1, _ = precision_recall_curve(y_test_int1, probs_dt1)\n",
        "auc_dt1 = auc(recall_dt1, precision_dt1)\n",
        "\n",
        "precision_nb1, recall_nb1, _ = precision_recall_curve(y_test_int1, probs_nb1)\n",
        "auc_nb1 = auc(recall_nb1, precision_nb1)\n",
        "\n",
        "precision_xg1, recall_xg1, _ = precision_recall_curve(y_test_int1, probs_xg1)\n",
        "auc_xg1 = auc(recall_xg1, precision_xg1)\n",
        "'''\n",
        "precision_cs1, recall_cs1, _ = precision_recall_curve(y_test_int1, probs_cs1)\n",
        "auc_cs1 = auc(recall_cs1, precision_cs1)\n",
        "'''\n",
        "precision_rf1, recall_rf1, _ = precision_recall_curve(y_test_int1, probs_rf1)\n",
        "auc_rf1 = auc(recall_rf1, precision_rf1)\n",
        "\n",
        "'''\n",
        "plt.plot(recall_lr1, precision_lr1, label=f'AUC Log. Reg. ROS) = {auc_lr:.2f}')\n",
        "plt.plot(recall_dt1, precision_dt1, label=f'AUC Dec. Tree ROS) = {auc_dt:.2f}')\n",
        "plt.plot(recall_nb1, precision_nb1, label=f'AUC Nai Bay. ROS) = {auc_rf:.2f}')\n",
        "plt.plot(recall_xg1, precision_xg1, label=f'AUC XGB ROS) = {auc_xg:.2f}')\n",
        "'''\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot([0, 1], [baseline_model, baseline_model], linestyle='--', label='Baseline model')\n",
        "plt.plot(recall_lr, precision_lr, label=f'AUC Log. Reg. Imb. = {auc_lr:.2f}')\n",
        "plt.plot(recall_dt, precision_dt, label=f'AUC Dec. Tree Imb. = {auc_dt:.2f}')\n",
        "plt.plot(recall_nb, precision_nb, label=f'AUC Nai Bay. Imb. = {auc_nb:.2f}')\n",
        "plt.plot(recall_xg, precision_xg, label=f'AUC XGB Imb. = {auc_xg:.2f}')\n",
        "#plt.plot(recall_cs, precision_cs, label=f'AUC CSVM Imb. = {auc_cs:.2f}')\n",
        "plt.plot(recall_rf, precision_rf, label=f'AUC RFC Imb. = {auc_rf:.2f}')\n",
        "plt.plot(recall_lr1, precision_lr1, label=f'AUC Log. Reg. Tomelinks = {auc_lr1:.2f}')\n",
        "plt.plot(recall_dt1, precision_dt1, label=f'AUC Dec. Tree Tomelinks = {auc_dt1:.2f}')\n",
        "plt.plot(recall_nb1, precision_nb1, label=f'AUC Nai Bay. Tomelinks = {auc_nb1:.2f}')\n",
        "plt.plot(recall_xg1, precision_xg1, label=f'AUC XGB Tomelinks = {auc_xg1:.2f}')\n",
        "#plt.plot(recall_cs1, precision_cs1, label=f'AUC CSVM Tomelinks = {auc_cs1:.2f}')\n",
        "plt.plot(recall_rf1, precision_rf1, label=f'AUC RFC Tomelinks = {auc_rf1:.2f}')\n",
        "plt.title('Precision-Recall Curves 2019: Imbalanced/Tomelinks', size=20)\n",
        "plt.xlabel('Recall', size=14)\n",
        "plt.ylabel('Precision', size=14)\n",
        "plt.legend()\n",
        "plt.show();\n",
        "\n",
        "'''\n",
        "plt.plot(recall_lr2, precision_lr2, label=f'AUC Log. Reg. ROS) = {auc_lr2:.2f}')\n",
        "plt.plot(recall_dt2, precision_dt2, label=f'AUC Dec. Tree ROS) = {auc_dt2:.2f}')\n",
        "plt.plot(recall_nb2, precision_nb2, label=f'AUC Nai Bay. ROS) = {auc_rf2:.2f}')\n",
        "plt.plot(recall_xg2, precision_xg2, label=f'AUC XGB ROS) = {auc_xg2:.2f}')\n",
        "'''\n",
        "#====RandomOverSampler====\n",
        "'''\n",
        "\n",
        "'''\n",
        "'''\n",
        "# import library\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "tl = RandomOverSampler(sampling_strategy='majority')\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_tl, y_tl = ros.fit_resample(x, y)\n",
        "\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "\n",
        "# import library\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from collections import Counter\n",
        "\n",
        "tl = RandomOverSampler(sampling_strategy='majority')\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_tl, y_tl = ros.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "\n",
        "# import library\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))\n",
        "\n",
        "from imblearn.under_sampling import SMOTE\n",
        "\n",
        "nm = SMOTE()\n",
        "\n",
        "x_nm, y_nm = nm.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape:', Counter(y_nm))\n",
        "\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x_smote,y_smote,test_size=0.5)\n",
        "\n",
        "xgb_predict = xgb_model.predict(x1_test)\n",
        "fxg = f1_score(xgb_predict,y1_test)\n",
        "print(\"===XGB Balanced - 2019 SMOTE===\")\n",
        "print('XGB F1-Score', fxg*100)\n",
        "print('XGB ROCAUC Score:', roc_auc_score(xgb_predict, y1_test), \"\\n\")\n",
        "print('XGB Confusion Matrix', confusion_matrix(xgb_predict, y1_test), \"\\n\")\n",
        "print('XGB Classification', classification_report(xgb_predict, y1_test), \"\\n\")\n",
        "print('XGB Accuracy Score', accuracy_score(xgb_predict, y1_test)*100)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "Naive = MultinomialNB()\n",
        "Naive.fit(x1_train,y1_train)\n",
        "# predict the labels on validation dataset\n",
        "nb_pred = Naive.predict(x1_test)\n",
        "fna = f1_score(nb_pred,y1_test)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"===Naive Bayes Balanced - 2019 SMOTE===\")\n",
        "print('Naive F1-score',fna*100)\n",
        "print('Naive ROCAUC score:',roc_auc_score(y1_test, nb_pred)*100, \"\\n\")\n",
        "print('Naive Confusion Matrix', confusion_matrix(y1_test, nb_pred), \"\\n\")\n",
        "print('Naive Classification', classification_report(y1_test, nb_pred), \"\\n\")\n",
        "print('Naive Accuracy Score', accuracy_score(y1_test, nb_pred)*100)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "Tree = DecisionTreeClassifier()\n",
        "Tree.fit(x1_train, y1_train)\n",
        "tree_pred = Tree.predict(x1_test)\n",
        "ftree = f1_score(tree_pred,y1_test)\n",
        "print(\"===Decision Tree Balanced - 2019 SMOTE ===\")\n",
        "print('DCT F1-score', ftree*100)\n",
        "print('DCT ROCAUC score:',roc_auc_score(y1_test, tree_pred)*100, \"\\n\")\n",
        "print('DCT Confusion Matrix', confusion_matrix(y1_test, tree_pred), \"\\n\")\n",
        "print('DCT Classification', classification_report(y1_test, tree_pred), \"\\n\")\n",
        "print('DCT Accuracy Score', accuracy_score(y1_test, tree_pred)*100)\n",
        "\n",
        "lR = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)\n",
        "lR.fit(x1_train,y1_train)\n",
        "lr_y_prediction = lR.predict(x1_test)\n",
        "fly = f1_score(lr_y_prediction,y1_test)\n",
        "print(\"===Logistic Regression - 2019 SMOTE ===\")\n",
        "print('Logistic F1-score',fly*100)\n",
        "print('Logistic ROCAUC score:',roc_auc_score(y1_test, lr_y_prediction))\n",
        "print('Logistic Confusion Matrix', confusion_matrix(y1_test,lr_y_prediction), \"\\n\")\n",
        "print('Logistic Classification', classification_report(y1_test,lr_y_prediction), \"\\n\")\n",
        "print('Logistic Accuracy Score', accuracy_score(y1_test,lr_y_prediction)*100)\n",
        "\n",
        "#LinearSVC Classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "lsvc_model = LinearSVC()\n",
        "lsvc_model.fit(x1_train,y1_train)\n",
        "lsvcm_pred = lsvc_model.predict(x1_test)\n",
        "lsvccm = f1_score(lsvc_pred,y1_test)\n",
        "print(\"=== LSVC - 2019 SMOTE ===\")\n",
        "print('LSVC F1 score', lsvccm*100)\n",
        "print('LSVC ROCAUC Score:', roc_auc_score(y1_test, lsvcm_pred)*100, \"\\n\")\n",
        "print('LSVC Confusion Matrix', confusion_matrix(y1_test, lsvcm_pred), \"\\n\")\n",
        "print('LSVC Classification', classification_report(y1_test, lsvcm_pred), \"\\n\")\n",
        "print('LSVC Accuracy Score', accuracy_score(y1_test, lsvcm_pred)*100)\n",
        "\n",
        "'''\n",
        "'''\n",
        "# load library\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc1 = RandomForestClassifier()\n",
        "\n",
        "# fit the predictor and target\n",
        "rfc1.fit(x1_train, y1_train)\n",
        "\n",
        "# predict\n",
        "rfc_predict = rfc1.predict(x1_test)# check performance\n",
        "print(\"=== RFC Balanced - 2019 SMOTE  ===\")\n",
        "print('RFC ROCAUC score:',roc_auc_score(y1_test, rfc_predict)*100)\n",
        "print('RFC Accuracy score:',accuracy_score(y1_test, rfc_predict)*100)\n",
        "print('RFC F1 score:',f1_score(y1_test, rfc_predict)*100)\n",
        "print('RFC Confusion Matrix', confusion_matrix(y1_test, rfc_predict), \"\\n\")\n",
        "print('RFC Classification', classification_report(y1_test, rfc_predict), \"\\n\")\n",
        "\n",
        "# load library\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# we can add class_weight='balanced' to add panalize mistake\n",
        "csvc_model = SVC(class_weight='balanced', probability=True)\n",
        "\n",
        "csvc_model.fit(x1_train, y1_train)\n",
        "\n",
        "csvc_predict = csvc_model.predict(x1_test)# check performance\n",
        "print(\"====CSVM Balanced - 2019 SMOTE ====\")\n",
        "print('CSVM ROCAUC score:',roc_auc_score(y1_test, csvc_predict)*100)\n",
        "print('CSVM Accuracy score:',accuracy_score(y1_test, csvc_predict)*100)\n",
        "print('CSVM F1 score:',f1_score(y1_test, csvc_predict)*100)\n",
        "print('CSVM Confusion Matrix', confusion_matrix(y1_test, csvc_predict), \"\\n\")\n",
        "print('CSVM Classification', classification_report(y1_test, csvc_predict), \"\\n\")\n",
        "'''\n",
        "'''\n",
        "#Multiple models\n",
        "models = [KNeighborsClassifier(),\n",
        "          LogisticRegression(solver='lbfgs', multi_class='ovr'),\n",
        "          DecisionTreeClassifier(),\n",
        "          SVC(gamma='scale'),\n",
        "          RandomForestClassifier(n_estimators=100),\n",
        "          ExtraTreesClassifier(n_estimators=100)]\n",
        "\n",
        "tvec = TfidfVectorizer(stop_words='english',\n",
        "                       #sublinear_tf=True,\n",
        "                       max_df=0.5,\n",
        "                       max_features=1000)\n",
        "\n",
        "tvec.fit(data_train['data'])\n",
        "X_train = tvec.transform(data_train['data'])\n",
        "X_test = tvec.transform(data_test['data'])\n",
        "\n",
        "res = []\n",
        "\n",
        "for model in models:\n",
        "    print(model)\n",
        "    print()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    print(score)\n",
        "    print()\n",
        "    cm = docm(y_test, y_pred, data_train.target_names)\n",
        "    print(cm)\n",
        "    res.append([model, score])\n",
        "    print()\n",
        "    print('-'*60)\n",
        "    print()\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.metrics import (precision_recall_curve, PrecisionRecallDisplay)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#predictions = clf.predict(X_test)\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "'''\n",
        "'''\n",
        "plot_precision_recall_curve(xgb_model, x1_test, y1_test, ax = plt.gca(),name = \"XGB - SMOTE\")\n",
        "plot_precision_recall_curve(Naive, x1_test, y1_test, ax = plt.gca(),name = \"Naive Bayes - SMOTE\")\n",
        "plot_precision_recall_curve(Tree, x1_test, y1_test, ax = plt.gca(),name = \"Decision Tree - SMOTE\")\n",
        "plot_precision_recall_curve(lR, x1_test, y1_test, ax = plt.gca(),name = \"Logistic Regression - SMOTE\")\n",
        "plt.title('Precision-Recall curve for SMOTE')\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}