# -*- coding: utf-8 -*-
"""Tomelinks_Classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GTN2Q9XyFLIyex-nmuU7PB8k4tUmSW-q
"""
# -*- coding: utf-8 -*-
"""NearMiss_Classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GTN2Q9XyFLIyex-nmuU7PB8k4tUmSW-q
"""
import random
import argparse
import sys
from pylab import *
import numpy as np # linear algebra
#np.set_printoptions(threshold=sys.maxsize)
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
#import matplotlib.axis as axis
#from matplotlib.xaxis import set_major_formatter
from matplotlib.axes import Axes
from itertools import zip_longest
import re
import csv
import time
from scipy import stats
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from timeit import default_timer as timer
'''
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
'''

parser = argparse.ArgumentParser(
                    prog = 'Sampling_Raw-1-ROS.py',
                    description = 'Run Imbalanced model for ROS with machine learning classifiers')

parser.add_argument("-o", "--output", action='store', type=argparse.FileType('w'), default=sys.stdout, help="Directs the code output to a name of your choice")      # positional argument
parser.add_argument("-nd", '--negdata', help="Specify the year of neg class of text data")      # option that takes a value
parser.add_argument("-pd", '--posdata', help="Specify the year of pos class of text data")
parser.add_argument("-g", '--group', default=str, required=False, help="Specify the year/group of the data") # on/off flag
parser.add_argument("-yc", '--yearcsv', action='store', type=argparse.FileType('w'), required=False, help="Specify the year of the csv")
parser.add_argument("-py", '--posyear', action='store', type=argparse.FileType('w'),  required=False, help="Specify the name pos class csv")
parser.add_argument("-ny", '--negyear', action='store', type=argparse.FileType('w'),  required=False, help="Specify the name neg class csv")
parser.add_argument("-i", '--iteration', action='store',  required=False, help="Specify the name iteration of filename")
args = parser.parse_args()

import os
# print(os.listdir("../input"))
plt.style.use('ggplot')

writef = args.output
sys.stdout = writef

df = pd.DataFrame()
with open(args.negdata, encoding="ISO-8859-1") as raw:
#raw = open(r"C:\\Users\\jod1\\Documents\\Document-Classification\\classifier\\NIST_FULL\\2012-neg.txt", encoding="ISO-8859-1")
    lines = raw.readlines()
    raw.close()

# remove /n at the end of each line
    for index, line in enumerate(lines):
        lines[index] = line.strip()
        print(lines[index])

    neg_df = pd.DataFrame(columns=['sentence'])
    i = 0
    first_col = ""
    for line in lines:
        first_col = re.sub(r' \(.*', "", line)
        neg_df.loc[i] = [first_col]
        i = i+1

neg_df.head()
neg_df['label'] = 0
print(neg_df.shape)

with open(args.posdata, encoding="ISO-8859-1") as raw1:
#raw1 = open(r"C:\\Users\\jod1\\Documents\\Document-Classification\\classifier\\NIST_FULL\\2012-pos.txt", encoding="ISO-8859-1")
    lines1 = raw1.readlines()
    raw1.close()

    # remove /n at the end of each line
    for index, line in enumerate(lines1):
        lines1[index] = line.strip()
        print(lines1[index])

    pos_df = pd.DataFrame(columns=['sentence'])
    i = 0
    first_col = ""
    for line in lines1:
        first_col = re.sub(r' \(.*', "", line)
        pos_df.loc[i] = [first_col]
        i = i+1

    pos_df.head()
    pos_df['label'] = 1

'''
df = df.append(pos_df)
df = df.append(neg_df)
print(df.shape)
print(pos_df.shape)
print(neg_df.shape)
'''

import pandas as pd
import numpy as np
import nltk
import re
import string
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support as score, f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
from nltk.corpus import stopwords
from nltk.corpus import wordnet
from nltk.stem.wordnet import WordNetLemmatizer
import string
from nltk.corpus import stopwords
from nltk.corpus import wordnet
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.tag import pos_tag
from nltk.tokenize import word_tokenize
nltk.download('wordnet')
nltk.download('stopwords')
stopwords.words('english')

# For Positive 
#Removing punctuations from entire dataset
punc_set = string.punctuation
punc_set

#Function for removing punctions
def remove_punc_pos(text):
    clean = "".join([x.lower() for x in text if x not in punc_set])
    return clean

#Applying the 'remove_punc' function to entire dataset
pos_df['no_punc'] = pos_df['sentence'].apply(lambda z:remove_punc_pos(z))

#Function for Tokenizing entire data for representing every word as datapoint
def tokenize_pos(text):
    tokens = re.split("\W+",text)
    return tokens

#Applying the 'tokenize' function to entire dataset
pos_df['tokenized_Data'] = pos_df['no_punc'].apply(lambda z:tokenize_pos(z))

#Importing stopwords from NLTK Library to remove stopwords now that we have tokenized it
stopwords = nltk.corpus.stopwords.words('english')

#Function for removing stopwords from single row
def remove_stopwords_pos(tokenized_words):
    Ligit_text=[word for word in tokenized_words if word not in stopwords]
    return Ligit_text

#Applying the function 'remove_stopwords' from the entire dataset
pos_df["no_stop"] = pos_df["tokenized_Data"].apply(lambda z:remove_stopwords_pos(z))

#Importing 'WordNetLemmatizer' as lemmatizing function to find lemma's of words
wnl = nltk.wordnet.WordNetLemmatizer()

#Function for lemmatizing the tokenzied text
def lemmatizing_pos(tokenized_text):
    lemma = [wnl.lemmatize(word) for word in tokenized_text]
    return lemma

#Applying the 'lemmatizing' function to entire dataset
pos_df['lemmatized'] = pos_df['no_stop'].apply(lambda z:lemmatizing_pos(z))

# #Importing the 'SnowballStemmer' and declaring variable 'sno' to save the stemmer in.
# #This Stemmer gives slightly better results as compared to 'PorterStemmer'
# sno = nltk.SnowballStemmer('english')

# #Function for applying stemming to find stem roots of all words
# def stemming(tokenized_text):
#     text= [sno.stem(word) for word in tokenized_text]
#     return text

# #Applying the 'stemming' function to entire dataset
# data['ss_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))


# ps = nltk.PorterStemmer()

# def stemming(tokenized_text):
#     text= [ps.stem(word) for word in tokenized_text]
#     return text

# data['ps_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))

#This step is done here because, the 'lemmatized' column is a list of tokenized words and when we apply vectorization
#techniques such as count vectorizer or TFIpos_df, they require string input. Hence convert all tokenzied words to string
pos_df['lemmatized'] = [" ".join(review) for review in pos_df['lemmatized'].values]

# For Negative
#Removing punctuations from entire dataset
punc_set1 = string.punctuation
punc_set1

#Function for removing punctions
def remove_punc_neg(text):
    clean1 = "".join([x.lower() for x in text if x not in punc_set])
    return clean1

#Applying the 'remove_punc' function to entire dataset
neg_df['no_punc'] = neg_df['sentence'].apply(lambda z:remove_punc_neg(z))

#Function for Tokenizing entire data for representing every word as datapoint
def tokenize_neg(text):
    tokens1 = re.split("\W+",text)
    return tokens1

#Applying the 'tokenize' function to entire dataset
neg_df['tokenized_Data'] = neg_df['no_punc'].apply(lambda z:tokenize_neg(z))

#Importing stopwords from NLTK Library to remove stopwords now that we have tokenized it
stopwords1 = nltk.corpus.stopwords.words('english')

#Function for removing stopwords from single row
def remove_stopwords_neg(tokenized_words):
    Ligit_text1 =[word for word in tokenized_words if word not in stopwords]
    return Ligit_text1

#Applying the function 'remove_stopwords' from the entire dataset
neg_df["no_stop"] = neg_df["tokenized_Data"].apply(lambda z:remove_stopwords_neg(z))

#Importing 'WordNetLemmatizer' as lemmatizing function to find lemma's of words
wnl = nltk.wordnet.WordNetLemmatizer()

#Function for lemmatizing the tokenzied text
def lemmatizing_neg(tokenized_text):
    lemma1 = [wnl.lemmatize(word) for word in tokenized_text]
    return lemma1

#Applying the 'lemmatizing' function to entire dataset
neg_df['lemmatized'] = neg_df['no_stop'].apply(lambda z:lemmatizing_neg(z))

# #Importing the 'SnowballStemmer' and declaring variable 'sno' to save the stemmer in.
# #This Stemmer gives slightly better results as compared to 'PorterStemmer'
# sno = nltk.SnowballStemmer('english')

# #Function for applying stemming to find stem roots of all words
# def stemming(tokenized_text):
#     text= [sno.stem(word) for word in tokenized_text]
#     return text

# #Applying the 'stemming' function to entire dataset
# data['ss_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))


# ps = nltk.PorterStemmer()

# def stemming(tokenized_text):
#     text= [ps.stem(word) for word in tokenized_text]
#     return text

# data['ps_stemmed'] = data['lemmatized'].apply(lambda z:stemming(z))

#This step is done here because, the 'lemmatized' column is a list of tokenized words and when we apply vectorization
#techniques such as count vectorizer or TFIneg_df, they require string input. Hence convert all tokenzied words to string
neg_df['lemmatized'] = [" ".join(review) for review in neg_df['lemmatized'].values]

df = df.append(pos_df)
df = df.append(neg_df)
print(df.shape)
print(pos_df.shape)
print(neg_df.shape)
df.to_csv(args.yearcsv)
pos_df.to_csv(args.posyear)
neg_df.to_csv(args.negyear)
'''
import os

def pause():
    programPause = input("Press the <ENTER> key to continue...")

print("Think about what you ate for dinner last night...")
pause()
'''
df.head()

time.sleep(500)


pos_num = pos_df.shape[0]
#after_pos = 29708

pos_00 = round(pos_num * 1.00)
pos_95 = round(pos_num * 0.95)
pos_90 = round(pos_num * 0.90)
pos_85 = round(pos_num * 0.85)
pos_80 = round(pos_num * 0.80)
pos_75 = round(pos_num * 0.75)
pos_70 = round(pos_num * 0.70)
pos_65 = round(pos_num * 0.65)
pos_60 = round(pos_num * 0.60)
pos_55 = round(pos_num * 0.55)
pos_50 = round(pos_num * 0.50)
pos_45 = round(pos_num * 0.45)
pos_40 = round(pos_num * 0.40)
pos_35 = round(pos_num * 0.35)
pos_30 = round(pos_num * 0.30)
pos_25 = round(pos_num * 0.25)
pos_20 = round(pos_num * 0.20)
pos_15 = round(pos_num * 0.15)
pos_10 = round(pos_num * 0.10)
pos_05 = round(pos_num * 0.05)

neg_num = pos_df.shape[0]

neg_00 = round(neg_num * 1.00)
neg_95 = round(neg_num * 0.95)
neg_90 = round(neg_num * 0.90)
neg_85 = round(neg_num * 0.85)
neg_80 = round(neg_num * 0.80)
neg_75 = round(neg_num * 0.75)
neg_70 = round(neg_num * 0.70)
neg_65 = round(neg_num * 0.65)
neg_60 = round(neg_num * 0.60)
neg_55 = round(neg_num * 0.55)
neg_50 = round(neg_num * 0.50)
neg_45 = round(neg_num * 0.45)
neg_40 = round(neg_num * 0.40)
neg_35 = round(neg_num * 0.35)
neg_30 = round(neg_num * 0.30)
neg_25 = round(neg_num * 0.25)
neg_20 = round(neg_num * 0.20)
neg_15 = round(neg_num * 0.15)
neg_10 = round(neg_num * 0.10)
neg_05 = round(neg_num * 0.05)

#print("Positive location of data", df.iloc[[29707]])
#print("Negative location of data", df.iloc[[48521]])

# Splitting Datasets Manually
pos_pt1=pos_df.iloc[0:pos_05, :]
neg_pt1=neg_df.iloc[0:neg_05, :]
pos_pt2=pos_df.iloc[0:pos_10, :]
neg_pt2=neg_df.iloc[0:neg_10, :]
pos_pt3=pos_df.iloc[0:pos_15, :]
neg_pt3=neg_df.iloc[0:neg_15, :]
pos_pt4=pos_df.iloc[0:pos_20, :]
neg_pt4=neg_df.iloc[0:neg_20, :]
neg_pt5=neg_df.iloc[0:neg_25, :]
pos_pt5=pos_df.iloc[0:pos_25, :]
pos_pt6=pos_df.iloc[0:pos_30, :]
neg_pt6=neg_df.iloc[0:neg_30, :]
pos_pt7=pos_df.iloc[0:pos_35, :]
neg_pt7=neg_df.iloc[0:neg_35, :]
pos_pt8=pos_df.iloc[0:pos_40, :]
neg_pt8=neg_df.iloc[0:neg_40, :]
pos_pt9=pos_df.iloc[0:pos_45, :]
neg_pt9=neg_df.iloc[0:neg_45, :]
neg_pt10=neg_df.iloc[0:neg_50, :]
pos_pt10=pos_df.iloc[0:pos_50, :]

# Splitting Datasets Manually
pos_pt11=pos_df.iloc[0:pos_55, :]
neg_pt11=neg_df.iloc[0:neg_55, :]
pos_pt12=pos_df.iloc[0:pos_60, :]
neg_pt12=neg_df.iloc[0:neg_60, :]
pos_pt13=pos_df.iloc[0:pos_65, :]
neg_pt13=neg_df.iloc[0:neg_65, :]
pos_pt14=pos_df.iloc[0:pos_70, :]
neg_pt14=neg_df.iloc[0:neg_70, :]
neg_pt15=neg_df.iloc[0:neg_75, :]
pos_pt15=pos_df.iloc[0:pos_75, :]
pos_pt16=pos_df.iloc[0:pos_80, :]
neg_pt16=neg_df.iloc[0:neg_80, :]
pos_pt17=pos_df.iloc[0:pos_85, :]
neg_pt17=neg_df.iloc[0:neg_85, :]
pos_pt18=pos_df.iloc[0:pos_90, :]
neg_pt18=neg_df.iloc[0:neg_90, :]
pos_pt19=pos_df.iloc[0:pos_95, :]
neg_pt19=neg_df.iloc[0:neg_95, :]
neg_pt20=neg_df.iloc[0:neg_00, :]
pos_pt20=pos_df.iloc[0:pos_00, :]

'''
# Splitting Datasets Manually
pos_pt1=df.iloc[0:pos_num-xy_num10, :]
neg_pt1=df.iloc[neg_num:neg_num+xy_num1, :]
pos_pt2=df.iloc[0:pos_num-xy_num9, :]
neg_pt2=df.iloc[neg_num:neg_num+xy_num2, :]
pos_pt3=df.iloc[0:pos_num-xy_num8, :]
neg_pt3=df.iloc[neg_num:neg_num+xy_num3, :]
pos_pt4=df.iloc[0:pos_num-xy_num7, :]
neg_pt4=df.iloc[neg_num:neg_num+xy_num4, :]
neg_pt5=df.iloc[0:pos_num-xy_num6, :]
pos_pt5=df.iloc[neg_num:neg_num+xy_num5, :]
pos_pt6=df.iloc[0:pos_num-xy_num5, :]
neg_pt6=df.iloc[neg_num:neg_num+xy_num6, :]
pos_pt7=df.iloc[0:pos_num-xy_num4, :]
neg_pt7=df.iloc[neg_num:neg_num+xy_num7, :]
pos_pt8=df.iloc[0:pos_num-xy_num3, :]
neg_pt8=df.iloc[neg_num:neg_num+xy_num8, :]
pos_pt9=df.iloc[0:pos_num-xy_num2, :]
neg_pt9=df.iloc[neg_num:neg_num+xy_num9, :]
neg_pt10=df.iloc[0:pos_num-xy_num1, :]
pos_pt10=df.iloc[neg_num:neg_num+xy_num10, :]
'''
df1 = pd.concat([pos_pt1, neg_pt1])
print("DF1:", round(df1.shape[0]))
df2 = pd.concat([pos_pt2, neg_pt2])
print("DF2:", round(df2.shape[0]))
df3 = pd.concat([pos_pt3, neg_pt3])
print("DF3:", round(df3.shape[0]))
df4 = pd.concat([pos_pt4, neg_pt4])
print("DF4:", round(df4.shape[0]))
df5 = pd.concat([pos_pt5, neg_pt5])
print("DF5:", round(df5.shape[0]))
df6 = pd.concat([pos_pt6, neg_pt6])
print("DF6:", round(df6.shape[0]))
df7 = pd.concat([pos_pt7, neg_pt7])
print("DF7:", round(df7.shape[0]))
df8 = pd.concat([pos_pt8, neg_pt8])
print("DF8:", round(df8.shape[0]))
df9 = pd.concat([pos_pt9, neg_pt9])
print("DF9:", round(df9.shape[0]))
df10 = pd.concat([pos_pt10, neg_pt10])
print("DF10:", round(df10.shape[0]))
df11 = pd.concat([pos_pt11, neg_pt11])
print("DF11:", round(df11.shape[0]))
df12 = pd.concat([pos_pt12, neg_pt12])
print("DF12:", round(df12.shape[0]))
df13 = pd.concat([pos_pt13, neg_pt3])
print("DF13:", round(df13.shape[0]))
df14 = pd.concat([pos_pt14, neg_pt14])
print("DF14:", round(df14.shape[0]))
df15 = pd.concat([pos_pt15, neg_pt15])
print("DF15:", round(df15.shape[0]))
df16 = pd.concat([pos_pt16, neg_pt16])
print("DF16:", round(df16.shape[0]))
df17 = pd.concat([pos_pt17, neg_pt17])
print("DF17:", round(df17.shape[0]))
df18 = pd.concat([pos_pt18, neg_pt18])
print("DF18:", round(df18.shape[0]))
df19 = pd.concat([pos_pt19, neg_pt19])
print("DF19:", round(df19.shape[0]))
df20 = pd.concat([pos_pt20, neg_pt20])
print("DF20:", round(df20.shape[0]))

#Splitting data into smaller dataframes for the purpose of Training and Testing

df1_l = "Split 1"
df2_l = "Split 2"
df3_l = "Split 3"
df4_l = "Split 4"
df5_l = "Split 5"
df6_l = "Split 6"
df7_l = "Split 7"
df8_l = "Split 8"
df9_l = "Split 9"
df10_l = "Split 10"
df11_l = "Split 11"
df12_l = "Split 12"
df13_l = "Split 13"
df14_l = "Split 14"
df15_l = "Split 15"
df16_l = "Split 16"
df17_l = "Split 17"
df18_l = "Split 18"
df19_l = "Split 19"
df20_l = "Split 20"

it1 = "1"
it2 = "2"
it3 = "3"
it4 = "4"
it5 = "5"
it6 = "6"
it7 = "7"
it8 = "8"
it9 = "9"
it10 = "10"
it11 = "11"
it12 = "12"
it13 = "13"
it14 = "14"
it15 = "15"
it16 = "16"
it17 = "17"
it18 = "18"
it19 = "19"
it20 = "20"

'''
ts01 = "TS 0.1"
ts02 = "TS 0.2"
ts03 = "TS 0.3"
ts04 = "TS 0.4"
ts05 = "TS 0.5"
'''
df1_split = round(df1.shape[0] * .5)
print(df1_split)
df2_split = round(df2.shape[0] * .5)
print(df2_split)
df3_split = round(df3.shape[0] * .5)
print(df3_split)
df4_split = round(df4.shape[0] * .5)
print(df4_split)
df5_split = round(df5.shape[0] * .5)
print(df5_split)
df6_split = round(df6.shape[0] * .5)
print(df6_split)
df7_split = round(df7.shape[0] * .5)
print(df7_split)
df8_split = round(df8.shape[0] * .5)
print(df8_split)
df9_split = round(df9.shape[0] * .5)
print(df9_split)
df10_split = round(df10.shape[0] * .5)
print(df10_split)
df11_split = round(df11.shape[0] * .5)
print(df11_split)
df12_split = round(df12.shape[0] * .5)
print(df12_split)
df13_split = round(df13.shape[0] * .5)
print(df13_split)
df14_split = round(df14.shape[0] * .5)
print(df14_split)
df15_split = round(df15.shape[0] * .5)
print(df15_split)
df16_split = round(df16.shape[0] * .5)
print(df16_split)
df17_split = round(df17.shape[0] * .5)
print(df17_split)
df18_split = round(df18.shape[0] * .5)
print(df18_split)
df19_split = round(df19.shape[0] * .5)
print(df19_split)
df20_split = round(df20.shape[0] * .5)
print(df20_split)


'''
xy_ran1=random.randint(1, df.shape[0])
xy_ran2=random.randint(1, df.shape[0])
xy_ran3=random.randint(1, df.shape[0])
xy_ran4=random.randint(1, df.shape[0])
xy_ran5=random.randint(1, df.shape[0])
xy_ran6=random.randint(1, df.shape[0])
xy_ran7=random.randint(1, df.shape[0])
xy_ran8=random.randint(1, df.shape[0])
xy_ran9=random.randint(1, df.shape[0])
xy_ran10=random.randint(1, df.shape[0])
'''

df1_sen = round(df1.shape[0])
df2_sen = round(df2.shape[0])
df3_sen = round(df3.shape[0])
df4_sen = round(df4.shape[0])
df5_sen = round(df5.shape[0])
df6_sen = round(df6.shape[0])
df7_sen = round(df7.shape[0])
df8_sen = round(df8.shape[0])
df9_sen = round(df9.shape[0])
df10_sen = round(df10.shape[0])
df11_sen = round(df11.shape[0])
df12_sen = round(df12.shape[0])
df13_sen = round(df13.shape[0])
df14_sen = round(df14.shape[0])
df15_sen = round(df15.shape[0])
df16_sen = round(df16.shape[0])
df17_sen = round(df17.shape[0])
df18_sen = round(df18.shape[0])
df19_sen = round(df19.shape[0])
df20_sen = round(df20.shape[0])

x1 = df1.iloc[0:df1_split,5]
x2 = df1.iloc[df1_sen-df1_split:df1_sen,5]
x3 = df2.iloc[0:df2_split,5]
x4 = df2.iloc[df2_sen-df2_split:df2_sen,5]
x5 = df3.iloc[0:df3_split,5]
x6 = df3.iloc[df3_sen-df3_split:df3_sen,5]
x7 = df4.iloc[0:df4_split,5]
x8 = df4.iloc[df4_sen-df4_split:df4_sen,5]
x9 = df5.iloc[0:df5_split,5]
x10 = df5.iloc[df5_sen-df5_split:df5_sen,5]
x11 = df6.iloc[0:df6_split,5]
x12 = df6.iloc[df6_sen-df6_split:df6_sen,5]
x13 = df7.iloc[0:df7_split,5]
x14 = df7.iloc[df7_sen-df7_split:df7_sen,5]
x15 = df8.iloc[0:df8_split,5]
x16 = df8.iloc[df8_sen-df8_split:df8_sen,5]
x17 = df9.iloc[0:df9_split,5]
x18 = df9.iloc[df9_sen-df9_split:df9_sen,5]
x19 = df10.iloc[0:df10_split,5]
x20 = df10.iloc[df10_sen-df10_split:df10_sen,5]
x21 = df11.iloc[0:df11_split,5]
x22 = df11.iloc[df11_sen-df11_split:df11_sen,5]
x23 = df12.iloc[0:df12_split,5]
x24 = df12.iloc[df12_sen-df12_split:df12_sen,5]
x25 = df13.iloc[0:df13_split,5]
x26 = df13.iloc[df13_sen-df13_split:df13_sen,5]
x27 = df14.iloc[0:df14_split,5]
x28 = df14.iloc[df14_sen-df14_split:df14_sen,5]
x29 = df15.iloc[0:df15_split,5]
x30 = df15.iloc[df15_sen-df15_split:df15_sen,5]
x31 = df16.iloc[0:df16_split,5]
x32 = df16.iloc[df16_sen-df16_split:df16_sen,5]
x33 = df17.iloc[0:df17_split,5]
x34 = df17.iloc[df17_sen-df17_split:df17_sen,5]
x35 = df18.iloc[0:df18_split,5]
x36 = df18.iloc[df18_sen-df18_split:df18_sen,5]
x37 = df19.iloc[0:df19_split,5]
x38 = df19.iloc[df19_sen-df19_split:df19_sen,5]
x39 = df20.iloc[0:df20_split,5]
x40 = df20.iloc[df20_sen-df20_split:df20_sen,5]

y1 = df1.iloc[0:df1_split,1]
y2 = df1.iloc[df1_sen-df1_split:df1_sen,1]
y3 = df2.iloc[0:df2_split,1]
y4 = df2.iloc[df2_sen-df2_split:df2_sen,1]
y5 = df3.iloc[0:df3_split,1]
y6 = df3.iloc[df3_sen-df3_split:df3_sen,1]
y7 = df4.iloc[0:df4_split,1]
y8 = df4.iloc[df4_sen-df4_split:df4_sen,1]
y9 = df5.iloc[0:df5_split,1]
y10 = df5.iloc[df5_sen-df5_split:df5_sen,1]
y11 = df6.iloc[0:df6_split,1]
y12 = df6.iloc[df6_sen-df6_split:df6_sen,1]
y13 = df7.iloc[0:df7_split,1]
y14 = df7.iloc[df7_sen-df7_split:df7_sen,1]
y15 = df8.iloc[0:df8_split,1]
y16 = df8.iloc[df8_sen-df8_split:df8_sen,1]
y17 = df9.iloc[0:df9_split,1]
y18 = df9.iloc[df9_sen-df9_split:df9_sen,1]
y19 = df10.iloc[0:df10_split,1]
y20 = df10.iloc[df10_sen-df10_split:df10_sen,1]
y21 = df11.iloc[0:df11_split,1]
y22 = df11.iloc[df11_sen-df11_split:df11_sen,1]
y23 = df12.iloc[0:df12_split,1]
y24 = df12.iloc[df12_sen-df12_split:df12_sen,1]
y25 = df13.iloc[0:df13_split,1]
y26 = df13.iloc[df13_sen-df13_split:df13_sen,1]
y27 = df14.iloc[0:df14_split,1]
y28 = df14.iloc[df14_sen-df14_split:df14_sen,1]
y29 = df15.iloc[0:df15_split,1]
y30 = df15.iloc[df15_sen-df15_split:df15_sen,1]
y31 = df16.iloc[0:df16_split,1]
y32 = df16.iloc[df16_sen-df16_split:df16_sen,1]
y33 = df17.iloc[0:df17_split,1]
y34 = df17.iloc[df17_sen-df17_split:df17_sen,1]
y35 = df18.iloc[0:df18_split,1]
y36 = df18.iloc[df18_sen-df18_split:df18_sen,1]
y37 = df19.iloc[0:df19_split,1]
y38 = df19.iloc[df19_sen-df19_split:df19_sen,1]
y39 = df20.iloc[0:df20_split,1]
y40 = df20.iloc[df20_sen-df20_split:df20_sen,1]

#x_seg = df.iloc[0:5,5]
#y_seg = df.iloc[0:5,1]
print("X1:", x1.shape)
print("X2:", x2.shape)
print("X3:", x3.shape)
print("X4:", x4.shape)
print("X5:", x5.shape)
print("X6:", x6.shape)
print("X7:", x7.shape)
print("X8:", x8.shape)
print("X9:", x9.shape)
print("X10:", x10.shape)
print("X11:", x11.shape)
print("X12:", x12.shape)
print("X13:", x13.shape)
print("X14:", x14.shape)
print("X15:", x15.shape)
print("X16:", x16.shape)
print("X17:", x17.shape)
print("X18:", x18.shape)
print("X19:", x19.shape)
print("X20:", x20.shape)
print("X21:", x21.shape)
print("X22:", x22.shape)
print("X23:", x23.shape)
print("X24:", x24.shape)
print("X25:", x25.shape)
print("X26:", x26.shape)
print("X27:", x27.shape)
print("X28:", x28.shape)
print("X29:", x29.shape)
print("X30:", x30.shape)
print("X31:", x31.shape)
print("X32:", x32.shape)
print("X33:", x33.shape)
print("X34:", x34.shape)
print("X35:", x35.shape)
print("X36:", x36.shape)
print("X37:", x37.shape)
print("X38:", x38.shape)
print("X39:", x39.shape)
print("X40:", x40.shape)

print("Y1:", y1.shape)
print("Y2:", y2.shape)
print("Y3:", y3.shape)
print("Y4:", y4.shape)
print("Y5:", y5.shape)
print("Y6:", y6.shape)
print("Y7:", y7.shape)
print("Y8:", y8.shape)
print("Y9:", y9.shape)
print("Y10:", y10.shape)
print("Y11:", y11.shape)
print("Y12:", y12.shape)
print("Y13:", y13.shape)
print("Y14:", y14.shape)
print("Y15:", y15.shape)
print("Y16:", y16.shape)
print("Y17:", y17.shape)
print("Y18:", y18.shape)
print("Y19:", y19.shape)
print("Y20:", y20.shape)
print("Y21:", y21.shape)
print("Y22:", y22.shape)
print("Y23:", y23.shape)
print("Y24:", y24.shape)
print("Y25:", y25.shape)
print("Y26:", y26.shape)
print("Y27:", y27.shape)
print("Y28:", y28.shape)
print("Y29:", y29.shape)
print("Y30:", y30.shape)
print("Y31:", y31.shape)
print("Y32:", y32.shape)
print("Y33:", y33.shape)
print("Y34:", y34.shape)
print("Y35:", y35.shape)
print("Y36:", y36.shape)
print("Y37:", y37.shape)
print("Y38:", y38.shape)
print("Y39:", y39.shape)
print("Y40:", y40.shape)


'''
x = df['lemmatized'].values
y = df['label'].values
print(x.shape)
print(y.shape)
'''
'''
train_set = [x1,x3,x5,x7,x9]
test_set = [x2,x4,x6,x8,x10]

train_label = [y1,y3,y5,y7,y9]
test_set = [y2,y4,y6,y8,y10]
'''
#Declaring and applying TFIDF functions to train and test data

tfidf_vect = TfidfVectorizer(ngram_range=(1,2))
tfidf_train = tfidf_vect.fit_transform(x1.values)
tfidf_test=tfidf_vect.transform(x2.values)
print(tfidf_train.shape)
print(tfidf_test.shape)
#tfidf_train.toarray()

#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
'''
# Values for testing set - PTest
Accuracy_LRN = []
Precision_LRN = []
Recall_LRN = []

Accuracy_DCT = []
Recall_DCT = []
Precision_DCT = []

Accuracy_NBB = []
Recall_NBB = []
Precision_NBB = []

Accuracy_XGB = []
Recall_XGB = []
Precision_XGB = []

# Values for testing set - Sampling
Accuracy_LRN_s = []
Precision_LRN_s = []
Recall_LRN_s = []

Accuracy_DCT_s = []
Recall_DCT_s = []
Precision_DCT_s = []

Accuracy_NBB_s = []
Recall_NBB_s = []
Precision_NBB_s = []

Accuracy_XGB_s = []
Recall_XGB_s = []
Precision_XGB_s = []
'''
'''
# Values for training set - PTest
Accuracy_LRN_tr = []
Precision_LRN_tr = []
Recall_LRN_tr = []

Accuracy_DCT_tr = []
Recall_DCT_tr = []
Precision_DCT_tr = []

Accuracy_NBB_tr = []
Recall_NBB_tr = []
precision_NBB_tr = []

Accuracy_RDD_tr = []
Recall_RDD_tr = []
precision_RDD_tr = []
'''
tfidf_vect = TfidfVectorizer()

#== DF1 ==
x_tfidf = tfidf_vect.fit_transform(df["lemmatized"])

'''
df['label'].value_counts()

import seaborn as sns
g = sns.countplot(df['label'])
g.set_xticklabels(['Negative','Positive'])
plt.show()
'''
# class count
label_count_neg, label_count_pos = df['label'].value_counts()

# Separate class
label_neg = df[df['label'] == 0]
label_pos = df[df['label'] == 1]# print the shape of the class
print('Label Negative:', label_neg.shape)
print('Label Positive:', label_pos.shape)

label_neg_under = label_neg.sample(label_count_pos)

test_under = pd.concat([label_neg_under, label_pos], axis=0)

print("total class of pos and neg :",test_under['label'].value_counts())# plot the count after under-sampling
test_under['label'].value_counts().plot(kind='bar', title='label (target)')

label_pos_over = label_pos.sample(label_count_neg, replace=True)

test_over = pd.concat([label_pos_over, label_neg], axis=0)

print("total class of pos and neg:",test_under['label'].value_counts())# plot the count after under-sampeling
test_over['label'].value_counts().plot(kind='bar', title='label (target)')

import imblearn

# import library
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler
x = x_tfidf
y = df['label']
print(x.shape)
print(y.shape)


rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable
x_rus, y_rus = rus.fit_resample(x, y)

print('Original dataset shape:', Counter(y))
print('Resample dataset shape', Counter(y_rus))

# import library
from collections import Counter
from imblearn.over_sampling import RandomOverSampler
'''
x =x_tfidf
y = df1["label"]
'''
ros = RandomUnderSampler(random_state=42)
#ros = RandomOverSampler(random_state=42)
#Random over-sampling with imblearn
# fit predictor and target variable
x_rus, y_rus = rus.fit_resample(x, y)

print('Original dataset shape', Counter(y))
print('Resample dataset shape', Counter(y_rus))
#Random over-sampling with imblearn
ros = RandomOverSampler(random_state=42)

# fit predictor and target variable
x_ros, y_ros = ros.fit_resample(x, y)

print('Original dataset shape', Counter(y))
print('Resample dataset shape', Counter(y_ros))
# import library

# Under-sampling: Tomek links
from imblearn.under_sampling import TomekLinks
from collections import Counter


tl = RandomOverSampler(sampling_strategy='majority')

# fit predictor and target variable
x_tl, y_tl = ros.fit_resample(x, y)

print('Original dataset shape', Counter(y))
print('Resample dataset shape', Counter(y_ros))

# import library
from imblearn.over_sampling import SMOTE

smote = SMOTE()

# fit predictor and target variable
x_smote, y_smote = smote.fit_resample(x, y)

print('Original dataset shape', Counter(y))
print('Resample dataset shape', Counter(y_ros))


from imblearn.under_sampling import NearMiss

nm = NearMiss()

x_nm, y_nm = ros.fit_resample(x, y)

print('Original dataset shape:', Counter(y))
print('Resample dataset shape:', Counter(y_nm))


probs_lr_scol = []
f1_lr_scol = []
rocauc_lr_scol = []
recall_lr_scol = []
precision_lr_scol = []
accuracy_lr_scol = []

probs_dt_scol = []
f1_dt_scol = []
rocauc_dt_scol = []
recall_dt_scol = []
precision_dt_scol = []
accuracy_dt_scol = []

probs_nb_scol = []
f1_nb_scol = []
rocauc_nb_scol = []
recall_nb_scol = []
precision_nb_scol = []
accuracy_nb_scol = []

probs_xg_scol = []
f1_xg_scol = []
rocauc_xg_scol = []
recall_xg_scol = []
precision_xg_scol = []
accuracy_xg_scol = []

probs_rf_scol = []
f1_rf_scol = []
rocauc_rf_scol = []
recall_rf_scol = []
precision_rf_scol = []
accuracy_rf_scol = []

# 1st Test Size - 5%

train_values= np.array([0.16, 0.33, 0.50, 0.67, 0.83])
'''
test_values = 1 - train_values
'''
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:
    # train_sizes = train_sizes + i
    #random_portion = round(np.random.uniform(0.2, 0.5), 3)
    #print(random_portion)
    x_train, x_test, y_train, y_test = train_test_split(x_ros, y_ros, train_size=i, stratify=y_ros)

    start1 = time.time()
    log = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train,y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction,y_test)
    f1_lr_scol.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df1_l, i)
    lr_end = time.time()
    print('Logistic F1-score',fly*100)
    print('Logistic ROCAUC score:',rocauc_lr*100)
    print('Logistic Recall score:', recalls_lr*100)
    print('Logistic Precision Score:', precisions_lr*100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test,ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test,ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr*100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier
    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred,y_test)
    f1_dt_scol.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df1_l, i)
    dt_end = time.time()
    print('DCT F1-score',fdct*100)
    print('DCT ROCAUC score:',rocauc_dt*100)
    print('DCT Recall score:', recalls_dt*100)
    print('DCT Precision Score:', precisions_dt*100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt*100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")


    from sklearn.naive_bayes import MultinomialNB
    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train,y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred,y_test)
    f1_nb_scol.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df1_l, i)
    print('Naive F1-score',fnb*100)
    print('Naive ROCAUC score:',rocauc_nb*100)
    print('Naive Recall score:', recalls_nb*100)
    print('Naive Precision Score:', precisions_nb*100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb*100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

# XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict,y_test)
    f1_xg_scol.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df1_l, i)
    print('XGB F1-Score', fxg*100)
    print('XGB ROCAUC Score:', rocauc_xg*100)
    print('XGB Recall score:', recall_xg*100)
    print('XGB Precision Score:', precisions_xg *100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb*100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

# Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier
    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train,y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred,y_test)
    f1_rf_scol.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df1_l, i)
    print('RFC F1 score', frfc*100)
    print('RFC ROCAUC Score:', rocauc_rf*100)
    print('RFC Recall score:', recalls_rf*100)
    print('RFC Precision Score:', precisions_rf*100)
    print('RFC Confusion Matrix', confusion_matrix(y_test,rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test,rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf*100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS Test-Size", df1_l,":", probs_lr_scol)
    print("Array of F1 Scores LR-ROS Test-Size:", df1_l,":", f1_lr_scol)
    print("Array of ROCAUC Scores LR-ROS:", df1_l,":", rocauc_lr_scol)
    print("Array of Recall Scores LR-ROS:", df1_l,":", recall_lr_scol)
    print("Array of Precision Scores LR-ROS:", df1_l,":", precision_lr_scol)
    print("Array of Accuracy Scores LR-ROS:", df1_l,":", accuracy_lr_scol)

    print("Array of Prob Scores DT-ROS:", df1_l,":", probs_dt_scol)
    print("Array of F1 Scores DT-ROS:", df1_l,":", f1_dt_scol)
    print("Array of ROCAUC Scores DT-ROS:", df1_l,":", rocauc_dt_scol)
    print("Array of Recall Scores DT-ROS:", df1_l,":", recall_dt_scol)
    print("Array of Precision Scores DT-ROS:", df1_l,":", precision_dt_scol)
    print("Array of Accuracy Scores DT-ROS:", df1_l,":", accuracy_dt_scol)

    print("Array of Prob Scores NB-ROS:", df1_l,":", probs_nb_scol)
    print("Array of F1 Scores NB-ROS:", df1_l,":", f1_nb_scol)
    print("Array of ROCAUC Scores NB-ROS:", df1_l,":", rocauc_nb_scol)
    print("Array of Recall Scores NB-ROS:", df1_l,":", recall_nb_scol)
    print("Array of Precision Scores NB-ROS:", df1_l,":", precision_nb_scol)
    print("Array of Accuracy Scores NB-ROS:", df1_l,":", accuracy_nb_scol)

    print("Array of Prob Scores XG-ROS:", df1_l,":", probs_xg_scol)
    print("Array of F1 Scores XG-ROS:",  df1_l,":", f1_xg_scol)
    print("Array of ROCAUC Scores XG-ROS:",  df1_l,":",  rocauc_xg_scol)
    print("Array of Recall Scores XG-ROS:",  df1_l,":",  recall_xg_scol)
    print("Array of Precision Scores XG-ROS:",  df1_l,":", precision_xg_scol)
    print("Array of Accuracy Scores XG-ROS:",  df1_l,":", accuracy_xg_scol)

    print("Array of Prob Scores RF-ROS:",  df1_l,":", probs_rf_scol)
    print("Array of F1 Scores RF-ROS:", df1_l,":",  f1_rf_scol)
    print("Array of ROCAUC Scores RF-ROS:",  df1_l,":", rocauc_rf_scol)
    print("Array of Recall Scores RF-ROS:", df1_l,":",  recall_rf_scol)
    print("Array of Precision Scores RF-ROS:", df1_l,":",  precision_rf_scol)
    print("Array of Accuracy Scores RF-ROS:", df1_l,":",  accuracy_rf_scol)

from itertools import chain
'''
classifier_list = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num = [0.83, 0.67, 0.50, 0.33, 0.17]
precision_csv_num = [precision_lr_scol, precision_dt_scol, precision_nb_scol, precision_xg_scol, precision_rf_scol]
recall_csv_num = [recall_lr_scol, recall_dt_scol, recall_nb_scol, recall_xg_scol, recall_rf_scol]
auc_csv_num = [rocauc_lr_scol, rocauc_dt_scol, rocauc_nb_scol, rocauc_xg_scol, rocauc_rf_scol]
accuracy_csv_num = [accuracy_lr_scol, accuracy_dt_scol, accuracy_nb_scol, accuracy_xg_scol, accuracy_rf_scol]
csv_data = {'Year': [ args.group for t in range(25)],
        'Sampling': ['N/A' for t in range(25)],
        'Technique': ['N/A' for t in range(25)],
        'Classifier': [list(classifier_list)*5],
        'Test Sizes': [list(test_sizes_num)*5],
        'Train Sizes': [list(train_sizes_num)*5],
        'Split': ['1' for t in range(25)],
        'Train': ['5%' for t in range(25)],
        'Precision': [list(chain(*precision_csv_num))],
        'Recall': [list(chain(*recall_csv_num))],
        'AUC': [list(chain(*auc_csv_num))],
        'Accuracy': [list(chain(*accuracy_csv_num))]}
csv_df = pd.DataFrame.from_dict(csv_data, orient="index")
#df = df.append(df1)
csv_df.to_csv("Iterations_test.csv")
'''

year = [ args.group for t in range(25)]
sampling = ['Oversampling' for t in range(25)]
technique = ['ROS' for t in range(25)]
classifier_names = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num = [0.83, 0.67, 0.50, 0.33, 0.17]
#v = [0, 1, 2, 3, 4]
#precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
#recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
#auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
#accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num = [precision_lr_scol, precision_dt_scol, precision_nb_scol, precision_xg_scol, precision_rf_scol]
recall_csv_num = [recall_lr_scol, recall_dt_scol, recall_nb_scol, recall_xg_scol, recall_rf_scol]
auc_csv_num = [rocauc_lr_scol, rocauc_dt_scol, rocauc_nb_scol, rocauc_xg_scol, rocauc_rf_scol]
accuracy_csv_num = [accuracy_lr_scol, accuracy_dt_scol, accuracy_nb_scol, accuracy_xg_scol, accuracy_rf_scol]
import itertools
rounds = 5
p = itertools.cycle(classifier_names)
o = itertools.cycle(test_sizes_num)
k = itertools.cycle(train_sizes_num)
#v = itertools.cycle(score_location)
#pr = itertools.cycle(precision_num)
#y = itertools.cycle(iteration_csv)
classifier_csv = [next(p) for _ in range(rounds)]*5
#test_size_csv = [next(o) for _ in range(rounds)]*5
test_size_csv = [a for b in test_sizes_num for a in (b,)*5]
train_size_csv = [c for d in train_sizes_num for c in (d,)*5]
split_csv = ['1' for t in range(25)]
train_csv = ['5%' for t in range(25)]
precision_csv = list(chain(*precision_csv_num))
recall_csv = list(chain(*recall_csv_num))
auc_csv = list(chain(*auc_csv_num))
accuracy_csv = list(chain(*accuracy_csv_num))
csv_data = [year, sampling, technique, classifier_csv, test_size_csv, train_size_csv, split_csv, train_csv, precision_csv, recall_csv, auc_csv, accuracy_csv]
export_data = zip_longest(*csv_data, fillvalue='')
filename = args.iteration
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerow(("Year", "Sampling", "Technique", "Classifier", "Test Split Size", "Train Split Size", "Iteration", "Training Data", "Precision", "Recall", "AUC", "Accuracy"))
    write.writerows(export_data)
'''

# Precision - 1st Test Size
#precision_nea1b = list([precision_rf_scol[0], precision_xg_scol[0], precision_dt_scol[0], precision_lr_scol[0], precision_nb_scol[0]])
precision_nea1 = list([test_sizes[0], precision_rf_scol[0], precision_xg_scol[0], precision_dt_scol[0], precision_lr_scol[0], precision_nb_scol[0]])
precision_nea2 = list([test_sizes[0], precision_rf_scol[1], precision_xg_scol[1], precision_dt_scol[1], precision_lr_scol[1], precision_nb_scol[1]])
precision_nea3 = list([test_sizes[0], precision_rf_scol[2], precision_xg_scol[2], precision_dt_scol[2], precision_lr_scol[2], precision_nb_scol[2]])
precision_nea4 = list([test_sizes[0], precision_rf_scol[3], precision_xg_scol[3], precision_dt_scol[3], precision_lr_scol[3], precision_nb_scol[3]])
precision_nea5 = list([test_sizes[0], precision_rf_scol[4], precision_xg_scol[4], precision_dt_scol[4], precision_lr_scol[4], precision_nb_scol[4]])

# Recall - 1st Test Size 
#recall_nea1b = list([recall_rf_scol[0], recall_xg_scol[0], recall_dt_scol[0], recall_lr_scol[0], recall_nb_scol[0]])
recall_nea1 = list([test_sizes[0], recall_rf_scol[0], recall_xg_scol[0], recall_dt_scol[0], recall_lr_scol[0], recall_nb_scol[0]])
recall_nea2 = list([test_sizes[0], recall_rf_scol[1], recall_xg_scol[1], recall_dt_scol[1], recall_lr_scol[1], recall_nb_scol[1]])
recall_nea3 = list([test_sizes[0], recall_rf_scol[2], recall_xg_scol[2], recall_dt_scol[2], recall_lr_scol[2], recall_nb_scol[2]])
recall_nea4 = list([test_sizes[0], recall_rf_scol[3], recall_xg_scol[3], recall_dt_scol[3], recall_lr_scol[3], recall_nb_scol[3]])
recall_nea5 = list([test_sizes[0], recall_rf_scol[4], recall_xg_scol[4], recall_dt_scol[4], recall_lr_scol[4], recall_nb_scol[4]])
'''

'''
precision_lr_scol_avg = (precision_lr_scol[0] + precision_lr_scol[1] + precision_lr_scol[2] + precision_lr_scol[3] + precision_lr_scol[4] + precision_lr_scol[5] + precision_lr_scol[6] + precision_lr_scol[7] + precision_lr_scol[8] + precision_lr_scol[9]) / 10
precision_dt_scol_avg = (precision_dt_scol[0] + precision_dt_scol[1] + precision_dt_scol[2] + precision_dt_scol[3] + precision_dt_scol[4] + precision_dt_scol[5] + precision_dt_scol[6] + precision_dt_scol[7] + precision_dt_scol[8] + precision_dt_scol[9]) / 10
precision_rf_scol_avg = (precision_rf_scol[0] + precision_rf_scol[1] + precision_rf_scol[2] + precision_rf_scol[3] + precision_rf_scol[4] + precision_rf_scol[5] + precision_rf_scol[6] + precision_rf_scol[7] + precision_rf_scol[8] + precision_rf_scol[9]) / 10
precision_nb_scol_avg = (precision_nb_scol[0] + precision_nb_scol[1] + precision_nb_scol[2] + precision_nb_scol[3] + precision_nb_scol[4] + precision_nb_scol[5] + precision_nb_scol[6] + precision_nb_scol[7] + precision_nb_scol[8] + precision_nb_scol[9]) / 10
precision_xg_scol_avg = (precision_xg_scol[0] + precision_xg_scol[1] + precision_xg_scol[2] + precision_xg_scol[3] + precision_xg_scol[4] + precision_xg_scol[5] + precision_xg_scol[6] + precision_xg_scol[7] + precision_xg_scol[8] + precision_xg_scol[9]) / 10
'''
precision_lr_scol_avg = (precision_lr_scol[0] + precision_lr_scol[1] + precision_lr_scol[2] + precision_lr_scol[3] + precision_lr_scol[4] ) / 5
precision_dt_scol_avg = (precision_dt_scol[0] + precision_dt_scol[1] + precision_dt_scol[2] + precision_dt_scol[3] + precision_dt_scol[4] ) / 5
precision_rf_scol_avg = (precision_rf_scol[0] + precision_rf_scol[1] + precision_rf_scol[2] + precision_rf_scol[3] + precision_rf_scol[4] ) / 5
precision_nb_scol_avg = (precision_nb_scol[0] + precision_nb_scol[1] + precision_nb_scol[2] + precision_nb_scol[3] + precision_nb_scol[4] ) / 5
precision_xg_scol_avg = (precision_xg_scol[0] + precision_xg_scol[1] + precision_xg_scol[2] + precision_xg_scol[3] + precision_xg_scol[4] ) / 5
'''
recall_lr_scol_avg = (recall_lr_scol[0] + recall_lr_scol[1] + recall_lr_scol[2] + recall_lr_scol[3] + recall_lr_scol[4] + recall_lr_scol[5] + recall_lr_scol[6] + recall_lr_scol[7] + recall_lr_scol[8] + recall_lr_scol[9]) / 10
recall_dt_scol_avg = (recall_dt_scol[0] + recall_dt_scol[1] + recall_dt_scol[2] + recall_dt_scol[3] + recall_dt_scol[4] + recall_dt_scol[5] + recall_dt_scol[6] + recall_dt_scol[7] + recall_dt_scol[8] + recall_dt_scol[9]) / 10
recall_rf_scol_avg = (recall_rf_scol[0] + recall_rf_scol[1] + recall_rf_scol[2] + recall_rf_scol[3] + recall_rf_scol[4] + recall_rf_scol[5] + recall_rf_scol[6] + recall_rf_scol[7] + recall_rf_scol[8] + recall_rf_scol[9]) / 10
recall_nb_scol_avg = (recall_nb_scol[0] + recall_nb_scol[1] + recall_nb_scol[2] + recall_nb_scol[3] + recall_nb_scol[4] + recall_nb_scol[5] + recall_nb_scol[6] + recall_nb_scol[7] + recall_nb_scol[8] + recall_nb_scol[9]) / 10
recall_xg_scol_avg = (recall_xg_scol[0] + recall_xg_scol[1] + recall_xg_scol[2] + recall_xg_scol[3] + recall_xg_scol[4] + recall_xg_scol[5] + recall_xg_scol[6] + recall_xg_scol[7] + recall_xg_scol[8] + recall_xg_scol[9]) / 10
'''

recall_lr_scol_avg = (recall_lr_scol[0] + recall_lr_scol[1] + recall_lr_scol[2] + recall_lr_scol[3] + recall_lr_scol[4] ) / 5
recall_dt_scol_avg = (recall_dt_scol[0] + recall_dt_scol[1] + recall_dt_scol[2] + recall_dt_scol[3] + recall_dt_scol[4] ) / 5
recall_rf_scol_avg = (recall_rf_scol[0] + recall_rf_scol[1] + recall_rf_scol[2] + recall_rf_scol[3] + recall_rf_scol[4] ) / 5
recall_nb_scol_avg = (recall_nb_scol[0] + recall_nb_scol[1] + recall_nb_scol[2] + recall_nb_scol[3] + recall_nb_scol[4] ) / 5
recall_xg_scol_avg = (recall_xg_scol[0] + recall_xg_scol[1] + recall_xg_scol[2] + recall_xg_scol[3] + recall_xg_scol[4] ) / 5
'''
avg_precision_nea = list([precision_lr_scol_avg, precision_dt_scol_avg, precision_rf_scol_avg, precision_nb_scol_avg, precision_xg_scol_avg])
avg_recall_nea = list([recall_lr_scol_avg, recall_dt_scol_avg, recall_rf_scol_avg, recall_nb_scol_avg, recall_xg_scol_avg])
'''
# 2nd Test Size - 10%


probs_lr_scol1 = []
f1_lr_scol1 = []
rocauc_lr_scol1 = []
recall_lr_scol1 = []
precision_lr_scol1 = []
accuracy_lr_scol1 = []

probs_dt_scol1 = []
f1_dt_scol1 = []
rocauc_dt_scol1 = []
recall_dt_scol1 = []
precision_dt_scol1 = []
accuracy_dt_scol1 = []

probs_nb_scol1 = []
f1_nb_scol1 = []
rocauc_nb_scol1 = []
recall_nb_scol1 = []
precision_nb_scol1 = []
accuracy_nb_scol1 = []

probs_xg_scol1 = []
f1_xg_scol1 = []
rocauc_xg_scol1 = []
recall_xg_scol1 = []
precision_xg_scol1 = []
accuracy_xg_scol1 = []

probs_rf_scol1 = []
f1_rf_scol1 = []
rocauc_rf_scol1 = []
recall_rf_scol1 = []
precision_rf_scol1 = []
accuracy_rf_scol1 = []


tfidf_vect1 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train1 = tfidf_vect1.fit_transform(x3.values)
tfidf_test1=tfidf_vect1.transform(x4.values)
print(tfidf_train1.shape)
print(tfidf_test1.shape)
#tfidf_train1.toarray()

x_tfidf1 = tfidf_vect1.fit_transform(df2["lemmatized"])
x_ros1, y_ros1 = ros.fit_resample(x_tfidf1, df2["label"])

# train_values = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
'''
test_values1 = 1 - train_values1
'''
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros1,y_ros1, train_size=i, stratify=y_ros1)

    start1 = time.time()
    log = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train,y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol1.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction,y_test)
    f1_lr_scol1.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol1.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol1.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol1.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol1.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df2_l, i)
    lr_end = time.time()
    print('Logistic F1-score',fly*100)
    print('Logistic ROCAUC score:',rocauc_lr*100)
    print('Logistic Recall score:', recalls_lr*100)
    print('Logistic Precision Score:', precisions_lr*100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test,ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test,ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr*100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier
    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol1.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred,y_test)
    f1_dt_scol1.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol1.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol1.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol1.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol1.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df2_l, i)
    dt_end = time.time()
    print('DCT F1-score',fdct*100)
    print('DCT ROCAUC score:',rocauc_dt*100)
    print('DCT Recall score:', recalls_dt*100)
    print('DCT Precision Score:', precisions_dt*100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt*100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")


    from sklearn.naive_bayes import MultinomialNB
    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train,y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol1.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred,y_test)
    f1_nb_scol1.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol1.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol1.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol1.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol1.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df2_l, i)
    print('Naive F1-score',fnb*100)
    print('Naive ROCAUC score:',rocauc_nb*100)
    print('Naive Recall score:', recalls_nb*100)
    print('Naive Precision Score:', precisions_nb*100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb*100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

# XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol1.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict,y_test)
    f1_xg_scol1.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol1.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol1.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol1.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol1.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df2_l, i)
    print('XGB F1-Score', fxg*100)
    print('XGB ROCAUC Score:', rocauc_xg*100)
    print('XGB Recall score:', recall_xg*100)
    print('XGB Precision Score:', precisions_xg *100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb*100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

# Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier
    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train,y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol1.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred,y_test)
    f1_rf_scol1.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol1.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol1.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol1.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol1.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df2_l, i)
    print('RFC F1 score', frfc*100)
    print('RFC ROCAUC Score:', rocauc_rf*100)
    print('RFC Recall score:', recalls_rf*100)
    print('RFC Precision Score:', precisions_rf*100)
    print('RFC Confusion Matrix', confusion_matrix(y_test,rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test,rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf*100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:",  df2_l,":",  probs_lr_scol1)
    print("Array of F1 Scores LR-ROS:",  df2_l,":",  f1_lr_scol1)
    print("Array of ROCAUC Scores LR-ROS:",  df2_l,":",  rocauc_lr_scol1)
    print("Array of Recall Scores LR-ROS:",  df2_l,":",  recall_lr_scol1)
    print("Array of Precision Scores LR-ROS:",  df2_l,":", precision_lr_scol1)
    print("Array of Accuracy Scores LR-ROS:", df2_l,":", accuracy_lr_scol1)

    print("Array of Prob Scores DT-ROS:", df2_l,":", probs_dt_scol1)
    print("Array of F1 Scores DT-ROS:", df2_l,":", f1_dt_scol1)
    print("Array of ROCAUC Scores DT-ROS:", df2_l,":", rocauc_dt_scol1)
    print("Array of Recall Scores DT-ROS:",df2_l,":", recall_dt_scol1)
    print("Array of Precision Scores DT-ROS:", df2_l,":", precision_dt_scol1)
    print("Array of Accuracy Scores DT-ROS:", df2_l,":", accuracy_dt_scol1)

    print("Array of Prob Scores NB-ROS:", df2_l,":", probs_nb_scol1)
    print("Array of F1 Scores NB-ROS:", df2_l,":", f1_nb_scol1)
    print("Array of ROCAUC Scores NB-ROS:", df2_l,":", rocauc_nb_scol1)
    print("Array of Recall Scores NB-ROS:", df2_l,":", recall_nb_scol1)
    print("Array of Precision Scores NB-ROS:", df2_l,":", precision_nb_scol1)
    print("Array of Accuracy Scores NB-ROS:", df2_l,":", accuracy_nb_scol1)

    print("Array of Prob Scores XG-ROS:", df2_l,":", probs_xg_scol1)
    print("Array of F1 Scores XG-ROS:", df2_l,":", f1_xg_scol1)
    print("Array of ROCAUC Scores XG-ROS:", df2_l,":", rocauc_xg_scol1)
    print("Array of Recall Scores XG-ROS:", df2_l,":", recall_xg_scol1)
    print("Array of Precision Scores XG-ROS:", df2_l,":", precision_xg_scol1)
    print("Array of Accuracy Scores XG-ROS:", df2_l,":", accuracy_xg_scol1)

    print("Array of Prob Scores RF-ROS:", df2_l,":", probs_rf_scol1)
    print("Array of F1 Scores RF-ROS:", df2_l,":", f1_rf_scol1)
    print("Array of ROCAUC Scores RF-ROS:", df2_l,":", rocauc_rf_scol1)
    print("Array of Recall Scores RF-ROS:", df2_l,":", recall_rf_scol1)
    print("Array of Precision Scores RF-ROS:", df2_l,":", precision_rf_scol1)
    print("Array of Accuracy Scores RF-ROS:", df2_l,":", accuracy_rf_scol1)
'''
classifier_list = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num = [0.83, 0.67, 0.50, 0.33, 0.17]
precision_csv_num1 = [precision_lr_scol1, precision_dt_scol1, precision_nb_scol1, precision_xg_scol1, precision_rf_scol1]
recall_csv_num1 = [recall_lr_scol1, recall_dt_scol1, recall_nb_scol1, recall_xg_scol1, recall_rf_scol1]
auc_csv_num1 = [rocauc_lr_scol1, rocauc_dt_scol1, rocauc_nb_scol1, rocauc_xg_scol1, rocauc_rf_scol1]
accuracy_csv_num1 = [accuracy_lr_scol1, accuracy_dt_scol1, accuracy_nb_scol1, accuracy_xg_scol1, accuracy_rf_scol1]
csv_data1 = {'Year': [ args.group for t in range(25)],
        'Sampling': ['N/A' for t in range(25)],
        'Technique': ['N/A' for t in range(25)],
        'Classifier': [list(classifier_list)*5],
        'Test Sizes': [list(test_sizes_num)*5],
        'Train Sizes': [list(train_sizes_num)*5],
        'Split': ['1' for t in range(25)],
        'Train': ['5%' for t in range(25)],
        'Precision': [list(chain(*precision_csv_num1))],
        'Recall': [list(chain(*recall_csv_num1))],
        'AUC': [list(chain(*auc_csv_num1))],
        'Accuracy': [list(chain(*accuracy_csv_num1))]}
csv_df1 = pd.DataFrame.from_dict(csv_data1, orient="index")
csv_df = csv_df.append(csv_df1)
csv_df.to_csv("Iterations_test.csv")
'''

from itertools import chain
year1 = [args.group for t in range(25)]
sampling1 =['Oversampling' for t in range(25)]
technique1 = ['ROS' for t in range(25)]
classifier_names1 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num1 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num1 = [0.83, 0.67, 0.50, 0.33, 0.17]
#v = [0, 1, 2, 3, 4]
#precision_csv_num = [precision_lr_scol1[z], precision_dt_scol1[z], precision_nb_scol1[z], precision_xg_scol1[z], precision_rf_scol1[z]]
#recall_csv_num = [recall_lr_scol1[z], recall_dt_scol1[z], recall_nb_scol1[z], recall_xg_scol1[z], recall_rf_scol1[z]]
#auc_csv_num = [rocauc_lr_scol1[z], rocauc_dt_scol1[z], rocauc_nb_scol1[z], rocauc_xg_scol1[z], rocauc_rf_scol1[z]]
#accuracy_csv_num = [accuracy_lr_scol1[z], accuracy_dt_scol1[z], accuracy_nb_scol1[z], accuracy_xg_scol1[z], accuracy_rf_scol1[z]]
precision_csv_num1 = [precision_lr_scol1, precision_dt_scol1, precision_nb_scol1, precision_xg_scol1, precision_rf_scol1]
recall_csv_num1 = [recall_lr_scol1, recall_dt_scol1, recall_nb_scol1, recall_xg_scol1, recall_rf_scol1]
auc_csv_num1 = [rocauc_lr_scol1, rocauc_dt_scol1, rocauc_nb_scol1, rocauc_xg_scol1, rocauc_rf_scol1]
accuracy_csv_num1 = [accuracy_lr_scol1, accuracy_dt_scol1, accuracy_nb_scol1, accuracy_xg_scol1, accuracy_rf_scol1]
import itertools
rounds = 5
p1 = itertools.cycle(classifier_names1)
o1 = itertools.cycle(test_sizes_num1)
k1 = itertools.cycle(train_sizes_num1)
#v = itertools.cycle(score_location)
#pr = itertools.cycle(precision_num)
#y = itertools.cycle(iteration_csv)
classifier_csv1 = [next(p1) for _ in range(rounds)]*5
test_size_csv1 = [a for b in test_sizes_num1 for a in (b,)*5]
train_size_csv1 = [c for d in train_sizes_num1 for c in (d,)*5]
split_csv1 = ['2' for t in range(25)]
train_csv1 = ['10%' for t in range(25)]
precision_csv1 = list(chain(*precision_csv_num1))
recall_csv1 = list(chain(*recall_csv_num1))
auc_csv1 = list(chain(*auc_csv_num1))
accuracy_csv1 = list(chain(*accuracy_csv_num1))
csv_data1 = [year1, sampling1, technique1, classifier_csv1, test_size_csv1, train_size_csv1, split_csv1, train_csv1, precision_csv1, recall_csv1, auc_csv1, accuracy_csv1]
export_data1 = zip_longest(*csv_data1, fillvalue='')
filename = args.iteration
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data1)

# Precision - 2nd test size
'''
# Precision - 1st Test Size
#precision_nea1b = list([precision_rf_scol1[0], precision_xg_scol1[0], precision_dt_scol1[0], precision_lr_scol1[0], precision_nb_scol1[0]])
precision_nea1 = list([test_sizes[0], precision_rf_scol1[0], precision_xg_scol1[0], precision_dt_scol1[0], precision_lr_scol1[0], precision_nb_scol1[0]])
precision_nea2 = list([test_sizes[0], precision_rf_scol1[1], precision_xg_scol1[1], precision_dt_scol1[1], precision_lr_scol1[1], precision_nb_scol1[1]])
precision_nea3 = list([test_sizes[0], precision_rf_scol1[2], precision_xg_scol1[2], precision_dt_scol1[2], precision_lr_scol1[2], precision_nb_scol1[2]])
precision_nea4 = list([test_sizes[0], precision_rf_scol1[3], precision_xg_scol1[3], precision_dt_scol1[3], precision_lr_scol1[3], precision_nb_scol1[3]])
precision_nea5 = list([test_sizes[0], precision_rf_scol1[4], precision_xg_scol1[4], precision_dt_scol1[4], precision_lr_scol1[4], precision_nb_scol1[4]])

# Recall - 1st Test Size 
#recall_nea1b = list([recall_rf_scol1[0], recall_xg_scol1[0], recall_dt_scol1[0], recall_lr_scol1[0], recall_nb_scol1[0]])
recall_nea1 = list([test_sizes[0], recall_rf_scol1[0], recall_xg_scol1[0], recall_dt_scol1[0], recall_lr_scol1[0], recall_nb_scol1[0]])
recall_nea2 = list([test_sizes[0], recall_rf_scol1[1], recall_xg_scol1[1], recall_dt_scol1[1], recall_lr_scol1[1], recall_nb_scol1[1]])
recall_nea3 = list([test_sizes[0], recall_rf_scol1[2], recall_xg_scol1[2], recall_dt_scol1[2], recall_lr_scol1[2], recall_nb_scol1[2]])
recall_nea4 = list([test_sizes[0], recall_rf_scol1[3], recall_xg_scol1[3], recall_dt_scol1[3], recall_lr_scol1[3], recall_nb_scol1[3]])
recall_nea5 = list([test_sizes[0], recall_rf_scol1[4], recall_xg_scol1[4], recall_dt_scol1[4], recall_lr_scol1[4], recall_nb_scol1[4]])
'''
'''
recall_nea16 = list([test_sizes[1], recall_lr_scol11[5], recall_dt_scol11[5], recall_rf_scol11[5], recall_nb_scol11[5], recall_xg_scol11[5]])
recall_nea17 = list([test_sizes[1], recall_lr_scol11[6], recall_dt_scol11[6], recall_rf_scol11[6], recall_nb_scol11[6], recall_xg_scol11[6]])
recall_nea18 = list([test_sizes[1], recall_lr_scol11[7], recall_dt_scol11[7], recall_rf_scol11[7], recall_nb_scol11[7], recall_xg_scol11[7]])
recall_nea19 = list([test_sizes[1], recall_lr_scol11[8], recall_dt_scol11[8], recall_rf_scol11[8], recall_nb_scol11[8], recall_xg_scol11[8]])
recall_nea30 = list([test_sizes[1], recall_lr_scol11[9], recall_dt_scol11[9], recall_rf_scol11[9], recall_nb_scol11[9], recall_xg_scol11[9]])
'''
precision_lr_scol1_avg = (precision_lr_scol1[0] + precision_lr_scol1[1] + precision_lr_scol1[2] + precision_lr_scol1[3] + precision_lr_scol1[4]) / 5
precision_dt_scol1_avg = (precision_dt_scol1[0] + precision_dt_scol1[1] + precision_dt_scol1[2] + precision_dt_scol1[3] + precision_dt_scol1[4]) / 5
precision_rf_scol1_avg = (precision_rf_scol1[0] + precision_rf_scol1[1] + precision_rf_scol1[2] + precision_rf_scol1[3] + precision_rf_scol1[4]) / 5
precision_nb_scol1_avg = (precision_nb_scol1[0] + precision_nb_scol1[1] + precision_nb_scol1[2] + precision_nb_scol1[3] + precision_nb_scol1[4]) / 5
precision_xg_scol1_avg = (precision_xg_scol1[0] + precision_xg_scol1[1] + precision_xg_scol1[2] + precision_xg_scol1[3] + precision_xg_scol1[4]) / 5

recall_lr_scol1_avg = (recall_lr_scol1[0] + recall_lr_scol1[1] + recall_lr_scol1[2] + recall_lr_scol1[3] + recall_lr_scol1[4]) / 5
recall_dt_scol1_avg = (recall_dt_scol1[0] + recall_dt_scol1[1] + recall_dt_scol1[2] + recall_dt_scol1[3] + recall_dt_scol1[4]) / 5
recall_rf_scol1_avg = (recall_rf_scol1[0] + recall_rf_scol1[1] + recall_rf_scol1[2] + recall_rf_scol1[3] + recall_rf_scol1[4]) / 5
recall_nb_scol1_avg = (recall_nb_scol1[0] + recall_nb_scol1[1] + recall_nb_scol1[2] + recall_nb_scol1[3] + recall_nb_scol1[4]) / 5
recall_xg_scol1_avg = (recall_xg_scol1[0] + recall_xg_scol1[1] + recall_xg_scol1[2] + recall_xg_scol1[3] + recall_xg_scol1[4]) / 5
'''
precision_lr_scol1_avg = (precision_lr_scol1[0] + precision_lr_scol1[1] + precision_lr_scol1[2] + precision_lr_scol1[3] + precision_lr_scol1[4] + precision_lr_scol1[5] + precision_lr_scol1[6] + precision_lr_scol1[7] + precision_lr_scol1[8] + precision_lr_scol1[9]) / 10
precision_dt_scol1_avg = (precision_dt_scol1[0] + precision_dt_scol1[1] + precision_dt_scol1[2] + precision_dt_scol1[3] + precision_dt_scol1[4] + precision_dt_scol1[5] + precision_dt_scol1[6] + precision_dt_scol1[7] + precision_dt_scol1[8] + precision_dt_scol1[9]) / 10
precision_rf_scol1_avg = (precision_rf_scol1[0] + precision_rf_scol1[1] + precision_rf_scol1[2] + precision_rf_scol1[3] + precision_rf_scol1[4] + precision_rf_scol1[5] + precision_rf_scol1[6] + precision_rf_scol1[7] + precision_rf_scol1[8] + precision_rf_scol1[9]) / 10
precision_nb_scol1_avg = (precision_nb_scol1[0] + precision_nb_scol1[1] + precision_nb_scol1[2] + precision_nb_scol1[3] + precision_nb_scol1[4] + precision_nb_scol1[5] + precision_nb_scol1[6] + precision_nb_scol1[7] + precision_nb_scol1[8] + precision_nb_scol1[9]) / 10
precision_xg_scol1_avg = (precision_xg_scol1[0] + precision_xg_scol1[1] + precision_xg_scol1[2] + precision_xg_scol1[3] + precision_xg_scol1[4] + precision_xg_scol1[5] + precision_xg_scol1[6] + precision_xg_scol1[7] + precision_xg_scol1[8] + precision_xg_scol1[9]) / 10


recall_lr_scol1_avg = (recall_lr_scol1[0] + recall_lr_scol1[1] + recall_lr_scol1[2] + recall_lr_scol1[3] + recall_lr_scol1[4] + recall_lr_scol1[5] + recall_lr_scol1[6] + recall_lr_scol1[7] + recall_lr_scol1[8] + recall_lr_scol1[9]) / 10
recall_dt_scol1_avg = (recall_dt_scol1[0] + recall_dt_scol1[1] + recall_dt_scol1[2] + recall_dt_scol1[3] + recall_dt_scol1[4] + recall_dt_scol1[5] + recall_dt_scol1[6] + recall_dt_scol1[7] + recall_dt_scol1[8] + recall_dt_scol1[9]) / 10
recall_rf_scol1_avg = (recall_rf_scol1[0] + recall_rf_scol1[1] + recall_rf_scol1[2] + recall_rf_scol1[3] + recall_rf_scol1[4] + recall_rf_scol1[5] + recall_rf_scol1[6] + recall_rf_scol1[7] + recall_rf_scol1[8] + recall_rf_scol1[9]) / 10
recall_nb_scol1_avg = (recall_nb_scol1[0] + recall_nb_scol1[1] + recall_nb_scol1[2] + recall_nb_scol1[3] + recall_nb_scol1[4] + recall_nb_scol1[5] + recall_nb_scol1[6] + recall_nb_scol1[7] + recall_nb_scol1[8] + recall_nb_scol1[9]) / 10
recall_xg_scol1_avg = (recall_xg_scol1[0] + recall_xg_scol1[1] + recall_xg_scol1[2] + recall_xg_scol1[3] + recall_xg_scol1[4] + recall_xg_scol1[5] + recall_xg_scol1[6] + recall_xg_scol1[7] + recall_xg_scol1[8] + recall_xg_scol1[9]) / 10
'''
'''
avg_precision_nea1 = list([test_sizes[1], precision_lr_scol1_avg, precision_dt_scol1_avg, precision_rf_scol1_avg, precision_nb_scol1_avg, precision_xg_scol1_avg])
avg_recall_nea1 = list([test_sizes[1], recall_lr_scol1_avg, recall_dt_scol1_avg, recall_rf_scol1_avg, recall_nb_scol1_avg, recall_xg_scol1_avg])
'''

# 3rd Test Size - 15%

probs_lr_scol2 = []
f1_lr_scol2 = []
rocauc_lr_scol2 = []
recall_lr_scol2 = []
precision_lr_scol2 = []
accuracy_lr_scol2 = []

probs_dt_scol2 = []
f1_dt_scol2 = []
rocauc_dt_scol2 = []
recall_dt_scol2 = []
precision_dt_scol2 = []
accuracy_dt_scol2 = []

probs_nb_scol2 = []
f1_nb_scol2 = []
rocauc_nb_scol2 = []
recall_nb_scol2 = []
precision_nb_scol2 = []
accuracy_nb_scol2 = []

probs_xg_scol2 = []
f1_xg_scol2 = []
rocauc_xg_scol2 = []
recall_xg_scol2 = []
precision_xg_scol2 = []
accuracy_xg_scol2 = []

probs_rf_scol2 = []
f1_rf_scol2 = []
rocauc_rf_scol2 = []
recall_rf_scol2 = []
precision_rf_scol2 = []
accuracy_rf_scol2 = []

tfidf_vect2= TfidfVectorizer(ngram_range=(1,2))
tfidf_train2 = tfidf_vect2.fit_transform(x5.values)
tfidf_test2=tfidf_vect2.transform(x6.values)
print(tfidf_train2.shape)
print(tfidf_test2.shape)
#tfidf_train2.toarray()

x_tfidf2 = tfidf_vect2.fit_transform(df3["lemmatized"])
x_ros2, y_ros2 = ros.fit_resample(x_tfidf2, df3["label"])

# train_values2 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values2 = 1 - train_values2
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros2, y_ros2, train_size=i, stratify=y_ros2)


    start1 = time.time()
    log = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train,y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol2.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction,y_test)
    f1_lr_scol2.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol2.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol2.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol2.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol2.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df3_l, i)
    lr_end = time.time()
    print('Logistic F1-score',fly*100)
    print('Logistic ROCAUC score:',rocauc_lr*100)
    print('Logistic Recall score:', recalls_lr*100)
    print('Logistic Precision Score:', precisions_lr*100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test,ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test,ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr*100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier
    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol2.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred,y_test)
    f1_dt_scol2.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol2.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol2.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol2.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol2.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df3_l, i)
    dt_end = time.time()
    print('DCT F1-score',fdct*100)
    print('DCT ROCAUC score:',rocauc_dt*100)
    print('DCT Recall score:', recalls_dt*100)
    print('DCT Precision Score:', precisions_dt*100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt*100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")


    from sklearn.naive_bayes import MultinomialNB
    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train,y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol2.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred,y_test)
    f1_nb_scol2.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol2.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol2.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol2.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol2.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df3_l, i)
    print('Naive F1-score',fnb*100)
    print('Naive ROCAUC score:',rocauc_nb*100)
    print('Naive Recall score:', recalls_nb*100)
    print('Naive Precision Score:', precisions_nb*100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb*100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

# XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol2.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict,y_test)
    f1_xg_scol2.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol2.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol2.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol2.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol2.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df3_l, i)
    print('XGB F1-Score', fxg*100)
    print('XGB ROCAUC Score:', rocauc_xg*100)
    print('XGB Recall score:', recall_xg*100)
    print('XGB Precision Score:', precisions_xg *100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb*100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

# Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier
    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train,y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol2.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred,y_test)
    f1_rf_scol2.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol2.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol2.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol2.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol2.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df3_l, i)
    print('RFC F1 score', frfc*100)
    print('RFC ROCAUC Score:', rocauc_rf*100)
    print('RFC Recall score:', recalls_rf*100)
    print('RFC Precision Score:', precisions_rf*100)
    print('RFC Confusion Matrix', confusion_matrix(y_test,rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test,rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf*100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:",  df3_l,":",  probs_lr_scol2)
    print("Array of F1 Scores LR-ROS:",  df3_l,":",  f1_lr_scol2)
    print("Array of ROCAUC Scores LR-ROS:",  df3_l,":",  rocauc_lr_scol2)
    print("Array of Recall Scores LR-ROS:",  df3_l,":",  recall_lr_scol2)
    print("Array of Precision Scores LR-ROS:",  df3_l,":", precision_lr_scol2)
    print("Array of Accuracy Scores LR-ROS:", df3_l,":", accuracy_lr_scol2)

    print("Array of Prob Scores DT-ROS:", df3_l,":", probs_dt_scol2)
    print("Array of F1 Scores DT-ROS:", df3_l,":", f1_dt_scol2)
    print("Array of ROCAUC Scores DT-ROS:", df3_l,":", rocauc_dt_scol2)
    print("Array of Recall Scores DT-ROS:",df3_l,":", recall_dt_scol2)
    print("Array of Precision Scores DT-ROS:", df3_l,":", precision_dt_scol2)
    print("Array of Accuracy Scores DT-ROS:", df3_l,":", accuracy_dt_scol2)

    print("Array of Prob Scores NB-ROS:", df3_l,":", probs_nb_scol2)
    print("Array of F1 Scores NB-ROS:", df3_l,":", f1_nb_scol2)
    print("Array of ROCAUC Scores NB-ROS:", df3_l,":", rocauc_nb_scol2)
    print("Array of Recall Scores NB-ROS:", df3_l,":", recall_nb_scol2)
    print("Array of Precision Scores NB-ROS:", df3_l,":", precision_nb_scol2)
    print("Array of Accuracy Scores NB-ROS:", df3_l,":", accuracy_nb_scol2)

    print("Array of Prob Scores XG-ROS:", df3_l,":", probs_xg_scol2)
    print("Array of F1 Scores XG-ROS:", df3_l,":", f1_xg_scol2)
    print("Array of ROCAUC Scores XG-ROS:", df3_l,":", rocauc_xg_scol2)
    print("Array of Recall Scores XG-ROS:", df3_l,":", recall_xg_scol2)
    print("Array of Precision Scores XG-ROS:", df3_l,":", precision_xg_scol2)
    print("Array of Accuracy Scores XG-ROS:", df3_l,":", accuracy_xg_scol2)

    print("Array of Prob Scores RF-ROS:", df3_l,":", probs_rf_scol2)
    print("Array of F1 Scores RF-ROS:", df3_l,":", f1_rf_scol2)
    print("Array of ROCAUC Scores RF-ROS:", df3_l,":", rocauc_rf_scol2)
    print("Array of Recall Scores RF-ROS:", df3_l,":", recall_rf_scol2)
    print("Array of Precision Scores RF-ROS:", df3_l,":", precision_rf_scol2)
    print("Array of Accuracy Scores RF-ROS:", df3_l,":", accuracy_rf_scol2)
    

from itertools import chain
year2 = [ args.group for t in range(25)]
sampling2 =['Oversampling' for t in range(25)]
technique2 = ['ROS' for t in range(25)]
classifier_names2 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num2 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num2 = [0.83, 0.67, 0.50, 0.33, 0.17]
#v = [0, 1, 2, 3, 4]
#precision_csv_num = [precision_lr_scol1[z], precision_dt_scol1[z], precision_nb_scol1[z], precision_xg_scol1[z], precision_rf_scol1[z]]
#recall_csv_num = [recall_lr_scol1[z], recall_dt_scol1[z], recall_nb_scol1[z], recall_xg_scol1[z], recall_rf_scol1[z]]
#auc_csv_num = [rocauc_lr_scol1[z], rocauc_dt_scol1[z], rocauc_nb_scol1[z], rocauc_xg_scol1[z], rocauc_rf_scol1[z]]
#accuracy_csv_num = [accuracy_lr_scol1[z], accuracy_dt_scol1[z], accuracy_nb_scol1[z], accuracy_xg_scol1[z], accuracy_rf_scol1[z]]
precision_csv_num2 = [precision_lr_scol2, precision_dt_scol2, precision_nb_scol2, precision_xg_scol2, precision_rf_scol2]
recall_csv_num2 = [recall_lr_scol2, recall_dt_scol2, recall_nb_scol2, recall_xg_scol2, recall_rf_scol2]
auc_csv_num2 = [rocauc_lr_scol2, rocauc_dt_scol2, rocauc_nb_scol2, rocauc_xg_scol2, rocauc_rf_scol2]
accuracy_csv_num2 = [accuracy_lr_scol2, accuracy_dt_scol2, accuracy_nb_scol2, accuracy_xg_scol2, accuracy_rf_scol2]
import itertools
rounds = 5
p2 = itertools.cycle(classifier_names2)
o2 = itertools.cycle(test_sizes_num2)
k2 = itertools.cycle(train_sizes_num2)
#v = itertools.cycle(score_location)
#pr = itertools.cycle(precision_num)
#y = itertools.cycle(iteration_csv)
classifier_csv2 = [next(p2) for _ in range(rounds)]*5
test_size_csv2 = [a for b in test_sizes_num2 for a in (b,)*5]
train_size_csv2 = [c for d in train_sizes_num2 for c in (d,)*5]
split_csv2 = ['3' for t in range(25)]
train_csv2 = ['15%' for t in range(25)]
precision_csv2 = list(chain(*precision_csv_num2))
recall_csv2 = list(chain(*recall_csv_num2))
auc_csv2 = list(chain(*auc_csv_num2))
accuracy_csv2 = list(chain(*accuracy_csv_num2))
csv_data2 = [year2, sampling2, technique2, classifier_csv2, test_size_csv2, train_size_csv2, split_csv2, train_csv2, precision_csv2, recall_csv2, auc_csv2, accuracy_csv2]
export_data2 = zip_longest(*csv_data2, fillvalue='')
filename = args.iteration
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data2)

'''
# Precision - 3rd Test Size
#precision_nea31b = list([precision_lr_scol2[0], precision_dt_scol2[0], precision_rf_scol2[0], precision_nb_scol2[0], precision_xg_scol2[0]])
precision_nea31 = list([test_sizes[2], precision_xg_scol2[0], precision_rf_scol2[0], precision_dt_scol2[0], precision_lr_scol2[0], precision_nb_scol2[0]])
#precision_nea31 = list([(test_sizes[2]-test_sizes[2]), (0.0+precision_rf_scol2[0]), (1.0+precision_xg_scol2[0]), (2.0+precision_dt_scol2[0]), (3.0+precision_lr_scol2[0]), (4.0+precision_nb_scol2[0])])
print("Iteration 1 Array:", precision_nea31)
precision_nea32 = list([test_sizes[2], precision_lr_scol2[1], precision_dt_scol2[1], precision_rf_scol2[1], precision_nb_scol2[1], precision_xg_scol2[1]])
#precision_nea32 = list([test_sizes[2], precision_xg_scol2[1], precision_rf_scol2[1], precision_dt_scol2[1],  precision_lr_scol2[1], precision_nb_scol2[1]])
#precision_nea32 = list([(test_sizes[2]-test_sizes[2]), (0.0+precision_rf_scol2[1]), (1.0+precision_xg_scol2[1]), (2.0+precision_dt_scol2[1]), (3.0+precision_lr_scol2[1]), (4.0+precision_nb_scol2[1])])
#print("Iteration 2 Array:", precision_nea32)
precision_nea33 = list([test_sizes[2], precision_lr_scol2[2], precision_dt_scol2[2], precision_rf_scol2[2], precision_nb_scol2[2], precision_xg_scol2[2]])
precision_nea34 = list([test_sizes[2], precision_lr_scol2[3], precision_dt_scol2[3], precision_rf_scol2[3], precision_nb_scol2[3], precision_xg_scol2[3]])
precision_nea35 = list([test_sizes[2], precision_lr_scol2[4], precision_dt_scol2[4], precision_rf_scol2[4], precision_nb_scol2[4], precision_xg_scol2[4]])

precision_nea36 = list([test_sizes[2], precision_lr_scol2[5], precision_dt_scol2[5], precision_rf_scol2[5], precision_nb_scol2[5], precision_xg_scol2[5]])
precision_nea37 = list([test_sizes[2], precision_lr_scol2[6], precision_dt_scol2[6], precision_rf_scol2[6], precision_nb_scol2[6], precision_xg_scol2[6]])
precision_nea38 = list([test_sizes[2], precision_lr_scol2[7], precision_dt_scol2[7], precision_rf_scol2[7], precision_nb_scol2[7], precision_xg_scol2[7]])
precision_nea39 = list([test_sizes[2], precision_lr_scol2[8], precision_dt_scol2[8], precision_rf_scol2[8], precision_nb_scol2[8], precision_xg_scol2[8]])
precision_nea30 = list([test_sizes[2], precision_lr_scol2[9], precision_dt_scol2[9], precision_rf_scol2[9], precision_nb_scol2[9], precision_xg_scol2[9]])


# Recall - 3nd Test Size
#recall_nea31b = list([recall_lr_scol2[0], recall_dt_scol2[0], recall_rf_scol2[0], recall_nb_scol2[0], recall_xg_scol2[0]])
recall_nea31 = list([test_sizes[2], recall_xg_scol2[0], recall_rf_scol2[0], recall_dt_scol2[0], recall_lr_scol2[0], recall_nb_scol2[0]])
#recall_nea31 = list([(test_sizes[2]-test_sizes[2]), (0.0+recall_rf_scol2[0]), (1.0+recall_xg_scol2[0]), (2.0+recall_dt_scol2[0]), (3.0+recall_lr_scol2[0]), (4.0+recall_nb_scol2[0])])
print("Iteration 1 Array:", recall_nea31)
recall_nea32 = list([test_sizes[2], recall_lr_scol2[1], recall_dt_scol2[1], recall_rf_scol2[1], recall_nb_scol2[1], recall_xg_scol2[1]])
#recall_nea32 = list([test_sizes[2], recall_xg_scol2[1], recall_rf_scol2[1], recall_dt_scol2[1],  recall_lr_scol2[1], recall_nb_scol2[1]])
#recall_nea32 = list([(test_sizes[2]-test_sizes[2]), (0.0+recall_rf_scol2[1]), (1.0+recall_xg_scol2[1]), (2.0+recall_dt_scol2[1]), (3.0+recall_lr_scol2[1]), (4.0+recall_nb_scol2[1])])
#print("Iteration 2 Array:", recall_nea32)
recall_nea33 = list([test_sizes[2], recall_lr_scol2[2], recall_dt_scol2[2], recall_rf_scol2[2], recall_nb_scol2[2], recall_xg_scol2[2]])
recall_nea34 = list([test_sizes[2], recall_lr_scol2[3], recall_dt_scol2[3], recall_rf_scol2[3], recall_nb_scol2[3], recall_xg_scol2[3]])
recall_nea35 = list([test_sizes[2], recall_lr_scol2[4], recall_dt_scol2[4], recall_rf_scol2[4], recall_nb_scol2[4], recall_xg_scol2[4]])

recall_nea36 = list([test_sizes[2], recall_lr_scol2[5], recall_dt_scol2[5], recall_rf_scol2[5], recall_nb_scol2[5], recall_xg_scol2[5]])
recall_nea37 = list([test_sizes[2], recall_lr_scol2[6], recall_dt_scol2[6], recall_rf_scol2[6], recall_nb_scol2[6], recall_xg_scol2[6]])
recall_nea38 = list([test_sizes[2], recall_lr_scol2[7], recall_dt_scol2[7], recall_rf_scol2[7], recall_nb_scol2[7], recall_xg_scol2[7]])
recall_nea39 = list([test_sizes[2], recall_lr_scol2[8], recall_dt_scol2[8], recall_rf_scol2[8], recall_nb_scol2[8], recall_xg_scol2[8]])
recall_nea30 = list([test_sizes[2], recall_lr_scol2[9], recall_dt_scol2[9], recall_rf_scol2[9], recall_nb_scol2[9], recall_xg_scol2[9]])

'''

precision_lr_scol2_avg = (precision_lr_scol2[0] + precision_lr_scol2[1] + precision_lr_scol2[2] + precision_lr_scol2[3] + precision_lr_scol2[4]) / 5
precision_dt_scol2_avg = (precision_dt_scol2[0] + precision_dt_scol2[1] + precision_dt_scol2[2] + precision_dt_scol2[3] + precision_dt_scol2[4]) / 5
precision_rf_scol2_avg = (precision_rf_scol2[0] + precision_rf_scol2[1] + precision_rf_scol2[2] + precision_rf_scol2[3] + precision_rf_scol2[4]) / 5
precision_nb_scol2_avg = (precision_nb_scol2[0] + precision_nb_scol2[1] + precision_nb_scol2[2] + precision_nb_scol2[3] + precision_nb_scol2[4]) / 5
precision_xg_scol2_avg = (precision_xg_scol2[0] + precision_xg_scol2[1] + precision_xg_scol2[2] + precision_xg_scol2[3] + precision_xg_scol2[4]) / 5


recall_lr_scol2_avg = (recall_lr_scol2[0] + recall_lr_scol2[1] + recall_lr_scol2[2] + recall_lr_scol2[3] + recall_lr_scol2[4]) / 5
recall_dt_scol2_avg = (recall_dt_scol2[0] + recall_dt_scol2[1] + recall_dt_scol2[2] + recall_dt_scol2[3] + recall_dt_scol2[4]) / 5
recall_rf_scol2_avg = (recall_rf_scol2[0] + recall_rf_scol2[1] + recall_rf_scol2[2] + recall_rf_scol2[3] + recall_rf_scol2[4]) / 5
recall_nb_scol2_avg = (recall_nb_scol2[0] + recall_nb_scol2[1] + recall_nb_scol2[2] + recall_nb_scol2[3] + recall_nb_scol2[4]) / 5
recall_xg_scol2_avg = (recall_xg_scol2[0] + recall_xg_scol2[1] + recall_xg_scol2[2] + recall_xg_scol2[3] + recall_xg_scol2[4]) / 5


'''
precision_lr_scol2_avg = (precision_lr_scol2[0] + precision_lr_scol2[1] + precision_lr_scol2[2] + precision_lr_scol2[3] + precision_lr_scol2[4] + precision_lr_scol2[5] + precision_lr_scol2[6] + precision_lr_scol2[7] + precision_lr_scol2[8] + precision_lr_scol2[9]) / 10
precision_dt_scol2_avg = (precision_dt_scol2[0] + precision_dt_scol2[1] + precision_dt_scol2[2] + precision_dt_scol2[3] + precision_dt_scol2[4] + precision_dt_scol2[5] + precision_dt_scol2[6] + precision_dt_scol2[7] + precision_dt_scol2[8] + precision_dt_scol2[9]) / 10
precision_rf_scol2_avg = (precision_rf_scol2[0] + precision_rf_scol2[1] + precision_rf_scol2[2] + precision_rf_scol2[3] + precision_rf_scol2[4] + precision_rf_scol2[5] + precision_rf_scol2[6] + precision_rf_scol2[7] + precision_rf_scol2[8] + precision_rf_scol2[9]) / 10
precision_nb_scol2_avg = (precision_nb_scol2[0] + precision_nb_scol2[1] + precision_nb_scol2[2] + precision_nb_scol2[3] + precision_nb_scol2[4] + precision_nb_scol2[5] + precision_nb_scol2[6] + precision_nb_scol2[7] + precision_nb_scol2[8] + precision_nb_scol2[9]) / 10
precision_xg_scol2_avg = (precision_xg_scol2[0] + precision_xg_scol2[1] + precision_xg_scol2[2] + precision_xg_scol2[3] + precision_xg_scol2[4] + precision_xg_scol2[5] + precision_xg_scol2[6] + precision_xg_scol2[7] + precision_xg_scol2[8] + precision_xg_scol2[9]) / 10


recall_lr_scol2_avg = (recall_lr_scol2[0] + recall_lr_scol2[1] + recall_lr_scol2[2] + recall_lr_scol2[3] + recall_lr_scol2[4] + recall_lr_scol2[5] + recall_lr_scol2[6] + recall_lr_scol2[7] + recall_lr_scol2[8] + recall_lr_scol2[9]) / 10
recall_dt_scol2_avg = (recall_dt_scol2[0] + recall_dt_scol2[1] + recall_dt_scol2[2] + recall_dt_scol2[3] + recall_dt_scol2[4] + recall_dt_scol2[5] + recall_dt_scol2[6] + recall_dt_scol2[7] + recall_dt_scol2[8] + recall_dt_scol2[9]) / 10
recall_rf_scol2_avg = (recall_rf_scol2[0] + recall_rf_scol2[1] + recall_rf_scol2[2] + recall_rf_scol2[3] + recall_rf_scol2[4] + recall_rf_scol2[5] + recall_rf_scol2[6] + recall_rf_scol2[7] + recall_rf_scol2[8] + recall_rf_scol2[9]) / 10
recall_nb_scol2_avg = (recall_nb_scol2[0] + recall_nb_scol2[1] + recall_nb_scol2[2] + recall_nb_scol2[3] + recall_nb_scol2[4] + recall_nb_scol2[5] + recall_nb_scol2[6] + recall_nb_scol2[7] + recall_nb_scol2[8] + recall_nb_scol2[9]) / 10
recall_xg_scol2_avg = (recall_xg_scol2[0] + recall_xg_scol2[1] + recall_xg_scol2[2] + recall_xg_scol2[3] + recall_xg_scol2[4] + recall_xg_scol2[5] + recall_xg_scol2[6] + recall_xg_scol2[7] + recall_xg_scol2[8] + recall_xg_scol2[9]) / 10
'''

'''
avg_precision_nea2 = list([test_sizes[2], precision_lr_scol2_avg, precision_dt_scol2_avg, precision_rf_scol2_avg, precision_nb_scol2_avg, precision_xg_scol2_avg])
avg_recall_nea2 = list([test_sizes[2], recall_lr_scol2_avg, recall_dt_scol2_avg, recall_rf_scol2_avg, recall_nb_scol2_avg, recall_xg_scol2_avg])
'''
# 4th Test Size - 20%

probs_lr_scol3 = []
f1_lr_scol3 = []
rocauc_lr_scol3 = []
recall_lr_scol3 = []
precision_lr_scol3 = []
accuracy_lr_scol3 = []

probs_dt_scol3 = []
f1_dt_scol3 = []
rocauc_dt_scol3 = []
recall_dt_scol3 = []
precision_dt_scol3 = []
accuracy_dt_scol3 = []

probs_nb_scol3 = []
f1_nb_scol3 = []
rocauc_nb_scol3 = []
recall_nb_scol3 = []
precision_nb_scol3 = []
accuracy_nb_scol3 = []

probs_xg_scol3 = []
f1_xg_scol3 = []
rocauc_xg_scol3 = []
recall_xg_scol3 = []
precision_xg_scol3 = []
accuracy_xg_scol3 = []

probs_rf_scol3 = []
f1_rf_scol3 = []
rocauc_rf_scol3 = []
recall_rf_scol3 = []
precision_rf_scol3 = []
accuracy_rf_scol3 = []

tfidf_vect3 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train3 = tfidf_vect3.fit_transform(x7.values)
tfidf_test3=tfidf_vect3.transform(x8.values)
print(tfidf_train3.shape)
print(tfidf_test3.shape)
#tfidf_train3.toarray()

x_tfidf3 = tfidf_vect3.fit_transform(df4["lemmatized"])
x_ros3, y_ros3 = ros.fit_resample(x_tfidf3, df4["label"])

# train_values3 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values3 = 1 - train_values3
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros3, y_ros3, train_size=i, stratify=y_ros3)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol3.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol3.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol3.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol3.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol3.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol3.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df4_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol3.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol3.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol3.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol3.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol3.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol3.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df4_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol3.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol3.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol3.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol3.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol3.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol3.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df4_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol3.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol3.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol3.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol3.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol3.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol3.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df4_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol3.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol3.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol3.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol3.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol3.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol3.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df4_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df4_l, ":", probs_lr_scol3)
    print("Array of F1 Scores LR-ROS:", df4_l, ":", f1_lr_scol3)
    print("Array of ROCAUC Scores LR-ROS:", df4_l, ":", rocauc_lr_scol3)
    print("Array of Recall Scores LR-ROS:", df4_l, ":", recall_lr_scol3)
    print("Array of Precision Scores LR-ROS:", df4_l, ":", precision_lr_scol3)
    print("Array of Accuracy Scores LR-ROS:", df4_l, ":", accuracy_lr_scol3)

    print("Array of Prob Scores DT-ROS:", df4_l, ":", probs_dt_scol3)
    print("Array of F1 Scores DT-ROS:", df4_l, ":", f1_dt_scol3)
    print("Array of ROCAUC Scores DT-ROS:", df4_l, ":", rocauc_dt_scol3)
    print("Array of Recall Scores DT-ROS:", df4_l, ":", recall_dt_scol3)
    print("Array of Precision Scores DT-ROS:", df4_l, ":", precision_dt_scol3)
    print("Array of Accuracy Scores DT-ROS:", df4_l, ":", accuracy_dt_scol3)

    print("Array of Prob Scores NB-ROS:", df4_l, ":", probs_nb_scol3)
    print("Array of F1 Scores NB-ROS:", df4_l, ":", f1_nb_scol3)
    print("Array of ROCAUC Scores NB-ROS:", df4_l, ":", rocauc_nb_scol3)
    print("Array of Recall Scores NB-ROS:", df4_l, ":", recall_nb_scol3)
    print("Array of Precision Scores NB-ROS:", df4_l, ":", precision_nb_scol3)
    print("Array of Accuracy Scores NB-ROS:", df4_l, ":", accuracy_nb_scol3)

    print("Array of Prob Scores XG-ROS:", df4_l, ":", probs_xg_scol3)
    print("Array of F1 Scores XG-ROS:", df4_l, ":", f1_xg_scol3)
    print("Array of ROCAUC Scores XG-ROS:", df4_l, ":", rocauc_xg_scol3)
    print("Array of Recall Scores XG-ROS:", df4_l, ":", recall_xg_scol3)
    print("Array of Precision Scores XG-ROS:", df4_l, ":", precision_xg_scol3)
    print("Array of Accuracy Scores XG-ROS:", df4_l, ":", accuracy_xg_scol3)

    print("Array of Prob Scores RF-ROS:", df4_l, ":", probs_rf_scol3)
    print("Array of F1 Scores RF-ROS:", df4_l, ":", f1_rf_scol3)
    print("Array of ROCAUC Scores RF-ROS:", df4_l, ":", rocauc_rf_scol3)
    print("Array of Recall Scores RF-ROS:", df4_l, ":", recall_rf_scol3)
    print("Array of Precision Scores RF-ROS:", df4_l, ":", precision_rf_scol3)
    print("Array of Accuracy Scores RF-ROS:", df4_l, ":", accuracy_rf_scol3)
    

year3 = [ args.group for t in range(25)]
sampling3 =['Oversampling' for t in range(25)]
technique3 = ['ROS' for t in range(25)]
classifier_names3 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num3 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num3 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num3 = [precision_lr_scol3, precision_dt_scol3, precision_nb_scol3, precision_xg_scol3, precision_rf_scol3]
recall_csv_num3 = [recall_lr_scol3, recall_dt_scol3, recall_nb_scol3, recall_xg_scol3, recall_rf_scol3]
auc_csv_num3 = [rocauc_lr_scol3, rocauc_dt_scol3, rocauc_nb_scol3, rocauc_xg_scol3, rocauc_rf_scol3]
accuracy_csv_num3 = [accuracy_lr_scol3, accuracy_dt_scol3, accuracy_nb_scol3, accuracy_xg_scol3, accuracy_rf_scol3]
import itertools
rounds = 5
p3 = itertools.cycle(classifier_names3)
o3 = itertools.cycle(test_sizes_num3)
k3 = itertools.cycle(train_sizes_num3)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv3 = [next(p3) for _ in range(rounds)] * 5
test_size_csv3 = [a for b in test_sizes_num3 for a in (b,)*5]
train_size_csv3 = [c for d in train_sizes_num3 for c in (d,)*5]
split_csv3 = ['4' for u in range(25)]
train_csv3 = ['20%' for u in range(25)]
precision_csv3 = list(chain(*precision_csv_num3))
recall_csv3 = list(chain(*recall_csv_num3))
auc_csv3 = list(chain(*auc_csv_num3))
accuracy_csv3 = list(chain(*accuracy_csv_num3))
csv_data3 = [year3, sampling3, technique3, classifier_csv3, test_size_csv3, train_size_csv3, split_csv3, train_csv3, precision_csv3, recall_csv3, auc_csv3, accuracy_csv3]
export_data3 = zip_longest(*csv_data3, fillvalue='')
filename = args.iteration
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data3)

'''
# 4th Test Size - Precision
#precision_nea31b = list([precision_lr_scol3[0], precision_dt_scol3[0], precision_rf_scol3[0], precision_nb_scol3[0], precision_xg_scol3[0]])
precision_nea31 = list([test_sizes[3], precision_xg_scol3[0], precision_rf_scol3[0], precision_dt_scol3[0], precision_lr_scol3[0], precision_nb_scol3[0]])
#precision_nea31 = list([(test_sizes[3] - test_sizes[3]), (0.0 + precision_rf_scol3[0]), (1.0 + precision_xg_scol3[0]),(2.0 + precision_dt_scol3[0]), (3.0 + precision_lr_scol3[0]), (4.0 + precision_nb_scol3[0])])
print("Iteration 1 Array:", precision_nea31)
precision_nea32 = list([test_sizes[3], precision_nb_scol3[1], precision_dt_scol3[1], precision_dt_scol3[1], precision_lr_scol3[1], precision_nb_scol3[1]])
# precision_nea32 = list([test_sizes[3], precision_nb_scol3[1], precision_dt_scol3[1], precision_dt_scol3[1],  precision_nb_scol3[1], precision_lr_scol3[1]])
#precision_nea32 = list([(test_sizes[3] - test_sizes[3]), (0.0 + precision_dt_scol3[1]), (1.0 + precision_nb_scol3[1]),(2.0 + precision_dt_scol3[1]), (3.0 + precision_nb_scol3[1]), (4.0 + precision_lr_scol3[1])])
#print("Iteration 2 Array:", precision_nea32)
precision_nea33 = list([test_sizes[3], precision_nb_scol3[2], precision_dt_scol3[2], precision_dt_scol3[2], precision_lr_scol3[2], precision_nb_scol3[2]])
precision_nea34 = list([test_sizes[3], precision_nb_scol3[3], precision_dt_scol3[3], precision_dt_scol3[3], precision_lr_scol3[3], precision_nb_scol3[3]])
precision_nea35 = list([test_sizes[3], precision_nb_scol3[4], precision_dt_scol3[4], precision_dt_scol3[4], precision_lr_scol3[4], precision_nb_scol3[4]])

precision_nea36 = list([test_sizes[3], precision_nb_scol3[5], precision_dt_scol3[5], precision_dt_scol3[5], precision_lr_scol3[5], precision_nb_scol3[5]])
precision_nea37 = list([test_sizes[3], precision_nb_scol3[6], precision_dt_scol3[6], precision_dt_scol3[6], precision_lr_scol3[6], precision_nb_scol3[6]])
precision_nea38 = list([test_sizes[3], precision_nb_scol3[7], precision_dt_scol3[7], precision_dt_scol3[7], precision_lr_scol3[7], precision_nb_scol3[7]])
precision_nea39 = list([test_sizes[3], precision_nb_scol3[8], precision_dt_scol3[8], precision_dt_scol3[8], precision_lr_scol3[8], precision_nb_scol3[8]])
precision_nea40 = list([test_sizes[3], precision_nb_scol3[9], precision_dt_scol3[9], precision_dt_scol3[9], precision_lr_scol3[9], precision_nb_scol3[9]])


# 4th Test Size - Recall
#recall_nea31b = list([recall_lr_scol3[0], recall_dt_scol3[0], recall_rf_scol3[0], recall_nb_scol3[0], recall_xg_scol3[0]])
recall_nea31 = list([test_sizes[3], recall_xg_scol3[0], recall_rf_scol3[0], recall_dt_scol3[0], recall_lr_scol3[0], recall_nb_scol3[0]])
#recall_nea31 = list([(test_sizes[3] - test_sizes[3]), (0.0 + recall_rf_scol3[0]), (1.0 + recall_xg_scol3[0]), (2.0 + recall_dt_scol3[0]), (3.0 + recall_lr_scol3[0]), (4.0 + recall_nb_scol3[0])])
print("Iteration 1 Array:", recall_nea31)
precision_nea32 = list([test_sizes[3], precision_nb_scol3[1], precision_dt_scol3[1], precision_dt_scol3[1], precision_lr_scol3[1], precision_nb_scol3[1]])
# precision_nea32 = list([test_sizes[3], precision_nb_scol3[1], precision_dt_scol3[1], precision_dt_scol3[1],  precision_nb_scol3[1], precision_lr_scol3[1]])
#precision_nea32 = list([(test_sizes[3] - test_sizes[3]), (0.0 + precision_dt_scol3[1]), (1.0 + precision_nb_scol3[1]),(2.0 + precision_dt_scol3[1]), (3.0 + precision_nb_scol3[1]), (4.0 + precision_lr_scol3[1])])
#print("Iteration 2 Array:", precision_nea32)
precision_nea33 = list([test_sizes[3], precision_nb_scol3[2], precision_dt_scol3[2], precision_dt_scol3[2], precision_lr_scol3[2], precision_nb_scol3[2]])
precision_nea34 = list([test_sizes[3], precision_nb_scol3[3], precision_dt_scol3[3], precision_dt_scol3[3], precision_lr_scol3[3], precision_nb_scol3[3]])
precision_nea35 = list([test_sizes[3], precision_nb_scol3[4], precision_dt_scol3[4], precision_dt_scol3[4], precision_lr_scol3[4], precision_nb_scol3[4]])

precision_nea36 = list([test_sizes[3], precision_nb_scol3[5], precision_dt_scol3[5], precision_dt_scol3[5], precision_lr_scol3[5], precision_nb_scol3[5]])
precision_nea37 = list([test_sizes[3], precision_nb_scol3[6], precision_dt_scol3[6], precision_dt_scol3[6], precision_lr_scol3[6], precision_nb_scol3[6]])
precision_nea38 = list([test_sizes[3], precision_nb_scol3[7], precision_dt_scol3[7], precision_dt_scol3[7], precision_lr_scol3[7], precision_nb_scol3[7]])
precision_nea39 = list([test_sizes[3], precision_nb_scol3[8], precision_dt_scol3[8], precision_dt_scol3[8], precision_lr_scol3[8], precision_nb_scol3[8]])
precision_nea40 = list([test_sizes[3], precision_nb_scol3[9], precision_dt_scol3[9], precision_dt_scol3[9], precision_lr_scol3[9], precision_nb_scol3[9]])
'''

precision_lr_scol3_avg = (precision_lr_scol3[0] + precision_lr_scol3[1] + precision_lr_scol3[2] + precision_lr_scol3[3] + precision_lr_scol3[4]) / 5
precision_dt_scol3_avg = (precision_dt_scol3[0] + precision_dt_scol3[1] + precision_dt_scol3[2] + precision_dt_scol3[3] + precision_dt_scol3[4]) / 5
precision_rf_scol3_avg = (precision_rf_scol3[0] + precision_rf_scol3[1] + precision_rf_scol3[2] + precision_rf_scol3[3] + precision_rf_scol3[4]) / 5
precision_nb_scol3_avg = (precision_nb_scol3[0] + precision_nb_scol3[1] + precision_nb_scol3[2] + precision_nb_scol3[3] + precision_nb_scol3[4]) / 5
precision_xg_scol3_avg = (precision_xg_scol3[0] + precision_xg_scol3[1] + precision_xg_scol3[2] + precision_xg_scol3[3] + precision_xg_scol3[4]) / 5

recall_lr_scol3_avg = (recall_lr_scol3[0] + recall_lr_scol3[1] + recall_lr_scol3[2] + recall_lr_scol3[3] + recall_lr_scol3[4]) / 5
recall_dt_scol3_avg = (recall_dt_scol3[0] + recall_dt_scol3[1] + recall_dt_scol3[2] + recall_dt_scol3[3] + recall_dt_scol3[4]) / 5
recall_rf_scol3_avg = (recall_rf_scol3[0] + recall_rf_scol3[1] + recall_rf_scol3[2] + recall_rf_scol3[3] + recall_rf_scol3[4]) / 5
recall_nb_scol3_avg = (recall_nb_scol3[0] + recall_nb_scol3[1] + recall_nb_scol3[2] + recall_nb_scol3[3] + recall_nb_scol3[4]) / 5
recall_xg_scol3_avg = (recall_xg_scol3[0] + recall_xg_scol3[1] + recall_xg_scol3[2] + recall_xg_scol3[3] + recall_xg_scol3[4]) / 5

'''
avg_precision_nea3 = list([test_sizes[3], precision_lr_scol3_avg, precision_dt_scol3_avg, precision_rf_scol3_avg, precision_nb_scol3_avg, precision_xg_scol3_avg])
avg_recall_nea3 = list([test_sizes[3], recall_lr_scol3_avg, recall_dt_scol3_avg, recall_rf_scol3_avg, recall_nb_scol3_avg, recall_xg_scol3_avg])
'''

# Test Size #5 - 25%
#x_tfidf = tfidf_vect.fit_transform(df5["lemmatized"])

probs_lr_scol4 = []
f1_lr_scol4 = []
rocauc_lr_scol4 = []
recall_lr_scol4 = []
precision_lr_scol4 = []
accuracy_lr_scol4 = []

probs_dt_scol4 = []
f1_dt_scol4 = []
rocauc_dt_scol4 = []
recall_dt_scol4 = []
precision_dt_scol4 = []
accuracy_dt_scol4 = []

probs_nb_scol4 = []
f1_nb_scol4 = []
rocauc_nb_scol4 = []
recall_nb_scol4 = []
precision_nb_scol4 = []
accuracy_nb_scol4 = []

probs_xg_scol4 = []
f1_xg_scol4 = []
rocauc_xg_scol4 = []
recall_xg_scol4 = []
precision_xg_scol4 = []
accuracy_xg_scol4 = []

probs_rf_scol4 = []
f1_rf_scol4 = []
rocauc_rf_scol4 = []
recall_rf_scol4 = []
precision_rf_scol4 = []
accuracy_rf_scol4 = []

tfidf_vect4 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train4 = tfidf_vect4.fit_transform(x9.values)
tfidf_test4=tfidf_vect4.transform(x10.values)
print(tfidf_train4.shape)
print(tfidf_test4.shape)
#tfidf_train4.toarray()

x_tfidf4 = tfidf_vect4.fit_transform(df5["lemmatized"])
x_ros4, y_ros4 = ros.fit_resample(x_tfidf4, df5["label"])

# train_values4 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values4 = 1 - train_values4
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros4, y_ros4, train_size=i, stratify=y_ros4)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol4.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol4.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol4.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol4.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol4.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol4.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df5_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol4.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol4.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol4.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol4.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol4.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol4.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df5_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol4.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol4.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol4.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol4.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol4.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol4.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df5_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol4.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol4.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol4.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol4.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol4.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol4.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df5_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol4.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol4.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol4.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol4.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol4.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol4.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df5_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df5_l, ":", probs_lr_scol4)
    print("Array of F1 Scores LR-ROS:", df5_l, ":", f1_lr_scol4)
    print("Array of ROCAUC Scores LR-ROS:", df5_l, ":", rocauc_lr_scol4)
    print("Array of Recall Scores LR-ROS:", df5_l, ":", recall_lr_scol4)
    print("Array of Precision Scores LR-ROS:", df5_l, ":", precision_lr_scol4)
    print("Array of Accuracy Scores LR-ROS:", df5_l, ":", accuracy_lr_scol4)

    print("Array of Prob Scores DT-ROS:", df5_l, ":", probs_dt_scol4)
    print("Array of F1 Scores DT-ROS:", df5_l, ":", f1_dt_scol4)
    print("Array of ROCAUC Scores DT-ROS:", df5_l, ":", rocauc_dt_scol4)
    print("Array of Recall Scores DT-ROS:", df5_l, ":", recall_dt_scol4)
    print("Array of Precision Scores DT-ROS:", df5_l, ":", precision_dt_scol4)
    print("Array of Accuracy Scores DT-ROS:", df5_l, ":", accuracy_dt_scol4)

    print("Array of Prob Scores NB-ROS:", df5_l, ":", probs_nb_scol4)
    print("Array of F1 Scores NB-ROS:", df5_l, ":", f1_nb_scol4)
    print("Array of ROCAUC Scores NB-ROS:", df5_l, ":", rocauc_nb_scol4)
    print("Array of Recall Scores NB-ROS:", df5_l, ":", recall_nb_scol4)
    print("Array of Precision Scores NB-ROS:", df5_l, ":", precision_nb_scol4)
    print("Array of Accuracy Scores NB-ROS:", df5_l, ":", accuracy_nb_scol4)

    print("Array of Prob Scores XG-ROS:", df5_l, ":", probs_xg_scol4)
    print("Array of F1 Scores XG-ROS:", df5_l, ":", f1_xg_scol4)
    print("Array of ROCAUC Scores XG-ROS:", df5_l, ":", rocauc_xg_scol4)
    print("Array of Recall Scores XG-ROS:", df5_l, ":", recall_xg_scol4)
    print("Array of Precision Scores XG-ROS:", df5_l, ":", precision_xg_scol4)
    print("Array of Accuracy Scores XG-ROS:", df5_l, ":", accuracy_xg_scol4)

    print("Array of Prob Scores RF-ROS:", df5_l, ":", probs_rf_scol4)
    print("Array of F1 Scores RF-ROS:", df5_l, ":", f1_rf_scol4)
    print("Array of ROCAUC Scores RF-ROS:", df5_l, ":", rocauc_rf_scol4)
    print("Array of Recall Scores RF-ROS:", df5_l, ":", recall_rf_scol4)
    print("Array of Precision Scores RF-ROS:", df5_l, ":", precision_rf_scol4)
    print("Array of Accuracy Scores RF-ROS:", df5_l, ":", accuracy_rf_scol4)


year4 = [ args.group for t in range(25)]
sampling4 =['Oversampling' for t in range(25)]
technique4 = ['ROS' for t in range(25)]
classifier_names4 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num4 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num4 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num4 = [precision_lr_scol4, precision_dt_scol4, precision_nb_scol4, precision_xg_scol4, precision_rf_scol4]
recall_csv_num4 = [recall_lr_scol4, recall_dt_scol4, recall_nb_scol4, recall_xg_scol4, recall_rf_scol4]
auc_csv_num4 = [rocauc_lr_scol4, rocauc_dt_scol4, rocauc_nb_scol4, rocauc_xg_scol4, rocauc_rf_scol4]
accuracy_csv_num4 = [accuracy_lr_scol4, accuracy_dt_scol4, accuracy_nb_scol4, accuracy_xg_scol4, accuracy_rf_scol4]
import itertools
rounds = 5
p4 = itertools.cycle(classifier_names4)
o4 = itertools.cycle(test_sizes_num4)
k4 = itertools.cycle(train_sizes_num4)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv4 = [next(p4) for _ in range(rounds)] * 5
test_size_csv4 = [a for b in test_sizes_num4 for a in (b,)*5]
train_size_csv4 = [c for d in train_sizes_num4 for c in (d,)*5]
split_csv4 = ['5' for u in range(25)]
train_csv4 = ['25%' for u in range(25)]
precision_csv4 = list(chain(*precision_csv_num4))
recall_csv4 = list(chain(*recall_csv_num4))
auc_csv4 = list(chain(*auc_csv_num4))
accuracy_csv4 = list(chain(*accuracy_csv_num4))
csv_data4 = [year4, sampling4, technique4, classifier_csv4, test_size_csv4, train_size_csv4, split_csv4, train_csv4, precision_csv4, recall_csv4, auc_csv4, accuracy_csv4]
export_data4 = zip_longest(*csv_data4, fillvalue='')
filename = args.iteration
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data4)

'''
# 5th Test Size - Precision
#precision_nea41b = list([precision_lr_scol4[0], precision_dt_scol4[0], precision_rf_scol4[0], precision_nb_scol4[0], precision_xg_scol4[0]])
precision_nea41 = list([test_sizes[4], precision_xg_scol4[0], precision_rf_scol4[0], precision_dt_scol4[0], precision_lr_scol4[0], precision_nb_scol4[0]])
#precision_nea41 = list([(test_sizes[4] - test_sizes[4]), (0.0 + precision_rf_scol4[0]), (1.0 + precision_xg_scol4[0]), (2.0 + precision_dt_scol4[0]), (3.0 + precision_lr_scol4[0]), (4.0 + precision_nb_scol4[0])])
#print("Iteration 1 Array:", precision_nea41)
# precision_nea42 = list([precision_lr_scol4[1], precision_dt_scol4[1], precision_rf_scol4[1], precision_nb_scol4[1], precision_xg_scol4[1]])
precision_nea42 = list([test_sizes[4], precision_xg_scol4[1], precision_rf_scol4[1], precision_dt_scol4[1],  precision_lr_scol4[1], precision_nb_scol4[1]])
#precision_nea42 = list([(test_sizes[4] - test_sizes[4]), (0.0 + precision_rf_scol4[1]), (1.0 + precision_xg_scol4[1]), (2.0 + precision_dt_scol4[1]), (3.0 + precision_lr_scol4[1]), (4.0 + precision_nb_scol4[1])])
#print("Iteration 2 Array:", precision_nea42)

precision_nea43 = list([test_sizes[4], precision_lr_scol4[2], precision_dt_scol4[2], precision_rf_scol4[2], precision_nb_scol4[2], precision_xg_scol4[2]])
precision_nea44 = list([test_sizes[4], precision_lr_scol4[3], precision_dt_scol4[3], precision_rf_scol4[3], precision_nb_scol4[3], precision_xg_scol4[3]])
precision_nea45 = list([test_sizes[4], precision_lr_scol4[4], precision_dt_scol4[4], precision_rf_scol4[4], precision_nb_scol4[4], precision_xg_scol4[4]])

precision_nea46 = list([test_sizes[4], precision_lr_scol4[5], precision_dt_scol4[5], precision_rf_scol4[5], precision_nb_scol4[5], precision_xg_scol4[5]])
precision_nea47 = list([test_sizes[4], precision_lr_scol4[6], precision_dt_scol4[6], precision_rf_scol4[6], precision_nb_scol4[6], precision_xg_scol4[6]])
precision_nea48 = list([test_sizes[4], precision_lr_scol4[7], precision_dt_scol4[7], precision_rf_scol4[7], precision_nb_scol4[7], precision_xg_scol4[7]])
precision_nea49 = list([test_sizes[4], precision_lr_scol4[8], precision_dt_scol4[8], precision_rf_scol4[8], precision_nb_scol4[8], precision_xg_scol4[8]])
precision_nea50 = list([test_sizes[4], precision_lr_scol4[9], precision_dt_scol4[9], precision_rf_scol4[9], precision_nb_scol4[9], precision_xg_scol4[9]])


# 5th Test Size - Recall
#recall_nea41b = list([recall_lr_scol4[0], recall_dt_scol4[0], recall_rf_scol4[0], recall_nb_scol4[0], recall_xg_scol4[0]])
recall_nea41 = list([test_sizes[4], recall_xg_scol4[0], recall_rf_scol4[0], recall_dt_scol4[0], recall_lr_scol4[0], recall_nb_scol4[0]])
#recall_nea41 = list([(test_sizes[4] - test_sizes[4]), (0.0 + recall_rf_scol4[0]), (1.0 + recall_xg_scol4[0]), (2.0 + recall_dt_scol4[0]), (3.0 + recall_lr_scol4[0]), (4.0 + recall_nb_scol4[0])])
print("Iteration 1 Array:", recall_nea41)
# recall_nea42 = list([recall_lr_scol4[1], recall_dt_scol4[1], recall_rf_scol4[1], recall_nb_scol4[1], recall_xg_scol4[1]])
recall_nea42 = list([test_sizes[4], recall_xg_scol4[1], recall_rf_scol4[1], recall_dt_scol4[1],  recall_lr_scol4[1], recall_nb_scol4[1]])
#recall_nea42 = list([(test_sizes[4] - test_sizes[4]), (0.0 + recall_rf_scol4[1]), (1.0 + recall_xg_scol4[1]),(2.0 + recall_dt_scol4[1]), (3.0 + recall_lr_scol4[1]), (4.0 + recall_nb_scol4[1])])
#print("Iteration 2 Array:", recall_nea42)

recall_nea43 = list([test_sizes[4], recall_lr_scol4[2], recall_dt_scol4[2], recall_rf_scol4[2], recall_nb_scol4[2], recall_xg_scol4[2]])
recall_nea44 = list([test_sizes[4], recall_lr_scol4[3], recall_dt_scol4[3], recall_rf_scol4[3], recall_nb_scol4[3], recall_xg_scol4[3]])
recall_nea45 = list([test_sizes[4], recall_lr_scol4[4], recall_dt_scol4[4], recall_rf_scol4[4], recall_nb_scol4[4], recall_xg_scol4[4]])

recall_nea46 = list([test_sizes[4], recall_lr_scol4[5], recall_dt_scol4[5], recall_rf_scol4[5], recall_nb_scol4[5], recall_xg_scol4[5]])
recall_nea47 = list([test_sizes[4], recall_lr_scol4[6], recall_dt_scol4[6], recall_rf_scol4[6], recall_nb_scol4[6], recall_xg_scol4[6]])
recall_nea48 = list([test_sizes[4], recall_lr_scol4[7], recall_dt_scol4[7], recall_rf_scol4[7], recall_nb_scol4[7], recall_xg_scol4[7]])
recall_nea49 = list([test_sizes[4], recall_lr_scol4[8], recall_dt_scol4[8], recall_rf_scol4[8], recall_nb_scol4[8], recall_xg_scol4[8]])
recall_nea50 = list([test_sizes[4], recall_lr_scol4[9], recall_dt_scol4[9], recall_rf_scol4[9], recall_nb_scol4[9], recall_xg_scol4[9]])
'''
'''
precision_lr_scol4_avg = (precision_lr_scol4[0] + precision_lr_scol4[1] + precision_lr_scol4[2] + precision_lr_scol4[3] + precision_lr_scol4[4] + precision_lr_scol4[5] + precision_lr_scol4[6] + precision_lr_scol4[7] + precision_lr_scol4[8] + precision_lr_scol4[9]) / 10
precision_dt_scol4_avg = (precision_dt_scol4[0] + precision_dt_scol4[1] + precision_dt_scol4[2] + precision_dt_scol4[3] + precision_dt_scol4[4] + precision_dt_scol4[5] + precision_dt_scol4[6] + precision_dt_scol4[7] + precision_dt_scol4[8] + precision_dt_scol4[9]) / 10
precision_rf_scol4_avg = (precision_rf_scol4[0] + precision_rf_scol4[1] + precision_rf_scol4[2] + precision_rf_scol4[3] + precision_rf_scol4[4] + precision_rf_scol4[5] + precision_rf_scol4[6] + precision_rf_scol4[7] + precision_rf_scol4[8] + precision_rf_scol4[9]) / 10
precision_nb_scol4_avg = (precision_nb_scol4[0] + precision_nb_scol4[1] + precision_nb_scol4[2] + precision_nb_scol4[3] + precision_nb_scol4[4] + precision_nb_scol4[5] + precision_nb_scol4[6] + precision_nb_scol4[7] + precision_nb_scol4[8] + precision_nb_scol4[9]) / 10
precision_xg_scol4_avg = (precision_xg_scol4[0] + precision_xg_scol4[1] + precision_xg_scol4[2] + precision_xg_scol4[3] + precision_xg_scol4[4] + precision_xg_scol4[5] + precision_xg_scol4[6] + precision_xg_scol4[7] + precision_xg_scol4[8] + precision_xg_scol4[9]) / 10


recall_lr_scol4_avg = (recall_lr_scol4[0] + recall_lr_scol4[1] + recall_lr_scol4[2] + recall_lr_scol4[3] + recall_lr_scol4[4] + recall_lr_scol4[5] + recall_lr_scol4[6] + recall_lr_scol4[7] + recall_lr_scol4[8] + recall_lr_scol4[9]) / 10
recall_dt_scol4_avg = (recall_dt_scol4[0] + recall_dt_scol4[1] + recall_dt_scol4[2] + recall_dt_scol4[3] + recall_dt_scol4[4] + recall_dt_scol4[5] + recall_dt_scol4[6] + recall_dt_scol4[7] + recall_dt_scol4[8] + recall_dt_scol4[9]) / 10
recall_rf_scol4_avg = (recall_rf_scol4[0] + recall_rf_scol4[1] + recall_rf_scol4[2] + recall_rf_scol4[3] + recall_rf_scol4[4] + recall_rf_scol4[5] + recall_rf_scol4[6] + recall_rf_scol4[7] + recall_rf_scol4[8] + recall_rf_scol4[9]) / 10
recall_nb_scol4_avg = (recall_nb_scol4[0] + recall_nb_scol4[1] + recall_nb_scol4[2] + recall_nb_scol4[3] + recall_nb_scol4[4] + recall_nb_scol4[5] + recall_nb_scol4[6] + recall_nb_scol4[7] + recall_nb_scol4[8] + recall_nb_scol4[9]) / 10
recall_xg_scol4_avg = (recall_xg_scol4[0] + recall_xg_scol4[1] + recall_xg_scol4[2] + recall_xg_scol4[3] + recall_xg_scol4[4] + recall_xg_scol4[5] + recall_xg_scol4[6] + recall_xg_scol4[7] + recall_xg_scol4[8] + recall_xg_scol4[9]) / 10
'''

precision_lr_scol4_avg = (precision_lr_scol4[0] + precision_lr_scol4[1] + precision_lr_scol4[2] + precision_lr_scol4[3] + precision_lr_scol4[4]) / 5
precision_dt_scol4_avg = (precision_dt_scol4[0] + precision_dt_scol4[1] + precision_dt_scol4[2] + precision_dt_scol4[3] + precision_dt_scol4[4]) / 5
precision_rf_scol4_avg = (precision_rf_scol4[0] + precision_rf_scol4[1] + precision_rf_scol4[2] + precision_rf_scol4[3] + precision_rf_scol4[4]) / 5
precision_nb_scol4_avg = (precision_nb_scol4[0] + precision_nb_scol4[1] + precision_nb_scol4[2] + precision_nb_scol4[3] + precision_nb_scol4[4]) / 5
precision_xg_scol4_avg = (precision_xg_scol4[0] + precision_xg_scol4[1] + precision_xg_scol4[2] + precision_xg_scol4[3] + precision_xg_scol4[4]) / 5


recall_lr_scol4_avg = (recall_lr_scol4[0] + recall_lr_scol4[1] + recall_lr_scol4[2] + recall_lr_scol4[3] + recall_lr_scol4[4]) / 5
recall_dt_scol4_avg = (recall_dt_scol4[0] + recall_dt_scol4[1] + recall_dt_scol4[2] + recall_dt_scol4[3] + recall_dt_scol4[4]) / 5
recall_rf_scol4_avg = (recall_rf_scol4[0] + recall_rf_scol4[1] + recall_rf_scol4[2] + recall_rf_scol4[3] + recall_rf_scol4[4]) / 5
recall_nb_scol4_avg = (recall_nb_scol4[0] + recall_nb_scol4[1] + recall_nb_scol4[2] + recall_nb_scol4[3] + recall_nb_scol4[4]) / 5
recall_xg_scol4_avg = (recall_xg_scol4[0] + recall_xg_scol4[1] + recall_xg_scol4[2] + recall_xg_scol4[3] + recall_xg_scol4[4]) / 5

'''
avg_precision_nea4 = list([test_sizes[4], precision_lr_scol4_avg, precision_dt_scol4_avg, precision_rf_scol4_avg, precision_nb_scol4_avg, precision_xg_scol4_avg])
avg_recall_nea4 = list([test_sizes[4], recall_lr_scol4_avg, recall_dt_scol4_avg, recall_rf_scol4_avg, recall_nb_scol4_avg, recall_xg_scol4_avg])
'''
# Test Size #6 - 30%

probs_lr_scol5 = []
f1_lr_scol5 = []
rocauc_lr_scol5 = []
recall_lr_scol5 = []
precision_lr_scol5 = []
accuracy_lr_scol5 = []

probs_dt_scol5 = []
f1_dt_scol5 = []
rocauc_dt_scol5 = []
recall_dt_scol5 = []
precision_dt_scol5 = []
accuracy_dt_scol5 = []

probs_nb_scol5 = []
f1_nb_scol5 = []
rocauc_nb_scol5 = []
recall_nb_scol5 = []
precision_nb_scol5 = []
accuracy_nb_scol5 = []

probs_xg_scol5 = []
f1_xg_scol5 = []
rocauc_xg_scol5 = []
recall_xg_scol5 = []
precision_xg_scol5 = []
accuracy_xg_scol5 = []

probs_rf_scol5 = []
f1_rf_scol5 = []
rocauc_rf_scol5 = []
recall_rf_scol5 = []
precision_rf_scol5 = []
accuracy_rf_scol5 = []

tfidf_vect5 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train5 = tfidf_vect5.fit_transform(x11.values)
tfidf_test5=tfidf_vect5.transform(x12.values)
print(tfidf_train5.shape)
print(tfidf_test5.shape)
#tfidf_train5.toarray()

x_tfidf5 = tfidf_vect5.fit_transform(df6["lemmatized"])
x_ros5, y_ros5 = ros.fit_resample(x_tfidf5, df6["label"])

# train_values5 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values5 = 1 - train_values5
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros5, y_ros5, train_size=i, stratify=y_ros5)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol5.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol5.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol5.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol5.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol5.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol5.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df6_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol5.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol5.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol5.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol5.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol5.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol5.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df6_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol5.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol5.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol5.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol5.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol5.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol5.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df6_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol5.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol5.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol5.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol5.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol5.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol5.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df6_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol5.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol5.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol5.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol5.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol5.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol5.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df6_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df6_l, ":", probs_lr_scol5)
    print("Array of F1 Scores LR-ROS:", df6_l, ":", f1_lr_scol5)
    print("Array of ROCAUC Scores LR-ROS:", df6_l, ":", rocauc_lr_scol5)
    print("Array of Recall Scores LR-ROS:", df6_l, ":", recall_lr_scol5)
    print("Array of Precision Scores LR-ROS:", df6_l, ":", precision_lr_scol5)
    print("Array of Accuracy Scores LR-ROS:", df6_l, ":", accuracy_lr_scol5)

    print("Array of Prob Scores DT-ROS:", df6_l, ":", probs_dt_scol5)
    print("Array of F1 Scores DT-ROS:", df6_l, ":", f1_dt_scol5)
    print("Array of ROCAUC Scores DT-ROS:", df6_l, ":", rocauc_dt_scol5)
    print("Array of Recall Scores DT-ROS:", df6_l, ":", recall_dt_scol5)
    print("Array of Precision Scores DT-ROS:", df6_l, ":", precision_dt_scol5)
    print("Array of Accuracy Scores DT-ROS:", df6_l, ":", accuracy_dt_scol5)

    print("Array of Prob Scores NB-ROS:", df6_l, ":", probs_nb_scol5)
    print("Array of F1 Scores NB-ROS:", df6_l, ":", f1_nb_scol5)
    print("Array of ROCAUC Scores NB-ROS:", df6_l, ":", rocauc_nb_scol5)
    print("Array of Recall Scores NB-ROS:", df6_l, ":", recall_nb_scol5)
    print("Array of Precision Scores NB-ROS:", df6_l, ":", precision_nb_scol5)
    print("Array of Accuracy Scores NB-ROS:", df6_l, ":", accuracy_nb_scol5)

    print("Array of Prob Scores XG-ROS:", df6_l, ":", probs_xg_scol5)
    print("Array of F1 Scores XG-ROS:", df6_l, ":", f1_xg_scol5)
    print("Array of ROCAUC Scores XG-ROS:", df6_l, ":", rocauc_xg_scol5)
    print("Array of Recall Scores XG-ROS:", df6_l, ":", recall_xg_scol5)
    print("Array of Precision Scores XG-ROS:", df6_l, ":", precision_xg_scol5)
    print("Array of Accuracy Scores XG-ROS:", df6_l, ":", accuracy_xg_scol5)

    print("Array of Prob Scores RF-ROS:", df6_l, ":", probs_rf_scol5)
    print("Array of F1 Scores RF-ROS:", df6_l, ":", f1_rf_scol5)
    print("Array of ROCAUC Scores RF-ROS:", df6_l, ":", rocauc_rf_scol5)
    print("Array of Recall Scores RF-ROS:", df6_l, ":", recall_rf_scol5)
    print("Array of Precision Scores RF-ROS:", df6_l, ":", precision_rf_scol5)
    print("Array of Accuracy Scores RF-ROS:", df6_l, ":", accuracy_rf_scol5)
    

year5 = [ args.group for t in range(25)]
sampling5 =['Oversampling' for t in range(25)]
technique5 = ['ROS' for t in range(25)]
classifier_names5 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num5 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num5 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 5]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num5 = [precision_lr_scol5, precision_dt_scol5, precision_nb_scol5, precision_xg_scol5, precision_rf_scol5]
recall_csv_num5 = [recall_lr_scol5, recall_dt_scol5, recall_nb_scol5, recall_xg_scol5, recall_rf_scol5]
auc_csv_num5 = [rocauc_lr_scol5, rocauc_dt_scol5, rocauc_nb_scol5, rocauc_xg_scol5, rocauc_rf_scol5]
accuracy_csv_num5 = [accuracy_lr_scol5, accuracy_dt_scol5, accuracy_nb_scol5, accuracy_xg_scol5, accuracy_rf_scol5]
import itertools
rounds = 5
p5 = itertools.cycle(classifier_names5)
o5 = itertools.cycle(test_sizes_num5)
k5 = itertools.cycle(train_sizes_num5)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv5 = [next(p5) for _ in range(rounds)] * 5
test_size_csv5 = [a for b in test_sizes_num5 for a in (b,)*5]
train_size_csv5 = [c for d in train_sizes_num5 for c in (d,)*5]
split_csv5 = ['6' for u in range(25)]
train_csv5 = ['30%' for u in range(25)]
precision_csv5 = list(chain(*precision_csv_num5))
recall_csv5 = list(chain(*recall_csv_num5))
auc_csv5 = list(chain(*auc_csv_num5))
accuracy_csv5 = list(chain(*accuracy_csv_num5))
csv_data5 = [year5, sampling5, technique5, classifier_csv5, test_size_csv5, train_size_csv5, split_csv5, train_csv5, precision_csv5,
            recall_csv5, auc_csv5, accuracy_csv5]
export_data5 = zip_longest(*csv_data5, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data5)

'''
# Precision - 6th test size
#precision_nea51b = list([precision_lr_scol5[0], precision_dt_scol5[0], precision_rf_scol5[0], precision_nb_scol5[0], precision_xg_scol5[0]])
precision_nea51 = list([test_sizes[5], precision_xg_scol5[0], precision_rf_scol5[0], precision_dt_scol5[0], precision_lr_scol5[0], precision_nb_scol5[0]])
#precision_nea51 = list([(test_sizes[5] - test_sizes[5]), (0.0 + precision_rf_scol5[0]), (1.0 + precision_xg_scol5[0]), (2.0 + precision_dt_scol5[0]), (3.0 + precision_lr_scol5[0]), (4.0 + precision_nb_scol5[0])])
print("Iteration 1 Array:", precision_nea51)
# precision_nea51 = list([precision_lr_scol5[1], precision_dt_scol5[1], precision_rf_scol5[1], precision_nb_scol5[1], precision_xg_scol5[1]])
precision_nea52 = list([test_sizes[5], precision_xg_scol5[1], precision_rf_scol5[1], precision_dt_scol5[1],  precision_lr_scol5[1], precision_nb_scol5[1]])
#precision_nea52 = list([(test_sizes[5] - test_sizes[5]), (0.0 + precision_rf_scol5[1]), (1.0 + precision_xg_scol5[1]),(2.0 + precision_dt_scol5[1]), (3.0 + precision_lr_scol5[1]), (4.0 + precision_nb_scol5[1])])
#print("Iteration 2 Array:", precision_nea52)
precision_nea53 = list([test_sizes[5], precision_lr_scol5[2], precision_dt_scol5[2], precision_rf_scol5[2], precision_nb_scol5[2], precision_xg_scol5[2]])
precision_nea54 = list([test_sizes[5], precision_lr_scol5[3], precision_dt_scol5[3], precision_rf_scol5[3], precision_nb_scol5[3], precision_xg_scol5[3]])
precision_nea55 = list([test_sizes[5], precision_lr_scol5[4], precision_dt_scol5[4], precision_rf_scol5[4], precision_nb_scol5[4], precision_xg_scol5[4]])

precision_nea56 = list([test_sizes[5], precision_lr_scol5[5], precision_dt_scol5[5], precision_rf_scol5[5], precision_nb_scol5[5], precision_xg_scol5[5]])
precision_nea57 = list([test_sizes[5], precision_lr_scol5[6], precision_dt_scol5[6], precision_rf_scol5[6], precision_nb_scol5[6], precision_xg_scol5[6]])
precision_nea58 = list([test_sizes[5], precision_lr_scol5[7], precision_dt_scol5[7], precision_rf_scol5[7], precision_nb_scol5[7], precision_xg_scol5[7]])
precision_nea59 = list([test_sizes[5], precision_lr_scol5[8], precision_dt_scol5[8], precision_rf_scol5[8], precision_nb_scol5[8], precision_xg_scol5[8]])
precision_nea60 = list([test_sizes[5], precision_lr_scol5[9], precision_dt_scol5[9], precision_rf_scol5[9], precision_nb_scol5[9], precision_xg_scol5[9]])


# Recall - 6th test size
#recall_nea51b = list([recall_lr_scol5[0], recall_dt_scol5[0], recall_rf_scol5[0], recall_nb_scol5[0], recall_xg_scol5[0]])
recall_nea51 = list([test_sizes[5], recall_xg_scol5[0], recall_rf_scol5[0], recall_dt_scol5[0], recall_lr_scol5[0], recall_nb_scol5[0]])
#recall_nea51 = list([(test_sizes[5] - test_sizes[5]), (0.0 + recall_rf_scol5[0]), (1.0 + recall_xg_scol5[0]),
#                        (2.0 + recall_dt_scol5[0]), (3.0 + recall_lr_scol5[0]), (4.0 + recall_nb_scol5[0])])
print("Iteration 1 Array:", recall_nea51)
# recall_nea51 = list([recall_lr_scol5[1], recall_dt_scol5[1], recall_rf_scol5[1], recall_nb_scol5[1], recall_xg_scol5[1]])
recall_nea52 = list([test_sizes[5], recall_xg_scol5[1], recall_rf_scol5[1], recall_dt_scol5[1],  recall_lr_scol5[1], recall_nb_scol5[1]])
#recall_nea52 = list([(test_sizes[5] - test_sizes[5]), (0.0 + recall_rf_scol5[1]), (1.0 + recall_xg_scol5[1]),
#                        (2.0 + recall_dt_scol5[1]), (3.0 + recall_lr_scol5[1]), (4.0 + recall_nb_scol5[1])])
print("Iteration 2 Array:", recall_nea52)

recall_nea53 = list([test_sizes[5], recall_lr_scol5[2], recall_dt_scol5[2], recall_rf_scol5[2], recall_nb_scol5[2], recall_xg_scol5[2]] )
recall_nea54 = list([test_sizes[5], recall_lr_scol5[3], recall_dt_scol5[3], recall_rf_scol5[3], recall_nb_scol5[3], recall_xg_scol5[3]] )
recall_nea55 = list([test_sizes[5], recall_lr_scol5[4], recall_dt_scol5[4], recall_rf_scol5[4], recall_nb_scol5[4], recall_xg_scol5[4]] )
recall_nea56 = list([test_sizes[5], recall_lr_scol5[5], recall_dt_scol5[5], recall_rf_scol5[5], recall_nb_scol5[5], recall_xg_scol5[5]] )
recall_nea57 = list([test_sizes[5], recall_lr_scol5[6], recall_dt_scol5[6], recall_rf_scol5[6], recall_nb_scol5[6], recall_xg_scol5[6]] )
recall_nea58 = list([test_sizes[5], recall_lr_scol5[7], recall_dt_scol5[7], recall_rf_scol5[7], recall_nb_scol5[7], recall_xg_scol5[7]] )
recall_nea59 = list([test_sizes[5], recall_lr_scol5[8], recall_dt_scol5[8], recall_rf_scol5[8], recall_nb_scol5[8], recall_xg_scol5[8]] )
recall_nea60 = list([test_sizes[5], recall_lr_scol5[9], recall_dt_scol5[9], recall_rf_scol5[9], recall_nb_scol5[9], recall_xg_scol5[9]] )
'''
'''
precision_lr_scol5_avg = (precision_lr_scol5[0] + precision_lr_scol5[1] + precision_lr_scol5[2] + precision_lr_scol5[3] + precision_lr_scol5[4] + precision_lr_scol5[5] + precision_lr_scol5[6] + precision_lr_scol5[7] + precision_lr_scol5[8] + precision_lr_scol5[9]) / 10
precision_dt_scol5_avg = (precision_dt_scol5[0] + precision_dt_scol5[1] + precision_dt_scol5[2] + precision_dt_scol5[3] + precision_dt_scol5[4] + precision_dt_scol5[5] + precision_dt_scol5[6] + precision_dt_scol5[7] + precision_dt_scol5[8] + precision_dt_scol5[9]) / 10
precision_rf_scol5_avg = (precision_rf_scol5[0] + precision_rf_scol5[1] + precision_rf_scol5[2] + precision_rf_scol5[3] + precision_rf_scol5[4] + precision_rf_scol5[5] + precision_rf_scol5[6] + precision_rf_scol5[7] + precision_rf_scol5[8] + precision_rf_scol5[9]) / 10
precision_nb_scol5_avg = (precision_nb_scol5[0] + precision_nb_scol5[1] + precision_nb_scol5[2] + precision_nb_scol5[3] + precision_nb_scol5[4] + precision_nb_scol5[5] + precision_nb_scol5[6] + precision_nb_scol5[7] + precision_nb_scol5[8] + precision_nb_scol5[9]) / 10
precision_xg_scol5_avg = (precision_xg_scol5[0] + precision_xg_scol5[1] + precision_xg_scol5[2] + precision_xg_scol5[3] + precision_xg_scol5[4] + precision_xg_scol5[5] + precision_xg_scol5[6] + precision_xg_scol5[7] + precision_xg_scol5[8] + precision_xg_scol5[9]) / 10

recall_lr_scol5_avg = (recall_lr_scol5[0] + recall_lr_scol5[1] + recall_lr_scol5[2] + recall_lr_scol5[3] + recall_lr_scol5[4] + recall_lr_scol5[5] + recall_lr_scol5[6] + recall_lr_scol5[7] + recall_lr_scol5[8] + recall_lr_scol5[9]) / 10
recall_dt_scol5_avg = (recall_dt_scol5[0] + recall_dt_scol5[1] + recall_dt_scol5[2] + recall_dt_scol5[3] + recall_dt_scol5[4] + recall_dt_scol5[5] + recall_dt_scol5[6] + recall_dt_scol5[7] + recall_dt_scol5[8] + recall_dt_scol5[9]) / 10
recall_rf_scol5_avg = (recall_rf_scol5[0] + recall_rf_scol5[1] + recall_rf_scol5[2] + recall_rf_scol5[3] + recall_rf_scol5[4] + recall_rf_scol5[5] + recall_rf_scol5[6] + recall_rf_scol5[7] + recall_rf_scol5[8] + recall_rf_scol5[9]) / 10
recall_nb_scol5_avg = (recall_nb_scol5[0] + recall_nb_scol5[1] + recall_nb_scol5[2] + recall_nb_scol5[3] + recall_nb_scol5[4] + recall_nb_scol5[5] + recall_nb_scol5[6] + recall_nb_scol5[7] + recall_nb_scol5[8] + recall_nb_scol5[9]) / 10
recall_xg_scol5_avg = (recall_xg_scol5[0] + recall_xg_scol5[1] + recall_xg_scol5[2] + recall_xg_scol5[3] + recall_xg_scol5[4] + recall_xg_scol5[5] + recall_xg_scol5[6] + recall_xg_scol5[7] + recall_xg_scol5[8] + recall_xg_scol5[9]) / 10
'''

precision_lr_scol5_avg = (precision_lr_scol5[0] + precision_lr_scol5[1] + precision_lr_scol5[2] + precision_lr_scol5[3] + precision_lr_scol5[4]) / 5
precision_dt_scol5_avg = (precision_dt_scol5[0] + precision_dt_scol5[1] + precision_dt_scol5[2] + precision_dt_scol5[3] + precision_dt_scol5[4]) / 5
precision_rf_scol5_avg = (precision_rf_scol5[0] + precision_rf_scol5[1] + precision_rf_scol5[2] + precision_rf_scol5[3] + precision_rf_scol5[4]) / 5
precision_nb_scol5_avg = (precision_nb_scol5[0] + precision_nb_scol5[1] + precision_nb_scol5[2] + precision_nb_scol5[3] + precision_nb_scol5[4]) / 5
precision_xg_scol5_avg = (precision_xg_scol5[0] + precision_xg_scol5[1] + precision_xg_scol5[2] + precision_xg_scol5[3] + precision_xg_scol5[4]) / 5

recall_lr_scol5_avg = (recall_lr_scol5[0] + recall_lr_scol5[1] + recall_lr_scol5[2] + recall_lr_scol5[3] + recall_lr_scol5[4]) / 5
recall_dt_scol5_avg = (recall_dt_scol5[0] + recall_dt_scol5[1] + recall_dt_scol5[2] + recall_dt_scol5[3] + recall_dt_scol5[4]) / 5
recall_rf_scol5_avg = (recall_rf_scol5[0] + recall_rf_scol5[1] + recall_rf_scol5[2] + recall_rf_scol5[3] + recall_rf_scol5[4]) / 5
recall_nb_scol5_avg = (recall_nb_scol5[0] + recall_nb_scol5[1] + recall_nb_scol5[2] + recall_nb_scol5[3] + recall_nb_scol5[4]) / 5
recall_xg_scol5_avg = (recall_xg_scol5[0] + recall_xg_scol5[1] + recall_xg_scol5[2] + recall_xg_scol5[3] + recall_xg_scol5[4]) / 5
'''
avg_precision_nea5 = list([test_sizes[5], precision_lr_scol5_avg, precision_dt_scol5_avg, precision_rf_scol5_avg, precision_nb_scol5_avg, precision_xg_scol5_avg])
avg_recall_nea5 = list([test_sizes[5], recall_lr_scol5_avg, recall_dt_scol5_avg, recall_rf_scol5_avg, recall_nb_scol5_avg, recall_xg_scol5_avg])
'''
# Test Size #7 - 35%


probs_lr_scol6 = []
f1_lr_scol6 = []
rocauc_lr_scol6 = []
recall_lr_scol6 = []
precision_lr_scol6 = []
accuracy_lr_scol6 = []

probs_dt_scol6 = []
f1_dt_scol6 = []
rocauc_dt_scol6 = []
recall_dt_scol6 = []
precision_dt_scol6 = []
accuracy_dt_scol6 = []

probs_nb_scol6 = []
f1_nb_scol6 = []
rocauc_nb_scol6 = []
recall_nb_scol6 = []
precision_nb_scol6 = []
accuracy_nb_scol6 = []

probs_xg_scol6 = []
f1_xg_scol6 = []
rocauc_xg_scol6 = []
recall_xg_scol6 = []
precision_xg_scol6 = []
accuracy_xg_scol6 = []

probs_rf_scol6 = []
f1_rf_scol6 = []
rocauc_rf_scol6 = []
recall_rf_scol6 = []
precision_rf_scol6 = []
accuracy_rf_scol6 = []

tfidf_vect6 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train6 = tfidf_vect6.fit_transform(x13.values)
tfidf_test6=tfidf_vect6.transform(x14.values)
print(tfidf_train6.shape)
print(tfidf_test6.shape)
#tfidf_train6.toarray()

x_tfidf6 = tfidf_vect6.fit_transform(df7["lemmatized"])
x_ros6, y_ros6 = ros.fit_resample(x_tfidf6, df7["label"])

# train_values6 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values6 = 1 - train_values6
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros6, y_ros6, train_size=i, stratify=y_ros6)



    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol6.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol6.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol6.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol6.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol6.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol6.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df7_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol6.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol6.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol6.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol6.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol6.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol6.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df7_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol6.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol6.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol6.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol6.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol6.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol6.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df7_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol6.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol6.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol6.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol6.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol6.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol6.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df7_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol6.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol6.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol6.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol6.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol6.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol6.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df7_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df7_l, ":", probs_lr_scol6)
    print("Array of F1 Scores LR-ROS:", df7_l, ":", f1_lr_scol6)
    print("Array of ROCAUC Scores LR-ROS:", df7_l, ":", rocauc_lr_scol6)
    print("Array of Recall Scores LR-ROS:", df7_l, ":", recall_lr_scol6)
    print("Array of Precision Scores LR-ROS:", df7_l, ":", precision_lr_scol6)
    print("Array of Accuracy Scores LR-ROS:", df7_l, ":", accuracy_lr_scol6)

    print("Array of Prob Scores DT-ROS:", df7_l, ":", probs_dt_scol6)
    print("Array of F1 Scores DT-ROS:", df7_l, ":", f1_dt_scol6)
    print("Array of ROCAUC Scores DT-ROS:", df7_l, ":", rocauc_dt_scol6)
    print("Array of Recall Scores DT-ROS:", df7_l, ":", recall_dt_scol6)
    print("Array of Precision Scores DT-ROS:", df7_l, ":", precision_dt_scol6)
    print("Array of Accuracy Scores DT-ROS:", df7_l, ":", accuracy_dt_scol6)

    print("Array of Prob Scores NB-ROS:", df7_l, ":", probs_nb_scol6)
    print("Array of F1 Scores NB-ROS:", df7_l, ":", f1_nb_scol6)
    print("Array of ROCAUC Scores NB-ROS:", df7_l, ":", rocauc_nb_scol6)
    print("Array of Recall Scores NB-ROS:", df7_l, ":", recall_nb_scol6)
    print("Array of Precision Scores NB-ROS:", df7_l, ":", precision_nb_scol6)
    print("Array of Accuracy Scores NB-ROS:", df7_l, ":", accuracy_nb_scol6)

    print("Array of Prob Scores XG-ROS:", df7_l, ":", probs_xg_scol6)
    print("Array of F1 Scores XG-ROS:", df7_l, ":", f1_xg_scol6)
    print("Array of ROCAUC Scores XG-ROS:", df7_l, ":", rocauc_xg_scol6)
    print("Array of Recall Scores XG-ROS:", df7_l, ":", recall_xg_scol6)
    print("Array of Precision Scores XG-ROS:", df7_l, ":", precision_xg_scol6)
    print("Array of Accuracy Scores XG-ROS:", df7_l, ":", accuracy_xg_scol6)

    print("Array of Prob Scores RF-ROS:", df7_l, ":", probs_rf_scol6)
    print("Array of F1 Scores RF-ROS:", df7_l, ":", f1_rf_scol6)
    print("Array of ROCAUC Scores RF-ROS:", df7_l, ":", rocauc_rf_scol6)
    print("Array of Recall Scores RF-ROS:", df7_l, ":", recall_rf_scol6)
    print("Array of Precision Scores RF-ROS:", df7_l, ":", precision_rf_scol6)
    print("Array of Accuracy Scores RF-ROS:", df7_l, ":", accuracy_rf_scol6)

year6 = [ args.group for t in range(25)]
sampling6 =['Oversampling' for t in range(25)]
technique6 = ['ROS' for t in range(25)]
classifier_names6 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num6 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num6 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 5]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num6 = [precision_lr_scol6, precision_dt_scol6, precision_nb_scol6, precision_xg_scol6, precision_rf_scol6]
recall_csv_num6 = [recall_lr_scol6, recall_dt_scol6, recall_nb_scol6, recall_xg_scol6, recall_rf_scol6]
auc_csv_num6 = [rocauc_lr_scol6, rocauc_dt_scol6, rocauc_nb_scol6, rocauc_xg_scol6, rocauc_rf_scol6]
accuracy_csv_num6 = [accuracy_lr_scol6, accuracy_dt_scol6, accuracy_nb_scol6, accuracy_xg_scol6, accuracy_rf_scol6]
import itertools
rounds = 5
p6 = itertools.cycle(classifier_names6)
o6 = itertools.cycle(test_sizes_num6)
k6 = itertools.cycle(train_sizes_num6)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv6 = [next(p6) for _ in range(rounds)] * 5
test_size_csv6 = [a for b in test_sizes_num6 for a in (b,)*5]
train_size_csv6 = [c for d in test_sizes_num6 for c in (d,)*5]
split_csv6 = ['7' for u in range(25)]
train_csv6 = ['35%' for u in range(25)]
precision_csv6 = list(chain(*precision_csv_num6))
recall_csv6 = list(chain(*recall_csv_num6))
auc_csv6 = list(chain(*auc_csv_num6))
accuracy_csv6 = list(chain(*accuracy_csv_num6))
csv_data6 = [year6, sampling6, technique6, classifier_csv6, test_size_csv6, train_size_csv6, split_csv6, train_csv6, precision_csv6,
            recall_csv6, auc_csv6, accuracy_csv6]
export_data6 = zip_longest(*csv_data6, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data6)

'''
# Precision - 7th test size 
#precision_nea61b = list([precision_lr_scol6[0], precision_dt_scol6[0], precision_rf_scol6[0], precision_nb_scol6[0], precision_xg_scol6[0]])
precision_nea61 = list([test_sizes[6], precision_xg_scol6[0], precision_rf_scol6[0], precision_dt_scol6[0], precision_lr_scol6[0], precision_nb_scol6[0]])
#precision_nea61 = list([(test_sizes[6] - test_sizes[6]), (0.0 + precision_rf_scol6[0]), (1.0 + precision_xg_scol6[0]), (2.0 + precision_dt_scol6[0]), (3.0 + precision_lr_scol6[0]), (4.0 + precision_nb_scol6[0])])
print("Iteration 1 Array:", precision_nea61)
# precision_nea62 = list([precision_lr_scol6[1], precision_dt_scol6[1], precision_rf_scol6[1], precision_nb_scol6[1], precision_xg_scol6[1]])
precision_nea62 = list([test_sizes[6], precision_xg_scol6[1], precision_rf_scol6[1], precision_dt_scol6[1],  precision_lr_scol6[1], precision_nb_scol6[1]])
#precision_nea62 = list([(test_sizes[6] - test_sizes[6]), (0.0 + precision_rf_scol6[1]), (1.0 + precision_xg_scol6[1]), (2.0 + precision_dt_scol6[1]), (3.0 + precision_lr_scol6[1]), (4.0 + precision_nb_scol6[1])])
print("Iteration 2 Array:", precision_nea62)

precision_nea63 = list([test_sizes[6], precision_lr_scol6[2], precision_dt_scol6[2], precision_rf_scol6[2], precision_nb_scol6[2], precision_xg_scol6[2]] )
precision_nea64 = list([test_sizes[6], precision_lr_scol6[3], precision_dt_scol6[3], precision_rf_scol6[3], precision_nb_scol6[3], precision_xg_scol6[3]] )
precision_nea65 = list([test_sizes[6], precision_lr_scol6[4], precision_dt_scol6[4], precision_rf_scol6[4], precision_nb_scol6[4], precision_xg_scol6[4]] )
precision_nea66 = list([test_sizes[6], precision_lr_scol6[5], precision_dt_scol6[5], precision_rf_scol6[5], precision_nb_scol6[5], precision_xg_scol6[5]] )
precision_nea67 = list([test_sizes[6], precision_lr_scol6[6], precision_dt_scol6[6], precision_rf_scol6[6], precision_nb_scol6[6], precision_xg_scol6[6]] )
precision_nea68 = list([test_sizes[6], precision_lr_scol6[7], precision_dt_scol6[7], precision_rf_scol6[7], precision_nb_scol6[7], precision_xg_scol6[7]] )
precision_nea69 = list([test_sizes[6], precision_lr_scol6[8], precision_dt_scol6[8], precision_rf_scol6[8], precision_nb_scol6[8], precision_xg_scol6[8]] )
precision_nea70 = list([test_sizes[6], precision_lr_scol6[9], precision_dt_scol6[9], precision_rf_scol6[9], precision_nb_scol6[9], precision_xg_scol6[9]] )


# Recall - 7th test size
#recall_nea61b = list([recall_lr_scol6[0], recall_dt_scol6[0], recall_rf_scol6[0], recall_nb_scol6[0], recall_xg_scol6[0]])
recall_nea61 = list([test_sizes[6], recall_xg_scol6[0], recall_rf_scol6[0], recall_dt_scol6[0], recall_lr_scol6[0], recall_nb_scol6[0]])
#recall_nea61 = list([(test_sizes[6] - test_sizes[6]), (0.0 + recall_rf_scol6[0]), (1.0 + recall_xg_scol6[0]),(2.0 + recall_dt_scol6[0]), (3.0 + recall_lr_scol6[0]), (4.0 + recall_nb_scol6[0])])
print("Iteration 1 Array:", recall_nea61)
# recall_nea62 = list([recall_lr_scol6[1], recall_dt_scol6[1], recall_rf_scol6[1], recall_nb_scol6[1], recall_xg_scol6[1]])
recall_nea62 = list([test_sizes[6], recall_xg_scol6[1], recall_rf_scol6[1], recall_dt_scol6[1],  recall_lr_scol6[1], recall_nb_scol6[1]])
#recall_nea62 = list([(test_sizes[6] - test_sizes[6]), (0.0 + recall_rf_scol6[1]), (1.0 + recall_xg_scol6[1]),(2.0 + recall_dt_scol6[1]), (3.0 + recall_lr_scol6[1]), (4.0 + recall_nb_scol6[1])])
#print("Iteration 2 Array:", recall_nea62)
recall_nea63 = list([test_sizes[6], recall_lr_scol6[2], recall_dt_scol6[2], recall_rf_scol6[2], recall_nb_scol6[2], recall_xg_scol6[2]] )
recall_nea64 = list([test_sizes[6], recall_lr_scol6[3], recall_dt_scol6[3], recall_rf_scol6[3], recall_nb_scol6[3], recall_xg_scol6[3]] )
recall_nea65 = list([test_sizes[6], recall_lr_scol6[4], recall_dt_scol6[4], recall_rf_scol6[4], recall_nb_scol6[4], recall_xg_scol6[4]] )
recall_nea66 = list([test_sizes[6], recall_lr_scol6[5], recall_dt_scol6[5], recall_rf_scol6[5], recall_nb_scol6[5], recall_xg_scol6[5]] )
recall_nea67 = list([test_sizes[6], recall_lr_scol6[6], recall_dt_scol6[6], recall_rf_scol6[6], recall_nb_scol6[6], recall_xg_scol6[6]] )
recall_nea68 = list([test_sizes[6], recall_lr_scol6[7], recall_dt_scol6[7], recall_rf_scol6[7], recall_nb_scol6[7], recall_xg_scol6[7]] )
recall_nea69 = list([test_sizes[6], recall_lr_scol6[8], recall_dt_scol6[8], recall_rf_scol6[8], recall_nb_scol6[8], recall_xg_scol6[8]] )
recall_nea70 = list([test_sizes[6], recall_lr_scol6[9], recall_dt_scol6[9], recall_rf_scol6[9], recall_nb_scol6[9], recall_xg_scol6[9]] )
'''
'''
precision_lr_scol6_avg = (precision_lr_scol6[0] + precision_lr_scol6[1] + precision_lr_scol6[2] + precision_lr_scol6[3] + precision_lr_scol6[4] + precision_lr_scol6[5] + precision_lr_scol6[6] + precision_lr_scol6[7] + precision_lr_scol6[8] + precision_lr_scol6[9]) / 10
precision_dt_scol6_avg = (precision_dt_scol6[0] + precision_dt_scol6[1] + precision_dt_scol6[2] + precision_dt_scol6[3] + precision_dt_scol6[4] + precision_dt_scol6[5] + precision_dt_scol6[6] + precision_dt_scol6[7] + precision_dt_scol6[8] + precision_dt_scol6[9]) / 10
precision_rf_scol6_avg = (precision_rf_scol6[0] + precision_rf_scol6[1] + precision_rf_scol6[2] + precision_rf_scol6[3] + precision_rf_scol6[4] + precision_rf_scol6[5] + precision_rf_scol6[6] + precision_rf_scol6[7] + precision_rf_scol6[8] + precision_rf_scol6[9]) / 10
precision_nb_scol6_avg = (precision_nb_scol6[0] + precision_nb_scol6[1] + precision_nb_scol6[2] + precision_nb_scol6[3] + precision_nb_scol6[4] + precision_nb_scol6[5] + precision_nb_scol6[6] + precision_nb_scol6[7] + precision_nb_scol6[8] + precision_nb_scol6[9]) / 10
precision_xg_scol6_avg = (precision_xg_scol6[0] + precision_xg_scol6[1] + precision_xg_scol6[2] + precision_xg_scol6[3] + precision_xg_scol6[4] + precision_xg_scol6[5] + precision_xg_scol6[6] + precision_xg_scol6[7] + precision_xg_scol6[8] + precision_xg_scol6[9]) / 10

recall_lr_scol6_avg = (recall_lr_scol6[0] + recall_lr_scol6[1] + recall_lr_scol6[2] + recall_lr_scol6[3] + recall_lr_scol6[4] + recall_lr_scol6[5] + recall_lr_scol6[6] + recall_lr_scol6[7] + recall_lr_scol6[8] + recall_lr_scol6[9]) / 10
recall_dt_scol6_avg = (recall_dt_scol6[0] + recall_dt_scol6[1] + recall_dt_scol6[2] + recall_dt_scol6[3] + recall_dt_scol6[4] + recall_dt_scol6[5] + recall_dt_scol6[6] + recall_dt_scol6[7] + recall_dt_scol6[8] + recall_dt_scol6[9]) / 10
recall_rf_scol6_avg = (recall_rf_scol6[0] + recall_rf_scol6[1] + recall_rf_scol6[2] + recall_rf_scol6[3] + recall_rf_scol6[4] + recall_rf_scol6[5] + recall_rf_scol6[6] + recall_rf_scol6[7] + recall_rf_scol6[8] + recall_rf_scol6[9]) / 10
recall_nb_scol6_avg = (recall_nb_scol6[0] + recall_nb_scol6[1] + recall_nb_scol6[2] + recall_nb_scol6[3] + recall_nb_scol6[4] + recall_nb_scol6[5] + recall_nb_scol6[6] + recall_nb_scol6[7] + recall_nb_scol6[8] + recall_nb_scol6[9]) / 10
recall_xg_scol6_avg = (recall_xg_scol6[0] + recall_xg_scol6[1] + recall_xg_scol6[2] + recall_xg_scol6[3] + recall_xg_scol6[4] + recall_xg_scol6[5] + recall_xg_scol6[6] + recall_xg_scol6[7] + recall_xg_scol6[8] + recall_xg_scol6[9]) / 10
'''

precision_lr_scol6_avg = (precision_lr_scol6[0] + precision_lr_scol6[1] + precision_lr_scol6[2] + precision_lr_scol6[3] + precision_lr_scol6[4]) / 5
precision_dt_scol6_avg = (precision_dt_scol6[0] + precision_dt_scol6[1] + precision_dt_scol6[2] + precision_dt_scol6[3] + precision_dt_scol6[4]) / 5
precision_rf_scol6_avg = (precision_rf_scol6[0] + precision_rf_scol6[1] + precision_rf_scol6[2] + precision_rf_scol6[3] + precision_rf_scol6[4]) / 5
precision_nb_scol6_avg = (precision_nb_scol6[0] + precision_nb_scol6[1] + precision_nb_scol6[2] + precision_nb_scol6[3] + precision_nb_scol6[4]) / 5
precision_xg_scol6_avg = (precision_xg_scol6[0] + precision_xg_scol6[1] + precision_xg_scol6[2] + precision_xg_scol6[3] + precision_xg_scol6[4]) / 5

recall_lr_scol6_avg = (recall_lr_scol6[0] + recall_lr_scol6[1] + recall_lr_scol6[2] + recall_lr_scol6[3] + recall_lr_scol6[4]) / 5
recall_dt_scol6_avg = (recall_dt_scol6[0] + recall_dt_scol6[1] + recall_dt_scol6[2] + recall_dt_scol6[3] + recall_dt_scol6[4]) / 5
recall_rf_scol6_avg = (recall_rf_scol6[0] + recall_rf_scol6[1] + recall_rf_scol6[2] + recall_rf_scol6[3] + recall_rf_scol6[4]) / 5
recall_nb_scol6_avg = (recall_nb_scol6[0] + recall_nb_scol6[1] + recall_nb_scol6[2] + recall_nb_scol6[3] + recall_nb_scol6[4]) / 5
recall_xg_scol6_avg = (recall_xg_scol6[0] + recall_xg_scol6[1] + recall_xg_scol6[2] + recall_xg_scol6[3] + recall_xg_scol6[4]) / 5

'''
avg_precision_nea6 = list([test_sizes[6], precision_lr_scol6_avg, precision_dt_scol6_avg, precision_rf_scol6_avg, precision_nb_scol6_avg, precision_xg_scol6_avg])
avg_recall_nea6 = list([test_sizes[6], recall_lr_scol6_avg, recall_dt_scol6_avg, recall_rf_scol6_avg, recall_nb_scol6_avg, recall_xg_scol6_avg])
'''
# Test Size #8 - 40%

probs_lr_scol7 = []
f1_lr_scol7 = []
rocauc_lr_scol7 = []
recall_lr_scol7 = []
precision_lr_scol7 = []
accuracy_lr_scol7 = []

probs_dt_scol7 = []
f1_dt_scol7 = []
rocauc_dt_scol7 = []
recall_dt_scol7 = []
precision_dt_scol7 = []
accuracy_dt_scol7 = []

probs_nb_scol7 = []
f1_nb_scol7 = []
rocauc_nb_scol7 = []
recall_nb_scol7 = []
precision_nb_scol7 = []
accuracy_nb_scol7 = []

probs_xg_scol7 = []
f1_xg_scol7 = []
rocauc_xg_scol7 = []
recall_xg_scol7 = []
precision_xg_scol7 = []
accuracy_xg_scol7 = []

probs_rf_scol7 = []
f1_rf_scol7 = []
rocauc_rf_scol7 = []
recall_rf_scol7 = []
precision_rf_scol7 = []
accuracy_rf_scol7 = []

tfidf_vect7 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train7 = tfidf_vect7.fit_transform(x15.values)
tfidf_test7=tfidf_vect7.transform(x16.values)
print(tfidf_train6.shape)
print(tfidf_test6.shape)
#tfidf_train7.toarray()

x_tfidf7 = tfidf_vect7.fit_transform(df8["lemmatized"])
x_ros7, y_ros7 = ros.fit_resample(x_tfidf7, df8["label"])


# train_values7 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values7 = 1 - train_values7
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros7, y_ros7, train_size=i, stratify=y_ros7)

    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol7.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol7.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol7.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol7.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol7.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol7.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df8_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol7.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol7.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol7.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol7.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol7.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol7.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df8_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol7.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol7.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol7.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol7.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol7.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol7.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df8_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol7.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol7.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol7.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol7.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol7.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol7.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df8_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol7.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol7.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol7.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol7.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol7.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol7.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df8_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df8_l, ":", probs_lr_scol7)
    print("Array of F1 Scores LR-ROS:", df8_l, ":", f1_lr_scol7)
    print("Array of ROCAUC Scores LR-ROS:", df8_l, ":", rocauc_lr_scol7)
    print("Array of Recall Scores LR-ROS:", df8_l, ":", recall_lr_scol7)
    print("Array of Precision Scores LR-ROS:", df8_l, ":", precision_lr_scol7)
    print("Array of Accuracy Scores LR-ROS:", df8_l, ":", accuracy_lr_scol7)

    print("Array of Prob Scores DT-ROS:", df8_l, ":", probs_dt_scol7)
    print("Array of F1 Scores DT-ROS:", df8_l, ":", f1_dt_scol7)
    print("Array of ROCAUC Scores DT-ROS:", df8_l, ":", rocauc_dt_scol7)
    print("Array of Recall Scores DT-ROS:", df8_l, ":", recall_dt_scol7)
    print("Array of Precision Scores DT-ROS:", df8_l, ":", precision_dt_scol7)
    print("Array of Accuracy Scores DT-ROS:", df8_l, ":", accuracy_dt_scol7)

    print("Array of Prob Scores NB-ROS:", df8_l, ":", probs_nb_scol7)
    print("Array of F1 Scores NB-ROS:", df8_l, ":", f1_nb_scol7)
    print("Array of ROCAUC Scores NB-ROS:", df8_l, ":", rocauc_nb_scol7)
    print("Array of Recall Scores NB-ROS:", df8_l, ":", recall_nb_scol7)
    print("Array of Precision Scores NB-ROS:", df8_l, ":", precision_nb_scol7)
    print("Array of Accuracy Scores NB-ROS:", df8_l, ":", accuracy_nb_scol7)

    print("Array of Prob Scores XG-ROS:", df8_l, ":", probs_xg_scol7)
    print("Array of F1 Scores XG-ROS:", df8_l, ":", f1_xg_scol7)
    print("Array of ROCAUC Scores XG-ROS:", df8_l, ":", rocauc_xg_scol7)
    print("Array of Recall Scores XG-ROS:", df8_l, ":", recall_xg_scol7)
    print("Array of Precision Scores XG-ROS:", df8_l, ":", precision_xg_scol7)
    print("Array of Accuracy Scores XG-ROS:", df8_l, ":", accuracy_xg_scol7)

    print("Array of Prob Scores RF-ROS:", df8_l, ":", probs_rf_scol7)
    print("Array of F1 Scores RF-ROS:", df8_l, ":", f1_rf_scol7)
    print("Array of ROCAUC Scores RF-ROS:", df8_l, ":", rocauc_rf_scol7)
    print("Array of Recall Scores RF-ROS:", df8_l, ":", recall_rf_scol7)
    print("Array of Precision Scores RF-ROS:", df8_l, ":", precision_rf_scol7)
    print("Array of Accuracy Scores RF-ROS:", df8_l, ":", accuracy_rf_scol7)

year7 = [ args.group for t in range(25)]
sampling7 =['Oversampling' for t in range(25)]
technique7 = ['ROS' for t in range(25)]
classifier_names7 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num7 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num7 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num7 = [precision_lr_scol7, precision_dt_scol7, precision_nb_scol7, precision_xg_scol7, precision_rf_scol7]
recall_csv_num7 = [recall_lr_scol7, recall_dt_scol7, recall_nb_scol7, recall_xg_scol7, recall_xg_scol7]
auc_csv_num7 = [rocauc_lr_scol7, rocauc_dt_scol7, rocauc_nb_scol7, rocauc_xg_scol7, rocauc_rf_scol7]
accuracy_csv_num7 = [accuracy_lr_scol7, accuracy_dt_scol7, accuracy_nb_scol7, accuracy_xg_scol7, accuracy_rf_scol7]
import itertools
rounds = 5
p7 = itertools.cycle(classifier_names7)
o7 = itertools.cycle(test_sizes_num7)
k7 = itertools.cycle(train_sizes_num7)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv7 = [next(p7) for _ in range(rounds)] * 5
test_size_csv7 = [a for b in test_sizes_num7 for a in (b,)*5]
train_size_csv7 = [c for d in train_sizes_num7 for c in (d,)*5]
split_csv7 = ['8' for u in range(25)]
train_csv7 = ['40%' for u in range(25)]
precision_csv7 = list(chain(*precision_csv_num7))
recall_csv7 = list(chain(*recall_csv_num7))
auc_csv7 = list(chain(*auc_csv_num7))
accuracy_csv7 = list(chain(*accuracy_csv_num7))
csv_data7 = [year7, sampling7, technique7, classifier_csv7, test_size_csv7, train_size_csv7, split_csv7, train_csv7, precision_csv7,
            recall_csv7, auc_csv7, accuracy_csv7]
export_data7 = zip_longest(*csv_data7, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data7)

'''
# PRecision - # 8 test size
precision_nea71b = list([precision_lr_scol7[0], precision_dt_scol7[0], precision_rf_scol7[0], precision_nb_scol7[0], precision_xg_scol7[0]])
precision_nea71 = list([test_sizes[7], precision_xg_scol7[0], precision_rf_scol7[0], precision_dt_scol7[0], precision_lr_scol7[0], precision_nb_scol7[0]])
# precision_nea71 = list([(test_sizes[7] - test_sizes[7]), (0.0 + precision_rf_scol7[0]), (1.0 + precision_xg_scol7[0]),(2.0 + precision_dt_scol7[0]), (3.0 + precision_lr_scol7[0]), (4.0 + precision_nb_scol7[0])])
print("Iteration 1 Array:", precision_nea71)
# precision_nea72 = list([precision_lr_scol7[1], precision_dt_scol7[1], precision_rf_scol7[1], precision_nb_scol7[1], precision_xg_scol7[1]])
precision_nea72 = list([test_sizes[7], precision_xg_scol7[1], precision_rf_scol7[1], precision_dt_scol7[1],  precision_lr_scol7[1], precision_nb_scol7[1]])
#precision_nea72 = list([(test_sizes[7] - test_sizes[7]), (0.0 + precision_rf_scol7[1]), (1.0 + precision_xg_scol7[1]), (2.0 + precision_dt_scol7[1]), (3.0 + precision_lr_scol7[1]), (4.0 + precision_nb_scol7[1])])
#print("Iteration 2 Array:", precision_nea62)

precision_nea73 = list([test_sizes[7], precision_lr_scol7[2], precision_dt_scol7[2], precision_rf_scol7[2], precision_nb_scol7[2], precision_xg_scol7[2]] )
precision_nea74 = list([test_sizes[7], precision_lr_scol7[3], precision_dt_scol7[3], precision_rf_scol7[3], precision_nb_scol7[3], precision_xg_scol7[3]] )
precision_nea75 = list([test_sizes[7], precision_lr_scol7[4], precision_dt_scol7[4], precision_rf_scol7[4], precision_nb_scol7[4], precision_xg_scol7[4]] )
precision_nea76 = list([test_sizes[7], precision_lr_scol7[5], precision_dt_scol7[5], precision_rf_scol7[5], precision_nb_scol7[5], precision_xg_scol7[5]] )
precision_nea77 = list([test_sizes[7], precision_lr_scol7[6], precision_dt_scol7[6], precision_rf_scol7[6], precision_nb_scol7[6], precision_xg_scol7[6]] )
precision_nea78 = list([test_sizes[7], precision_lr_scol7[7], precision_dt_scol7[7], precision_rf_scol7[7], precision_nb_scol7[7], precision_xg_scol7[7]] )
precision_nea79 = list([test_sizes[7], precision_lr_scol7[8], precision_dt_scol7[8], precision_rf_scol7[8], precision_nb_scol7[8], precision_xg_scol7[8]] )
precision_nea80 = list([test_sizes[7], precision_lr_scol7[9], precision_dt_scol7[9], precision_rf_scol7[9], precision_nb_scol7[9], precision_xg_scol7[9]] )



# Recall - #8 test size
#recall_nea71b = list([recall_lr_scol7[0], recall_dt_scol7[0], recall_rf_scol7[0], recall_nb_scol7[0], recall_xg_scol7[0]])
recall_nea71 = list([test_sizes[7], recall_xg_scol7[0], recall_rf_scol7[0], recall_dt_scol7[0], recall_lr_scol7[0], recall_nb_scol7[0]])
# recall_nea71 = list([(test_sizes[9] - test_sizes[9]), (0.0 + recall_rf_scol7[0]), (1.0 + recall_xg_scol7[0]), (2.0 + recall_dt_scol7[0]), (3.0 + recall_lr_scol7[0]), (4.0 + recall_nb_scol7[0])])
print("Iteration 1 Array:", recall_nea71)
# recall_nea72 = list([recall_lr_scol7[1], recall_dt_scol7[1], recall_rf_scol7[1], recall_nb_scol7[1], recall_xg_scol7[1]])
recall_nea72 = list([test_sizes[7], recall_xg_scol7[1], recall_rf_scol7[1], recall_dt_scol7[1],  recall_lr_scol7[1], recall_nb_scol7[1]])
#recall_nea72 = list([(test_sizes[9] - test_sizes[9]), (0.0 + recall_rf_scol7[1]), (1.0 + recall_xg_scol7[1]),(2.0 + recall_dt_scol7[1]), (3.0 + recall_lr_scol7[1]), (4.0 + recall_nb_scol7[1])])
print("Iteration 2 Array:", recall_nea72)
recall_nea73 = list([test_sizes[7], recall_lr_scol7[2], recall_dt_scol7[2], recall_rf_scol7[2], recall_nb_scol7[2], recall_xg_scol7[2]] )
recall_nea74 = list([test_sizes[7], recall_lr_scol7[3], recall_dt_scol7[3], recall_rf_scol7[3], recall_nb_scol7[3], recall_xg_scol7[3]] )
recall_nea75 = list([test_sizes[7], recall_lr_scol7[4], recall_dt_scol7[4], recall_rf_scol7[4], recall_nb_scol7[4], recall_xg_scol7[4]] )
recall_nea76 = list([test_sizes[7], recall_lr_scol7[5], recall_dt_scol7[5], recall_rf_scol7[5], recall_nb_scol7[5], recall_xg_scol7[5]] )
recall_nea87 = list([test_sizes[7], recall_lr_scol7[6], recall_dt_scol7[6], recall_rf_scol7[6], recall_nb_scol7[6], recall_xg_scol7[6]] )
recall_nea88 = list([test_sizes[7], recall_lr_scol7[7], recall_dt_scol7[7], recall_rf_scol7[7], recall_nb_scol7[7], recall_xg_scol7[7]] )
recall_nea89 = list([test_sizes[7], recall_lr_scol7[8], recall_dt_scol7[8], recall_rf_scol7[8], recall_nb_scol7[8], recall_xg_scol7[8]] )
recall_nea90 = list([test_sizes[7], recall_lr_scol7[9], recall_dt_scol7[9], recall_rf_scol7[9], recall_nb_scol7[9], recall_xg_scol7[9]] )

precision_lr_scol7_avg = (precision_lr_scol7[0] + precision_lr_scol7[1] + precision_lr_scol7[2] + precision_lr_scol7[3] + precision_lr_scol7[4] + precision_lr_scol7[5] + precision_lr_scol7[6] + precision_lr_scol7[7] + precision_lr_scol7[8] + precision_lr_scol7[9]) / 10
precision_dt_scol7_avg = (precision_dt_scol7[0] + precision_dt_scol7[1] + precision_dt_scol7[2] + precision_dt_scol7[3] + precision_dt_scol7[4] + precision_dt_scol7[5] + precision_dt_scol7[6] + precision_dt_scol7[7] + precision_dt_scol7[8] + precision_dt_scol7[9]) / 10
precision_rf_scol7_avg = (precision_rf_scol7[0] + precision_rf_scol7[1] + precision_rf_scol7[2] + precision_rf_scol7[3] + precision_rf_scol7[4] + precision_rf_scol7[5] + precision_rf_scol7[6] + precision_rf_scol7[7] + precision_rf_scol7[8] + precision_rf_scol7[9]) / 10
precision_nb_scol7_avg = (precision_nb_scol7[0] + precision_nb_scol7[1] + precision_nb_scol7[2] + precision_nb_scol7[3] + precision_nb_scol7[4] + precision_nb_scol7[5] + precision_nb_scol7[6] + precision_nb_scol7[7] + precision_nb_scol7[8] + precision_nb_scol7[9]) / 10
precision_xg_scol7_avg = (precision_xg_scol7[0] + precision_xg_scol7[1] + precision_xg_scol7[2] + precision_xg_scol7[3] + precision_xg_scol7[4] + precision_xg_scol7[5] + precision_xg_scol7[6] + precision_xg_scol7[7] + precision_xg_scol7[8] + precision_xg_scol7[9]) / 10

recall_lr_scol7_avg = (recall_lr_scol7[0] + recall_lr_scol7[1] + recall_lr_scol7[2] + recall_lr_scol7[3] + recall_lr_scol7[4] + recall_lr_scol7[5] + recall_lr_scol7[6] + recall_lr_scol7[7] + recall_lr_scol7[8] + recall_lr_scol7[9]) / 10
recall_dt_scol7_avg = (recall_dt_scol7[0] + recall_dt_scol7[1] + recall_dt_scol7[2] + recall_dt_scol7[3] + recall_dt_scol7[4] + recall_dt_scol7[5] + recall_dt_scol7[6] + recall_dt_scol7[7] + recall_dt_scol7[8] + recall_dt_scol7[9]) / 10
recall_rf_scol7_avg = (recall_rf_scol7[0] + recall_rf_scol7[1] + recall_rf_scol7[2] + recall_rf_scol7[3] + recall_rf_scol7[4] + recall_rf_scol7[5] + recall_rf_scol7[6] + recall_rf_scol7[7] + recall_rf_scol7[8] + recall_rf_scol7[9]) / 10
recall_nb_scol7_avg = (recall_nb_scol7[0] + recall_nb_scol7[1] + recall_nb_scol7[2] + recall_nb_scol7[3] + recall_nb_scol7[4] + recall_nb_scol7[5] + recall_nb_scol7[6] + recall_nb_scol7[7] + recall_nb_scol7[8] + recall_nb_scol7[9]) / 10
recall_xg_scol7_avg = (recall_xg_scol7[0] + recall_xg_scol7[1] + recall_xg_scol7[2] + recall_xg_scol7[3] + recall_xg_scol7[4] + recall_xg_scol7[5] + recall_xg_scol7[6] + recall_xg_scol7[7] + recall_xg_scol7[8] + recall_xg_scol7[9]) / 10
'''


precision_lr_scol7_avg = (precision_lr_scol7[0] + precision_lr_scol7[1] + precision_lr_scol7[2] + precision_lr_scol7[3] + precision_lr_scol7[4]) / 5
precision_dt_scol7_avg = (precision_dt_scol7[0] + precision_dt_scol7[1] + precision_dt_scol7[2] + precision_dt_scol7[3] + precision_dt_scol7[4]) / 5
precision_rf_scol7_avg = (precision_rf_scol7[0] + precision_rf_scol7[1] + precision_rf_scol7[2] + precision_rf_scol7[3] + precision_rf_scol7[4]) / 5
precision_nb_scol7_avg = (precision_nb_scol7[0] + precision_nb_scol7[1] + precision_nb_scol7[2] + precision_nb_scol7[3] + precision_nb_scol7[4]) / 5
precision_xg_scol7_avg = (precision_xg_scol7[0] + precision_xg_scol7[1] + precision_xg_scol7[2] + precision_xg_scol7[3] + precision_xg_scol7[4]) / 5

recall_lr_scol7_avg = (recall_lr_scol7[0] + recall_lr_scol7[1] + recall_lr_scol7[2] + recall_lr_scol7[3] + recall_lr_scol7[4]) / 5
recall_dt_scol7_avg = (recall_dt_scol7[0] + recall_dt_scol7[1] + recall_dt_scol7[2] + recall_dt_scol7[3] + recall_dt_scol7[4]) / 5
recall_rf_scol7_avg = (recall_rf_scol7[0] + recall_rf_scol7[1] + recall_rf_scol7[2] + recall_rf_scol7[3] + recall_rf_scol7[4]) / 5
recall_nb_scol7_avg = (recall_nb_scol7[0] + recall_nb_scol7[1] + recall_nb_scol7[2] + recall_nb_scol7[3] + recall_nb_scol7[4]) / 5
recall_xg_scol7_avg = (recall_xg_scol7[0] + recall_xg_scol7[1] + recall_xg_scol7[2] + recall_xg_scol7[3] + recall_xg_scol7[4]) / 5

'''
avg_precision_nea7 = list([test_sizes[7], precision_lr_scol7_avg, precision_dt_scol7_avg, precision_rf_scol7_avg, precision_nb_scol7_avg, precision_xg_scol7_avg])
avg_recall_nea7 = list([test_sizes[7], recall_lr_scol7_avg, recall_dt_scol7_avg, recall_rf_scol7_avg, recall_nb_scol7_avg, recall_xg_scol7_avg])
'''

# Test Size #9 - 45%
x_tfidf = tfidf_vect.fit_transform(df["lemmatized"])

probs_lr_scol8 = []
f1_lr_scol8 = []
rocauc_lr_scol8 = []
recall_lr_scol8 = []
precision_lr_scol8 = []
accuracy_lr_scol8 = []

probs_dt_scol8 = []
f1_dt_scol8 = []
rocauc_dt_scol8 = []
recall_dt_scol8 = []
precision_dt_scol8 = []
accuracy_dt_scol8 = []

probs_nb_scol8 = []
f1_nb_scol8 = []
rocauc_nb_scol8 = []
recall_nb_scol8 = []
precision_nb_scol8 = []
accuracy_nb_scol8 = []

probs_xg_scol8 = []
f1_xg_scol8 = []
rocauc_xg_scol8 = []
recall_xg_scol8 = []
precision_xg_scol8 = []
accuracy_xg_scol8 = []

probs_rf_scol8 = []
f1_rf_scol8 = []
rocauc_rf_scol8 = []
recall_rf_scol8 = []
precision_rf_scol8 = []
accuracy_rf_scol8 = []

tfidf_vect8 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train8 = tfidf_vect8.fit_transform(x17.values)
tfidf_test8=tfidf_vect8.transform(x18.values)
print(tfidf_train8.shape)
print(tfidf_test8.shape)
#tfidf_train8.toarray()

x_tfidf8 = tfidf_vect8.fit_transform(df9["lemmatized"])
x_ros8, y_ros8 = ros.fit_resample(x_tfidf8, df9["label"])

# train_values8 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values8 = 1 - train_values8
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros8, y_ros8, train_size=i, stratify=y_ros8)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol8.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol8.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol8.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol8.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol8.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol8.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df9_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol8.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol8.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol8.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol8.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol8.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol8.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df9_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol8.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol8.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol8.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol8.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol8.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol8.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df9_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol8.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol8.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol8.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol8.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol8.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol8.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df9_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol8.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol8.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol8.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol8.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol8.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol8.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df9_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df9_l, ":", probs_lr_scol8)
    print("Array of F1 Scores LR-ROS:", df9_l, ":", f1_lr_scol8)
    print("Array of ROCAUC Scores LR-ROS:", df9_l, ":", rocauc_lr_scol8)
    print("Array of Recall Scores LR-ROS:", df9_l, ":", recall_lr_scol8)
    print("Array of Precision Scores LR-ROS:", df9_l, ":", precision_lr_scol8)
    print("Array of Accuracy Scores LR-ROS:", df9_l, ":", accuracy_lr_scol8)

    print("Array of Prob Scores DT-ROS:", df9_l, ":", probs_dt_scol8)
    print("Array of F1 Scores DT-ROS:", df9_l, ":", f1_dt_scol8)
    print("Array of ROCAUC Scores DT-ROS:", df9_l, ":", rocauc_dt_scol8)
    print("Array of Recall Scores DT-ROS:", df9_l, ":", recall_dt_scol8)
    print("Array of Precision Scores DT-ROS:", df9_l, ":", precision_dt_scol8)
    print("Array of Accuracy Scores DT-ROS:", df9_l, ":", accuracy_dt_scol8)

    print("Array of Prob Scores NB-ROS:", df9_l, ":", probs_nb_scol8)
    print("Array of F1 Scores NB-ROS:", df9_l, ":", f1_nb_scol8)
    print("Array of ROCAUC Scores NB-ROS:", df9_l, ":", rocauc_nb_scol8)
    print("Array of Recall Scores NB-ROS:", df9_l, ":", recall_nb_scol8)
    print("Array of Precision Scores NB-ROS:", df9_l, ":", precision_nb_scol8)
    print("Array of Accuracy Scores NB-ROS:", df9_l, ":", accuracy_nb_scol8)

    print("Array of Prob Scores XG-ROS:", df9_l, ":", probs_xg_scol8)
    print("Array of F1 Scores XG-ROS:", df9_l, ":", f1_xg_scol8)
    print("Array of ROCAUC Scores XG-ROS:", df9_l, ":", rocauc_xg_scol8)
    print("Array of Recall Scores XG-ROS:", df9_l, ":", recall_xg_scol8)
    print("Array of Precision Scores XG-ROS:", df9_l, ":", precision_xg_scol8)
    print("Array of Accuracy Scores XG-ROS:", df9_l, ":", accuracy_xg_scol8)

    print("Array of Prob Scores RF-ROS:", df9_l, ":", probs_rf_scol8)
    print("Array of F1 Scores RF-ROS:", df9_l, ":", f1_rf_scol8)
    print("Array of ROCAUC Scores RF-ROS:", df9_l, ":", rocauc_rf_scol8)
    print("Array of Recall Scores RF-ROS:", df9_l, ":", recall_rf_scol8)
    print("Array of Precision Scores RF-ROS:", df9_l, ":", precision_rf_scol8)
    print("Array of Accuracy Scores RF-ROS:", df9_l, ":", accuracy_rf_scol8)

year8 = [ args.group for t in range(25)]
sampling8 =['Oversampling' for t in range(25)]
technique8 = ['ROS' for t in range(25)]
classifier_names8 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num8 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num8 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num8 = [precision_lr_scol8, precision_dt_scol8, precision_nb_scol8, precision_xg_scol8, precision_rf_scol8]
recall_csv_num8 = [recall_lr_scol8, recall_dt_scol8, recall_nb_scol8, recall_xg_scol8, recall_xg_scol8]
auc_csv_num8 = [rocauc_lr_scol8, rocauc_dt_scol8, rocauc_nb_scol8, rocauc_xg_scol8, rocauc_rf_scol8]
accuracy_csv_num8 = [accuracy_lr_scol8, accuracy_dt_scol8, accuracy_nb_scol8, accuracy_xg_scol8, accuracy_rf_scol8]
import itertools
rounds = 5
p8 = itertools.cycle(classifier_names8)
o8 = itertools.cycle(test_sizes_num8)
k8 = itertools.cycle(train_sizes_num8)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv8 = [next(p8) for _ in range(rounds)] * 5
test_size_csv8 = [a for b in test_sizes_num8 for a in (b,)*5]
train_size_csv8 = [c for d in train_sizes_num8 for c in (d,)*5]
split_csv8 = ['9' for u in range(25)]
train_csv8 = ['45%' for u in range(25)]
precision_csv8 = list(chain(*precision_csv_num8))
recall_csv8 = list(chain(*recall_csv_num8))
auc_csv8 = list(chain(*auc_csv_num8))
accuracy_csv8 = list(chain(*accuracy_csv_num8))
csv_data8 = [year8, sampling8, technique8, classifier_csv8, test_size_csv8, train_size_csv8, split_csv8, train_csv8, precision_csv8,
            recall_csv8, auc_csv8, accuracy_csv8]
export_data8 = zip_longest(*csv_data8, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data8)

'''
# Precision - #9 test size
#precision_nea81b = list([precision_lr_scol8[0], precision_dt_scol8[0], precision_rf_scol8[0], precision_nb_scol8[0], precision_xg_scol8[0]])
precision_nea81 = list([test_sizes[8], precision_xg_scol8[0], precision_rf_scol8[0], precision_dt_scol8[0], precision_lr_scol8[0], precision_nb_scol8[0]])
# precision_nea81 = list([(test_sizes[8] - test_sizes[8]), (0.0 + precision_rf_scol8[0]), (1.0 + precision_xg_scol8[0]), (2.0 + precision_dt_scol8[0]), (3.0 + precision_lr_scol8[0]), (4.0 + precision_nb_scol8[0])])
print("Iteration 1 Array:", precision_nea81)
# precision_nea82 = list([precision_lr_scol8[1], precision_dt_scol8[1], precision_rf_scol8[1], precision_nb_scol8[1], precision_xg_scol8[1]])
precision_nea82 = list([test_sizes[8], precision_xg_scol8[1], precision_rf_scol8[1], precision_dt_scol8[1],  precision_lr_scol8[1], precision_nb_scol8[1]])
#precision_nea82 = list([(test_sizes[8] - test_sizes[8]), (0.0 + precision_rf_scol8[1]), (1.0 + precision_xg_scol8[1]),(2.0 + precision_dt_scol8[1]), (3.0 + precision_lr_scol8[1]), (4.0 + precision_nb_scol8[1])])
print("Iteration 2 Array:", precision_nea82)

precision_nea83 = list([test_sizes[8], precision_lr_scol8[2], precision_dt_scol8[2], precision_rf_scol8[2], precision_nb_scol8[2], precision_xg_scol8[2]] )
precision_nea84 = list([test_sizes[8], precision_lr_scol8[3], precision_dt_scol8[3], precision_rf_scol8[3], precision_nb_scol8[3], precision_xg_scol8[3]] )
precision_nea85 = list([test_sizes[8], precision_lr_scol8[4], precision_dt_scol8[4], precision_rf_scol8[4], precision_nb_scol8[4], precision_xg_scol8[4]] )
precision_nea86 = list([test_sizes[8], precision_lr_scol8[5], precision_dt_scol8[5], precision_rf_scol8[5], precision_nb_scol8[5], precision_xg_scol8[5]] )
precision_nea87 = list([test_sizes[8], precision_lr_scol8[6], precision_dt_scol8[6], precision_rf_scol8[6], precision_nb_scol8[6], precision_xg_scol8[6]] )
precision_nea88 = list([test_sizes[8], precision_lr_scol8[7], precision_dt_scol8[7], precision_rf_scol8[7], precision_nb_scol8[7], precision_xg_scol8[7]] )
precision_nea89 = list([test_sizes[8], precision_lr_scol8[8], precision_dt_scol8[8], precision_rf_scol8[8], precision_nb_scol8[8], precision_xg_scol8[8]] )
precision_nea90 = list([test_sizes[8], precision_lr_scol8[9], precision_dt_scol8[9], precision_rf_scol8[9], precision_nb_scol8[9], precision_xg_scol8[9]] )


# Recall - #9 test size
#recall_nea81b = list([recall_lr_scol8[0], recall_dt_scol8[0], recall_rf_scol8[0], recall_nb_scol8[0], recall_xg_scol8[0]])
recall_nea81 = list([test_sizes[8], recall_xg_scol8[0], recall_rf_scol8[0], recall_dt_scol8[0], recall_lr_scol8[0], recall_nb_scol8[0]])
#recall_nea81 = list([(test_sizes[9] - test_sizes[9]), (0.0 + recall_rf_scol8[0]), (1.0 + recall_xg_scol8[0], (2.0 + recall_dt_scol8[0]), (3.0 + recall_lr_scol8[0]), (4.0 + recall_nb_scol8[0])])
print("Iteration 1 Array:", recall_nea81)
# recall_nea82 = list([recall_lr_scol8[1], recall_dt_scol8[1], recall_rf_scol8[1], recall_nb_scol8[1], recall_xg_scol8[1]])
recall_nea82 = list([test_sizes[8], recall_xg_scol8[1], recall_rf_scol8[1], recall_dt_scol8[1],  recall_lr_scol8[1], recall_nb_scol8[1]])
#recall_nea82 = list([(test_sizes[8] - test_sizes[8]), (0.0 + recall_rf_scol8[1]), (1.0 + recall_xg_scol8[1]),(2.0 + recall_dt_scol8[1]), (3.0 + recall_lr_scol8[1]), (4.0 + recall_nb_scol8[1])])
print("Iteration 2 Array:", recall_nea82)

recall_nea83 = list([test_sizes[8], recall_lr_scol8[2], recall_dt_scol8[2], recall_rf_scol8[2], recall_nb_scol8[2], recall_xg_scol8[2]] )
recall_nea84 = list([test_sizes[8], recall_lr_scol8[3], recall_dt_scol8[3], recall_rf_scol8[3], recall_nb_scol8[3], recall_xg_scol8[3]] )
recall_nea85 = list([test_sizes[8], recall_lr_scol8[4], recall_dt_scol8[4], recall_rf_scol8[4], recall_nb_scol8[4], recall_xg_scol8[4]] )
recall_nea86 = list([test_sizes[8], recall_lr_scol8[5], recall_dt_scol8[5], recall_rf_scol8[5], recall_nb_scol8[5], recall_xg_scol8[5]] )
recall_nea87 = list([test_sizes[8], recall_lr_scol8[6], recall_dt_scol8[6], recall_rf_scol8[6], recall_nb_scol8[6], recall_xg_scol8[6]] )
recall_nea88 = list([test_sizes[8], recall_lr_scol8[7], recall_dt_scol8[7], recall_rf_scol8[7], recall_nb_scol8[7], recall_xg_scol8[7]] )
recall_nea89 = list([test_sizes[8], recall_lr_scol8[8], recall_dt_scol8[8], recall_rf_scol8[8], recall_nb_scol8[8], recall_xg_scol8[8]] )
recall_nea90 = list([test_sizes[8], recall_lr_scol8[9], recall_dt_scol8[9], recall_rf_scol8[9], recall_nb_scol8[9], recall_xg_scol8[9]] )
'''
precision_lr_scol8_avg = (precision_lr_scol8[0] + precision_lr_scol8[1] + precision_lr_scol8[2] + precision_lr_scol8[3] + precision_lr_scol8[4]) / 5
precision_dt_scol8_avg = (precision_dt_scol8[0] + precision_dt_scol8[1] + precision_dt_scol8[2] + precision_dt_scol8[3] + precision_dt_scol8[4]) / 5
precision_rf_scol8_avg = (precision_rf_scol8[0] + precision_rf_scol8[1] + precision_rf_scol8[2] + precision_rf_scol8[3] + precision_rf_scol8[4]) / 5
precision_nb_scol8_avg = (precision_nb_scol8[0] + precision_nb_scol8[1] + precision_nb_scol8[2] + precision_nb_scol8[3] + precision_nb_scol8[4]) / 5
precision_xg_scol8_avg = (precision_xg_scol8[0] + precision_xg_scol8[1] + precision_xg_scol8[2] + precision_xg_scol8[3] + precision_xg_scol8[4]) / 5

recall_lr_scol8_avg = (recall_lr_scol8[0] + recall_lr_scol8[1] + recall_lr_scol8[2] + recall_lr_scol8[3] + recall_lr_scol8[4]) / 5
recall_dt_scol8_avg = (recall_dt_scol8[0] + recall_dt_scol8[1] + recall_dt_scol8[2] + recall_dt_scol8[3] + recall_dt_scol8[4]) / 5
recall_rf_scol8_avg = (recall_rf_scol8[0] + recall_rf_scol8[1] + recall_rf_scol8[2] + recall_rf_scol8[3] + recall_rf_scol8[4]) / 5
recall_nb_scol8_avg = (recall_nb_scol8[0] + recall_nb_scol8[1] + recall_nb_scol8[2] + recall_nb_scol8[3] + recall_nb_scol8[4]) / 5
recall_xg_scol8_avg = (recall_xg_scol8[0] + recall_xg_scol8[1] + recall_xg_scol8[2] + recall_xg_scol8[3] + recall_xg_scol8[4]) / 5

'''
avg_precision_nea8 = list([test_sizes[8], precision_lr_scol8_avg, precision_dt_scol8_avg, precision_rf_scol8_avg, precision_nb_scol8_avg, precision_xg_scol8_avg])
avg_recall_nea8 = list([test_sizes[8], recall_lr_scol8_avg, recall_dt_scol8_avg, recall_rf_scol8_avg, recall_nb_scol8_avg, recall_xg_scol8_avg])
'''

# Test Size #10 - 50%

probs_lr_scol9 = []
f1_lr_scol9 = []
rocauc_lr_scol9 = []
recall_lr_scol9 = []
precision_lr_scol9 = []
accuracy_lr_scol9 = []

probs_dt_scol9 = []
f1_dt_scol9 = []
rocauc_dt_scol9 = []
recall_dt_scol9 = []
precision_dt_scol9 = []
accuracy_dt_scol9 = []

probs_nb_scol9 = []
f1_nb_scol9 = []
rocauc_nb_scol9 = []
recall_nb_scol9 = []
precision_nb_scol9 = []
accuracy_nb_scol9 = []

probs_xg_scol9 = []
f1_xg_scol9 = []
rocauc_xg_scol9 = []
recall_xg_scol9 = []
precision_xg_scol9 = []
accuracy_xg_scol9 = []

probs_rf_scol9 = []
f1_rf_scol9 = []
rocauc_rf_scol9 = []
recall_rf_scol9 = []
precision_rf_scol9 = []
accuracy_rf_scol9 = []

tfidf_vect9 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train9 = tfidf_vect9.fit_transform(x19.values)
tfidf_test9=tfidf_vect9.transform(x20.values)
print(tfidf_train9.shape)
print(tfidf_test9.shape)
#tfidf_train9.toarray()

x_tfidf9 = tfidf_vect9.fit_transform(df10["lemmatized"])
x_ros9, y_ros9 = ros.fit_resample(x_tfidf9, df10["label"])

# train_values9 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values9 = 1 - train_values9
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros9, y_ros9, train_size=i, stratify=y_ros9)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol9.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol9.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol9.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol9.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol9.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol9.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df10_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol9.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol9.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol9.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol9.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol9.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol9.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df10_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol9.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol9.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol9.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol9.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol9.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol9.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df10_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol9.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol9.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol9.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol9.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol9.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol9.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df10_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol9.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol9.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol9.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol9.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol9.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol9.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df10_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df10_l, ":", probs_lr_scol9)
    print("Array of F1 Scores LR-ROS:", df10_l, ":", f1_lr_scol9)
    print("Array of ROCAUC Scores LR-ROS:", df10_l, ":", rocauc_lr_scol9)
    print("Array of Recall Scores LR-ROS:", df10_l, ":", recall_lr_scol9)
    print("Array of Precision Scores LR-ROS:", df10_l, ":", precision_lr_scol9)
    print("Array of Accuracy Scores LR-ROS:", df10_l, ":", accuracy_lr_scol9)

    print("Array of Prob Scores DT-ROS:", df10_l, ":", probs_dt_scol9)
    print("Array of F1 Scores DT-ROS:", df10_l, ":", f1_dt_scol9)
    print("Array of ROCAUC Scores DT-ROS:", df10_l, ":", rocauc_dt_scol9)
    print("Array of Recall Scores DT-ROS:", df10_l, ":", recall_dt_scol9)
    print("Array of Precision Scores DT-ROS:", df10_l, ":", precision_dt_scol9)
    print("Array of Accuracy Scores DT-ROS:", df10_l, ":", accuracy_dt_scol9)

    print("Array of Prob Scores NB-ROS:", df10_l, ":", probs_nb_scol9)
    print("Array of F1 Scores NB-ROS:", df10_l, ":", f1_nb_scol9)
    print("Array of ROCAUC Scores NB-ROS:", df10_l, ":", rocauc_nb_scol9)
    print("Array of Recall Scores NB-ROS:", df10_l, ":", recall_nb_scol9)
    print("Array of Precision Scores NB-ROS:", df10_l, ":", precision_nb_scol9)
    print("Array of Accuracy Scores NB-ROS:", df10_l, ":", accuracy_nb_scol9)

    print("Array of Prob Scores XG-ROS:", df10_l, ":", probs_xg_scol9)
    print("Array of F1 Scores XG-ROS:", df10_l, ":", f1_xg_scol9)
    print("Array of ROCAUC Scores XG-ROS:", df10_l, ":", rocauc_xg_scol9)
    print("Array of Recall Scores XG-ROS:", df10_l, ":", recall_xg_scol9)
    print("Array of Precision Scores XG-ROS:", df10_l, ":", precision_xg_scol9)
    print("Array of Accuracy Scores XG-ROS:", df10_l, ":", accuracy_xg_scol9)

    print("Array of Prob Scores RF-ROS:", df10_l, ":", probs_rf_scol9)
    print("Array of F1 Scores RF-ROS:", df10_l, ":", f1_rf_scol9)
    print("Array of ROCAUC Scores RF-ROS:", df10_l, ":", rocauc_rf_scol9)
    print("Array of Recall Scores RF-ROS:", df10_l, ":", recall_rf_scol9)
    print("Array of Precision Scores RF-ROS:", df10_l, ":", precision_rf_scol9)
    print("Array of Accuracy Scores RF-ROS:", df10_l, ":", accuracy_rf_scol9)

year9 = [ args.group for t in range(25)]
sampling9 =['Oversampling' for t in range(25)]
technique9 = ['ROS' for t in range(25)]
classifier_names9 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num9 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num9 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num9 = [precision_lr_scol9, precision_dt_scol9, precision_nb_scol9, precision_xg_scol9, precision_rf_scol9]
recall_csv_num9 = [recall_lr_scol9, recall_dt_scol9, recall_nb_scol9, recall_xg_scol9, recall_xg_scol9]
auc_csv_num9 = [rocauc_lr_scol9, rocauc_dt_scol9, rocauc_nb_scol9, rocauc_xg_scol9, rocauc_rf_scol9]
accuracy_csv_num9 = [accuracy_lr_scol9, accuracy_dt_scol9, accuracy_nb_scol9, accuracy_xg_scol9, accuracy_rf_scol9]
import itertools
rounds = 5
p9 = itertools.cycle(classifier_names9)
o9 = itertools.cycle(test_sizes_num9)
k9 = itertools.cycle(train_sizes_num9)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv9 = [next(p9) for _ in range(rounds)] * 5
test_size_csv9 = [a for b in test_sizes_num9 for a in (b,)*5]
train_size_csv9 = [c for d in train_sizes_num9 for c in (d,)*5]
split_csv9 = ['10' for u in range(25)]
train_csv9 = ['50%' for u in range(25)]
precision_csv9 = list(chain(*precision_csv_num9))
recall_csv9 = list(chain(*recall_csv_num9))
auc_csv9 = list(chain(*auc_csv_num9))
accuracy_csv9 = list(chain(*accuracy_csv_num9))
csv_data9 = [year9, sampling9, technique9, classifier_csv9, test_size_csv9, train_size_csv9, split_csv9, train_csv9, precision_csv9,
            recall_csv9, auc_csv9, accuracy_csv9]
export_data9 = zip_longest(*csv_data9, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data9)

'''
# Preicsion - #10 test size
#precision_nea91b = list([precision_lr_scol9[0], precision_dt_scol9[0], precision_rf_scol9[0], precision_nb_scol9[0], precision_xg_scol9[0]])
precision_nea91 = list([test_sizes[9], precision_xg_scol9[0], precision_rf_scol9[0], precision_dt_scol9[0], precision_lr_scol9[0], precision_nb_scol9[0]])
#precision_nea91 = list([(test_sizes[9] - test_sizes[9]), (0.0 + precision_rf_scol9[0]), (1.0 + precision_xg_scol9[0]),(2.0 + precision_dt_scol9[0]), (3.0 + precision_lr_scol9[0]), (4.0 + precision_nb_scol9[0])])
print("Iteration 1 Array:", precision_nea91)
# precision_nea92 = list([precision_lr_scol9[1], precision_dt_scol9[1], precision_rf_scol9[1], precision_nb_scol9[1], precision_xg_scol9[1]])
precision_nea92 = list([test_sizes[9], precision_xg_scol9[1], precision_rf_scol9[1], precision_dt_scol9[1],  precision_lr_scol9[1], precision_nb_scol9[1]])
#precision_nea92 = list([(test_sizes[9] - test_sizes[9]), (0.0 + precision_rf_scol9[1]), (1.0 + precision_xg_scol9[1]),(2.0 + precision_dt_scol9[1]), (3.0 + precision_lr_scol9[1]), (4.0 + precision_nb_scol9[1])])
print("Iteration 2 Array:", precision_nea92)
precision_nea93 = list([test_sizes[9], precision_lr_scol9[2], precision_dt_scol9[2], precision_rf_scol9[2], precision_nb_scol9[2], precision_xg_scol9[2]] )
precision_nea94 = list([test_sizes[9], precision_lr_scol9[3], precision_dt_scol9[3], precision_rf_scol9[3], precision_nb_scol9[3], precision_xg_scol9[3]] )
precision_nea95 = list([test_sizes[9], precision_lr_scol9[4], precision_dt_scol9[4], precision_rf_scol9[4], precision_nb_scol9[4], precision_xg_scol9[4]] )
precision_nea96 = list([test_sizes[9], precision_lr_scol9[5], precision_dt_scol9[5], precision_rf_scol9[5], precision_nb_scol9[5], precision_xg_scol9[5]] )
precision_nea97 = list([test_sizes[9], precision_lr_scol9[6], precision_dt_scol9[6], precision_rf_scol9[6], precision_nb_scol9[6], precision_xg_scol9[6]] )
precision_nea98 = list([test_sizes[9], precision_lr_scol9[7], precision_dt_scol9[7], precision_rf_scol9[7], precision_nb_scol9[7], precision_xg_scol9[7]] )
precision_nea99 = list([test_sizes[9], precision_lr_scol9[8], precision_dt_scol9[8], precision_rf_scol9[8], precision_nb_scol9[8], precision_xg_scol9[8]] )
precision_nea100 = list([test_sizes[9], precision_lr_scol9[9], precision_dt_scol9[9], precision_rf_scol9[9], precision_nb_scol9[9], precision_xg_scol9[9]] )

# Recall - 10 test size
#recall_nea91b = list([recall_lr_scol9[0], recall_dt_scol9[0], recall_rf_scol9[0], recall_nb_scol9[0], recall_xg_scol9[0]])
recall_nea91 = list([test_sizes[9], recall_xg_scol9[0], recall_rf_scol9[0], recall_dt_scol9[0], recall_lr_scol9[0], recall_nb_scol9[0]])
# recall_nea91 = list([(test_sizes[9] - test_sizes[9]), (0.0 + recall_rf_scol9[0]), (1.0 + recall_xg_scol9[0]),(2.0 + recall_dt_scol9[0]), (3.0 + recall_lr_scol9[0]), (4.0 + recall_nb_scol9[0])])
print("Iteration 1 Array:", recall_nea91)
# recall_nea92 = list([recall_lr_scol9[1], recall_dt_scol9[1], recall_rf_scol9[1], recall_nb_scol9[1], recall_xg_scol9[1]])
recall_nea92 = list([test_sizes[9], recall_xg_scol9[1], recall_rf_scol9[1], recall_dt_scol9[1],  recall_lr_scol9[1], recall_nb_scol9[1]])
#recall_nea92 = list([(test_sizes[9] - test_sizes[9]), (0.0 + recall_rf_scol9[1]), (1.0 + recall_xg_scol9[1]),(2.0 + recall_dt_scol9[1]), (3.0 + recall_lr_scol9[1]), (4.0 + recall_nb_scol9[1])])
print("Iteration 2 Array:", recall_nea92)

recall_nea93 = list([test_sizes[9], recall_lr_scol9[2], recall_dt_scol9[2], recall_rf_scol9[2], recall_nb_scol9[2], recall_xg_scol9[2]] )
recall_nea94 = list([test_sizes[9], recall_lr_scol9[3], recall_dt_scol9[3], recall_rf_scol9[3], recall_nb_scol9[3], recall_xg_scol9[3]] )
recall_nea95 = list([test_sizes[9], recall_lr_scol9[4], recall_dt_scol9[4], recall_rf_scol9[4], recall_nb_scol9[4], recall_xg_scol9[4]] )
recall_nea96 = list([test_sizes[9], recall_lr_scol9[5], recall_dt_scol9[5], recall_rf_scol9[5], recall_nb_scol9[5], recall_xg_scol9[5]] )
recall_nea97 = list([test_sizes[9], recall_lr_scol9[6], recall_dt_scol9[6], recall_rf_scol9[6], recall_nb_scol9[6], recall_xg_scol9[6]] )
recall_nea98 = list([test_sizes[9], recall_lr_scol9[7], recall_dt_scol9[7], recall_rf_scol9[7], recall_nb_scol9[7], recall_xg_scol9[7]] )
recall_nea99 = list([test_sizes[9], recall_lr_scol9[8], recall_dt_scol9[8], recall_rf_scol9[8], recall_nb_scol9[8], recall_xg_scol9[8]] )
recall_nea100 = list([test_sizes[9], recall_lr_scol9[9], recall_dt_scol9[9], recall_rf_scol9[9], recall_nb_scol9[9], recall_xg_scol9[9]] )


precision_lr_scol9_avg = (precision_lr_scol9[0] + precision_lr_scol9[1] + precision_lr_scol9[2] + precision_lr_scol9[3] + precision_lr_scol9[4] + precision_lr_scol9[5] + precision_lr_scol9[6] + precision_lr_scol9[7] + precision_lr_scol9[8] + precision_lr_scol9[9]) / 10
precision_dt_scol9_avg = (precision_dt_scol9[0] + precision_dt_scol9[1] + precision_dt_scol9[2] + precision_dt_scol9[3] + precision_dt_scol9[4] + precision_dt_scol9[5] + precision_dt_scol9[6] + precision_dt_scol9[7] + precision_dt_scol9[8] + precision_dt_scol9[9]) / 10
precision_rf_scol9_avg = (precision_rf_scol9[0] + precision_rf_scol9[1] + precision_rf_scol9[2] + precision_rf_scol9[3] + precision_rf_scol9[4] + precision_rf_scol9[5] + precision_rf_scol9[6] + precision_rf_scol9[7] + precision_rf_scol9[8] + precision_rf_scol9[9]) / 10
precision_nb_scol9_avg = (precision_nb_scol9[0] + precision_nb_scol9[1] + precision_nb_scol9[2] + precision_nb_scol9[3] + precision_nb_scol9[4] + precision_nb_scol9[5] + precision_nb_scol9[6] + precision_nb_scol9[7] + precision_nb_scol9[8] + precision_nb_scol9[9]) / 10
precision_xg_scol9_avg = (precision_xg_scol9[0] + precision_xg_scol9[1] + precision_xg_scol9[2] + precision_xg_scol9[3] + precision_xg_scol9[4] + precision_xg_scol9[5] + precision_xg_scol9[6] + precision_xg_scol9[7] + precision_xg_scol9[8] + precision_xg_scol9[9]) / 10

recall_lr_scol9_avg = (recall_lr_scol9[0] + recall_lr_scol9[1] + recall_lr_scol9[2] + recall_lr_scol9[3] + recall_lr_scol9[4] + recall_lr_scol9[5] + recall_lr_scol9[6] + recall_lr_scol9[7] + recall_lr_scol9[8] + recall_lr_scol9[9]) / 10
recall_dt_scol9_avg = (recall_dt_scol9[0] + recall_dt_scol9[1] + recall_dt_scol9[2] + recall_dt_scol9[3] + recall_dt_scol9[4] + recall_dt_scol9[5] + recall_dt_scol9[6] + recall_dt_scol9[7] + recall_dt_scol9[8] + recall_dt_scol9[9]) / 10
recall_rf_scol9_avg = (recall_rf_scol9[0] + recall_rf_scol9[1] + recall_rf_scol9[2] + recall_rf_scol9[3] + recall_rf_scol9[4] + recall_rf_scol9[5] + recall_rf_scol9[6] + recall_rf_scol9[7] + recall_rf_scol9[8] + recall_rf_scol9[9]) / 10
recall_nb_scol9_avg = (recall_nb_scol9[0] + recall_nb_scol9[1] + recall_nb_scol9[2] + recall_nb_scol9[3] + recall_nb_scol9[4] + recall_nb_scol9[5] + recall_nb_scol9[6] + recall_nb_scol9[7] + recall_nb_scol9[8] + recall_nb_scol9[9]) / 10
recall_xg_scol9_avg = (recall_xg_scol9[0] + recall_xg_scol9[1] + recall_xg_scol9[2] + recall_xg_scol9[3] + recall_xg_scol9[4] + recall_xg_scol9[5] + recall_xg_scol9[6] + recall_xg_scol9[7] + recall_xg_scol9[8] + recall_xg_scol9[9]) / 10
'''

precision_lr_scol9_avg = (precision_lr_scol9[0] + precision_lr_scol9[1] + precision_lr_scol9[2] + precision_lr_scol9[3] + precision_lr_scol9[4]) / 5
precision_dt_scol9_avg = (precision_dt_scol9[0] + precision_dt_scol9[1] + precision_dt_scol9[2] + precision_dt_scol9[3] + precision_dt_scol9[4]) / 5
precision_rf_scol9_avg = (precision_rf_scol9[0] + precision_rf_scol9[1] + precision_rf_scol9[2] + precision_rf_scol9[3] + precision_rf_scol9[4]) / 5
precision_nb_scol9_avg = (precision_nb_scol9[0] + precision_nb_scol9[1] + precision_nb_scol9[2] + precision_nb_scol9[3] + precision_nb_scol9[4]) / 5
precision_xg_scol9_avg = (precision_xg_scol9[0] + precision_xg_scol9[1] + precision_xg_scol9[2] + precision_xg_scol9[3] + precision_xg_scol9[4]) / 5

recall_lr_scol9_avg = (recall_lr_scol9[0] + recall_lr_scol9[1] + recall_lr_scol9[2] + recall_lr_scol9[3] + recall_lr_scol9[4]) / 5
recall_dt_scol9_avg = (recall_dt_scol9[0] + recall_dt_scol9[1] + recall_dt_scol9[2] + recall_dt_scol9[3] + recall_dt_scol9[4]) / 5
recall_rf_scol9_avg = (recall_rf_scol9[0] + recall_rf_scol9[1] + recall_rf_scol9[2] + recall_rf_scol9[3] + recall_rf_scol9[4]) / 5
recall_nb_scol9_avg = (recall_nb_scol9[0] + recall_nb_scol9[1] + recall_nb_scol9[2] + recall_nb_scol9[3] + recall_nb_scol9[4]) / 5
recall_xg_scol9_avg = (recall_xg_scol9[0] + recall_xg_scol9[1] + recall_xg_scol9[2] + recall_xg_scol9[3] + recall_xg_scol9[4]) / 5

'''
avg_precision_nea9 = list([test_sizes[9], precision_lr_scol9_avg, precision_dt_scol9_avg, precision_rf_scol9_avg, precision_nb_scol9_avg, precision_xg_scol9_avg])
avg_recall_nea9 = list([test_sizes[9], recall_lr_scol9_avg, recall_dt_scol9_avg, recall_rf_scol9_avg, recall_nb_scol9_avg, recall_xg_scol9_avg])
'''

# Test Size #11 - 55%

probs_lr_scol10 = []
f1_lr_scol10 = []
rocauc_lr_scol10 = []
recall_lr_scol10 = []
precision_lr_scol10 = []
accuracy_lr_scol10 = []

probs_dt_scol10 = []
f1_dt_scol10 = []
rocauc_dt_scol10 = []
recall_dt_scol10 = []
precision_dt_scol10 = []
accuracy_dt_scol10 = []

probs_nb_scol10 = []
f1_nb_scol10 = []
rocauc_nb_scol10 = []
recall_nb_scol10 = []
precision_nb_scol10 = []
accuracy_nb_scol10 = []

probs_xg_scol10 = []
f1_xg_scol10 = []
rocauc_xg_scol10 = []
recall_xg_scol10 = []
precision_xg_scol10 = []
accuracy_xg_scol10 = []

probs_rf_scol10 = []
f1_rf_scol10 = []
rocauc_rf_scol10 = []
recall_rf_scol10 = []
precision_rf_scol10 = []
accuracy_rf_scol10 = []

tfidf_vect10 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train10 = tfidf_vect10.fit_transform(x21.values)
tfidf_test10=tfidf_vect10.transform(x22.values)
print(tfidf_train10.shape)
print(tfidf_test10.shape)
#tfidf_train10.toarray()

x_tfidf10 = tfidf_vect10.fit_transform(df11["lemmatized"])
x_ros10, y_ros10 = ros.fit_resample(x_tfidf10, df11["label"])

# train_values10 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values10 = 1 - train_values10
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros10, y_ros10, train_size=i, stratify=y_ros10)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol10.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol10.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol10.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol10.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol10.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol10.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df11_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol10.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol10.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol10.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol10.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol10.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol10.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df11_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol10.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol10.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol10.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol10.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol10.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol10.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df11_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol10.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol10.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol10.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol10.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol10.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol10.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df11_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol10.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol10.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol10.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol10.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol10.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol10.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df11_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df11_l, ":", probs_lr_scol10)
    print("Array of F1 Scores LR-ROS:", df11_l, ":", f1_lr_scol10)
    print("Array of ROCAUC Scores LR-ROS:", df11_l, ":", rocauc_lr_scol10)
    print("Array of Recall Scores LR-ROS:", df11_l, ":", recall_lr_scol10)
    print("Array of Precision Scores LR-ROS:", df11_l, ":", precision_lr_scol10)
    print("Array of Accuracy Scores LR-ROS:", df11_l, ":", accuracy_lr_scol10)

    print("Array of Prob Scores DT-ROS:", df11_l, ":", probs_dt_scol10)
    print("Array of F1 Scores DT-ROS:", df11_l, ":", f1_dt_scol10)
    print("Array of ROCAUC Scores DT-ROS:", df11_l, ":", rocauc_dt_scol10)
    print("Array of Recall Scores DT-ROS:", df11_l, ":", recall_dt_scol10)
    print("Array of Precision Scores DT-ROS:", df11_l, ":", precision_dt_scol10)
    print("Array of Accuracy Scores DT-ROS:", df11_l, ":", accuracy_dt_scol10)

    print("Array of Prob Scores NB-ROS:", df11_l, ":", probs_nb_scol10)
    print("Array of F1 Scores NB-ROS:", df11_l, ":", f1_nb_scol10)
    print("Array of ROCAUC Scores NB-ROS:", df11_l, ":", rocauc_nb_scol10)
    print("Array of Recall Scores NB-ROS:", df11_l, ":", recall_nb_scol10)
    print("Array of Precision Scores NB-ROS:", df11_l, ":", precision_nb_scol10)
    print("Array of Accuracy Scores NB-ROS:", df11_l, ":", accuracy_nb_scol10)

    print("Array of Prob Scores XG-ROS:", df11_l, ":", probs_xg_scol10)
    print("Array of F1 Scores XG-ROS:", df11_l, ":", f1_xg_scol10)
    print("Array of ROCAUC Scores XG-ROS:", df11_l, ":", rocauc_xg_scol10)
    print("Array of Recall Scores XG-ROS:", df11_l, ":", recall_xg_scol10)
    print("Array of Precision Scores XG-ROS:", df11_l, ":", precision_xg_scol10)
    print("Array of Accuracy Scores XG-ROS:", df11_l, ":", accuracy_xg_scol10)

    print("Array of Prob Scores RF-ROS:", df11_l, ":", probs_rf_scol10)
    print("Array of F1 Scores RF-ROS:", df11_l, ":", f1_rf_scol10)
    print("Array of ROCAUC Scores RF-ROS:", df11_l, ":", rocauc_rf_scol10)
    print("Array of Recall Scores RF-ROS:", df11_l, ":", recall_rf_scol10)
    print("Array of Precision Scores RF-ROS:", df11_l, ":", precision_rf_scol10)
    print("Array of Accuracy Scores RF-ROS:", df11_l, ":", accuracy_rf_scol10)
    

year10 = [ args.group for t in range(25)]
sampling10 =['Oversampling' for t in range(25)]
technique10 = ['ROS' for t in range(25)]
classifier_names10 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num10 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num10 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num10 = [precision_lr_scol10, precision_dt_scol10, precision_nb_scol10, precision_xg_scol10, precision_rf_scol10]
recall_csv_num10 = [recall_lr_scol10, recall_dt_scol10, recall_nb_scol10, recall_xg_scol10, recall_xg_scol10]
auc_csv_num10 = [rocauc_lr_scol10, rocauc_dt_scol10, rocauc_nb_scol10, rocauc_xg_scol10, rocauc_rf_scol10]
accuracy_csv_num10 = [accuracy_lr_scol10, accuracy_dt_scol10, accuracy_nb_scol10, accuracy_xg_scol10, accuracy_rf_scol10]
import itertools
rounds = 5
p10 = itertools.cycle(classifier_names10)
o10 = itertools.cycle(test_sizes_num10)
k10 = itertools.cycle(train_sizes_num10)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv10 = [next(p10) for _ in range(rounds)] * 5
test_size_csv10 = [a for b in test_sizes_num10 for a in (b,)*5]
train_size_csv10 = [c for d in train_sizes_num10 for c in (d,)*5]
split_csv10 = ['11' for u in range(25)]
train_csv10 = ['55%' for u in range(25)]
precision_csv10 = list(chain(*precision_csv_num10))
recall_csv10 = list(chain(*recall_csv_num10))
auc_csv10 = list(chain(*auc_csv_num10))
accuracy_csv10 = list(chain(*accuracy_csv_num10))
csv_data10 = [year10, sampling10, technique10, classifier_csv10, test_size_csv10, train_size_csv10, split_csv10, train_csv10, precision_csv10,
            recall_csv10, auc_csv10, accuracy_csv10]
export_data10 = zip_longest(*csv_data10, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data10)

'''
# Preicsion - #11 test size
#precision_nea101b = list([precision_lr_scol20[0], precision_dt_scol20[0], precision_rf_scol20[0], precision_nb_scol20[0], precision_xg_scol20[0]])
precision_nea101 = list([test_sizes[10], precision_xg_scol20[0], precision_rf_scol20[0], precision_dt_scol20[0], precision_lr_scol20[0], precision_nb_scol20[0]])
#precision_nea101 = list([(test_sizes[10] - test_sizes[10]), (0.0 + precision_rf_scol20[0]), (1.0 + precision_xg_scol20[0]),(2.0 + precision_dt_scol20[0]), (3.0 + precision_lr_scol20[0]), (4.0 + precision_nb_scol20[0])])
print("Iteration 1 Array:", precision_nea101)
# precision_nea102 = list([precision_lr_scol20[1], precision_dt_scol20[1], precision_rf_scol20[1], precision_nb_scol20[1], precision_xg_scol20[1]])
precision_nea102 = list([test_sizes[10], precision_xg_scol20[1], precision_rf_scol20[1], precision_dt_scol20[1],  precision_lr_scol20[1], precision_nb_scol20[1]])
#precision_nea102 = list([(test_sizes[10] - test_sizes[10]), (0.0 + precision_rf_scol20[1]), (1.0 + precision_xg_scol20[1]),(2.0 + precision_dt_scol20[1]), (3.0 + precision_lr_scol20[1]), (4.0 + precision_nb_scol20[1])])
print("Iteration 2 Array:", precision_nea102)
precision_nea103 = list([test_sizes[10], precision_lr_scol20[2], precision_dt_scol20[2], precision_rf_scol20[2], precision_nb_scol20[2], precision_xg_scol20[2]] )
precision_nea104 = list([test_sizes[10], precision_lr_scol20[3], precision_dt_scol20[3], precision_rf_scol20[3], precision_nb_scol20[3], precision_xg_scol20[3]] )
precision_nea105 = list([test_sizes[10], precision_lr_scol20[4], precision_dt_scol20[4], precision_rf_scol20[4], precision_nb_scol20[4], precision_xg_scol20[4]] )
precision_nea106 = list([test_sizes[10], precision_lr_scol20[5], precision_dt_scol20[5], precision_rf_scol20[5], precision_nb_scol20[5], precision_xg_scol20[5]] )
precision_nea107 = list([test_sizes[10], precision_lr_scol20[6], precision_dt_scol20[6], precision_rf_scol20[6], precision_nb_scol20[6], precision_xg_scol20[6]] )
precision_nea108 = list([test_sizes[10], precision_lr_scol20[7], precision_dt_scol20[7], precision_rf_scol20[7], precision_nb_scol20[7], precision_xg_scol20[7]] )
precision_nea109 = list([test_sizes[10], precision_lr_scol20[8], precision_dt_scol20[8], precision_rf_scol20[8], precision_nb_scol20[8], precision_xg_scol20[8]] )
precision_nea110 = list([test_sizes[10], precision_lr_scol20[9], precision_dt_scol20[9], precision_rf_scol20[9], precision_nb_scol20[9], precision_xg_scol20[9]] )

# Recall - 10 test size
#recall_nea101b = list([recall_lr_scol20[0], recall_dt_scol20[0], recall_rf_scol20[0], recall_nb_scol20[0], recall_xg_scol20[0]])
recall_nea101 = list([test_sizes[10], recall_xg_scol20[0], recall_rf_scol20[0], recall_dt_scol20[0], recall_lr_scol20[0], recall_nb_scol20[0]])
# recall_nea101 = list([(test_sizes[10] - test_sizes[10]), (0.0 + recall_rf_scol20[0]), (1.0 + recall_xg_scol20[0]),(2.0 + recall_dt_scol20[0]), (3.0 + recall_lr_scol20[0]), (4.0 + recall_nb_scol20[0])])
print("Iteration 1 Array:", recall_nea101)
# recall_nea = list([recall_lr_scol20[1], recall_dt_scol20[1], recall_rf_scol20[1], recall_nb_scol20[1], recall_xg_scol20[1]])
recall_nea102 = list([test_sizes[10], recall_xg_scol20[1], recall_rf_scol20[1], recall_dt_scol20[1],  recall_lr_scol20[1], recall_nb_scol20[1]])
#recall_nea102 = list([(test_sizes[10] - test_sizes[10]), (0.0 + recall_rf_scol20[1]), (1.0 + recall_xg_scol20[1]),(2.0 + recall_dt_scol20[1]), (3.0 + recall_lr_scol20[1]), (4.0 + recall_nb_scol20[1])])
print("Iteration 2 Array:", recall_nea102)

recall_nea103 = list([test_sizes[10], recall_lr_scol20[2], recall_dt_scol20[2], recall_rf_scol20[2], recall_nb_scol20[2], recall_xg_scol20[2]] )
recall_nea104 = list([test_sizes[10], recall_lr_scol20[3], recall_dt_scol20[3], recall_rf_scol20[3], recall_nb_scol20[3], recall_xg_scol20[3]] )
recall_nea105 = list([test_sizes[10], recall_lr_scol20[4], recall_dt_scol20[4], recall_rf_scol20[4], recall_nb_scol20[4], recall_xg_scol20[4]] )
recall_nea106 = list([test_sizes[10], recall_lr_scol20[5], recall_dt_scol20[5], recall_rf_scol20[5], recall_nb_scol20[5], recall_xg_scol20[5]] )
recall_nea107 = list([test_sizes[10], recall_lr_scol20[6], recall_dt_scol20[6], recall_rf_scol20[6], recall_nb_scol20[6], recall_xg_scol20[6]] )
recall_nea108 = list([test_sizes[10], recall_lr_scol20[7], recall_dt_scol20[7], recall_rf_scol20[7], recall_nb_scol20[7], recall_xg_scol20[7]] )
recall_nea109 = list([test_sizes[10], recall_lr_scol20[8], recall_dt_scol20[8], recall_rf_scol20[8], recall_nb_scol20[8], recall_xg_scol20[8]] )
recall_nea110 = list([test_sizes[10], recall_lr_scol20[9], recall_dt_scol20[9], recall_rf_scol20[9], recall_nb_scol20[9], recall_xg_scol20[9]] )


precision_lr_scol10_avg = (precision_lr_scol10[0] + precision_lr_scol10[1] + precision_lr_scol10[2] + precision_lr_scol10[3] + precision_lr_scol10[4] + precision_lr_scol10[5] + precision_lr_scol10[6] + precision_lr_scol10[7] + precision_lr_scol10[8] + precision_lr_scol10[9]) / 10
precision_dt_scol10_avg = (precision_dt_scol10[0] + precision_dt_scol10[1] + precision_dt_scol10[2] + precision_dt_scol10[3] + precision_dt_scol10[4] + precision_dt_scol10[5] + precision_dt_scol10[6] + precision_dt_scol10[7] + precision_dt_scol10[8] + precision_dt_scol10[9]) / 10
precision_rf_scol10_avg = (precision_rf_scol10[0] + precision_rf_scol10[1] + precision_rf_scol10[2] + precision_rf_scol10[3] + precision_rf_scol10[4] + precision_rf_scol10[5] + precision_rf_scol10[6] + precision_rf_scol10[7] + precision_rf_scol10[8] + precision_rf_scol10[9]) / 10
precision_nb_scol10_avg = (precision_nb_scol10[0] + precision_nb_scol10[1] + precision_nb_scol10[2] + precision_nb_scol10[3] + precision_nb_scol10[4] + precision_nb_scol10[5] + precision_nb_scol10[6] + precision_nb_scol10[7] + precision_nb_scol10[8] + precision_nb_scol10[9]) / 10
precision_xg_scol10_avg = (precision_xg_scol10[0] + precision_xg_scol10[1] + precision_xg_scol10[2] + precision_xg_scol10[3] + precision_xg_scol10[4] + precision_xg_scol10[5] + precision_xg_scol10[6] + precision_xg_scol10[7] + precision_xg_scol10[8] + precision_xg_scol10[9]) / 10

recall_lr_scol10_avg = (recall_lr_scol10[0] + recall_lr_scol10[1] + recall_lr_scol10[2] + recall_lr_scol10[3] + recall_lr_scol10[4] + recall_lr_scol10[5] + recall_lr_scol10[6] + recall_lr_scol10[7] + recall_lr_scol10[8] + recall_lr_scol10[9]) / 10
recall_dt_scol10_avg = (recall_dt_scol10[0] + recall_dt_scol10[1] + recall_dt_scol10[2] + recall_dt_scol10[3] + recall_dt_scol10[4] + recall_dt_scol10[5] + recall_dt_scol10[6] + recall_dt_scol10[7] + recall_dt_scol10[8] + recall_dt_scol10[9]) / 10
recall_rf_scol10_avg = (recall_rf_scol10[0] + recall_rf_scol10[1] + recall_rf_scol10[2] + recall_rf_scol10[3] + recall_rf_scol10[4] + recall_rf_scol10[5] + recall_rf_scol10[6] + recall_rf_scol10[7] + recall_rf_scol10[8] + recall_rf_scol10[9]) / 10
recall_nb_scol10_avg = (recall_nb_scol10[0] + recall_nb_scol10[1] + recall_nb_scol10[2] + recall_nb_scol10[3] + recall_nb_scol10[4] + recall_nb_scol10[5] + recall_nb_scol10[6] + recall_nb_scol10[7] + recall_nb_scol10[8] + recall_nb_scol10[9]) / 10
recall_xg_scol10_avg = (recall_xg_scol10[0] + recall_xg_scol10[1] + recall_xg_scol10[2] + recall_xg_scol10[3] + recall_xg_scol10[4] + recall_xg_scol10[5] + recall_xg_scol10[6] + recall_xg_scol10[7] + recall_xg_scol10[8] + recall_xg_scol10[9]) / 10
'''

precision_lr_scol10_avg = (precision_lr_scol10[0] + precision_lr_scol10[1] + precision_lr_scol10[2] + precision_lr_scol10[3] + precision_lr_scol10[4]) / 5
precision_dt_scol10_avg = (precision_dt_scol10[0] + precision_dt_scol10[1] + precision_dt_scol10[2] + precision_dt_scol10[3] + precision_dt_scol10[4]) / 5
precision_rf_scol10_avg = (precision_rf_scol10[0] + precision_rf_scol10[1] + precision_rf_scol10[2] + precision_rf_scol10[3] + precision_rf_scol10[4]) / 5
precision_nb_scol10_avg = (precision_nb_scol10[0] + precision_nb_scol10[1] + precision_nb_scol10[2] + precision_nb_scol10[3] + precision_nb_scol10[4]) / 5
precision_xg_scol10_avg = (precision_xg_scol10[0] + precision_xg_scol10[1] + precision_xg_scol10[2] + precision_xg_scol10[3] + precision_xg_scol10[4]) / 5

recall_lr_scol10_avg = (recall_lr_scol10[0] + recall_lr_scol10[1] + recall_lr_scol10[2] + recall_lr_scol10[3] + recall_lr_scol10[4]) / 5
recall_dt_scol10_avg = (recall_dt_scol10[0] + recall_dt_scol10[1] + recall_dt_scol10[2] + recall_dt_scol10[3] + recall_dt_scol10[4]) / 5
recall_rf_scol10_avg = (recall_rf_scol10[0] + recall_rf_scol10[1] + recall_rf_scol10[2] + recall_rf_scol10[3] + recall_rf_scol10[4]) / 5
recall_nb_scol10_avg = (recall_nb_scol10[0] + recall_nb_scol10[1] + recall_nb_scol10[2] + recall_nb_scol10[3] + recall_nb_scol10[4]) / 5
recall_xg_scol10_avg = (recall_xg_scol10[0] + recall_xg_scol10[1] + recall_xg_scol10[2] + recall_xg_scol10[3] + recall_xg_scol10[4]) / 5

'''
avg_precision_nea10 = list([test_sizes[10], precision_lr_scol10_avg, precision_dt_scol10_avg, precision_rf_scol10_avg, precision_nb_scol10_avg, precision_xg_scol10_avg])
avg_recall_nea10 = list([test_sizes[10], recall_lr_scol10_avg, recall_dt_scol10_avg, recall_rf_scol10_avg, recall_nb_scol10_avg, recall_xg_scol10_avg])
'''
### Curves
precision_lr_curve = list([precision_lr_scol_avg, precision_lr_scol2_avg, precision_lr_scol2_avg, precision_lr_scol2_avg, precision_lr_scol2_avg, precision_lr_scol2_avg, precision_lr_scol2_avg, precision_lr_scol8_avg, precision_lr_scol9_avg])
precision_dt_curve = list([precision_dt_scol_avg, precision_dt_scol2_avg, precision_dt_scol2_avg, precision_dt_scol2_avg, precision_dt_scol2_avg, precision_dt_scol2_avg, precision_dt_scol2_avg, precision_dt_scol8_avg, precision_dt_scol9_avg])
precision_rf_curve = list([precision_rf_scol_avg, precision_rf_scol2_avg, precision_rf_scol2_avg, precision_rf_scol2_avg, precision_rf_scol2_avg, precision_rf_scol2_avg, precision_rf_scol2_avg, precision_rf_scol8_avg, precision_rf_scol9_avg])
precision_nb_curve = list([precision_nb_scol_avg, precision_nb_scol2_avg, precision_nb_scol2_avg, precision_nb_scol2_avg, precision_nb_scol2_avg, precision_nb_scol2_avg, precision_nb_scol2_avg, precision_nb_scol8_avg, precision_nb_scol9_avg])
precision_xg_curve = list([precision_xg_scol_avg, precision_xg_scol2_avg, precision_xg_scol2_avg, precision_xg_scol2_avg,  precision_xg_scol2_avg, precision_xg_scol2_avg, precision_xg_scol2_avg, precision_xg_scol8_avg, precision_xg_scol9_avg])

recall_lr_curve = list([recall_lr_scol_avg, recall_lr_scol2_avg, recall_lr_scol2_avg, recall_lr_scol2_avg, recall_lr_scol2_avg, recall_lr_scol2_avg, recall_lr_scol2_avg, recall_lr_scol8_avg, recall_lr_scol9_avg])
recall_dt_curve = list([recall_dt_scol_avg, recall_dt_scol2_avg, recall_dt_scol2_avg, recall_dt_scol2_avg, recall_dt_scol2_avg, recall_dt_scol2_avg, recall_dt_scol2_avg, recall_dt_scol8_avg, recall_dt_scol9_avg])
recall_rf_curve = list([recall_rf_scol_avg, recall_rf_scol2_avg, recall_rf_scol2_avg, recall_rf_scol2_avg, recall_rf_scol2_avg, recall_rf_scol2_avg, recall_rf_scol2_avg, recall_rf_scol8_avg, recall_rf_scol9_avg])
recall_nb_curve = list([recall_nb_scol_avg, recall_nb_scol2_avg, recall_nb_scol2_avg, recall_nb_scol2_avg, recall_nb_scol2_avg, recall_nb_scol2_avg, recall_nb_scol2_avg, recall_nb_scol8_avg, recall_nb_scol9_avg])
recall_xg_curve = list([recall_xg_scol_avg, recall_xg_scol2_avg, recall_xg_scol2_avg, recall_xg_scol2_avg,  recall_xg_scol2_avg, recall_xg_scol2_avg, recall_xg_scol2_avg, recall_xg_scol8_avg, recall_xg_scol9_avg])

# Test Size #12 - 60%

probs_lr_scol11 = []
f1_lr_scol11 = []
rocauc_lr_scol11 = []
recall_lr_scol11 = []
precision_lr_scol11 = []
accuracy_lr_scol11 = []

probs_dt_scol11 = []
f1_dt_scol11 = []
rocauc_dt_scol11 = []
recall_dt_scol11 = []
precision_dt_scol11 = []
accuracy_dt_scol11 = []

probs_nb_scol11 = []
f1_nb_scol11 = []
rocauc_nb_scol11 = []
recall_nb_scol11 = []
precision_nb_scol11 = []
accuracy_nb_scol11 = []

probs_xg_scol11 = []
f1_xg_scol11 = []
rocauc_xg_scol11 = []
recall_xg_scol11 = []
precision_xg_scol11 = []
accuracy_xg_scol11 = []

probs_rf_scol11 = []
f1_rf_scol11 = []
rocauc_rf_scol11 = []
recall_rf_scol11 = []
precision_rf_scol11 = []
accuracy_rf_scol11 = []

tfidf_vect11 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train11 = tfidf_vect11.fit_transform(x23.values)
tfidf_test11=tfidf_vect11.transform(x24.values)
print(tfidf_train11.shape)
print(tfidf_test11.shape)
#tfidf_train11.toarray()

x_tfidf11 = tfidf_vect11.fit_transform(df12["lemmatized"])
x_ros11, y_ros11 = ros.fit_resample(x_tfidf11, df12["label"])

# train_values11 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values11 = 1 - train_values11
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros11, y_ros11, train_size=i, stratify=y_ros11)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol11.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol11.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol11.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol11.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol11.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol11.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df12_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol11.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol11.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol11.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol11.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol11.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol11.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df12_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol11.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol11.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol11.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol11.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol11.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol11.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df12_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol11.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol11.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol11.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol11.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol11.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol11.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df12_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol11.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol11.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol11.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol11.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol11.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol11.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df12_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df12_l, ":", probs_lr_scol11)
    print("Array of F1 Scores LR-ROS:", df12_l, ":", f1_lr_scol11)
    print("Array of ROCAUC Scores LR-ROS:", df12_l, ":", rocauc_lr_scol11)
    print("Array of Recall Scores LR-ROS:", df12_l, ":", recall_lr_scol11)
    print("Array of Precision Scores LR-ROS:", df12_l, ":", precision_lr_scol11)
    print("Array of Accuracy Scores LR-ROS:", df12_l, ":", accuracy_lr_scol11)

    print("Array of Prob Scores DT-ROS:", df12_l, ":", probs_dt_scol11)
    print("Array of F1 Scores DT-ROS:", df12_l, ":", f1_dt_scol11)
    print("Array of ROCAUC Scores DT-ROS:", df12_l, ":", rocauc_dt_scol11)
    print("Array of Recall Scores DT-ROS:", df12_l, ":", recall_dt_scol11)
    print("Array of Precision Scores DT-ROS:", df12_l, ":", precision_dt_scol11)
    print("Array of Accuracy Scores DT-ROS:", df12_l, ":", accuracy_dt_scol11)

    print("Array of Prob Scores NB-ROS:", df12_l, ":", probs_nb_scol11)
    print("Array of F1 Scores NB-ROS:", df12_l, ":", f1_nb_scol11)
    print("Array of ROCAUC Scores NB-ROS:", df12_l, ":", rocauc_nb_scol11)
    print("Array of Recall Scores NB-ROS:", df12_l, ":", recall_nb_scol11)
    print("Array of Precision Scores NB-ROS:", df12_l, ":", precision_nb_scol11)
    print("Array of Accuracy Scores NB-ROS:", df12_l, ":", accuracy_nb_scol11)

    print("Array of Prob Scores XG-ROS:", df12_l, ":", probs_xg_scol11)
    print("Array of F1 Scores XG-ROS:", df12_l, ":", f1_xg_scol11)
    print("Array of ROCAUC Scores XG-ROS:", df12_l, ":", rocauc_xg_scol11)
    print("Array of Recall Scores XG-ROS:", df12_l, ":", recall_xg_scol11)
    print("Array of Precision Scores XG-ROS:", df12_l, ":", precision_xg_scol11)
    print("Array of Accuracy Scores XG-ROS:", df12_l, ":", accuracy_xg_scol11)

    print("Array of Prob Scores RF-ROS:", df12_l, ":", probs_rf_scol11)
    print("Array of F1 Scores RF-ROS:", df12_l, ":", f1_rf_scol11)
    print("Array of ROCAUC Scores RF-ROS:", df12_l, ":", rocauc_rf_scol11)
    print("Array of Recall Scores RF-ROS:", df12_l, ":", recall_rf_scol11)
    print("Array of Precision Scores RF-ROS:", df12_l, ":", precision_rf_scol11)
    print("Array of Accuracy Scores RF-ROS:", df12_l, ":", accuracy_rf_scol11)

year11 = [ args.group for t in range(25)]
sampling11 =['Oversampling' for t in range(25)]
technique11 = ['ROS' for t in range(25)]
classifier_names11 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num11 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num11 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num11 = [precision_lr_scol11, precision_dt_scol11, precision_nb_scol11, precision_xg_scol11, precision_rf_scol11]
recall_csv_num11 = [recall_lr_scol11, recall_dt_scol11, recall_nb_scol11, recall_xg_scol11, recall_xg_scol11]
auc_csv_num11 = [rocauc_lr_scol11, rocauc_dt_scol11, rocauc_nb_scol11, rocauc_xg_scol11, rocauc_rf_scol11]
accuracy_csv_num11 = [accuracy_lr_scol11, accuracy_dt_scol11, accuracy_nb_scol11, accuracy_xg_scol11, accuracy_rf_scol11]
import itertools
rounds = 5
p11 = itertools.cycle(classifier_names11)
o11 = itertools.cycle(test_sizes_num11)
k11 = itertools.cycle(train_sizes_num11)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv11 = [next(p11) for _ in range(rounds)] * 5
test_size_csv11 = [a for b in test_sizes_num11 for a in (b,)*5]
train_size_csv11 = [c for d in train_sizes_num11 for c in (d,)*5]
split_csv11 = ['12' for u in range(25)]
train_csv11 = ['60%' for u in range(25)]
precision_csv11 = list(chain(*precision_csv_num11))
recall_csv11 = list(chain(*recall_csv_num11))
auc_csv11 = list(chain(*auc_csv_num11))
accuracy_csv11 = list(chain(*accuracy_csv_num11))
csv_data11 = [year11, sampling11, technique11, classifier_csv11, test_size_csv11, train_size_csv11, split_csv11, train_csv11, precision_csv11,
            recall_csv11, auc_csv11, accuracy_csv11]
export_data11 = zip_longest(*csv_data11, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data11)
'''
'''
'''
# Preicsion - #12 test size
#precision_nea111b = list([precision_lr_scol11[0], precision_dt_scol11[0], precision_rf_scol11[0], precision_nb_scol11[0], precision_xg_scol11[0]])
precision_nea111 = list([test_sizes[11], precision_xg_scol11[0], precision_rf_scol11[0], precision_dt_scol11[0], precision_lr_scol11[0], precision_nb_scol11[0]])
#precision_nea111 = list([(test_sizes[11] - test_sizes[11]), (0.0 + precision_rf_scol11[0]), (1.0 + precision_xg_scol11[0]),(2.0 + precision_dt_scol11[0]), (3.0 + precision_lr_scol11[0]), (4.0 + precision_nb_scol11[0])])
print("Iteration 1 Array:", precision_nea111)
# precision_nea112 = list([precision_lr_scol11[1], precision_dt_scol11[1], precision_rf_scol11[1], precision_nb_scol11[1], precision_xg_scol11[1]])
precision_nea112 = list([test_sizes[11], precision_xg_scol11[1], precision_rf_scol11[1], precision_dt_scol11[1],  precision_lr_scol11[1], precision_nb_scol11[1]])
#precision_nea112 = list([(test_sizes[11] - test_sizes[11]), (0.0 + precision_rf_scol11[1]), (1.0 + precision_xg_scol11[1]),(2.0 + precision_dt_scol11[1]), (3.0 + precision_lr_scol11[1]), (4.0 + precision_nb_scol11[1])])
print("Iteration 2 Array:", precision_nea112)
precision_nea113 = list([test_sizes[11], precision_lr_scol11[2], precision_dt_scol11[2], precision_rf_scol11[2], precision_nb_scol11[2], precision_xg_scol11[2]] )
precision_nea114 = list([test_sizes[11], precision_lr_scol11[3], precision_dt_scol11[3], precision_rf_scol11[3], precision_nb_scol11[3], precision_xg_scol11[3]] )
precision_nea115 = list([test_sizes[11], precision_lr_scol11[4], precision_dt_scol11[4], precision_rf_scol11[4], precision_nb_scol11[4], precision_xg_scol11[4]] )
precision_nea116 = list([test_sizes[11], precision_lr_scol11[5], precision_dt_scol11[5], precision_rf_scol11[5], precision_nb_scol11[5], precision_xg_scol11[5]] )
precision_nea117 = list([test_sizes[11], precision_lr_scol11[6], precision_dt_scol11[6], precision_rf_scol11[6], precision_nb_scol11[6], precision_xg_scol11[6]] )
precision_nea118 = list([test_sizes[11], precision_lr_scol11[7], precision_dt_scol11[7], precision_rf_scol11[7], precision_nb_scol11[7], precision_xg_scol11[7]] )
precision_nea119 = list([test_sizes[11], precision_lr_scol11[8], precision_dt_scol11[8], precision_rf_scol11[8], precision_nb_scol11[8], precision_xg_scol11[8]] )
precision_nea120 = list([test_sizes[11], precision_lr_scol11[9], precision_dt_scol11[9], precision_rf_scol11[9], precision_nb_scol11[9], precision_xg_scol11[9]] )

# Recall - 11 test size
#recall_nea111b = list([recall_lr_scol11[0], recall_dt_scol11[0], recall_rf_scol11[0], recall_nb_scol11[0], recall_xg_scol11[0]])
recall_nea111 = list([test_sizes[11], recall_xg_scol11[0], recall_rf_scol11[0], recall_dt_scol11[0], recall_lr_scol11[0], recall_nb_scol11[0]])
# recall_nea111 = list([(test_sizes[11] - test_sizes[11]), (0.0 + recall_rf_scol11[0]), (1.0 + recall_xg_scol11[0]),(2.0 + recall_dt_scol11[0]), (3.0 + recall_lr_scol11[0]), (4.0 + recall_nb_scol11[0])])
print("Iteration 1 Array:", recall_nea111)
# recall_nea112 = list([recall_lr_scol11[1], recall_dt_scol11[1], recall_rf_scol11[1], recall_nb_scol11[1], recall_xg_scol11[1]])
recall_nea112 = list([test_sizes[11], recall_xg_scol11[1], recall_rf_scol11[1], recall_dt_scol11[1],  recall_lr_scol11[1], recall_nb_scol11[1]])
#recall_nea112 = list([(test_sizes[11] - test_sizes[11]), (0.0 + recall_rf_scol11[1]), (1.0 + recall_xg_scol11[1]),(2.0 + recall_dt_scol11[1]), (3.0 + recall_lr_scol11[1]), (4.0 + recall_nb_scol11[1])])
print("Iteration 2 Array:", recall_nea112)

recall_nea113 = list([test_sizes[11], recall_lr_scol11[2], recall_dt_scol11[2], recall_rf_scol11[2], recall_nb_scol11[2], recall_xg_scol11[2]] )
recall_nea114 = list([test_sizes[11], recall_lr_scol11[3], recall_dt_scol11[3], recall_rf_scol11[3], recall_nb_scol11[3], recall_xg_scol11[3]] )
recall_nea115 = list([test_sizes[11], recall_lr_scol11[4], recall_dt_scol11[4], recall_rf_scol11[4], recall_nb_scol11[4], recall_xg_scol11[4]] )
recall_nea116 = list([test_sizes[11], recall_lr_scol11[5], recall_dt_scol11[5], recall_rf_scol11[5], recall_nb_scol11[5], recall_xg_scol11[5]] )
recall_nea117 = list([test_sizes[11], recall_lr_scol11[6], recall_dt_scol11[6], recall_rf_scol11[6], recall_nb_scol11[6], recall_xg_scol11[6]] )
recall_nea118 = list([test_sizes[11], recall_lr_scol11[7], recall_dt_scol11[7], recall_rf_scol11[7], recall_nb_scol11[7], recall_xg_scol11[7]] )
recall_nea119 = list([test_sizes[11], recall_lr_scol11[8], recall_dt_scol11[8], recall_rf_scol11[8], recall_nb_scol11[8], recall_xg_scol11[8]] )
recall_nea120 = list([test_sizes[11], recall_lr_scol11[9], recall_dt_scol11[9], recall_rf_scol11[9], recall_nb_scol11[9], recall_xg_scol11[9]] )


precision_lr_scol11_avg = (precision_lr_scol11[0] + precision_lr_scol11[1] + precision_lr_scol11[2] + precision_lr_scol11[3] + precision_lr_scol11[4] + precision_lr_scol11[5] + precision_lr_scol11[6] + precision_lr_scol11[7] + precision_lr_scol11[8] + precision_lr_scol11[9]) / 10
precision_dt_scol11_avg = (precision_dt_scol11[0] + precision_dt_scol11[1] + precision_dt_scol11[2] + precision_dt_scol11[3] + precision_dt_scol11[4] + precision_dt_scol11[5] + precision_dt_scol11[6] + precision_dt_scol11[7] + precision_dt_scol11[8] + precision_dt_scol11[9]) / 10
precision_rf_scol11_avg = (precision_rf_scol11[0] + precision_rf_scol11[1] + precision_rf_scol11[2] + precision_rf_scol11[3] + precision_rf_scol11[4] + precision_rf_scol11[5] + precision_rf_scol11[6] + precision_rf_scol11[7] + precision_rf_scol11[8] + precision_rf_scol11[9]) / 10
precision_nb_scol11_avg = (precision_nb_scol11[0] + precision_nb_scol11[1] + precision_nb_scol11[2] + precision_nb_scol11[3] + precision_nb_scol11[4] + precision_nb_scol11[5] + precision_nb_scol11[6] + precision_nb_scol11[7] + precision_nb_scol11[8] + precision_nb_scol11[9]) / 10
precision_xg_scol11_avg = (precision_xg_scol11[0] + precision_xg_scol11[1] + precision_xg_scol11[2] + precision_xg_scol11[3] + precision_xg_scol11[4] + precision_xg_scol11[5] + precision_xg_scol11[6] + precision_xg_scol11[7] + precision_xg_scol11[8] + precision_xg_scol11[9]) / 10

recall_lr_scol11_avg = (recall_lr_scol11[0] + recall_lr_scol11[1] + recall_lr_scol11[2] + recall_lr_scol11[3] + recall_lr_scol11[4] + recall_lr_scol11[5] + recall_lr_scol11[6] + recall_lr_scol11[7] + recall_lr_scol11[8] + recall_lr_scol11[9]) / 10
recall_dt_scol11_avg = (recall_dt_scol11[0] + recall_dt_scol11[1] + recall_dt_scol11[2] + recall_dt_scol11[3] + recall_dt_scol11[4] + recall_dt_scol11[5] + recall_dt_scol11[6] + recall_dt_scol11[7] + recall_dt_scol11[8] + recall_dt_scol11[9]) / 10
recall_rf_scol11_avg = (recall_rf_scol11[0] + recall_rf_scol11[1] + recall_rf_scol11[2] + recall_rf_scol11[3] + recall_rf_scol11[4] + recall_rf_scol11[5] + recall_rf_scol11[6] + recall_rf_scol11[7] + recall_rf_scol11[8] + recall_rf_scol11[9]) / 10
recall_nb_scol11_avg = (recall_nb_scol11[0] + recall_nb_scol11[1] + recall_nb_scol11[2] + recall_nb_scol11[3] + recall_nb_scol11[4] + recall_nb_scol11[5] + recall_nb_scol11[6] + recall_nb_scol11[7] + recall_nb_scol11[8] + recall_nb_scol11[9]) / 10
recall_xg_scol11_avg = (recall_xg_scol11[0] + recall_xg_scol11[1] + recall_xg_scol11[2] + recall_xg_scol11[3] + recall_xg_scol11[4] + recall_xg_scol11[5] + recall_xg_scol11[6] + recall_xg_scol11[7] + recall_xg_scol11[8] + recall_xg_scol11[9]) / 10
'''

precision_lr_scol11_avg = (precision_lr_scol11[0] + precision_lr_scol11[1] + precision_lr_scol11[2] + precision_lr_scol11[3] + precision_lr_scol11[4]) / 5
precision_dt_scol11_avg = (precision_dt_scol11[0] + precision_dt_scol11[1] + precision_dt_scol11[2] + precision_dt_scol11[3] + precision_dt_scol11[4]) / 5
precision_rf_scol11_avg = (precision_rf_scol11[0] + precision_rf_scol11[1] + precision_rf_scol11[2] + precision_rf_scol11[3] + precision_rf_scol11[4]) / 5
precision_nb_scol11_avg = (precision_nb_scol11[0] + precision_nb_scol11[1] + precision_nb_scol11[2] + precision_nb_scol11[3] + precision_nb_scol11[4]) / 5
precision_xg_scol11_avg = (precision_xg_scol11[0] + precision_xg_scol11[1] + precision_xg_scol11[2] + precision_xg_scol11[3] + precision_xg_scol11[4]) / 5

recall_lr_scol11_avg = (recall_lr_scol11[0] + recall_lr_scol11[1] + recall_lr_scol11[2] + recall_lr_scol11[3] + recall_lr_scol11[4]) / 5
recall_dt_scol11_avg = (recall_dt_scol11[0] + recall_dt_scol11[1] + recall_dt_scol11[2] + recall_dt_scol11[3] + recall_dt_scol11[4]) / 5
recall_rf_scol11_avg = (recall_rf_scol11[0] + recall_rf_scol11[1] + recall_rf_scol11[2] + recall_rf_scol11[3] + recall_rf_scol11[4]) / 5
recall_nb_scol11_avg = (recall_nb_scol11[0] + recall_nb_scol11[1] + recall_nb_scol11[2] + recall_nb_scol11[3] + recall_nb_scol11[4]) / 5
recall_xg_scol11_avg = (recall_xg_scol11[0] + recall_xg_scol11[1] + recall_xg_scol11[2] + recall_xg_scol11[3] + recall_xg_scol11[4]) / 5

# Test Size #13 - 65%

probs_lr_scol12 = []
f1_lr_scol12 = []
rocauc_lr_scol12 = []
recall_lr_scol12 = []
precision_lr_scol12 = []
accuracy_lr_scol12 = []

probs_dt_scol12 = []
f1_dt_scol12 = []
rocauc_dt_scol12 = []
recall_dt_scol12 = []
precision_dt_scol12 = []
accuracy_dt_scol12 = []

probs_nb_scol12 = []
f1_nb_scol12 = []
rocauc_nb_scol12 = []
recall_nb_scol12 = []
precision_nb_scol12 = []
accuracy_nb_scol12 = []

probs_xg_scol12 = []
f1_xg_scol12 = []
rocauc_xg_scol12 = []
recall_xg_scol12 = []
precision_xg_scol12 = []
accuracy_xg_scol12 = []

probs_rf_scol12 = []
f1_rf_scol12 = []
rocauc_rf_scol12 = []
recall_rf_scol12 = []
precision_rf_scol12 = []
accuracy_rf_scol12 = []

tfidf_vect12 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train12 = tfidf_vect12.fit_transform(x25.values)
tfidf_test12=tfidf_vect12.transform(x26.values)
print(tfidf_train12.shape)
print(tfidf_test12.shape)
#tfidf_train12.toarray()

x_tfidf12 = tfidf_vect12.fit_transform(df13["lemmatized"])
x_ros12, y_ros12 = ros.fit_resample(x_tfidf12, df13["label"])

# train_values12 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values12 = 1 - train_values12
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros12, y_ros12, train_size=i, stratify=y_ros12)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol12.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol12.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol12.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol12.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol12.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol12.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df13_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol12.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol12.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol12.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol12.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol12.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol12.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df13_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol12.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol12.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol12.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol12.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol12.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol12.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df13_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol12.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol12.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol12.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol12.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol12.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol12.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df13_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol12.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol12.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol12.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol12.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol12.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol12.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df13_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df13_l, ":", probs_lr_scol12)
    print("Array of F1 Scores LR-ROS:", df13_l, ":", f1_lr_scol12)
    print("Array of ROCAUC Scores LR-ROS:", df13_l, ":", rocauc_lr_scol12)
    print("Array of Recall Scores LR-ROS:", df13_l, ":", recall_lr_scol12)
    print("Array of Precision Scores LR-ROS:", df13_l, ":", precision_lr_scol12)
    print("Array of Accuracy Scores LR-ROS:", df13_l, ":", accuracy_lr_scol12)

    print("Array of Prob Scores DT-ROS:", df13_l, ":", probs_dt_scol12)
    print("Array of F1 Scores DT-ROS:", df13_l, ":", f1_dt_scol12)
    print("Array of ROCAUC Scores DT-ROS:", df13_l, ":", rocauc_dt_scol12)
    print("Array of Recall Scores DT-ROS:", df13_l, ":", recall_dt_scol12)
    print("Array of Precision Scores DT-ROS:", df13_l, ":", precision_dt_scol12)
    print("Array of Accuracy Scores DT-ROS:", df13_l, ":", accuracy_dt_scol12)

    print("Array of Prob Scores NB-ROS:", df13_l, ":", probs_nb_scol12)
    print("Array of F1 Scores NB-ROS:", df13_l, ":", f1_nb_scol12)
    print("Array of ROCAUC Scores NB-ROS:", df13_l, ":", rocauc_nb_scol12)
    print("Array of Recall Scores NB-ROS:", df13_l, ":", recall_nb_scol12)
    print("Array of Precision Scores NB-ROS:", df13_l, ":", precision_nb_scol12)
    print("Array of Accuracy Scores NB-ROS:", df13_l, ":", accuracy_nb_scol12)

    print("Array of Prob Scores XG-ROS:", df13_l, ":", probs_xg_scol12)
    print("Array of F1 Scores XG-ROS:", df13_l, ":", f1_xg_scol12)
    print("Array of ROCAUC Scores XG-ROS:", df13_l, ":", rocauc_xg_scol12)
    print("Array of Recall Scores XG-ROS:", df13_l, ":", recall_xg_scol12)
    print("Array of Precision Scores XG-ROS:", df13_l, ":", precision_xg_scol12)
    print("Array of Accuracy Scores XG-ROS:", df13_l, ":", accuracy_xg_scol12)

    print("Array of Prob Scores RF-ROS:", df13_l, ":", probs_rf_scol12)
    print("Array of F1 Scores RF-ROS:", df13_l, ":", f1_rf_scol12)
    print("Array of ROCAUC Scores RF-ROS:", df13_l, ":", rocauc_rf_scol12)
    print("Array of Recall Scores RF-ROS:", df13_l, ":", recall_rf_scol12)
    print("Array of Precision Scores RF-ROS:", df13_l, ":", precision_rf_scol12)
    print("Array of Accuracy Scores RF-ROS:", df13_l, ":", accuracy_rf_scol12)

year12 = [ args.group for t in range(25)]
sampling12 =['Oversampling' for t in range(25)]
technique12 = ['ROS' for t in range(25)]
classifier_names12 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num12 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num12 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num12 = [precision_lr_scol12, precision_dt_scol12, precision_nb_scol12, precision_xg_scol12, precision_rf_scol12]
recall_csv_num12 = [recall_lr_scol12, recall_dt_scol12, recall_nb_scol12, recall_xg_scol12, recall_xg_scol12]
auc_csv_num12 = [rocauc_lr_scol12, rocauc_dt_scol12, rocauc_nb_scol12, rocauc_xg_scol12, rocauc_rf_scol12]
accuracy_csv_num12 = [accuracy_lr_scol12, accuracy_dt_scol12, accuracy_nb_scol12, accuracy_xg_scol12, accuracy_rf_scol12]
import itertools
rounds = 5
p12 = itertools.cycle(classifier_names12)
o12 = itertools.cycle(test_sizes_num12)
k12 = itertools.cycle(train_sizes_num12)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv12 = [next(p12) for _ in range(rounds)] * 5
test_size_csv12 = [a for b in test_sizes_num12 for a in (b,)*5]
train_size_csv12 = [c for d in train_sizes_num12 for c in (d,)*5]
split_csv12 = ['13' for u in range(25)]
train_csv12 = ['65%' for u in range(25)]
precision_csv12 = list(chain(*precision_csv_num12))
recall_csv12 = list(chain(*recall_csv_num12))
auc_csv12 = list(chain(*auc_csv_num12))
accuracy_csv12 = list(chain(*accuracy_csv_num12))
csv_data12 = [year12, sampling12, technique12, classifier_csv12, test_size_csv12, train_size_csv12, split_csv12, train_csv12, precision_csv12,
            recall_csv12, auc_csv12, accuracy_csv12]
export_data12 = zip_longest(*csv_data12, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data12)
  
'''
# Preicsion - #13 test size
#precision_nea121b = list([precision_lr_scol12[0], precision_dt_scol12[0], precision_rf_scol12[0], precision_nb_scol12[0], precision_xg_scol12[0]])
precision_nea121 = list([test_sizes[12], precision_xg_scol12[0], precision_rf_scol12[0], precision_dt_scol12[0], precision_lr_scol12[0], precision_nb_scol12[0]])
#precision_nea121 = list([(test_sizes[12] - test_sizes[12]), (0.0 + precision_rf_scol12[0]), (1.0 + precision_xg_scol12[0]),(2.0 + precision_dt_scol12[0]), (3.0 + precision_lr_scol12[0]), (4.0 + precision_nb_scol12[0])])
print("Iteration 1 Array:", precision_nea121)
# precision_nea122 = list([precision_lr_scol12[1], precision_dt_scol12[1], precision_rf_scol12[1], precision_nb_scol12[1], precision_xg_scol12[1]])
precision_nea122 = list([test_sizes[12], precision_xg_scol12[1], precision_rf_scol12[1], precision_dt_scol12[1],  precision_lr_scol12[1], precision_nb_scol12[1]])
#precision_nea122 = list([(test_sizes[12] - test_sizes[12]), (0.0 + precision_rf_scol12[1]), (1.0 + precision_xg_scol12[1]),(2.0 + precision_dt_scol12[1]), (3.0 + precision_lr_scol12[1]), (4.0 + precision_nb_scol12[1])])
print("Iteration 2 Array:", precision_nea122)
precision_nea123 = list([test_sizes[12], precision_lr_scol12[2], precision_dt_scol12[2], precision_rf_scol12[2], precision_nb_scol12[2], precision_xg_scol12[2]] )
precision_nea124 = list([test_sizes[12], precision_lr_scol12[3], precision_dt_scol12[3], precision_rf_scol12[3], precision_nb_scol12[3], precision_xg_scol12[3]] )
precision_nea125 = list([test_sizes[12], precision_lr_scol12[4], precision_dt_scol12[4], precision_rf_scol12[4], precision_nb_scol12[4], precision_xg_scol12[4]] )
precision_nea126 = list([test_sizes[12], precision_lr_scol12[5], precision_dt_scol12[5], precision_rf_scol12[5], precision_nb_scol12[5], precision_xg_scol12[5]] )
precision_nea127 = list([test_sizes[12], precision_lr_scol12[6], precision_dt_scol12[6], precision_rf_scol12[6], precision_nb_scol12[6], precision_xg_scol12[6]] )
precision_nea128 = list([test_sizes[12], precision_lr_scol12[7], precision_dt_scol12[7], precision_rf_scol12[7], precision_nb_scol12[7], precision_xg_scol12[7]] )
precision_nea129 = list([test_sizes[12], precision_lr_scol12[8], precision_dt_scol12[8], precision_rf_scol12[8], precision_nb_scol12[8], precision_xg_scol12[8]] )
precision_nea130 = list([test_sizes[12], precision_lr_scol12[9], precision_dt_scol12[9], precision_rf_scol12[9], precision_nb_scol12[9], precision_xg_scol12[9]] )

# Recall - 10 test size
#recall_nea121b = list([recall_lr_scol12[0], recall_dt_scol12[0], recall_rf_scol12[0], recall_nb_scol12[0], recall_xg_scol12[0]])
recall_nea121 = list([test_sizes[12], recall_xg_scol12[0], recall_rf_scol12[0], recall_dt_scol12[0], recall_lr_scol12[0], recall_nb_scol12[0]])
# recall_nea121 = list([(test_sizes[12] - test_sizes[12]), (0.0 + recall_rf_scol12[0]), (1.0 + recall_xg_scol12[0]),(2.0 + recall_dt_scol12[0]), (3.0 + recall_lr_scol12[0]), (4.0 + recall_nb_scol12[0])])
print("Iteration 1 Array:", recall_nea121)
# recall_nea122 = list([recall_lr_scol12[1], recall_dt_scol12[1], recall_rf_scol12[1], recall_nb_scol12[1], recall_xg_scol12[1]])
recall_nea122 = list([test_sizes[12], recall_xg_scol12[1], recall_rf_scol12[1], recall_dt_scol12[1],  recall_lr_scol12[1], recall_nb_scol12[1]])
#recall_nea122 = list([(test_sizes[12] - test_sizes[12]), (0.0 + recall_rf_scol12[1]), (1.0 + recall_xg_scol12[1]),(2.0 + recall_dt_scol12[1]), (3.0 + recall_lr_scol12[1]), (4.0 + recall_nb_scol12[1])])
print("Iteration 2 Array:", recall_nea122)

recall_nea123 = list([test_sizes[12], recall_lr_scol12[2], recall_dt_scol12[2], recall_rf_scol12[2], recall_nb_scol12[2], recall_xg_scol12[2]] )
recall_nea124 = list([test_sizes[12], recall_lr_scol12[3], recall_dt_scol12[3], recall_rf_scol12[3], recall_nb_scol12[3], recall_xg_scol12[3]] )
recall_nea125 = list([test_sizes[12], recall_lr_scol12[4], recall_dt_scol12[4], recall_rf_scol12[4], recall_nb_scol12[4], recall_xg_scol12[4]] )
recall_nea126 = list([test_sizes[12], recall_lr_scol12[5], recall_dt_scol12[5], recall_rf_scol12[5], recall_nb_scol12[5], recall_xg_scol12[5]] )
recall_nea127 = list([test_sizes[12], recall_lr_scol12[6], recall_dt_scol12[6], recall_rf_scol12[6], recall_nb_scol12[6], recall_xg_scol12[6]] )
recall_nea128 = list([test_sizes[12], recall_lr_scol12[7], recall_dt_scol12[7], recall_rf_scol12[7], recall_nb_scol12[7], recall_xg_scol12[7]] )
recall_nea129 = list([test_sizes[12], recall_lr_scol12[8], recall_dt_scol12[8], recall_rf_scol12[8], recall_nb_scol12[8], recall_xg_scol12[8]] )
recall_nea130 = list([test_sizes[12], recall_lr_scol12[9], recall_dt_scol12[9], recall_rf_scol12[9], recall_nb_scol12[9], recall_xg_scol12[9]] )


precision_lr_scol12_avg = (precision_lr_scol12[0] + precision_lr_scol12[1] + precision_lr_scol12[2] + precision_lr_scol12[3] + precision_lr_scol12[4] + precision_lr_scol12[5] + precision_lr_scol12[6] + precision_lr_scol12[7] + precision_lr_scol12[8] + precision_lr_scol12[9]) / 10
precision_dt_scol12_avg = (precision_dt_scol12[0] + precision_dt_scol12[1] + precision_dt_scol12[2] + precision_dt_scol12[3] + precision_dt_scol12[4] + precision_dt_scol12[5] + precision_dt_scol12[6] + precision_dt_scol12[7] + precision_dt_scol12[8] + precision_dt_scol12[9]) / 10
precision_rf_scol12_avg = (precision_rf_scol12[0] + precision_rf_scol12[1] + precision_rf_scol12[2] + precision_rf_scol12[3] + precision_rf_scol12[4] + precision_rf_scol12[5] + precision_rf_scol12[6] + precision_rf_scol12[7] + precision_rf_scol12[8] + precision_rf_scol12[9]) / 10
precision_nb_scol12_avg = (precision_nb_scol12[0] + precision_nb_scol12[1] + precision_nb_scol12[2] + precision_nb_scol12[3] + precision_nb_scol12[4] + precision_nb_scol12[5] + precision_nb_scol12[6] + precision_nb_scol12[7] + precision_nb_scol12[8] + precision_nb_scol12[9]) / 10
precision_xg_scol12_avg = (precision_xg_scol12[0] + precision_xg_scol12[1] + precision_xg_scol12[2] + precision_xg_scol12[3] + precision_xg_scol12[4] + precision_xg_scol12[5] + precision_xg_scol12[6] + precision_xg_scol12[7] + precision_xg_scol12[8] + precision_xg_scol12[9]) / 10

recall_lr_scol12_avg = (recall_lr_scol12[0] + recall_lr_scol12[1] + recall_lr_scol12[2] + recall_lr_scol12[3] + recall_lr_scol12[4] + recall_lr_scol12[5] + recall_lr_scol12[6] + recall_lr_scol12[7] + recall_lr_scol12[8] + recall_lr_scol12[9]) / 10
recall_dt_scol12_avg = (recall_dt_scol12[0] + recall_dt_scol12[1] + recall_dt_scol12[2] + recall_dt_scol12[3] + recall_dt_scol12[4] + recall_dt_scol12[5] + recall_dt_scol12[6] + recall_dt_scol12[7] + recall_dt_scol12[8] + recall_dt_scol12[9]) / 10
recall_rf_scol12_avg = (recall_rf_scol12[0] + recall_rf_scol12[1] + recall_rf_scol12[2] + recall_rf_scol12[3] + recall_rf_scol12[4] + recall_rf_scol12[5] + recall_rf_scol12[6] + recall_rf_scol12[7] + recall_rf_scol12[8] + recall_rf_scol12[9]) / 10
recall_nb_scol12_avg = (recall_nb_scol12[0] + recall_nb_scol12[1] + recall_nb_scol12[2] + recall_nb_scol12[3] + recall_nb_scol12[4] + recall_nb_scol12[5] + recall_nb_scol12[6] + recall_nb_scol12[7] + recall_nb_scol12[8] + recall_nb_scol12[9]) / 10
recall_xg_scol12_avg = (recall_xg_scol12[0] + recall_xg_scol12[1] + recall_xg_scol12[2] + recall_xg_scol12[3] + recall_xg_scol12[4] + recall_xg_scol12[5] + recall_xg_scol12[6] + recall_xg_scol12[7] + recall_xg_scol12[8] + recall_xg_scol12[9]) / 10
'''

precision_lr_scol12_avg = (precision_lr_scol12[0] + precision_lr_scol12[1] + precision_lr_scol12[2] + precision_lr_scol12[3] + precision_lr_scol12[4]) / 5
precision_dt_scol12_avg = (precision_dt_scol12[0] + precision_dt_scol12[1] + precision_dt_scol12[2] + precision_dt_scol12[3] + precision_dt_scol12[4]) / 5
precision_rf_scol12_avg = (precision_rf_scol12[0] + precision_rf_scol12[1] + precision_rf_scol12[2] + precision_rf_scol12[3] + precision_rf_scol12[4]) / 5
precision_nb_scol12_avg = (precision_nb_scol12[0] + precision_nb_scol12[1] + precision_nb_scol12[2] + precision_nb_scol12[3] + precision_nb_scol12[4]) / 5
precision_xg_scol12_avg = (precision_xg_scol12[0] + precision_xg_scol12[1] + precision_xg_scol12[2] + precision_xg_scol12[3] + precision_xg_scol12[4]) / 5

recall_lr_scol12_avg = (recall_lr_scol12[0] + recall_lr_scol12[1] + recall_lr_scol12[2] + recall_lr_scol12[3] + recall_lr_scol12[4]) / 5
recall_dt_scol12_avg = (recall_dt_scol12[0] + recall_dt_scol12[1] + recall_dt_scol12[2] + recall_dt_scol12[3] + recall_dt_scol12[4]) / 5
recall_rf_scol12_avg = (recall_rf_scol12[0] + recall_rf_scol12[1] + recall_rf_scol12[2] + recall_rf_scol12[3] + recall_rf_scol12[4]) / 5
recall_nb_scol12_avg = (recall_nb_scol12[0] + recall_nb_scol12[1] + recall_nb_scol12[2] + recall_nb_scol12[3] + recall_nb_scol12[4]) / 5
recall_xg_scol12_avg = (recall_xg_scol12[0] + recall_xg_scol12[1] + recall_xg_scol12[2] + recall_xg_scol12[3] + recall_xg_scol12[4]) / 5

# Test Size #14 - 70%

probs_lr_scol13 = []
f1_lr_scol13 = []
rocauc_lr_scol13 = []
recall_lr_scol13 = []
precision_lr_scol13 = []
accuracy_lr_scol13 = []

probs_dt_scol13 = []
f1_dt_scol13 = []
rocauc_dt_scol13 = []
recall_dt_scol13 = []
precision_dt_scol13 = []
accuracy_dt_scol13 = []

probs_nb_scol13 = []
f1_nb_scol13 = []
rocauc_nb_scol13 = []
recall_nb_scol13 = []
precision_nb_scol13 = []
accuracy_nb_scol13 = []

probs_xg_scol13 = []
f1_xg_scol13 = []
rocauc_xg_scol13 = []
recall_xg_scol13 = []
precision_xg_scol13 = []
accuracy_xg_scol13 = []

probs_rf_scol13 = []
f1_rf_scol13 = []
rocauc_rf_scol13 = []
recall_rf_scol13 = []
precision_rf_scol13 = []
accuracy_rf_scol13 = []

tfidf_vect13 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train13 = tfidf_vect13.fit_transform(x27.values)
tfidf_test13=tfidf_vect13.transform(x28.values)
print(tfidf_train13.shape)
print(tfidf_test13.shape)
#tfidf_train13.toarray()

x_tfidf13 = tfidf_vect13.fit_transform(df14["lemmatized"])
x_ros13, y_ros13 = ros.fit_resample(x_tfidf13, df14["label"])

# train_values13 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values13 = 1 - train_values13
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.136, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros13, y_ros13, train_size=i, stratify=y_ros13)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol13.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol13.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol13.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol13.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol13.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol13.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df14_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol13.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol13.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol13.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol13.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol13.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol13.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df14_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol13.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol13.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol13.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol13.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol13.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol13.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df14_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol13.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol13.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol13.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol13.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol13.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol13.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df14_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol13.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol13.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol13.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol13.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol13.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol13.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df14_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df14_l, ":", probs_lr_scol13)
    print("Array of F1 Scores LR-ROS:", df14_l, ":", f1_lr_scol13)
    print("Array of ROCAUC Scores LR-ROS:", df14_l, ":", rocauc_lr_scol13)
    print("Array of Recall Scores LR-ROS:", df14_l, ":", recall_lr_scol13)
    print("Array of Precision Scores LR-ROS:", df14_l, ":", precision_lr_scol13)
    print("Array of Accuracy Scores LR-ROS:", df14_l, ":", accuracy_lr_scol13)

    print("Array of Prob Scores DT-ROS:", df14_l, ":", probs_dt_scol13)
    print("Array of F1 Scores DT-ROS:", df14_l, ":", f1_dt_scol13)
    print("Array of ROCAUC Scores DT-ROS:", df14_l, ":", rocauc_dt_scol13)
    print("Array of Recall Scores DT-ROS:", df14_l, ":", recall_dt_scol13)
    print("Array of Precision Scores DT-ROS:", df14_l, ":", precision_dt_scol13)
    print("Array of Accuracy Scores DT-ROS:", df14_l, ":", accuracy_dt_scol13)

    print("Array of Prob Scores NB-ROS:", df14_l, ":", probs_nb_scol13)
    print("Array of F1 Scores NB-ROS:", df14_l, ":", f1_nb_scol13)
    print("Array of ROCAUC Scores NB-ROS:", df14_l, ":", rocauc_nb_scol13)
    print("Array of Recall Scores NB-ROS:", df14_l, ":", recall_nb_scol13)
    print("Array of Precision Scores NB-ROS:", df14_l, ":", precision_nb_scol13)
    print("Array of Accuracy Scores NB-ROS:", df14_l, ":", accuracy_nb_scol13)

    print("Array of Prob Scores XG-ROS:", df14_l, ":", probs_xg_scol13)
    print("Array of F1 Scores XG-ROS:", df14_l, ":", f1_xg_scol13)
    print("Array of ROCAUC Scores XG-ROS:", df14_l, ":", rocauc_xg_scol13)
    print("Array of Recall Scores XG-ROS:", df14_l, ":", recall_xg_scol13)
    print("Array of Precision Scores XG-ROS:", df14_l, ":", precision_xg_scol13)
    print("Array of Accuracy Scores XG-ROS:", df14_l, ":", accuracy_xg_scol13)

    print("Array of Prob Scores RF-ROS:", df14_l, ":", probs_rf_scol13)
    print("Array of F1 Scores RF-ROS:", df14_l, ":", f1_rf_scol13)
    print("Array of ROCAUC Scores RF-ROS:", df14_l, ":", rocauc_rf_scol13)
    print("Array of Recall Scores RF-ROS:", df14_l, ":", recall_rf_scol13)
    print("Array of Precision Scores RF-ROS:", df14_l, ":", precision_rf_scol13)
    print("Array of Accuracy Scores RF-ROS:", df14_l, ":", accuracy_rf_scol13)

year13 = [ args.group for t in range(25)]
sampling13 =['Oversampling' for t in range(25)]
technique13 = ['ROS' for t in range(25)]
classifier_names13 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num13 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num13 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num13 = [precision_lr_scol13, precision_dt_scol13, precision_nb_scol13, precision_xg_scol13, precision_rf_scol13]
recall_csv_num13 = [recall_lr_scol13, recall_dt_scol13, recall_nb_scol13, recall_xg_scol13, recall_xg_scol13]
auc_csv_num13 = [rocauc_lr_scol13, rocauc_dt_scol13, rocauc_nb_scol13, rocauc_xg_scol13, rocauc_rf_scol13]
accuracy_csv_num13 = [accuracy_lr_scol13, accuracy_dt_scol13, accuracy_nb_scol13, accuracy_xg_scol13, accuracy_rf_scol13]
import itertools
rounds = 5
p13 = itertools.cycle(classifier_names13)
o13 = itertools.cycle(test_sizes_num13)
k13 = itertools.cycle(train_sizes_num13)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv13 = [next(p13) for _ in range(rounds)] * 5
test_size_csv13 = [a for b in test_sizes_num13 for a in (b,)*5]
train_size_csv13 = [c for d in train_sizes_num13 for c in (d,)*5]
split_csv13 = ['14' for u in range(25)]
train_csv13 = ['70%' for u in range(25)]
precision_csv13 = list(chain(*precision_csv_num13))
recall_csv13 = list(chain(*recall_csv_num13))
auc_csv13 = list(chain(*auc_csv_num13))
accuracy_csv13 = list(chain(*accuracy_csv_num13))
csv_data13 = [year13, sampling13, technique13, classifier_csv13, test_size_csv13, train_size_csv13, split_csv13, train_csv13, precision_csv13,
            recall_csv13, auc_csv13, accuracy_csv13]
export_data13 = zip_longest(*csv_data13, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data13)

'''
# Preicsion - #14 test size
#precision_nea131b = list([precision_lr_scol13[0], precision_dt_scol13[0], precision_rf_scol13[0], precision_nb_scol13[0], precision_xg_scol13[0]])
precision_nea131 = list([test_sizes[13], precision_xg_scol13[0], precision_rf_scol13[0], precision_dt_scol13[0], precision_lr_scol13[0], precision_nb_scol13[0]])
#precision_nea131 = list([(test_sizes[13] - test_sizes[13]), (0.0 + precision_rf_scol13[0]), (1.0 + precision_xg_scol13[0]),(2.0 + precision_dt_scol13[0]), (3.0 + precision_lr_scol13[0]), (4.0 + precision_nb_scol13[0])])
print("Iteration 1 Array:", precision_nea131)
# precision_nea132 = list([precision_lr_scol13[1], precision_dt_scol13[1], precision_rf_scol13[1], precision_nb_scol13[1], precision_xg_scol13[1]])
precision_nea132 = list([test_sizes[13], precision_xg_scol13[1], precision_rf_scol13[1], precision_dt_scol13[1],  precision_lr_scol13[1], precision_nb_scol13[1]])
#precision_nea132 = list([(test_sizes[13] - test_sizes[13]), (0.0 + precision_rf_scol13[1]), (1.0 + precision_xg_scol13[1]),(2.0 + precision_dt_scol13[1]), (3.0 + precision_lr_scol13[1]), (4.0 + precision_nb_scol13[1])])
print("Iteration 2 Array:", precision_nea132)
precision_nea133 = list([test_sizes[13], precision_lr_scol13[2], precision_dt_scol13[2], precision_rf_scol13[2], precision_nb_scol13[2], precision_xg_scol13[2]] )
precision_nea134 = list([test_sizes[13], precision_lr_scol13[3], precision_dt_scol13[3], precision_rf_scol13[3], precision_nb_scol13[3], precision_xg_scol13[3]] )
precision_nea135 = list([test_sizes[13], precision_lr_scol13[4], precision_dt_scol13[4], precision_rf_scol13[4], precision_nb_scol13[4], precision_xg_scol13[4]] )
precision_nea136 = list([test_sizes[13], precision_lr_scol13[5], precision_dt_scol13[5], precision_rf_scol13[5], precision_nb_scol13[5], precision_xg_scol13[5]] )
precision_nea137 = list([test_sizes[13], precision_lr_scol13[6], precision_dt_scol13[6], precision_rf_scol13[6], precision_nb_scol13[6], precision_xg_scol13[6]] )
precision_nea138 = list([test_sizes[13], precision_lr_scol13[7], precision_dt_scol13[7], precision_rf_scol13[7], precision_nb_scol13[7], precision_xg_scol13[7]] )
precision_nea139 = list([test_sizes[13], precision_lr_scol13[8], precision_dt_scol13[8], precision_rf_scol13[8], precision_nb_scol13[8], precision_xg_scol13[8]] )
precision_nea140 = list([test_sizes[13], precision_lr_scol13[9], precision_dt_scol13[9], precision_rf_scol13[9], precision_nb_scol13[9], precision_xg_scol13[9]] )

# Recall - 10 test size
#recall_nea131b = list([recall_lr_scol13[0], recall_dt_scol13[0], recall_rf_scol13[0], recall_nb_scol13[0], recall_xg_scol13[0]])
recall_nea131 = list([test_sizes[13], recall_xg_scol13[0], recall_rf_scol13[0], recall_dt_scol13[0], recall_lr_scol13[0], recall_nb_scol13[0]])
# recall_nea131 = list([(test_sizes[13] - test_sizes[13]), (0.0 + recall_rf_scol13[0]), (1.0 + recall_xg_scol13[0]),(2.0 + recall_dt_scol13[0]), (3.0 + recall_lr_scol13[0]), (4.0 + recall_nb_scol13[0])])
print("Iteration 1 Array:", recall_nea131)
# recall_nea132 = list([recall_lr_scol13[1], recall_dt_scol13[1], recall_rf_scol13[1], recall_nb_scol13[1], recall_xg_scol13[1]])
recall_nea132 = list([test_sizes[13], recall_xg_scol13[1], recall_rf_scol13[1], recall_dt_scol13[1],  recall_lr_scol13[1], recall_nb_scol13[1]])
#recall_nea132 = list([(test_sizes[13] - test_sizes[13]), (0.0 + recall_rf_scol13[1]), (1.0 + recall_xg_scol13[1]),(2.0 + recall_dt_scol13[1]), (3.0 + recall_lr_scol13[1]), (4.0 + recall_nb_scol13[1])])
print("Iteration 2 Array:", recall_nea132)

recall_nea133 = list([test_sizes[13], recall_lr_scol13[2], recall_dt_scol13[2], recall_rf_scol13[2], recall_nb_scol13[2], recall_xg_scol13[2]] )
recall_nea134 = list([test_sizes[13], recall_lr_scol13[3], recall_dt_scol13[3], recall_rf_scol13[3], recall_nb_scol13[3], recall_xg_scol13[3]] )
recall_nea135 = list([test_sizes[13], recall_lr_scol13[4], recall_dt_scol13[4], recall_rf_scol13[4], recall_nb_scol13[4], recall_xg_scol13[4]] )
recall_nea136 = list([test_sizes[13], recall_lr_scol13[5], recall_dt_scol13[5], recall_rf_scol13[5], recall_nb_scol13[5], recall_xg_scol13[5]] )
recall_nea137 = list([test_sizes[13], recall_lr_scol13[6], recall_dt_scol13[6], recall_rf_scol13[6], recall_nb_scol13[6], recall_xg_scol13[6]] )
recall_nea138 = list([test_sizes[13], recall_lr_scol13[7], recall_dt_scol13[7], recall_rf_scol13[7], recall_nb_scol13[7], recall_xg_scol13[7]] )
recall_nea139 = list([test_sizes[13], recall_lr_scol13[8], recall_dt_scol13[8], recall_rf_scol13[8], recall_nb_scol13[8], recall_xg_scol13[8]] )
recall_nea140 = list([test_sizes[13], recall_lr_scol13[9], recall_dt_scol13[9], recall_rf_scol13[9], recall_nb_scol13[9], recall_xg_scol13[9]] )


precision_lr_scol13_avg = (precision_lr_scol13[0] + precision_lr_scol13[1] + precision_lr_scol13[2] + precision_lr_scol13[3] + precision_lr_scol13[4] + precision_lr_scol13[5] + precision_lr_scol13[6] + precision_lr_scol13[7] + precision_lr_scol13[8] + precision_lr_scol13[9]) / 10
precision_dt_scol13_avg = (precision_dt_scol13[0] + precision_dt_scol13[1] + precision_dt_scol13[2] + precision_dt_scol13[3] + precision_dt_scol13[4] + precision_dt_scol13[5] + precision_dt_scol13[6] + precision_dt_scol13[7] + precision_dt_scol13[8] + precision_dt_scol13[9]) / 10
precision_rf_scol13_avg = (precision_rf_scol13[0] + precision_rf_scol13[1] + precision_rf_scol13[2] + precision_rf_scol13[3] + precision_rf_scol13[4] + precision_rf_scol13[5] + precision_rf_scol13[6] + precision_rf_scol13[7] + precision_rf_scol13[8] + precision_rf_scol13[9]) / 10
precision_nb_scol13_avg = (precision_nb_scol13[0] + precision_nb_scol13[1] + precision_nb_scol13[2] + precision_nb_scol13[3] + precision_nb_scol13[4] + precision_nb_scol13[5] + precision_nb_scol13[6] + precision_nb_scol13[7] + precision_nb_scol13[8] + precision_nb_scol13[9]) / 10
precision_xg_scol13_avg = (precision_xg_scol13[0] + precision_xg_scol13[1] + precision_xg_scol13[2] + precision_xg_scol13[3] + precision_xg_scol13[4] + precision_xg_scol13[5] + precision_xg_scol13[6] + precision_xg_scol13[7] + precision_xg_scol13[8] + precision_xg_scol13[9]) / 10

recall_lr_scol13_avg = (recall_lr_scol13[0] + recall_lr_scol13[1] + recall_lr_scol13[2] + recall_lr_scol13[3] + recall_lr_scol13[4] + recall_lr_scol13[5] + recall_lr_scol13[6] + recall_lr_scol13[7] + recall_lr_scol13[8] + recall_lr_scol13[9]) / 10
recall_dt_scol13_avg = (recall_dt_scol13[0] + recall_dt_scol13[1] + recall_dt_scol13[2] + recall_dt_scol13[3] + recall_dt_scol13[4] + recall_dt_scol13[5] + recall_dt_scol13[6] + recall_dt_scol13[7] + recall_dt_scol13[8] + recall_dt_scol13[9]) / 10
recall_rf_scol13_avg = (recall_rf_scol13[0] + recall_rf_scol13[1] + recall_rf_scol13[2] + recall_rf_scol13[3] + recall_rf_scol13[4] + recall_rf_scol13[5] + recall_rf_scol13[6] + recall_rf_scol13[7] + recall_rf_scol13[8] + recall_rf_scol13[9]) / 10
recall_nb_scol13_avg = (recall_nb_scol13[0] + recall_nb_scol13[1] + recall_nb_scol13[2] + recall_nb_scol13[3] + recall_nb_scol13[4] + recall_nb_scol13[5] + recall_nb_scol13[6] + recall_nb_scol13[7] + recall_nb_scol13[8] + recall_nb_scol13[9]) / 10
recall_xg_scol13_avg = (recall_xg_scol13[0] + recall_xg_scol13[1] + recall_xg_scol13[2] + recall_xg_scol13[3] + recall_xg_scol13[4] + recall_xg_scol13[5] + recall_xg_scol13[6] + recall_xg_scol13[7] + recall_xg_scol13[8] + recall_xg_scol13[9]) / 10
'''

precision_lr_scol13_avg = (precision_lr_scol13[0] + precision_lr_scol13[1] + precision_lr_scol13[2] + precision_lr_scol13[3] + precision_lr_scol13[4]) / 5
precision_dt_scol13_avg = (precision_dt_scol13[0] + precision_dt_scol13[1] + precision_dt_scol13[2] + precision_dt_scol13[3] + precision_dt_scol13[4]) / 5
precision_rf_scol13_avg = (precision_rf_scol13[0] + precision_rf_scol13[1] + precision_rf_scol13[2] + precision_rf_scol13[3] + precision_rf_scol13[4]) / 5
precision_nb_scol13_avg = (precision_nb_scol13[0] + precision_nb_scol13[1] + precision_nb_scol13[2] + precision_nb_scol13[3] + precision_nb_scol13[4]) / 5
precision_xg_scol13_avg = (precision_xg_scol13[0] + precision_xg_scol13[1] + precision_xg_scol13[2] + precision_xg_scol13[3] + precision_xg_scol13[4]) / 5

recall_lr_scol13_avg = (recall_lr_scol13[0] + recall_lr_scol13[1] + recall_lr_scol13[2] + recall_lr_scol13[3] + recall_lr_scol13[4]) / 5
recall_dt_scol13_avg = (recall_dt_scol13[0] + recall_dt_scol13[1] + recall_dt_scol13[2] + recall_dt_scol13[3] + recall_dt_scol13[4]) / 5
recall_rf_scol13_avg = (recall_rf_scol13[0] + recall_rf_scol13[1] + recall_rf_scol13[2] + recall_rf_scol13[3] + recall_rf_scol13[4]) / 5
recall_nb_scol13_avg = (recall_nb_scol13[0] + recall_nb_scol13[1] + recall_nb_scol13[2] + recall_nb_scol13[3] + recall_nb_scol13[4]) / 5
recall_xg_scol13_avg = (recall_xg_scol13[0] + recall_xg_scol13[1] + recall_xg_scol13[2] + recall_xg_scol13[3] + recall_xg_scol13[4]) / 5

# Test Size #15 - 75%

probs_lr_scol14 = []
f1_lr_scol14 = []
rocauc_lr_scol14 = []
recall_lr_scol14 = []
precision_lr_scol14 = []
accuracy_lr_scol14 = []

probs_dt_scol14 = []
f1_dt_scol14 = []
rocauc_dt_scol14 = []
recall_dt_scol14 = []
precision_dt_scol14 = []
accuracy_dt_scol14 = []

probs_nb_scol14 = []
f1_nb_scol14 = []
rocauc_nb_scol14 = []
recall_nb_scol14 = []
precision_nb_scol14 = []
accuracy_nb_scol14 = []

probs_xg_scol14 = []
f1_xg_scol14 = []
rocauc_xg_scol14 = []
recall_xg_scol14 = []
precision_xg_scol14 = []
accuracy_xg_scol14 = []

probs_rf_scol14 = []
f1_rf_scol14 = []
rocauc_rf_scol14 = []
recall_rf_scol14 = []
precision_rf_scol14 = []
accuracy_rf_scol14 = []

tfidf_vect14 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train14 = tfidf_vect14.fit_transform(x29.values)
tfidf_test14=tfidf_vect14.transform(x30.values)
print(tfidf_train14.shape)
print(tfidf_test14.shape)
#tfidf_train14.toarray()

x_tfidf14 = tfidf_vect14.fit_transform(df15["lemmatized"])
x_ros14, y_ros14 = ros.fit_resample(x_tfidf14, df15["label"])

# train_values14 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values14 = 1 - train_values14
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros14, y_ros14, train_size=i, stratify=y_ros14)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol14.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol14.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol14.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol14.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol14.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol14.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df15_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol14.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol14.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol14.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol14.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol14.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol14.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df15_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol14.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol14.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol14.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol14.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol14.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol14.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df15_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol14.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol14.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol14.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol14.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol14.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol14.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df15_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol14.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol14.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol14.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol14.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol14.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol14.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df15_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df15_l, ":", probs_lr_scol14)
    print("Array of F1 Scores LR-ROS:", df15_l, ":", f1_lr_scol14)
    print("Array of ROCAUC Scores LR-ROS:", df15_l, ":", rocauc_lr_scol14)
    print("Array of Recall Scores LR-ROS:", df15_l, ":", recall_lr_scol14)
    print("Array of Precision Scores LR-ROS:", df15_l, ":", precision_lr_scol14)
    print("Array of Accuracy Scores LR-ROS:", df15_l, ":", accuracy_lr_scol14)

    print("Array of Prob Scores DT-ROS:", df15_l, ":", probs_dt_scol14)
    print("Array of F1 Scores DT-ROS:", df15_l, ":", f1_dt_scol14)
    print("Array of ROCAUC Scores DT-ROS:", df15_l, ":", rocauc_dt_scol14)
    print("Array of Recall Scores DT-ROS:", df15_l, ":", recall_dt_scol14)
    print("Array of Precision Scores DT-ROS:", df15_l, ":", precision_dt_scol14)
    print("Array of Accuracy Scores DT-ROS:", df15_l, ":", accuracy_dt_scol14)

    print("Array of Prob Scores NB-ROS:", df15_l, ":", probs_nb_scol14)
    print("Array of F1 Scores NB-ROS:", df15_l, ":", f1_nb_scol14)
    print("Array of ROCAUC Scores NB-ROS:", df15_l, ":", rocauc_nb_scol14)
    print("Array of Recall Scores NB-ROS:", df15_l, ":", recall_nb_scol14)
    print("Array of Precision Scores NB-ROS:", df15_l, ":", precision_nb_scol14)
    print("Array of Accuracy Scores NB-ROS:", df15_l, ":", accuracy_nb_scol14)

    print("Array of Prob Scores XG-ROS:", df15_l, ":", probs_xg_scol14)
    print("Array of F1 Scores XG-ROS:", df15_l, ":", f1_xg_scol14)
    print("Array of ROCAUC Scores XG-ROS:", df15_l, ":", rocauc_xg_scol14)
    print("Array of Recall Scores XG-ROS:", df15_l, ":", recall_xg_scol14)
    print("Array of Precision Scores XG-ROS:", df15_l, ":", precision_xg_scol14)
    print("Array of Accuracy Scores XG-ROS:", df15_l, ":", accuracy_xg_scol14)

    print("Array of Prob Scores RF-ROS:", df15_l, ":", probs_rf_scol14)
    print("Array of F1 Scores RF-ROS:", df15_l, ":", f1_rf_scol14)
    print("Array of ROCAUC Scores RF-ROS:", df15_l, ":", rocauc_rf_scol14)
    print("Array of Recall Scores RF-ROS:", df15_l, ":", recall_rf_scol14)
    print("Array of Precision Scores RF-ROS:", df15_l, ":", precision_rf_scol14)
    print("Array of Accuracy Scores RF-ROS:", df15_l, ":", accuracy_rf_scol14)

year14 = [ args.group for t in range(25)]
sampling14 =['Oversampling' for t in range(25)]
technique14 = ['ROS' for t in range(25)]
classifier_names14 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num14 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num14 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num14 = [precision_lr_scol14, precision_dt_scol14, precision_nb_scol14, precision_xg_scol14, precision_rf_scol14]
recall_csv_num14 = [recall_lr_scol14, recall_dt_scol14, recall_nb_scol14, recall_xg_scol14, recall_xg_scol14]
auc_csv_num14 = [rocauc_lr_scol14, rocauc_dt_scol14, rocauc_nb_scol14, rocauc_xg_scol14, rocauc_rf_scol14]
accuracy_csv_num14 = [accuracy_lr_scol14, accuracy_dt_scol14, accuracy_nb_scol14, accuracy_xg_scol14, accuracy_rf_scol14]
import itertools
rounds = 5
p14 = itertools.cycle(classifier_names14)
o14 = itertools.cycle(test_sizes_num14)
k14 = itertools.cycle(train_sizes_num14)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv14 = [next(p14) for _ in range(rounds)] * 5
test_size_csv14 = [a for b in test_sizes_num14 for a in (b,)*5]
train_size_csv14 = [c for d in train_sizes_num14 for c in (d,)*5]
split_csv14 = ['15' for u in range(25)]
train_csv14 = ['75%' for u in range(25)]
precision_csv14 = list(chain(*precision_csv_num14))
recall_csv14 = list(chain(*recall_csv_num14))
auc_csv14 = list(chain(*auc_csv_num14))
accuracy_csv14 = list(chain(*accuracy_csv_num14))
csv_data14 = [year14, sampling14, technique14, classifier_csv14, test_size_csv14, train_size_csv14, split_csv14, train_csv14, precision_csv14,
            recall_csv14, auc_csv14, accuracy_csv14]
export_data14 = zip_longest(*csv_data14, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data14)

'''
# Preicsion - #15 test size
#precision_nea141b = list([precision_lr_scol14[0], precision_dt_scol14[0], precision_rf_scol14[0], precision_nb_scol14[0], precision_xg_scol14[0]])
precision_nea141 = list([test_sizes[14], precision_xg_scol14[0], precision_rf_scol14[0], precision_dt_scol14[0], precision_lr_scol14[0], precision_nb_scol14[0]])
#precision_nea141 = list([(test_sizes[14] - test_sizes[14]), (0.0 + precision_rf_scol14[0]), (1.0 + precision_xg_scol14[0]),(2.0 + precision_dt_scol14[0]), (3.0 + precision_lr_scol14[0]), (4.0 + precision_nb_scol14[0])])
print("Iteration 1 Array:", precision_nea141)
# precision_nea142 = list([precision_lr_scol14[1], precision_dt_scol14[1], precision_rf_scol14[1], precision_nb_scol14[1], precision_xg_scol14[1]])
precision_nea142 = list([test_sizes[14], precision_xg_scol14[1], precision_rf_scol14[1], precision_dt_scol14[1],  precision_lr_scol14[1], precision_nb_scol14[1]])
#precision_nea142 = list([(test_sizes[14] - test_sizes[14]), (0.0 + precision_rf_scol14[1]), (1.0 + precision_xg_scol14[1]),(2.0 + precision_dt_scol14[1]), (3.0 + precision_lr_scol14[1]), (4.0 + precision_nb_scol14[1])])
print("Iteration 2 Array:", precision_nea142)
precision_nea143 = list([test_sizes[14], precision_lr_scol14[2], precision_dt_scol14[2], precision_rf_scol14[2], precision_nb_scol14[2], precision_xg_scol14[2]] )
precision_nea144 = list([test_sizes[14], precision_lr_scol14[3], precision_dt_scol14[3], precision_rf_scol14[3], precision_nb_scol14[3], precision_xg_scol14[3]] )
precision_nea145 = list([test_sizes[14], precision_lr_scol14[4], precision_dt_scol14[4], precision_rf_scol14[4], precision_nb_scol14[4], precision_xg_scol14[4]] )
precision_nea146 = list([test_sizes[14], precision_lr_scol14[5], precision_dt_scol14[5], precision_rf_scol14[5], precision_nb_scol14[5], precision_xg_scol14[5]] )
precision_nea147 = list([test_sizes[14], precision_lr_scol14[6], precision_dt_scol14[6], precision_rf_scol14[6], precision_nb_scol14[6], precision_xg_scol14[6]] )
precision_nea148 = list([test_sizes[14], precision_lr_scol14[7], precision_dt_scol14[7], precision_rf_scol14[7], precision_nb_scol14[7], precision_xg_scol14[7]] )
precision_nea149 = list([test_sizes[14], precision_lr_scol14[8], precision_dt_scol14[8], precision_rf_scol14[8], precision_nb_scol14[8], precision_xg_scol14[8]] )
precision_nea150 = list([test_sizes[14], precision_lr_scol14[9], precision_dt_scol14[9], precision_rf_scol14[9], precision_nb_scol14[9], precision_xg_scol14[9]] )

# Recall - 10 test size
#recall_nea141b = list([recall_lr_scol14[0], recall_dt_scol14[0], recall_rf_scol14[0], recall_nb_scol14[0], recall_xg_scol14[0]])
recall_nea141 = list([test_sizes[14], recall_xg_scol14[0], recall_rf_scol14[0], recall_dt_scol14[0], recall_lr_scol14[0], recall_nb_scol14[0]])
# recall_nea141 = list([(test_sizes[14] - test_sizes[14]), (0.0 + recall_rf_scol14[0]), (1.0 + recall_xg_scol14[0]),(2.0 + recall_dt_scol14[0]), (3.0 + recall_lr_scol14[0]), (4.0 + recall_nb_scol14[0])])
print("Iteration 1 Array:", recall_nea141)
# recall_nea142 = list([recall_lr_scol14[1], recall_dt_scol14[1], recall_rf_scol14[1], recall_nb_scol14[1], recall_xg_scol14[1]])
recall_nea142 = list([test_sizes[14], recall_xg_scol14[1], recall_rf_scol14[1], recall_dt_scol14[1],  recall_lr_scol14[1], recall_nb_scol14[1]])
#recall_nea142 = list([(test_sizes[14] - test_sizes[14]), (0.0 + recall_rf_scol14[1]), (1.0 + recall_xg_scol14[1]),(2.0 + recall_dt_scol14[1]), (3.0 + recall_lr_scol14[1]), (4.0 + recall_nb_scol14[1])])
print("Iteration 2 Array:", recall_nea142)

recall_nea143 = list([test_sizes[14], recall_lr_scol14[2], recall_dt_scol14[2], recall_rf_scol14[2], recall_nb_scol14[2], recall_xg_scol14[2]] )
recall_nea144 = list([test_sizes[14], recall_lr_scol14[3], recall_dt_scol14[3], recall_rf_scol14[3], recall_nb_scol14[3], recall_xg_scol14[3]] )
recall_nea145 = list([test_sizes[14], recall_lr_scol14[4], recall_dt_scol14[4], recall_rf_scol14[4], recall_nb_scol14[4], recall_xg_scol14[4]] )
recall_nea146 = list([test_sizes[14], recall_lr_scol14[5], recall_dt_scol14[5], recall_rf_scol14[5], recall_nb_scol14[5], recall_xg_scol14[5]] )
recall_nea147 = list([test_sizes[14], recall_lr_scol14[6], recall_dt_scol14[6], recall_rf_scol14[6], recall_nb_scol14[6], recall_xg_scol14[6]] )
recall_nea148 = list([test_sizes[14], recall_lr_scol14[7], recall_dt_scol14[7], recall_rf_scol14[7], recall_nb_scol14[7], recall_xg_scol14[7]] )
recall_nea149 = list([test_sizes[14], recall_lr_scol14[8], recall_dt_scol14[8], recall_rf_scol14[8], recall_nb_scol14[8], recall_xg_scol14[8]] )
recall_nea150 = list([test_sizes[14], recall_lr_scol14[9], recall_dt_scol14[9], recall_rf_scol14[9], recall_nb_scol14[9], recall_xg_scol14[9]] )


precision_lr_scol14_avg = (precision_lr_scol14[0] + precision_lr_scol14[1] + precision_lr_scol14[2] + precision_lr_scol14[3] + precision_lr_scol14[4] + precision_lr_scol14[5] + precision_lr_scol14[6] + precision_lr_scol14[7] + precision_lr_scol14[8] + precision_lr_scol14[9]) / 10
precision_dt_scol14_avg = (precision_dt_scol14[0] + precision_dt_scol14[1] + precision_dt_scol14[2] + precision_dt_scol14[3] + precision_dt_scol14[4] + precision_dt_scol14[5] + precision_dt_scol14[6] + precision_dt_scol14[7] + precision_dt_scol14[8] + precision_dt_scol14[9]) / 10
precision_rf_scol14_avg = (precision_rf_scol14[0] + precision_rf_scol14[1] + precision_rf_scol14[2] + precision_rf_scol14[3] + precision_rf_scol14[4] + precision_rf_scol14[5] + precision_rf_scol14[6] + precision_rf_scol14[7] + precision_rf_scol14[8] + precision_rf_scol14[9]) / 10
precision_nb_scol14_avg = (precision_nb_scol14[0] + precision_nb_scol14[1] + precision_nb_scol14[2] + precision_nb_scol14[3] + precision_nb_scol14[4] + precision_nb_scol14[5] + precision_nb_scol14[6] + precision_nb_scol14[7] + precision_nb_scol14[8] + precision_nb_scol14[9]) / 10
precision_xg_scol14_avg = (precision_xg_scol14[0] + precision_xg_scol14[1] + precision_xg_scol14[2] + precision_xg_scol14[3] + precision_xg_scol14[4] + precision_xg_scol14[5] + precision_xg_scol14[6] + precision_xg_scol14[7] + precision_xg_scol14[8] + precision_xg_scol14[9]) / 10

recall_lr_scol14_avg = (recall_lr_scol14[0] + recall_lr_scol14[1] + recall_lr_scol14[2] + recall_lr_scol14[3] + recall_lr_scol14[4] + recall_lr_scol14[5] + recall_lr_scol14[6] + recall_lr_scol14[7] + recall_lr_scol14[8] + recall_lr_scol14[9]) / 10
recall_dt_scol14_avg = (recall_dt_scol14[0] + recall_dt_scol14[1] + recall_dt_scol14[2] + recall_dt_scol14[3] + recall_dt_scol14[4] + recall_dt_scol14[5] + recall_dt_scol14[6] + recall_dt_scol14[7] + recall_dt_scol14[8] + recall_dt_scol14[9]) / 10
recall_rf_scol14_avg = (recall_rf_scol14[0] + recall_rf_scol14[1] + recall_rf_scol14[2] + recall_rf_scol14[3] + recall_rf_scol14[4] + recall_rf_scol14[5] + recall_rf_scol14[6] + recall_rf_scol14[7] + recall_rf_scol14[8] + recall_rf_scol14[9]) / 10
recall_nb_scol14_avg = (recall_nb_scol14[0] + recall_nb_scol14[1] + recall_nb_scol14[2] + recall_nb_scol14[3] + recall_nb_scol14[4] + recall_nb_scol14[5] + recall_nb_scol14[6] + recall_nb_scol14[7] + recall_nb_scol14[8] + recall_nb_scol14[9]) / 10
recall_xg_scol14_avg = (recall_xg_scol14[0] + recall_xg_scol14[1] + recall_xg_scol14[2] + recall_xg_scol14[3] + recall_xg_scol14[4] + recall_xg_scol14[5] + recall_xg_scol14[6] + recall_xg_scol14[7] + recall_xg_scol14[8] + recall_xg_scol14[9]) / 10
'''

precision_lr_scol14_avg = (precision_lr_scol14[0] + precision_lr_scol14[1] + precision_lr_scol14[2] + precision_lr_scol14[3] + precision_lr_scol14[4]) / 5
precision_dt_scol14_avg = (precision_dt_scol14[0] + precision_dt_scol14[1] + precision_dt_scol14[2] + precision_dt_scol14[3] + precision_dt_scol14[4]) / 5
precision_rf_scol14_avg = (precision_rf_scol14[0] + precision_rf_scol14[1] + precision_rf_scol14[2] + precision_rf_scol14[3] + precision_rf_scol14[4]) / 5
precision_nb_scol14_avg = (precision_nb_scol14[0] + precision_nb_scol14[1] + precision_nb_scol14[2] + precision_nb_scol14[3] + precision_nb_scol14[4]) / 5
precision_xg_scol14_avg = (precision_xg_scol14[0] + precision_xg_scol14[1] + precision_xg_scol14[2] + precision_xg_scol14[3] + precision_xg_scol14[4]) / 5

recall_lr_scol14_avg = (recall_lr_scol14[0] + recall_lr_scol14[1] + recall_lr_scol14[2] + recall_lr_scol14[3] + recall_lr_scol14[4]) / 5
recall_dt_scol14_avg = (recall_dt_scol14[0] + recall_dt_scol14[1] + recall_dt_scol14[2] + recall_dt_scol14[3] + recall_dt_scol14[4]) / 5
recall_rf_scol14_avg = (recall_rf_scol14[0] + recall_rf_scol14[1] + recall_rf_scol14[2] + recall_rf_scol14[3] + recall_rf_scol14[4]) / 5
recall_nb_scol14_avg = (recall_nb_scol14[0] + recall_nb_scol14[1] + recall_nb_scol14[2] + recall_nb_scol14[3] + recall_nb_scol14[4]) / 5
recall_xg_scol14_avg = (recall_xg_scol14[0] + recall_xg_scol14[1] + recall_xg_scol14[2] + recall_xg_scol14[3] + recall_xg_scol14[4]) / 5

# Test Size #16 - 80%

probs_lr_scol15 = []
f1_lr_scol15 = []
rocauc_lr_scol15 = []
recall_lr_scol15 = []
precision_lr_scol15 = []
accuracy_lr_scol15 = []

probs_dt_scol15 = []
f1_dt_scol15 = []
rocauc_dt_scol15 = []
recall_dt_scol15 = []
precision_dt_scol15 = []
accuracy_dt_scol15 = []

probs_nb_scol15 = []
f1_nb_scol15 = []
rocauc_nb_scol15 = []
recall_nb_scol15 = []
precision_nb_scol15 = []
accuracy_nb_scol15 = []

probs_xg_scol15 = []
f1_xg_scol15 = []
rocauc_xg_scol15 = []
recall_xg_scol15 = []
precision_xg_scol15 = []
accuracy_xg_scol15 = []

probs_rf_scol15 = []
f1_rf_scol15 = []
rocauc_rf_scol15 = []
recall_rf_scol15 = []
precision_rf_scol15 = []
accuracy_rf_scol15 = []

tfidf_vect15 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train15 = tfidf_vect15.fit_transform(x31.values)
tfidf_test15=tfidf_vect15.transform(x32.values)
print(tfidf_train15.shape)
print(tfidf_test15.shape)
#tfidf_train15.toarray()

x_tfidf15 = tfidf_vect15.fit_transform(df16["lemmatized"])
x_ros15, y_ros15 = ros.fit_resample(x_tfidf15, df16["label"])

# train_values15 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values15 = 1 - train_values15
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros15, y_ros15, train_size=i, stratify=y_ros15)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol15.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol15.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol15.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol15.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol15.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol15.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df16_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol15.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol15.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol15.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol15.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol15.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol15.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df16_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol15.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol15.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol15.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol15.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol15.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol15.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df16_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol15.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol15.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol15.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol15.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol15.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol15.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df16_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol15.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol15.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol15.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol15.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol15.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol15.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df16_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df16_l, ":", probs_lr_scol15)
    print("Array of F1 Scores LR-ROS:", df16_l, ":", f1_lr_scol15)
    print("Array of ROCAUC Scores LR-ROS:", df16_l, ":", rocauc_lr_scol15)
    print("Array of Recall Scores LR-ROS:", df16_l, ":", recall_lr_scol15)
    print("Array of Precision Scores LR-ROS:", df16_l, ":", precision_lr_scol15)
    print("Array of Accuracy Scores LR-ROS:", df16_l, ":", accuracy_lr_scol15)

    print("Array of Prob Scores DT-ROS:", df16_l, ":", probs_dt_scol15)
    print("Array of F1 Scores DT-ROS:", df16_l, ":", f1_dt_scol15)
    print("Array of ROCAUC Scores DT-ROS:", df16_l, ":", rocauc_dt_scol15)
    print("Array of Recall Scores DT-ROS:", df16_l, ":", recall_dt_scol15)
    print("Array of Precision Scores DT-ROS:", df16_l, ":", precision_dt_scol15)
    print("Array of Accuracy Scores DT-ROS:", df16_l, ":", accuracy_dt_scol15)

    print("Array of Prob Scores NB-ROS:", df16_l, ":", probs_nb_scol15)
    print("Array of F1 Scores NB-ROS:", df16_l, ":", f1_nb_scol15)
    print("Array of ROCAUC Scores NB-ROS:", df16_l, ":", rocauc_nb_scol15)
    print("Array of Recall Scores NB-ROS:", df16_l, ":", recall_nb_scol15)
    print("Array of Precision Scores NB-ROS:", df16_l, ":", precision_nb_scol15)
    print("Array of Accuracy Scores NB-ROS:", df16_l, ":", accuracy_nb_scol15)

    print("Array of Prob Scores XG-ROS:", df16_l, ":", probs_xg_scol15)
    print("Array of F1 Scores XG-ROS:", df16_l, ":", f1_xg_scol15)
    print("Array of ROCAUC Scores XG-ROS:", df16_l, ":", rocauc_xg_scol15)
    print("Array of Recall Scores XG-ROS:", df16_l, ":", recall_xg_scol15)
    print("Array of Precision Scores XG-ROS:", df16_l, ":", precision_xg_scol15)
    print("Array of Accuracy Scores XG-ROS:", df16_l, ":", accuracy_xg_scol15)

    print("Array of Prob Scores RF-ROS:", df16_l, ":", probs_rf_scol15)
    print("Array of F1 Scores RF-ROS:", df16_l, ":", f1_rf_scol15)
    print("Array of ROCAUC Scores RF-ROS:", df16_l, ":", rocauc_rf_scol15)
    print("Array of Recall Scores RF-ROS:", df16_l, ":", recall_rf_scol15)
    print("Array of Precision Scores RF-ROS:", df16_l, ":", precision_rf_scol15)
    print("Array of Accuracy Scores RF-ROS:", df16_l, ":", accuracy_rf_scol15)
    

year15 = [ args.group for t in range(25)]
sampling15 = ['Oversampling' for t in range(25)]
technique15 = ['ROS' for t in range(25)]
classifier_names15 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num15 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num15 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num15 = [precision_lr_scol15, precision_dt_scol15, precision_nb_scol15, precision_xg_scol15, precision_rf_scol15]
recall_csv_num15 = [recall_lr_scol15, recall_dt_scol15, recall_nb_scol15, recall_xg_scol15, recall_xg_scol15]
auc_csv_num15 = [rocauc_lr_scol15, rocauc_dt_scol15, rocauc_nb_scol15, rocauc_xg_scol15, rocauc_rf_scol15]
accuracy_csv_num15 = [accuracy_lr_scol15, accuracy_dt_scol15, accuracy_nb_scol15, accuracy_xg_scol15, accuracy_rf_scol15]
import itertools
rounds = 5
p15 = itertools.cycle(classifier_names15)
o15 = itertools.cycle(test_sizes_num15)
k15 = itertools.cycle(train_sizes_num15)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv15 = [next(p15) for _ in range(rounds)] * 5
test_size_csv15 = [a for b in test_sizes_num15 for a in (b,)*5]
train_size_csv15 = [c for d in train_sizes_num15 for c in (d,)*5]
split_csv15 = ['16' for u in range(25)]
train_csv15 = ['80%' for u in range(25)]
precision_csv15 = list(chain(*precision_csv_num15))
recall_csv15 = list(chain(*recall_csv_num15))
auc_csv15 = list(chain(*auc_csv_num15))
accuracy_csv15 = list(chain(*accuracy_csv_num15))
csv_data15 = [year15, sampling15, technique15, classifier_csv15, test_size_csv15, train_size_csv15, split_csv15, train_csv15, precision_csv15,
            recall_csv15, auc_csv15, accuracy_csv15]
export_data15 = zip_longest(*csv_data15, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data15)

'''
# Preicsion - #16 test size
#precision_nea151b = list([precision_lr_scol15[0], precision_dt_scol15[0], precision_rf_scol15[0], precision_nb_scol15[0], precision_xg_scol15[0]])
precision_nea151 = list([test_sizes[15], precision_xg_scol15[0], precision_rf_scol15[0], precision_dt_scol15[0], precision_lr_scol15[0], precision_nb_scol15[0]])
#precision_nea151 = list([(test_sizes[15] - test_sizes[15]), (0.0 + precision_rf_scol15[0]), (1.0 + precision_xg_scol15[0]),(2.0 + precision_dt_scol15[0]), (3.0 + precision_lr_scol15[0]), (4.0 + precision_nb_scol15[0])])
print("Iteration 1 Array:", precision_nea151)
# precision_nea152 = list([precision_lr_scol15[1], precision_dt_scol15[1], precision_rf_scol15[1], precision_nb_scol15[1], precision_xg_scol15[1]])
precision_nea152 = list([test_sizes[15], precision_xg_scol15[1], precision_rf_scol15[1], precision_dt_scol15[1],  precision_lr_scol15[1], precision_nb_scol15[1]])
#precision_nea152 = list([(test_sizes[15] - test_sizes[15]), (0.0 + precision_rf_scol15[1]), (1.0 + precision_xg_scol15[1]),(2.0 + precision_dt_scol15[1]), (3.0 + precision_lr_scol15[1]), (4.0 + precision_nb_scol15[1])])
print("Iteration 2 Array:", precision_nea152)
precision_nea153 = list([test_sizes[15], precision_lr_scol15[2], precision_dt_scol15[2], precision_rf_scol15[2], precision_nb_scol15[2], precision_xg_scol15[2]] )
precision_nea154 = list([test_sizes[15], precision_lr_scol15[3], precision_dt_scol15[3], precision_rf_scol15[3], precision_nb_scol15[3], precision_xg_scol15[3]] )
precision_nea155 = list([test_sizes[15], precision_lr_scol15[4], precision_dt_scol15[4], precision_rf_scol15[4], precision_nb_scol15[4], precision_xg_scol15[4]] )
precision_nea156 = list([test_sizes[15], precision_lr_scol15[5], precision_dt_scol15[5], precision_rf_scol15[5], precision_nb_scol15[5], precision_xg_scol15[5]] )
precision_nea157 = list([test_sizes[15], precision_lr_scol15[6], precision_dt_scol15[6], precision_rf_scol15[6], precision_nb_scol15[6], precision_xg_scol15[6]] )
precision_nea158 = list([test_sizes[15], precision_lr_scol15[7], precision_dt_scol15[7], precision_rf_scol15[7], precision_nb_scol15[7], precision_xg_scol15[7]] )
precision_nea159 = list([test_sizes[15], precision_lr_scol15[8], precision_dt_scol15[8], precision_rf_scol15[8], precision_nb_scol15[8], precision_xg_scol15[8]] )
precision_nea160 = list([test_sizes[15], precision_lr_scol15[9], precision_dt_scol15[9], precision_rf_scol15[9], precision_nb_scol15[9], precision_xg_scol15[9]] )

# Recall - 10 test size
#recall_nea151b = list([recall_lr_scol15[0], recall_dt_scol15[0], recall_rf_scol15[0], recall_nb_scol15[0], recall_xg_scol15[0]])
recall_nea151 = list([test_sizes[15], recall_xg_scol15[0], recall_rf_scol15[0], recall_dt_scol15[0], recall_lr_scol15[0], recall_nb_scol15[0]])
# recall_nea151 = list([(test_sizes[15] - test_sizes[15]), (0.0 + recall_rf_scol15[0]), (1.0 + recall_xg_scol15[0]),(2.0 + recall_dt_scol15[0]), (3.0 + recall_lr_scol15[0]), (4.0 + recall_nb_scol15[0])])
print("Iteration 1 Array:", recall_nea151)
# recall_nea152 = list([recall_lr_scol15[1], recall_dt_scol15[1], recall_rf_scol15[1], recall_nb_scol15[1], recall_xg_scol15[1]])
recall_nea152 = list([test_sizes[15], recall_xg_scol15[1], recall_rf_scol15[1], recall_dt_scol15[1],  recall_lr_scol15[1], recall_nb_scol15[1]])
#recall_nea152 = list([(test_sizes[15] - test_sizes[15]), (0.0 + recall_rf_scol15[1]), (1.0 + recall_xg_scol15[1]),(2.0 + recall_dt_scol15[1]), (3.0 + recall_lr_scol15[1]), (4.0 + recall_nb_scol15[1])])
print("Iteration 2 Array:", recall_nea152)

recall_nea153 = list([test_sizes[15], recall_lr_scol15[2], recall_dt_scol15[2], recall_rf_scol15[2], recall_nb_scol15[2], recall_xg_scol15[2]] )
recall_nea154 = list([test_sizes[15], recall_lr_scol15[3], recall_dt_scol15[3], recall_rf_scol15[3], recall_nb_scol15[3], recall_xg_scol15[3]] )
recall_nea155 = list([test_sizes[15], recall_lr_scol15[4], recall_dt_scol15[4], recall_rf_scol15[4], recall_nb_scol15[4], recall_xg_scol15[4]] )
recall_nea156 = list([test_sizes[15], recall_lr_scol15[5], recall_dt_scol15[5], recall_rf_scol15[5], recall_nb_scol15[5], recall_xg_scol15[5]] )
recall_nea157 = list([test_sizes[15], recall_lr_scol15[6], recall_dt_scol15[6], recall_rf_scol15[6], recall_nb_scol15[6], recall_xg_scol15[6]] )
recall_nea158 = list([test_sizes[15], recall_lr_scol15[7], recall_dt_scol15[7], recall_rf_scol15[7], recall_nb_scol15[7], recall_xg_scol15[7]] )
recall_nea159 = list([test_sizes[15], recall_lr_scol15[8], recall_dt_scol15[8], recall_rf_scol15[8], recall_nb_scol15[8], recall_xg_scol15[8]] )
recall_nea160 = list([test_sizes[15], recall_lr_scol15[9], recall_dt_scol15[9], recall_rf_scol15[9], recall_nb_scol15[9], recall_xg_scol15[9]] )


precision_lr_scol15_avg = (precision_lr_scol15[0] + precision_lr_scol15[1] + precision_lr_scol15[2] + precision_lr_scol15[3] + precision_lr_scol15[4] + precision_lr_scol15[5] + precision_lr_scol15[6] + precision_lr_scol15[7] + precision_lr_scol15[8] + precision_lr_scol15[9]) / 10
precision_dt_scol15_avg = (precision_dt_scol15[0] + precision_dt_scol15[1] + precision_dt_scol15[2] + precision_dt_scol15[3] + precision_dt_scol15[4] + precision_dt_scol15[5] + precision_dt_scol15[6] + precision_dt_scol15[7] + precision_dt_scol15[8] + precision_dt_scol15[9]) / 10
precision_rf_scol15_avg = (precision_rf_scol15[0] + precision_rf_scol15[1] + precision_rf_scol15[2] + precision_rf_scol15[3] + precision_rf_scol15[4] + precision_rf_scol15[5] + precision_rf_scol15[6] + precision_rf_scol15[7] + precision_rf_scol15[8] + precision_rf_scol15[9]) / 10
precision_nb_scol15_avg = (precision_nb_scol15[0] + precision_nb_scol15[1] + precision_nb_scol15[2] + precision_nb_scol15[3] + precision_nb_scol15[4] + precision_nb_scol15[5] + precision_nb_scol15[6] + precision_nb_scol15[7] + precision_nb_scol15[8] + precision_nb_scol15[9]) / 10
precision_xg_scol15_avg = (precision_xg_scol15[0] + precision_xg_scol15[1] + precision_xg_scol15[2] + precision_xg_scol15[3] + precision_xg_scol15[4] + precision_xg_scol15[5] + precision_xg_scol15[6] + precision_xg_scol15[7] + precision_xg_scol15[8] + precision_xg_scol15[9]) / 10

recall_lr_scol15_avg = (recall_lr_scol15[0] + recall_lr_scol15[1] + recall_lr_scol15[2] + recall_lr_scol15[3] + recall_lr_scol15[4] + recall_lr_scol15[5] + recall_lr_scol15[6] + recall_lr_scol15[7] + recall_lr_scol15[8] + recall_lr_scol15[9]) / 10
recall_dt_scol15_avg = (recall_dt_scol15[0] + recall_dt_scol15[1] + recall_dt_scol15[2] + recall_dt_scol15[3] + recall_dt_scol15[4] + recall_dt_scol15[5] + recall_dt_scol15[6] + recall_dt_scol15[7] + recall_dt_scol15[8] + recall_dt_scol15[9]) / 10
recall_rf_scol15_avg = (recall_rf_scol15[0] + recall_rf_scol15[1] + recall_rf_scol15[2] + recall_rf_scol15[3] + recall_rf_scol15[4] + recall_rf_scol15[5] + recall_rf_scol15[6] + recall_rf_scol15[7] + recall_rf_scol15[8] + recall_rf_scol15[9]) / 10
recall_nb_scol15_avg = (recall_nb_scol15[0] + recall_nb_scol15[1] + recall_nb_scol15[2] + recall_nb_scol15[3] + recall_nb_scol15[4] + recall_nb_scol15[5] + recall_nb_scol15[6] + recall_nb_scol15[7] + recall_nb_scol15[8] + recall_nb_scol15[9]) / 10
recall_xg_scol15_avg = (recall_xg_scol15[0] + recall_xg_scol15[1] + recall_xg_scol15[2] + recall_xg_scol15[3] + recall_xg_scol15[4] + recall_xg_scol15[5] + recall_xg_scol15[6] + recall_xg_scol15[7] + recall_xg_scol15[8] + recall_xg_scol15[9]) / 10
'''

precision_lr_scol15_avg = (precision_lr_scol15[0] + precision_lr_scol15[1] + precision_lr_scol15[2] + precision_lr_scol15[3] + precision_lr_scol15[4]) / 5
precision_dt_scol15_avg = (precision_dt_scol15[0] + precision_dt_scol15[1] + precision_dt_scol15[2] + precision_dt_scol15[3] + precision_dt_scol15[4]) / 5
precision_rf_scol15_avg = (precision_rf_scol15[0] + precision_rf_scol15[1] + precision_rf_scol15[2] + precision_rf_scol15[3] + precision_rf_scol15[4]) / 5
precision_nb_scol15_avg = (precision_nb_scol15[0] + precision_nb_scol15[1] + precision_nb_scol15[2] + precision_nb_scol15[3] + precision_nb_scol15[4]) / 5
precision_xg_scol15_avg = (precision_xg_scol15[0] + precision_xg_scol15[1] + precision_xg_scol15[2] + precision_xg_scol15[3] + precision_xg_scol15[4]) / 5

recall_lr_scol15_avg = (recall_lr_scol15[0] + recall_lr_scol15[1] + recall_lr_scol15[2] + recall_lr_scol15[3] + recall_lr_scol15[4]) / 5
recall_dt_scol15_avg = (recall_dt_scol15[0] + recall_dt_scol15[1] + recall_dt_scol15[2] + recall_dt_scol15[3] + recall_dt_scol15[4]) / 5
recall_rf_scol15_avg = (recall_rf_scol15[0] + recall_rf_scol15[1] + recall_rf_scol15[2] + recall_rf_scol15[3] + recall_rf_scol15[4]) / 5
recall_nb_scol15_avg = (recall_nb_scol15[0] + recall_nb_scol15[1] + recall_nb_scol15[2] + recall_nb_scol15[3] + recall_nb_scol15[4]) / 5
recall_xg_scol15_avg = (recall_xg_scol15[0] + recall_xg_scol15[1] + recall_xg_scol15[2] + recall_xg_scol15[3] + recall_xg_scol15[4]) / 5

# Test Size #17 - 85%

probs_lr_scol16 = []
f1_lr_scol16 = []
rocauc_lr_scol16 = []
recall_lr_scol16 = []
precision_lr_scol16 = []
accuracy_lr_scol16 = []

probs_dt_scol16 = []
f1_dt_scol16 = []
rocauc_dt_scol16 = []
recall_dt_scol16 = []
precision_dt_scol16 = []
accuracy_dt_scol16 = []

probs_nb_scol16 = []
f1_nb_scol16 = []
rocauc_nb_scol16 = []
recall_nb_scol16 = []
precision_nb_scol16 = []
accuracy_nb_scol16 = []

probs_xg_scol16 = []
f1_xg_scol16 = []
rocauc_xg_scol16 = []
recall_xg_scol16 = []
precision_xg_scol16 = []
accuracy_xg_scol16 = []

probs_rf_scol16 = []
f1_rf_scol16 = []
rocauc_rf_scol16 = []
recall_rf_scol16 = []
precision_rf_scol16 = []
accuracy_rf_scol16 = []

tfidf_vect16 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train16 = tfidf_vect16.fit_transform(x33.values)
tfidf_test16=tfidf_vect16.transform(x34.values)
print(tfidf_train16.shape)
print(tfidf_test16.shape)
#tfidf_train16.toarray()

x_tfidf16 = tfidf_vect16.fit_transform(df17["lemmatized"])
x_ros16, y_ros16 = ros.fit_resample(x_tfidf16, df17["label"])

# train_values16 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values16 = 1 - train_values16
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros16, y_ros16, train_size=i, stratify=y_ros16)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol16.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol16.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol16.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol16.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol16.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol16.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df17_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol16.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol16.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol16.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol16.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol16.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol16.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df17_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol16.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol16.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol16.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol16.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol16.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol16.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df17_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol16.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol16.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol16.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol16.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol16.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol16.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df17_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol16.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol16.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol16.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol16.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol16.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol16.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df17_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df17_l, ":", probs_lr_scol16)
    print("Array of F1 Scores LR-ROS:", df17_l, ":", f1_lr_scol16)
    print("Array of ROCAUC Scores LR-ROS:", df17_l, ":", rocauc_lr_scol16)
    print("Array of Recall Scores LR-ROS:", df17_l, ":", recall_lr_scol16)
    print("Array of Precision Scores LR-ROS:", df17_l, ":", precision_lr_scol16)
    print("Array of Accuracy Scores LR-ROS:", df17_l, ":", accuracy_lr_scol16)

    print("Array of Prob Scores DT-ROS:", df17_l, ":", probs_dt_scol16)
    print("Array of F1 Scores DT-ROS:", df17_l, ":", f1_dt_scol16)
    print("Array of ROCAUC Scores DT-ROS:", df17_l, ":", rocauc_dt_scol16)
    print("Array of Recall Scores DT-ROS:", df17_l, ":", recall_dt_scol16)
    print("Array of Precision Scores DT-ROS:", df17_l, ":", precision_dt_scol16)
    print("Array of Accuracy Scores DT-ROS:", df17_l, ":", accuracy_dt_scol16)

    print("Array of Prob Scores NB-ROS:", df17_l, ":", probs_nb_scol16)
    print("Array of F1 Scores NB-ROS:", df17_l, ":", f1_nb_scol16)
    print("Array of ROCAUC Scores NB-ROS:", df17_l, ":", rocauc_nb_scol16)
    print("Array of Recall Scores NB-ROS:", df17_l, ":", recall_nb_scol16)
    print("Array of Precision Scores NB-ROS:", df17_l, ":", precision_nb_scol16)
    print("Array of Accuracy Scores NB-ROS:", df17_l, ":", accuracy_nb_scol16)

    print("Array of Prob Scores XG-ROS:", df17_l, ":", probs_xg_scol16)
    print("Array of F1 Scores XG-ROS:", df17_l, ":", f1_xg_scol16)
    print("Array of ROCAUC Scores XG-ROS:", df17_l, ":", rocauc_xg_scol16)
    print("Array of Recall Scores XG-ROS:", df17_l, ":", recall_xg_scol16)
    print("Array of Precision Scores XG-ROS:", df17_l, ":", precision_xg_scol16)
    print("Array of Accuracy Scores XG-ROS:", df17_l, ":", accuracy_xg_scol16)

    print("Array of Prob Scores RF-ROS:", df17_l, ":", probs_rf_scol16)
    print("Array of F1 Scores RF-ROS:", df17_l, ":", f1_rf_scol16)
    print("Array of ROCAUC Scores RF-ROS:", df17_l, ":", rocauc_rf_scol16)
    print("Array of Recall Scores RF-ROS:", df17_l, ":", recall_rf_scol16)
    print("Array of Precision Scores RF-ROS:", df17_l, ":", precision_rf_scol16)
    print("Array of Accuracy Scores RF-ROS:", df17_l, ":", accuracy_rf_scol16)
    

year16 = [ args.group for t in range(25)]
sampling16 = ['Oversampling' for t in range(25)]
technique16 = ['ROS' for t in range(25)]
classifier_names16 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num16 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num16 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num16 = [precision_lr_scol16, precision_dt_scol16, precision_nb_scol16, precision_xg_scol16, precision_rf_scol16]
recall_csv_num16 = [recall_lr_scol16, recall_dt_scol16, recall_nb_scol16, recall_xg_scol16, recall_xg_scol16]
auc_csv_num16 = [rocauc_lr_scol16, rocauc_dt_scol16, rocauc_nb_scol16, rocauc_xg_scol16, rocauc_rf_scol16]
accuracy_csv_num16 = [accuracy_lr_scol16, accuracy_dt_scol16, accuracy_nb_scol16, accuracy_xg_scol16, accuracy_rf_scol16]
import itertools
rounds = 5
p16 = itertools.cycle(classifier_names16)
o16 = itertools.cycle(test_sizes_num16)
k16 = itertools.cycle(train_sizes_num16)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv16 = [next(p16) for _ in range(rounds)] * 5
test_size_csv16 = [a for b in test_sizes_num16 for a in (b,)*5]
train_size_csv16 = [c for d in train_sizes_num16 for c in (d,)*5]
split_csv16 = ['17' for u in range(25)]
train_csv16 = ['85%' for u in range(25)]
precision_csv16 = list(chain(*precision_csv_num16))
recall_csv16 = list(chain(*recall_csv_num16))
auc_csv16 = list(chain(*auc_csv_num16))
accuracy_csv16 = list(chain(*accuracy_csv_num16))
csv_data16 = [year16, sampling16, technique16, classifier_csv16, test_size_csv16, train_size_csv16, split_csv16, train_csv16, precision_csv16,
            recall_csv16, auc_csv16, accuracy_csv16]
export_data16 = zip_longest(*csv_data16, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data16)
'''
# Preicsion - #17 test size
#precision_nea161b = list([precision_lr_scol16[0], precision_dt_scol16[0], precision_rf_scol16[0], precision_nb_scol16[0], precision_xg_scol16[0]])
precision_nea161 = list([test_sizes[16], precision_xg_scol16[0], precision_rf_scol16[0], precision_dt_scol16[0], precision_lr_scol16[0], precision_nb_scol16[0]])
#precision_nea161 = list([(test_sizes[16] - test_sizes[16]), (0.0 + precision_rf_scol16[0]), (1.0 + precision_xg_scol16[0]),(2.0 + precision_dt_scol16[0]), (3.0 + precision_lr_scol16[0]), (4.0 + precision_nb_scol16[0])])
print("Iteration 1 Array:", precision_nea161)
# precision_nea162 = list([precision_lr_scol16[1], precision_dt_scol16[1], precision_rf_scol16[1], precision_nb_scol16[1], precision_xg_scol16[1]])
precision_nea162 = list([test_sizes[16], precision_xg_scol16[1], precision_rf_scol16[1], precision_dt_scol16[1],  precision_lr_scol16[1], precision_nb_scol16[1]])
#precision_nea162 = list([(test_sizes[16] - test_sizes[16]), (0.0 + precision_rf_scol16[1]), (1.0 + precision_xg_scol16[1]),(2.0 + precision_dt_scol16[1]), (3.0 + precision_lr_scol16[1]), (4.0 + precision_nb_scol16[1])])
print("Iteration 2 Array:", precision_nea162)
precision_nea163 = list([test_sizes[16], precision_lr_scol16[2], precision_dt_scol16[2], precision_rf_scol16[2], precision_nb_scol16[2], precision_xg_scol16[2]] )
precision_nea164 = list([test_sizes[16], precision_lr_scol16[3], precision_dt_scol16[3], precision_rf_scol16[3], precision_nb_scol16[3], precision_xg_scol16[3]] )
precision_nea165 = list([test_sizes[16], precision_lr_scol16[4], precision_dt_scol16[4], precision_rf_scol16[4], precision_nb_scol16[4], precision_xg_scol16[4]] )
precision_nea166 = list([test_sizes[16], precision_lr_scol16[5], precision_dt_scol16[5], precision_rf_scol16[5], precision_nb_scol16[5], precision_xg_scol16[5]] )
precision_nea167 = list([test_sizes[16], precision_lr_scol16[6], precision_dt_scol16[6], precision_rf_scol16[6], precision_nb_scol16[6], precision_xg_scol16[6]] )
precision_nea168 = list([test_sizes[16], precision_lr_scol16[7], precision_dt_scol16[7], precision_rf_scol16[7], precision_nb_scol16[7], precision_xg_scol16[7]] )
precision_nea169 = list([test_sizes[16], precision_lr_scol16[8], precision_dt_scol16[8], precision_rf_scol16[8], precision_nb_scol16[8], precision_xg_scol16[8]] )
precision_nea170 = list([test_sizes[16], precision_lr_scol16[9], precision_dt_scol16[9], precision_rf_scol16[9], precision_nb_scol16[9], precision_xg_scol16[9]] )

# Recall - 17 test size
#recall_nea161b = list([recall_lr_scol16[0], recall_dt_scol16[0], recall_rf_scol16[0], recall_nb_scol16[0], recall_xg_scol16[0]])
recall_nea161 = list([test_sizes[16], recall_xg_scol16[0], recall_rf_scol16[0], recall_dt_scol16[0], recall_lr_scol16[0], recall_nb_scol16[0]])
# recall_nea161 = list([(test_sizes[16] - test_sizes[16]), (0.0 + recall_rf_scol16[0]), (1.0 + recall_xg_scol16[0]),(2.0 + recall_dt_scol16[0]), (3.0 + recall_lr_scol16[0]), (4.0 + recall_nb_scol16[0])])
print("Iteration 1 Array:", recall_nea161)
# recall_nea162 = list([recall_lr_scol16[1], recall_dt_scol16[1], recall_rf_scol16[1], recall_nb_scol16[1], recall_xg_scol16[1]])
recall_nea162 = list([test_sizes[16], recall_xg_scol16[1], recall_rf_scol16[1], recall_dt_scol16[1],  recall_lr_scol16[1], recall_nb_scol16[1]])
#recall_nea162 = list([(test_sizes[16] - test_sizes[16]), (0.0 + recall_rf_scol16[1]), (1.0 + recall_xg_scol16[1]),(2.0 + recall_dt_scol16[1]), (3.0 + recall_lr_scol16[1]), (4.0 + recall_nb_scol16[1])])
print("Iteration 2 Array:", recall_nea162)

recall_nea163 = list([test_sizes[16], recall_lr_scol16[2], recall_dt_scol16[2], recall_rf_scol16[2], recall_nb_scol16[2], recall_xg_scol16[2]] )
recall_nea164 = list([test_sizes[16], recall_lr_scol16[3], recall_dt_scol16[3], recall_rf_scol16[3], recall_nb_scol16[3], recall_xg_scol16[3]] )
recall_nea165 = list([test_sizes[16], recall_lr_scol16[4], recall_dt_scol16[4], recall_rf_scol16[4], recall_nb_scol16[4], recall_xg_scol16[4]] )
recall_nea166 = list([test_sizes[16], recall_lr_scol16[5], recall_dt_scol16[5], recall_rf_scol16[5], recall_nb_scol16[5], recall_xg_scol16[5]] )
recall_nea167 = list([test_sizes[16], recall_lr_scol16[6], recall_dt_scol16[6], recall_rf_scol16[6], recall_nb_scol16[6], recall_xg_scol16[6]] )
recall_nea168 = list([test_sizes[16], recall_lr_scol16[7], recall_dt_scol16[7], recall_rf_scol16[7], recall_nb_scol16[7], recall_xg_scol16[7]] )
recall_nea169 = list([test_sizes[16], recall_lr_scol16[8], recall_dt_scol16[8], recall_rf_scol16[8], recall_nb_scol16[8], recall_xg_scol16[8]] )
recall_nea170 = list([test_sizes[16], recall_lr_scol16[9], recall_dt_scol16[9], recall_rf_scol16[9], recall_nb_scol16[9], recall_xg_scol16[9]] )


precision_lr_scol16_avg = (precision_lr_scol16[0] + precision_lr_scol16[1] + precision_lr_scol16[2] + precision_lr_scol16[3] + precision_lr_scol16[4] + precision_lr_scol16[5] + precision_lr_scol16[6] + precision_lr_scol16[7] + precision_lr_scol16[8] + precision_lr_scol16[9]) / 10
precision_dt_scol16_avg = (precision_dt_scol16[0] + precision_dt_scol16[1] + precision_dt_scol16[2] + precision_dt_scol16[3] + precision_dt_scol16[4] + precision_dt_scol16[5] + precision_dt_scol16[6] + precision_dt_scol16[7] + precision_dt_scol16[8] + precision_dt_scol16[9]) / 10
precision_rf_scol16_avg = (precision_rf_scol16[0] + precision_rf_scol16[1] + precision_rf_scol16[2] + precision_rf_scol16[3] + precision_rf_scol16[4] + precision_rf_scol16[5] + precision_rf_scol16[6] + precision_rf_scol16[7] + precision_rf_scol16[8] + precision_rf_scol16[9]) / 10
precision_nb_scol16_avg = (precision_nb_scol16[0] + precision_nb_scol16[1] + precision_nb_scol16[2] + precision_nb_scol16[3] + precision_nb_scol16[4] + precision_nb_scol16[5] + precision_nb_scol16[6] + precision_nb_scol16[7] + precision_nb_scol16[8] + precision_nb_scol16[9]) / 10
precision_xg_scol16_avg = (precision_xg_scol16[0] + precision_xg_scol16[1] + precision_xg_scol16[2] + precision_xg_scol16[3] + precision_xg_scol16[4] + precision_xg_scol16[5] + precision_xg_scol16[6] + precision_xg_scol16[7] + precision_xg_scol16[8] + precision_xg_scol16[9]) / 10

recall_lr_scol16_avg = (recall_lr_scol16[0] + recall_lr_scol16[1] + recall_lr_scol16[2] + recall_lr_scol16[3] + recall_lr_scol16[4] + recall_lr_scol16[5] + recall_lr_scol16[6] + recall_lr_scol16[7] + recall_lr_scol16[8] + recall_lr_scol16[9]) / 10
recall_dt_scol16_avg = (recall_dt_scol16[0] + recall_dt_scol16[1] + recall_dt_scol16[2] + recall_dt_scol16[3] + recall_dt_scol16[4] + recall_dt_scol16[5] + recall_dt_scol16[6] + recall_dt_scol16[7] + recall_dt_scol16[8] + recall_dt_scol16[9]) / 10
recall_rf_scol16_avg = (recall_rf_scol16[0] + recall_rf_scol16[1] + recall_rf_scol16[2] + recall_rf_scol16[3] + recall_rf_scol16[4] + recall_rf_scol16[5] + recall_rf_scol16[6] + recall_rf_scol16[7] + recall_rf_scol16[8] + recall_rf_scol16[9]) / 10
recall_nb_scol16_avg = (recall_nb_scol16[0] + recall_nb_scol16[1] + recall_nb_scol16[2] + recall_nb_scol16[3] + recall_nb_scol16[4] + recall_nb_scol16[5] + recall_nb_scol16[6] + recall_nb_scol16[7] + recall_nb_scol16[8] + recall_nb_scol16[9]) / 10
recall_xg_scol16_avg = (recall_xg_scol16[0] + recall_xg_scol16[1] + recall_xg_scol16[2] + recall_xg_scol16[3] + recall_xg_scol16[4] + recall_xg_scol16[5] + recall_xg_scol16[6] + recall_xg_scol16[7] + recall_xg_scol16[8] + recall_xg_scol16[9]) / 10
'''

precision_lr_scol16_avg = (precision_lr_scol16[0] + precision_lr_scol16[1] + precision_lr_scol16[2] + precision_lr_scol16[3] + precision_lr_scol16[4]) / 5
precision_dt_scol16_avg = (precision_dt_scol16[0] + precision_dt_scol16[1] + precision_dt_scol16[2] + precision_dt_scol16[3] + precision_dt_scol16[4]) / 5
precision_rf_scol16_avg = (precision_rf_scol16[0] + precision_rf_scol16[1] + precision_rf_scol16[2] + precision_rf_scol16[3] + precision_rf_scol16[4]) / 5
precision_nb_scol16_avg = (precision_nb_scol16[0] + precision_nb_scol16[1] + precision_nb_scol16[2] + precision_nb_scol16[3] + precision_nb_scol16[4]) / 5
precision_xg_scol16_avg = (precision_xg_scol16[0] + precision_xg_scol16[1] + precision_xg_scol16[2] + precision_xg_scol16[3] + precision_xg_scol16[4]) / 5

recall_lr_scol16_avg = (recall_lr_scol16[0] + recall_lr_scol16[1] + recall_lr_scol16[2] + recall_lr_scol16[3] + recall_lr_scol16[4]) / 5
recall_dt_scol16_avg = (recall_dt_scol16[0] + recall_dt_scol16[1] + recall_dt_scol16[2] + recall_dt_scol16[3] + recall_dt_scol16[4]) / 5
recall_rf_scol16_avg = (recall_rf_scol16[0] + recall_rf_scol16[1] + recall_rf_scol16[2] + recall_rf_scol16[3] + recall_rf_scol16[4]) / 5
recall_nb_scol16_avg = (recall_nb_scol16[0] + recall_nb_scol16[1] + recall_nb_scol16[2] + recall_nb_scol16[3] + recall_nb_scol16[4]) / 5
recall_xg_scol16_avg = (recall_xg_scol16[0] + recall_xg_scol16[1] + recall_xg_scol16[2] + recall_xg_scol16[3] + recall_xg_scol16[4]) / 5

# Test Size #18 - 90%

probs_lr_scol17 = []
f1_lr_scol17 = []
rocauc_lr_scol17 = []
recall_lr_scol17 = []
precision_lr_scol17 = []
accuracy_lr_scol17 = []

probs_dt_scol17 = []
f1_dt_scol17 = []
rocauc_dt_scol17 = []
recall_dt_scol17 = []
precision_dt_scol17 = []
accuracy_dt_scol17 = []

probs_nb_scol17 = []
f1_nb_scol17 = []
rocauc_nb_scol17 = []
recall_nb_scol17 = []
precision_nb_scol17 = []
accuracy_nb_scol17 = []

probs_xg_scol17 = []
f1_xg_scol17 = []
rocauc_xg_scol17 = []
recall_xg_scol17 = []
precision_xg_scol17 = []
accuracy_xg_scol17 = []

probs_rf_scol17 = []
f1_rf_scol17 = []
rocauc_rf_scol17 = []
recall_rf_scol17 = []
precision_rf_scol17 = []
accuracy_rf_scol17 = []

tfidf_vect17 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train17 = tfidf_vect17.fit_transform(x35.values)
tfidf_test17=tfidf_vect17.transform(x36.values)
print(tfidf_train17.shape)
print(tfidf_test17.shape)
#tfidf_train17.toarray()

x_tfidf17 = tfidf_vect17.fit_transform(df18["lemmatized"])
x_ros17, y_ros17 = ros.fit_resample(x_tfidf17, df18["label"])

# train_values17 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values17 = 1 - train_values17
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros17, y_ros17, train_size=i, stratify=y_ros17)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol17.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol17.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol17.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol17.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol17.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol17.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df18_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol17.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol17.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol17.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol17.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol17.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol17.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df18_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol17.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol17.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol17.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol17.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol17.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol17.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df18_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol17.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol17.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol17.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol17.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol17.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol17.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df18_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol17.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol17.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol17.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol17.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol17.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol17.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df18_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df18_l, ":", probs_lr_scol17)
    print("Array of F1 Scores LR-ROS:", df18_l, ":", f1_lr_scol17)
    print("Array of ROCAUC Scores LR-ROS:", df18_l, ":", rocauc_lr_scol17)
    print("Array of Recall Scores LR-ROS:", df18_l, ":", recall_lr_scol17)
    print("Array of Precision Scores LR-ROS:", df18_l, ":", precision_lr_scol17)
    print("Array of Accuracy Scores LR-ROS:", df18_l, ":", accuracy_lr_scol17)

    print("Array of Prob Scores DT-ROS:", df18_l, ":", probs_dt_scol17)
    print("Array of F1 Scores DT-ROS:", df18_l, ":", f1_dt_scol17)
    print("Array of ROCAUC Scores DT-ROS:", df18_l, ":", rocauc_dt_scol17)
    print("Array of Recall Scores DT-ROS:", df18_l, ":", recall_dt_scol17)
    print("Array of Precision Scores DT-ROS:", df18_l, ":", precision_dt_scol17)
    print("Array of Accuracy Scores DT-ROS:", df18_l, ":", accuracy_dt_scol17)

    print("Array of Prob Scores NB-ROS:", df18_l, ":", probs_nb_scol17)
    print("Array of F1 Scores NB-ROS:", df18_l, ":", f1_nb_scol17)
    print("Array of ROCAUC Scores NB-ROS:", df18_l, ":", rocauc_nb_scol17)
    print("Array of Recall Scores NB-ROS:", df18_l, ":", recall_nb_scol17)
    print("Array of Precision Scores NB-ROS:", df18_l, ":", precision_nb_scol17)
    print("Array of Accuracy Scores NB-ROS:", df18_l, ":", accuracy_nb_scol17)

    print("Array of Prob Scores XG-ROS:", df18_l, ":", probs_xg_scol17)
    print("Array of F1 Scores XG-ROS:", df18_l, ":", f1_xg_scol17)
    print("Array of ROCAUC Scores XG-ROS:", df18_l, ":", rocauc_xg_scol17)
    print("Array of Recall Scores XG-ROS:", df18_l, ":", recall_xg_scol17)
    print("Array of Precision Scores XG-ROS:", df18_l, ":", precision_xg_scol17)
    print("Array of Accuracy Scores XG-ROS:", df18_l, ":", accuracy_xg_scol17)

    print("Array of Prob Scores RF-ROS:", df18_l, ":", probs_rf_scol17)
    print("Array of F1 Scores RF-ROS:", df18_l, ":", f1_rf_scol17)
    print("Array of ROCAUC Scores RF-ROS:", df18_l, ":", rocauc_rf_scol17)
    print("Array of Recall Scores RF-ROS:", df18_l, ":", recall_rf_scol17)
    print("Array of Precision Scores RF-ROS:", df18_l, ":", precision_rf_scol17)
    print("Array of Accuracy Scores RF-ROS:", df18_l, ":", accuracy_rf_scol17)

year17 = [ args.group for t in range(25)]
sampling17 = ['Oversampling' for t in range(25)]
technique17 = ['ROS' for t in range(25)]
classifier_names17 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num17 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num17 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num17 = [precision_lr_scol17, precision_dt_scol17, precision_nb_scol17, precision_xg_scol17, precision_rf_scol17]
recall_csv_num17 = [recall_lr_scol17, recall_dt_scol17, recall_nb_scol17, recall_xg_scol17, recall_xg_scol17]
auc_csv_num17 = [rocauc_lr_scol17, rocauc_dt_scol17, rocauc_nb_scol17, rocauc_xg_scol17, rocauc_rf_scol17]
accuracy_csv_num17 = [accuracy_lr_scol17, accuracy_dt_scol17, accuracy_nb_scol17, accuracy_xg_scol17, accuracy_rf_scol17]
import itertools
rounds = 5
p17 = itertools.cycle(classifier_names17)
o17 = itertools.cycle(test_sizes_num17)
k17 = itertools.cycle(train_sizes_num17)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv17 = [next(p17) for _ in range(rounds)] * 5
test_size_csv17 = [a for b in test_sizes_num17 for a in (b,)*5]
train_size_csv17 = [c for d in train_sizes_num17 for c in (d,)*5]
split_csv17 = ['18' for u in range(25)]
train_csv17 = ['90%' for u in range(25)]
precision_csv17 = list(chain(*precision_csv_num17))
recall_csv17 = list(chain(*recall_csv_num17))
auc_csv17 = list(chain(*auc_csv_num17))
accuracy_csv17 = list(chain(*accuracy_csv_num17))
csv_data17 = [year17, sampling17, technique17, classifier_csv17, test_size_csv17, train_size_csv17, split_csv17, train_csv17, precision_csv17,
            recall_csv17, auc_csv17, accuracy_csv17]
export_data17 = zip_longest(*csv_data17, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data17)

'''
# Preicsion - #18 test size
#precision_nea171b = list([precision_lr_scol17[0], precision_dt_scol17[0], precision_rf_scol17[0], precision_nb_scol17[0], precision_xg_scol17[0]])
precision_nea171 = list([test_sizes[17], precision_xg_scol17[0], precision_rf_scol17[0], precision_dt_scol17[0], precision_lr_scol17[0], precision_nb_scol17[0]])
#precision_nea171 = list([(test_sizes[17] - test_sizes[17]), (0.0 + precision_rf_scol17[0]), (1.0 + precision_xg_scol17[0]),(2.0 + precision_dt_scol17[0]), (3.0 + precision_lr_scol17[0]), (4.0 + precision_nb_scol17[0])])
print("Iteration 1 Array:", precision_nea171)
# precision_nea172 = list([precision_lr_scol17[1], precision_dt_scol17[1], precision_rf_scol17[1], precision_nb_scol17[1], precision_xg_scol17[1]])
precision_nea172 = list([test_sizes[17], precision_xg_scol17[1], precision_rf_scol17[1], precision_dt_scol17[1],  precision_lr_scol17[1], precision_nb_scol17[1]])
#precision_nea172 = list([(test_sizes[17] - test_sizes[17]), (0.0 + precision_rf_scol17[1]), (1.0 + precision_xg_scol17[1]),(2.0 + precision_dt_scol17[1]), (3.0 + precision_lr_scol17[1]), (4.0 + precision_nb_scol17[1])])
print("Iteration 2 Array:", precision_nea172)
precision_nea173 = list([test_sizes[17], precision_lr_scol17[2], precision_dt_scol17[2], precision_rf_scol17[2], precision_nb_scol17[2], precision_xg_scol17[2]] )
precision_nea174 = list([test_sizes[17], precision_lr_scol17[3], precision_dt_scol17[3], precision_rf_scol17[3], precision_nb_scol17[3], precision_xg_scol17[3]] )
precision_nea175 = list([test_sizes[17], precision_lr_scol17[4], precision_dt_scol17[4], precision_rf_scol17[4], precision_nb_scol17[4], precision_xg_scol17[4]] )
precision_nea176 = list([test_sizes[17], precision_lr_scol17[5], precision_dt_scol17[5], precision_rf_scol17[5], precision_nb_scol17[5], precision_xg_scol17[5]] )
precision_nea177 = list([test_sizes[17], precision_lr_scol17[6], precision_dt_scol17[6], precision_rf_scol17[6], precision_nb_scol17[6], precision_xg_scol17[6]] )
precision_nea178 = list([test_sizes[17], precision_lr_scol17[7], precision_dt_scol17[7], precision_rf_scol17[7], precision_nb_scol17[7], precision_xg_scol17[7]] )
precision_nea179 = list([test_sizes[17], precision_lr_scol17[8], precision_dt_scol17[8], precision_rf_scol17[8], precision_nb_scol17[8], precision_xg_scol17[8]] )
precision_nea180 = list([test_sizes[17], precision_lr_scol17[9], precision_dt_scol17[9], precision_rf_scol17[9], precision_nb_scol17[9], precision_xg_scol17[9]] )

# Recall - 18 test size
#recall_nea171b = list([recall_lr_scol17[0], recall_dt_scol17[0], recall_rf_scol17[0], recall_nb_scol17[0], recall_xg_scol17[0]])
recall_nea171 = list([test_sizes[17], recall_xg_scol17[0], recall_rf_scol17[0], recall_dt_scol17[0], recall_lr_scol17[0], recall_nb_scol17[0]])
# recall_nea171 = list([(test_sizes[17] - test_sizes[17]), (0.0 + recall_rf_scol17[0]), (1.0 + recall_xg_scol17[0]),(2.0 + recall_dt_scol17[0]), (3.0 + recall_lr_scol17[0]), (4.0 + recall_nb_scol17[0])])
print("Iteration 1 Array:", recall_nea171)
# recall_nea172 = list([recall_lr_scol17[1], recall_dt_scol17[1], recall_rf_scol17[1], recall_nb_scol17[1], recall_xg_scol17[1]])
recall_nea172 = list([test_sizes[17], recall_xg_scol17[1], recall_rf_scol17[1], recall_dt_scol17[1],  recall_lr_scol17[1], recall_nb_scol17[1]])
#recall_nea172 = list([(test_sizes[17] - test_sizes[17]), (0.0 + recall_rf_scol17[1]), (1.0 + recall_xg_scol17[1]),(2.0 + recall_dt_scol17[1]), (3.0 + recall_lr_scol17[1]), (4.0 + recall_nb_scol17[1])])
print("Iteration 2 Array:", recall_nea172)

recall_nea173 = list([test_sizes[17], recall_lr_scol17[2], recall_dt_scol17[2], recall_rf_scol17[2], recall_nb_scol17[2], recall_xg_scol17[2]] )
recall_nea174 = list([test_sizes[17], recall_lr_scol17[3], recall_dt_scol17[3], recall_rf_scol17[3], recall_nb_scol17[3], recall_xg_scol17[3]] )
recall_nea175 = list([test_sizes[17], recall_lr_scol17[4], recall_dt_scol17[4], recall_rf_scol17[4], recall_nb_scol17[4], recall_xg_scol17[4]] )
recall_nea176 = list([test_sizes[17], recall_lr_scol17[5], recall_dt_scol17[5], recall_rf_scol17[5], recall_nb_scol17[5], recall_xg_scol17[5]] )
recall_nea177 = list([test_sizes[17], recall_lr_scol17[6], recall_dt_scol17[6], recall_rf_scol17[6], recall_nb_scol17[6], recall_xg_scol17[6]] )
recall_nea178 = list([test_sizes[17], recall_lr_scol17[7], recall_dt_scol17[7], recall_rf_scol17[7], recall_nb_scol17[7], recall_xg_scol17[7]] )
recall_nea179 = list([test_sizes[17], recall_lr_scol17[8], recall_dt_scol17[8], recall_rf_scol17[8], recall_nb_scol17[8], recall_xg_scol17[8]] )
recall_nea180 = list([test_sizes[17], recall_lr_scol17[9], recall_dt_scol17[9], recall_rf_scol17[9], recall_nb_scol17[9], recall_xg_scol17[9]] )


precision_lr_scol17_avg = (precision_lr_scol17[0] + precision_lr_scol17[1] + precision_lr_scol17[2] + precision_lr_scol17[3] + precision_lr_scol17[4] + precision_lr_scol17[5] + precision_lr_scol17[6] + precision_lr_scol17[7] + precision_lr_scol17[8] + precision_lr_scol17[9]) / 10
precision_dt_scol17_avg = (precision_dt_scol17[0] + precision_dt_scol17[1] + precision_dt_scol17[2] + precision_dt_scol17[3] + precision_dt_scol17[4] + precision_dt_scol17[5] + precision_dt_scol17[6] + precision_dt_scol17[7] + precision_dt_scol17[8] + precision_dt_scol17[9]) / 10
precision_rf_scol17_avg = (precision_rf_scol17[0] + precision_rf_scol17[1] + precision_rf_scol17[2] + precision_rf_scol17[3] + precision_rf_scol17[4] + precision_rf_scol17[5] + precision_rf_scol17[6] + precision_rf_scol17[7] + precision_rf_scol17[8] + precision_rf_scol17[9]) / 10
precision_nb_scol17_avg = (precision_nb_scol17[0] + precision_nb_scol17[1] + precision_nb_scol17[2] + precision_nb_scol17[3] + precision_nb_scol17[4] + precision_nb_scol17[5] + precision_nb_scol17[6] + precision_nb_scol17[7] + precision_nb_scol17[8] + precision_nb_scol17[9]) / 10
precision_xg_scol17_avg = (precision_xg_scol17[0] + precision_xg_scol17[1] + precision_xg_scol17[2] + precision_xg_scol17[3] + precision_xg_scol17[4] + precision_xg_scol17[5] + precision_xg_scol17[6] + precision_xg_scol17[7] + precision_xg_scol17[8] + precision_xg_scol17[9]) / 10

recall_lr_scol17_avg = (recall_lr_scol17[0] + recall_lr_scol17[1] + recall_lr_scol17[2] + recall_lr_scol17[3] + recall_lr_scol17[4] + recall_lr_scol17[5] + recall_lr_scol17[6] + recall_lr_scol17[7] + recall_lr_scol17[8] + recall_lr_scol17[9]) / 10
recall_dt_scol17_avg = (recall_dt_scol17[0] + recall_dt_scol17[1] + recall_dt_scol17[2] + recall_dt_scol17[3] + recall_dt_scol17[4] + recall_dt_scol17[5] + recall_dt_scol17[6] + recall_dt_scol17[7] + recall_dt_scol17[8] + recall_dt_scol17[9]) / 10
recall_rf_scol17_avg = (recall_rf_scol17[0] + recall_rf_scol17[1] + recall_rf_scol17[2] + recall_rf_scol17[3] + recall_rf_scol17[4] + recall_rf_scol17[5] + recall_rf_scol17[6] + recall_rf_scol17[7] + recall_rf_scol17[8] + recall_rf_scol17[9]) / 10
recall_nb_scol17_avg = (recall_nb_scol17[0] + recall_nb_scol17[1] + recall_nb_scol17[2] + recall_nb_scol17[3] + recall_nb_scol17[4] + recall_nb_scol17[5] + recall_nb_scol17[6] + recall_nb_scol17[7] + recall_nb_scol17[8] + recall_nb_scol17[9]) / 10
recall_xg_scol17_avg = (recall_xg_scol17[0] + recall_xg_scol17[1] + recall_xg_scol17[2] + recall_xg_scol17[3] + recall_xg_scol17[4] + recall_xg_scol17[5] + recall_xg_scol17[6] + recall_xg_scol17[7] + recall_xg_scol17[8] + recall_xg_scol17[9]) / 10
'''

precision_lr_scol17_avg = (precision_lr_scol17[0] + precision_lr_scol17[1] + precision_lr_scol17[2] + precision_lr_scol17[3] + precision_lr_scol17[4]) / 5
precision_dt_scol17_avg = (precision_dt_scol17[0] + precision_dt_scol17[1] + precision_dt_scol17[2] + precision_dt_scol17[3] + precision_dt_scol17[4]) / 5
precision_rf_scol17_avg = (precision_rf_scol17[0] + precision_rf_scol17[1] + precision_rf_scol17[2] + precision_rf_scol17[3] + precision_rf_scol17[4]) / 5
precision_nb_scol17_avg = (precision_nb_scol17[0] + precision_nb_scol17[1] + precision_nb_scol17[2] + precision_nb_scol17[3] + precision_nb_scol17[4]) / 5
precision_xg_scol17_avg = (precision_xg_scol17[0] + precision_xg_scol17[1] + precision_xg_scol17[2] + precision_xg_scol17[3] + precision_xg_scol17[4]) / 5

recall_lr_scol17_avg = (recall_lr_scol17[0] + recall_lr_scol17[1] + recall_lr_scol17[2] + recall_lr_scol17[3] + recall_lr_scol17[4]) / 5
recall_dt_scol17_avg = (recall_dt_scol17[0] + recall_dt_scol17[1] + recall_dt_scol17[2] + recall_dt_scol17[3] + recall_dt_scol17[4]) / 5
recall_rf_scol17_avg = (recall_rf_scol17[0] + recall_rf_scol17[1] + recall_rf_scol17[2] + recall_rf_scol17[3] + recall_rf_scol17[4]) / 5
recall_nb_scol17_avg = (recall_nb_scol17[0] + recall_nb_scol17[1] + recall_nb_scol17[2] + recall_nb_scol17[3] + recall_nb_scol17[4]) / 5
recall_xg_scol17_avg = (recall_xg_scol17[0] + recall_xg_scol17[1] + recall_xg_scol17[2] + recall_xg_scol17[3] + recall_xg_scol17[4]) / 5

# Test Size #19 - 95%

probs_lr_scol18 = []
f1_lr_scol18 = []
rocauc_lr_scol18 = []
recall_lr_scol18 = []
precision_lr_scol18 = []
accuracy_lr_scol18 = []

probs_dt_scol18 = []
f1_dt_scol18 = []
rocauc_dt_scol18 = []
recall_dt_scol18 = []
precision_dt_scol18 = []
accuracy_dt_scol18 = []

probs_nb_scol18 = []
f1_nb_scol18 = []
rocauc_nb_scol18 = []
recall_nb_scol18 = []
precision_nb_scol18 = []
accuracy_nb_scol18 = []

probs_xg_scol18 = []
f1_xg_scol18 = []
rocauc_xg_scol18 = []
recall_xg_scol18 = []
precision_xg_scol18 = []
accuracy_xg_scol18 = []

probs_rf_scol18 = []
f1_rf_scol18 = []
rocauc_rf_scol18 = []
recall_rf_scol18 = []
precision_rf_scol18 = []
accuracy_rf_scol18 = []

tfidf_vect18 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train18 = tfidf_vect18.fit_transform(x37.values)
tfidf_test18=tfidf_vect18.transform(x38.values)
print(tfidf_train18.shape)
print(tfidf_test18.shape)
#tfidf_train18.toarray()

x_tfidf18 = tfidf_vect18.fit_transform(df19["lemmatized"])
x_ros18, y_ros18 = ros.fit_resample(x_tfidf18, df19["label"])

# train_values18 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values18 = 1 - train_values18
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros18, y_ros18, train_size=i, stratify=y_ros18)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol18.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol18.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol18.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol18.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol18.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol18.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df19_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol18.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol18.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol18.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol18.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol18.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol18.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df19_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol18.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol18.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol18.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol18.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol18.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol18.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df19_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol18.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol18.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol18.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol18.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol18.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol18.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df19_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol18.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol18.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol18.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol18.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol18.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol18.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df19_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df19_l, ":", probs_lr_scol18)
    print("Array of F1 Scores LR-ROS:", df19_l, ":", f1_lr_scol18)
    print("Array of ROCAUC Scores LR-ROS:", df19_l, ":", rocauc_lr_scol18)
    print("Array of Recall Scores LR-ROS:", df19_l, ":", recall_lr_scol18)
    print("Array of Precision Scores LR-ROS:", df19_l, ":", precision_lr_scol18)
    print("Array of Accuracy Scores LR-ROS:", df19_l, ":", accuracy_lr_scol18)

    print("Array of Prob Scores DT-ROS:", df19_l, ":", probs_dt_scol18)
    print("Array of F1 Scores DT-ROS:", df19_l, ":", f1_dt_scol18)
    print("Array of ROCAUC Scores DT-ROS:", df19_l, ":", rocauc_dt_scol18)
    print("Array of Recall Scores DT-ROS:", df19_l, ":", recall_dt_scol18)
    print("Array of Precision Scores DT-ROS:", df19_l, ":", precision_dt_scol18)
    print("Array of Accuracy Scores DT-ROS:", df19_l, ":", accuracy_dt_scol18)

    print("Array of Prob Scores NB-ROS:", df19_l, ":", probs_nb_scol18)
    print("Array of F1 Scores NB-ROS:", df19_l, ":", f1_nb_scol18)
    print("Array of ROCAUC Scores NB-ROS:", df19_l, ":", rocauc_nb_scol18)
    print("Array of Recall Scores NB-ROS:", df19_l, ":", recall_nb_scol18)
    print("Array of Precision Scores NB-ROS:", df19_l, ":", precision_nb_scol18)
    print("Array of Accuracy Scores NB-ROS:", df19_l, ":", accuracy_nb_scol18)

    print("Array of Prob Scores XG-ROS:", df19_l, ":", probs_xg_scol18)
    print("Array of F1 Scores XG-ROS:", df19_l, ":", f1_xg_scol18)
    print("Array of ROCAUC Scores XG-ROS:", df19_l, ":", rocauc_xg_scol18)
    print("Array of Recall Scores XG-ROS:", df19_l, ":", recall_xg_scol18)
    print("Array of Precision Scores XG-ROS:", df19_l, ":", precision_xg_scol18)
    print("Array of Accuracy Scores XG-ROS:", df19_l, ":", accuracy_xg_scol18)

    print("Array of Prob Scores RF-ROS:", df19_l, ":", probs_rf_scol18)
    print("Array of F1 Scores RF-ROS:", df19_l, ":", f1_rf_scol18)
    print("Array of ROCAUC Scores RF-ROS:", df19_l, ":", rocauc_rf_scol18)
    print("Array of Recall Scores RF-ROS:", df19_l, ":", recall_rf_scol18)
    print("Array of Precision Scores RF-ROS:", df19_l, ":", precision_rf_scol18)
    print("Array of Accuracy Scores RF-ROS:", df19_l, ":", accuracy_rf_scol18)
    

year18 = [ args.group for t in range(25)]
sampling18 = ['Oversampling' for t in range(25)]
technique18 = ['ROS' for t in range(25)]
classifier_names18 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num18 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num18 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num18 = [precision_lr_scol18, precision_dt_scol18, precision_nb_scol18, precision_xg_scol18, precision_rf_scol18]
recall_csv_num18 = [recall_lr_scol18, recall_dt_scol18, recall_nb_scol18, recall_xg_scol18, recall_xg_scol18]
auc_csv_num18 = [rocauc_lr_scol18, rocauc_dt_scol18, rocauc_nb_scol18, rocauc_xg_scol18, rocauc_rf_scol18]
accuracy_csv_num18 = [accuracy_lr_scol18, accuracy_dt_scol18, accuracy_nb_scol18, accuracy_xg_scol18, accuracy_rf_scol18]
import itertools
rounds = 5
p18 = itertools.cycle(classifier_names18)
o18 = itertools.cycle(test_sizes_num18)
k18 = itertools.cycle(train_sizes_num18)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv18 = [next(p18) for _ in range(rounds)] * 5
test_size_csv18 = [a for b in test_sizes_num18 for a in (b,)*5]
train_size_csv18 = [c for d in train_sizes_num18 for c in (d,)*5]
split_csv18 = ['19' for u in range(25)]
train_csv18 = ['95%' for u in range(25)]
precision_csv18 = list(chain(*precision_csv_num18))
recall_csv18 = list(chain(*recall_csv_num18))
auc_csv18 = list(chain(*auc_csv_num18))
accuracy_csv18 = list(chain(*accuracy_csv_num18))
csv_data18 = [year18, sampling18, technique18, classifier_csv18, test_size_csv18, train_size_csv18, split_csv18, train_csv18, precision_csv18,
            recall_csv18, auc_csv18, accuracy_csv18]
export_data18 = zip_longest(*csv_data18, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data18)
        

'''
# Preicsion - #19 test size
#precision_nea181b = list([precision_lr_scol18[0], precision_dt_scol18[0], precision_rf_scol18[0], precision_nb_scol18[0], precision_xg_scol18[0]])
precision_nea181 = list([test_sizes[18], precision_xg_scol18[0], precision_rf_scol18[0], precision_dt_scol18[0], precision_lr_scol18[0], precision_nb_scol18[0]])
#precision_nea181 = list([(test_sizes[18] - test_sizes[18]), (0.0 + precision_rf_scol18[0]), (1.0 + precision_xg_scol18[0]),(2.0 + precision_dt_scol18[0]), (3.0 + precision_lr_scol18[0]), (4.0 + precision_nb_scol18[0])])
print("Iteration 1 Array:", precision_nea181)
# precision_nea182 = list([precision_lr_scol18[1], precision_dt_scol18[1], precision_rf_scol18[1], precision_nb_scol18[1], precision_xg_scol18[1]])
precision_nea182 = list([test_sizes[18], precision_xg_scol18[1], precision_rf_scol18[1], precision_dt_scol18[1],  precision_lr_scol18[1], precision_nb_scol18[1]])
#precision_nea182 = list([(test_sizes[18] - test_sizes[18]), (0.0 + precision_rf_scol18[1]), (1.0 + precision_xg_scol18[1]),(2.0 + precision_dt_scol18[1]), (3.0 + precision_lr_scol18[1]), (4.0 + precision_nb_scol18[1])])
print("Iteration 2 Array:", precision_nea182)
precision_nea183 = list([test_sizes[18], precision_lr_scol18[2], precision_dt_scol18[2], precision_rf_scol18[2], precision_nb_scol18[2], precision_xg_scol18[2]] )
precision_nea184 = list([test_sizes[18], precision_lr_scol18[3], precision_dt_scol18[3], precision_rf_scol18[3], precision_nb_scol18[3], precision_xg_scol18[3]] )
precision_nea185 = list([test_sizes[18], precision_lr_scol18[4], precision_dt_scol18[4], precision_rf_scol18[4], precision_nb_scol18[4], precision_xg_scol18[4]] )
precision_nea186 = list([test_sizes[18], precision_lr_scol18[5], precision_dt_scol18[5], precision_rf_scol18[5], precision_nb_scol18[5], precision_xg_scol18[5]] )
precision_nea187 = list([test_sizes[18], precision_lr_scol18[6], precision_dt_scol18[6], precision_rf_scol18[6], precision_nb_scol18[6], precision_xg_scol18[6]] )
precision_nea188 = list([test_sizes[18], precision_lr_scol18[7], precision_dt_scol18[7], precision_rf_scol18[7], precision_nb_scol18[7], precision_xg_scol18[7]] )
precision_nea189 = list([test_sizes[18], precision_lr_scol18[8], precision_dt_scol18[8], precision_rf_scol18[8], precision_nb_scol18[8], precision_xg_scol18[8]] )
precision_nea190 = list([test_sizes[18], precision_lr_scol18[9], precision_dt_scol18[9], precision_rf_scol18[9], precision_nb_scol18[9], precision_xg_scol18[9]] )

# Recall - 10 test size
#recall_nea181b = list([recall_lr_scol18[0], recall_dt_scol18[0], recall_rf_scol18[0], recall_nb_scol18[0], recall_xg_scol18[0]])
recall_nea181 = list([test_sizes[18], recall_xg_scol18[0], recall_rf_scol18[0], recall_dt_scol18[0], recall_lr_scol18[0], recall_nb_scol18[0]])
# recall_nea181 = list([(test_sizes[18] - test_sizes[18]), (0.0 + recall_rf_scol18[0]), (1.0 + recall_xg_scol18[0]),(2.0 + recall_dt_scol18[0]), (3.0 + recall_lr_scol18[0]), (4.0 + recall_nb_scol18[0])])
print("Iteration 1 Array:", recall_nea181)
# recall_nea182 = list([recall_lr_scol18[1], recall_dt_scol18[1], recall_rf_scol18[1], recall_nb_scol18[1], recall_xg_scol18[1]])
recall_nea182 = list([test_sizes[18], recall_xg_scol18[1], recall_rf_scol18[1], recall_dt_scol18[1],  recall_lr_scol18[1], recall_nb_scol18[1]])
#recall_nea182 = list([(test_sizes[18] - test_sizes[18]), (0.0 + recall_rf_scol18[1]), (1.0 + recall_xg_scol18[1]),(2.0 + recall_dt_scol18[1]), (3.0 + recall_lr_scol18[1]), (4.0 + recall_nb_scol18[1])])
print("Iteration 2 Array:", recall_nea182)

recall_nea183 = list([test_sizes[18], recall_lr_scol18[2], recall_dt_scol18[2], recall_rf_scol18[2], recall_nb_scol18[2], recall_xg_scol18[2]] )
recall_nea184 = list([test_sizes[18], recall_lr_scol18[3], recall_dt_scol18[3], recall_rf_scol18[3], recall_nb_scol18[3], recall_xg_scol18[3]] )
recall_nea185 = list([test_sizes[18], recall_lr_scol18[4], recall_dt_scol18[4], recall_rf_scol18[4], recall_nb_scol18[4], recall_xg_scol18[4]] )
recall_nea186 = list([test_sizes[18], recall_lr_scol18[5], recall_dt_scol18[5], recall_rf_scol18[5], recall_nb_scol18[5], recall_xg_scol18[5]] )
recall_nea187 = list([test_sizes[18], recall_lr_scol18[6], recall_dt_scol18[6], recall_rf_scol18[6], recall_nb_scol18[6], recall_xg_scol18[6]] )
recall_nea188 = list([test_sizes[18], recall_lr_scol18[7], recall_dt_scol18[7], recall_rf_scol18[7], recall_nb_scol18[7], recall_xg_scol18[7]] )
recall_nea189 = list([test_sizes[18], recall_lr_scol18[8], recall_dt_scol18[8], recall_rf_scol18[8], recall_nb_scol18[8], recall_xg_scol18[8]] )
recall_nea190 = list([test_sizes[18], recall_lr_scol18[9], recall_dt_scol18[9], recall_rf_scol18[9], recall_nb_scol18[9], recall_xg_scol18[9]] )


precision_lr_scol18_avg = (precision_lr_scol18[0] + precision_lr_scol18[1] + precision_lr_scol18[2] + precision_lr_scol18[3] + precision_lr_scol18[4] + precision_lr_scol18[5] + precision_lr_scol18[6] + precision_lr_scol18[7] + precision_lr_scol18[8] + precision_lr_scol18[9]) / 10
precision_dt_scol18_avg = (precision_dt_scol18[0] + precision_dt_scol18[1] + precision_dt_scol18[2] + precision_dt_scol18[3] + precision_dt_scol18[4] + precision_dt_scol18[5] + precision_dt_scol18[6] + precision_dt_scol18[7] + precision_dt_scol18[8] + precision_dt_scol18[9]) / 10
precision_rf_scol18_avg = (precision_rf_scol18[0] + precision_rf_scol18[1] + precision_rf_scol18[2] + precision_rf_scol18[3] + precision_rf_scol18[4] + precision_rf_scol18[5] + precision_rf_scol18[6] + precision_rf_scol18[7] + precision_rf_scol18[8] + precision_rf_scol18[9]) / 10
precision_nb_scol18_avg = (precision_nb_scol18[0] + precision_nb_scol18[1] + precision_nb_scol18[2] + precision_nb_scol18[3] + precision_nb_scol18[4] + precision_nb_scol18[5] + precision_nb_scol18[6] + precision_nb_scol18[7] + precision_nb_scol18[8] + precision_nb_scol18[9]) / 10
precision_xg_scol18_avg = (precision_xg_scol18[0] + precision_xg_scol18[1] + precision_xg_scol18[2] + precision_xg_scol18[3] + precision_xg_scol18[4] + precision_xg_scol18[5] + precision_xg_scol18[6] + precision_xg_scol18[7] + precision_xg_scol18[8] + precision_xg_scol18[9]) / 10

recall_lr_scol18_avg = (recall_lr_scol18[0] + recall_lr_scol18[1] + recall_lr_scol18[2] + recall_lr_scol18[3] + recall_lr_scol18[4] + recall_lr_scol18[5] + recall_lr_scol18[6] + recall_lr_scol18[7] + recall_lr_scol18[8] + recall_lr_scol18[9]) / 10
recall_dt_scol18_avg = (recall_dt_scol18[0] + recall_dt_scol18[1] + recall_dt_scol18[2] + recall_dt_scol18[3] + recall_dt_scol18[4] + recall_dt_scol18[5] + recall_dt_scol18[6] + recall_dt_scol18[7] + recall_dt_scol18[8] + recall_dt_scol18[9]) / 10
recall_rf_scol18_avg = (recall_rf_scol18[0] + recall_rf_scol18[1] + recall_rf_scol18[2] + recall_rf_scol18[3] + recall_rf_scol18[4] + recall_rf_scol18[5] + recall_rf_scol18[6] + recall_rf_scol18[7] + recall_rf_scol18[8] + recall_rf_scol18[9]) / 10
recall_nb_scol18_avg = (recall_nb_scol18[0] + recall_nb_scol18[1] + recall_nb_scol18[2] + recall_nb_scol18[3] + recall_nb_scol18[4] + recall_nb_scol18[5] + recall_nb_scol18[6] + recall_nb_scol18[7] + recall_nb_scol18[8] + recall_nb_scol18[9]) / 10
recall_xg_scol18_avg = (recall_xg_scol18[0] + recall_xg_scol18[1] + recall_xg_scol18[2] + recall_xg_scol18[3] + recall_xg_scol18[4] + recall_xg_scol18[5] + recall_xg_scol18[6] + recall_xg_scol18[7] + recall_xg_scol18[8] + recall_xg_scol18[9]) / 10
'''

precision_lr_scol18_avg = (precision_lr_scol18[0] + precision_lr_scol18[1] + precision_lr_scol18[2] + precision_lr_scol18[3] + precision_lr_scol18[4]) / 5
precision_dt_scol18_avg = (precision_dt_scol18[0] + precision_dt_scol18[1] + precision_dt_scol18[2] + precision_dt_scol18[3] + precision_dt_scol18[4]) / 5
precision_rf_scol18_avg = (precision_rf_scol18[0] + precision_rf_scol18[1] + precision_rf_scol18[2] + precision_rf_scol18[3] + precision_rf_scol18[4]) / 5
precision_nb_scol18_avg = (precision_nb_scol18[0] + precision_nb_scol18[1] + precision_nb_scol18[2] + precision_nb_scol18[3] + precision_nb_scol18[4]) / 5
precision_xg_scol18_avg = (precision_xg_scol18[0] + precision_xg_scol18[1] + precision_xg_scol18[2] + precision_xg_scol18[3] + precision_xg_scol18[4]) / 5

recall_lr_scol18_avg = (recall_lr_scol18[0] + recall_lr_scol18[1] + recall_lr_scol18[2] + recall_lr_scol18[3] + recall_lr_scol18[4]) / 5
recall_dt_scol18_avg = (recall_dt_scol18[0] + recall_dt_scol18[1] + recall_dt_scol18[2] + recall_dt_scol18[3] + recall_dt_scol18[4]) / 5
recall_rf_scol18_avg = (recall_rf_scol18[0] + recall_rf_scol18[1] + recall_rf_scol18[2] + recall_rf_scol18[3] + recall_rf_scol18[4]) / 5
recall_nb_scol18_avg = (recall_nb_scol18[0] + recall_nb_scol18[1] + recall_nb_scol18[2] + recall_nb_scol18[3] + recall_nb_scol18[4]) / 5
recall_xg_scol18_avg = (recall_xg_scol18[0] + recall_xg_scol18[1] + recall_xg_scol18[2] + recall_xg_scol18[3] + recall_xg_scol18[4]) / 5

# Test Size #20 - 100%

probs_lr_scol19 = []
f1_lr_scol19 = []
rocauc_lr_scol19 = []
recall_lr_scol19 = []
precision_lr_scol19 = []
accuracy_lr_scol19 = []

probs_dt_scol19 = []
f1_dt_scol19 = []
rocauc_dt_scol19 = []
recall_dt_scol19 = []
precision_dt_scol19 = []
accuracy_dt_scol19 = []

probs_nb_scol19 = []
f1_nb_scol19 = []
rocauc_nb_scol19 = []
recall_nb_scol19 = []
precision_nb_scol19 = []
accuracy_nb_scol19 = []

probs_xg_scol19 = []
f1_xg_scol19 = []
rocauc_xg_scol19 = []
recall_xg_scol19 = []
precision_xg_scol19 = []
accuracy_xg_scol19 = []

probs_rf_scol19 = []
f1_rf_scol19 = []
rocauc_rf_scol19 = []
recall_rf_scol19 = []
precision_rf_scol19 = []
accuracy_rf_scol19 = []

tfidf_vect19 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train19 = tfidf_vect19.fit_transform(x39.values)
tfidf_test19=tfidf_vect19.transform(x40.values)
print(tfidf_train19.shape)
print(tfidf_test19.shape)
#tfidf_train19.toarray()

x_tfidf19 = tfidf_vect19.fit_transform(df20["lemmatized"])
x_ros19, y_ros19 = ros.fit_resample(x_tfidf19, df20["label"])

# train_values19 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
# test_values19 = 1 - train_values19
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i in train_values:

    x_train, x_test, y_train, y_test = train_test_split(x_ros19, y_ros19, train_size=i, stratify=y_ros19)


    start1 = time.time()
    log = LogisticRegression(penalty='l2', random_state=0, solver='lbfgs', multi_class='auto', max_iter=500)
    model_lr = log.fit(x_train, y_train)
    probs_lr = model_lr.predict_proba(x_test)[:, 1]
    probs_lr_scol19.append(probs_lr)
    ly_prediction = log.predict(x_test)
    fly = f1_score(ly_prediction, y_test)
    f1_lr_scol19.append(fly)
    rocauc_lr = roc_auc_score(y_test, ly_prediction)
    rocauc_lr_scol19.append(rocauc_lr)
    recalls_lr = recall_score(y_test, ly_prediction)
    recall_lr_scol19.append(recalls_lr)
    precisions_lr = precision_score(y_test, ly_prediction)
    precision_lr_scol19.append(precisions_lr)
    accuracys_lr = accuracy_score(y_test, ly_prediction)
    accuracy_lr_scol19.append(accuracys_lr)
    print("===Logistic Regression with TfidfVectorizer ROS - ", args.group, df20_l, i)
    lr_end = time.time()
    print('Logistic F1-score', fly * 100)
    print('Logistic ROCAUC score:', rocauc_lr * 100)
    print('Logistic Recall score:', recalls_lr * 100)
    print('Logistic Precision Score:', precisions_lr * 100)
    print('Logistic Confusion Matrix', confusion_matrix(y_test, ly_prediction), "\n")
    print('Logistic Classification', classification_report(y_test, ly_prediction), "\n")
    print('Logistic Accuracy Score', accuracys_lr * 100)
    print("Execution Time for Logistic Regression ROS: ", lr_end - start1, "seconds")

    start2 = time.time()
    from sklearn.tree import DecisionTreeClassifier

    DCT = DecisionTreeClassifier()
    model_dt = DCT.fit(x_train, y_train)
    probs_dt = model_dt.predict_proba(x_test)[:, 1]
    probs_dt_scol19.append(probs_dt)
    dct_pred = DCT.predict(x_test)
    fdct = f1_score(dct_pred, y_test)
    f1_dt_scol19.append(fdct)
    rocauc_dt = roc_auc_score(y_test, dct_pred)
    rocauc_dt_scol19.append(rocauc_dt)
    recalls_dt = recall_score(y_test, dct_pred)
    recall_dt_scol19.append(recalls_dt)
    precisions_dt = precision_score(y_test, dct_pred)
    precision_dt_scol19.append(precisions_dt)
    accuracys_dt = accuracy_score(y_test, dct_pred)
    accuracy_dt_scol19.append(accuracys_dt)
    print("===DecisionTreeClassifier with TfidfVectorizer ROS - ", args.group, df20_l, i)
    dt_end = time.time()
    print('DCT F1-score', fdct * 100)
    print('DCT ROCAUC score:', rocauc_dt * 100)
    print('DCT Recall score:', recalls_dt * 100)
    print('DCT Precision Score:', precisions_dt * 100)
    print('DCT Confusion Matrix', confusion_matrix(y_test, dct_pred), "\n")
    print('DCT Classification', classification_report(y_test, dct_pred), "\n")
    print('DCT Accuracy Score', accuracys_dt * 100)
    print("Execution Time for Decision Tree ROS: ", dt_end - start2, "seconds")

    from sklearn.naive_bayes import MultinomialNB

    start3 = time.time()
    Naive = MultinomialNB()
    model_nb = Naive.fit(x_train, y_train)
    probs_nb = model_nb.predict_proba(x_test)[:, 1]
    probs_nb_scol19.append(probs_nb)
    # predict the labels on validation dataset
    ny_pred = Naive.predict(x_test)
    fnb = f1_score(ny_pred, y_test)
    f1_nb_scol19.append(fnb)
    rocauc_nb = roc_auc_score(y_test, ny_pred)
    rocauc_nb_scol19.append(rocauc_nb)
    recalls_nb = recall_score(y_test, ny_pred)
    recall_nb_scol19.append(recalls_nb)
    precisions_nb = precision_score(y_test, ny_pred)
    precision_nb_scol19.append(precisions_nb)
    accuracys_nb = accuracy_score(y_test, ny_pred)
    accuracy_nb_scol19.append(accuracys_nb)
    nb_end = time.time()
    # Use accuracy_score function to get the accuracy
    print("===Naive Bayes with TfidfVectorizer ROS - ", args.group, df20_l, i)
    print('Naive F1-score', fnb * 100)
    print('Naive ROCAUC score:', rocauc_nb * 100)
    print('Naive Recall score:', recalls_nb * 100)
    print('Naive Precision Score:', precisions_nb * 100)
    print('Naive Confusion Matrix', confusion_matrix(y_test, ny_pred), "\n")
    print('Naive Classification', classification_report(y_test, ny_pred), "\n")
    print('Naive Accuracy Score', accuracys_nb * 100)
    print("Execution Time for Naive Bayes ROS: ", nb_end - start3, "seconds")

    # XGBoost Classifier

    start4 = time.time()
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

    xgb_model = XGBClassifier().fit(x_train, y_train)
    probs_xg = xgb_model.predict_proba(x_test)[:, 1]
    probs_xg_scol19.append(probs_xg)
    # predict
    xgb_y_predict = xgb_model.predict(x_test)
    fxg = f1_score(xgb_y_predict, y_test)
    f1_xg_scol19.append(fxg)
    rocauc_xg = roc_auc_score(xgb_y_predict, y_test)
    rocauc_xg_scol19.append(rocauc_xg)
    recall_xg = recall_score(xgb_y_predict, y_test)
    recall_xg_scol19.append(recall_xg)
    precisions_xg = precision_score(xgb_y_predict, y_test)
    precision_xg_scol19.append(precisions_xg)
    accuracys_xg = accuracy_score(xgb_y_predict, y_test)
    accuracy_xg_scol19.append(accuracys_xg)
    xg_end = time.time()
    print("===XGB with TfidfVectorizer ROS - ", args.group, df20_l, i)
    print('XGB F1-Score', fxg * 100)
    print('XGB ROCAUC Score:', rocauc_xg * 100)
    print('XGB Recall score:', recall_xg * 100)
    print('XGB Precision Score:', precisions_xg * 100)
    print('XGB Confusion Matrix', confusion_matrix(xgb_y_predict, y_test), "\n")
    print('XGB Classification', classification_report(xgb_y_predict, y_test), "\n")
    print('XGB Accuracy Score', accuracys_nb * 100)
    print("Execution Time for XGBoost Classifier ROS: ", xg_end - start4, "seconds")

    # Random Forest Classifier
    from sklearn.ensemble import RandomForestClassifier

    start5 = time.time()
    rfc_model = RandomForestClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train)
    probs_rf = rfc_model.predict_proba(x_test)[:, 1]
    probs_rf_scol19.append(probs_rf)
    rfc_pred = rfc_model.predict(x_test)
    frfc = f1_score(rfc_pred, y_test)
    f1_rf_scol19.append(frfc)
    rocauc_rf = roc_auc_score(y_test, rfc_pred)
    rocauc_rf_scol19.append(rocauc_rf)
    recalls_rf = recall_score(rfc_pred, y_test)
    recall_rf_scol19.append(recalls_rf)
    precisions_rf = precision_score(rfc_pred, y_test)
    precision_rf_scol19.append(precisions_rf)
    accuracys_rf = accuracy_score(rfc_pred, y_test)
    accuracy_rf_scol19.append(accuracys_rf)
    rf_end = time.time()
    print("====RandomForest with Tfidf ROS ", args.group, df20_l, i)
    print('RFC F1 score', frfc * 100)
    print('RFC ROCAUC Score:', rocauc_rf * 100)
    print('RFC Recall score:', recalls_rf * 100)
    print('RFC Precision Score:', precisions_rf * 100)
    print('RFC Confusion Matrix', confusion_matrix(y_test, rfc_pred), "\n")
    print('RFC Classification', classification_report(y_test, rfc_pred), "\n")
    print('RFC Accuracy Score', accuracys_rf * 100)
    print("Execution Time for Random Forest Classifier ROS: ", rf_end - start5, "seconds")

    print("Array of Prob Scores LR-ROS:", df20_l, ":", probs_lr_scol19)
    print("Array of F1 Scores LR-ROS:", df20_l, ":", f1_lr_scol19)
    print("Array of ROCAUC Scores LR-ROS:", df20_l, ":", rocauc_lr_scol19)
    print("Array of Recall Scores LR-ROS:", df20_l, ":", recall_lr_scol19)
    print("Array of Precision Scores LR-ROS:", df20_l, ":", precision_lr_scol19)
    print("Array of Accuracy Scores LR-ROS:", df20_l, ":", accuracy_lr_scol19)

    print("Array of Prob Scores DT-ROS:", df20_l, ":", probs_dt_scol19)
    print("Array of F1 Scores DT-ROS:", df20_l, ":", f1_dt_scol19)
    print("Array of ROCAUC Scores DT-ROS:", df20_l, ":", rocauc_dt_scol19)
    print("Array of Recall Scores DT-ROS:", df20_l, ":", recall_dt_scol19)
    print("Array of Precision Scores DT-ROS:", df20_l, ":", precision_dt_scol19)
    print("Array of Accuracy Scores DT-ROS:", df20_l, ":", accuracy_dt_scol19)

    print("Array of Prob Scores NB-ROS:", df20_l, ":", probs_nb_scol19)
    print("Array of F1 Scores NB-ROS:", df20_l, ":", f1_nb_scol19)
    print("Array of ROCAUC Scores NB-ROS:", df20_l, ":", rocauc_nb_scol19)
    print("Array of Recall Scores NB-ROS:", df20_l, ":", recall_nb_scol19)
    print("Array of Precision Scores NB-ROS:", df20_l, ":", precision_nb_scol19)
    print("Array of Accuracy Scores NB-ROS:", df20_l, ":", accuracy_nb_scol19)

    print("Array of Prob Scores XG-ROS:", df20_l, ":", probs_xg_scol19)
    print("Array of F1 Scores XG-ROS:", df20_l, ":", f1_xg_scol19)
    print("Array of ROCAUC Scores XG-ROS:", df20_l, ":", rocauc_xg_scol19)
    print("Array of Recall Scores XG-ROS:", df20_l, ":", recall_xg_scol19)
    print("Array of Precision Scores XG-ROS:", df20_l, ":", precision_xg_scol19)
    print("Array of Accuracy Scores XG-ROS:", df20_l, ":", accuracy_xg_scol19)

    print("Array of Prob Scores RF-ROS:", df20_l, ":", probs_rf_scol19)
    print("Array of F1 Scores RF-ROS:", df20_l, ":", f1_rf_scol19)
    print("Array of ROCAUC Scores RF-ROS:", df20_l, ":", rocauc_rf_scol19)
    print("Array of Recall Scores RF-ROS:", df20_l, ":", recall_rf_scol19)
    print("Array of Precision Scores RF-ROS:", df20_l, ":", precision_rf_scol19)
    print("Array of Accuracy Scores RF-ROS:", df20_l, ":", accuracy_rf_scol19)
    

year19 = [ args.group for t in range(25)]
sampling19 = ['Oversampling' for t in range(25)]
technique19 = ['ROS' for t in range(25)]
classifier_names19 = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'Random Forest']
test_sizes_num19 = [0.17, 0.33, 0.50, 0.67, 0.83]
train_sizes_num19 = [0.83, 0.67, 0.50, 0.33, 0.17]
# v = [0, 1, 2, 3, 4]
# precision_csv_num = [precision_lr_scol[z], precision_dt_scol[z], precision_nb_scol[z], precision_xg_scol[z], precision_rf_scol[z]]
# recall_csv_num = [recall_lr_scol[z], recall_dt_scol[z], recall_nb_scol[z], recall_xg_scol[z], recall_rf_scol[z]]
# auc_csv_num = [rocauc_lr_scol[z], rocauc_dt_scol[z], rocauc_nb_scol[z], rocauc_xg_scol[z], rocauc_rf_scol[z]]
# accuracy_csv_num = [accuracy_lr_scol[z], accuracy_dt_scol[z], accuracy_nb_scol[z], accuracy_xg_scol[z], accuracy_rf_scol[z]]
precision_csv_num19 = [precision_lr_scol19, precision_dt_scol19, precision_nb_scol19, precision_xg_scol19, precision_rf_scol19]
recall_csv_num19 = [recall_lr_scol19, recall_dt_scol19, recall_nb_scol19, recall_xg_scol19, recall_xg_scol19]
auc_csv_num19 = [rocauc_lr_scol19, rocauc_dt_scol19, rocauc_nb_scol19, rocauc_xg_scol19, rocauc_rf_scol19]
accuracy_csv_num19 = [accuracy_lr_scol19, accuracy_dt_scol19, accuracy_nb_scol19, accuracy_xg_scol19, accuracy_rf_scol19]
import itertools
rounds = 5
p19 = itertools.cycle(classifier_names19)
o19 = itertools.cycle(test_sizes_num19)
k19 = itertools.cycle(train_sizes_num19)
# v = itertools.cycle(score_location)
# pr = itertools.cycle(precision_num)
# y = itertools.cycle(iteration_csv)
classifier_csv19 = [next(p19) for _ in range(rounds)] * 5
test_size_csv19 = [a for b in test_sizes_num19 for a in (b,)*5]
train_size_csv19 = [c for d in train_sizes_num19 for c in (d,)*5]
split_csv19 = ['20' for u in range(25)]
train_csv19 = ['100%' for u in range(25)]
precision_csv19 = list(chain(*precision_csv_num19))
recall_csv19 = list(chain(*recall_csv_num19))
auc_csv19 = list(chain(*auc_csv_num19))
accuracy_csv19 = list(chain(*accuracy_csv_num19))
csv_data19 = [year19, sampling19, technique19, classifier_csv19, test_size_csv19, train_size_csv19, split_csv19, train_csv19, precision_csv19,
            recall_csv19, auc_csv19, accuracy_csv19]
export_data19 = zip_longest(*csv_data19, fillvalue='')
with open(filename, 'a', newline='') as file:
    write = csv.writer(file)
    write.writerows(export_data19)

'''
# Preicsion - #20 test size
#precision_nea191b = list([precision_lr_scol19[0], precision_dt_scol19[0], precision_rf_scol19[0], precision_nb_scol19[0], precision_xg_scol19[0]])
precision_nea191 = list([test_sizes[19], precision_xg_scol19[0], precision_rf_scol19[0], precision_dt_scol19[0], precision_lr_scol19[0], precision_nb_scol19[0]])
#precision_nea191 = list([(test_sizes[19] - test_sizes[19]), (0.0 + precision_rf_scol19[0]), (1.0 + precision_xg_scol19[0]),(2.0 + precision_dt_scol19[0]), (3.0 + precision_lr_scol19[0]), (4.0 + precision_nb_scol19[0])])
print("Iteration 1 Array:", precision_nea191)
# precision_nea192 = list([precision_lr_scol19[1], precision_dt_scol19[1], precision_rf_scol19[1], precision_nb_scol19[1], precision_xg_scol19[1]])
precision_nea192 = list([test_sizes[19], precision_xg_scol19[1], precision_rf_scol19[1], precision_dt_scol19[1],  precision_lr_scol19[1], precision_nb_scol19[1]])
#precision_nea192 = list([(test_sizes[19] - test_sizes[19]), (0.0 + precision_rf_scol19[1]), (1.0 + precision_xg_scol19[1]),(2.0 + precision_dt_scol19[1]), (3.0 + precision_lr_scol19[1]), (4.0 + precision_nb_scol19[1])])
print("Iteration 2 Array:", precision_nea192)
precision_nea193 = list([test_sizes[19], precision_lr_scol19[2], precision_dt_scol19[2], precision_rf_scol19[2], precision_nb_scol19[2], precision_xg_scol19[2]] )
precision_nea194 = list([test_sizes[19], precision_lr_scol19[3], precision_dt_scol19[3], precision_rf_scol19[3], precision_nb_scol19[3], precision_xg_scol19[3]] )
precision_nea195 = list([test_sizes[19], precision_lr_scol19[4], precision_dt_scol19[4], precision_rf_scol19[4], precision_nb_scol19[4], precision_xg_scol19[4]] )
precision_nea196 = list([test_sizes[19], precision_lr_scol19[5], precision_dt_scol19[5], precision_rf_scol19[5], precision_nb_scol19[5], precision_xg_scol19[5]] )
precision_nea197 = list([test_sizes[19], precision_lr_scol19[6], precision_dt_scol19[6], precision_rf_scol19[6], precision_nb_scol19[6], precision_xg_scol19[6]] )
precision_nea198 = list([test_sizes[19], precision_lr_scol19[7], precision_dt_scol19[7], precision_rf_scol19[7], precision_nb_scol19[7], precision_xg_scol19[7]] )
precision_nea199 = list([test_sizes[19], precision_lr_scol19[8], precision_dt_scol19[8], precision_rf_scol19[8], precision_nb_scol19[8], precision_xg_scol19[8]] )
precision_nea200 = list([test_sizes[19], precision_lr_scol19[9], precision_dt_scol19[9], precision_rf_scol19[9], precision_nb_scol19[9], precision_xg_scol19[9]] )

# Recall - 10 test size
#recall_nea191b = list([recall_lr_scol19[0], recall_dt_scol19[0], recall_rf_scol19[0], recall_nb_scol19[0], recall_xg_scol19[0]])
recall_nea191 = list([test_sizes[19], recall_xg_scol19[0], recall_rf_scol19[0], recall_dt_scol19[0], recall_lr_scol19[0], recall_nb_scol19[0]])
# recall_nea191 = list([(test_sizes[19] - test_sizes[19]), (0.0 + recall_rf_scol19[0]), (1.0 + recall_xg_scol19[0]),(2.0 + recall_dt_scol19[0]), (3.0 + recall_lr_scol19[0]), (4.0 + recall_nb_scol19[0])])
print("Iteration 1 Array:", recall_nea191)
# recall_nea192 = list([recall_lr_scol19[1], recall_dt_scol19[1], recall_rf_scol19[1], recall_nb_scol19[1], recall_xg_scol19[1]])
recall_nea192 = list([test_sizes[19], recall_xg_scol19[1], recall_rf_scol19[1], recall_dt_scol19[1],  recall_lr_scol19[1], recall_nb_scol19[1]])
#recall_nea192 = list([(test_sizes[19] - test_sizes[19]), (0.0 + recall_rf_scol19[1]), (1.0 + recall_xg_scol19[1]),(2.0 + recall_dt_scol19[1]), (3.0 + recall_lr_scol19[1]), (4.0 + recall_nb_scol19[1])])
print("Iteration 2 Array:", recall_nea192)

recall_nea193 = list([test_sizes[19], recall_lr_scol19[2], recall_dt_scol19[2], recall_rf_scol19[2], recall_nb_scol19[2], recall_xg_scol19[2]] )
recall_nea194 = list([test_sizes[19], recall_lr_scol19[3], recall_dt_scol19[3], recall_rf_scol19[3], recall_nb_scol19[3], recall_xg_scol19[3]] )
recall_nea195 = list([test_sizes[19], recall_lr_scol19[4], recall_dt_scol19[4], recall_rf_scol19[4], recall_nb_scol19[4], recall_xg_scol19[4]] )
recall_nea196 = list([test_sizes[19], recall_lr_scol19[5], recall_dt_scol19[5], recall_rf_scol19[5], recall_nb_scol19[5], recall_xg_scol19[5]] )
recall_nea197 = list([test_sizes[19], recall_lr_scol19[6], recall_dt_scol19[6], recall_rf_scol19[6], recall_nb_scol19[6], recall_xg_scol19[6]] )
recall_nea198 = list([test_sizes[19], recall_lr_scol19[7], recall_dt_scol19[7], recall_rf_scol19[7], recall_nb_scol19[7], recall_xg_scol19[7]] )
recall_nea199 = list([test_sizes[19], recall_lr_scol19[8], recall_dt_scol19[8], recall_rf_scol19[8], recall_nb_scol19[8], recall_xg_scol19[8]] )
recall_nea200 = list([test_sizes[19], recall_lr_scol19[9], recall_dt_scol19[9], recall_rf_scol19[9], recall_nb_scol19[9], recall_xg_scol19[9]] )


precision_lr_scol19_avg = (precision_lr_scol19[0] + precision_lr_scol19[1] + precision_lr_scol19[2] + precision_lr_scol19[3] + precision_lr_scol19[4] + precision_lr_scol19[5] + precision_lr_scol19[6] + precision_lr_scol19[7] + precision_lr_scol19[8] + precision_lr_scol19[9]) / 10
precision_dt_scol19_avg = (precision_dt_scol19[0] + precision_dt_scol19[1] + precision_dt_scol19[2] + precision_dt_scol19[3] + precision_dt_scol19[4] + precision_dt_scol19[5] + precision_dt_scol19[6] + precision_dt_scol19[7] + precision_dt_scol19[8] + precision_dt_scol19[9]) / 10
precision_rf_scol19_avg = (precision_rf_scol19[0] + precision_rf_scol19[1] + precision_rf_scol19[2] + precision_rf_scol19[3] + precision_rf_scol19[4] + precision_rf_scol19[5] + precision_rf_scol19[6] + precision_rf_scol19[7] + precision_rf_scol19[8] + precision_rf_scol19[9]) / 10
precision_nb_scol19_avg = (precision_nb_scol19[0] + precision_nb_scol19[1] + precision_nb_scol19[2] + precision_nb_scol19[3] + precision_nb_scol19[4] + precision_nb_scol19[5] + precision_nb_scol19[6] + precision_nb_scol19[7] + precision_nb_scol19[8] + precision_nb_scol19[9]) / 10
precision_xg_scol19_avg = (precision_xg_scol19[0] + precision_xg_scol19[1] + precision_xg_scol19[2] + precision_xg_scol19[3] + precision_xg_scol19[4] + precision_xg_scol19[5] + precision_xg_scol19[6] + precision_xg_scol19[7] + precision_xg_scol19[8] + precision_xg_scol19[9]) / 10

recall_lr_scol19_avg = (recall_lr_scol19[0] + recall_lr_scol19[1] + recall_lr_scol19[2] + recall_lr_scol19[3] + recall_lr_scol19[4] + recall_lr_scol19[5] + recall_lr_scol19[6] + recall_lr_scol19[7] + recall_lr_scol19[8] + recall_lr_scol19[9]) / 10
recall_dt_scol19_avg = (recall_dt_scol19[0] + recall_dt_scol19[1] + recall_dt_scol19[2] + recall_dt_scol19[3] + recall_dt_scol19[4] + recall_dt_scol19[5] + recall_dt_scol19[6] + recall_dt_scol19[7] + recall_dt_scol19[8] + recall_dt_scol19[9]) / 10
recall_rf_scol19_avg = (recall_rf_scol19[0] + recall_rf_scol19[1] + recall_rf_scol19[2] + recall_rf_scol19[3] + recall_rf_scol19[4] + recall_rf_scol19[5] + recall_rf_scol19[6] + recall_rf_scol19[7] + recall_rf_scol19[8] + recall_rf_scol19[9]) / 10
recall_nb_scol19_avg = (recall_nb_scol19[0] + recall_nb_scol19[1] + recall_nb_scol19[2] + recall_nb_scol19[3] + recall_nb_scol19[4] + recall_nb_scol19[5] + recall_nb_scol19[6] + recall_nb_scol19[7] + recall_nb_scol19[8] + recall_nb_scol19[9]) / 10
recall_xg_scol19_avg = (recall_xg_scol19[0] + recall_xg_scol19[1] + recall_xg_scol19[2] + recall_xg_scol19[3] + recall_xg_scol19[4] + recall_xg_scol19[5] + recall_xg_scol19[6] + recall_xg_scol19[7] + recall_xg_scol19[8] + recall_xg_scol19[9]) / 10
'''

precision_lr_scol19_avg = (precision_lr_scol19[0] + precision_lr_scol19[1] + precision_lr_scol19[2] + precision_lr_scol19[3] + precision_lr_scol19[4]) / 5
precision_dt_scol19_avg = (precision_dt_scol19[0] + precision_dt_scol19[1] + precision_dt_scol19[2] + precision_dt_scol19[3] + precision_dt_scol19[4]) / 5
precision_rf_scol19_avg = (precision_rf_scol19[0] + precision_rf_scol19[1] + precision_rf_scol19[2] + precision_rf_scol19[3] + precision_rf_scol19[4]) / 5
precision_nb_scol19_avg = (precision_nb_scol19[0] + precision_nb_scol19[1] + precision_nb_scol19[2] + precision_nb_scol19[3] + precision_nb_scol19[4]) / 5
precision_xg_scol19_avg = (precision_xg_scol19[0] + precision_xg_scol19[1] + precision_xg_scol19[2] + precision_xg_scol19[3] + precision_xg_scol19[4]) / 5

recall_lr_scol19_avg = (recall_lr_scol19[0] + recall_lr_scol19[1] + recall_lr_scol19[2] + recall_lr_scol19[3] + recall_lr_scol19[4]) / 5
recall_dt_scol19_avg = (recall_dt_scol19[0] + recall_dt_scol19[1] + recall_dt_scol19[2] + recall_dt_scol19[3] + recall_dt_scol19[4]) / 5
recall_rf_scol19_avg = (recall_rf_scol19[0] + recall_rf_scol19[1] + recall_rf_scol19[2] + recall_rf_scol19[3] + recall_rf_scol19[4]) / 5
recall_nb_scol19_avg = (recall_nb_scol19[0] + recall_nb_scol19[1] + recall_nb_scol19[2] + recall_nb_scol19[3] + recall_nb_scol19[4]) / 5
recall_xg_scol19_avg = (recall_xg_scol19[0] + recall_xg_scol19[1] + recall_xg_scol19[2] + recall_xg_scol19[3] + recall_xg_scol19[4]) / 5

'''
### Curves
precision_lr_curve = list([precision_lr_scol_avg, precision_lr_scol7_avg, precision_lr_scol7_avg, precision_lr_scol7_avg, precision_lr_scol7_avg, precision_lr_scol7_avg, precision_lr_scol7_avg, precision_lr_scol8_avg, precision_lr_scol9_avg])
precision_dt_curve = list([precision_dt_scol_avg, precision_dt_scol7_avg, precision_dt_scol7_avg, precision_dt_scol7_avg, precision_dt_scol7_avg, precision_dt_scol7_avg, precision_dt_scol7_avg, precision_dt_scol8_avg, precision_dt_scol9_avg])
precision_rf_curve = list([precision_rf_scol_avg, precision_rf_scol7_avg, precision_rf_scol7_avg, precision_rf_scol7_avg, precision_rf_scol7_avg, precision_rf_scol7_avg, precision_rf_scol7_avg, precision_rf_scol8_avg, precision_rf_scol9_avg])
precision_nb_curve = list([precision_nb_scol_avg, precision_nb_scol7_avg, precision_nb_scol7_avg, precision_nb_scol7_avg, precision_nb_scol7_avg, precision_nb_scol7_avg, precision_nb_scol7_avg, precision_nb_scol8_avg, precision_nb_scol9_avg])
precision_xg_curve = list([precision_xg_scol_avg, precision_xg_scol7_avg, precision_xg_scol7_avg, precision_xg_scol7_avg,  precision_xg_scol7_avg, precision_xg_scol7_avg, precision_xg_scol7_avg, precision_xg_scol8_avg, precision_xg_scol9_avg])

recall_lr_curve = list([recall_lr_scol_avg, recall_lr_scol7_avg, recall_lr_scol7_avg, recall_lr_scol7_avg, recall_lr_scol7_avg, recall_lr_scol7_avg, recall_lr_scol7_avg, recall_lr_scol8_avg, recall_lr_scol9_avg])
recall_dt_curve = list([recall_dt_scol_avg, recall_dt_scol7_avg, recall_dt_scol7_avg, recall_dt_scol7_avg, recall_dt_scol7_avg, recall_dt_scol7_avg, recall_dt_scol7_avg, recall_dt_scol8_avg, recall_dt_scol9_avg])
recall_rf_curve = list([recall_rf_scol_avg, recall_rf_scol7_avg, recall_rf_scol7_avg, recall_rf_scol7_avg, recall_rf_scol7_avg, recall_rf_scol7_avg, recall_rf_scol7_avg, recall_rf_scol8_avg, recall_rf_scol9_avg])
recall_nb_curve = list([recall_nb_scol_avg, recall_nb_scol7_avg, recall_nb_scol7_avg, recall_nb_scol7_avg, recall_nb_scol7_avg, recall_nb_scol7_avg, recall_nb_scol7_avg, recall_nb_scol8_avg, recall_nb_scol9_avg])
recall_xg_curve = list([recall_xg_scol_avg, recall_xg_scol7_avg, recall_xg_scol7_avg, recall_xg_scol7_avg,  recall_xg_scol7_avg, recall_xg_scol7_avg, recall_xg_scol7_avg, recall_xg_scol8_avg, recall_xg_scol9_avg])
'''

### Curves
precision_lr_curve = list([precision_lr_scol_avg, precision_lr_scol1_avg, precision_lr_scol2_avg, precision_lr_scol3_avg, precision_lr_scol4_avg, precision_lr_scol5_avg, precision_lr_scol6_avg, precision_lr_scol7_avg, precision_lr_scol8_avg, precision_lr_scol9_avg, precision_lr_scol10_avg, precision_lr_scol11_avg, precision_lr_scol12_avg, precision_lr_scol13_avg, precision_lr_scol14_avg, precision_lr_scol15_avg, precision_lr_scol16_avg, precision_lr_scol17_avg, precision_lr_scol18_avg, precision_lr_scol19_avg])
precision_dt_curve = list([precision_dt_scol_avg, precision_dt_scol1_avg, precision_dt_scol2_avg, precision_dt_scol3_avg, precision_dt_scol4_avg, precision_dt_scol5_avg, precision_dt_scol6_avg, precision_dt_scol7_avg, precision_dt_scol8_avg, precision_dt_scol9_avg, precision_dt_scol10_avg, precision_dt_scol11_avg, precision_dt_scol12_avg, precision_dt_scol13_avg, precision_dt_scol14_avg, precision_dt_scol15_avg, precision_dt_scol16_avg, precision_dt_scol17_avg, precision_dt_scol18_avg, precision_dt_scol19_avg])
precision_rf_curve = list([precision_rf_scol_avg, precision_rf_scol1_avg, precision_rf_scol2_avg, precision_rf_scol3_avg, precision_rf_scol4_avg, precision_rf_scol5_avg, precision_rf_scol6_avg, precision_rf_scol7_avg, precision_rf_scol8_avg, precision_rf_scol9_avg, precision_rf_scol10_avg, precision_rf_scol11_avg, precision_rf_scol12_avg, precision_rf_scol13_avg, precision_rf_scol14_avg, precision_rf_scol15_avg, precision_rf_scol16_avg, precision_rf_scol17_avg, precision_rf_scol18_avg, precision_rf_scol19_avg])
precision_nb_curve = list([precision_nb_scol_avg, precision_nb_scol1_avg, precision_nb_scol2_avg, precision_nb_scol3_avg, precision_nb_scol4_avg, precision_nb_scol5_avg, precision_nb_scol6_avg, precision_nb_scol7_avg, precision_nb_scol8_avg, precision_nb_scol9_avg, precision_nb_scol10_avg, precision_nb_scol11_avg, precision_nb_scol12_avg, precision_nb_scol13_avg, precision_nb_scol14_avg, precision_nb_scol15_avg, precision_nb_scol16_avg, precision_nb_scol17_avg, precision_nb_scol18_avg, precision_nb_scol19_avg])
precision_xg_curve = list([precision_xg_scol_avg, precision_xg_scol1_avg, precision_xg_scol2_avg, precision_xg_scol3_avg, precision_xg_scol4_avg, precision_xg_scol5_avg, precision_xg_scol6_avg, precision_xg_scol7_avg, precision_xg_scol8_avg, precision_xg_scol9_avg, precision_xg_scol10_avg, precision_xg_scol11_avg, precision_xg_scol12_avg, precision_xg_scol13_avg, precision_xg_scol14_avg, precision_xg_scol15_avg, precision_xg_scol16_avg, precision_xg_scol17_avg, precision_xg_scol18_avg, precision_xg_scol19_avg])

recall_lr_curve = list([recall_lr_scol_avg, recall_lr_scol1_avg, recall_lr_scol2_avg, recall_lr_scol3_avg, recall_lr_scol4_avg, recall_lr_scol5_avg, recall_lr_scol6_avg, recall_lr_scol7_avg, recall_lr_scol8_avg, recall_lr_scol9_avg, recall_lr_scol10_avg, recall_lr_scol11_avg, recall_lr_scol12_avg, recall_lr_scol13_avg, recall_lr_scol14_avg, recall_lr_scol15_avg, recall_lr_scol16_avg, recall_lr_scol17_avg, recall_lr_scol18_avg, recall_lr_scol19_avg])
recall_dt_curve = list([recall_dt_scol_avg, recall_dt_scol1_avg, recall_dt_scol2_avg, recall_dt_scol3_avg, recall_dt_scol4_avg, recall_dt_scol5_avg, recall_dt_scol6_avg, recall_dt_scol7_avg, recall_dt_scol8_avg, recall_dt_scol9_avg, recall_dt_scol10_avg, recall_dt_scol11_avg, recall_dt_scol12_avg, recall_dt_scol13_avg, recall_dt_scol14_avg, recall_dt_scol15_avg, recall_dt_scol16_avg, recall_dt_scol17_avg, recall_dt_scol18_avg, recall_dt_scol19_avg])
recall_rf_curve = list([recall_rf_scol_avg, recall_rf_scol1_avg, recall_rf_scol2_avg, recall_rf_scol3_avg, recall_rf_scol4_avg, recall_rf_scol5_avg, recall_rf_scol6_avg, recall_rf_scol7_avg, recall_rf_scol8_avg, recall_rf_scol9_avg, recall_rf_scol10_avg, recall_rf_scol11_avg, recall_rf_scol12_avg, recall_rf_scol13_avg, recall_rf_scol14_avg, recall_rf_scol15_avg, recall_rf_scol16_avg, recall_rf_scol17_avg, recall_rf_scol18_avg, recall_rf_scol19_avg])
recall_nb_curve = list([recall_nb_scol_avg, recall_nb_scol1_avg, recall_nb_scol2_avg, recall_nb_scol3_avg, recall_nb_scol4_avg, recall_nb_scol5_avg, recall_nb_scol6_avg, recall_nb_scol7_avg, recall_nb_scol8_avg, recall_nb_scol9_avg, recall_nb_scol10_avg, recall_nb_scol11_avg, recall_nb_scol12_avg, recall_nb_scol13_avg, recall_nb_scol14_avg, recall_nb_scol15_avg, recall_nb_scol16_avg, recall_nb_scol17_avg, recall_nb_scol18_avg, recall_nb_scol19_avg])
recall_xg_curve = list([recall_xg_scol_avg, recall_xg_scol1_avg, recall_xg_scol2_avg, recall_xg_scol3_avg, recall_xg_scol4_avg, recall_xg_scol5_avg, recall_xg_scol6_avg, recall_xg_scol7_avg, recall_xg_scol8_avg, recall_xg_scol9_avg, recall_xg_scol10_avg, recall_xg_scol11_avg, recall_xg_scol12_avg, recall_xg_scol13_avg, recall_xg_scol14_avg, recall_xg_scol15_avg, recall_xg_scol16_avg, recall_xg_scol17_avg, recall_xg_scol18_avg, recall_xg_scol19_avg])


fig, ax = plt.subplots()

legend_names = ['TS - 5%', 'TS - 15%', 'TS - 25%', 'TS - 35%', 'TS - 45%', 'TS - 55%', 'TS - 65%', 'TS - 75%', 'TS - 85%', 'TS - 95%']

'''
classifier_names = {
     0: "Log Reg",
     1: "Dec Tre",
     2: "Naive Bayes",
     3: "XGBoost",
     4: "Random Forest"
}
'''

'''
length_50 = np.length(50, 60, N)
length_60 = np.length(60, 70, N)
length_70 = np.length(70, 80, N)
'''
'''
ln_x1 = [x for x in range(len(precision_sam1))]
print("Array x-axis 1", ln_x1)
ln_x2 = [x for x in range(len(precision_sam11))]
print("Array x-axis 2", ln_x2)
ln_x3 = [x for x in range(len(precision_sam31))]
print("Array x-axis 3", ln_x3)
ln_x4 = [x for x in range(len(precision_sam31))]
print("Array x-axis 4", ln_x4)
ln_x5 = [x for x in range(len(precision_sam41))]
print("Array x-axis 5", ln_x5)
ln_x6 = [x for x in range(len(precision_sam51))]
print("Array x-axis 6", ln_x6)
ln_x7 = [x for x in range(len(precision_sam61))]
print("Array x-axis 7", ln_x7)
ln_x8 = [x for x in range(len(precision_sam71))]
print("Array x-axis 8", ln_x8)
ln_x9 = [x for x in range(len(precision_sam81))]
print("Array x-axis 9", ln_x9)
ln_x10 = [x for x in range(len(precision_sam91))]
print("Array x-axis 10", ln_x10)
'''
'''
ln_x1 = [x for x in range(len(avg_precision_sam))]
print("Array x-axis 1", ln_x1)
ln_x2 = [x for x in range(len(avg_precision_sam1))]
print("Array x-axis 2", ln_x2)
ln_x3 = [x for x in range(len(avg_precision_sam2))]
print("Array x-axis 3", ln_x3)
ln_x4 = [x for x in range(len(avg_precision_sam3))]
print("Array x-axis 4", ln_x4)
ln_x5 = [x for x in range(len(avg_precision_sam4))]
print("Array x-axis 5", ln_x5)
ln_x6 = [x for x in range(len(avg_precision_sam5))]
print("Array x-axis 6", ln_x6)
ln_x7 = [x for x in range(len(avg_precision_sam6))]
print("Array x-axis 7", ln_x7)
ln_x8 = [x for x in range(len(avg_precision_sam7))]
print("Array x-axis 8", ln_x8)
ln_x9 = [x for x in range(len(avg_precision_sam8))]
print("Array x-axis 9", ln_x9)
ln_x10 = [x for x in range(len(avg_precision_sam9))]
print("Array x-axis 10", ln_x10)
'''

ln_x1 = [x for x in range(len(precision_lr_curve))]
ln_x2 = [x for x in range(len(precision_dt_curve))]
ln_x3 = [x for x in range(len(precision_rf_curve))]
ln_x4 = [x for x in range(len(precision_nb_curve))]
ln_x5 = [x for x in range(len(precision_xg_curve))]

'''
test_size1 = [0.05 for x in range(6)]
test_size2 = [0.15 for x in range(6)]
test_size3 = [0.25 for x in range(6)]
test_size4 = [0.35 for x in range(6)]
test_size5 = [0.45 for x in range(6)]
test_size6 = [0.55 for x in range(6)]
test_size7 = [0.65 for x in range(6)]
test_size8 = [0.75 for x in range(6)]
test_size9 = [0.85 for x in range(6)]
test_size10 = [0.95 for x in range(6)]
#test_sizes[0] = [precision_sam1, precision_sam3]
#test_sizes[1] = [precision_sam11, precision_sam12]
#test_sizes[3] = [precision_sam31, precision_sam32]
#x = [ln_x1, ln_x2, ln_x3, ln_x4, ln_x5, ln_x6]
# = [test_sizes[0], test_sizes[0], test_sizes[1], ]
#labels = [x.get_text() for x in Axes.get_xticklabels()]
'''

def update_ticks(x, pos):
    if x == 0:
        return '0.05'
    elif x == 1:
        return '0.10'
    elif x == 2:
        return '0.15'
    elif x == 3:
        return '0.20'
    elif x == 4:
        return '0.25'
    elif x == 5:
        return '0.30'
    elif x == 6:
        return '0.35'
    elif x == 7:
        return '0.40'
    elif x == 8:
        return '0.45'
    elif x == 9:
        return '0.5'
    elif x == 10:
        return '0.55'
    elif x == 11:
        return '0.6'
    elif x == 12:
        return '0.65'
    elif x == 13:
        return '0.7'
    elif x == 14:
        return '0.75'
    elif x == 15:
        return '0.8'
    elif x == 16:
        return '0.85'
    elif x == 17:
        return '0.9'
    elif x == 18:
        return '0.95'
    elif x == 19:
        return '1.0'
    else:
        return x


#Axes.set_xticklabels(labels)
#labels = ['Log Reg', '', 'Dec Tre', '', 'Nai Bay', '', 'XGBoost', '', 'Ran For']
#y_axis = [precision_sam1, precision_sam3, precision_sam11, precision_sam12]
#y = []
# precision_sam3, precision_sam13
#split1 = [precision_sam1, precision_sam3]
#split2 = [precision_sam11, precision_sam12]
#split3 = [precision_sam31, precision_sam32, precision_sam33]
# , precision_sam31, precision_sam32, precision_sam33
#y_axis = [(split1), (split2)]
'''
ax.set_title('Recall: NearMiss - Randomization 2012', size=20)
ax.plot(ln_x1, recall_sam1, label=legend_names[0])
ax.plot(ln_x2, recall_sam11, label=legend_names[1])
ax.plot(ln_x3, recall_sam31, label=legend_names[2])
ax.plot(ln_x4, recall_sam31, label=legend_names[3])
ax.plot(ln_x5, recall_sam41, label=legend_names[4])
ax.plot(ln_x6, recall_sam51,label=legend_names[5])
ax.plot(ln_x7, recall_sam61, label=legend_names[6])
ax.plot(ln_x8, recall_sam71, label=legend_names[7])
ax.plot(ln_x9, recall_sam81, label=legend_names[8])
ax.plot(ln_x10, recall_sam91, label=legend_names[9])
'''
ax.set_title('Precision: NearMiss - Randomization 2012', size=20)
ax.plot(ln_x1, precision_lr_curve, label=legend_names[0])
ax.plot(ln_x2, precision_dt_curve, label=legend_names[1])
ax.plot(ln_x3, precision_rf_curve, label=legend_names[2])
ax.plot(ln_x4, precision_nb_curve, label=legend_names[3])
ax.plot(ln_x5, precision_xg_curve, label=legend_names[4])
'''
#plt.xticks(x, labels)
#plt.plot(precision_sam3, precision_sam3, label=f'50%: Iteration 2')
#plt.plot(precision_sam3, precision_sam3, label=f'50%: Iteration 3')
#plt.plot(precision_sam11, precision_sam11, label=f'60%: Iteration 1')
#plt.plot(precision_sam12, precision_sam12, label=f'60%: Iteration 2')
#plt.plot(precision_sam13, precision_sam13, label=f'60%: Iteration 3')
#plt.plot(precision_sam31, precision_sam31, label=f'70%: Iteration 1')
#plt.plot(precision_sam32, precision_sam32, label=f'70%: Iteration 2')
#plt.plot(precision_sam33, precision_sam33, label=f'70%: Iteration 3')
'''
ax.xaxis.set_major_formatter(mticker.FuncFormatter(update_ticks))
ax.yaxis.set_major_locator(mticker.LinearLocator(11))
ax.set_xlim([0.0, 1.0])
ax.set_xlabel('Training Size', size=14)
ax.set_ylim([0.0, 1.0])
ax.set_ylabel('Precision', size=14)
'''
ax2 = ax.twinx()
ax2.yaxis.set_major_locator(mticker.LinearLocator(11))
ax2.set_ylabel('Precision', size=14)
ax2.set(ylim=ax.get_ylim())
'''
ax.legend()

'''
fig2 = plt.figure(10, 7)
data_pre = [precision_sam1b, precision_sam11b, precision_sam31b, precision_sam31b, precision_sam41b, precision_sam51b, precision_sam61b, precision_sam71b, precision_sam81b, precision_sam91b]
bpl = ax.boxplot(data_pre, vert=True, sym='', widths=0.6)
ticks = ['TS - 5%', 'TS - 15%', 'TS - 25%', 'TS - 35%', 'TS - 45%', 'TS - 55%', 'TS - 65%', 'TS - 75%', 'TS - 85%', 'TS - 95%']
#bpr = plt.boxplot(data_rec, positions=np.array(range(len(data_rec)))*2.0+0.4, vert=True, sym='', widths=0.6)
#bpl = plt.boxplot(data_pre, positions=[1, 3, 5, 7, 9], sym='', vert=True,  widths=0.6)
#bpr = plt.boxplot(data_rec, positions=[2, 4, 6, 8, 10],  sym='', vert=True, widths=0.6)
set_box_color(bpl, '#305C79') # colors are from http://colorbrewer2.org/
set_box_color(bpr, '#FF7900')

# draw temporary red and blue lines and use them to create a legend
#plt.plot([], c='#305C79', label='Precision', data=data_pre)
#plt.legend()
plt.xticks(ticks)
#plt.xlim(-2, len(ticks)*2)
#plt.ylim(0, 8)
#plt.tight_layout()
plt.title('Precision: Randomization NearMiss 2012')
plt.xlabel('Test Sizes/Iterations')
plt.ylabel('Precision')
plt.savefig('boxplot.png')
'''

plt.show();

writef.close()