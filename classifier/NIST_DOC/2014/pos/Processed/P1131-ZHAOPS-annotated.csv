,sentence,label,data
,,,
0,An Enhanced Context-sensitive Proximity Model for Probabilistic Information Retrieval,null,null
,,,
1,"Jiashu Zhao1, Jimmy Xiangji Huang2",null,null
,,,
2,"Information Retrieval and Knowledge Management Research Lab 1Department of Computer Science & Engineering, 2School of Information Technology",null,null
,,,
3,"York University, Toronto, Canada",null,null
,,,
4,"1jessie@cse.yorku.ca, 2jhuang@yorku.ca",null,null
,,,
5,ABSTRACT,null,null
,,,
6,"We propose to enhance proximity-based probabilistic retrieval models with more contextual information. A term pair with higher contextual relevance of term proximity is assigned a higher weight. Several measures are proposed to estimate the contextual relevance of term proximity1. We assume the top ranked documents from a basic weighting model are more relevant to the query, and calculate the contextual relevance of term proximity using the top ranked documents. We propose a context-sensitive2 proximity model, and the experimental results on standard TREC data sets show the effectiveness of our proposed model.",Y,null
,,,
7,Keywords,null,null
,,,
8,"Context-Sensitive IR, Measure, Proximity, Probabilistic Model",null,null
,,,
9,1. INTRODUCTION AND MOTIVATION,null,null
,,,
10,"The study of how to integrate the context information of queries and documents into retrieval process draw a lot of attention in recent years [3]. More specifically, many term proximity approaches [2, 9, 10, 11], which reward the documents where the query terms occurring closer to each other, show significant improvements over basic Information Retrieval (IR) models. In these proximity-based approaches, all the query term pairs are usually treated equally and the difference among various query pairs are not considered, although there is a need to distinguish the importance of term proximities. For example, given a query ""recycle automobile tires"", there is a stronger association between ""automobile"" and ""tire"" than the association between ""recycle"" and ""automobile"". In the top ranked documents, ""automobile"" and ""tire"" are expected to occur close to each other, while ""recycle"" and ""automobile"" do not necessarily have to occur close.",null,null
,,,
11,"In this paper, we focus on the problem of differentiating the influence of associated query term pairs. We propose",null,null
,,,
12,1The contextual relevance of term proximity is the relevancy between the query term proximity and the topic of the query. 2Context-sensitive means that the contextual relevance of term proximity is considered.,null,null
,,,
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609527.",null,null
,,,
14,"a proximity enhancement approach to integrate the contextual relevance of term proximity into the retrieval process. We also propose four measures for estimating the contextual relevance of term proximity, and reward the query term pairs according to both the proximity and the contextual relevance of proximity. There are several studies that boost proximity retrieval models. A machine learning method is proposed to determine the ""goodness"" of a span in [8]. [1] learns the concept importance from several sources (e.g. google n-gram corpus, query logs and wikipedia titles). SVM is used to learn different weights for various term dependencies in [6]. The importance of the global statistics is examined for proximity weighting [4]. Phrases are treated as providing a context for the component query terms in [7]. The contribution of this paper is that we propose the contextual relevance of term proximity, which represents to what extent the corresponding term pair should be related to the topic of the query. The contextual relevancy of term proximity is combined with the value of term proximity to characterize how much a document should be boosted.",null,null
,,,
15,"The remainder of this paper is organized as follows. In Section 2, we introduce four measures for estimating the contextual relevance of term proximity. In Section 3, we propose an enhanced context-sensitive proximity model using the proposed measures. Section 4 presents the experimental results and parameter sensitivities. Section 5 concludes the findings and discusses possible future directions.",null,null
,,,
16,2. CONTEXTUAL RELEVANCE OF TERM,null,null
,,,
17,PROXIMITY,null,null
,,,
18,"In this section, we propose how to estimate the contextual relevance of term proximity. The contextual relevance of term proximity is defined as how much the corresponding term pair should be related to the topic of the query in the context. The notations used in this paper are shown as follows.",null,null
,,,
19,"· Q ,"" {q1, ..., qm} is a query · D is a relevant document · tf (qi, D) is the term frequency of qi in D · {pos1,i, pos2,i, ..., postfi,i} are the positions of qi in the""",null,null
,,,
20,"document D · dist(posk1,i, posk2,j ) is defined as dist(posk1,i, posk2,j ) ,",null,null
,,,
21,"|posk1,i - posk2,j |, which is the distance between two positions.",null,null
,,,
22,"We measure the contextual relevance of term proximity base on the assumption that distributions of qi and qj in a relevant documents can represent the association between qi and qj. If qi and qj occur closely in relevant documents,",null,null
,,,
23,1131,null,null
,,,
24,RelCoOccur RelSqRecip RelM inDist RelKernel,null,null
,,,
25,"q1, q2 1.0000 0.2331 0.0486 1.3200",null,null
,,,
26,"q1, q3 1.0000 0.0408 0.0009 0.7200",null,null
,,,
27,"q1, q4 1.0000 0.0434 0.0025 0.7200",null,null
,,,
28,"q1, q5 0.0000 0.0000 0.0000 0.0000",null,null
,,,
29,"q2, q3 1.0000 0.0523 0.0067 0.7200",null,null
,,,
30,"q2, q4 1.0000 0.0434 0.0025 0.7200",null,null
,,,
31,"q2, q5 0.0000 0.0000 0.0000 0.0000",null,null
,,,
32,"q3, q4 1.0000 1.0000 0.3133 0.4800",null,null
,,,
33,"q3, q5 0.0000 0.0000 0.0000 0.0000",null,null
,,,
34,Table 1: An example of the contextual relevance of term proximity,null,null
,,,
35,"q4, q5 0.0000 0.0000 0.0000 0.0000",null,null
,,,
36,"the contextual relevance of term proximity between qi and qj is high. On the contrary, if qi and qj do not co-occur or occur far away to each other, the contextual relevance of term proximity between qi and qj is low. Therefore we propose the following four methods for estimating the contextual relevance of term proximity between qi and qj in a relevant document D. For the extreme case when qi and qj do not co-occur in D, we consider the contextual relevance of term proximity equals 0. Otherwise, we define the following measures to generate a positive value for the contextual relevance of term proximity.",null,null
,,,
37,"Definition 1. RelCoOccur(qi, qj , D) is defined to be 1, if qi and qj both occur in D.",null,null
,,,
38,"RelCoOccur(qi, qj , D) , 1{qiDqj D}",null,null
,,,
39,-1,null,null
,,,
40,Definition 2. The RelSqRecip is defined as the sum of squared reciprocal distances between qi and qj.,null,null
,,,
41,"tf (qi,D) tf (qj ,D)",null,null
,,,
42,1,null,null
,,,
43,"RelSqRecip(qi, qj , D) ,",null,null
,,,
44,"k1 ,1",null,null
,,,
45,"k2,""1 dist(posk1,i, posk2,j )2""",null,null
,,,
46,-2,null,null
,,,
47,Definition 3. The RelMinDist is a defined as the following function of the minimum distance between qi and qj.,null,null
,,,
48,"RelMinDist(qi, qj , D) ,"" ln( + e-MinDist(qi,qj ,D)) (3)""",null,null
,,,
49,"where  is a parameter, and M inDist(qi, qj, D) is the minimum distance between all co-occurring qi and qj in D.",null,null
,,,
50,"M inDist(qi, qj, D) ,"" mink1{1..tf (qi,D)},k2{1..tf (qj ,D)}(dist(posk1,i, posk2,j ))""",null,null
,,,
51,Definition 4. The RelKernel is defined as the sum of the kernel functions of distances between qi and qj.,null,null
,,,
52,"RelKernel(qi, qj , D)",null,null
,,,
53,"tf (qi,D) tf (qj ,D)",null,null
,,,
54,1,null,null
,,,
55,-4,null,null
,,,
56,",",null,null
,,,
57,"Kernel( 2 dist(posk1,i, posk2,j ))",null,null
,,,
58,"k1,1 k2,1",null,null
,,,
59,where Kernel(·) is kernel function. Here we use the triangle,null,null
,,,
60,kernel function.,null,null
,,,
61,K ernel(u),null,null
,,,
62,",",null,null
,,,
63,(1,null,null
,,,
64,-,null,null
,,,
65,u) ,null,null
,,,
66,·,null,null
,,,
67,1{u},null,null
,,,
68,-5,null,null
,,,
69,"where u is an input value, and  is the kernel parameter.",null,null
,,,
70,"These functions measure the contextual relevance from different perspectives. RelCoOccur measures whether qi and qj are co-occurring in D. RelSqRecip, RelMinDist and RelKernel considers the positions of qi and qj in D. In RelSqRecip, we generate a squared reciprocal function for the distances between all the occurrences of qi and qj, and accumulate the values over D. Then the query term pairs with terms occurring closer to each other and/or occurring more frequently",null,null
,,,
71,"will have higher contextual relevance. RelMinDist is modified from [9], where the minimum distance is shown to be more effective than the other distance-based and span-based proximity approaches. RelKernel utilizes the term proximity approach proposed in [10], where a query term is simulated by the kernel function, where the triangle kernel function is recognized to be the most effective. Different types of information are incorporated in these measures.",null,null
,,,
72,"To better analyze the contextual relevance measurements defined above, we present an example for a given query Q ,"" {q1, q2, q3, q4, q5} and a relevant document D.""",null,null
,,,
73,"D , {xq1xq2xxxxq3q4xxxxxq1xq2}",null,null
,,,
74,"where x represents a non-query term. By observing the query and the document, we find that the term q5 does not present in D, which means it does not related to D, and therefore do not have an association with other query terms. Since q3 and q4 are adjacent to each other and far apart from other query terms, q3 and q4 are more likely to have a stronger association than the combination of q2 and q4. We calculate the contextual relevance of term proximity between q2 and q4 as an instance, and the procedure will be the same for the rest of the query term pairs. The term frequency of terms q2 and q4 are tf (q2, D) ,"" 2 and tf (q4, D) "","" 1. The positions of q2 and q4 in D are pos(q2, D) "","" {4, 18} and pos(q4, D) "","" {10} correspondingly. Therefore there are 2 co-occurrences of q2 and q4, and the corresponding distances between these co-occurrences are {6, 8}. Then we can calculate Rel(q2, q4, D) with these distances by formulae (1-4). Table 1 shows the values of the contextual relevance of term proximity in this example.""",null,null
,,,
75,"We can see that the contextual relevance measures defined above show different characteristics. RelCoOccur detects term pairs with or without an association. For example, q5 and other query terms do not have an association. The term pairs containing q5 are distinguished by RelCoOccur. On the other hand, RelCoOccur does not consider the term distributions in D. RelMinDist takes into account the closest occurrences between a pair of quay terms, and does not consider the frequency of occurrences. RelMinDist and RelKernel accumulates over all the occurrences of two query terms, with different functions and therefore generates different values.",null,null
,,,
76,3. CONTEXT-SENSITIVE PROXIMITY MODEL,null,null
,,,
77,"In this section, we propose a context-sensitive proximity retrieval model, by integrating the proposed measures for contextual relevance of term proximity into retrieval process. Naturally we treat the values of contextual relevance as weights to reward the query term pairs with higher contextual relevance and to penalize the query term pairs with lower contextual relevance. In practice, we assume the top ranked documents returned by a basic retrieval model (for example, BM25) are more relevant than the rest of the documents. The averaged contextual relevance of term proximity over the top ranked documents is multiplied by the proximity part in the weighting function. A general form of the",null,null
,,,
78,1132,null,null
,,,
79,context-sensitive proximity model is,null,null
,,,
80,RelP rox(D ),null,null
,,,
81,","" (1 - )  qi w(qi, D )""",null,null
,,,
82,-6,null,null
,,,
83,#NAME?,null,null
,,,
84,"where D is a given document, w(qi, D ) is the weight of qi in D by a basic probabilistic weighting function, P rox(qi, qj, D ) is a bigram proximity weighting approach,  is a balancing parameter, topDoc is the number of top ranked documents, AR(qi, qj, topDoc) is the average contextual relevance value of term proximity between qi and qj over the top ranked documents",null,null
,,,
85,"1 AR(qi, qj, topDoc) ,"" topDoc Rel(qi, qj, D) (7)""",null,null
,,,
86,D,null,null
,,,
87,"where Rel(qi, qj, D) is one of the measures defined in Section 2. Please note that AR(qi, qj, topDoc), P rox(qi, qj, D ) and w(qi, D ) need to be normalized to the same scale.",null,null
,,,
88,"In formula (6), we use the probabilistic BM25 [5] as the basic weighting function. We adopt the proximity approach used in CRTER [10], since it is an effective pairwise proximity model for probabilistic IR. The BM25 weighting function has the following form.",null,null
,,,
89,"w(qi, D )",null,null
,,,
90,","" (k1 + 1)  tf (qi, D )  (k3 + 1)  qtf (qi)  log N - n(qi) + 0.5""",null,null
,,,
91,"K + tf (qi, D )",null,null
,,,
92,k3 + qtf (qi),null,null
,,,
93,n(qi) + 0.5,null,null
,,,
94,-8,null,null
,,,
95,"where N is the number of documents in the collection, n(qi) is the number of documents containing qi, qtf (qi ) is the within-query term frequency, dl (D ) is the length D , avdl is the average document length, the kis are tuning constants, K equals k1  ((1 - b) + b  dl(D)/avdl). The proximity part of CRTER is shown as follows.",null,null
,,,
96,"P rox(qi, qj , D ) ,"" w(qi,j , D )""",null,null
,,,
97,-9,null,null
,,,
98,"where qi,j represents the association between query terms qi and qj, w(qi,j, D ) is the BM25 weighting function with the following features of qi,j [10]",null,null
,,,
99,"tf (qi,j ,",null,null
,,,
100,D,null,null
,,,
101,),null,null
,,,
102,",",null,null
,,,
103,"tf (qi,D",null,null
,,,
104,),null,null
,,,
105,"tf (qj ,D",null,null
,,,
106,),null,null
,,,
107,K,null,null
,,,
108,er,null,null
,,,
109,nel(,null,null
,,,
110,1 2,null,null
,,,
111,dist(posk1,null,null
,,,
112,",i",null,null
,,,
113,",",null,null
,,,
114,"posk2,j ))",null,null
,,,
115,"k1 ,1",null,null
,,,
116,"k2 ,1",null,null
,,,
117,"qtf (qi,j )",null,null
,,,
118,",",null,null
,,,
119,K ernel(,null,null
,,,
120,1 2,null,null
,,,
121,),null,null
,,,
122,·,null,null
,,,
123,"min(qtf (qi),",null,null
,,,
124,qtf,null,null
,,,
125,(qj )),null,null
,,,
126,"n(qi,j ) ,",null,null
,,,
127,D,null,null
,,,
128,"tf (qi,j , D ) Occur(qi,j , D )",null,null
,,,
129,"where Kernel(·) is a kernel function, and Occur(qi,j, D )",null,null
,,,
130,equals,null,null
,,,
131,"tfi k1 ,1",null,null
,,,
132,1 . tfj,null,null
,,,
133,"k2 ,1",null,null
,,,
134,{K,null,null
,,,
135,ernel(,null,null
,,,
136,1 2,null,null
,,,
137,dist(posk1,null,null
,,,
138,",i",null,null
,,,
139,",posk2",null,null
,,,
140,",j",null,null
,,,
141,")),0}",null,null
,,,
142,4. EXPERIMENTS,null,null
,,,
143,We evaluate the proposed approach on three standard,null,null
,,,
144,"TREC data sets. They are AP88-89 with topics 51-100,",null,null
,,,
145,"Web2G with topics 401-450, and TREC8 with topics 401-",Y,null
,,,
146,450. AP88-89 contains articles published by Association,null,null
,,,
147,Press from the year of 1988 to 1989. The WT2G collec-,Y,null
,,,
148,tion is a 2G size crawl of Web documents. The TREC8,Y,null
,,,
149,"contains newswire articles from various sources, such as Fi-",null,null
,,,
150,"nancial Times (FT), the Federal Register (FR) etc. For all",null,null
,,,
151,"the data sets used, each term is stemmed using Porter's En-",null,null
,,,
152,"glish stemmer, and standard English stopwords are removed.",null,null
,,,
153,"We have three baseline models, BM25, Dirichlet Language",null,null
,,,
154,Data Sets,null,null
,,,
155,BM25 Dirichlet LM,null,null
,,,
156,CRTER Improvement over BM25,null,null
,,,
157,RelCoOccur Improvement over BM25 Improvement over CRTER,null,null
,,,
158,RelSqRecip Improvement over BM25 Improvement over CRTER,null,null
,,,
159,RelM inDist Improvement over BM25 Improvement over CRTER,null,null
,,,
160,RelKernel Improvement over BM25 Improvement over CRTER,null,null
,,,
161,AP88-89,null,null
,,,
162,0.2708 0.2763,null,null
,,,
163,0.2744 1.329%,null,null
,,,
164,0.2768 2.216% 0.875%,null,null
,,,
165,0.2812* 3.840% 2.478%,null,null
,,,
166,0.2800 3.397% 2.041%,null,null
,,,
167,0.2812* 3.840% 2.478%,null,null
,,,
168,Web2G,null,null
,,,
169,0.3136 0.3060,null,null
,,,
170,0.3298* 5.166%,null,null
,,,
171,0.3375* 7.621% 2.335%,null,null
,,,
172,0.3444*  9.821% 4.427%,null,null
,,,
173,0.3444*  9.821% 4.427%,null,null
,,,
174,0.3425* 9.216% 3.851%,null,null
,,,
175,TREC8,Y,null
,,,
176,0.2467 0.2552,null,null
,,,
177,0.2606 * 5.634%,null,null
,,,
178,0.2622* 6.283% 0.614%,null,null
,,,
179,0.2633* 6.729% 1.036%,null,null
,,,
180,0.2615* 5.999% 0.345%,null,null
,,,
181,0.2625* 6.405% 0.729%,null,null
,,,
182,"Table 2: Overall MAP Performance (""*"" indicates significant improvement over BM25, and """" indicates significant improvement over CRTER)",null,null
,,,
183,"Model (LM) and CRTER. The best parameters are chosen in the baseline models for fair comparisons. In BM25, the values of k1, k2, k3 and b are set to be 1.2, 0, 8 and 0.35 respectively, since they are recognized with a good performance. In CRTER model, we use the recommended settings [10]., which are  ,"" 25,  "","" 0.2, and triangle kernel function. In our proposed context-sensitive proximity model, we use the same parameters in the basic weighting model part (e.g. BM25) and the proximity part (e.g. CRTER). In RelKernel, we set the kernel parameter  "","" 25. In RelMinDist, we set  "","" 1, which has the best performance in [9]. We normalize AR(qi, qj, topDoc), P rox(qi, qj, D ) and w(qi, D ) in formula (6) to the scale of [0,1]. We use the Mean Average Precision (MAP) as our evaluation metric.""",null,null
,,,
184,"Table 2 shows the overall MAP performance. The proposed context-sensitive proximity model outperforms BM25, Language Model (LM) and CRTER with all of the contextual relevance measuring approaches on all the data sets. For the space limitation, we only include these comparisons. It shows that using the contextual relevance of term proximity can further boost the retrieval performance. We can see that the RelCoOccur, which measures whether two query terms are co-occurring in the relevant documents, reaches the lowest MAP among the contextual relevance measures, which indicates the necessity of considering the term location information in the term pair contextual relevance definition. RelSqRecip has the highest MAP over the other approaches on all the data sets. In general, considering both the closeness and frequency of two query terms in the contextual relevance definition benefits the contextual relevance estimation.",null,null
,,,
185,"In Table 3, we investigate how the number of top relevant documents affects the retrieval performance. We take the topDoc ,"" 5, 10, 20, 30, 40, 50 60, 70, and 80 documents as relevant, and calculate the average contextual relevance obtained from these documents. The bolded values are the best performance among different topDoc values. We can see that the best topDoc will be around 5 to 40. It means that selecting too many top documents as relevant will introduce noises to the model.""",null,null
,,,
186,"Figure ?? shows the sensitivity of  on all the data sets. We can see that with the growth of , MAP first increases",null,null
,,,
187,1133,null,null
,,,
188,AP88-89 Web2G TREC8,Y,null
,,,
189,RelCoOccur RelSqRecip RelM inDist RelKernel,null,null
,,,
190,RelCoOccur RelSqRecip RelM inDist RelKernel,null,null
,,,
191,RelCoOccur RelSqRecip RelM inDist RelKernel,null,null
,,,
192,5,null,null
,,,
193,0.2757 0.281 0.2800 0.2812,null,null
,,,
194,0.3348 0.3401 0.3351 0.3358,null,null
,,,
195,0.2622 0.2633 0.2612 0.2625,null,null
,,,
196,10,null,null
,,,
197,0.2766 0.2812 0.2794 0.2796,null,null
,,,
198,0.3359 0.342 0.3444 0.3409,null,null
,,,
199,0.2612 0.263 0.2614 0.2622,null,null
,,,
200,20,null,null
,,,
201,0.2768 0.2801 0.2800 0.2801,null,null
,,,
202,0.3354 0.3409 0.3421 0.3425,null,null
,,,
203,0.2614 0.2627 0.2615 0.2619,null,null
,,,
204,30,null,null
,,,
205,0.2767 0.2801 0.2796 0.2801,null,null
,,,
206,0.3367 0.3401 0.3382 0.3406,null,null
,,,
207,0.2611 0.2623 0.2612 0.2615,null,null
,,,
208,40,null,null
,,,
209,0.2762 0.2789 0.2797 0.2789,null,null
,,,
210,0.3375 0.3444 0.3406 0.3423,null,null
,,,
211,0.2611 0.2617 0.2606 0.2607,null,null
,,,
212,50,null,null
,,,
213,0.2759 0.2781 0.2784 0.2781,null,null
,,,
214,0.3369 0.3435 0.3414 0.3418,null,null
,,,
215,0.261 0.2615 0.2605 0.2604,null,null
,,,
216,60,null,null
,,,
217,0.2758 0.278 0.279 0.2783,null,null
,,,
218,0.3367 0.3433 0.3427 0.3421,null,null
,,,
219,0.2608 0.2613 0.2606 0.2605,null,null
,,,
220,Table 3: Performance over the change of topDoc,null,null
,,,
221,70,null,null
,,,
222,0.2755 0.2777 0.2787 0.2781,null,null
,,,
223,0.3374 0.3424 0.3434 0.3414,null,null
,,,
224,0.2601 0.2614 0.2607 0.2605,null,null
,,,
225,80,null,null
,,,
226,0.2753 0.2774 0.2786 0.278,null,null
,,,
227,0.3363 0.3419 0.3433 0.3399,null,null
,,,
228,0.2599 0.2612 0.2605 0.2606,null,null
,,,
229,0.285,null,null
,,,
230,0.28,null,null
,,,
231,0.275,null,null
,,,
232,0.27,null,null
,,,
233,0.265,null,null
,,,
234,0.26,null,null
,,,
235,0.255,null,null
,,,
236,QualityCoOccur,null,null
,,,
237,0.25,null,null
,,,
238,QualitySqRecip,null,null
,,,
239,0.245,null,null
,,,
240,QualityMinDist QualityKernel,null,null
,,,
241,0.24,null,null
,,,
242,0,null,null
,,,
243,0.2,null,null
,,,
244,0.4,null,null
,,,
245,0.6,null,null
,,,
246,0.8,null,null
,,,
247,1,null,null
,,,
248,(a) AP88-89,null,null
,,,
249,0.36,null,null
,,,
250,0.35,null,null
,,,
251,0.34,null,null
,,,
252,0.33,null,null
,,,
253,0.32,null,null
,,,
254,0.31,null,null
,,,
255,0.3,null,null
,,,
256,QualityCoOccur,null,null
,,,
257,0.29,null,null
,,,
258,QualitySqRecip,null,null
,,,
259,0.28,null,null
,,,
260,QualityMinDist,null,null
,,,
261,QualityKernel,null,null
,,,
262,0.27,null,null
,,,
263,0,null,null
,,,
264,0.2,null,null
,,,
265,0.4,null,null
,,,
266,0.6,null,null
,,,
267,0.8,null,null
,,,
268,1,null,null
,,,
269,(b) Web2G Figure 1: Sensitivity of ,null,null
,,,
270,0.26,null,null
,,,
271,0.25,null,null
,,,
272,0.24,null,null
,,,
273,0.23,null,null
,,,
274,QualityCoOccur,null,null
,,,
275,QualitySqRecip,null,null
,,,
276,0.22,null,null
,,,
277,QualityMinDist,null,null
,,,
278,QualityKernel,null,null
,,,
279,0.21,null,null
,,,
280,0,null,null
,,,
281,0.2,null,null
,,,
282,0.4,null,null
,,,
283,0.6,null,null
,,,
284,0.8,null,null
,,,
285,1,null,null
,,,
286,(c) TREC8,Y,null
,,,
287,MAP MAP MAP,null,null
,,,
288,"and then decreases. Please note that when  ,"" 0, there is no proximity utilized, which is our baseline BM25. When  "","" 1, only term proximity and the contextual relevance of term proximity are considered. In CRTER, the recommended setting for the balancing parameter is 0.2. After introducing the contextual relevance of term proximity, we can see that the balancing parameter  with a value of around 0.3 or 0.4 is better. The reason is that the contextual relevance is normalized to [0,1]. The value for the second part of formula (6) becomes smaller, therefore it requires a larger balancing parameter.""",null,null
,,,
289,5. CONCLUSIONS AND FUTURE WORK,null,null
,,,
290,"We propose a new approach to integrate the contextual relevance of term proximity in retrieval. The contextual relevance of term proximity evaluates how much we should focus on a pair of query terms. In particular, we propose four measures to estimate the contextual relevance of term proximity, namely RelOcOccur, RelSqRecip, RelMinDist, and RelKernel. They incorporate different types of information utilized in the contextual relevance of term proximity. We further propose a context-sensitive proximity model via multiplying the contextual relevance of term proximity by the proximity part in a retrieval model.",null,null
,,,
291,"We evaluate our proposed context-sensitive proximity model on several TREC standard data sets, and the experimental results show the effectiveness of our proposed model over three baselines BM25, Dirichlet LM and CRTER with optimal parameter settings. In more detail, we discuss how many top documents should be selected for calculating the proximity contextual relevance, and how the balancing parameter  affects the retrieval performance.",Y,null
,,,
292,"In the future, we can extend the contextual relevance of term proximity to more query terms. In addition, the contextual relevance of term proximity can be adopted in other",null,null
,,,
293,basic weighting models (e.g. Language Model) and/or other,null,null
,,,
294,proximity approaches. We can also apply the proposed,null,null
,,,
295,model into relevance feedback.,null,null
,,,
296,6. ACKNOWLEDGEMENTS,null,null
,,,
297,This research is supported by the research grant from the,null,null
,,,
298,NSERC of Canada and the Early Researcher Award. We,null,null
,,,
299,thank four anonymous reviewers for their thorough review,null,null
,,,
300,comments on this paper.,null,null
,,,
301,"7. REFERENCES [1] M. Bendersky, D. Metzler, and W. B. Croft. Learning concept importance using a weighted dependence model. In Proc. of WSDM, pages 31­40. ACM, 2010. [2] S. Buttcher, C. Clarke, and B. Lushman. Term proximity scoring for ad-hoc retrieval on very large text collections. In Proc. of SIGIR, page 622. ACM, 2006. [3] W. Croft, D. Metzler, and T. Strohman. Search engines: Information retrieval in practice. Addison-Wesley, 2010. [4] C. Macdonald and I. Ounis. Global statistics in proximity weighting models. In Web N-gram Workshop, pages 30­37, 2010. [5] S. E. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, M. Gatford, et al. Okapi at TREC-3. In Proc. of TREC, pages 109­126. NIST, 1995. [6] L. Shi and J.-Y. Nie. Using various term dependencies according to their utilities. In Proc. of CIKM, pages 1493­1496. ACM, 2010. [7] R. Song, M. J. Taylor, J.-R. Wen, H.-W. Hon, and Y. Yu. Viewing term proximity from a different perspective. In Proc. of ECIR, pages 346­357. Springer, 2008. [8] K. M. Svore, P. H. Kanani, and N. Khan. How good is a span of terms? exploiting proximity to improve web retrieval. In Proc. of SIGIR, pages 154­161. ACM, 2010. [9] T. Tao and C. Zhai. An exploration of proximity measures in information retrieval. In Proc. of SIGIR, pages 259­302. ACM, 2007. [10] J. Zhao, J. Huang, and B. He. CRTER: using cross terms",null,null
,,,
302,"to enhance probabilistic information retrieval. In Proc. of SIGIR, pages 155­164, 2011. [11] J. Zhao, J. X. Huang, and Z. Ye. Modeling term associations for probabilistic information retrieval. ACM Transactions on Information Systems (TOIS), 32(2):7, 2014.",null,null
,,,
303,1134,null,null
,,,
304,,null,null
