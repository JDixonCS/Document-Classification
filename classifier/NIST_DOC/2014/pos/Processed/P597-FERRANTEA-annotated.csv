,sentence,label,data
,,,
0,Injecting User Models and Time into Precision via Markov Chains,null,null
,,,
1,Marco Ferrante,null,null
,,,
2,"Dept. Mathematics University of Padua, Italy",null,null
,,,
3,ferrante@math.unipd.it,null,null
,,,
4,Nicola Ferro,null,null
,,,
5,"Dept. Information Engineering University of Padua, Italy",null,null
,,,
6,ferro@dei.unipd.it,null,null
,,,
7,Maria Maistro,null,null
,,,
8,"Dept. Information Engineering University of Padua, Italy",null,null
,,,
9,maistro@dei.unipd.it,null,null
,,,
10,ABSTRACT,null,null
,,,
11,"We propose a family of new evaluation measures, called Markov Precision (MP), which exploits continuous-time and discrete-time Markov chains in order to inject user models into precision. Continuous-time MP behaves like timecalibrated measures, bringing the time spent by the user into the evaluation of a system; discrete-time MP behaves like traditional evaluation measures. Being part of the same Markovian framework, the time-based and rank-based versions of MP produce values that are directly comparable.",null,null
,,,
12,We show that it is possible to re-create average precision using specific user models and this helps in providing an explanation of Average Precision (AP) in terms of user models more realistic than the ones currently used to justify it. We also propose several alternative models that take into account different possible behaviors in scanning a ranked result list.,null,null
,,,
13,"Finally, we conduct a thorough experimental evaluation of MP on standard TREC collections in order to show that MP is as reliable as other measures and we provide an example of calibration of its time parameters based on click logs from Yandex.",Y,null
,,,
14,Categories and Subject Descriptors,null,null
,,,
15,H.3.4 [Information Search and Retrieval]: Systems and Software--Performance evaluation (efficiency and effectiveness),null,null
,,,
16,General Terms,null,null
,,,
17,"Experimentation, Measurement, Performance",null,null
,,,
18,Keywords,null,null
,,,
19,Evaluation; Markov Precision; User Model; Time,null,null
,,,
20,1. INTRODUCTION,null,null
,,,
21,Experimental evaluation has been central to Information Retrieval (IR) since its beginning [15] and Cranfield is the,null,null
,,,
22,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609637.",null,null
,,,
23,"predominant paradigm for carrying out system-oriented experimentation [11]. Over the decades, several measures have been proposed to evaluate retrieval effectiveness.",null,null
,,,
24,"AP [5] represents the ""gold standard"" measure in IR [35], known to be stable [3] and informative [1], with a natural top-heavy bias and an underlying theoretical basis as approximation of the area under the precision/recall curve. Nevertheless, due to its dependence on the recall base, it assumes a perfect knowledge of the relevance of each document in the collection, which is an approximation when pooling is adopted and not assessed documents are assumed to be not relevant [14], and is even more exacerbated in the case of large scale or dynamic collections [4, 35].",null,null
,,,
25,"However, the strongest criticism to AP comes from the absence of a convincing user model for it, a feature which is deemed extremely important in order to make the interpretation of a measure meaningful and to bridge the gap between system-oriented and user-oriented studies [7, 21, 31]. In this respect, [22] argued that the model behind AP is abstract, complex, and far from the real behavior of users interacting with an IR system, especially when it comes to its dependence on the recall base which is something actually unknown to real users. As a consequence, [25] proposed a simple but moderately plausibile user model for AP, which allows for a mix of different behaviors in the population of users.",null,null
,,,
26,"In this paper, we take up from the final considerations of [25], at page 690: ""this argument could provide the basis for a more elaborate model, by for example basing the set of ps(n) on some more sophisticated view of stopping behaviour"", where ps(n) is the probability that the user satisfaction point is the document at rank n.",null,null
,,,
27,"We propose a family of measures of retrieval effectiveness, called Markov Precision (MP), where we exploit Markov chains [23] to inject different user models into precision and which does not depend on the recall base. We represent each position in a ranked result list with a state in a Markov chain and the different topologies and transition probabilities among the states of the Markov chain allow us to model the different and perhaps complex user behaviors and paths in scanning a ranked result list. The invariant distribution of the Markov chain provides us with the probability of the user being in a given state/rank position in stationary conditions and we use these probabilities to compute a weighted average of precision at those rank positions.",null,null
,,,
28,The framework we propose is actually more general and it is based on continuous-time Markov chains in order to take into account also the time a user spends in visiting a sin-,null,null
,,,
29,597,null,null
,,,
30,"gle document. It is then possible to extract a discrete-time Markov chain, when considering only the transitions among rank positions and not the time spent in each document. This gives us a two-fold opportunity: when we consider the discrete-time Markov chain, we are basically reasoning as traditional evaluation measures which assess the utility for the user in scanning the ranked result list; when we consider the continuous-time Markov chain,we also embed the information about the time spent by the user in visiting a document and we have a single measure including both aspects. This represents a valuable contribution of the paper since, up to now, rank and time have been two separate variables according to which retrieval effectiveness is evaluated [31].",null,null
,,,
31,"The Markov chain approach relies on some assumptions ­ e.g. no long-term memory and exponentially distributed holding times ­ which may seem oversimplifications of the reality, e.g. a user who considers the whole history of visited documents to decide whether to stop or not. However, other measures, such as Rank-Biased Precision (RBP) [22] where transitioning to the next document or stopping is a step-bystep decision based just on the persistence parameter, are memory-less in this sense. Moreover, a Markovian model is simple enough to be easily dealt with while still being quite powerful and this work intends to be a first step towards a richer world of models that we will explore in the future.",null,null
,,,
32,"We then propose some basic models for the transition matrix of the Markov chain. Clearly, this is not intended to be an exhaustive list of all the possible models but more of an exemplification of how it is possible to plug different user models into the framework. Still, these basic models provide a second valuable contribution of the paper. Indeed, we will show how some of these models, when provided with the same level of information about the recall base as AP, actually are AP, thus giving an explanation of it in terms of a slightly richer user model than the one of [25]. We will also show how some of them are extremely highly correlated to AP, thus suggesting how AP can be considered a very good approximation of more complex user strategies. This helps in shedding some light on why AP is the de-facto ""gold standard"" in IR, even though it has been so often criticized.",null,null
,,,
33,"Finally, we conduct a thorough experimental evaluation of the MP measure both using standard Text REtrieval Conference (TREC)1 collections and click-logs with assessed queries made available by Yandex [29]. The results show that MP is comparable to other measures for some desirable properties like robustness to pool downsampling while the Yandex click-logs allow us to estimate the time spent by the users on the documents and apply the continous-time Markov chain.",Y,null
,,,
34,The paper is organized as follows: Section 2 presents the related works; Section 3 discusses other pertinent measures to which MP will be compared; Section 4 fully introduces MP; Section 5 reports the conducted experimental evaluation of MP; and Section 6 draws some conclusion and provides an outlook for future work.,null,null
,,,
35,2. RELATED WORKS,null,null
,,,
36,"Markov-based approaches have been previously exploited in IR, for example: Markov chains have been used to generate query models [19], for query expansion [12, 20], and for document ranking [13]. However, to the best of our knowl-",null,null
,,,
37,1http://trec.nist.gov/,Y,null
,,,
38,"edge, Markov chains have not been applied to the definition of a fully-fledged measure for retrieval effectiveness.",null,null
,,,
39,"[8] uses Markov chains to address the placement problem in the case of two-dimensional results presentation: they have to allocate images on a grid to maximize the expected total utility of the user, according to some evaluation measure, and the Markov chain models how the user moves in the grid. Their approach differs from ours since they are not defining a measure of effectiveness which embeds a Markov chain but they rather solve an optimization problem via a Markov chain; moreover, they only use discrete-time Markov chains and limit transitions only to adjacent states. What we share is the idea that a Markov chain can be used to model how a user scans a result list, mono dimensional in our case, two-dimensional in their case.",null,null
,,,
40,"When it comes to other evaluation measures, the focus of the paper is on lab-style evaluation, search tasks with informational intents [2], and binary relevance. So, for example, measures for novelty and diversity are out of the scope of the present paper [10] as are measures for graded relevance like Discounted Cumulated Gain (DCG) [16], Expected Reciprocal Rank (ERR) [6], or Q-measure [26].",null,null
,,,
41,"With regard to the time dimension brought in by the continuous-time Markov chain, the most relevant work is Time-Biased Gain (TBG) [30, 31]. We share the idea of getting time into evaluation measures but we adopted a different approach. While TBG substitutes traditional evaluation measures, MP provides a single framework for keeping both aspects depending on which Markov chain you use. With respect to the user model adopted in TBG, there are some relevant differences: first, we use full Markov models while [30] at page 2014 points out that ""our model can be viewed as a semi-Markov model""; then, TBG assumes a sequential scanning of the result lists where MP allows the user to move and jump backward and forward in the results list. What TBG addressed and is not in the scope of the present work is how to calibrate the measure with respect to time: [31] proposed a procedure to calibrate time with respect to document length and [30] extended it to stochastic simulation. In the present work, we provide a basic example of calibration based on the estimation of average time spent per document from click logs, just to show how the parameters of the framework could be tuned. However, in the future, nothing prevents us (or others) from investigating more advanced calibration strategies or applying those proposed by [30, 31].",null,null
,,,
42,"Previous work on click logs [17] has reported that, on average, users scan ranked list in a forward linear fashion while MP allow users to move forward and backward in a ranked list. As reported in Section 5.5, from Yandex logs, we found that 21% of the users move backward in the ranked list, thus supporting our assumption, even if more exploration on this is left for future work. Moreover, U-measure [28] is a recent proposal which shares with MP the idea of removing the constraint of the linear scan but it does not adopt Markov models and has also somewhat different goals, such as evaluating complex tasks like multi-query sessions and diversified IR.",null,null
,,,
43,"When it comes to other ways of modelling user behaviour into evaluation measures, [7] proposes relying on three components: a browsing model, a model of document utility, and a utility accumulation model. Even if we took up from [25], MP can also be framed in the light of the work of [7]. Indeed,",null,null
,,,
44,598,null,null
,,,
45,"the Markovian model provides us with the browsing model, precision account for the model of document utility, and the weighted average of precision by the invariant distribution of the Markov chain supplies the utility accumulation model.",null,null
,,,
46,"Thus, evaluation measures of direct comparison, which will be detailed in Section 3, are those built around the concept of precision, namely AP, P@10, and Rprec [5]. RBP [22] comes into play as a binary evaluation measure not dependent on the recall base, even though it is not built around the concept of precision despite its name. Finally, we are also interested in Binary Preference (bpref) [4], just to have a comparison point when testing MP with respect to reducedsize pools. In this last respect, we are not interested in infAP [35], since we are neither looking for an estimator of AP nor investigating alternative strategies for pool downsampling. For the same reason, we are not interested here in experimenting with respect to condensed-list measures [27].",null,null
,,,
47,3. OTHER EVALUATION MEASURES,null,null
,,,
48,"Let us consider a ranked list of T documents in response to a given topic, let dn be the document retrieved at position n  T whose relevance is denoted by an, equal to 1 if the document is considered relevant and 0 otherwise. The ranked list of documents is denoted with D ,"" {di, i  T } and R "", {ij : j ,"" 1, . . . , T and aij "","" 1} is the set of the ranks of the relevant documents, whose cardinality is r "","" |R| and which indicate the total number of relevant retrieved documents by the system for the given topic. Let RB be the recall base of the topic, i.e. the total number of judged relevant documents for a given topic, and N RB the total number of judged not relevant documents for a given topic.""",null,null
,,,
49,The precision at rank n is thus defined as,null,null
,,,
50,1n,null,null
,,,
51,"Prec(n) , n",null,null
,,,
52,am,null,null
,,,
53,-1,null,null
,,,
54,"m,1",null,null
,,,
55,"which corresponds to the percentage or ""density"" of relevant",null,null
,,,
56,"documents present among the first n, n included, in the",null,null
,,,
57,"list. Note that Rprec is Prec(RB), which makes clear its",null,null
,,,
58,dependence on the recall base.,null,null
,,,
59,The recall at rank T is defined as,null,null
,,,
60,Rec(T ),null,null
,,,
61,",",null,null
,,,
62,r RB,null,null
,,,
63,-2,null,null
,,,
64,which corresponds to the fraction of relevant documents of the specific run with respect to the total number of judged relevant documents.,null,null
,,,
65,3.1 Average Precision (AP),null,null
,,,
66,"The original definition of Average Precision (AP) [5] is the average over all RB judged relevant documents of the precision at their ranks, considering zero the precision at the not retrieved relevant documents:",null,null
,,,
67,"AP , 1",null,null
,,,
68,"Prec(i) , r · 1 Prec(i) (3)",null,null
,,,
69,RB,null,null
,,,
70,RB r,null,null
,,,
71,iR,null,null
,,,
72,iR,null,null
,,,
73,"where, in the last equation, the first operand is the recall and the second one is the arithmetic mean of the precisions at each relevant retrieved document. This formulation further highlights the dependence of AP on the recall base and the recall itself.",null,null
,,,
74,"As previously discussed, [25] proposed a simple, probabilistic user model measure of effectiveness called Normalized Cumulative Precision (NCP), which includes AP as a particular case. The author assumes that any given user will stop his search at a given document in the ranked list, that we call its satisfaction point, according to a common probability law.",null,null
,,,
75,"Furthermore, he considers that a user will stop his search only at relevant documents and that the probability that he stops at any given relevant documents is fixed and independent from the specific run he is considering, while it is 0 at any non relevant document. So, he defines a probability distribution ps on the set of all the documents available for a given topic.",null,null
,,,
76,"Given a specific run and the set of its retrieved documents D, the definition of the NCP is then the expectation (average) of the precision at the ranks of the retrieved, relevant documents, accordingly to a distribution ps(·), i.e.",null,null
,,,
77,+,null,null
,,,
78,"N CP (ps) , Eps [Prec(n)] , ps(dn)Prec(n) .",null,null
,,,
79,"n,1",null,null
,,,
80,It is easy to see that the above definition of AP is in this con-,null,null
,,,
81,text equal to the NCP measure when we choose the uniform,null,null
,,,
82,law pU over all the relevant documents for the topic,null,null
,,,
83,1,null,null
,,,
84,"pU (dn) , ",null,null
,,,
85,RB 0,null,null
,,,
86,if dn is relevant otherwise,null,null
,,,
87,"The previous user model is simple and it can be considered as a starting point for more sophisticated models, as also suggested by [25] itself. As in the case of AP, the assumption that the user knows the recall base of a given topic is a weakness of this model. Furthermore, the probability that a user stops their search at a given document on a specific run depends on a probability distribution defined on the whole set of relevant documents available for a given topic.",null,null
,,,
88,"The choice of the uniform distribution to determine the stopping point in a given search is itself of difficult interpretation, since this means that any relevant document in a ranked list of retrieved documents has the same probability.",null,null
,,,
89,"We will see in the next section how, stepping from the intuition behind NCP, we can define, thanks to simple Markov chains, a more realistic user model, how AP can be still considered as a good approximation in many cases and how to generalize AP to a whole new class of Markovian models.",null,null
,,,
90,3.2 Rank-Biased Precision (RBP),null,null
,,,
91,"Rank-Biased Precision (RBP) [22] assumes a user model where the user starts from the top ranked document and with probability p, called persistence, goes to the next document or with probability 1 - p stops. RBP is defined as follows:",null,null
,,,
92,"RBP , (1 - p) pi-1",null,null
,,,
93,-4,null,null
,,,
94,iR,null,null
,,,
95,"It can be noted that, despite its name, RBP does not depend on the notion of precision. Nevertheless, it represents a measure for binary relevance which does not depend on the recall base and thus gives a comparison point in this last respect for MP.",null,null
,,,
96,599,null,null
,,,
97,3.3 Binary Preference (bpref),null,null
,,,
98,"Binary Preference (bpref) [4, 32] is a measure based on binary preferences and it evaluates systems using only the judged documents. It can be thought of as the inverse of the fraction of judged irrelevant documents that are retrieved before relevant ones:",null,null
,,,
99,"bpref , 1",null,null
,,,
100,1 - |j ranked higher than i|,null,null
,,,
101,-5,null,null
,,,
102,RB,null,null
,,,
103,"min(RB, N RB)",null,null
,,,
104,iR,null,null
,,,
105,"where j is a member of the first RB not relevant retrieved documents. bpref has proved to be quite robust in the case of incomplete and imperfect relevance judgements. Here, for us, it represents a comparison point when evaluating MP with respect to reduced-size pools.",null,null
,,,
106,"It can be noted how heavily bpref depends on the recall base RB. This is not only a scale factor as in the case of AP but it also determines the cardinality of the set from which the not relevant documents j are taken. Moreover, it makes use also of N RB, the total number of judged not relevant documents, a kind of information which is hard to imagine available to any real user. So, in a sense, it seems much more a ""pool-oriented"" than a system-oriented measure since, for determining its score, it uses much more information about the pool than about the system under examination and this could be an explanation of its robustness to the pool reduction.",null,null
,,,
107,4. A MARKOVIAN USER MODEL,null,null
,,,
108,4.1 General framework,null,null
,,,
109,"We will assume that each user starts from a chosen document in the ranked list and considers this document for a random time, that is distributed according to a known positive random variable. Then they decides, according to a probability law that we will specify in the sequel and independent from the random time spent in the first document, to move to another document in the list. Then, they considers this new document for a random time and moves, independently, to a third relevant document and so on.",null,null
,,,
110,"After a random number of forward and backward movements along the ranked list, the user will end their search and we will evaluate the total utility provided by the system to them by taking the average of the precision of the judged relevant documents they has considered during their search. According to this construction when we compute this average, the precision of a document visited k times will contribute to the mean with a k/n weight.",null,null
,,,
111,"We mathematically model the user behavior in the framework of the Markovian processes [23]. To fix the notation, we will denote by X0, X1, X2, . . . the (random) sequence of document ranks visited by the user and by T0, T1, T2 the random times spent, respectively, visiting the first document considered, the second one and so on. Therefore, X0 , i means that the user starts from the first document at rank i and T0 ,"" t0 means that they spends t0 units of time visiting this first document, then X1 "","" j means that they visits the document at rank j as the second one, and so on.""",null,null
,,,
112,"First of all, we will assume that X0 is a random variable on T ,"" {1, 2, . . . , T } with a given distribution  "","" (1, . . . , T ); so for any i  T , P[X0 "", i] ,"" i. Then, we will assume that the probability to pass from the document at rank i to the""",null,null
,,,
113,document at rank j will only depend on the starting rank i and not on the whole list of documents visited before.,null,null
,,,
114,This can be formalized as follows:,null,null
,,,
115,"P[Xn+1 , j|Xn ,"" i, Xn-1 "","" in-1, . . . , X0 "", i0] , (6)",null,null
,,,
116,", P[Xn+1 , j|Xn , i] ,"" pi,j""",null,null
,,,
117,"for any n  N and i, j, i0, . . . , in-1  T .",null,null
,,,
118,"p1,T",null,null
,,,
119,"p1,2",null,null
,,,
120,"p1,T-1 p1,3",null,null
,,,
121,"p2,T-1 p2,3",null,null
,,,
122,"p2,T",null,null
,,,
123,d1,null,null
,,,
124,d2,null,null
,,,
125,d3,null,null
,,,
126,dT-1,null,null
,,,
127,dT,null,null
,,,
128,"pT-1,1",null,null
,,,
129,"pT-1,2",null,null
,,,
130,"pT-1,3",null,null
,,,
131,"pT,T-1 pT,3",null,null
,,,
132,"pT,1",null,null
,,,
133,"pT,2",null,null
,,,
134,Figure 1: Structure of the Markov chain (Xn)nN.,null,null
,,,
135,Thanks to the condition (6) and fixing a starting distribu-,null,null
,,,
136,"tion , the random variables (Xn)nN define a time homoge-",null,null
,,,
137,"nous discrete time Markov Chain, shown in Figure 1, with",null,null
,,,
138,"state space T , initial distribution  and transition matrix",null,null
,,,
139,"P ,"" (pi,j )i,jT (Markov(,P) in the sequel).""",null,null
,,,
140,"To obtain a continuous-time Markov Chain, we have to",null,null
,,,
141,assume that the holding times Tn have all exponential dis-,null,null
,,,
142,"tribution, i.e.  0",null,null
,,,
143,t<0,null,null
,,,
144,"P[Tn  t] ,  1 - exp(-t) t  0",null,null
,,,
145,"Furthermore, conditioned on the fact that Xn ,"" i, the law of Tn will be exponential with parameter i, where i is a positive real number that may depend on the specific state i of the chain the user is visiting at that time.""",null,null
,,,
146,"When our interest is only on the jump chain (Xn)nN, i.e. when we are interested in extracting the corresponding discrete-time Markov chain to act as a traditional evaluation measure, we simply assume that all these variables are exponential with parameter  ,"" 1. When we are also interested in the time dimension, we have to provide a calibration for these exponential variables. We report a very simple example in Section 5 using click logs from Yandex.""",null,null
,,,
147,"The reason for choosing such a model will be immediately clear. Let us assume hereafter that the matrix P will be irreducible. This means that we can move in a finite number of steps from any document to any other document with positive probability. Thanks to (6) and the multiplication rule, the probability to pass in n steps from the document i to the document j is equal to p(i,nj), the (i, j) entry of the matrix P n and the irreducibility means that given any pair (i, j) there exists n > 0 such that p(i,nj) > 0. Furthermore, the probability distribution of any random variable Xn, which denotes the rank of the document visited after n movements, is completely determined by  and P , since",null,null
,,,
148,"P[Xn , j] , (P n)j .",null,null
,,,
149,"Given such a model, we assume that a user will visit a number n of documents in the list and then they will stop their search. In order to measure their satisfaction, we will evaluate the average of the precision of the ranks of the judged",null,null
,,,
150,600,null,null
,,,
151,relevant documents visited by the user during their search as,null,null
,,,
152,1 n-1 n Prec(Yk) .,null,null
,,,
153,"k,0",null,null
,,,
154,"where (Yn)nN denotes the sub-chain of (Xn)nN that considers just the visits to the judged relevant documents at ranks R, and shown in Figure 2.",null,null
,,,
155,"p1,2",null,null
,,,
156,"p1,T p2,T",null,null
,,,
157,d1,null,null
,,,
158,d2,null,null
,,,
159,d3,null,null
,,,
160,dT-1,null,null
,,,
161,dT,null,null
,,,
162,"pT,1",null,null
,,,
163,"pT,2",null,null
,,,
164,Figure 2: Structure of the sub-Markov chain (Yn)nN (relevant documents are shown in grey; not relevant ones in white).,null,null
,,,
165,Note that this sub-chain has in general a transition ma-,null,null
,,,
166,"trix different form P . The new transition matrix P can be computed easily from P by solving a linear system as detailed in [23] and discussed in Section 4.3.1. Note that P computed in this way somehow ""absorbs"" and takes into account also the probabilities of passing through not relevant documents (which are basically redistributed over the relevant ones) and makes it different from the transition matrix that you would have obtained by using only the relevant documents since the beginning.",null,null
,,,
167,"Clearly the previous quantity is of little use if evaluated at an unknown finite step n. However, the Ergodic Theorem of the theory of the Markov processes is perfect for approximating this quantity:",null,null
,,,
168,"Theorem 1. Let P be irreducible,  be any distribution",null,null
,,,
169,"and R finite. If (Yn)n0 is Markov(,P ), then for any function f : R  R we have",null,null
,,,
170,P,null,null
,,,
171,1 n,null,null
,,,
172,n-1,null,null
,,,
173,f (Yk) ,null,null
,,,
174,f,null,null
,,,
175,as,null,null
,,,
176,n,null,null
,,,
177,",1",null,null
,,,
178,"k,0",null,null
,,,
179,"where f , iR if (i) and  is the invariant distribution of P .",null,null
,,,
180,"The importance of this class of theorems is clear: almost surely and independently of the initial distribution , we can approximate, for n large, the average over the time by the (much simpler) average over the states of the Markov chain. Indeed, under the previous assumptions it is possible to prove that the matrix P admits a unique invariant distribution, i.e a probability distribution  such that if (Yn)n0 is Markov(,P ), then for any n",null,null
,,,
181,"P[Yn , j] , j .",null,null
,,,
182,"Moreover, the invariant distribution in this case is the unique left eigenvector of the eigenvalue 1 of the matrix P , i.e. the unique solution of the linear equation",null,null
,,,
183," , P .",null,null
,,,
184,"Remark 1. Under additional hypotheses, it can be proved that the invariant distribution itself is the limit of any row of the matrix P n, as n  , useful result in order to evaluate in practice the invariant distribution. The convergence is generally very fast and for n , 10 we already have a reasonable approximation of the true value of . This justifies the use of MP to approximate the mean precision of the usually few documents visited by a user.",null,null
,,,
185,"We can now define a new family of user oriented retrieval effectiveness measures, called Markov Precision (MP), which depends on the specific user model and the invariant distribution derived.",null,null
,,,
186,"Definition 1. Given a ranked list of retrieved documents, defined by R the ranks of its judged relevant documents and defined a Markov (,P) user model, the Markov Precision metric will be defined as",null,null
,,,
187,"M P , iPrec(i).",null,null
,,,
188,iR,null,null
,,,
189,where Prec(n) represent the Precision at n and  the (unique) invariant distribution of the Markov chain (Yn)nN.,null,null
,,,
190,"MP is defined without knowing the recall base RB of a given topic, but just the ranks of the judged relevant documents in a given run for this topic. As pointed out, for example in [22], the need to know the value of RB represents a weakness in AP that is overcome here.",null,null
,,,
191,"In order to include the time dimension and thanks to the Ergodic Theorem for the continuous time Markov chains, we can replicate the previous computations and define a new measure",null,null
,,,
192,"M P cont , iPrec(i).",null,null
,,,
193,iR,null,null
,,,
194,"where i ,",null,null
,,,
195,", i (i )-1",null,null
,,,
196,jR j (j )-1,null,null
,,,
197,denotes,null,null
,,,
198,again,null,null
,,,
199,the,null,null
,,,
200,(unique),null,null
,,,
201,distribution of the Markov chain (Yn)nN and i is the pa-,null,null
,,,
202,rameter of the holding time in state i. To use this alternative,null,null
,,,
203,"measure, we have to provide a calibration for the coefficients",null,null
,,,
204,i and we will compare MP with MPcont in a very simple,null,null
,,,
205,example in Section 5 using click logs from Yandex.,null,null
,,,
206,4.2 Average Precision,null,null
,,,
207,"In order to define a simple Markovian user model, whose MP value will be AP, let us consider the following transition probabilities among the documents in a given ranked list:",null,null
,,,
208,P[Xn+1,null,null
,,,
209,",",null,null
,,,
210,j|Xn,null,null
,,,
211,",",null,null
,,,
212,i],null,null
,,,
213,",",null,null
,,,
214,1 T -1,null,null
,,,
215,-7,null,null
,,,
216,"for any i, j  T , i ,"" j, and where, again, T denotes the""",null,null
,,,
217,cardinality of the set T .,null,null
,,,
218,In this model we assume that a user moves from a docu-,null,null
,,,
219,"ment to another document with a fixed, constant probability,",null,null
,,,
220,the value of which depends on the total number of relevant,null,null
,,,
221,documents present in the specific run.,null,null
,,,
222,Since the invariant distribution is,null,null
,,,
223,1 T,null,null
,,,
224,",",null,null
,,,
225,1 T,null,null
,,,
226,",",null,null
,,,
227,.,null,null
,,,
228,.,null,null
,,,
229,.,null,null
,,,
230,",",null,null
,,,
231,1 T,null,null
,,,
232,we obtain,null,null
,,,
233,that,null,null
,,,
234,1,null,null
,,,
235,"MP ,",null,null
,,,
236,P rec(i),null,null
,,,
237,T,null,null
,,,
238,iR,null,null
,,,
239,which is equal to AP,null,null
,,,
240,once multiplied by,null,null
,,,
241,T RB,null,null
,,,
242,.,null,null
,,,
243,Note that if,null,null
,,,
244,we create the Markov chain starting directly from the rele-,null,null
,,,
245,vant documents R we have to multiply MP by Rec(T ) as in,null,null
,,,
246,601,null,null
,,,
247,"equation 3. In this way, we explain AP with a slightly richer user model, where the user can move forward and backward among any document and is not forced to visit only the relevant ones. It is also clear from the equation above that MP is not AP unless you provide it with the same amount of information AP knows about the recall base, namely rescaling MP by the recall base.",null,null
,,,
248,"Looking at this the other way around, this instantiation of MP (without the rescaling) can be considered a kind of AP where the artificial knowledge of the recall base has been removed and so, it tells us how AP might look like if you remove the dependency on the recall base and insert an explicit user model. This consideration will turn out to be useful in the experimental part when we will find other user models, highly correlated to AP, which may give a richer explanation of it.",null,null
,,,
249,"Moreover, the previous constant invariant distribution is common to many others user models. For example, if the transition matrix is irreducible and symmetric or even just bistochastic, meaning that the sum of the entries on each column is equal to 1, the invariant distribution is again the above constant vector. In this sense, if the validity of the present Markovian user model is accepted, it shows once more why AP has become a reference point, since it represents a good approximation for a wide class of models that we can define.",null,null
,,,
250,4.3 Other models,null,null
,,,
251,We will analyze three possible choices:,null,null
,,,
252,"· state space choice: the Markov chain (Xn)nN is on the whole set T , indicated with AD (all documents model), or on the set R, indicated with OR (only relevant documents model);",null,null
,,,
253,"· connectedness: the nonzero transition probabilities are among all the documents, indicated with GL (global model), or only among adjacent documents, indicated with LO (local model);",null,null
,,,
254,"· transition probabilities: the transition probabilities are proportional to the inverse of the distance, indicated with ID (inverse distance model), or to the inverse of the logarithm of the distance, indicated with LID (logarithmic inverse distance model).",null,null
,,,
255,"We will obtain eight models that we will call after the possible three choices. So, for example, MP GL AD ID is an effectiveness measure with transition probabilities among all the retrieved documents, based on a model on the whole set T , and with transition probabilities proportional to the inverse of the distance of the documents in the ranked list and so on for the other combinations of the parameters.",null,null
,,,
256,4.3.1 State space choice,null,null
,,,
257,"In the AD case, we consider the whole Markov chain (Xn)nN on the whole set T with a given initial distribution  and a transition matrix P ,"" (pi,j )i,jT and then we derive the subchain (Yn)nN on the set R. In order to obtain the invariant distribution of the subchain, we will have to derive its transition matrix P . It can be proved (see [23]) that this matrix can be defined as follows""",null,null
,,,
258,"pi,j ,"" hji for i, j  R""",null,null
,,,
259,Table 1: Main features of the adopted data sets.,null,null
,,,
260,Topics Runs Min. Rel Avg. Rel Max. Rel,null,null
,,,
261,TREC 7,Y,null
,,,
262,50,null,null
,,,
263,103,null,null
,,,
264,7,null,null
,,,
265,93.48,null,null
,,,
266,361,null,null
,,,
267,TREC 8,Y,null
,,,
268,50,null,null
,,,
269,129,null,null
,,,
270,6,null,null
,,,
271,94.56,null,null
,,,
272,347,null,null
,,,
273,TREC 10 50,Y,null
,,,
274,97,null,null
,,,
275,2,null,null
,,,
276,67.26,null,null
,,,
277,372,null,null
,,,
278,TREC 14 50,Y,null
,,,
279,74,null,null
,,,
280,9,null,null
,,,
281,131.22,null,null
,,,
282,376,null,null
,,,
283,"where the vector (hji , i  T ) is the minimal non-negative solution to the linear system",null,null
,,,
284,"hji ,"" pi,j +""",null,null
,,,
285,pikhjk .,null,null
,,,
286,-8,null,null
,,,
287,"k,R",null,null
,,,
288,"So, once this linear system is solved, we obtain the transition",null,null
,,,
289,matrix P needed to compute the Markov Precision for the given model.,null,null
,,,
290,"In the OR model, we create the Markov Chain (Xn)nN directly on the set R.",null,null
,,,
291,4.3.2 Connectedness,null,null
,,,
292,"In the GL model, we assume that the transition probabilities pi,j > 0 for any choice of i ,"" j. In this case we will assume that there will be a positive, even if very small, probability to pass from any document in the ranked list to any other. For example, the previous model for Average precision is a GL model""",null,null
,,,
293,"By contrast, in LO we will assume that there exist transition probabilities only among adjacent nodes. This is the same kind of logic behind RBP, even though RBP allows only for forward transitions, and is similar to the strategy of [8] for the two-dimensional placement problem.",null,null
,,,
294,4.3.3 Transition probabilities,null,null
,,,
295,"In the ID model, we assume that the probability to pass",null,null
,,,
296,from one document to another one in the ranked list is pro-,null,null
,,,
297,portional to the inverse of the relative distance of these two,null,null
,,,
298,documents:,null,null
,,,
299,1 |i-j|+1,null,null
,,,
300,"if i , j",null,null
,,,
301,"(i, j) ,  0",null,null
,,,
302,"if i , j",null,null
,,,
303,-9,null,null
,,,
304,"Denoting by (s1, . . . , sm) the states of the Markov chain, we thus have the following transition probabilities:",null,null
,,,
305,"psi,sj ,",null,null
,,,
306,"(si, sj ) (si, sk)",null,null
,,,
307,k,null,null
,,,
308,-10,null,null
,,,
309,It is immediately clear that the probabilities (10) define an irreducible transition matrix P of a discrete time Markov Chain on the state space and therefore we can define Markov precision for this model.,null,null
,,,
310,"In the LID model, we smooth the distance by using the base 10 logarithm so that that transition probabilities do not decrease not too fast. The choice of the base 10 for the logarithm is due to a typical Web scenario focused on the page of the first 10 results.",null,null
,,,
311,5. EVALUATION,null,null
,,,
312,5.1 Experimental Setup,null,null
,,,
313,"In order to assess MP and compare it to the other pertinent evaluation measures (AP, P@10, Rprec, RBP, and",null,null
,,,
314,602,null,null
,,,
315,Table 2: Kendall  correlation between AP and the other comparison measures using complete judgments (high correlations marked with *).,null,null
,,,
316,AP P@10 Rprec bpref RBP TREC 7 1.000 0.8018 0.9261* 0.9275 0.7886 TREC 8 1.000 0.8264 0.9219* 0.9361* 0.8090 TREC 10 1.000 0.7551 0.8730 0.8896 0.7401 TREC 14 1.000 0.7295 0.9377 0.8394 0.7229,Y,null
,,,
317,"bpref), we conducted a correlation analysis and we studied its robustness to pool downsampling. As far as RBP is concerned, we set p ,"" 0.8, which indicates a medium persistence of the user.""",null,null
,,,
318,"We used the following data sets: TREC 7 Ad Hoc, TREC 8 Ad Hoc, TREC 10 Web, and TREC 14 Robust, whose features are summarized in Table 1. We used all the topics and all the runs that retrieved at least one document per topic. In the case of collections with graded relevance assessment (TREC 10 and 14), we mapped them to binary relevance with a lenient strategy, i.e. both relevant and highly relevant documents have been mapped to relevant ones.",Y,null
,,,
319,"As far as pool downsampling is concerned, we used the same strategy of [4]: it basically creates separate random lists of relevant/not relevant documents and select a given fraction R% of them, ensuring that at least 1 relevant and 10 not relevant documents are in the pool. We used R% ,"" [90, 70, 50, 30, 10].""",null,null
,,,
320,"As far as the calibration of time is concerned, we used click logs made available by Yandex [29] in the context of the Relevance Prediction Challenge2. The logs consist of 340,796,067 records with 30,717,251 unique queries, retrieving 10 URLs each. We used the training set where there are 5,191 assessed queries which correspond to 30,741,907 records and we selected those queries which appear at least in 100 sessions each to calibrate the time.",null,null
,,,
321,The full source code of the software used to conduct the experiments is available for download3 in order to ease comparison and verification of the results.,null,null
,,,
322,5.2 Correlation Analysis,null,null
,,,
323,"Table 2 reports the Kendall  correlation [18] between AP and the other comparison measures, using complete judgements, for all the collections. Previous work [33, 34] considered correlations greater than 0.9 as equivalent rankings and correlations less than 0.8 as rankings containing noticeable differences. Table 2 is consistent with previous findings, with a high correlation between AP, Rprec, and bpref and lower correlation values for P@10 and RBP.",null,null
,,,
324,"Table 3 reports the Kendall  correlation between the different models for MP, discussed in Section 4.3 and whose notation (GL/LO, AD/OR, ID/LID) is used here as well, and the performance measures of direct comparison, for all the considered collections4. For each variant of MP, the table reports its actual value and also a second row labelled with the suffix @Rec(T ) to indicate a rescaled version of",null,null
,,,
325,"2http://imat-relpred.yandex.ru/en/ 3http://matters.dei.unipd.it/ 4The fact that the values for the LO AD ID and LO AD LID models are the same is not due to a copy&paste error but to the fact that the two chains, in the local model, are the same apart from a constant and so they produce equal rankings.",null,null
,,,
326,"MP by recall. Indeed, this is the same operation needed to make MP equal to AP in the case of the model with constant transition probabilities discussed in Section 4.2 and corresponds to providing MP with the same level of information about the recall base that also AP uses. This has a twofold purpose: (i) to determine if there are other models beyond the ones of Section 4.2 which can give us an additional interpretation of AP; (ii) to get a general feeling of what is the impact of injecting information about the recall into an evaluation measure. In the table, we have marked high correlations, those above 0.90, with a star and we have marked extremely high correlations, those above 0.97, with two stars.",null,null
,,,
327,"As a general trend MP tends not to have high correlations with the other evaluation measures, indicating that it takes a different angle from them. This can be accounted for by the effect of the user model explicitly embedded in MP which, for example, allows the user to move forward and backward in the result list while other measures allow only for sequential scans. On the other hand, the proposed models keep it not too far away from the other measures, especially those around precision (AP, P@10, Rprec), since the correlation never drops below 0.70. This is coherent with the fact that both MP and the other measures (AP, P@10, Rprec) are all around the concept of precision and so they have a common denominator.",null,null
,,,
328,"Moreover, it can be noted that MP tends to be more correlated with P@10 and then with Rprec and AP. This is consistent with the fact that MP does not depend on the recall base, as P@10 does, while Rprec implicitly and AP explicitly depend on it.",null,null
,,,
329,"Finally, the results show a moderate correlation with bpref and a slightly lower one with RBP, whose only common denominator is to not depend on the recall base.",null,null
,,,
330,"Whit regard to @Rec(T ), we can note how they greatly boost the correlation with AP in almost all cases, often moving MP from low to high correlations, and, in turn, increase the correlation with Rprec and bpref (more correlated by themselves to AP) with respect to the one with RBP which tends to decrease.",null,null
,,,
331,"In particular, there are some cases, like MP GL AD LID or MP LO AD ID, where it jumps between 0.97 and 1.00. We consider this a case in which MP is providing us with an alternative interpretation of AP, in the sense discussed in Section 4.2. For example, MP GL AD LID provided with information about recall tells us that we can look at AP as a measure that also models a user who can move backward and forward among all the documents in the list and who prefers smaller jumps to bigger ones. The fact that we have found a few models so highly correlated with AP suggests that AP has become a gold standard also because it represents some articulated user models.",null,null
,,,
332,5.3 Effect of Incompleteness on Absolute Performances,null,null
,,,
333,"Figure 3 shows the effect of reducing the pool size on the absolute average performances, over all the topics and runs. For space reasons, we do not report figures for all the possible combinations reported in Table 3 but just some to give the reader an idea of the behavior of MP; the considerations made here are however valid also for the not reported figures.",null,null
,,,
334,It can be noted how MP shows consistent behavior over all the collections and for various models: its absolute aver-,null,null
,,,
335,603,null,null
,,,
336,Table 3: Kendall  correlation between different instantiations of MP and the other comparison measures,null,null
,,,
337,using complete judgments (high correlations marked with *; extremely high correlations marked with **).,null,null
,,,
338,MP GL AD ID MP GL AD ID@Rec(T ) MP GL AD LID MP GL AD LID@Rec(T ) MP GL OR ID MP GL OR ID@Rec(T ) MP GL OR LID MP GL OR LID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO OR ID MP LO OR ID@Rec(T ) MP LO OR LID MP LO OR LID@Rec(T ),null,null
,,,
339,AP 0.7381 0.9823** 0.7378 0.9954** 0.7322 0.9117* 0.7379 0.9726** 0.7435 0.9946** 0.7435 0.9946** 0.7271 0.9130* 0.7386 0.9552*,null,null
,,,
340,TREC 7 P@10 Rprec 0.7522 0.7703 0.7916 0.9243* 0.7638 0.7712 0.7994 0.9252* 0.8311 0.7797 0.8316 0.8937 0.7853 0.7782 0.8158 0.9238* 0.7706 0.7706 0.7994 0.9225* 0.7706 0.7706 0.7994 0.9225* 0.8229 0.7754 0.8283 0.8958 0.8065 0.7826 0.8278 0.9166*,Y,null
,,,
341,bpref 0.7827 0.9322* 0.7802 0.9277* 0.7689 0.8848 0.7788 0.9232* 0.7874 0.9265* 0.7874 0.9265* 0.7634 0.8853 0.7787 0.9142*,null,null
,,,
342,RBP 0.7490 0.7799 0.7632 0.7858 0.7689 0.8243 0.7858 0.8029 0.7685 0.7858 0.7685 0.7858 0.8393 0.8211 0.8058 0.8164,null,null
,,,
343,AP 0.8997 0.9815** 0.8912 0.9953** 0.8162 0.9208* 0.8664 0.9722** 0.8931 0.9953** 0.8931 0.9953** 0.8138 0.9195* 0.8534 0.9506*,null,null
,,,
344,P@10 0.8510 0.8128 0.8641 0.8221 0.9081* 0.8756 0.8884 0.8477 0.8642 0.8248 0.8642 0.8248 0.9013* 0.9195* 0.8982 0.8623,null,null
,,,
345,TREC 8 Rprec 0.9074* 0.9217* 0.9033* 0.9209* 0.8349 0.9024* 0.8853 0.9281* 0.9011* 0.9219* 0.9011* 0.9219* 0.8305 0.8714 0.8708 0.9186*,Y,null
,,,
346,bpref 0.9222* 0.9299* 0.9173* 0.9337* 0.8402 0.9145* 0.8947 0.9390* 0.9174* 0.9343* 0.9174* 0.9343* 0.8354 0.8987 0.8810 0.9319*,null,null
,,,
347,RBP 0.8382 0.7938 0.8551 0.8041 0.9152* 0.8637 0.8858 0.8324 0.8537 0.8066 0.8537 0.8066 0.9176* 0.9127* 0.8995 0.8466,null,null
,,,
348,MP GL AD ID MP GL AD ID@Rec(T ) MP GL AD LID MP GL AD LID@Rec(T ) MP GL OR ID MP GL OR ID@Rec(T ) MP GL OR LID MP GL OR LID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO AD ID MP LO AD ID@Rec(T ) MP LO OR ID MP LO OR ID@Rec(T ) MP LO OR LID MP LO OR LID@Rec(T ),null,null
,,,
349,AP 0.7264 0.9726** 0.7125 0.9941** 0.7034 0.9117* 0.7052 0.9738** 0.7240 0.9742** 0.7240 0.9742** 0.7035 0.9326* 0.7114 0.9579*,null,null
,,,
350,TREC 10 P@10 Rprec 0.7832 0.7727 0.7340 0.8631 0.7971 0.7633 0.7512 0.8707 0.8269 0.7663 0.8316 0.8937 0.8077 0.7672 0.7575 0.8740 0.7969 0.7703 0.7376 0.8654 0.7969 0.7703 0.7376 0.8654 0.8300 0.7646 0.7726 0.8767 0.8172 0.7676 0.7601 0.8747,Y,null
,,,
351,bpref 0.7611 0.8771 0.7494 0.8878 0.7470 0.8848 0.7466 0.8916 0.7614 0.8802 0.7614 0.8802 0.7449 0.8960 0.7533 0.8949,null,null
,,,
352,RBP 0.8013 0.8771 0.8187 0.7360 0.8590 0.8243 0.8396 0.7448 0.8159 0.7218 0.8159 0.7218 0.8618 0.7618 0.8472 0.7477,null,null
,,,
353,AP 0.8351 0.9896** 0.8294 0.9977** 0.7968 0.9601* 0.8140 0.9924** 0.8297 0.9970** 0.8297 0.9970** 0.7997 0.9674* 0.8084 0.9877**,null,null
,,,
354,TREC 14 P@10 Rprec 0.8078 0.8566 0.7221 0.9333* 0.8185 0.8501 0.7303 0.9385 0.8461 0.8206 0.7526 0.9327* 0.8291 0.8348 0.7375 0.9398* 0.8180 0.8504 0.7295 0.9363* 0.8180 0.8504 0.7295 0.9363* 0.8348 0.8234 0.7429* 0.9348* 0.8324 0.8306 0.7372 0.9381*,Y,null
,,,
355,bpref 0.7778 0.8360 0.7751 0.8397 0.7677 0.8650 0.7716 0.8432 0.7783 0.8405 0.7783 0.8405 0.7714 0.8597 0.7689 0.8489,null,null
,,,
356,RBP 0.7980 0.7140 0.8071 0.8397 0.8302 0.7444 0.8155 0.7293 0.8089 0.7214 0.8089 0.7214 0.8220 0.7377 0.8180 0.7306,null,null
,,,
357,"age values decrease as the pool reduction rate increases in a manner similare to AP and Rprec. Consistently with previous results, P@10 and RBP exhibit a more marked decrease while bpref tends to stay constant. This positive property of bpref is an indicator that it is not very sensible or it does not fully exploit the additional information which is provided when the pool increases.",null,null
,,,
358,5.4 Effect of Incompleteness on Rank Correlation,null,null
,,,
359,"Figure 4 shows the effect of reducing the pool size on the Kendall  correlation between each measure on the full pool and the pool at a given reduction rate. The results shown are consistent with previous findings as far as the measures of direct comparison are concerned, showing that bpref is almost always the more robust measure to pool reduction. It is indeed plausible that, keeping bpref the absolute average performances almost constant, also the ranking of the systems does not change much.",null,null
,,,
360,"As far as MP is concerned, we can note that global models [GL], shown in the case of TREC 7, 8 and 10, tend to perform comparably to AP and, when provided with the same information about the recall base, which both AP and bpref exploit, they consistently improve their performances and, in the case of TREC 8, they outperform AP and perform closely to bpref. This is an interesting result since, unlike",Y,null
,,,
361,"bpref, the absolute average performances of MP vary at different pool reduction rates, indicating that MP is able to exploit the variable amount of information available at different pool reduction rates, still not affecting too much the overall ranking of the systems.",null,null
,,,
362,"The global models [GL] on only relevant documents [OR] behave consistently with the global ones on all documents [AD], shown in the case of TREC 7 and TREC 10, even if they are a little bit more resilient to the pool reduction. This is consistent with the fact that they use less information than the AD ones and so they are less sensitive to the pool size. The TREC 7 also shows the effect of using the inverse of the distance [ID] or the log of the inverse of the distance [LID], which provides more robustness to pool reduction.",Y,null
,,,
363,"When it comes to local models [LO], these tend to behave comparably to the global ones in the case of all documents [AD], as can be noted in the case of TREC 8, while they are more affected by the pool reduction in the case of only relevant documents [OR], as can be noted in the case of TREC 14.",Y,null
,,,
364,5.5 Time Calibration,null,null
,,,
365,"On the basis of the click logs, 21% of the observed transitions are backward, a fact that validates our assumption that a user moves forward and backward along the ranked list.",null,null
,,,
366,604,null,null
,,,
367,Performances averaged over topics and runs,null,null
,,,
368,0.45 0.4,null,null
,,,
369,0.35 0.3,null,null
,,,
370,0.25 0.2,null,null
,,,
371,0.15 0.1,null,null
,,,
372,0.05 0,null,null
,,,
373,100%,null,null
,,,
374,90%,null,null
,,,
375,"TREC 07, 1998, Ad Hoc",Y,null
,,,
376,GL_OR_ID GL_OR_ID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
377,70%,null,null
,,,
378,50%,null,null
,,,
379,Pool reduction rate,null,null
,,,
380,30%,null,null
,,,
381,10%,null,null
,,,
382,Performances averaged over topics and runs,null,null
,,,
383,0.45 0.4,null,null
,,,
384,0.35 0.3,null,null
,,,
385,0.25 0.2,null,null
,,,
386,0.15 0.1,null,null
,,,
387,0.05 0,null,null
,,,
388,100%,null,null
,,,
389,90%,null,null
,,,
390,"TREC 08, 1999, Ad Hoc",Y,null
,,,
391,70%,null,null
,,,
392,50%,null,null
,,,
393,Pool reduction rate,null,null
,,,
394,GL_AD_ID GL_AD_ID@Rec(T) LO_AD_ID LO_AD_ID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
395,30%,null,null
,,,
396,10%,null,null
,,,
397,Performances averaged over topics and runs,null,null
,,,
398,0.35 0.3,null,null
,,,
399,0.25 0.2,null,null
,,,
400,0.15 0.1,null,null
,,,
401,0.05 0,null,null
,,,
402,100%,null,null
,,,
403,90%,null,null
,,,
404,"TREC 10, 2001, Web",Y,null
,,,
405,70%,null,null
,,,
406,50%,null,null
,,,
407,Pool reduction rate,null,null
,,,
408,GL_AD_LID GL_AD_LID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
409,30%,null,null
,,,
410,10%,null,null
,,,
411,Performances averaged over topics and runs,null,null
,,,
412,0.45 0.4,null,null
,,,
413,0.35 0.3,null,null
,,,
414,0.25 0.2,null,null
,,,
415,0.15 0.1,null,null
,,,
416,0.05 0,null,null
,,,
417,100%,null,null
,,,
418,90%,null,null
,,,
419,"TREC 14, 2005, Robust",Y,null
,,,
420,LO_AD_ID LO_AD_ID@Rec(T) LO_OR_ID LO_OR_ID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
421,70%,null,null
,,,
422,50%,null,null
,,,
423,Pool reduction rate,null,null
,,,
424,30%,null,null
,,,
425,10%,null,null
,,,
426,Figure 3: Pool reduction rate (x axis) vs. performance averaged over topics and runs (y axis),null,null
,,,
427,"TREC 07, 1998, Ad Hoc 1",Y,null
,,,
428,0.9,null,null
,,,
429,0.8,null,null
,,,
430,0.7,null,null
,,,
431,0.6 0.5 0.4 100%,null,null
,,,
432,GL_OR_ID GL_OR_ID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
433,90%,null,null
,,,
434,70%,null,null
,,,
435,50%,null,null
,,,
436,Pool reduction rate,null,null
,,,
437,30%,null,null
,,,
438,10%,null,null
,,,
439,Kendalls  correlation,null,null
,,,
440,1,null,null
,,,
441,0.95,null,null
,,,
442,0.9,null,null
,,,
443,0.85,null,null
,,,
444,0.8,null,null
,,,
445,0.75,null,null
,,,
446,0.7 0.65,null,null
,,,
447,0.6 0.55,null,null
,,,
448,0.5 100%,null,null
,,,
449,GL_AD_ID GL_AD_ID@Rec(T) LO_AD_ID LO_AD_ID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
450,90%,null,null
,,,
451,"TREC 08, 1999, Ad Hoc",Y,null
,,,
452,70%,null,null
,,,
453,50%,null,null
,,,
454,Pool reduction rate,null,null
,,,
455,30%,null,null
,,,
456,10%,null,null
,,,
457,Kendalls  correlation,null,null
,,,
458,"TREC 10, 2001, Web 1",Y,null
,,,
459,0.9,null,null
,,,
460,0.8,null,null
,,,
461,0.7,null,null
,,,
462,0.6 0.5 0.4 100%,null,null
,,,
463,GL_AD_LID GL_AD_LID@Rec(T) GL_OR_LID GL_OR_LID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
464,90%,null,null
,,,
465,70%,null,null
,,,
466,50%,null,null
,,,
467,Pool reduction rate,null,null
,,,
468,30%,null,null
,,,
469,10%,null,null
,,,
470,Kendalls  correlation,null,null
,,,
471,"TREC 14, 2005, Robust 1",Y,null
,,,
472,0.9,null,null
,,,
473,0.8,null,null
,,,
474,0.7,null,null
,,,
475,0.6 0.5 0.4 100%,null,null
,,,
476,LO_AD_ID LO_AD_ID@Rec(T) LO_OR_ID LO_OR_ID@Rec(T) AP P@10 Rprec bpref RBP,null,null
,,,
477,90%,null,null
,,,
478,70%,null,null
,,,
479,50%,null,null
,,,
480,Pool reduction rate,null,null
,,,
481,30%,null,null
,,,
482,10%,null,null
,,,
483,Figure 4: Pool reduction rate (x axis) vs. Kendall's rank correlation (y axis),null,null
,,,
484,Kendalls  correlation,null,null
,,,
485,"To compare the discrete-time version of MP with the continuous-time one, we have considered 3 runs with 5 relevant documents and estimated the parameters of the exponential holding times by the inverse of the sample mean of the time spent by the users visiting these states, multiplied by (n - 1)/n. We used the GL AD ID model and the values of discrete-time MP and continuous-time MP are reported in Table 4.",null,null
,,,
486,"Note that the precisions at each fixed rank n of the first, second and third runs are decreasing and as one expects MP of the three runs is decreasing. However, since the (estimated) holding times of the first documents in the first run are very low, continuos-time MP is smaller for the first run. This clearly shows that the use of continuous-time MP depends heavily on the calibration of the holding times.",null,null
,,,
487,6. CONCLUSIONS AND FUTURE WORK,null,null
,,,
488,"We introduced a new family of measures, called MP, which exploit Markov chains in order to inject different user models and time into precision and which is not dependent on the recall base. This permitted us to overcome some of the traditional criticisms of AP (lack of a clear user model, dependence on the recall base) while still offering a measure which is AP when provided with the same amount of information about the recall base that AP exploits. Moreover, MP goes beyond almost all the evaluation measures allowing for non sequential scanning of the result lists.",null,null
,,,
489,"We have proposed some basic user interaction models and validated their properties, in terms of correlation to other measures and robustness to pool reduction, thus showing it is as reliable as them. We have also found that some of these models have an extremely high correlation with AP and this can help in providing alternative interpretations of AP in the light of more complex user models and in explaining why AP is a ""gold standard"" in IR.",null,null
,,,
490,"MP also bridges the gap between ""rank-oriented""and ""timeoriented"" measures, providing a single unified framework where both viewpoints can co-exist and allowing for direct",null,null
,,,
491,"comparison among the values of the ""rank-oriented""(discretetime Markov chain) and ""time-oriented"" (continuous-time Markov chain) versions. We have also provided an example of how time can be calibrated using click logs from Yandex.",null,null
,,,
492,"Future works concern the investigation of alternative user models able to account also for the number of relevant/not relevant documents visited so far ­ a kind of information which is actually available to a real user ­ by employing a multidimensional Markov chains to not violate the memoryless assumption. A further interesting option would also be to investigate whether click model-based IR measures [9] can be represented via the Markov chain and thus embedded in MP, i.e. whether the transition probabilities of the Markov chain can be learned directly from click-logs, thus leveraging models fully induced by user behaviour.",null,null
,,,
493,"Another area of interest concerns how to calibrate time into MP: work on click model-based measures can shed some light in this respect and the techniques proposed by [30, 31] for calibrating time with respect to document length can link MP not only to click logs but also to document collections.",null,null
,,,
494,"An interesting question for the future is whether MP could fit search tasks other than informational ones, such as fact, entity, or attributes focused searches or whether it could also work with other kinds of test collections, such as nuggetbased ones [24].",null,null
,,,
495,"Finally, the robustness of MP could be further investigated, for example evaluating how it performs on condensedlists [27].",null,null
,,,
496,Acknowledgements,null,null
,,,
497,We wish to thank the anonymous reviewers and meta-reviewers whose comments and discussions helped us in improving the paper and better clarifying some angles of it.,null,null
,,,
498,"The PREFORMA project5 (contract no. 619568), as part of the 7th Framework Program of the European Commission, has partially supported the reported work.",null,null
,,,
499,5http://www.preforma-project.eu/,null,null
,,,
500,605,null,null
,,,
501,Table 4: Estimated parameters of the exponential holding times for three runs and values of the discrete-time,null,null
,,,
502,and continuous-time MP.,null,null
,,,
503,Run,null,null
,,,
504,µ1,null,null
,,,
505,µ2,null,null
,,,
506,µ3,null,null
,,,
507,µ4,null,null
,,,
508,µ5,null,null
,,,
509,µ6,null,null
,,,
510,µ7,null,null
,,,
511,µ8,null,null
,,,
512,µ9,null,null
,,,
513,µ10 disc MP cont MP,null,null
,,,
514,"(1,1,1,1,0,0,0,1,0,0) 0.2000 0.0357 0.2000 0.0400 0.0056 0.0005 0.0035 0.0017 0.0034 0.0024 0.9205 0.6603",null,null
,,,
515,"(1,1,1,0,1,0,0,0,1,0) 0.0177 0.0047 0.0037 0.0015 0.0041 0.0031 0.0057 0.0022 0.0061 0.0045 0.8668 0.8710",null,null
,,,
516,"(1,1,0,1,1,0,0,0,0,1) 0.0056 0.0051 0.0062 0.0031 0.0046 0.0025 0.005 0.0022 0.007 0.005 0.8120 0.8001",null,null
,,,
517,7. REFERENCES,null,null
,,,
518,"[1] J. A. Aslam, E. Yilmaz, and V. Pavlu. The Maximum Entropy Method for Analyzing Retrieval Measures. In SIGIR, pages 27­34, ACM, 2005.",null,null
,,,
519,"[2] A. Broder. A Taxonomy of Web Search. SIGIR Forum, 36(2):3­10, 2002.",null,null
,,,
520,"[3] C. Buckley and E. M. Voorhees. Evaluating Evaluation Measure Stability. In SIGIR, pages 33­40, ACM, 2000.",null,null
,,,
521,"[4] C. Buckley and E. M. Voorhees. Retrieval Evaluation with Incomplete Information. In SIGIR, pages 25­32. ACM, 2004.",null,null
,,,
522,"[5] C. Buckley and E. M. Voorhees. Retrieval System Evaluation. In TREC. Experiment and Evaluation in Information Retrieval, pages 53­78. MIT Press, USA, 2005.",null,null
,,,
523,"[6] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected Reciprocal Rank for Graded Relevance. In CIKM, pages 621­630. ACM, 2009.",null,null
,,,
524,"[7] B. Carterette. System Effectiveness, User Models, and User Utility: A Conceptual Framework for Investigation. In SIGIR, pages 903­912. ACM, 2011.",null,null
,,,
525,"[8] F. Chierichetti, R. Kumar, and P. Raghavan. Optimizing Two-Dimensional Search Results Presentation. In WSDM, pages 257­266, ACM, 2011.",null,null
,,,
526,"[9] A. Chuklin, P. Serdyukov, and M. de Rijke. Click Model-Based Information Retrieval Metrics. In SIGIR, pages 493­502, ACM, 2013.",null,null
,,,
527,"[10] C. L. A. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. A Comparative Analysis of Cascade Measures for Novelty and Diversity. In WSDM, pages 84­75, ACM 2011.",null,null
,,,
528,"[11] C. W. Cleverdon. The Cranfield Tests on Index Languages Devices. In Readings in Information Retrieval, pages 47­60. Morgan Kaufmann Publisher, Inc., USA, 1997.",null,null
,,,
529,"[12] K. Collins-Thompson and J. Callan. Query Expansion Using Random Walk Models. In CIKM, pages 704­711. ACM, 2005.",null,null
,,,
530,"[13] C. Danilowicz and J. Balin´ski. Document ranking based upon Markov chains. IPM, 37(4):623--637, July 2001.",null,null
,,,
531,"[14] D. K. Harman. Overview of the Third Text REtrieval Conference (TREC-3). In D. K. Harman, editor, Overview of the Third Text REtrieval Conference (TREC-3) , pages 1­19. NIST, Special Pubblication 500-225, Washington, USA., 1994.",null,null
,,,
532,"[15] D. K. Harman. Information Retrieval Evaluation. Morgan & Claypool Publishers, USA, 2011.",null,null
,,,
533,"[16] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated Gain-Based Evaluation of IR Techniques. ACM TOIS, 20(4):422­446, 2002.",null,null
,,,
534,"[17] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and G. Gay. Accurately Interpreting Clickthrough Data as",null,null
,,,
535,"Implicit Feedback. In SIGIR, pages 154­161, ACM, 2005. [18] M. G. Kendall. The Treatment of Ties in Ranking Problems. Biometrika, 33(3):239­251, 1945. [19] J. Lafferty and C. Zhai. Document Language Models, Query Models, and Risk Minimization for Information Retrieval. In SIGIR, pages 111­119, ACM, 2001. [20] K. T. Maxwell and W. B. Croft. Compact Query Term Selection Using Topically Related Text. In SIGIR, pages 583­592, ACM 2013. [21] A. Moffat, P. Thomas, and F. Scholer. Users Versus Models: What Observation Tells Us About Effectiveness Metrics. In CIKM, pages 659­668. ACM, 2013. [22] A. Moffat and J. Zobel. Rank-biased Precision for Measurement of Retrieval Effectiveness. ACM TOIS, 27(1):2:1­2:27, 2008. [23] J. R. Norris. Markov chains. Cambridge University Press, UK, 1998. [24] V. Pavlu, S. Rajput, P. B. Golbus, and J. A. Aslam. IR System Evaluation using Nugget-based Test Collections. In WSDM, pages 393­402, ACM, 2012. [25] S. Robertson. A New Interpretation of Average Precision. In SIGIR, pages 689­690. ACM, 2008. [26] T. Sakai. Ranking the NTCIR Systems Based on Multigrade Relevance. In AIRS 2004, pages 251­262. LNCS 3411, Springer, 2005. [27] T. Sakai. Alternatives to Bpref. In SIGIR, pages 71­78, ACM, 2007. [28] T. Sakai and Z. Dou. Summaries, Ranked Retrieval and Sessions: A Unified Framework for Information Access Evaluation. In SIGIR, pages 473­482, ACM, 2013. [29] P. Serdyukov, N. Craswell, and G. Dupret. WSCD2012: Workshop on Web Search Click Data 2012. In WSDM, pages 771­772. ACM, 2012. [30] M. D. Smucker and C. L. A. Clarke. Stochastic Simulation of Time-Biased Gain. In CIKM, pages 2040­2044. ACM, 2012. [31] M. D. Smucker and C. L. A. Clarke. Time-Based Calibration of Effectiveness Measures. In SIGIR, pages 95­104. ACM, 2012. [32] I. Soboroff. Dynamic Test Collections: Measuring Search Effectiveness on the Live Web. In SIGIR, pages 276­283. ACM, 2006. [33] E. Voorhees. Evaluation by Highly Relevant Documents. In SIGIR, pages 74­82, ACM, 2001. [34] E. M. Voorhees. Variations in relevance judgments and the measurement of retrieval effectiveness. IPM, 36(5):697­716, 2000. [35] E. Yilmaz and J. A. Aslam. Estimating Average Precision With Incomplete and Imperfect Judgments. In CIKM, pages 102­111. ACM, 2006.",null,null
,,,
536,606,null,null
,,,
537,,null,null
