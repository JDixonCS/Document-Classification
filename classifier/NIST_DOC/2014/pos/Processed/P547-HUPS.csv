,sentence,label,data
0,Leveraging Knowledge across Media for Spammer Detection in Microblogging,null,null
1,"Xia Hu, Jiliang Tang, and Huan Liu",null,null
2,"Computer Science and Engineering Arizona State University Tempe, AZ 85287, USA",null,null
3,"{xia.hu, jiliang.tang, huan.liu}@asu.edu",null,null
4,ABSTRACT,null,null
5,"While microblogging has emerged as an important information sharing and communication platform, it has also become a convenient venue for spammers to overwhelm other users with unwanted content. Currently, spammer detection in microblogging focuses on using social networking information, but little on content analysis due to the distinct nature of microblogging messages. First, label information is hard to obtain. Second, the texts in microblogging are short and noisy. As we know, spammer detection has been extensively studied for years in various media, e.g., emails, SMS and the web. Motivated by abundant resources available in the other media, we investigate whether we can take advantage of the existing resources for spammer detection in microblogging. While people accept that texts in microblogging are different from those in other media, there is no quantitative analysis to show how different they are. In this paper, we first perform a comprehensive linguistic study to compare spam across different media. Inspired by the findings, we present an optimization formulation that enables the design of spammer detection in microblogging using knowledge from external media. We conduct experiments on real-world Twitter datasets to verify (1) whether email, SMS and web spam resources help and (2) how different media help for spammer detection in microblogging.",null,null
6,Categories and Subject Descriptors,null,null
7,H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval--Classification; I.2.7 [Artificial Intelligence]: Natural Language Processing,null,null
8,General Terms,null,null
9,"Algorithm, Performance, Experimentation",null,null
10,Keywords,null,null
11,"Spammer Detection, Twitter, Emails, SMS, Web, CrossMedia Mining, Social Media",null,null
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'14, July 6­11, 2014, Gold Coast, Queensland, Australia. Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00. http://dx.doi.org/10.1145/2600428.2609632 .",null,null
13,1. INTRODUCTION,null,null
14,"Microblogging ­ a style of communicating through shortform content ­ has emerged as a popular social networking platform. Microblogging systems have been increasingly used for large-scale information dissemination and sharing in various fields such as marketing, journalism or public relations. With microblogging's growing popularity, activities of spamming have become rampant in launching various attacks in the medium. For example, the spammers spread ads to generate sales, disseminate pornography, viruses, phishing, or simply to compromise a system's reputation [3]. To improve user experience and the overall value of a system, it is essential to detect spammers in microblogging.",null,null
15,"Existing methods for spammer detection in social media [26] focus on using social networking information. These network-based methods characterize the spammers by analyzing the network features, e.g., social status. The assumption behind this strategy is that it is difficult for the spammers to establish a large number of social relations with legitimate users. Different from other social media sites, in microblogging, users can follow anyone without prior consent from the followee. Many users just follow back when they are followed by someone for the sake of courtesy [20]. So, the spammers can easily enhance their influence score to fool the system. In this case, content analysis could complement network-based methods in spammer detection; thus, we explore the use of content information in this work.",null,null
16,"A straightforward way to perform content-based spammer detection [22] is to model this task as a supervised learning problem. These methods extract effective textual features from the messages and build a classifier or a regressor based on the features. Given a new user, the built model can output a class label or score to determine whether it is a spammer based on microblogging messages the user posted. Content-based methods become difficult to be directly applied due to the distinct features of microblogging data. First, in microblogging, it is time-consuming and labor intensive to obtain labeled data, which is essential in building an effective supervised spammer detection model. Given the size and dynamic nature of microblogging, a manual labeling process is neither scalable nor sensible. Second, the texts in microblogging are short and noisy; thus, we lack sufficient aggregated information to evaluate the given messages. These present great challenges to directly making use of existing content-based methods for effective spammer detection in microblogging.",null,null
17,"While the problem of spamming in microblogging is relatively new, it has been extensively studied for years in other",null,null
18,547,null,null
19,"platforms, e.g., email communication [4], SMS [14] and the web [31]. Similarly, the spammers in these platforms unfairly overwhelm other users by spreading unwanted information, which leads to phishing, malware, and scams [20]. Also, it has been reported in Natural Language Processing (NLP) literature that microblogging is not as noisy as was expected [2]. Although microblogging is an informal communication medium, it has been shown to be similar to other platforms [21] and it is seemingly possible to employ NLP tools to ""clean"" it [11]. Motivated by the previous findings, we explore the possibility of using knowledge learned from other platforms to facilitate spammer detection in the context of microblogging.",null,null
20,"In this paper, we explore the use of resources available in other media to help spammer detection in microblogging. To study this problem, we need to answer the following questions: Are the resources from other media potentially helpful for spammer detection in microblogging? How do we explicitly model and make use of the resources from other media for spammer detection? Is the knowledge learned from other media helpful for microblogging spammer detection? By answering the above questions, this paper presents the following contributions:",null,null
21,· Conducting a quantitative analysis of linguistic variation of spam resources from different media;,null,null
22,· Formally defining the problem of leveraging knowledge across media for spammer detection in microblogging;,null,null
23,· Presenting a novel framework of leveraging knowledge from existing corpora to help spammer detection in microblogging; and,null,null
24,"· Systematically evaluating the proposed method on realworld Twitter, email, SMS and web datasets and elaborating the effects of the knowledge learned from different media on spammer detection in Twitter.",null,null
25,"The remainder of this paper is organized as follows. In Section 2, we conduct a quantitative study to examine the differences between spam corpora in different media from a linguistic perspective. In Section 3, we formally define the problem of leveraging knowledge across media for spammer detection in microblogging. In Section 4, we propose a novel framework for the problem we study. In Section 5, we report empirical results on real-world datasets. In Section 6, we review existing literature related to our work. In Section 7, we conclude this work and present some future work.",null,null
26,2. LINGUISTIC VARIATION ANALYSIS,null,null
27,"This work is motivated by numerous spam resources available in other well-studied media, e.g., email, SMS and web. A natural question could be, given the short and noisy form of microblogging messages, how different are the texts in microblogging when compared to those in other media? Before proceeding further, we also examine whether the textual information from other media is potentially useful in the problem we study.",null,null
28,2.1 Datasets,null,null
29,"Two Twitter datasets are used in our study for experiment purposes, i.e., TAMU Social Honeypots and Twitter Suspended Spammers. In addition, three representative datasets from different types of media, including Enron",null,null
30,"Email Dataset, SMS Dataset and Web Dataset, are used in the analysis. The statistics of the datasets are presented in Table 1. Now we introduce the datasets in detail.",null,null
31,"TAMU Social Honeypots Dataset (TweetH): Lee et al. [22] created a collection of 41,499 Twitter users with identity labels: spammers and legitimate users. The dataset was collected from December 30, 2009 to August 2, 2010 on Twitter. It consists of users, their number of followers and tweets. We filtered the non-English tweets and users with less than two tweets.",null,null
32,"Twitter Suspended Spammers Dataset (TweetS): We employed a data crawling process, which is similar to [32, 34], to construct this dataset. We first crawled a Twitter dataset from July to September 2012 via the Twitter Search API. The users that were suspended by Twitter during this period are considered as the gold standard [32] of spammers in the experiment. We then randomly sampled the legitimate users from a publicly available Twitter dataset provided by TREC 2011.1 We filtered the non-English tweets and users with less than two tweets.",null,null
33,"The first dataset TweetH has balanced number of spammers and legitimate users. To avoid effects brought by different class distribution, according to the literature of spammer detection [22], we made the two classes in TweetS imbalanced, i.e., the number of legitimate users is much greater than that of spammers in the dataset.",null,null
34,"Enron Email Dataset (Email): We used a subset of a widely used Enron email dataset,2 which is collected during the investigation of Enron corporation and contains more than 200,000 emails between its employees. The emails in this dataset are preprocessed and used as a testbed in [25] for experiments. Each email in the dataset is labeled as either ""spam"" or ""ham"".",null,null
35,"SMS Dataset(SMS): We used the SMS spam collection provided by Almeida et al. [1] for analysis. This dataset is constructed based on two sources, Grumbletext web site3 and NUS SMS Corpus.4 The spam messages were manually labeled, and the ham messages were randomly sampled from the NUS SMS Corpus. To the best of our knowledge, this is the largest public SMS spam dataset.",null,null
36,Web Dataset (Web): Web spam is a key challenge for internet users. Web pages which are created to deceive other users by manipulating search engine. Webb et al. [31] constructed the Web Dataset. This is the largest publicly available dataset to the best of our knowledge. We removed the web pages that have no textual content or only contain http request error information.,null,null
37,2.2 Lexical Analysis,null,null
38,"To evaluate the style of a language, many metrics have been proposed in literature of linguistics and communication [2, 30]. In this subsection, we first introduce the metrics used in our study and then discuss lexical analysis results on the datasets from different media.",null,null
39,"Basic Statistics: average Word Length (WL, in characters) and average Sentence Length (SL, in words) are used to evaluate the basic style of different datasets. In addition to those, we further employ other widely used lexical metrics in the analysis. We list the metrics below.",null,null
40,1http://trec.nist.gov/data/tweets/ 2http://www.isi.edu/~adibi/Enron/Enron.htm 3http://www.grumbletext.co.uk/ 4http://wing.comp.nus.edu.sg/SMSCorpus/,null,null
41,548,null,null
42,Table 1: Statistics of the Datasets TweetH TweetS Email,null,null
43,# of Spam Messages # of Legitimate Messages # of Messages Avg. # of Words per Document,null,null
44,"1,310,318 1,220,198 2,530,516",null,null
45,18.64,null,null
46,"71,842 308,957 380,799",null,null
47,17.88,null,null
48,"10,582 13,990 24,572 168.87",null,null
49,SMS,null,null
50,747 4827 5574 14.59,null,null
51,Web,null,null
52,"22,386 N.A. 82,386 57.67",null,null
53,Table 2: Lexical Analysis Results,null,null
54,Basics,null,null
55,Lexical Analysis,null,null
56,WL SL TTR LD OOV,null,null
57,TweetH TweetS Email SMS Web,null,null
58,4.12 12.95 5.42 0.48 0.32 3.95 12.38 5.65 0.50 0.31 4.52 17.88 5.46 0.53 0.29 3.99 12.60 6.54 0.45 0.34 4.81 18.66 6.13 0.48 0.32,null,null
59,Type-Token Ratio (TTR): This is a widely used metric,null,null
60,"to evaluate the difficulty (or readability) of words, sentences",null,null
61,"and documents by measuring their lexical variety [7, 33].",null,null
62,The basic assumption of using TTR is that difficult words,null,null
63,are those that appear least often in a document. Given a,null,null
64,"corpus D, TTR is calculated as T T R(D) ,",null,null
65,wD,null,null
66,F req(w) Size(D),null,null
67,",",null,null
68,"where w means a word (token) in the corpus, F req(w) means",null,null
69,"word frequency of w in D, and Size(D) means the number",null,null
70,"of distinct words (types) in D. In practice, a higher TTR",null,null
71,indicates a larger amount of lexical variation and a lower,null,null
72,score indicates relatively less lexical variation [33].,null,null
73,Lexical Density (LD): We employ lexical density to,null,null
74,further analyze the stylistic difference between different cor-,null,null
75,"pora. Lexical words [15], also known as content or infor-",null,null
76,"mation carrying words, refer to verbs, nouns, adjectives and",null,null
77,"adverbs. Similarly, given a document D, LD is defined as",null,null
78,"LD(D) ,",null,null
79,wLex,null,null
80,F req(w) Size(D),null,null
81,",",null,null
82,where,null,null
83,Lex,null,null
84,means,null,null
85,the,null,null
86,whole,null,null
87,lex-,null,null
88,"ical words dictionary. In general, a higher lexical density",null,null
89,"indicates that it is a more formal document, and a lower",null,null
90,lexical density represents a more conversational one.,null,null
91,Out-of-Vocabulary (OOV): This metric is to measure,null,null
92,the ratio of out-of-vocabulary words in the corpora. We use,null,null
93,"a list of top 10,000 words with highest frequency provided",null,null
94,"by the Project Gutenberg [16] in our study. In general, a",null,null
95,higher OOV rate indicates that the language is more infor-,null,null
96,mal. Many NLP and IR models suffer from high OOV rates.,null,null
97,Experimental results of the lexical analysis are presented,null,null
98,"in Table 2. By comparing the results of different metrics, we",null,null
99,observe the following: (1) The word lengths of different cor-,null,null
100,"pora are very similar, and the sentence lengths of TweetH,",null,null
101,TweetS and SMS are smaller than those of more formal me-,null,null
102,dia Email and Web. This indicates that the textual form of,null,null
103,"microblogging data is similar to SMS, and relatively different",null,null
104,"from email and web. (2) In most of the tests, microblogging",null,null
105,data is similar to the datasets from the other media. It,null,null
106,"demonstrates that, although microblogging is considered an",null,null
107,"informal media, the language use is similar to that in other",null,null
108,"media, especially in email and SMS. We observe that the",null,null
109,type-token ratios of microblogging are smaller than those of,null,null
110,SMS and web. It suggests that the language used in mi-,null,null
111,croblogging is easier than that in the other two platforms.,null,null
112,We further employ hypothesis testing to examine the lex-,null,null
113,ical differences between microblogging datasets and other,null,null
114,Table 3: Hypothesis Testing Results (P-Values),null,null
115,TweetH,null,null
116,TweetS,null,null
117,TTR LD OOV TTR LD OOV,null,null
118,Email 0.318 0.108 0.442 0.234 0.267 0.308 SMS <0.01 0.205 0.350 <0.01 0.082 0.163 Web <0.01 0.623 0.398 0.108 0.551 0.462,null,null
119,"datasets. For each lexical metric, we form a null hypothesis for a microblogging dataset and a dataset from the other media. The null hypothesis is: in terms of the specific lexical metric, there is no difference between microblogging data and data from the other media. We test the hypotheses on all pairs of the datasets for all the three lexical metrics.",null,null
120,"In particular, to verify the difference between TweetH and Email datasets on the TTR, we construct two vectors ttrth and ttrem. Each element of the first vector ttrth is obtained by calculating the TTR score of a subset sampled with bootstrapping from TweetH dataset. Similarly, each element in the second vector corresponds to the TTR score of a subset sampled with bootstrapping from Email dataset. In the experiment, the two vectors contain equal number of elements.5 Each element in the vectors corresponds to 100 data instances. We formulate a two-sample two-tail t-test on the two constructed vectors ttrth and ttrem. We examine whether there is sufficient statistical evidence to support the hypothesis that the two datasets have the same sample mean, and it is defined as follows:",null,null
121,"H0 : th - em , 0",null,null
122,(1),null,null
123,"H1 : th - em , 0",null,null
124,"where H0 is the null hypothesis, H1 is the alternative hypothesis, and c and r represent the sample means of the two vectors, respectively. Similarly, we form the hypothesis testings for other pairs of datasets with other lexical metrics.",null,null
125,"The t-test results, p-values, are summarized in Table 3. From the table, we can observe the following: (1) With few exceptions, the results are much greater than the significance level  ,"" 0.05. It demonstrates that there is no statistical evidence to reject the null hypothesis in the tests on the two datasets. In other words, the results suggest that microblogging data is not significantly different from the datasets in other media. (2) In some tests, microblogging data appears more similar to Email than the other datasets.""",null,null
126,"In conclusion, while characteristics of different datasets appear different, there are no statistically significant lexical differences between them. The resources from other media are potentially useful in the task we study. Next, we formally define the problem we study and introduce the proposed learning framework for spammer detection.",null,null
127,"5Note this is the setting used for experiment purposes, and it is not a mandatory setting for a two-sample t-test.",null,null
128,549,null,null
129,3. PROBLEM STATEMENT,null,null
130,"In this section, we first present the notations and then",null,null
131,formally define the problem we study.,null,null
132,"Notation: lower-case bold Roman letters (e.g., a) denote",null,null
133,"column vectors, upper-case letters (e.g., A) denote matri-",null,null
134,"ces, and lowercase letters (e.g., a) denote scalars. A(i, j) denotes the entry at the ith row and jth column of a ma-",null,null
135,"trix A. Let A denote the Euclidean norm, and A F",null,null
136,"the Frobenius norm of the matrix A. Specifically, A F ,",null,null
137,"m i,1",null,null
138,"n j,1",null,null
139,"A(i,",null,null
140,j)2.,null,null
141,Let AT,null,null
142,and,null,null
143,T r(A) denote the trans-,null,null
144,"pose and trace of A, respectively.",null,null
145,"Let S ,"" [X, Y] be available resources from other media,""",null,null
146,with the content information X and identity label matrix Y. We use term-user matrix X  Rm×d to denote con-,null,null
147,"tent information, i.e., posts written by the users, where",null,null
148,"m is the number of textual features, and d is the number",null,null
149,"of users in the other media. X ,"" {X1, X2, ..., Xr} means""",null,null
150,"the combination of content information from multiple media, and Y  Rd×c ,"" {Y1, Y2, ..., Yr} means the combi-""",null,null
151,"nation of label information from the media. For each user (xi, yi)  Rm+c consists of message content and identity label, where xi  Rm is the message feature vector and yi  Rc is the spammer label vector. In this paper, we con-",null,null
152,"sider the task we study as a two-class classification problem,",null,null
153,"i.e., c ,"" 2. For example, yi "","" (1, 0) means this user is a spammer. yiT yi "", 1 constrains that yi has to have one la-",null,null
154,"bel and cannot be (0, 0) or (1, 1). It is practical to extend",null,null
155,this setting to a multi-class or regression problem. We use T  Rm×n to denote the content information of microblog-,null,null
156,"ging users, where m is the number of textual features, and",null,null
157,n is the number of users in microblogging. The texts from,null,null
158,microblogging and other media share the same feature space.,null,null
159,We now formally define the problem as follows:,null,null
160,"We have a set of resources S from different media, with",null,null
161,"the content information X ,"" {X1, X2, ..., Xr} and identity label information Y "","" {Y1, Y2, ..., Yr}. Given the content""",null,null
162,"information T from microblogging, our goal is to automat-",null,null
163,ically infer the identity labels for unknown users in T as,null,null
164,spammers or legitimate users.,null,null
165,4. LEVERAGING KNOWLEDGE ACROSS MEDIA FOR SPAMMER DETECTION,null,null
166,"We plot the work flow of our proposed framework in Figure 1. From the figure, we see that there are two constraints on the learned model for spammer detection. As shown in the upper right part of the figure, the first constraint is from the lexicon information U, which is learned from the other media sources S. As shown in the lower right part of the figure, the second constraint is a Laplacian regularization M learned from microblogging content information. We now introduce each part of the proposed framework in detail.",null,null
167,4.1 Modeling Knowledge across Media,null,null
168,"As we discussed in the last section, from a linguistic perspective, it does not show significant difference between microblogging data and other types of data. A straightforward method to make use of external information is to learn a supervised model based on data from the other media, and apply the learned classifier on microblogging data for spammer detection. However, this method yields two problems to be directly applied to our task. First, text representation models, like n-gram model, often lead to a high-dimensional",null,null
169,"T ,",null,null
170,Ut Ht,null,null
171,Vt,null,null
172,Spammer Detection,null,null
173,Modeling Knowledge across Media,null,null
174,"UH V ,",null,null
175,"S ,"" {Email, SMS, Web}""",null,null
176,M,null,null
177,Microblogging,null,null
178,Modeling Content Information,null,null
179,Figure 1: Illustration of the Proposed Spammer Detection Framework,null,null
180,"feature space because of the large size of data and vocabulary. Second, texts in the media are short, thus making the data representation very sparse [21].",null,null
181,"To tackle the problems, instead of learning knowledge at word-level, we propose to capture the external knowledge from topic-level. In particular, the proposed method is built on the orthogonal nonnegative matrix tri-factorization model (ONMTF) [9]. The basic idea of the ONMTF model is to cluster data instances based on distribution of features, and cluster features according to the distribution of data instances. The principle of ONMTF is consistent with PLSI [17], in which each document is a mixture of latent topics that each word can be generated from. The ONMTF can be formulated by optimizing:",null,null
182,min,null,null
183,"U,H,V0",null,null
184,X - UHVT,null,null
185,2 F,null,null
186,",",null,null
187,(2),null,null
188,"s.t. UT U ,"" I, VT V "","" I,""",null,null
189,"where X is the content matrix, and U  Rm + ×c and V  Rd+×c are nonnegative matrices indicating low-dimensional representations of words and users, respectively. m is the size of vocabulary, c is the number of classes, d is the number of users. H  Rc+×c provides a condensed view of X. The orthogonal and nonnegative conditions of U and V provide",null,null
190,a hard assignment of class label to the words and users.,null,null
191,"With the ONMTF model, we project the original content",null,null
192,information from the other media into a latent topic space.,null,null
193,"By adding a topic-level least squares penalty to the ONMTF,",null,null
194,our proposed framework can be mathematically formulated,null,null
195,as solving the following optimization problem:,null,null
196,min,null,null
197,"U,H,V,W0",null,null
198,"J,",null,null
199,X - UHVT,null,null
200,2 F,null,null
201,+,null,null
202,VW - Y,null,null
203,2 F,null,null
204,",",null,null
205,(3),null,null
206,"s.t. UT U ,"" I, VT V "","" I,""",null,null
207,"where W represents the weights and Y is the label matrix. In the formulation, the first term is the basic factorization model, and the second introduces label information from the other media by using a linear penalty.  is to control the effect of external information to the learned lexicon U, in which each row represents the predicted label of a word.",null,null
208,"As the problem in Eq. (3) is not convex with respect to the four variables together, there is no closed-form solution for the problem. Next, we introduce an alternative scheme to solve the optimization problem.",null,null
209,550,null,null
210,4.1.1 Optimization Algorithm,null,null
211,"Following [9], we propose to optimize the objective with respect to one variable, while fixing others. The algorithm will keep updating the variables until convergence.",null,null
212,Computation of H: Optimizing the objective function in Eq. (3) with respect to H is equivalent to solving,null,null
213,min,null,null
214,H0,null,null
215,"JH ,",null,null
216,X - UHVT,null,null
217,2 F,null,null
218,.,null,null
219,(4),null,null
220,Let H be the Lagrange multiplier for constraint H  0; the Lagrange function L(H) is defined as follows:,null,null
221,"L(H) ,",null,null
222,X - UHVT,null,null
223,2 F,null,null
224,-,null,null
225,T r(H HT ).,null,null
226,(5),null,null
227,"By setting the derivative HL(H) ,"" 0, we get""",null,null
228,"H , -2UT XV + 2UT UHVT V.",null,null
229,(6),null,null
230,The Karush-Kuhn-Tucker complementary condition [6] for the nonnegativity constraint of H gives,null,null
231,"H (i, j)H(i, j) , 0 ;",null,null
232,(7),null,null
233,"thus, we obtain",null,null
234,"[-UT XV + UT UHVT V](i, j)H(i, j) , 0.",null,null
235,(8),null,null
236,"Similar to [9], it leads to the updating rule of H,",null,null
237,"H(i, j)  H(i, j)",null,null
238,"[UT XV](i, j) [UT UHVT V](i, j) .",null,null
239,(9),null,null
240,Computation of U: Optimizing the objective function in Eq. (3) with respect to U is equivalent to solving,null,null
241,min,null,null
242,U0,null,null
243,"JU ,",null,null
244,X - UHVT,null,null
245,2 F,null,null
246,"s.t. UT U , I.",null,null
247,(10),null,null
248,"Let U and U be the Lagrange multipliers for constraints U  0 and UT U ,"" I, respectively; the Lagrange function""",null,null
249,L(U) is defined as follows:,null,null
250,"L(U) ,",null,null
251,X - UHVT,null,null
252,2 F,null,null
253,- T r(U UT ),null,null
254,+,null,null
255,T r(U (UT U,null,null
256,-,null,null
257,I)),null,null
258,(11),null,null
259,"By setting the derivative UL(U) ,"" 0, we get""",null,null
260,"U , -2XVHT + 2UHVT VHT + 2UU .",null,null
261,(12),null,null
262,"With the KKT complementary condition for the nonnegativity constraint of U, we have",null,null
263,"U (i, j)U(i, j) , 0;",null,null
264,(13),null,null
265,"thus, we obtain",null,null
266,"[-XVHT + UHVT VHT + UU ](i, j)U(i, j) ,"" 0, (14)""",null,null
267,where,null,null
268,"U ,UT XVHT - HVT VHT .",null,null
269,(15),null,null
270,"anLdet -U(Ui,,j),+U",null,null
271,"--U , where (|U (i, j)| -",null,null
272,"+U (i, j) ,"" (|U U (i, j))/2 [9];""",null,null
273,"(i, j)|+U we get",null,null
274,"(i,",null,null
275,j))/2,null,null
276,"[-(XVHT + U-U ) + (UHVT VHT + U+U )](i, j)U(i, j) ,"" 0, (16)""",null,null
277,"which leads to the updating rule of U,",null,null
278,"U(i, j)  U(i, j)",null,null
279,[XVHT + [UHVT VHT,null,null
280,"U-U ](i, j) + U+U ](i,",null,null
281,j,null,null
282,),null,null
283,.,null,null
284,(17),null,null
285,Algorithm 1: Modeling Knowledge across Media,null,null
286,"Input: {X, Y, , I} Output: V",null,null
287,"1: Initialize U, V, H, W  0 2: while Not convergent and iter  I do",null,null
288,3:,null,null
289,"Update H(i, j)  H(i, j)",null,null
290,"[UT XV](i,j) [UT UHVT V](i,j)",null,null
291,4:,null,null
292,"Update U(i, j)  U(i, j)",null,null
293,"[XVHT +U- U ](i,j) [UHVT VHT +U+ U ](i,j)",null,null
294,5:,null,null
295,"Update V(i, j)  V(i, j)",null,null
296,"[XT UH+YWT +V- V ](i,j) [VHT UT UH+VWWT +V+ V ](i,j)",null,null
297,6:,null,null
298,"Update W(i, j)  W(i, j)",null,null
299,"[VT Y](i,j) [VT VW](i,j)",null,null
300,"7: iter , iter + 1",null,null
301,8: end while,null,null
302,Computation of V: Optimizing the objective function in Eq. (3) with respect to V is equivalent to solving,null,null
303,min,null,null
304,V0,null,null
305,"J,",null,null
306,X - UHVT,null,null
307,2 F,null,null
308,+,null,null
309,VW - Y,null,null
310,2 F,null,null
311,(18),null,null
312,"s.t. VT V , I.",null,null
313,"Similar to the computation of U, by introducing two Lagrange multipliers V and V for the constraints, we get",null,null
314,"[-(XT UH + YWT + V-V ) + (VHT UT UH + VWWT + V+V )](i, j)V (i, j) ,"" 0,""",null,null
315,"(19) which leads to the updating rule of V,",null,null
316,"V(i, j)  V(i, j)",null,null
317,"[XT UH + YWT + V-V ](i, j) [VHT UT UH + VWWT + V+V ](i, j)",null,null
318,(20),null,null
319,Computation of W: Optimizing the objective function,null,null
320,in Eq. (3) with respect to W is equivalent to solving,null,null
321,min,null,null
322,W0,null,null
323,"J,",null,null
324,VW - Y,null,null
325,2 F,null,null
326,.,null,null
327,(21),null,null
328,"Similar to the computation of U, by introducing a Lagrange multiplier and satisfying KKT condition, we obtain",null,null
329,"[VT VW - VT Y](i, j)W(i, j) ,"" 0,""",null,null
330,(22),null,null
331,"which leads to the updating rule of W,",null,null
332,"W(i, j)  W(i, j)",null,null
333,"[VT Y](i, j) [VT VW](i, j) .",null,null
334,(23),null,null
335,"We summarize the algorithm of optimizing Eq. (3) in Algorithm 1, where I is the number of maximum iterations. In line 1, we conduct initialization for the variables. From lines 2 to 8, the four variables are updated with the updating rules until convergence or until they reach the number of maximum iterations. The correctness and convergence of the updating rules can be proven with the standard auxiliary function approach [28].",null,null
336,4.2 Modeling Content Information,null,null
337,"In this subsection, as shown in the lower right part of Figure 1, we introduce how to model content information of microblogging data in the proposed model.",null,null
338,551,null,null
339,To make use of the content information of microblogging,null,null
340,"messages, we introduce a graph Laplacian [8] in the proposed model. We construct a graph based on content information of the users. In the graph, each node represents a user and each edge represents the affinity between two users. The adjacency matrix M  Rn×n of the graph is defined as",null,null
341,1 if u  N (v) or v  N (u),null,null
342,"M(u, v) ,",null,null
343,(24),null,null
344,0 otherwise,null,null
345,"where u and v are nodes, and N (u) represents the k-nearest neighbor of the user. Content similarity is adopted to obtain the k-nearest neighbor in this work. Since we aim to model the mutual content similarity between two users, the adjacency matrix is symmetric.",null,null
346,"The basic idea of of using the graph Laplacian to model the content information is that if two nodes are close in the graph, i.e., they posted similar messages, their identity labels should be close to each other. It can be mathematically formulated as minimizing the following loss function:",null,null
347,nn,null,null
348,R,null,null
349,",",null,null
350,1 2,null,null
351,"Vt(i, ) - Vt(j, )",null,null
352,2 2,null,null
353,"M(i,",null,null
354,j).,null,null
355,"i,1 j,1",null,null
356,(25),null,null
357,This loss function will incur a penalty if two users have dif-,null,null
358,"ferent predicted labels when they are close to each other in the graph. Let D  Rn×n denote a diagonal matrix, and",null,null
359,its diagonal element is the degree of a user in the adjacency,null,null
360,"matrix M, i.e., D(i, i) ,",null,null
361,"n j,1",null,null
362,"M(i,",null,null
363,j,null,null
364,).,null,null
365,Theorem 1. The formulation in Eq. (25) is equivalent to the following objective function:,null,null
366,"R ,"" T r(VtT LVt),""",null,null
367,(26),null,null
368,"where the Laplacian matrix [8] L is defined as L , D - M.",null,null
369,Proof. It is easy to verify that Eq. (25) can be rewritten as,null,null
370,"R,",null,null
371,", ,",null,null
372,nn c,null,null
373,"Vt(i, k)M(i, j)VtT (i, k)",null,null
374,"i,1 j,1 k,1",null,null
375,nn c,null,null
376,-,null,null
377,"Vt(i, k)M(i, j)VtT (j, k)",null,null
378,"i,1 j,1 k,1",null,null
379,T r(VtT (D - M)Vt),null,null
380,"T r(VtT LVt),",null,null
381,(27),null,null
382,which completes the proof. 2,null,null
383,4.3 Spammer Detection Framework,null,null
384,"As illustrated in Figure 1, we employ two types of information to formulate two kinds of constraints on the learned model. By integrating knowledge learned from other media and content information from microblogging, we can perform spammer detection by optimizing",null,null
385,min,null,null
386,"Ut ,Ht ,Vt 0",null,null
387,"J,",null,null
388,T - UtHtVtT,null,null
389,2 F,null,null
390,+,null,null
391,T r(VtT LVt),null,null
392,+,null,null
393,GU (Ut - U),null,null
394,2 F,null,null
395,"),",null,null
396,(28),null,null
397,"s.t. UTt Ut ,"" I, VtT Vt "","" I,""",null,null
398,"where the first term is to factorize the microblogging data into three variables, which are similar to the idea discussed in Section 4.1. The second term is to introduce content information and the third is to introduce knowledge learned from the other media. U is the lexicon learned from the other",null,null
399,Algorithm 2: Spammer Detection in Microblogging,null,null
400,"Input: {T, U, , , I }",null,null
401,Output: Vt,null,null
402,1: Construct matrices L in Eq. (26),null,null
403,"2: Initialize Ut ,"" U, V, H  0 3: while Not convergent and iter  I do""",null,null
404,4:,null,null
405,"Update Ht(i, j)  Ht(i, j)",null,null
406,"[UTt XVt ](i,j) [UTt UtHt VtT Vt](i,j)",null,null
407,5: Update,null,null
408,"Ut(i, j)  Ut(i, j)",null,null
409,"[XVt HTt +GU U+Ut - U ](i,j) [Ut HtVtT Vt HTt +GU Ut+Ut+ U ](i,j)",null,null
410,6: Update,null,null
411,7:,null,null
412,"Vt(i, j)  Vt(i, j)",null,null
413,"[XT Ut Ht+MVt+Vt - V ](i,j) [Vt HTt UTt UtHt +DVt+Vt + V ](i,j)",null,null
414,"8: iter , iter + 1",null,null
415,9: end while,null,null
416,"media by solving the problem in Eq. (3). GU  {0, 1}m×m is a diagonal indicator matrix to control the impact of the learned lexicon, i.e., GU (i, i) ,"" 1 represents that the i-th word contains identity information, GU (i, i) "", 0 otherwise.",null,null
417,"This optimization problem is not convex with respect to the three parameters together. Following the optimization procedure to solve Eq. (3), we propose an algorithm to solve the problem in Eq. (28) and summarize it in Algorithm 2. In line 1, we construct the Laplacian matrix L. In line 2, we initialize the variables. From lines 3 to 9, we keep updating the variables with the updating rules until convergence or until the number of maximum iterations is reached.",null,null
418,5. EXPERIMENTS,null,null
419,"In this section, we empirically evaluate the proposed learning framework and the factors that could bring in effects to the framework. Through the experiments, we aim to answer the following two questions:",null,null
420,· How effective is the proposed framework compared with other possible solutions of using external information across media in real-world spammer detection tasks?,null,null
421,· What impact do the other resources have on the performance of spammer detection in microblogging?,null,null
422,5.1 Experimental Setup,null,null
423,"We follow a standard experiment setup used in spammer detection literature [34] to evaluate the effectiveness of our proposed framework for leveraging knowledge aCross media for Spammer Detection (CSD). In particular, we compare the proposed framework CSD with different baseline methods for spammer detection. To avoid bias, both TweetH and TweetS, introduced in Section 2.1, are used in the experiments. For email data, we consider each sender a user; For SMS and web data, we do not have user information and consider each message as sent from a distinct user. In the experiment, precision, recall and F1-measure are used as the performance metrics.",null,null
424,"To evaluate the general performance of the proposed framework, we use all of the three datasets from different media, i.e., Email, SMS and Web datasets. In the first set of experiments, to be discussed in Section 5.2, we simply combine them together and consider them as homogeneous data sources. In the second set of experiments, to be discussed in",null,null
425,552,null,null
426,Least Squares Lasso MFTr MFSD CSD,null,null
427,Table 4: Spammer Detection Results on TweetH Dataset,null,null
428,External Data I (50%),null,null
429,External Data II (100%),null,null
430,Precision Recall F1-measure (gain) Precision Recall F1-measure (gain),null,null
431,0.823 0.834,null,null
432,0.828 (N.A.),null,null
433,0.839 0.852,null,null
434,0.845 (N.A.),null,null
435,0.865 0.891 0.878 (+5.96%),null,null
436,0.873 0.905 0.889 (+5.12%),null,null
437,0.866 0.899 0.882 (+6.49%),null,null
438,0.887 0.918 0.902 (+6.72%),null,null
439,0.644 0.703 0.672 (-18.7%),null,null
440,0.650 0.715 0.681 (-19.5%),null,null
441,0.906 0.939 0.922 (+11.3%),null,null
442,0.913 0.944 0.928 (+9.79%),null,null
443,Least Squares Lasso MFTr MFSD CSD,null,null
444,Table 5: Spammer Detection Results on TweetS Dataset,null,null
445,External Data I (50%),null,null
446,External Data II (100%),null,null
447,Precision Recall F1-measure (gain) Precision Recall F1-measure (gain),null,null
448,0.766 0.813,null,null
449,0.789 (N.A.),null,null
450,0.793 0.820,null,null
451,0.806 (N.A.),null,null
452,0.801 0.849 0.824 (+4.50%),null,null
453,0.814 0.848 0.831 (+3.02%),null,null
454,0.810 0.857 0.833 (+5.58%),null,null
455,0.833 0.878 0.855 (+6.03%),null,null
456,0.621 0.69 0.654 (-17.1%),null,null
457,0.642 0.681 0.661 (-18.0%),null,null
458,0.832 0.875 0.853 (+8.13%),null,null
459,0.848 0.919 0.882 (+9.40%),null,null
460,"Section 5.3, we consider their individual impact on the performance of spammer detection. A standard procedure for data preprocessing is used in our experiments. The unigram model is employed to construct the feature space, tf-idf is used as the feature weight.",null,null
461,"As we discussed in Sections 4.1 and 4.3, three positive parameters are involved in the experiments, including  in Eq. (3), and  and  in Eq. (28).  is to control the effect of knowledge from other media to the learned lexicon,  is to control the contribution of Laplacian regularization, and  is to control the contribution of lexicon to the spammer detection model. Since all the parameters can be tuned via crossvalidation with a set of validation data, in the experiment, we empirically set  ,"" 0.1,  "", 0.1 and  , 0.1 for general experiment purposes. The effects of the parameters on the learning model will be further discussed in Section 5.4.",null,null
462,5.2 Performance Evaluation,null,null
463,"We compare the proposed method CSD with other methods for spammer detection, accordingly answer the first question asked above. The baseline methods are listed below.",null,null
464,"· Least Squares: One possible solution for our task is to consider it as a supervised learning problem. We simply train a classification model with the available external data and apply the learned model on microblogging data for spammer detection. The widely used classifier, Least Squares [12], is used for comparison.",null,null
465,"· Lasso: Sparse learning methods are effective for highdimensional data in social media. We further include Lasso [29] as the baseline method, which performs continuous shrinkage and automatic feature selection by adding l1 norm regularization to the Least Squares.",null,null
466,"· MFTr : Although we first present a quantitative linguistic variation analysis and provide a unified model for spammer detection across different media, domain adaption and transfer learning have received great attention in various applications [27]. We apply a widely used transfer learning method [23], which transfers the knowledge directly from labeled data in the source do-",null,null
467,"main to the target domain for classification, to test its performance on spammer detection in the experiment.",null,null
468,"· MFSD: We test the performance of the unsupervised learning method by employing the basic matrix factorization model MFSD. This is a variant of our proposed method without introducing any knowledge learned from external sources. As a common initialization for clustering methods, we randomly assign initial centroids and an initial class indicator matrix for MFSD.",null,null
469,"Experimental results of the methods on the two datasets, TweetH and TweetS, are respectively reported in Table 4 and 5. To avoid bias brought by the sizes of the training data,6 we conduct two sets of experiments with different numbers of training instances. In the experiments, ""External Data I (50%)"" means that we randomly chose 50% from the whole training data. ""External Data II (100%)"" means that we use all the data for training. Also, ""gain"" represents the percentage improvement of the methods in comparison with the first baseline method Least Squares. In the experiment, each result denotes an average of 10 test runs. By comparing the spammer detection performance of different methods, we observe the following:",null,null
470,"(1) From the results in the tables, we can observe that our proposed method CSD consistently outperforms other baseline methods on both datasets with different sizes of training data. Our method achieves better results than the state-of-the-art method MFTr on both datasets. We apply two-sample one-tail t-tests to compare CSD to the four baseline methods. The experiment results demonstrate that the proposed model performs significantly better (with significance level  , 0.01) than the four methods.",null,null
471,"(2) The performance of our proposed method CSD is better than the first three baselines, which are based on different strategies of using resources from the other media. This demonstrates the excellent use of cross-media knowledge in the proposed framework for spammer detection.",null,null
472,"6Similar to the definitions in machine learning literature, training data here refers to the labeled data from the external sources, and testing data represents the unlabeled microblogging data.",null,null
473,553,null,null
474,Performance,null,null
475,1 0.95,null,null
476,0.9 0.85,null,null
477,0.8 0.75,null,null
478,0.7 Precision,null,null
479,CSD_Email CSD_SMS CSD_Web CSD,null,null
480,Recall,null,null
481,Metrics,null,null
482,F1-measure,null,null
483,Figure 2: Results on TweetH Dataset,null,null
484,Performance,null,null
485,1 0.95,null,null
486,0.9 0.85,null,null
487,0.8 0.75,null,null
488,0.7 Precision,null,null
489,CSD_Email CSD_SMS CSD_Web CSD,null,null
490,Recall,null,null
491,Metrics,null,null
492,F1-measure,null,null
493,Figure 3: Results on TweetS Dataset,null,null
494,"(3) Among the baseline methods, MFTr achieves the best results. It demonstrates that the knowledge transferred from other media help the task of spammer detection in microblogging. Lasso performs better than Least Squares. This shows that, for high-dimensional textual data from email, SMS and web, feature selection is necessary for a supervised learning method for this task we study.",null,null
495,(4) The method MFSD achieves the worst performance among all the baseline methods. It shows that learning based on microblogging data itself can not discriminant well between spammers and legitimate users. It further demonstrates that the knowledge learned from external sources is helpful to build an effective model to tackle the problem.,null,null
496,"In summary, with the effective use of data from the other media, our proposed framework outperforms the baseline methods in spammer detection. Next, we investigate the effects of different resources on the spammer detection task.",null,null
497,5.3 Effects of External Information,null,null
498,"In this subsection, we study the effects of the external information from the other media on our proposed framework, accordingly answering the second question asked in the beginning of Section 5.",null,null
499,"We first evaluate the performance of the proposed framework with data from only one of the three media. In particular, we learn a lexicon based on one of the three types of media, i.e., email, SMS and web, and perform spammer detection on the microblogging datasets. We do not have legitimate web pages in the original Web dataset. To build a classifier CSD Web, following the data construction procedure proposed in [18], we randomly sample 20,100 web",null,null
500,"snippets with BingAPI as legitimate data. The experimental results of the methods on the two microblogging datasets are plotted in Figures 2 and 3, respectively. In the figures, the first three bars represent the performance of the baselines with one type of external information. The last is the method with all three types of external information. From the figures, we observe the following:",null,null
501,"(1) With the integration of all three types of external information, CSD consistently achieves better performance than the three baselines with only one type of information. It demonstrates that the proposed method uses beneficial information to perform effective spammer detection.",null,null
502,"(2) Among the three baseline methods, CSD Email and CSD SMS achieve better performance than CSD Web. It shows that, as external resources, email and SMS data are more suitable to be used for the spammer detection in microblogging than the web data. This result is consistent with the linguistic variation analysis in Section 2.",null,null
503,"To further explore the effects of different media sources on the performance of spammer detection in microblogging, we employ a ""knockout"" technique in the experiment. Knockout has been widely used in many fields, e.g., gene function analysis, to test the performance variance brought by one component when it is made inoperative in the framework [10]. We conduct the experiments by knocking out one type of the external information from the proposed framework. The results are summarized in Table 6. In the table, ""loss"" represents the performance decrease of the methods as compared to the setting ""Default"" which is learned based on data from all three media sources. The three columns in the middle are experimental settings, in which ""0"" means this resource is knocked out. The last two columns are the F1measure results under different experimental settings. From the table, we observe the following:",null,null
504,"(1) By knocking out one of the external sources, performance of the proposed framework decreases. This suggests that all the three types of external information are useful for spammer detection in microblogging.",null,null
505,(2) Knocking out email from the resources incurs the most performance decrease among all the experimental settings. This demonstrates that email is the most effective source among the three types of information. This finding is consistent with our discussion above.,null,null
506,"In summary, the use of data from the other media shows the effectiveness in spammer detection task. The superior performance of the proposed method CSD validates its excellent use of knowledge from the other media.",null,null
507,5.4 Parameter Analysis,null,null
508,"As discussed in Section 5.1, three positive parameters, i.e., ,  and , are involved in the proposed framework. We first examine the effects brought by , which is to control the contribution of knowledge from other media to the learned lexicon. In previous subsections, for general experimental purposes, we empirically set  ,"" 0.1. We now conduct experiments to compare the spammer detection performance of the four methods introduced in Section 5.3 with different settings of . The experiment results on the TweetH dataset are plotted in Figure 4. From the figure, we observe the following: (1) The general trends of the four methods are similar with the variation of different parameter settings. They achieve relatively good performance when setting  in the range of [0.1, 10]. (2) In most cases, performance of""",null,null
509,554,null,null
510,Table 6: Learning from Different Media for Spammer Detection in Microblogging,null,null
511,Email SMS,null,null
512,Web TweetH (loss),null,null
513,TweetS (loss),null,null
514,Default,null,null
515,1,null,null
516,1,null,null
517,1,null,null
518,0.928 (N.A.),null,null
519,0.882 (N.A.),null,null
520,Knock Out One Term,null,null
521,0 1 1,null,null
522,1,null,null
523,1,null,null
524,0.881 (-5.09%),null,null
525,0.843 (-4.43%),null,null
526,0,null,null
527,1,null,null
528,0.911 (-1.86%),null,null
529,0.856 (-2.96%),null,null
530,1,null,null
531,0,null,null
532,0.923 (-0.57%),null,null
533,0.860 (-2.50%),null,null
534,Spammer Detection Performance,null,null
535,1 0.95,null,null
536,0.9 0.85,null,null
537,0.8 0.75,null,null
538,0.7 0.65,null,null
539,0.6 1e-4,null,null
540,1e-3,null,null
541,0.01,null,null
542,0.1,null,null
543,1,null,null
544,Parameter ,null,null
545,CSD_Email CSD_SMS CSD_Web CSD,null,null
546,10,null,null
547,100,null,null
548,Figure 4: Performance with Different  Settings,null,null
549,Spammer Detection Performance,null,null
550,1,null,null
551,0.95,null,null
552,0.9,null,null
553,0.85,null,null
554,0.8,null,null
555,0.75,null,null
556,0.7,null,null
557,0.65 10,null,null
558,5,null,null
559,10,null,null
560,1,null,null
561,5,null,null
562,0.1 0.01,null,null
563,1 0.1 0.01,null,null
564,Parameter -- ,null,null
565,1e-3 1e-3,null,null
566,Parameter -- ,null,null
567,Figure 5: Impact of Content Information () and External Information (),null,null
568,the proposed CSD is better than the other three methods. It demonstrates that the combination of the three resources improve the spammer detection performance.,null,null
569,"We further examine the effects of the parameters  and  discussed in Eq. (28) on the proposed framework.  is to control the contribution of content information and  is to control the effects of external information from the other media. To understand the effects brought by the parameters, we compare the spammer detection performance of the proposed CSD on the Twitter datasets with different parameter settings. The results on the TweetH dataset are plotted in Figure 5. From the figure, we observe that the proposed method CSD performs well when   [0.1, 5] and   [0.1, 1]. Generally, the performance of CSD is not quite sensitive to the parameters. The proposed framework can perform well when choosing parameter settings in a reasonable range. Similar results have been observed for the two sets of experiments on the TweetS dataset; we omit the results owing to lack of space.",null,null
570,6. RELATED WORK,null,null
571,"Significant efforts have been devoted to detecting spammers in various online social networks, including Facebook [5], Twitter [19, 20, 22], Renren [32], Blogosphere [24], etc. One effective way to perform spammer detection is to use the social network information. The assumption is that spammers cannot establish a large number of social trust relations with normal users. This assumption might not hold in many social networks. Yang et al. [32] studied the spammers in Renren, and found that spammers can have their friend requests accepted by many other users and thus blend into the Renren social graph. Different from Facebook-like OSNs, microblogging systems feature unidirectional user bindings because anyone can follow anyone else without prior consent from the followee. Ghosh et al. [13] show that spammers can acquire many legitimate followers. Besides the methods based on social networks, some efforts [22] have also been devoted to study characteristics related to tweet content and user social behavior. By understanding spammer activities in social networks, features are extracted to perform effective spammer detection. These methods need a large amount of labeled data, which is hard to obtain in social media.",null,null
572,"Spammer detection on emails [4], SMS [14] and the web [31] has been a hot topic for quite a few years. The spams are designed to corrupt the user experience by spreading ads or driving traffic to particular web sites [31]. A popular and well-developed approach for anti-spam applications is learning-based filtering. The basic idea is that we extract effective features from the labeled data and build a classifier. We then classify new users / messages as either spam or ham according to their content information for filtering. The attempts have been done in these areas and the abundant labeled resources are the major motivation of our work.",null,null
573,"Some efforts have been made to employ domain adaption and transfer learning in various applications, e.g. sentiment analysis [23] and text classification [27]. Our work started the investigation of leveraging knowledge from other media for spammer detection in microblogging. Different from traditional methods, based on the quantitatively linguistic variation analysis, our proposed framework naturally combines knowledge learned from internal and external data sources in a unified model. In addition, some work has been done to study the linguistic challenges of social media texts. It is accepted that texts in social media are noisy, but it is also reported by researchers that the texts are not as noisy as what people expected [2]. The language used in Twitter is more like a projection of the language of formal media like news and blogs with shorter form [21], and it is possible to make use of normalization and domain adaption to ""clean"" it [11]. The evidence provided by linguists also motivate us to explore the language differences of spams across different media, and make use of resources from other media to help spammer detection in microblogging.",null,null
574,555,null,null
575,7. CONCLUSIONS AND FUTURE WORK,null,null
576,"Texts in microblogging are short, noisy, and labeling processing is time-consuming and labor-intensive, which presents great challenges for spammer detection. In this paper, we first conduct a quantitative analysis to study how noisy the microblogging texts are by comparing them with spam messages from other media. The results suggest that microblogging data is not significantly different from data from the other media. Based on the observations, a matrix factorization model is employed to learn lexicon information from external spam resources. By incorporating external information from other media and content information from microblogging, we propose a novel framework for spammer detection. The experimental results demonstrate the effectiveness of our proposed model as well as the roles of different types of information in spammer detection.",null,null
577,This work suggests some interesting future directions. Different types of medium resources have different effects on the spammer detection performance. It would be interesting to quantify the contributions of different types of sources to spammer detection in microblogging. This could be an important support for source selection in spammer detection.,null,null
578,Acknowledgments,null,null
579,"We truly thank the anonymous reviewers for their pertinent comments. This work is, in part, supported by ONR (N000141410095) and ARO (#025071).",null,null
580,8. REFERENCES,null,null
581,"[1] T. A. Almeida, J. M. G. Hidalgo, and A. Yamakami. Contributions to the study of sms spam filtering: new collection and results. In Proceedings of DocEng, 2011.",null,null
582,"[2] T. Baldwin, P. Cook, M. Lui, A. MacKinlay, and L. Wang. How noisy social media text, how diffrnt social media sources? In Proceedings of IJCNLP, 2013.",null,null
583,"[3] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All your contacts are belong to us: automated identity theft attacks on social networks. In WWW, 2009.",null,null
584,"[4] E. Blanzieri and A. Bryl. A survey of learning-based techniques of email spam filtering. Artificial Intelligence Review, 29(1):63­92, 2008.",null,null
585,"[5] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. The socialbot network: when bots socialize for fame and money. In ACSAC, 2011.",null,null
586,"[6] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.",null,null
587,"[7] H. M. Breland. Word frequency and word difficulty: A comparison of counts in four corpora. PSS, 1996.",null,null
588,"[8] F. Chung. Spectral graph theory. Number 92. Amer Mathematical Society, 1997.",null,null
589,"[9] C. Ding, T. Li, and M. Jordan. Convex and semi-nonnegative matrix factorizations. TPAMI, 2010.",null,null
590,"[10] T. Egener, J. Granado, and M. Guitton. High frequency of phenotypic deviations in physcomitrella patens plants transformed with a gene-disruption library. BMC Plant Biology, 2:6, 2002.",null,null
591,"[11] J. Eisenstein. What to do about bad language on the internet. In Proceedings of NAACL-HLT, 2013.",null,null
592,"[12] J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning, 2008.",null,null
593,"[13] S. Ghosh, B. Viswanath, F. Kooti, N. Sharma, G. Korlam, F. Benevenuto, N. Ganguly, and K. Gummadi. Understanding and combating link farming in the twitter social network. In WWW, 2012.",null,null
594,"[14] J. M. G´omez Hidalgo, G. C. Bringas, E. P. Sa´nz, and F. C. Garc´ia. Content based sms spam filtering. In Proceedings of DocEng, 2006.",null,null
595,[15] M. A. Halliday and C. M. Matthiessen. An introduction to functional grammar. 2004.,null,null
596,"[16] M. Hart. Project gutenberg. Project Gutenberg, 1971. [17] T. Hofmann. Probabilistic latent semantic indexing. In",null,null
597,"Proceedings of SIGIR, 1999. [18] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting",null,null
598,"internal and external semantics for the clustering of short texts using world knowledge. In CIKM, 2009. [19] X. Hu, J. Tang, and H. Liu. Online social spammer detection. In AAAI, 2014. [20] X. Hu, J. Tang, Y. Zhang, and H. Liu. Social spammer detection in microblogging. In IJCAI, 2013. [21] X. Hu, L. Tang, J. Tang, and H. Liu. Exploiting social relations for sentiment analysis in microblogging. In WSDM, 2013. [22] K. Lee, J. Caverlee, and S. Webb. Uncovering social spammers: social honeypots + machine learning. In Proceedings of SIGIR, 2010. [23] T. Li, Y. Zhang, and V. Sindhwani. A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge. In Proceedings of ACL, 2009. [24] Y.-R. Lin, H. Sundaram, Y. Chi, J. Tatemura, and B. L. Tseng. Splog detection using self-similarity analysis on blog temporal dynamics. In AirWeb, 2007. [25] V. Metsis, I. Androutsopoulos, and G. Paliouras. Spam filtering with naive bayes-which naive bayes? In Proceedings of CEAS, 2006. [26] D. O'Callaghan, M. Harrigan, J. Carthy, and P. Cunningham. Network analysis of recurring youtube spam campaigns. In Proceedings of ICWSM, 2012. [27] S. J. Pan and Q. Yang. A survey on transfer learning. TKDE, pages 1345­1359, 2010. [28] D. Seung and L. Lee. Algorithms for non-negative matrix factorization. NIPS, pages 556­562, 2001. [29] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), pages 267­288, 1996. [30] R. Wardhaugh. An introduction to sociolinguistics, volume 28. Wiley. com, 2011. [31] S. Webb, J. Caverlee, and C. Pu. Introducing the webb spam corpus: Using email spam to identify web spam automatically. In CEAS, 2006. [32] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Zhao, and Y. Dai. Uncovering social network sybils in the wild. In Proceedings of IMC, 2011. [33] S. J. Yates. Oral and written linguistic aspects of computer conferencing. Pragmatics and beyond New Series, 1996. [34] Y. Zhu, X. Wang, E. Zhong, N. Liu, H. Li, and Q. Yang. Discovering spammers in social networks. In Proceedings of AAAI, 2012.",null,null
599,556,null,null
600,,null,null
