,sentence,label,data
0,How Do Users Respond to Voice Input Errors?,null,null
1,Lexical and Phonetic Query Reformulation in Voice Search,null,null
2,Jiepu Jiang,null,null
3,"School of Information Sciences, University of Pittsburgh",null,null
4,jiepu.jiang@gmail.com,null,null
5,Wei Jeng,null,null
6,"School of Information Sciences, University of Pittsburgh",null,null
7,wej9@pitt.edu,null,null
8,Daqing He,null,null
9,"School of Information Sciences, University of Pittsburgh",null,null
10,dah44@pitt.edu,null,null
11,ABSTRACT,null,null
12,"Voice search offers users with a new search experience: instead of typing, users can vocalize their search queries. However, due to voice input errors (such as speech recognition errors and improper system interruptions), users need to frequently reformulate queries to handle the incorrectly recognized queries. We conducted user experiments with native English speakers on their query reformulation behaviors in voice search and found that users often reformulate queries with both lexical and phonetic changes to previous queries. In this paper, we first characterize and analyze typical voice input errors in voice search and users' corresponding reformulation strategies. Then, we evaluate the impacts of typical voice input errors on users' search progress and the effectiveness of different reformulation strategies on handling these errors. This study provides a clearer picture on how to further improve current voice search systems.",null,null
13,Categories and Subject Descriptors,null,null
14,"H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval ­ query formulation, relevance feedback.",null,null
15,General Terms,null,null
16,"Measurement, Experimentation, Human Factors.",null,null
17,Keywords,null,null
18,Query reformulation; voice search; voice input errors.,null,null
19,1. INTRODUCTION,null,null
20,"Supporting query reformulation has long been recognized as an important strategy to help users further their search progress [3]. Users may need to reformulate queries several times until their information needs are fully satisfied. The need for reformulation may be attached to the users themselves. As users may have limited understanding of their information needs, the retrieval system and the collection, it is difficult for them to develop one single query to complete the search. At the same time, the need for reformulation may come from search problems being explorative where relevant documents may be scattered among different subtopics, so that it is impossible to retrieve all relevant documents with a single query. Therefore, many studies [7, 22] concentrated on supporting reformulation of textual queries.",null,null
21,"Along with the rapidly increasing usage of mobile devices and the improvement of speech processing, voice search becomes an",null,null
22,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'13, July 28­August 1, 2013, Dublin, Ireland. Copyright © 2013 ACM 978-1-4503-2034-4/13/07...$15.00.",null,null
23,"alternative search mode. During voice search, users can vocalize their queries and the retrieval system utilizes the voice recognition results for retrieval [6, 19]. Though previous studies found that query reformulation plays an important role in conventional textual search systems, to the best of our knowledge, there are very limited studies on voice search, especially concerning users' query reformulation in voice search.",null,null
24,"In this paper, we therefore focus on explaining query reformulation behaviors in the context of voice search. The term voice query1 refers to the query in voice search. It contains not only the lexical contents, but also the phonetic characteristics such as the speaker's stress, speed, and intonation. In comparison, we refer to those searches in which users need to type queries on a keyboard as conventional searches.",null,null
25,"We mainly concentrate on three research objectives in this study. First, voice search relies on users' vocalization of queries and systems' automatic speech recognition to transcribe voice queries, which may result in various voice input errors. Voice input errors include not only the errors from automatic speech recognition but also the system's interruptions during users' vocalization of queries. Therefore, our first objective is to characterize the types of voice input errors in voice search and evaluate their impacts on voice search.",null,null
26,"Second, upon recognition of voice input errors, users will take actions in their subsequent query reformulation to overcome the errors. As voice queries involve both lexical and phonetic characteristics, users' reformulation choices and preferences would also be different from those in conventional searches. Therefore, our second objective is to identify and characterize users' query reformulation patterns in voice search.",null,null
27,"Third, as the ultimate goal of this study is to shed light on how to support query reformulation in voice search, it is important to analyze users' preferences of using different reformulation patterns and examine the effectiveness of the reformulation patterns in handling voice input errors. In this study, we evaluate the effectiveness of the reformulation patterns by how they overcome the voice input errors and improve the retrieval performance.",null,null
28,"To meet our research objectives, we conducted a series of voice search experiments involving native English speakers working on TREC search topics using the Google voice search app on the iPad. The participants were only permitted to speak voice queries to initiate searches and reformulate queries. Within a certain time limit, the participants could freely issue multiple voice queries, read or click on returned search results, and use Google's query suggestions. Users' voice queries, the system's transcription",null,null
29,"1 In this paper, we use voice queries to refer to spoken queries and speech queries, which were used in previous studies [5]. Our rationale is to keep a consistency with Google Voice Search, the platform used in our experiment.",null,null
30,143,null,null
31,"results to the voice queries, and the clicked documents were all recorded for analysis.",null,null
32,"The rest of the paper is organized as follows: Section 2 reviews related studies in query reformulation and voice-based search; Section 3 introduces our methods for experimentation and analysis; in Section 4, we characterize voice query input errors and voice query reformulation patterns; Section 5 evaluates the impacts of voice input errors on voice search; Section 6 evaluates the effectiveness of each type of voice query reformulation; finally, we discuss suggestions for future development of voicebased search systems and outline our conclusions.",null,null
33,2. RELATED WORKS,null,null
34,2.1 Voice Search,null,null
35,"Voice search [8, 23] or voice-enabled search [2, 20] refer to the search systems that allow users to input search queries in a spoken language and then retrieve the relevant entries based on systemgenerated transcriptions of the voice queries. Currently, voice search is commonly applied via mobile devices. Researchers examined the scenario of using voice search compared with traditional desktop search. For example, Schalkwyk et al. [19] analyzed Google's search logs and found that users utilized Google Voice Search more frequently when they tried to find information such as food and local geographical information (e.g. city names and local restaurants). However, it remains unclear whether the location-related information needs are intrinsically related to voice search, or are due to the fact that the current devices supporting voice search are mostly mobile devices.",null,null
36,"Existing studies on voice search are very limited, especially those related to users' voice queries and query reformulations. Schalkwyk et al. [19] reported statistics of queries from Google Voice's search logs which found that voice queries are statistically shorter than desktop search queries. Crestani et al. [6] conducted a user experiment based on collections of users' voice queries. However, the experiment environment did not involve a real search system. Participants were asked to formulate voice queries without knowing whether their voice queries could be recognized, or if they would retrieve meaningful results. In comparison, in our experiments, participants freely interacted with the voice search systems, so that the participants' interactions, particularly their responses to voice input errors, could be collected and studied.",null,null
37,2.2 Query Reformulation,null,null
38,"The lexical query reformulation patterns we adopted in this paper come from the summarization of many previous studies, including [9­11, 18, 21]. As we did not aim to create a systematic taxonomy of the reformulation patterns in voice search, we simplified the patterns to only four types: addition, substitution, removal, and re-ordering. However, our substitution pattern involved many other patterns defined in previous works, such as stemming [9, 21] and acronyms [9]. Also, many textual reformulation patterns that do not exist in voice search were removed, including: punctuation [21], URL stripping [9], substring [9], spelling correction [1], and capitalization [21].",null,null
39,3. METHODS,null,null
40,3.1 Settings and Experiment System,null,null
41,"As stated, we are interested in users' query reformulation behaviors in voice search, especially how they utilize query reformulations to cope with voice input errors. Admittedly, as currently voice search is mostly used on mobile devices, an ideal experiment setting for our study should simulate mobile search environment, including many issues previously found to have an",null,null
42,"impact on automatic speech recognition (ASR) and voice search, such as the background noise [19]. However, after consideration, we decided to conduct our study in a controlled laboratory experiment setting for the following reason: our focus is on how users change their queries when voice input errors happen in voice search. Therefore, automatic speech recognition (ASR) errors and the often concerned noise and vocabulary issues in ASR [19], though important in voice search, are just part of the problem and have secondary importance in our study.",null,null
43,"Among the state-of-the-art web search engines that support voice search, we adopted the Google search app on the iPad for our experiment because of the popularity of Google in conventional web search. We believed that users with Google search experience could more easily understand its voice search function. In addition, using the iPad for experiment also replicated some form of mobile search environment.",null,null
44,"As our study focus on query reformulation behaviors in voice search, we simply adopted Google voice search as an out-of-box system, despite it is unclear how the voice search system and its ASR were implemented. Although the voice search system and the effectiveness of ASR can influence experiment results, we believe that Google voice search system is probably the best choice for this experiment and the experiment results would be still representative of users in other voice search systems.",null,null
45,"Figure 1 contains screenshots of the system2. As shown in Fig.1 (a), a user can touch the voice search icon to issue voice queries. If the user stops speaking or pauses for a while, the system concludes that the user has completed the voice query. Then it starts the recognition of the voice query and uses the transcribed query to search (see Fig.1 (b)).",null,null
46,"Google voice search system provides different audio cues to indicate its various statuses, which includes: starting or stopping ""listening"" a voice query; displaying the transcribed query; and failing to generate the transcribed query. These audio cues are very useful in our transcriptions of the experiment recordings.",null,null
47,(a),null,null
48,(b),null,null
49,(c),null,null
50,Figure 1. Screenshots of the Google search app on iPad.,null,null
51,3.2 Search Tasks and Topics,null,null
52,"Our experiment setting is similar to the one adopted by the TREC session track [17], in which users can issue multiple queries to work on one search topic.",null,null
53,"Ideally, search topics should be representative of users' information needs in the mobile search environment. However, as discussed in Section 3.1, our experiment setting was not a real mobile environment, therefore we selected conventional TREC ad hoc search topics in our experiments. On the one hand, we could not find many mobile search topics due to limited resources. On the other hand, we also wanted to study the connections between query reformulation in voice search and those in conventional",null,null
54,"2 The screenshots were made in January 2013, 6 months after the experiments. However, the main system features did not change.",null,null
55,144,null,null
56,"textual queries as part of our future study. Therefore, we selected 50 TREC topics for our study, of which 30 are from the TREC robust track in 2004, and 20 are from the TREC web track in 2009 and 2010. The selected topics were representative of informational search problems [4]. Table 1 shows the selected TREC topic numbers.",null,null
57,"Although the literature shows that many searches on mobile devices involve location-related information needs [19], we did not want to restrict our findings by not including other types of information needs. The first reason is that there is no absolute demarcation line between mobile devices and portable computers. The second is that many voice search systems such as Google can be used on laptop and desktop computers.",null,null
58,Table 1. Selected topics for experiments.,null,null
59,Datasets,null,null
60,Robust Track 2004,null,null
61,Selected Topics,null,null
62,"301, 302, 303, 307, 309, 311, 313, 314, 316, 318, 321, 322, 338, 348, 351, 356, 365, 380, 404, 406, 608, 628, 630, 637, 647, 651, 654, 672, 683, 698",null,null
63,"Web Track 51, 52, 54, 56, 68, 70, 72, 73, 74, 91, 94, 100, 2009, 2010 104, 107, 108, 110, 112, 113, 122, 141",null,null
64,3.3 Experiment Procedure,null,null
65,"We recruited 20 participants (14 females and 6 males). The majority of them were college students (13) and graduate students (3). All 20 participants were native English speakers, and their average age is 23.7 with standard deviation being 4.72.",null,null
66,"Each participant was compensated financially for their involvement in the experiment, which lasted for about 1.5 hours. At the beginning of the experiment, each participant was trained to work on one TREC topic (other than the 50 topics in table 1) to make sure that they knew how to use the voice search system, and were clear about what operations they were allowed to do during the experiments.",null,null
67,"They then each worked on 25 of the 50 topics listed in Table 1. We alternated the topic assignments to reduce learning and fatigue bias. For each topic, the participant first read the topic description on a computer screen and then worked on each topic using the Google voice search app on iPad for 2 minutes. The participant could only vocalize queries, browse and click the search results, and use Google's query suggestions. The participant was not allowed to type queries on the iPad touch screen. After each topic, the participants were asked to answer a short questionnaire regarding their perceptions of topic difficulty and familiarity.",null,null
68,"The experiment paused for a 5-minute break after the participant finished 15 topics. When all 25 topics were completed, each participant was interviewed for about 10 minutes on his/her perceptions of the voice search and query reformulation. The whole experimental process was recorded for later transcription and analysis of users' voice queries and interviews.",null,null
69,3.4 Data,null,null
70,Two coders manually transcribed the voice queries and agreed on 100% of the transcribed texts except for the use of plurals and prepositions (which are difficult to identify and usually do not affect search results after stemming and stopword removal).,null,null
71,"Google's search history automatically records the system's transcribed queries and the users' click-through pages. For each participant, we created a Google user account and recorded the user's search history during the experiments.",null,null
72,Each participant went through a semi-structured interview at the end of the experiments on their opinions of using voice search systems and especially on how they constructed and reformulated voice queries. Some of the interview questions were based on our own experience of using voice search and a pilot study. As the,null,null
73,"study was highly exploratory, we also developed new interview questions for the experiments. We hired a professional transcription company to transcribe the interview texts.",null,null
74,"The experiment was conducted in July 2012. In total, we collected 1,650 voice queries and 32 cases of using query suggestions. On average, each subject issued 3.30 voice queries per topic (SD,""2.50). Among the 1,650 voice queries, 742 were correctly recognized. Voice input error happened in 908 voice queries, of which 810 were caused by speech recognition error and 98 by system interruption. We also found 42 voice queries for which the system could not provide any transcription results. For these queries, we simply counted their transcribed queries as empty strings and their search results as empty lists. These voice queries and query suggestions provided us with 1,182 query reformulation pairs. The average number of results clicked by a user throughout the session of a search topic were 1.41 (SD"",""1.14). On average, for each topic, 9.76 unique clicked results were aggregated as qrels (SD"",3.11).",null,null
75,3.5 Search Effectiveness Evaluation,null,null
76,"For each topic, we assume that a set of topic-level relevant results can be collected to evaluate each query in the search sessions dealing with that topic. Such evaluation method was widely adopted in multi-query search session evaluation, e.g. [12­ 14, 16]. Due to the time limitation of the experiments, we did not ask the participants to make relevance judgments, but relied on the clicked results as relevant documents for evaluation. Similar methods were widely adopted in web search [15].",null,null
77,"Due to the voice input errors, sometimes a participant will not be able to find any meaningful results within the 2-minute session. Thus, for each topic, we aggregated the results clicked by any of the participants when they were working on that topic. Each clicked result was assigned a relevance score of 1 for that topic. Other results were considered non-relevant (relevance score is 0). On such a basis, we can calculate standard evaluation metrics such as nDCG of the queries.",null,null
78,"Note that this method will be biased toward the transcribed queries in evaluation, because only those results retrieved by the transcribed queries have the chance to being clicked upon (i.e. some of the voice queries' results were not clicked upon because they were never shown to the participants). Thus, the evaluated effectiveness of the voice queries may be underestimated. However, this problem does not affect the validity of our study. As will be shown in Section 6, even if they are underestimated, voice queries still outperform their corresponding transcribed queries in nearly all the cases.",null,null
79,"Google search history only records clicked results of queries. Thus, we crawled the first page of Google results for each of the voice queries and system transcribed queries. These results were accessed 5 months after our experiments. Although these results may be somewhat different from those at the time we conducted the experiments, we assume they do not influence the comparison between queries.",null,null
80,4. VOICE INPUT ERRORS AND REFORMULATION PATTERNS,null,null
81,4.1 Voice Input Error Identification,null,null
82,"In voice search, a user speaks a voice query (qv), and the search system generates the transcription of qv for search, which is referred to as the transcribed query (qtr). We say a voice input error occurs when the actual content of a voice query qv differs from its transcribed query qtr. Let {qv(1), ... , qv(n)} be n voice queries, and {qtr(1), ... , qtr(n)} be the corresponding n transcribed",null,null
83,145,null,null
84,queries. The transition from qv(i) to qv(i+1) is referred to as a voice query reformulation.,null,null
85,"Through comparison of manually transcribed voice queries with system transcribed voice queries, we can obtain recognition errors, which include:",null,null
86,"Missing words: words in qv that do not appear in qtr. Incorrect words: words in qtr that do not appear in qv. When identifying recognition errors in this experiment, we did not consider the word differences caused by letter case (e.g. ""United States"" and ""united states"" are considered as equivalent) and plurals (e.g. ""neil young tickets"" is considered as equivalent to ""neil young ticket""). The reason for this is that these types of errors do not have a significant impact on search results. In addition to the system's speech recognition errors, voice input errors can also be caused by the system's interruption of the participants' voice inputs. While vocalizing a query, if the participant pauses for a certain amount of time, the system will ""think"" that the participant has completed the query. So the system will stop listening to the participant's voice input and directly transcribe the unfinished voice query for search. This type of error can be reliably identified by listening to the recording. The participant would pause and then start to talk again but the system had already issued the audio cue for stopping listening. Therefore, we manually annotated each voice query with one of the following four categories, two of which indicate the voice input error type: Speech Recognition Error: the participant completed a query without any interruption, but the voice query was not recognized correctly. This error can be characterized by missing words or/and incorrect words as mentioned earlier. System Interruption: the participant was improperly interrupted by the system and failed to speak all of the query words. No Error: no voice input error. Query Suggestion: the participant used a Google's query suggestion. If the search history recorded that the participant searched for a query while we did not hear it in the recording, we consider that to be a case of using Google's query suggestion. During the annotation of voice input errors, the two coders agreed on 100% of the voice queries' category types. Because the participants usually stopped speaking when system interruption happened, we cannot determine the unspoken contents of the queries (i.e. for queries with system interruption, we can only have information on qtr but not qv). Thus, in much of the later analysis that requires the information on qv, we mainly focus on queries without voice input errors and those with speech recognition errors.",null,null
87,4.2 Voice Query Reformulation Patterns,null,null
88,"As voice queries have both lexical and phonetic characteristics, voice query reformulation can incorporate not only textual changes to the query but also phonetic changes. Thus, voice query reformulation can have lexical query reformulation, phonetic query reformulation or both. In the remainder of this section, we will discuss the patterns of voice query reformulation, which were summarized from previous works [9] and our observations on the experiment's results.",null,null
89,4.2.1 Lexical Query Reformulation,null,null
90,"Expanded from previous studies [9], we characterized lexical query reformulation into addition, substitution, removal, and reordering of words, or the combination of these patterns. Although these patterns also exist in conventional search, users may utilize them for different reasons in voice search.",null,null
91,Addition (ADD): adding new words to the query. We refer to the newly-added words as ADD words. For example:,null,null
92,Voice Query,null,null
93,Transcribed Query ADD words,null,null
94,q1 the sun,null,null
95,the son,null,null
96,q2 the sun solar system the sun solar system solar system,null,null
97,"Substitution (SUB): replacing words with semantically-related words. In voice search, we noticed that users may substitute the words that were incorrectly recognized with other words of similar meanings. We refer to the words being replaced and the new words as SUB words. For example:",null,null
98,Voice Query Transcribed Query SUB words,null,null
99,q1 art theft,null,null
100,test,null,null
101,q2 art embezzlement are in Dublin,null,null
102,q3 stolen artwork stolen artwork,null,null
103,theftembezzlement embezzlementstolen artartwork,null,null
104,"Different from the substitution pattern in [9], we also count ""acronym"", ""abbreviation"", and ""word stemming"" in [9] as word substitution patterns, for example:",null,null
105,avp  association of volleyball professionals united states  us ireland peace talk interruption  ireland peace talk interrupted,null,null
106,"Removal (RMV): removing words from the query. In voice search, we noticed that the participant may remove a part of a voice query, if the part was not correctly recognized and was not essential to the search topic. The words being removed are referred to as RMV words. For example:",null,null
107,Voice Query,null,null
108,Transcribed Query RMV words,null,null
109,q1 advantages of same sex schools andy just open it goes,null,null
110,q2 same sex schools,null,null
111,same sex schools,null,null
112,advantages of,null,null
113,"Re-ordering (ORD): changing the order of the words in a query. The words being re-ordered are referred to as ORD words. In voice search, we noticed that the words being re-ordered are usually those wrongly recognized. For example:",null,null
114,Voice Query,null,null
115,Transcribed Query,null,null
116,q1 interruptions to ireland peace talk is directions to ireland peace talks q2 ireland peace talk interruptions ireland peace talks interruptions,null,null
117,4.2.2 Phonetic Query Reformulation,null,null
118,Phonetic query reformulation is unique in voice search. During,null,null
119,"our transcription of experiment recordings, we found the",null,null
120,following human recognizable phonetic query reformulation,null,null
121,patterns:,null,null
122,Partial Emphasis (PE). Partial emphasis refers to the behavior,null,null
123,of phonetically emphasizing a part of the current query that also,null,null
124,"appeared in the previous query. Typically, the users can put stress",null,null
125,"(STR) on certain words, or slow down (SLW) at these words, or",null,null
126,use both. Sometimes the users may only emphasize a vowel or,null,null
127,consonant in the word. We also noticed other ways of,null,null
128,"emphasizing words when speaking voice queries. For example,",null,null
129,"some users spell out each letter in the word (SPL), or try different",null,null
130,pronunciations (DIF) for some non-English words (e.g. Puerto,null,null
131,"Rico). Overall, STR and SLW are the two primary patterns of",null,null
132,"partial emphasis, whereas SPL and DIF occurred rarely in our",null,null
133,experiments. The recurring words being emphasized during,null,null
134,speaking are referred to as PE words. We use the following,null,null
135,methods to represent the PE methods:,null,null
136,PE STR SLW SPL,null,null
137,DIF,null,null
138,Example,null,null
139,rap and crime rap and c-r-i-m-e P·u·e·r·t·o Rico PuertoRico,null,null
140,"Explanation put stress on ""rap"" slow down at ""crime"" spell out each letter in ""Puerto""",null,null
141,"pronounce ""Puerto"" differently",null,null
142,"In voice search, we notice that the part of the query being emphasized is usually that part being incorrectly recognized in previous searches. For example:",null,null
143,146,null,null
144,Voice Query,null,null
145,Transcribed Query PE words,null,null
146,q1 rap and crime,null,null
147,rap and crying,null,null
148,q2 rap and c-r-i-m-e,null,null
149,rob and crime,null,null
150,q3 rap music influence rap music influence,null,null
151,crime rap,null,null
152,"Whole Emphasis (WE). Whole emphasis is to place emphasis on every part of the query, usually by putting stress or slow down on each of the words. It usually happens when the majority of the previous query was wrongly recognized. For example:",null,null
153,Voice Query,null,null
154,Transcribed Query,null,null
155,q1 art embezzlement,null,null
156,are in dublin,null,null
157,q2 a-r-t e-m-b-e-z-z-l-e-m-e-n-t art embezzlement,null,null
158,We did not find other meaningful phonetic reformulation patterns other than PE and WE in our transcription.,null,null
159,4.2.3 Recognition of Query Reformulation Types,null,null
160,"We recognize lexical query reformulation types by automatic and manual methods. Let q1q2 be a lexical query reformulation, then the procedures of recognizing the patterns are:",null,null
161,"Step 1: automatically check whether all words in q1 also appear in q2. If yes, any extra words in q2 are recognized as ADD words, and q2 is an ADD of q1. Similarly, if all q2's words are in q1, any extra words in q1 are recognized as RMV words, and q2 is an RMV of q1.",null,null
162,"Step 2: For the rest of the query pairs, check manually whether q2 contains SUB words of q1. The two coders agreed on 93.9% of the cases at the beginning, and finally came to agreements on the remaining 6.1% after further discussion.",null,null
163,"Step 3: Compared with q1, if some newly appeared words in q2 are not recognized as SUB words, we mark them as ADD words and q2 as an ADD of q1. Similarly, if q2 removed some words in q1 and the removed words are not substituted by other words, we mark them as RMV words and q2 as an RMV of q1.",null,null
164,"Step 4: Finally, if two words appeared in both q1 and q2, and their sequence was changed, we mark q2 as an ORD of q1.",null,null
165,"Note that ADD, RMV, SUB, and ORD are not exclusive of each other. For example:",null,null
166,Reformulation,null,null
167,Reformulation Type & Words,null,null
168,q1: information retrieval system q2: search system development,null,null
169,ADD: development SUB: retrieval  search RMV: information,null,null
170,"The phonetic query reformulation types and the PE words were manually recognized. In transcribing the recordings, we found that STR and SLW almost always happened together. Thus, we mark STR and SLW as one type ""STR/SLW"". Finally, we come to four exclusive phonetic reformulation patterns: STR/SLW, SPL, DIF, and WE. The two coders agreed on 87.6% of the cases at the beginning, and finally came to agreement on the remaining 12.4% after further discussion.",null,null
171,5. INFLUENCE OF VOICE INPUT ERROR,null,null
172,5.1 Voice Input Errors in Individual Queries,null,null
173,RQ1: How do speech recognition errors affect voice queries?,null,null
174,"Speech recognition error is the major type of voice input error. It occurred in 810 voice queries (89.2% of all 908 queries with voice input errors in our study). We found that speech recognition error can greatly change the content and results of voice query, most likely hurting the performance of voice search.",null,null
175,"At the word level, we calculated the average percentage of missing words in voice queries and the average percentage of incorrect words in transcribed queries. As shown in Table 2, when speech recognition error occurred, about half of the words (49.7%) in voice queries were missing in the transcribed queries. Similarly,",null,null
176,about half of the words (49.3%) in transcribed queries were incorrect transcriptions. On average there were 1.77 missing words and 1.84 incorrect words per query.,null,null
177,"Such high proportions of missing words and incorrect words greatly affected the results of voice search. For each of the 810 voice queries with speech recognition errors, we calculated the Jaccard similarity of Google's first pages of results between voice query and transcribed query (i.e. Jaccard(qv, qtr) in Table 2). As shown in Table 2, the average Jaccard similarity was only 0.118, indicating very low overlap between those retrieved by the transcribed queries and those that should have been retrieved by the voice queries' true content. Figure 2(a) further illustrated the low overlap by showing the distribution of Jaccard similarity, which indicated that, for 69% (556 out of 810) of voice queries with speech recognition errors, the search results will be totally different from users' expectations (i.e. Jaccard similarity is 0).",null,null
178,"Table 2. Comparison of voice queries that contained no errors, speech recognition errors, or system interruptions.",null,null
179,No Errors 742 Queries,null,null
180,Speech Recognition System,null,null
181,Errors,null,null
182,Interruptions,null,null
183,810 Queries,null,null
184,98 Queries,null,null
185,mean SD mean,null,null
186,SD,null,null
187,nDCG@10 of qv 0.275 0.20 0.264,null,null
188,0.22,null,null
189,nDCG@10 of qtr 0.275 0.20 0.083* 0.16,null,null
190,Length of qv 3.82 1.68 4.14*,null,null
191,1.99,null,null
192,Length of qtr 3.82 1.68 4.21*,null,null
193,2.31,null,null
194,# missing words -,null,null
195,- 1.77,null,null
196,1.09,null,null
197,# incorrect words -,null,null
198,- 1.84,null,null
199,1.44,null,null
200,% missing words -,null,null
201,- 49.7% 29%,null,null
202,% incorrect words -,null,null
203,- 49.3% 31%,null,null
204,"Jaccard(qv, qtr) -",null,null
205,- 0.118,null,null
206,0.27,null,null
207,nDCG@10 -,null,null
208,- -0.182 0.23,null,null
209,mean SD,null,null
210,-,null,null
211,-,null,null
212,0.061 0.14,null,null
213,-,null,null
214,-,null,null
215,2.34 1.41,null,null
216,-,null,null
217,-,null,null
218,-,null,null
219,-,null,null
220,-,null,null
221,-,null,null
222,-,null,null
223,-,null,null
224,-,null,null
225,-,null,null
226,-,null,null
227,-,null,null
228,*: the difference between queries with no errors and recognition errors is significant at 0.01 level according to Welch t-test; : the difference,null,null
229,between queries with no errors and system interruptions is significant at 0.01 level according to Welch t-test; : the difference between qv and qtr under the same error conditions is significant at 0.01 level according to,null,null
230,paired t-test.,null,null
231,1.0 Jaccard 0.8,null,null
232,0.6 nDCG @10,null,null
233,0.4,null,null
234,0.2 0.6,null,null
235,0.0,null,null
236,0.4,null,null
237,1 101 201 301 401 501 601 701 801,null,null
238,-0.2,null,null
239,# of queries,null,null
240,0.2,null,null
241,-0.4,null,null
242,0.0,null,null
243,-0.6,null,null
244,1 101 201 301 401 501 601 701 801,null,null
245,# of queries -0.8,null,null
246,(a),null,null
247,(b),null,null
248,Figure 2. Jaccard similarity and nDCG@10 of the top 10 results of qv and qtr for 810 queries with recognition errors.,null,null
249,"In addition, speech recognition errors hurt the performance of voice search significantly. As shown in Table 2, the average nDCG@10 of the 810 voice queries with speech recognition errors was 0.084. However, if all the speech recognition errors were corrected, the average nDCG@10 could be significantly improved to as high as 0.264, comparable to the average nDCG@10 of voice queries with no voice input errors (0.275).",null,null
250,"Figure 2(b) further shows the distribution of nDCG@10 for the 810 queries (i.e. the difference of nDCG@10 between the transcribed query and the voice query). For 500 queries (62% of the 810), nDCG@10 declined. The remaining 310 queries, whose search performance was not hurt, were intrinsically inefficient queries. Even inputted correctly, these queries could only have an average nDCG@10 value of 0.117, which is significantly less than other queries. Therefore, these queries' performance was not",null,null
251,147,null,null
252,hurt probably because there was not much room to degrade their search performance.,null,null
253,RQ2: How do system interruptions affect voice queries?,null,null
254,"System interruptions occurred in 98 queries (10.8% of all 908 queries with voice input errors), which also greatly altered the content of queries and hurt the performance of voice search. When system interruption occurred, it was impossible to determine the real content of the voice queries. Therefore, we calculated statistics only for the transcribed queries.",null,null
255,"Compared with the 742 correctly recognized voice queries, the 98 queries with system interruptions performed significantly worse (0.061 vs. 0.275 in average nDCG@10). When system interruption occurred, the transcribed queries were also significantly shorter than those of the correctly recognized queries (2.34 vs. 3.82 words), probably because the users were interrupted improperly and were not able to vocalize the entire query words.",null,null
256,RQ3: When do speech recognition errors happen?,null,null
257,"We found that query length may be one factor related to speech recognition errors. As shown in Table 2, queries with speech recognition errors were significantly longer than those correctly recognized queries (4.14 vs. 3.82 words). On the one hand, this is not surprising: as recognition error may happen in any word of a voice query, the more words spoken, the more likely an error happens. On the other hand, the longer the query, the richer the context it provides, which may help the speech recognition. Therefore, further study is needed on whether or not query length can affect speech recognition errors.",null,null
258,"We also explored the relationship between speech recognition errors and certain types of words. We calculated recognition error rates for the words used by the participants, which is defined as the number of times a word was not recognized correctly divided by the total number of times the word was used in voice queries. We only calculated error rates for words being used at least 10 times. Table 3 shows the categorization of the 20 words with the highest recognition error rate.",null,null
259,"The first recognizable category of words with high recognition error rates are acronyms, such as ""ER"" (emergency room, a TV show), ""AVP"" (the Association of Volleyball Professionals), US and USA. One can hardly expect the system to recognize certain obscure acronyms, such as ""ER"" and ""AVP"".",null,null
260,"Our interviews showed that more than half of the participants (N,""14) reported their concerns about the use of acronyms. When the acronyms were not recognized, they tended to reformulate queries using the full words. For example, participant S14 said that """"I was a little concerned ... Like how I said AVP, and it pops up APP, which would be a totally different topic. I was a little worried about that ... Once I realized what AVP was, I tried to use association, the full name. [sic]"""". Participant S20 said that """"When I did the NRA, instead of giving me a single letter, N-R-A, it spelled out `in' like that. Then I just switched over to actually saying the National Rifle Association because that was quicker.""""""",null,null
261,"Acronyms, named entities and non-English words comprise half of the top 20 words with the highest error rates. Examples of the uncategorized words are also listed in Table 3 as ""other words"".",null,null
262,5.2 Voice Input Errors in Search Sessions,null,null
263,RQ4: How do voice input errors influence search sessions?,null,null
264,"We collected 500 search sessions (20 participants with each working on 25 topics). We divided the 500 sessions into two groups by whether or not voice input errors occurred in the session. As shown in table 4, voice input errors occurred in 187 sessions.",null,null
265,Table 3. Categorization of 20 words with the highest recognition error rates.,null,null
266,Type Acronym Named Entity,null,null
267,Non-English Other words,null,null
268,Examples (# NOT recognized correctly / # used),null,null
269,"ER(29/29), AVP(11/11), US(57/61), USA(6/11)",null,null
270,"Owen(25/26), Culpeper(18/27), Ralph(22/36), Gulf(13/24), Falkland(14/27)",null,null
271,Nino(31/46),null,null
272,"theft(14/14), achievement(10/10), taxing(18/21), fraud(12/14), violence(19/27), talk(9/15), sun(24/41), aspirin(23/43), embezzlement(9/18), maglev(8/16)",null,null
273,Table 4. Comparison of session-level statistics between sessions with and without voice input errors.,null,null
274,187 Sessions 313 Sessions,null,null
275,w/o Voice,null,null
276,w/ Voice,null,null
277,Input Errors Input Errors,null,null
278,mean SD mean SD,null,null
279,# voice queries,null,null
280,1.44 0.82 4.41* 2.51,null,null
281,# unique voice queries,null,null
282,1.44 0.82 3.30* 1.87,null,null
283,# queries w/o voice input errors # queries w/ recognition errors,null,null
284,1.44 0.82 1.51 1.36,null,null
285,0,null,null
286,0,null,null
287,2.59* 2.14,null,null
288,# queries w/ system interruptions # unique results by qv # unique results by qtr,null,null
289,# unique relevant results by qv # unique relevant results by qtr # clicked results in the session,null,null
290,0 13.38 13.38 2.90 2.90 1.39,null,null
291,0,null,null
292,0.31* 0.65,null,null
293,6.66 26.69* 13.90,null,null
294,6.66 37.95* 21.00,null,null
295,1.56 3.04 1.59,null,null
296,1.56 2.78 1.71,null,null
297,1.01 1.34 1.23,null,null
298,% sessions user clicked results 84.49% - 69.97% -,null,null
299,% sessions qtr found relevant results 95.72% - 92.01% -,null,null
300,*: the difference between sessions w/ and w/o voice input errors is,null,null
301,significant at 0.01 level according to Welch t-test;  and : the difference,null,null
302,between qv and qtr is significant at 0.01 level according to paired t-test.,null,null
303,"We found that, within the same period of time (a 2-minute search session), the participants issued significantly more voice queries when voice input errors occurred in the search session. As shown in Table 4, the average number of voice queries in sessions with errors was 4.41 and 1.44 without errors (the difference is significant). When voice input errors occurred in the search session, on average 1.11 queries in the session were repeating previously used queries, whereas when no errors occurred, users seldom repeated used queries. After removing the repeated queries, the participants still issued significantly more unique voice queries when voice input error occurred (3.30 vs. 1.44).",null,null
304,"One consequence of the increased number of voice queries in sessions with voice input errors was that the participants had to spend more efforts to browse and examine the extra returned results. As showed in Table 4, the unique number of results returned by the transcribed queries in sessions with voice input errors was significantly higher than that of those without voice input errors. Although some of the participants could immediately reformulate the voice query without looking at any results, the increased number of returned results at least would not reduce the participants' search efforts.",null,null
305,"We further looked into retrieval effectiveness of search sessions. In sessions with voice input errors, although more results were returned within a session, on average less unique relevant results were actually found. In the 313 sessions with voice input errors, on average the transcribed queries returned only 2.78 unique relevant results within a session. Whereas, if no voice input errors occurred, those sessions' voice queries should result in on average 3.04 relevant results (the difference is significant). Compared with the 313 sessions with voice input errors, the transcribed queries also returned more relevant results in the 187 sessions without any voice input error (2.90 vs. 2.78) and triggered more clicks (1.39 vs. 1.34), but the differences are not statistically significant.",null,null
306,148,null,null
307,"Voice input error also has a higher likelihood of causing a failed search session, in which no relevant result were found. On average, 95.72% of the sessions without voice input errors returned at least one relevant result and in 84.49% of the sessions the participants clicked at least one result. In comparison, when voice input error occurred, only 92.01% of the sessions returned at least one relevant result and in 69.97% of the sessions the participants clicked at least one result.",null,null
308,"In addition, voice input errors can also affect the participants' affective feelings. In our interviews, 90% of our participants reported frustration with their search experience when voice input",null,null
309,"error occurred. For example, participant S15 reported: ""It's frustrating! I know I'm saying the word right and I know what I'm looking for, but it's just not connecting, and that disconnection is like arrgh! ... (hope I can) just type it. [sic]"".",null,null
310,"To summarize, our results demonstrated that voice input errors significantly affected the performance of voice queries, and consequently made the whole search process more difficult and less effective. In response, users utilized both lexical and phonetic reformulations to handle the errors, which will be analyzed in the next section.",null,null
311,Table 5. Change in nDCG@10 after query reformulation.,null,null
312,qv(2),null,null
313,No Error,null,null
314,Recognition Error,null,null
315,System Interruption,null,null
316,Query Suggestion,null,null
317,All,null,null
318,nDCG@10,null,null
319,nDCG@10,null,null
320,nDCG@10,null,null
321,nDCG@10,null,null
322,nDCG@10,null,null
323,No Error,null,null
324,qv,null,null
325,0.266  0.218  0.255  0.204,null,null
326,-,null,null
327,-,null,null
328,-,null,null
329,qtr,null,null
330,0.266  0.218  0.255  0.095  0.256  0.059  0.290  0.244,null,null
331,0.262  0.164 ,null,null
332,# cases,null,null
333,209,null,null
334,143,null,null
335,27,null,null
336,15,null,null
337,394,null,null
338,qv(1),null,null
339,Recognition Error,null,null
340,System,null,null
341,qv qtr Frequency,null,null
342,qtr,null,null
343,0.248  0.248 0.053  0.248 ,null,null
344,231,null,null
345,0.071  0.237 ,null,null
346,Interruption Frequency,null,null
347,30,null,null
348,0.261  0.267 0.058  0.074,null,null
349,392,null,null
350,0.038  0.085 56,null,null
351,0.096  0.062,null,null
352,44,null,null
353,0.134  0.012 7,null,null
354,0.099  0.226,null,null
355,14,null,null
356,0,null,null
357,0.059  0.135 ,null,null
358,681,null,null
359,0.056  0.128  93,null,null
360,Query,null,null
361,qtr,null,null
362,0.299  0.100,null,null
363,Suggestion Frequency,null,null
364,4,null,null
365,0.189  0.020 6,null,null
366,0.235  0.000 1,null,null
367,0.233  0.110 3,null,null
368,0.233  0.061  14,null,null
369,All,null,null
370,qtr,null,null
371,0.150  0.233 ,null,null
372,Frequency,null,null
373,474,null,null
374,0.104  0.079  597,null,null
375,0.156  0.056 79,null,null
376,0.201  0.223  32,null,null
377,"0.129  0.143  1,182",null,null
378," and : the difference between qv(1) and qv(2), or between qtr(1) and qtr(2), is significant at 0.01 level according to paired t-tests.",null,null
379,6. VOICE QUERY REFORMULATION,null,null
380,"In this section, we focus on users' query reformulations. In the following discussion, we use qv(1) and qtr(1), qv(2) and qtr(2) for the voice query and transcribed query both before and after query reformulation, respectively.",null,null
381,6.1 Effectiveness,null,null
382,RQ5: Can users' query reformulations improve search performance of voice queries?,null,null
383,"We found that query reformulation in voice search led to overall improvements in performance, but the magnitude depends on whether voice input errors occurred before or after reformulation.",null,null
384,"Table 5 shows the comparison of search performance before and after query reformulation when different types of voice input errors occurred in qv(1) and qv(2). If counting all 1,182 cases of reformulation, search performance (as measured by nDCG@10) improved significantly from 0.129 to 0.143 (+10.85%) because of query reformulation. However, the improvements mainly occurred in the cases where voice input error occurred in qv(1) and qv(2) was correctly recognized, e.g. ""Recognition Error""  ""No Error"" and ""System interruption""  ""No Error"". If no voice input error occurred in qv(1) or voice input error occurred in qv(2), query reformulation resulted in limited improvements and it sometimes even hindered search performance.",null,null
385,"Since results in Section 5 demonstrated the great influence of voice input errors on search performance, it is not surprising that the effectiveness of query reformulations also largely relied on whether or not voice input errors occurred in qv(2).",null,null
386,RQ6: Can users' query reformulation correct the speech recognition errors in previous queries?,null,null
387,"We found that when recognition error occurred in qv(1), users' query reformulation corrected some of the missing words in qv(1). However, at the same time, new voice input errors could also",null,null
388,"happen in qv(2), which may counteract the corrected errors and",null,null
389,finally lead to degradation in search performance.,null,null
390,Table 6 shows the missing and incorrect words before and after,null,null
391,query reformulation for 681 query reformulation cases in which speech recognition errors occurred in qv(1). We separately,null,null
392,"calculated the statistics by the different types of queries and voice input errors in qv(2). As showed in Table 6, when no voice input error occurred in qv(2) (231 out of 681 cases), it is not surprising",null,null
393,that the number of missing and incorrect words both dropped to 0,null,null
394,"after query reformulation. When speech recognition errors occurred in qv(2) (392 out of 681), the number of missing words",null,null
395,only dropped slightly from 1.89 to 1.74 (the difference is,null,null
396,significant at 0.05 level of significance) and the number of,null,null
397,incorrect words slightly increased (the difference is not,null,null
398,significant).,null,null
399,Does this mean users' query reformulations can only correct,null,null
400,voice input errors when the reformulated queries are correctly,null,null
401,"recognized? On the contrary, in further analysis, we found that even when speech recognition errors occurred again in qv(2), users' query reformulation did correct parts of the errors in qv(1). However, at the same time, new errors also appeared in qv(2).",null,null
402,"To better explain the case, we calculated: the number of missing words in qv(1) that were correctly recognized in qtr(2); the number of missing words in qv(1) that were removed in qv(2); and the number of new missing words in qv(2) (those are missing words in qv(2) but not in qv(1)). As shown in Table 6, when speech recognition error occurred in qv(2), 27.5% (0.52 out of 1.89) of the missing words in qv(1) were corrected after query reformulation",null,null
403,"and 18.0% (0.34 out of 1.89) were simply removed. However, on average, 0.72 new missing words were produced in qv(2), which",null,null
404,"still impeded the performance. When system interruption occurred in qv(2), on average, only",null,null
405,"0.23 missing words in qv(1) were corrected, which is significantly",null,null
406,149,null,null
407,less than the 0.52 missing words corrected in the cases in which speech recognition error occurred in qv(2).,null,null
408,Table 6. Comparison of the missing and incorrect words,null,null
409,before and after query reformulation for the 681 query pairs in which speech recognition error happened in qv(1).,null,null
410,qv(2),null,null
411,# missing words,null,null
412,qv(1)  qv(2),null,null
413,# incorrect words,null,null
414,qtr(1)  qtr(2),null,null
415,# missing,null,null
416,words in qv(1),null,null
417,corrected in qtr(2),null,null
418,# missing,null,null
419,words in qv(1),null,null
420,removed in qv(2),null,null
421,# new,null,null
422,missing,null,null
423,words in qv(2),null,null
424,No Errors 1.75  0.00** 1.81  0.00** 1.13,null,null
425,0.61 0.00,null,null
426,Rec Errors 1.89  1.74* 1.72  1.78,null,null
427,0.52,null,null
428,0.34 0.72,null,null
429,Sys Interrupt 1.71,null,null
430,-,null,null
431,0.23,null,null
432,-,null,null
433,-,null,null
434,Suggestion 1.14,null,null
435,-,null,null
436,0.86,null,null
437,-,null,null
438,-,null,null
439,* and **: the difference of qv(1) and qv(2) is significant at 0.05 and 0.01 level.,null,null
440,Table 7. The frequencies of using reformulation patterns.,null,null
441,qv(1),null,null
442,ADD SUB RMV ORD Lexical,null,null
443,No Errors 90.50 % 15.04 % 66.75 % 33.51 % 99.74 % Rec Errors 32.98 % 16.34 % 37.93 % 43.03 % 77.36 %,null,null
444,Overall 53.82 % 14.87 % 48.37 % 39.58 % 85.47 %,null,null
445,qv(1),null,null
446,STR/ SLW,null,null
447,SPL,null,null
448,DIF,null,null
449,WE Phonetic,null,null
450,No Errors,null,null
451,0 %,null,null
452,0 %,null,null
453,0 % 0.26 % 0.26 %,null,null
454,Rec Errors 14.84 % 0.60 % 0.90 % 9.30 % 25.64 % Overall 9.46 % 0.39 % 0.57 % 6.02 % 16.44 %,null,null
455,6.2 Use of Reformulation Patterns,null,null
456,Lexical & Phonetic,null,null
457,0.26 % 11.99 % 7.74 % Repeat w/o PE or WE,null,null
458,0 %,null,null
459,20.54 % 13.58 %,null,null
460,RQ7: How do users utilize different query reformulate patterns in voice search? Do voice input errors influence the use of query reformulation patterns?,null,null
461,"Table 7 shows the frequency of using different reformulation patterns in voice search. Despite how the query input mechanism changes dramatically in voice search, lexical reformulations were still the primary forms of query reformulation. No matter if speech recognition errors occurred, lexical reformulations were consistently used much more frequently than phonetic reformulations.",null,null
462,"However, speech recognition errors did significantly affect the use of specific lexical query reformulation patterns. When speech recognition errors occurred, the participants tended to reformulate queries using more substitution (SUB) and re-ordering (ORD) patterns but dramatically less addition (ADD) and removal (RMV) patterns. As further examined in RQ8, this is probably because substitution and re-ordering can effectively correct the missing words in previous queries, whereas addition and removal cannot.",null,null
463,"The use of phonetic reformulation patterns is almost always associated with speech recognition errors. As shown in Table 7, when no voice input error occurred in qv(1), only 0.26% of the query reformulations adopted phonetic reformulation patterns. In comparison, 25.64% of the query reformulations adopted phonetic reformulation patterns when speech recognition errors happened in qv(1). In addition to the phonetic reformulation patterns, repeating is also closely connected with speech recognition errors. When speech recognition errors occurred in qv(1), we found that 20.54% of the reformulations were simply repeating qv(1) without any recognizable phonetic changes.",null,null
464,"Among all of the phonetic reformulation patterns, partial emphasis (PE) was used more frequently than whole emphasis (WE). As we mentioned in Section 4, stressing (STR) and slowing down (SLW) were the most frequent patterns for partial emphasis, while spelling (SPL) and using different pronunciations (DIF)",null,null
465,rarely happened. Repeating was used as frequently as phonetic reformulation patterns when recognition errors happened in qv(1).,null,null
466,"To conclude, our results indicate that in voice search, a user's adoption of both lexical and phonetic query reformulation patterns were greatly impacted by voice input errors. As further illustrated in RQ8, many of the reformulation patterns were used specifically to correct the missing words occurred in previous queries.",null,null
467,RQ8: How do users utilize different reformulation patterns to handle speech recognition errors? Are these patterns effective in correcting speech recognition errors?,null,null
468,"When speech recognition errors happen, it is very common for some of the words spoken by the users to be incorrectly recognized or missing from the system's transcribed queries. Solutions to speech recognition errors should be able to effectively correct these errors. Among the lexical and phonetic query reformulation patterns summarized in our paper, four patterns can be used specifically related to the missing words: substitution (SUB), removal (RMV), re-ordering (ORD), and partial emphasis (PE). Users can substitute other words for the missing words, or remove the missing words, or re-order the missing words and other words, or phonetically emphasize the missing words. In comparison, the other patterns affect equally the missing words and other words in the query.",null,null
469,"We evaluate the reformulation patterns by their effectiveness of correcting the missing words in voice queries. Similarly, we can evaluate by their effectiveness of reducing the incorrect words in transcribed queries. However, due to space limitation, we only reported the following measures regarding the missing words:",null,null
470,"(1) For each of the four patterns that can be used specifically for handling the missing words (i.e. SUB, RMV, ORD, and PE), we calculated the percentage that the pattern was used specifically related to the missing words (i.e. the missing words were substituted, removed, re-ordered, or emphasized) out of all the cases that the reformulation pattern was used.",null,null
471,"(2) The success rate of each pattern in correcting the missing words. For re-ordering (ORD) and partial emphasis (PE) patterns, the success rate was calculated as the percentage of missing words being corrected out of all the cases that the missing words were re-ordered or specifically emphasized. For addition (ADD), whole emphasis (WE), and repeating patterns, the success rate was calculated as the percentage of missing words being corrected out of all the cases that ADD, WE, or repeating was used (since it is difficult to identify whether these patterns were used specifically on the missing words). For substitution, the success rate was calculated as the percentage of the replaced words being correctly recognized out of all the cases that the missing words were replaced.",null,null
472,(3) The improvement in nDCG@10 between qtr(1) and qtr(2) when each pattern was used.,null,null
473,"As shown in Table 8, the percentage of the patterns used specifically related to the missing words indicates users' adoption of the pattern to solve speech recognition errors. Among all of the patterns, partial emphasis (PE) has most usage. When PE was used, it was nearly always (93.69%) the case that the words emphasized were the missing words from qv(1). In comparison, substitution (SUB), removal (RMV), and re-ordering (ORD) patterns have fewer but still considerably high usage (84.30%, 62.82% and 75.23%). Results indicate that, when recognition errors happened, these lexical patterns were primarily used to correct speech recognition errors, which is different from the intention to use these patterns in conventional searches.",null,null
474,Table 8 also reveals the effectiveness of different reformulation patterns in correcting speech recognition errors. As indicated in,null,null
475,150,null,null
476,"the results, different reformulation patterns vary widely in their success rates in correcting missing words in previous queries. Among these patterns, substitution (SUB) and re-ordering (ORD) had the two highest success rates (73.5% and 69.1%). In comparison, partial emphasis (PE) was less effective (62.5%). It is indicated that when recognition errors happened, it was usually more effective to modify the missing words into others (SUB) or to change the contexts around the missing words (ORD), rather than emphasizing with phonetic changes (PE).",null,null
477,Table 8. Effectiveness of reformulation patterns in correcting speech recognition errors that occurred in previous queries.,null,null
478,% used Success,null,null
479,specifically rate of related to correcting the missing missing,null,null
480,nDCG@10 qtr(1)  qtr(2),null,null
481,words in qv(1) words,null,null
482,ADD,null,null
483,-,null,null
484,40.73 % 0.085  0.119,null,null
485,SUB 84.30 % 73.53 % 0.052  0.156 ,null,null
486,RMV 62.82 %,null,null
487,-,null,null
488,0.077  0.111,null,null
489,ORD 75.23 % 69.14 % 0.062  0.147 ,null,null
490,PE 93.69 % 62.50 % 0.022  0.150 ,null,null
491,WE,null,null
492,-,null,null
493,60.94 % 0.028  0.110 ,null,null
494,Repeat w/o PE and WE,null,null
495,-,null,null
496,59.73 % 0.051  0.142 ,null,null
497,Overall,null,null
498,-,null,null
499,47.45 % 0.058  0.132 ,null,null
500,: the difference of nDCG@10 is significant at 0.01 level according to,null,null
501,paired t-tests.,null,null
502,We suspect that users' adoption of partial emphasis (PE) is,null,null
503,directly related to their everyday life experience: when others,null,null
504,"miss your words, it is natural to repeat and emphasize the missing",null,null
505,"part. However, it seems that this method cannot work well for",null,null
506,automatic speech recognition systems. The speech recognition,null,null
507,algorithms are usually trained with samples of the normal way of,null,null
508,"speaking, but the phonetic query reformulations may make the",null,null
509,queries quite different from the normal way of speaking.,null,null
510,"According to the success rates, partial emphasis (PE), whole",null,null
511,"emphasis (WE), and repeating effectively helped to correct the",null,null
512,missing words (compared to the overall success rate of only,null,null
513,"47.45%). However, we suspect that the effectiveness of the",null,null
514,phonetic reformulation patterns is over-estimated. Compared with,null,null
515,"repeating, the phonetic patterns emphasized either certain parts of",null,null
516,"the queries or the entire queries. Therefore, we can use repeating",null,null
517,as a baseline to evaluate the effectiveness of phonetic emphasis.,null,null
518,"However, as partial emphasis (PE) and whole emphasis (WE) had",null,null
519,"only slightly higher success rates compared to repeating, it is",null,null
520,arguable whether or not phonetic emphasis was truly useful.,null,null
521,"Finally, we looked into the improvement of the transcribed",null,null
522,queries' search performance (by nDCG@10) after each pattern,null,null
523,had been used in reformulated queries. Except for addition (ADD),null,null
524,"and removal (RMV), we observed significant improvements with",null,null
525,"other patterns. In addition, the magnitude of nDCG@10",null,null
526,improvements for other patterns was also greater than those of,null,null
527,ADD and RMV patterns. This indicates that ADD and RMV are,null,null
528,less effective solutions to speech recognition errors.,null,null
529,"To conclude, we found that substitution, re-ordering, partial",null,null
530,"emphasis, whole emphasis, and repeating were five effective",null,null
531,reformulation strategies in voice search to handle recognition,null,null
532,"errors. Among these patterns, substitution and re-ordering are",null,null
533,"lexical patterns, but they outperformed the other three phonetic",null,null
534,patterns in solving speech recognition errors.,null,null
535,7. DISCUSSION AND FUTURE WORK,null,null
536,(1) Should we use and support long and natural language queries or short and keyword queries in voice search?,null,null
537,Our results show that query length is an important factor associated with speech recognition errors (see Table 2 and,null,null
538,"discussion in RQ3). Long queries are prone to speech recognition errors. This reminds us of the different findings in previous studies: Schalkwyk et al. found that voice search queries were tend to be shorter than in conventional searches [19], whereas Crestani et al. found that voice queries tend to longer and more similar to natural language [6].",null,null
539,"Since we did not conduct conventional search experiments for comparison, we cannot come to an answer to this disputable issue. We suggest that further studies are needed to identify the characteristics of queries in voice search. We believe that users' adoption of short or long queries depends on various factors. On the one hand, as voice search may be closer to people's normal ways of speaking, voice queries are probably also closer to natural language queries. On the other hand, as long queries may have more speech recognition errors, users may also prefer shorter and simpler keyword queries in voice search.",null,null
540,"(2) Query suggestion in voice search. Although the participants were told explicitly that they could use Google's query suggestions in our experiment, we did not observe many cases of them doing so (see Table 5). We tried some cases in Google and found that currently, Google's query suggestion in voice search is simply suggesting queries based on the transcribed queries' texts. Therefore, it is not surprising that the suggestions are ineffective when the transcribed texts are likely to be incorrect (due to voice input errors). For example, we submitted an incorrect transcription ""rap and crying"" (the correct one is ""rap and crime"") to Google and obtained two suggestions that are irrelevant to ""rap and crime"" but probably relevant to ""rap and crying"": ""rapper crying at bet awards"" and ""soulja boy crying"". This shows that query suggestion is more challenging in voice search. In addition, we believe that query suggestion is more important for users in voice search than in conventional search. As shown in our results, despite various query reformulation methods have been developed, users' voice query reformulations might not totally resolve the old recognition errors, and at the same time could introduce new errors. In comparison, it may be a better solution for users to accept a good query suggestion for query reformulation. This calls for studies on query suggestion algorithms specifically designed for voice search. Probably a promising solution is to develop effective query suggestion algorithms considering not only the transcribed texts, but also speech recognition results.",null,null
541,(3) Interface for supporting voice query inputs and voice query reformulation.,null,null
542,"Considering the effort and risk of issuing a voice query, voice search systems should employ proper methods to reduce the efforts and risks of constructing and reformulating voice queries. Based on our observation, one suggestion is to design a voice query reformulation interface that frees users from having to speak the whole voice query again if they only intend to correct one or two error words. For example, the users should be given the ability to specify and repeat the part of the query that they want to modify and let the search system recompose a new voice query based on the updated information.",null,null
543,"In addition, our experiments also shown that system interruptions greatly harmed the performance of voice search, even though they occurred less frequently (see Table 2 & 5). The participants could not finish their voice queries, and sometimes became really frustrated after several consecutive interruptions. Voice query generation may impose higher cognitive load on the users than typing textual queries. Therefore, voice search systems should better manage their interruptions. For example, systems",null,null
544,151,null,null
545,can allow users to control whether or not they will be interrupted while speaking voice queries.,null,null
546,8. CONCLUSION,null,null
547,"In this paper, we studied two significant and closely related issues in voice search. First, what is the influence of voice input errors on search effectiveness in voice search? Second, how do users utilize different query reformulation patterns, including both lexical and phonetic query reformulation patterns, to handle these voice input errors? We conducted a controlled laboratory experiment for voice search, which helped answer these questions.",null,null
548,"Our study systematically evaluated the influence of voice input errors on voice search from the aspects of individual queries and overall search sessions. We found that voice input errors greatly changed the content and results of queries, resulting significant decline of search performance for individual queries. This in turn led to increased efforts and negative feelings of users, hindering overall performance of the search session. In addition, current query suggestion algorithms may fail to generate effective suggestions due to voice input errors in transcribed queries.",null,null
549,"Then, we characterized users' query reformulation patterns in voice search and evaluated the effectiveness of those patterns in handling voice input errors and improving search effectiveness. We found that users utilized both lexical query reformulation patterns that exist in conventional search and phonetic query reformulation patterns newly found in voice search. Despite some of the patterns effectively corrected voice input errors, users' query reformulation resulted in limited overall improvements in search performance, because voice input errors occurred frequently in reformulated queries.",null,null
550,"Our study suggested voice input errors as the essential issue to be resolved in voice search. A possible solution is to better support users' query reformulation, which includes designing better interface supporting voice query reformulation and developing query suggestion algorithms using both lexical and phonetic information. To a broader extent, our study explored the influence of query input devices on user behaviors and search systems. Our methods and results may shed light on user behaviors and search systems in similar situations, such as when handwriting is used for input.",null,null
551,"Admittedly, our study has one limitation in that the experiment setting did not fully replicate mobile search environment and tasks. This may influence the occurrences of the different types of voice input errors and users' adoption of the voice query reformulation patterns. However, it is very likely that the impacts of voice input errors on voice search systems and the effectiveness of different voice query reformulation patterns are representative of the cases in other voice search systems.",null,null
552,9. REFERENCES,null,null
553,"[1] Anick, P. 2003. Using terminological feedback for web search refinement: a log-based study. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval (SIGIR '03): 88-95.",null,null
554,"[2] Ballinger, B. et al. 2010. On-Demand Language Model Interpolation for Mobile Speech Input. Interspeech (2010): 1812­1815.",null,null
555,"[3] Bates, M.J. 1979. Information search tactics. Journal of the American Society for Information Science, 30(4): 205­214.",null,null
556,"[4] Broder, A. 2002. A taxonomy of web search. SIGIR Forum 36(2): 3-10.",null,null
557,"[5] Crestani, F. 2002. Spoken query processing for interactive information retrieval. Data Knowl. Eng. 41, 1 (April 2002): 105-124.",null,null
558,"[6] Crestani, F. et al. 2006. Written versus spoken queries: A qualitative and quantitative comparative analysis. J. Am. Soc. Inf. Sci., 57: 881­890.",null,null
559,"[7] Dang, V. and Croft, W.B. 2010. Query reformulation using anchor text. In Proceedings of the third ACM international conference on Web search and data mining (WSDM '10): 4150.",null,null
560,"[8] Feng, J. and Bangalore, S. 2009. Effects of word confusion networks on voice search. (Mar. 2009): 238­245.",null,null
561,"[9] Huang, J. and Efthimiadis, E. N. 2009. Analyzing and evaluating query reformulation strategies in web search logs. In Proceedings of the 18th ACM conference on Information and knowledge management (CIKM '09): 77-86.",null,null
562,"[10] Jansen, B.J. et al. 2005. A temporal comparison of AltaVista Web searching. J. Am. Soc. Inf. Sci., 56(6): 559­570.",null,null
563,"[11] Jansen, B.J. et al. 2009. Patterns of query reformulation during Web searching. J. Am. Soc. Inf. Sci., 60(7): 1358­ 1371.",null,null
564,"[12] Järvelin, K. et al. 2008. Discounted Cumulated Gain Based Evaluation of Multiple-Query IR Sessions. LNCS 4956: Proceedings of the 30th European Conference on Information Retrieval (ECIR '08): 4­15.",null,null
565,"[13] Jiang, J. et al. 2012. Contextual evaluation of query reformulations in a search session by user simulation. In Proceedings of the 21st ACM international conference on Information and knowledge management (CIKM '12): 26352638.",null,null
566,"[14] Jiang, J. et al. 2012. On Duplicate Results in a Search Session. Proceedings of the 21st Text REtrieval Conference, (TREC 2012).",null,null
567,"[15] Joachims, T. 2002. Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '02): 133-142",null,null
568,"[16] Kanoulas, E. et al. 2011. Evaluating multi-query sessions. Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR '11): 1053­1062.",null,null
569,"[17] Kanoulas, E. et al. 2011. Session Track 2011 Overview. The 20th Text REtrieval Conference Notebook Proceedings (TREC 2011).",null,null
570,"[18] Rieh, S.Y. et al. 2006. Analysis of multiple query reformulations on the web: The interactive information retrieval context. Information Processing & Management. 42(3): 751­768.",null,null
571,"[19] Schalkwyk, J. et al. 2010. ""Your Word is my Command"": Google Search by Voice: A Case Study. Advances in Speech Recognition SE - 4. A. Neustein, ed. Springer US. 61­90.",null,null
572,"[20] Song, Y.-I. et al. 2009. Voice search of structured media data. 2009 IEEE International Conference on Acoustics, Speech and Signal Processing (Apr. 2009): 3941­3944.",null,null
573,"[21] Teevan, J. et al. 2007. Information re-retrieval: repeat queries in Yahoo's logs. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '07): 151-158.",null,null
574,"[22] Wang, X. et al. 2008. Mining term association patterns from search logs for effective query reformulation. In Proceedings of the 17th ACM conference on Information and knowledge management (CIKM '08): 479-488.",null,null
575,"[23] Wang, Y.-Y. et al. 2008. An introduction to voice search. Signal Processing Magazine, IEEE.",null,null
576,152,null,null
577,,null,null
