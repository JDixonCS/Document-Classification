,sentence,label,data
0,Using Term Location Information to Enhance Probabilistic Information Retrieval,null,null
1,"Baiyan Liu, Xiangdong An, Jimmy Xiangji Huang",null,null
2,Information Retrieval and Knowledge Management Research Lab School of Information Technology,null,null
3,"York University, Toronto, ON M3J 1P3, Canada",null,null
4,"{baiyan, xan, jhuang}@yorku.ca",null,null
5,ABSTRACT,null,null
6,"Nouns are more important than other parts of speech in information retrieval and are more often found near the beginning or the end of sentences. In this paper, we investigate the effects of rewarding terms based on their location in sentences on information retrieval. Particularly, we propose a novel Term Location (TEL) retrieval model based on BM25 to enhance probabilistic information retrieval, where a kernel-based method is used to capture term placement patterns. Experiments on f ve TREC datasets of varied size and content indicate the proposed model signif cantly outperforms the optimized BM25 and DirichletLM in MAP over all datasets with all kernel functions, and excels the optimized BM25 and DirichletLM over most of the datasets in P@5 and P@20 with different kernel functions.",null,null
7,Categories and Subject Descriptors,null,null
8,H.3.3 [Information Systems]: Information Search and Retrieval,null,null
9,Keywords,null,null
10,"Term location, probabilistic information retrieval, noun",null,null
11,1. INTRODUCTION,null,null
12,"English has 5 basic sentence patterns [1, 10]: (1) Subject + Verb (e.g., Joe swims); (2) Subject + Verb + Object (e.g., Joe plays the guitar); (3) Subject + Verb + Complement (e.g., Joe becomes a doctor); (4) Subject + Verb + Indirect Object + Direct Object (e.g., I give her a gift); and (5) Subject + Verb + Object + Complement (e.g., We elect him president). Most English simple sentences follow these 5 patterns and exceptions are rare (compound and complex sentences can be split into simple sentences) [10], where nouns and noun-phrases are mostly located in the beginning or the end of sentences. On the other hand, past research has indicated that nouns and noun-phrases are more information-bearing than the other parts of speech in information retrieval (IR) [6, 3, 8, 12]. Therefore, integrating term location information into IR may help improve retrieval performances.",null,null
13,"Two illustrative experiments are conducted to verify the hypothesis. The f rst illustrative experiment on WT2g dataset (247,491 web documents, TREC'99 Web track) indicates nouns do concen-",null,null
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prof t or commercial advantage and that copies bear this notice and the full citation on the f rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specif c permission and/or a fee. Request permissions from Permissions@acm.org. SIGIR'15, August 09 - 13, 2015, Santiago, Chile.",null,null
15,c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.,null,null
16,DOI: http://dx.doi.org/10.1145/2766462.2767827.,null,null
17,"trate on both ends of sentences as shown in Table 1, where AvgDis is the average of the normalized distances of a set T of nouns from the middle of their sentences as def ned by Eq. 1. In Eq. 1, |T | means the cardinality of set T (In this paper, except as explicitly",null,null
18,"noted, |x| means absolute value of x).",null,null
19,"AvgDis ,",null,null
20,tT avg(|M id(t) - P os(t)|/M id(t)) |T |,null,null
21,(1),null,null
22,"where M id(t) is the middle position of the sentence that noun t is in, P os(t) is the position of t, and T is the set of nouns. Since a term may appear in a document more than once, average function avg(.) is used. AvgDis has a range of [0, 1], and is closer to 0 if all nouns are gathered in the middle of sentences.",null,null
23,"Table 1 shows that AvgDis > 0.5 on both halves of the sentences, which means that the nouns are nearer to the beginning or the end of sentences than to the middle of sentences.",null,null
24,End Left Right,null,null
25,Table 1: Noun placement in sentences,null,null
26,AvgDis # Nouns Avg. sent. len. # Sentences,null,null
27,"0.5901 24,918,926 0.613 26,286,542",null,null
28,10.5619,null,null
29,"14,360,676",null,null
30,Table 2: Relevant noun placement in sentences,null,null
31,Term,null,null
32,Score Term Score,null,null
33,louisa,null,null
34,43 head,null,null
35,-24,null,null
36,gradgrind 27 ladi,null,null
37,-17,null,null
38,tom,null,null
39,23 hand,null,null
40,-16,null,null
41,bounderbi 22 countri -16,null,null
42,slackbridg 15 time,null,null
43,-16,null,null
44,The second illustrative experiment on Hard Times by Charles,null,null
45,Dickens [2] illustrates that relevant terms are more likely located in,null,null
46,"the beginning or the end of than in the middle of sentences as shown in Table 2, where Score > 0 if a term is more often found near the beginning or the end of sentences, and Score < 0 otherwise. To obtain Score of a term t in a document D, sentences in D are each partitioned into three parts, {p1 p2 p3}, where |p1| , |p3| and |p2| ,"" |p1| + |p3|, and a score to t for its each occurrence in D is""",null,null
47,assigned by Eq. 2:,null,null
48,"Score(t) ,",null,null
49,1 -1,null,null
50,if t  p1  p3 if t  p2,null,null
51,(2),null,null
52,Then Score of t for all of its occurrences in D is given by Eq.,null,null
53,3:,null,null
54,"Score(t, D) , Score(ti)",null,null
55,(3),null,null
56,ti D,null,null
57,"where ti is the ith occurrence of t in D. Table 2 shows that the highest scoring terms ""louisa"", ""grad-",null,null
58,"grind"", ""bounderbi"", ""tom"", and ""slackbridg"" turn out to be the",null,null
59,883,null,null
60,"main or minor characters in the book, whereas the lowest scoring terms are not particularly related with the novel.",null,null
61,The results from the two illustrative experiments above indicate the hypothesis deserves a deeper investigation. The main contributions of this paper are as follows:,null,null
62,· We extend BM25 naturally with term location information to enhance probabilistic information retrieveal;,null,null
63,"· In order to reward terms that are more likely to be nouns, we propose a novel kernel-based Term Location (TEL) retrieval model to capture term placement patterns;",null,null
64,· Experiments on f ve TREC datasets of varied size and content indicate the proposed model is highly promising.,null,null
65,2. RELATED WORK,null,null
66,"Jing and Croft [6] proposed PhraseFinder to automatically construct collection-dependent association thesauri, and then used the association thesauri to assist query expansion and found that nouns and noun-phrases were most effective in improving IR. Liu et al. [8] classif ed noun-phrases into four types ­ proper names, dictionary phrases, simple phrases, and complex phrases ­ and ranked documents based on phrase similarity. Zheng et al [17] used nounphrases and semantic relationships to represent documents in order to assist document clustering, where noun-phrases were extracted with the assistance of WordNet. Yang et al [14] used a parse tree to transform the sentences in legal agreements into subject-verbobject (SVO) representations, which are then used in conjunction with cue terms to identify the provisions provided by the sentences. However, they found that provision extraction using the SVO representation resulted in high precision but low recall, which could be due to the specif city of SVO sentence patterns and the diff culty in parsing complex sentences. Hung et al. [4] used syntactic pattern matching to extract syntactically complete sentences that express event-based commonsense knowledge from web documents, and then semantic role labeling was used to tag the semantic roles of the terms in the sentences, such as the subject and the object. Ibekwe-SanJuan et al. [5] built f nite state automaton with syntactic patterns and synonyms from WordNet, which was used to tag the sentences in scientif c documents according to its category. It is diff cult to f nd syntactic patterns that are effective in all the documents of a single corpus, and rule-based part-of-speech taggers are less effective in unseen text [7]. Terms were rewarded based on their locations in a document in [15, 16].",null,null
67,3. OUR APPROACH 3.1 Term Location,null,null
68,We assume that the most important terms in the documents are,null,null
69,near the beginning or the end of the sentences. We determine the importance (relevancy) of a term t by examining its distance from the middle of its sentence in document D as def ned by Eq. 4:,null,null
70,"q(t, D) ,"" |M id(t, D) - P os(t, D)|""",null,null
71,(4),null,null
72,"where M id(t, D) ,"" (SL(t, D) - 1)/2,""",null,null
73,"SL(t, D) is the length of the sentence in D that contains t, and P os(t, D) is the location of t in the sentence. We use the average distance of t from the middle of its sentences in D if t appears more than once in D, which is def ned as r(t, D) by Eq. 5:",null,null
74,"r(t, D) ,"" ( q(ti, D))/tf (t, D)""",null,null
75,(5),null,null
76,ti D,null,null
77,"where ti is the ith occurrence of t in D and tf (t, D) is the term frequency of t in D. We def ne m(t, D) to be the average length of the sentence(s) that contain t in D as Eq. 6:",null,null
78,"m(t, D) ,",null,null
79,"tiD SL(ti, D)   tf (t, D)",null,null
80,+,null,null
81,(6),null,null
82,"where parameter  has a larger effect for longer sentences since it is proportional to the lengths of the sentences, and parameter  has a proportionally smaller effect for longer sentences since it is the same for all sentences. These two parameters are used to balance term weights in particularly short or long sentences.",null,null
83,3.2 Kernel Functions,null,null
84,In order to measure the distances of the terms from the middle,null,null
85,"of their sentences, we f t a kernel function over each sentence. We",null,null
86,adjust the weight of each term based on its average distance to the,null,null
87,"middle of its sentences. In this paper, we explore the following",null,null
88,"kernel functions for our location based reward function RN (t, D)",null,null
89,used in Eq. 9:,null,null
90,r2,null,null
91,"Gaussian - Kernel(r, m) , 1 - e -2m2",null,null
92,Triangle,null,null
93,-,null,null
94,"Kernel(r, m)",null,null
95,",",null,null
96,r m,null,null
97,Cosine,null,null
98,-,null,null
99,"Kernel(r, m)",null,null
100,",",null,null
101,1,null,null
102,-,null,null
103,1,null,null
104,+,null,null
105,cos 2,null,null
106,r m,null,null
107,"Circle - Kernel(r, m) , 1 -",null,null
108,1-,null,null
109,r2 m,null,null
110,"Quartic - Kernel(r, m) , 1 -",null,null
111,1-,null,null
112,r2 m,null,null
113,2,null,null
114,"Epanechnikov - Kernel(r, m) ,",null,null
115,r2 m,null,null
116,"Triweight - Kernel(r, m) , 1 -",null,null
117,1-,null,null
118,r 23 m,null,null
119,"Among them, Gaussian kernel is widely used in statistics and machine learning such as Support Vector Machines, Triangle kernel, Circle Kernel, and Cosine Kernel are applied to estimate the proximitybased density distribution for the positional language model [9]. Since the kernel functions are not maturely applied in IR, we also explore Quartic kernel, Epanechnikov kernel and Triweight kernel in this work. In these kernel functions, r and m are def ned by Eqs. 5 and 6, respectively. With these kernel functions, the number of terms that are given maximum reward decreases as m(t, D) increases.",null,null
120,3.3 Integration into BM25,null,null
121,"In this experiment, we use the BM25 weighting model as our base weighting model. BM25 is def ned as follows:",null,null
122,"Score(t, D) ,"" T F (t, D)  IDF (t)""",null,null
123,(7),null,null
124,where,null,null
125,"T F (t, D)",null,null
126,",",null,null
127,(k3,null,null
128,+ 1) (k3,null,null
129, +,null,null
130,"tf (t, D)  qtf qtf (t))  K",null,null
131,(t),null,null
132,",",null,null
133,IDF,null,null
134,(t),null,null
135,",",null,null
136,log2,null,null
137,N,null,null
138,- n(t) n(t) +,null,null
139,+ 0.5 0.5,null,null
140,",",null,null
141,"K , k1 ",null,null
142,1,null,null
143,-,null,null
144,b,null,null
145,+,null,null
146,b  |D| AvgDL,null,null
147,"+ tf (t, D),",null,null
148,"k1, k3, and b are tuning parameters for BM25, qtf (t) is the frequency of t in the query, |D| is the number of terms in D, AvgDL is the average length of the documents in the collection, N is the number of documents in the collection, and n(t) is the number of documents in the collection that contain t. We modify T F (t, D) to",null,null
149,account for the reward given to the terms based on their locations in,null,null
150,the sentences. We def ne the Term Location score (TL) as follows:,null,null
151,"T L(t, D)",null,null
152,",",null,null
153,(k3,null,null
154,+,null,null
155,1),null,null
156," RN(t, D)  tf (t, D) (k3 + qtf (t))  KT L",null,null
157,qtf (t),null,null
158,(8),null,null
159,884,null,null
160,Performance improvement (%),null,null
161,MAP improvements of TEL over best BM25 with different kernel functions 3.5,null,null
162,3,null,null
163,2.5,null,null
164,2 1.5,null,null
165,1 0.5,null,null
166,0 WT2G,null,null
167,DISK4&5,null,null
168,Gaussian MAP Triangle MAP Circle MAP Cosine MAP Quartic MAP Epanechnikov MAP Triweight MAP,null,null
169,WT10G Dataset,null,null
170,BLOGS06,null,null
171,GOV2,null,null
172,Performance improvement (%),null,null
173,P@5 improvements of TEL over best BM25 with different kernel functions 7,null,null
174,6,null,null
175,Gaussian P@5,null,null
176,Triangle P@5,null,null
177,5,null,null
178,Circle P@5,null,null
179,Cosine P@5,null,null
180,4,null,null
181,Quartic P@5,null,null
182,Epanechnikov P@5,null,null
183,3,null,null
184,Triweight P@5,null,null
185,2,null,null
186,1,null,null
187,0,null,null
188,-1,null,null
189,-2 WT2G,null,null
190,DISK4&5,null,null
191,WT10G Dataset,null,null
192,BLOGS06,null,null
193,GOV2,null,null
194,Performance improvement (%),null,null
195,P@20 improvements of TEL over best BM25 with different kernel functions 2.5,null,null
196,Gaussian P@20 2,null,null
197,Triangle P@20,null,null
198,Circle P@20,null,null
199,1.5,null,null
200,Cosine P@20,null,null
201,Quartic P@20,null,null
202,1,null,null
203,Epanechnikov P@20,null,null
204,Triweight P@20,null,null
205,0.5,null,null
206,0,null,null
207,-0.5,null,null
208,-1 WT2G,null,null
209,DISK4&5,null,null
210,WT10G Dataset,null,null
211,BLOGS06,null,null
212,GOV2,null,null
213,Figure 1: Performance improvements of TEL over best BM25 with different kernel functions.,null,null
214,Performance improvement (%),null,null
215,MAP improvements of TEL over best DirichletLM with different kernel functions 6,null,null
216,P@5 improvements of TEL over best DirichletLM with different kernel functions 14,null,null
217,P@20 improvements of TEL over best DirichletLM with different kernel functions 5,null,null
218,Gaussian LM MAP,null,null
219,5,null,null
220,Triangle LM MAP,null,null
221,Circle LM MAP,null,null
222,4,null,null
223,Cosine LM MAP,null,null
224,Quartic LM MAP,null,null
225,Epanechnikov LM MAP,null,null
226,3,null,null
227,Triweight LM MAP,null,null
228,2,null,null
229,1,null,null
230,Performance improvement (%),null,null
231,12,null,null
232,4.5 Gaussian LM P@20,null,null
233,Performance improvement (%),null,null
234,4,null,null
235,Triangle LM P@20,null,null
236,10,null,null
237,Circle LM P@20,null,null
238,3.5,null,null
239,Cosine LM P@20,null,null
240,8,null,null
241,3,null,null
242,Quartic LM P@20,null,null
243,Gaussian LM P@5,null,null
244,Epanechnikov LM P@20,null,null
245,6,null,null
246,Triangle LM P@5,null,null
247,2.5,null,null
248,Triweight LM P@20,null,null
249,Circle LM P@5,null,null
250,4,null,null
251,Cosine LM P@5,null,null
252,2,null,null
253,Quartic LM P@5,null,null
254,1.5,null,null
255,2,null,null
256,Epanechnikov LM P@5,null,null
257,Triweight LM P@5,null,null
258,1,null,null
259,0,null,null
260,0.5,null,null
261,0 WT2G,null,null
262,DISK4&5,null,null
263,WT10G Dataset,null,null
264,BLOGS06,null,null
265,GOV2,null,null
266,-2 WT2G,null,null
267,DISK4&5,null,null
268,WT10G Dataset,null,null
269,BLOGS06,null,null
270,GOV2,null,null
271,0 WT2G,null,null
272,DISK4&5,null,null
273,WT10G Dataset,null,null
274,BLOGS06,null,null
275,GOV2,null,null
276,Figure 2: Performance improvements of TEL over best DirichletLM with different kernel functions.,null,null
277,where,null,null
278,"KT L , k1 ",null,null
279,1,null,null
280,-,null,null
281,b,null,null
282,+,null,null
283,b  |D| AvgDL,null,null
284,"+ RN (t, D)  tf (t, D) (9)",null,null
285,"We integrate our model into BM25 to form the Term Location Score (TEL) as follows: T EL(t, D) ,"" ((1 - )  T F (t, D) +   T L(t, D))  IDF (t)""",null,null
286,(10) where  controls the contribution of our model.,null,null
287,4. EXPERIMENTAL RESULTS,null,null
288,"We conduct experiments on f ve standard TREC collections: WT2G, DISK4&5, WT10G, BLOGS06, and GOV2. These datasets vary in both size and content, where WT2g contains 247,491 general Web documents (TREC'99 Web track), DISK4&5 is comprised of 528,155 newswire documents from sources such as the Financial Times and the Federal Register (TREC'97-99 Ad hoc track), WT10G has 1,692,096 general web documents (TREC'00-01 Web track), BLOGS06 consists of 3,215,171 feeds from late 2005 to early 2006 with associated permalink and homepage documents (TREC'06-08 Blog track), and GOV2 holds 25,178,548 documents crawled from .gov sites (TREC'04-06 Terabyte track).",null,null
289,We compare our model against the following weighting models when they perform best on each dataset with parameters obtained as follows:,null,null
290,"1. BM25, with k1 , 1.2 and k3 ,"" 8. We adjust b in the range of [0.1, 0.9] in steps of 0.1 for each dataset to f nd the value of b that gives the best MAP for that dataset.""",null,null
291,"2. DirichletLM. We adjust µ in the range of [100, 3000] in steps of 100. We f nd the optimal value of µ for each dataset.",null,null
292,"The proposed model T EL uses the same values as BM25 for k1, k3, and b, and sets  ,"" 0.2,  "","" 3, and  "", 3 for all datasets.",null,null
293,"In the future, we would study the optimal values of the model parameters and their relations with the characteristics of the datasets. We use the TREC off cial evaluation measures in our experiments, namely the topical MAP on BLOGS06 [11], and Mean Average Precision (MAP) on all the other datasets [13]. To stress the top retrieved documents, we also include P@5 and P@20 as the evaluation measures. All statistical tests are based on Wilcoxon Matchedpairs Signed-rank test.",null,null
294,"The experimental results are presented in Table 3. To illustrate the performance differences graphically, we plot the results in Figures 1 and 2. As shown by the two f gures, our model TEL outperforms optimized BM25 and DirichletLM in M AP over all datasets with all kernel functions, and outperforms the two optimized baseline models over most of the datasets in P @5 and P @20 with different kernel functions. The performance improvements of our model TEL against DirichletLM are greater than those against BM25. According to the two f gures, each kernel function has its advantage on some datasets. There is no single kernel function that outperforms others on all the datasets.",null,null
295,5. CONCLUSIONS AND FUTURE WORK,null,null
296,"In this paper, we extend BM25 and reward the terms based on their locations in the sentences with kernel functions. Experimental study shows that the proposed model performs signif cantly better than BM25 and DirichletLM on MAP over all datasets, and significantly better on P@5, p@10, and p@20 over most datasets.",null,null
297,"In the future, more experiments will be conducted to further investigate the proposed model. We would investigate non-symmetric kernel functions and kernel functions with negative values since the placement of the terms at the beginning of the sentences is different from that at the end of the sentences as indicated in the f rst illustra-",null,null
298,885,null,null
299,Model BM 25 DirichletLM TEL Gaussian TEL Triangle TEL Circle TEL Cosine TEL Quartic TEL Epanechnikov TEL Triweight,null,null
300,Eval Metric M AP P @5 P @20 M AP P @5 P @20 MAP P@5 P@20 MAP P@5 P@20 MAP P@5 P@20 M AP,null,null
301,P @5,null,null
302,P @20,null,null
303,MAP P@5 P@20 MAP P@5 P@20 MAP P@5 P@20,null,null
304,WT2G,null,null
305,0.3167 0.5120 0.3870,null,null
306,0.3059 0.5080 0.3870,null,null
307,"0.3223*+ (+1.77%,+5.36%)",null,null
308,"0.5200* (+1.56%,+2.36%)",null,null
309,"0.3960 (+2.33%,+2.33%)",null,null
310,"0.3179 (+0.38%,+3.92%)",null,null
311,"0.5040 (-1.56%,-0.79%)",null,null
312,"0.3890* (+0.52%,+0.52%)",null,null
313,"0.3235*+ (+2.15%,+5.75%)",null,null
314,"0.5280* (+3.13%,+3.49%)",null,null
315,"0.3950 (+2.07%,+2.07%)",null,null
316,"0.3186 (+0.60%,+4.15%)",null,null
317,"0.5160* (+0.78%,+1.57%)",null,null
318,"0.3890* (+0.52%,+0.52%)",null,null
319,"0.3199*+ (+1.01%,+4.58%)",null,null
320,"0.5160* (+0.78%,+1.57%)",null,null
321,"0.3900* (+0.78%,+0.78%)",null,null
322,"0.3201*+ (+1.07%,4.64%)",null,null
323,"0.5200* (+1.56%,+2.36%)",null,null
324,"0.3930 (+1.55%,+1.55%)",null,null
325,"0.3179 (+0.38%,+3.92%)",null,null
326,"0.5080 (-0.78%,0.00%)",null,null
327,"0.3880* (+0.26%,+0.26%)",null,null
328,DISK4&5,null,null
329,0.2176 0.4680 0.3613,null,null
330,0.2190 0.4560 0.3627,null,null
331,"0.2201 (+1.15%,+0.50%)",null,null
332,"0.4627+ (-1.13%,+1.47%)",null,null
333,"0.3653* (+1.11%,+0.72%)",null,null
334,"0.2209* (+1.52%,+0.87%)",null,null
335,"0.4613+ (-1.43%,+1.16%)",null,null
336,"0.3640*+ (+0.75%,+0.36%)",null,null
337,"0.2201 (+1.15%,+0.50%)",null,null
338,"0.4627+ (-1.13%,+1.47%)",null,null
339,"0.3647* (+0.94%,+0.55%)",null,null
340,"0.2209* (+1.52%,+0.87%)",null,null
341,"0.4613+ (-1.43%,+1.16%)",null,null
342,"0.3643*+ (+0.83%,+0.44%)",null,null
343,"0.2209* (+1.52%,+0.87%)",null,null
344,"0.4613+ (-1.43%,+1.16%)",null,null
345,"0.3643*+ (+0.83%,+0.44%)",null,null
346,"0.2206 (+1.38%,+0.73%)",null,null
347,"0.4640+ (-0.85%,1.75%)",null,null
348,"0.3660* (+1.30%,0.91%)",null,null
349,"0.2205* (+1.33%,+0.68%)",null,null
350,"0.4613+ (-1.43%,+1.16%)",null,null
351,"0.3640*+ (+0.75%,+0.36%)",null,null
352,WT10G,null,null
353,0.2134 0.3918 0.2776,null,null
354,0.2168 0.3531 0.2745,null,null
355,"0.2202* (+3.19%,+1.57%)",null,null
356,"0.3898+ (-0.51%,10.39%)",null,null
357,"0.2765 (-0.40%,+0.73%)",null,null
358,"0.2196* (+2.91%,+1.29%)",null,null
359,"0.3898+ (-0.51%,+10.39%)",null,null
360,"0.2755+ (-0.76%,+0.36%)",null,null
361,"0.2202* (+3.19%,+1.57%)",null,null
362,"0.4000* (+2.09%,+13.28%)",null,null
363,"0.2770 (-0.22%,+0.91%)",null,null
364,"0.2197* (+2.95%,+1.43%)",null,null
365,"0.3898+ (-0.51%,+10.39%)",null,null
366,"0.2770+ (-0.22%,+0.91%)",null,null
367,"0.2199* (+3.05%,+1.43%)",null,null
368,"0.3918+ (+0.00%,+10.96%)",null,null
369,"0.2755 (-0.76%,+0.36%)",null,null
370,"0.2206* (+3.37%,+1.75%)",null,null
371,"0.3918+ (+0.00%,+10.96%)",null,null
372,"0.2760 (-0.58%,+0.55%)",null,null
373,"0.2198* (+3.00%,+1.38%)",null,null
374,"0.3898+ (-0.51%,+10.39%)",null,null
375,"0.2765+ (-0.40%,+0.73%)",null,null
376,BLOGS06,null,null
377,0.3195 0.6380 0.6095,null,null
378,0.3125 0.6080 0.5935,null,null
379,"0.3238+ (+1.35%,+3.62%)",null,null
380,"0.6640* (+4.08%,+9.21%)",null,null
381,"0.6180 (+1.39%,+4.13%)",null,null
382,"0.3241*+ (+1.44%,+3.71%)",null,null
383,"0.6800* (+6.58%,+11.84%)",null,null
384,"0.6225 (+2.13%,+4.89%)",null,null
385,"0.3238+ (+1.35%,+3.62%)",null,null
386,"0.6680* (+4.70%,+9.87%)",null,null
387,"0.6185 (+1.48%,+4.21%)",null,null
388,"0.3239*+ (+1.38%,+3.65%)",null,null
389,"0.6760* (+5.96%,+11.18%)",null,null
390,"0.6210 (+1.89%,+4.63%)",null,null
391,"0.3239*+ (+1.38%,+3.65%)",null,null
392,"0.6760* (+5.96%,+11.18%)",null,null
393,"0.6220 (+2.05%,+4.80%)",null,null
394,"0.3239+ (+1.38%,+3.65%)",null,null
395,"0.6740* (+5.64%,+10.86%)",null,null
396,"0.6195 (+1.64%,+4.38%)",null,null
397,"0.3239*+ (+1.38%,+3.65%)",null,null
398,"0.6760* (+5.96%,+11.18%)",null,null
399,"0.6220 (+2.05%,+4.80%)",null,null
400,GOV2,null,null
401,0.3008 0.6094 0.5406,null,null
402,0.2983 0.5919 0.5272,null,null
403,"0.3045*+ (+1.23%,+2.08%)",null,null
404,"0.6174*+ (+1.31%,+4.31%)",null,null
405,"0.5383 (-0.43%,+2.11%)",null,null
406,"0.3041*+ (+1.10%,+1.94%)",null,null
407,"0.6067+ (-0.44%,,+2.50%)",null,null
408,"0.5356 (-0.92%,+1.59%)",null,null
409,"0.3045*+ (+1.23%,+2.08%)",null,null
410,"0.6148*+ (+0.89%,+8.37%)",null,null
411,"0.5376 (-0.55%,+1.97%)",null,null
412,"0.3043*+ (+1.16%,+2.01%)",null,null
413,"0.6054+ (-0.66%,+2.28%)",null,null
414,"0.5383 (-0.43%,+2.11%)",null,null
415,"0.3043*+ (+1.16%,+2.01%)",null,null
416,"0.6040+ (-0.89,+2.04%)",null,null
417,"0.5393 (-0.24%,+2.30%)",null,null
418,"0.3044*+ (+1.20%,+2.04%)",null,null
419,"0.6107*+ (+0.21%,+3.18%)",null,null
420,"0.5383 (-0.43%,+2.11%)",null,null
421,"0.3043*+ (+1.16%,+2.01%)",null,null
422,"0.6054+ (-0.66%,+2.28%)",null,null
423,"0.5379 (-0.50%,+2.03%)",null,null
424,"Table 3: Comparison between TEL and two baselines BM25 and DirichletLM with different kernel functions: Parameter b of BM25 and parameter µ of DirichletLM are obtained and set individually for each dataset for their best performances, and ""*"" and ""+"" denote statistically signif cant improvements over BM25 and DirichletLM (Wilcoxon signed-rank test with p < 0.05), respectively.",null,null
425,The best result obtained on each dataset is in bold. The two percentages below each value are the percentage improvement of TEL,null,null
426,"over BM25 and DirichletLM, respectively.",null,null
427,tive experiment. It is also worthwhile to analyze the optimal values of the model parameters and their relations with the characteristics of the datasets. Different term proximity measures would also be explored to improve the performance of our model.,null,null
428,6. ACKNOWLEDGMENTS,null,null
429,This research is supported by the research grant from the Natural Sciences & Engineering Research Council (NSERC) of Canada and NSERC CREATE Award. We thank anonymous reviewers for their thorough review comments on this paper.,null,null
430,7. REFERENCES,null,null
431,"[1] H. Ann. The Essentials of English -- a writer's handbook. New York, Pearson Education, 2003.",null,null
432,"[2] C. Dickens. Hard Times. Bradbury & Evans, 1854. [3] D. A. Evans and C. Zhai. Noun-phrase analysis in unrestricted text for",null,null
433,"information retrieval. In ACL 1996, pages 17­24. [4] S.-H. Hung, C.-H. Lin, and J.-S. Hong. Web mining for event-based",null,null
434,"commonsense knowledge using lexico-syntactic pattern matching and semantic role labeling. Expert Systems with Applications, 37(1):341­347, 2010. [5] F. Ibekwe-SanJuan and et al. Annotation of scientif c summaries for information retrieval. CoRR, 2011.",null,null
435,"[6] Y. Jing and W. B. Croft. An association thesaurus for information retrieval. In RIAO'94, pages 146­160.",null,null
436,"[7] K. Liu and et al. Effectiveness of lexico-syntactic pattern matching for ontology enrichment with clinical documents. Meth. of info. in med., 50(5):397, 2011.",null,null
437,"[8] S. Liu, F. Liu, C. Yu, and W. Meng. An effective approach to document retrieval via utilizing wordnet and recognizing phrases. In SIGIR'04, pages 266­272.",null,null
438,"[9] Y. Lv and C. Zhai. Positional language models for information retrieval. In SIGIR'09, pages 299­306.",null,null
439,"[10] C. F. Meyer. Introducing English Linguistics. Cambridge University Press, 2010.",null,null
440,[11] I. Ounis and et al. Overview of the TREC-2006 blog track. [12] O. Vechtomova. Noun phrases in interactive query expansion and document,null,null
441,"ranking. Info. Retrieval, 9:399­420, 2006. [13] E. Voorhees and D. Harman. TREC: Experiment and evaluation in information",null,null
442,"retrieval. MIT Press, 2005.",null,null
443,"[14] D. Yang and et al. A natural language processing and semantic-based system for contract analysis. In ICTAI 2013, pages 707­712.",null,null
444,"[15] J. Zhao, X. Huang, and S. Wu. Rewarding term location information to enhance probabilistic information retrieval. In SIGIR'12.",null,null
445,"[16] J. Zhao, X. Huang, and Z. Ye. Modeling term associations for probabilistic information retrieval. ACM Trans. Inf. Syst., 32(2), 2014.",null,null
446,"[17] H.-T. Zheng and et al. Exploiting noun phrases and semantic relationships for text document clustering. Info. Sci., 179(13):2249­2262, 2009.",null,null
447,886,null,null
448,,null,null
