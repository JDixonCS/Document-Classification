,sentence
0,Short Research Papers 3C: Search
1,
2,"SIGIR '19, July 21­25, 2019, Paris, France"
3,
4,Enhanced News Retrieval: Passages Lead the Way!
5,
6,Matteo Catena
7,"ISTI-CNR, Pisa, Italy matteo.catena@isti.cnr.it"
8,
9,Ophir Frieder
10,"Georgetown University, USA ophir@ir.cs.georgetown.edu"
11,
12,Cristina Ioana Muntean
13,"ISTI-CNR, Pisa, Italy cristina.muntean@isti.cnr.it"
14,
15,Franco Maria Nardini
16,"ISTI-CNR, Pisa, Italy francomaria.nardini@isti.cnr.it"
17,
18,Raffaele Perego
19,"ISTI-CNR, Pisa, Italy raffaele.perego@isti.cnr.it"
20,
21,Nicola Tonellotto
22,"ISTI-CNR, Pisa, Italy nicola.tonellotto@isti.cnr.it"
23,
24,ABSTRACT
25,"We observe that most relevant terms in unstructured news articles are primarily concentrated towards the beginning and the end of the document. Exploiting this observation, we propose a novel version of the classical BM25 weighting model, called BM25 Passage"
26,CCS CONCEPTS
27,· Information systems  Probabilistic retrieval models;
28,"ACM Reference Format: Matteo Catena, Ophir Frieder, Cristina Ioana Muntean, Franco Maria Nardini, Raffaele Perego, and Nicola Tonellotto. 2019. Enhanced News Retrieval: Passages Lead the Way!. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval"
29,1 INTRODUCTION
30,"Passage retrieval, present in literature for decades [10], is the task of retrieving only portions of documents, i.e., passages, relevant to a particular information need. At times, passage retrieval is viewed as an intermediate step in other information retrieval tasks, e.g., question answering and summarization."
31,"Believing that certain passages pose greater relevance to a given query, we investigate how such relevance can be exploited to improve retrieval on a particular domain, specifically news retrieval. We differ from both existing passage retrieval [10] and passage detection [6] efforts, where the aim is to either retrieve only highly relevant passages or detect unrelated injected passages from within documents, respectively. In contrast, our goal is not to answer a query by retrieving single passages or detect injected unrelated passages, but to focus on improving the effectiveness of a retrieval"
32,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331373"
33,
34,"system in retrieving entire news articles. To this end, we exploit passage relevance, capitalizing on their keyword density."
35,"Specifically, we introduce a variant of the well-known BM25 weighting model [7], called BM25 Passage"
36,"The exploitation of term positions in Information Retrieval applications is common. One of the most notable examples related to our work is the BM25F weighting model [9], where term statistics are computed separately for the different fields that make up a document"
37,"Term positions are also exploited in the news context for news summarization and classification tasks [2­4]. In news recommendation, the first few sentences and the article title are known to boost the performance of recommender systems. The performance of the system can be further improved by considering the rest of the document, and the best results can be observed when using the whole article text, as in our approach [1, 12]. This result suggests that although news articles tend to concentrate relevant content in the beginning, this does not necessarily imply that the remaining sections of the text can be ignored without hindering accuracy. By making the best of these two observations, we analyze the distribution of the occurrences of highly relevant terms and note that news documents belonging to different collections are consistently characterized by areas with different densities of highly relevant terms. We thus exploit this fact to improve a classical IR weighting model such as BM25. To the best of our knowledge, this is the first contribution in this direction exploiting the in-document distributions of impactful terms within news documents in the BM25 weighting function."
38,
39,1269
40,
41,Short Research Papers 3C: Search
42,
43,"SIGIR '19, July 21­25, 2019, Paris, France"
44,
45,2 PROBLEM
46,
47,"In modern information retrieval systems, given a user query, a relevance score is associated with the query-document pairs. Such"
48,relevance score is computed by exploiting a heuristic similarity
49,"function, estimating, according to some statistical procedure, the"
50,"probability of relevance of a document with respect to a query. Then, the documents retrieved are ranked by their score, and the K"
51,documents with the highest score are returned to the user.
52,The BM25 scoring function is among the most successful query-
53,"document similarity functions, whose roots lie in the Probabilistic"
54,"Relevance Framework [7]. In most IR systems, the relevance score sq"
55,term statistics such as the inverse document frequency
56,
57,st
58,
59,(k1 + 1)t f
60,
61,(1
62,
63,-
64,
65,b
66,
67,)
68,
69,+
70,
71,b
72,
73,dl av  _d l
74,
75,"wIDF , +tf"
76,
77,(1)
78,
79,"where t f is the in-document term frequency, dl is the document"
80,
81,"length, av_dl is the average document length of the collection, wq"
82,
83,"is a query-only weight, b and k1 are parameters"
84,
85,"k1 = 1.2). The wI DF component is the IDF factor, which is given"
86,
87,by wI DF
88,
89,=
90,
91,log
92,
93,N -Nt +0.5 Nt +0.5
94,
95,","
96,
97,where
98,
99,N
100,
101,is the number of documents
102,
103,in
104,
105,"the collection, and Nt is the document frequency of term t."
106,
107,When taking into account the fields that make up a document
108,
109,"(e.g., title, headings, abstract and body), each field may be treated as"
110,
111,a separate collection of
112,
113,"collection, and the relevance score of a document can be computed"
114,
115,as a weighted linear combination of the BM25 scores over the indi-
116,
117,"vidual fields. However, in [9] the authors proved that such a linear"
118,
119,"combination of scores has several drawbacks, such as breaking the"
120,
121,t f saturation after a few occurrences
122,
123,query term over several fields could rank higher than a document
124,
125,"matching several query terms in one field only), or affecting the"
126,
127,document length parameter
128,
129,"to the actual field weight rather than the whole document). Hence,"
130,
131,the authors suggested the BM25F weighting model for structured
132,
133,"documents, computing a weighted linear combination of field-based"
134,
135,term frequencies and then plugging that combination into the BM25
136,
137,formula. The novel t f factor boosts the specific fields without alter-
138,
139,ing collection statistics. The BM25F model is considered one of the
140,
141,most successful Web search and corporate search algorithms [8].
142,
143,With unstructured documents we lack the strong relevance sig-
144,
145,nals derived from the term frequency of the query keywords in the
146,
147,"different fields available in Web document. However, we formulate"
148,
149,the hypothesis that in curated unstructured documents such as
150,
151,news articles it is possible to leverage the distribution of keywords
152,
153,in the documents to derive analogous strong relevance signals.
154,
155,To validate our hypothesis on the structure of news articles and
156,
157,to quantify the impact of some distinguishing document portions
158,
159,"(referred to as passage in the following) over other portions, we"
160,
161,analyze the density of highly discriminative terms in large news
162,
163,Top 15
164,
165,Top 10
166,
167,Aquaint
168,
169,0.13 0.09 0.09 0.09 0.09 0.10 0.09 0.09 0.09 0.14
170,
171,0.21
172,
173,RCV1 0.13 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.15
174,
175,Signal 0.14 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.14
176,
177,0.18
178,
179,Aquaint RCV1
180,
181,0.15 0.08 0.09 0.09 0.09 0.09 0.09 0.09 0.09 0.15 0.15 0.08 0.08 0.08 0.08 0.09 0.09 0.09 0.09 0.17
182,
183,0.15
184,
185,Signal Aquaint
186,
187,0.16 0.09 0.09 0.08 0.08 0.09 0.08 0.08 0.09 0.16 0.21 0.07 0.07 0.07 0.07 0.08 0.07 0.07 0.07 0.20
188,
189,0.12
190,
191,RCV1 0.21 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.21
192,
193,0.09
194,
195,Signal 0.21 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.22
196,
197,1 2 3 4 5 6 7 8 9 10
198,
199,Top 5
200,
201,Figure 1: Probability distribution for the positions of key terms occurrences in the news articles of the three collections used.
202,
203,"corpora. We consider a term as discriminative, hereinafter key term, if it appears in only a few documents, i.e., it has a high IDF value."
204,For each news article in our three test collections
205,"Hence, we propose a variant of BM25 called BM25P which uses different weights for the different passages. Our proposed BM25P model computes a linear combination t fP of the term frequencies t fi in each passage i of document d"
206,
207,t fP =
208,
209,wi · t fi .
210,
211,(2)
212,
213,i P
214,
215,As suggested in [9] we plugged the term frequency t fP into the original BM25 formula
216,
217,1Tests conducted with different values of |P
218,
219,1270
220,
221,Short Research Papers 3C: Search
222,
223,"SIGIR '19, July 21­25, 2019, Paris, France"
224,
225,"in Fig. 1 gives us a clear indication of the impact of each passage within the document from the point of view of important terms. This probability distribution is used to compute the term frequency weights: wi is directly proportional to the probability distribution of important terms in the i-th passage. We re-scale all weights with the hyperparameter  to amplify the importance of highly relevant terms in impactful passages. In the following we will use the distributions of top-5, top-10 and top-15 key terms as different passage weighting methods to be plugged into BM25P, which we henceforth refer to as BM25P5, BM25P10, and BM25P15. Note that BM25P with all passage weights and  set to 1 is equivalent to BM25."
226,https://www.overleaf.com/project/5c506da7b0bc603b37fb19de
227,
228,3 EXPERIMENTAL SETUP
229,The experimental assessment of the proposed weighting model relies on the following corpora of English news articles:
230,· the AQUAINT Corpus by Linguistic Data Consortium
231,"The 2005 Robust and HARD TREC tracks provide 50 queries and their associated relevance judgements for the Aquaint dataset. The Signal and RCV1 datasets do not provide any evaluation data. Hence, for these two datasets, we adopt the methodology described in [5] and use the news titles as pseudo-queries. According to this methodology, there is only one relevant news article for each query, i.e., the article to which the title belongs to. All other articles of the collection are considered to be non-relevant. Specifically, for each of these two datasets we randomly selected 40, 000 documents to generate the same number of pseudo-queries for each collection. Statistics for the three datasets are summarized in Table 1."
232,
233,Table 1: Statistics of the three collections used. Dataset # Queries avg. QLen # Docs avg. DocLen
234,
235,Aquaint Signal RCV1
236,
237,"50 40,000 40,000"
238,
239,"2.60 1,033,000 249.42"
240,
241,"6.64 1,000,000 224.22"
242,
243,5.77
244,
245,"804,000"
246,
247,147.38
248,
249,"For each dataset, we index the unstructured body of news articles"
250,"With the query relevance data built as detailed above, we investigate if, by weighting news passages differently, our proposed BM25P model is able to improve retrieval effectiveness w.r.t. BM25. We answer this research question by retrieving the top 1, 000 documents for each query from the respective news corpus by using BM25 and BM25P. With BM25P, documents are virtually divided into 10 passages weighted as discussed above."
251,"Once queries have been processed, we observe the rank of the relevant documents retrieved and compare the results obtained for BM25P with the BM25 ones. To measure retrieval effectiveness, we consider NDCG@k and MRR metrics. NDCG@k is used to evaluate the performance on the Aquaint dataset, where we have multiple relevant documents per query. Conversely, MRR, as the"
252,
253,Table 2: NDCG at different cutoffs for BM25 and BM25P
254,
255,NDCG@k
256,NDCG@1 NDCG@3 NDCG@5 NDCG@10 NDCG@15 NDCG@20
257,
258,BM25
259,0.200 0.291 0.280 0.270 0.269 0.273
260,
261,BM25P5
262,0.310 +55.0%  0.303 +4.12% 0.288 +3.03% 0.271 +0.11% 0.271 +0.65% 0.268 -2.11%
263,
264,BM25P10
265,0.370 +85.0% 0.335 +15.01% 0.329 +17.44% 0.298 +10.20%  0.296 +9.96% 0.289 +5.81%
266,
267,BM25P15
268,0.290 +45.0%  0.317 +8.78% 0.301 +7.39% 0.291 +7.44% 0.290 +7.91%  0.282 +3.35%
269,
270,"mean of the reciprocal of the rank of the first relevant result, allows us to quantify how good is a given retrieval method in pushing a relevant result towards top rank positions, especially for the Signal and RCV1 datasets, where only one relevant document per query is known. We also evaluate the baseline BM25 and the weighting methods proposed for BM25P, i.e., BM25P5, BM25P10, and BM25P15, for different values of the  hyper-parameter."
271,
272,4 EXPERIMENTAL RESULTS
273,"The experiments conducted aim to assess whether BM25P achieves a better overall ranking quality with respect to BM25. Table 2 reports the NDCG at different cutoffs measured on the Aquaint dataset for BM25, BM25P5, BM25P10, and BM25P15. All these tests were performed with  = 10. We highlight that BM25P consistently outperforms BM25. Indeed, BM25P10 results the best setting for the passage weights, with improvements over BM25 that are always statistically significant apart from a single case"
274,"We further investigate the performance of BM25P against BM25 on the Aquaint dataset, by varying  to assess the impact of this hyper-parameter on the retrieval effectiveness measured in terms of NDCG@5. We present the results of this investigation in Figure 2. Results show that, for   10, BM25P always performs better than BM25. For BM25P5 and BM25P10, the effectiveness does not sensibly increase for  values greater than 10, while for BM25P15 the performance tends to increase even if it is not able to outperform the one of BM25P10 for any value of  . In conclusion BM2510 with  = 10 is the best weighting model in terms of NDCG@5."
275,"It is worth highlighting that, since the Aquaint dataset provides 50 queries only, the achievement of statistically significant improvements is particularly challenging. Therefore, we investigate the robustness of such improvements by testing BM25P also on the Signal and RCV1 datasets. For each one of these datasets we have in fact 40, 000 pseudo-queries obtained from the news titles as previously discussed. The results of these additional experiments are reported in Table 3, where we evaluate the retrieval performance in terms of MRR for the Signal, RCV1 and Aquaint datasets."
276,"The results show that BM25P performs significantly better than BM25 on all three datatsets, thus confirming the results achieved by"
277,
278,1271
279,
280,Short Research Papers 3C: Search
281,
282,"SIGIR '19, July 21­25, 2019, Paris, France"
283,
284,0.32
285,
286,0.30
287,
288,NDCG@5
289,
290,0.28
291,
292,0.26
293,
294,BM25P5
295,
296,BM25P10
297,
298,0.24
299,
300,BM25P15
301,
302,BM25
303,
304,0
305,
306,10
307,
308,20
309,
310,30
311,
312,40
313,
314,50
315,
316,
317,
318,"Figure 2: NDCG@5 for BM25 and BM25P, on Aquaint, for BM25P and for different values of  from 5 to 50."
319,
320,"BM25P in terms of NDCG@k on the Aquaint collection. Indeed, results also confirm that the best performing method on this dataset is BM25P10 when  = 10. A slightly different result is achieved for the Signal and RCV1 datasets, where the best performing method results to be BM25P5. Indeed, on these collections, BM25P5, BM25P10 and BM25P15 always show statistically significant improvements w.r.t. BM25 with p < 0.01 for   10."
321,"Table 3 reports the MRR while varying the value of . MRR is higher for   10 than for  < 10. When  = 10, the average value of the scaled weights wi is equal to 1, i.e., the value of  divided by the number of passages. When  < 10, the average value of the scaled weights wi becomes lesser than 1, thus penalizing the contribution of t fP with respect to the document length normalization in the denominator of Eq.(1). Conversely, the mean of the weights is greater than or equal to 1 when   10, and the initial and final passages of the news can get larger weights than the others passages. The best performing setting is BM25P10"
322,5 CONCLUSIONS
323,"For news articles, we observed that a common stylistic feature is the preponderance of occurrences of key terms"
324,
325,Table 3: MRR for BM25 and BM25P on the three collections for different values of  . We report statistical significance w.r.t. BM25 with  for p < 0.01 and  for p < 0.05.
326,
327,
328,Model
329,
330,1
331,
332,5
333,
334,10 20 30 40 50
335,
336,BM25 0.485 0.485 0.485 0.485 0.485 0.485 0.485
337,
338,Aquaint
339,
340,BM25P5 BM25P10
341,
342,0.438 0.458
343,
344,0.518 0.547 0.548 0.544 0.554 0.554 0.577 0.591 0.578 0.588  0.589 0.586
345,
346,BM25P15 0.446 0.532 0.540 0.547 0.545 0.558 0.558
347,
348,Signal
349,
350,BM25 0.342 0.342 0.342 0.342 0.342 0.342 0.342 BM25P5 0.268 0.337 0.351 0.356 0.356 0.354 0.352 BM25P10 0.276 0.340 0.350 0.353 0.352 0.351 0.349 BM25P15 0.276 0.339 0.349 0.351 0.350 0.348 0.347
351,
352,RCV1
353,
354,BM25 0.340 0.340 0.340 0.340 0.340 0.340 0.340
355,BM25P5 0.258 0.344 0.363 0.369 0.365 0.360 0.356 BM25P10 0.253 0.339 0.356 0.360 0.356 0.351 0.347 BM25P15 0.249 0.334 0.351 0.355 0.351 0.346 0.342
356,
357,distribution variations among the different passages of the news.
358,In BM25P such distribution information is used to assign different
359,"weights to the occurrences of query terms, depending on which"
360,"passage they appear in, boosting or reducing the importance of"
361,"certain passages in the document, typically giving greater impor-"
362,tance to the first and last passages. This distinguishes BM25P from
363,the traditional BM25 which does not consider the position of the
364,"occurrences in the document. Our experiments showed that, by"
365,"differently weighting news passages, BM25P markedly improves"
366,"NDCG and MRR with respect to using BM25. In particular, we ob-"
367,served that BM25P significantly improves NDCG on Aquaint with
368,"percentages up to 85% for small cutoffs, while the MRR computed"
369,on Signal and RCV1 increases of 4.1% and 8.5% respectively.
370,As future work we plan to study the impact of
371,ing the number of passages weighted ­ here set equal to 10 ­ and the
372,use of our BM25P model in conjunction with BM25F for retrieving
373,semi-structured news articles.
374,Acknowledgements. This paper is supported by the EU H2020 BIGDATAGRAPES
375,REFERENCES
376,"[1] Toine Bogers and Antal van den Bosch. 2007. Comparing and Evaluating Information Retrieval Algorithms for News Recommendation. In Proc. RecSys. ACM, 141­144."
377,[2] Jose M. Chenlo and David E. Losada. 2014. An empirical study of sentence features for subjectivity and polarity classification. Inf. Sc. 280
378,[3] Dipanjan Das and André F.T. Martins. 2007. A survey on automatic text summarization. Lit. Survey for the Lang. and Stat. II course at CMU 4
379,"[4] Chin-Yew Lin. 1999. Training a Selection Function for Extraction. In Proc. CIKM. ACM, 55­62."
380,"[5] Sean MacAvaney, Andrew Yates, Kai Hui, and Ophir Frieder. 2019. Content-Based Weak Supervision for Ad-Hoc Re-Ranking. In SIGIR 2019."
381,"[6] Saket Mengle and Nazli Goharian. 2009. Passage detection using text classification. JASIST 60, 4"
382,"[7] Stephen E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike Gatford. 1996. Okapi at TREC-3. 109­126."
383,"[8] Stephen E. Robertson and Hugo Zaragoza. 2009. The Probabilistic Relevance Framework: BM25 and Beyond. Found. Trends Inf. Retr. 3, 4"
384,"[9] Stephen E. Robertson, Hugo Zaragoza, and Michael Taylor. 2004. Simple BM25 Extension to Multiple Weighted Fields. In Proc. CIKM. ACM, 42­49."
385,"[10] Gerard Salton, James Allan, and Chris Buckley. 1993. Approaches to Passage Retrieval in Full Text Information Systems. In Proc. SIGIR. ACM, 49­58."
386,"[11] Mark D. Smucker, James Allan, and Ben Carterette. 2007. A Comparison of Statistical Significance Tests for Information Retrieval Evaluation. In Proc. CIKM. ACM, 623­632."
387,"[12] Anastasios Tombros and Mark Sanderson. 1998. Advantages of Query Biased Summaries in Information Retrieval. In Proc. SIGIR. ACM, 2­10."
388,
389,1272
390,
391,
