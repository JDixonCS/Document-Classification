,sentence,label,data
,,,
0,Short Research Papers 2B: Recommendation and Evaluation,null,null
,,,
1,,null,null
,,,
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
3,,null,null
,,,
4,Text Retrieval Priors for Bayesian Logistic Regression,null,null
,,,
5,,null,null
,,,
6,Eugene Yang,null,null
,,,
7,"IR Lab, Georgetown University Washington, DC, USA",null,null
,,,
8,eugene@ir.cs.georgetown.edu,null,null
,,,
9,,null,null
,,,
10,David D. Lewis,null,null
,,,
11,"Cyxtera Technologies Dallas, TX, USA",null,null
,,,
12,sigir2019paper@davelewis.com,null,null
,,,
13,,null,null
,,,
14,Ophir Frieder,null,null
,,,
15,"IR Lab, Georgetown University Washington, DC, USA",null,null
,,,
16,ophir@ir.cs.georgetown.edu,null,null
,,,
17,,null,null
,,,
18,ABSTRACT,null,null
,,,
19,"Discriminative learning algorithms such as logistic regression excel when training data are plentiful, but falter when it is meager. An extreme case is text retrieval",null,null
,,,
20,CCS CONCEPTS,null,null
,,,
21,· Information systems  Clustering and classification; · Computing methodologies  Supervised learning by classification; Regularization; · Theory of computation  Bayesian analysis.,null,null
,,,
22,KEYWORDS,null,null
,,,
23,"text classification, regularization, ad hoc retrieval, Bayesian priors, Bayesian logistic regression",null,null
,,,
24,"ACM Reference Format: Eugene Yang, David D. Lewis, and Ophir Frieder. 2019. Text Retrieval Priors for Bayesian Logistic Regression. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",null,null
,,,
25,1 INTRODUCTION,null,null
,,,
26,"Discriminative learning methods such as regularized logistic regression are widely used in applications, such as text categorization, where large amounts of labeled training data are available. When little or no labeled data is available, as in ad hoc retrieval and relevance feedback, heuristics such as BM25, based on domain knowledge",null,null
,,,
27,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331299",null,null
,,,
28,,null,null
,,,
29,"generative approaches dominate at small training set sizes, while discriminative ones dominate for large training sets [8].",null,null
,,,
30,In high recall retrieval,null,null
,,,
31,Our contribution is a deceptively simple synthesis: logistic regression that regularizes toward the coefficient values of a good text retrieval query,null,null
,,,
32,2 BACKGROUND,null,null
,,,
33,"Regularization--the penalization of solutions that deviate from prior expectations--is a key technique for avoiding fitting to accidental properties of data in supervised learning. A common approach is the so-called L2 penalty, which is proportional to the squares of the coefficients",null,null
,,,
34,L2 penalties can be given a Bayesian interpretation [4]. Assume a conditional probability model y = f,null,null
,,,
35,Suppose that the prior is a product of independent univariate gaussian distributions N,null,null
,,,
36,,null,null
,,,
37,p(w|D),null,null
,,,
38,,null,null
,,,
39,=,null,null
,,,
40,,null,null
,,,
41,p,null,null
,,,
42,,null,null
,,,
43,n,null,null
,,,
44,p(yi |w; xi),null,null
,,,
45,i =1,null,null
,,,
46,=,null,null
,,,
47,,null,null
,,,
48,d +1,null,null
,,,
49,,null,null
,,,
50,,null,null
,,,
51,1,null,null
,,,
52,,null,null
,,,
53,e-,null,null
,,,
54,,null,null
,,,
55,(wj -bj 2j 2,null,null
,,,
56,,null,null
,,,
57,)2,null,null
,,,
58,,null,null
,,,
59,j=1 2 j 2,null,null
,,,
60,,null,null
,,,
61,p(D),null,null
,,,
62,,null,null
,,,
63,1045,null,null
,,,
64,,null,null
,,,
65,Short Research Papers 2B: Recommendation and Evaluation,null,null
,,,
66,,null,null
,,,
67,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
68,,null,null
,,,
69,"where p(D|w) is the conditional probability of seeing the y values given the corresponding x's, and p(D) is the unconditional probability.",null,null
,,,
70,"When d is large, as in information retrieval, we typically ask algorithms to produce the MAP",null,null
,,,
71,,null,null
,,,
72,n,null,null
,,,
73,,null,null
,,,
74,d,null,null
,,,
75,,null,null
,,,
76,,null,null
,,,
77,,null,null
,,,
78,w,null,null
,,,
79,,null,null
,,,
80,=,null,null
,,,
81,,null,null
,,,
82,argmax,null,null
,,,
83,,null,null
,,,
84,,null,null
,,,
85,,null,null
,,,
86,-,null,null
,,,
87,,null,null
,,,
88,ln p(yi |w; xi) +,null,null
,,,
89,,null,null
,,,
90,j,null,null
,,,
91,,null,null
,,,
92,w,null,null
,,,
93,,null,null
,,,
94,,null,null
,,,
95,,null,null
,,,
96,i =1,null,null
,,,
97,,null,null
,,,
98,j =1,null,null
,,,
99,,null,null
,,,
100,,null,null
,,,
101,,null,null
,,,
102,,null,null
,,,
103,,null,null
,,,
104,,null,null
,,,
105,,null,null
,,,
106,"where bj is the prior mode for coefficient j, and j is inversely",null,null
,,,
107,,null,null
,,,
108,proportional to the standard deviation of the prior on coefficient j.,null,null
,,,
109,,null,null
,,,
110,The usual L2 penalization scheme corresponds to an assumption,null,null
,,,
111,,null,null
,,,
112,that all coefficients will be small,null,null
,,,
113,,null,null
,,,
114,that smallness is the same for all coefficients,null,null
,,,
115,,null,null
,,,
116,"deviation, and thus penalty).",null,null
,,,
117,,null,null
,,,
118,"Some studies have relaxed these assumptions. Dayanik, et al [3]",null,null
,,,
119,,null,null
,,,
120,used IDF,null,null
,,,
121,,null,null
,,,
122,from a category corpus to set the mode or standard deviation of,null,null
,,,
123,,null,null
,,,
124,Bayesian priors on coefficients of a logistic regression model. In,null,null
,,,
125,,null,null
,,,
126,"more recent work, we used keyword queries with no category",null,null
,,,
127,,null,null
,,,
128,corpus to set modes,null,null
,,,
129,,null,null
,,,
130,[15].,null,null
,,,
131,,null,null
,,,
132,Several authors have proposed first training a generative model,null,null
,,,
133,,null,null
,,,
134,"such as Naive Bayes or Rocchio, and then using the resulting co-",null,null
,,,
135,,null,null
,,,
136,efficients as a prior or parameter space constraint on training a,null,null
,,,
137,,null,null
,,,
138,"logistic regression model [6, 17]. This method has questionable",null,null
,,,
139,,null,null
,,,
140,"statistical foundations when applied to a single training set, but is",null,null
,,,
141,,null,null
,,,
142,more justifiable when applied to multiple training sets in transfer,null,null
,,,
143,,null,null
,,,
144,learning [9].,null,null
,,,
145,,null,null
,,,
146,3 IDF-BASED REGULARIZATION,null,null
,,,
147,Modern term weighting schemes such as BM25 [11] were developed to deal with the ultimate low-data scenario: ranked retrieval with no training data. We suggest this provides a simpler alternative than past approaches for incorporating domain knowledge in supervised learning for text analytics problems.,null,null
,,,
148,"The notion of IDF weighting is key. Justifications for IDF weighting of query terms fall into two major classes [10], and give a new perspective on Dayanik's methods for constructing priors [3]. In probabilistic IR models, IDF weights appear as the coefficients of a generative learning model",null,null
,,,
149,"In contrast, information-theoretic interpretations of IDF view rare terms as being more informative about relevance. This view suggests that less training data should be required to produce a large coefficient for high IDF terms than low IDF terms. In other words, priors for high IDF terms should have a higher variance, regardless of their mode. This translates to a smaller penalty on coefficient magnitude.",null,null
,,,
150,"Based on these perspectives, we tested the following four schemes for determining priors:",null,null
,,,
151,· UPQM: Uniform penalty,null,null
,,,
152,,null,null
,,,
153,"where QT F is the number of occurrences of the term in the keyword query. When each term occurs only once, this is identical to Dayanik's Mode method [3]. · UPQIM: Uniform penalty. Prior mode equal to a BM25 query. Similar to Dayanik's Mode/TFIDF method, but requiring only a single query, not a corpus of queries or category descriptions. · IIPQM: Inverse IDF penalty: penalty is inversely proportional to IDF. QTF modes. · IIPQIM: Inverse IDF penalty and BM25 modes.",null,null
,,,
154,"Using the same notation, we refer to conventional L2 regularization, with a uniform penalty toward zero modes, as UPZM.",null,null
,,,
155,"Our four methods leave three prior values unspecified: the prior mode and penalty for the intercept coefficient of the logistic regression model, and the base prior penalty for term coefficients. The intercept affects only calibration of the model, not ranking, so for these experiments we used a fixed zero mode prior.",null,null
,,,
156,"Choosing a base penalty value, however, is needed both as a uniform penalty for UP methods, and to be divided by IDF values in IIP methods. Dayanik, et al chose their base penalty value by using 10-fold cross-validation [3]. This required a minimum of 10 training examples, and arguably was unstable well above that size. Since priors provide their main benefit for small training sets, we eschewed cross-validation and instead explored a range of base penalty values",null,null
,,,
157,"Our method is easy to implement, since most existing logistic regression code bases support L2 penalties in their optimization code",null,null
,,,
158,4 METHODS,null,null
,,,
159,4.1 Data Sets,null,null
,,,
160,We used two test collections drawn from high recall retrieval research: the Jeb Bush Collection and RCV1-v2.,Y,"Jeb Bush Collection, RCV1-v2"
,,,
161,"The Jeb Bush Collection consists of email to and from a state governor in the United States [12]. It consists of 290,099 files, of which 274,124 are unique based on MD5 hash. The TREC 2015 and 2016 Total Recall Tracks defined a total of 44 topics on the Jeb Bush data and distributed short titles and labeled data for each [5, 12]. The 2016 labels were ternary, so we treated both ""relevant"" and ""important"" as positive and ""non-relevant"" as negative. To ensure enough positive examples for accurate estimation of effectiveness, our experiments used only the 33 topics with at least 160 positive documents. We used the topic title as our keyword query. This provided from one to five keywords per topic.",Y,"TREC, Jeb Bush Collection"
,,,
162,"RCV1-v2 is a widely used text categorization dataset [7]. It consists of 804,414 newswire stories categorized by professional editors. Of the 823 categories, we chose the 82 categories that had at least",Y,RCV1-v2
,,,
163,1 https://github.com/eugene- yang/priorsgd,null,null
,,,
164,,null,null
,,,
165,1046,null,null
,,,
166,,null,null
,,,
167,Short Research Papers 2B: Recommendation and Evaluation,null,null
,,,
168,,null,null
,,,
169,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
170,,null,null
,,,
171,Table 1: Mean testset R-precision for logistic regression variants with base penalty strength of 1.0 and various training set sizes. Percentages are relative improvements of knowledge-based priors over a uniform prior. With no training data,null,null
,,,
172,,null,null
,,,
173,Jeb Bush Collection,Y,Jeb Bush Collection
,,,
174,,null,null
,,,
175,RCV1-v2,null,null
,,,
176,,null,null
,,,
177,Size UPZM UPQM,null,null
,,,
178,,null,null
,,,
179,UPQIM,null,null
,,,
180,,null,null
,,,
181,IIPQM,null,null
,,,
182,,null,null
,,,
183,IIPQIM UPZM UPQM,null,null
,,,
184,,null,null
,,,
185,UPQIM,null,null
,,,
186,,null,null
,,,
187,IIPQM,null,null
,,,
188,,null,null
,,,
189,IIPQIM,null,null
,,,
190,,null,null
,,,
191,0,null,null
,,,
192,,null,null
,,,
193,0.5 34.6,null,null
,,,
194,,null,null
,,,
195,1 13.1 37.9,null,null
,,,
196,,null,null
,,,
197,2 13.1 29.6,null,null
,,,
198,,null,null
,,,
199,4 17.3 33.2,null,null
,,,
200,,null,null
,,,
201,8 22.9 36.9,null,null
,,,
202,,null,null
,,,
203,16 29.8 42.1,null,null
,,,
204,,null,null
,,,
205,32 38.3 47.6,null,null
,,,
206,,null,null
,,,
207,64 47.3 53.5,null,null
,,,
208,,null,null
,,,
209,128 55.2 59.7,null,null
,,,
210,,null,null
,,,
211,63.0 63.8,null,null
,,,
212,,null,null
,,,
213,"10,000 positive documents with an eye toward future studies of variation across training sets. Each category has a Reuters Business Briefing",null,null
,,,
214,"Text processing simply replaced punctuation with whitespace, and then formed tokens at whitespace boundaries. We used BM25 within document weights, i.e. saturated TF weights.",Y,BM25
,,,
215,4.2 Evaluation,null,null
,,,
216,"The impact of prior knowledge depends on training set size. As usual in supervised learning research, we nested smaller training sets in larger ones. Training sets of size 1 consisted of a single randomly selected positive example. Larger training sets",null,null
,,,
217,"Variability in effectiveness between training sets is high for small training sets and low richness. To produce more stable results for the Jeb Bush collection we averaged across ten randomly drawn training sets of 128 documents and their included balanced subsets. With the larger number, and higher richness, of categories for RCV1-v2 averaging over replicates was less necessary for stability",null,null
,,,
218,"Documents were ranked by logistic regression scores, with ties",null,null
,,,
219,5 RESULTS AND ANALYSIS,null,null
,,,
220,"We compare our four methods with two baselines: a BM25 query formed from the keyword query for each topic, and UPZM logistic regression. Text retrieval baselines are rarely used in research on",Y,BM25
,,,
221,,null,null
,,,
222,"Figure 1: Mean test set R-precision for training sets of size 1 and 128, as a function of the base regularization penalty",null,null
,,,
223,"domain knowledge in supervised learning, but should be. As Table 1 shows, BM25",null,null
,,,
224,"Table 1 shows the mean R-precision values for each of our four methods plus UPZM, all with a base penalty of 1.0",null,null
,,,
225,5.1 Choosing the Base Penalty,null,null
,,,
226,"Figure 1 shows the impact of varying the base penalty value for each of the supervised methods, on training sets of size 1 and 128",null,null
,,,
227,,null,null
,,,
228,1047,null,null
,,,
229,,null,null
,,,
230,Short Research Papers 2B: Recommendation and Evaluation,null,null
,,,
231,,null,null
,,,
232,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
233,,null,null
,,,
234,"Figure 2: A heatmap display of the interaction between base penalty strength and training set size, both with log2 scaling, for UPZM and IIPQM on Jeb Bush. Lighter cells indicate higher average R-precision. Colors are scaled row-by-row, so that lighter",Y,Jeb Bush
,,,
235,colors indicate dominance for that training set size across both algorithms and all penalties.,null,null
,,,
236,,null,null
,,,
237,from the Jeb Bush data. We see classical regularization curves with maximum effectiveness at intermediate regularization strengths.,Y,Jeb Bush
,,,
238,Training on a single positive example provides insight into the methods. At high penalties,null,null
,,,
239,The joint relationship between training set size and base penalty strength is shown in Figure 2. We use a heatmap to compare UPZM and IIPQM for all penalty strengths and training set sizes,null,null
,,,
240,"We see that UPZM is dominated under almost all conditions. The IIPQM results show that a base penalization in the range 2-4 to 24 provides good average effectiveness across all training set sizes. Examining the averaged RCV1-v2 data shows a similar ""ridge of light."" Per-category data on both datasets shows this range of penalties is optimal for most individual categories as well.",null,null
,,,
241,6 FUTURE WORK,null,null
,,,
242,"Our experiments examined the generalization behavior of IDFbased priors under controlled variations in base penalty strength and training set size. Operational HRR scenarios are more complex. First, a variety of active learning algorithms and batch size schemes are used to iteratively generate training sets [2]. Second, an HRR dataset is both the source of training data and the target of prioritization, so that documents that are labeled no longer need to be scored. Both factors will require experimentation to understand in full.",null,null
,,,
243,The success of inverse IDF regularization penalties when keywords are available suggests using this technique even without,null,null
,,,
244,,null,null
,,,
245,"prior knowledge. IDF weighting has been used in application areas as diverse as images, video, music, and genomic data, so the technique may have broad applicability.",null,null
,,,
246,7 CONCLUSION,null,null
,,,
247,"Regularized logistic regression is a standard workhorse for machine learning, but has faltered when applied to tiny training sets. We show that its effectiveness can be improved under all conditions, and vastly for small training sets, by IDF-based priors.",null,null
,,,
248,REFERENCES,null,null
,,,
249,"[1] Mustafa Abualsaud, Nimesh Ghelani, Haotian Zhang, Mark D Smucker, Gordon V Cormack, and Maura R Grossman. 2018. A System for Efficient High-Recall Retrieval.. In SIGIR. 1317­1320.",null,null
,,,
250,[2] Gordon F. Cormack and Maura F. Grossman. 2014. Evaluation of machinelearning protocols for technology-assisted review in electronic discovery. SIGIR 2014,null,null
,,,
251,"[3] Aynur Dayanik, David D Lewis, David Madigan, Vladimir Menkov, and Alexander Genkin. 2006. Constructing informative prior distributions from domain knowledge in text classification. In SIGIR 2006. ACM.",null,null
,,,
252,"[4] Alexander Genkin, David D. Lewis, and David Madigan. 2007. Large-Scale Bayesian Logistic Regression for Text Categorization. Technometrics 49, 3",null,null
,,,
253,"[5] Maura R. Grossman, Gordon V. Cormack, and Adam Roegiest. 2016. TREC 2016 Total Recall Track Overview.",null,null
,,,
254,[6] David D. Lewis and William A Gale. 1994. A sequential algorithm for training text classifiers. In SIGIR 1994. 3­12.,null,null
,,,
255,"[7] David D. Lewis, Yiming Yang, Tony G. Rose, and Fan Li. 2004. RCV1: A New Benchmark Collection for Text Categorization Research. JMLR 5",null,null
,,,
256,[8] Andrew Y Ng and Michael I Jordan. 2002. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In Advances in neural information processing systems. 841­848.,null,null
,,,
257,"[9] Sinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Transactions on knowledge and data engineering 22, 10",null,null
,,,
258,"[10] Stephen Robertson. 2004. Understanding inverse document frequency: on theoretical arguments for IDF. JDoc 60, 5",null,null
,,,
259,"[11] Stephen Robertson and Hugo Zaragoza. 2009. The probabilistic relevance framework: BM25 and beyond. F&T in IR 3, 4",null,null
,,,
260,[12] Adam Roegiest and Gordon V. Cormack. 2015. TREC 2015 Total Recall Track Overview.,null,null
,,,
261,[13] Harrisen Scells and Guido Zuccon. 2018. Generating Better Queries for Systematic Reviews.. In SIGIR. 475­484.,null,null
,,,
262,[14] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning: From theory to algorithms. Cambridge university press.,null,null
,,,
263,"[15] Eugene Yang, David D. Lewis, and Ophir Frieder. 2019. A Regularization Approach to Combining Keywords and Training Data in Technology-Assisted Review. In ICAIL 2019. Montreal, Canada.",null,null
,,,
264,"[16] Eugene Yang, David D. Lewis, Ophir Frieder, David Grossman, and Roman Yurchak. 2018. Retrieval and Richness when Querying by Document. DESIRES",null,null
,,,
265,"[17] Yi Zhang. 2004. Using bayesian priors to combine classifiers for adaptive filtering. In SIGIR 2004. ACM, 345­352.",null,null
,,,
266,,null,null
,,,
267,1048,null,null
,,,
268,,null,null
,,,
269,,null,null
