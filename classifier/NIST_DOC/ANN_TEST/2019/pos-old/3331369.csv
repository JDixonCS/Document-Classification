,sentence,label,data
0,Short Research Papers 3C: Search,null,null
1,,null,null
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
3,,null,null
4,ery Performance Prediction for Pseudo-Feedback-Based Retrieval,null,null
5,,null,null
6,Haggai Roitman,null,null
7,IBM Research ­ Haifa haggai@il.ibm.com,null,null
8,ABSTRACT,null,null
9,The query performance prediction task,null,null
10,ACM Reference Format: Haggai Roitman and Oren Kurland. 2019. Query Performance Prediction for Pseudo-Feedback-Based Retrieval. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,null,null
11,1 INTRODUCTION,null,null
12,The query performance prediction task,null,null
13,"We address the QPP challenge for a di erent, common, retrieval paradigm: pseudo-feedback-based retrieval [3]. That is, an initial search is performed for a query. Then, top-retrieved documents, considered pseudo relevant, are utilized to induce a query model",null,null
14,"Thus, in contrast to the single-retrieval setting addressed in almost all prior work on QPP, here the e ectiveness of the nal result list presented to the user depends not only on the retrieval used to produce it",null,null
15,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331369",null,null
16,,null,null
17,Oren Kurland,null,null
18,Technion ­ Israel Institute of Technology kurland@ie.technion.ac.il,null,null
19,"that the nal result list will be e ective regardless of the querymodel induction approach employed. Accordingly, our novel approach for QPP for pseudo-feedback-based retrieval accounts for the presumed e ectiveness of the initially retrieved list, its association with the nal retrieved list and properties of the latter.",null,null
20,"Empirical evaluation shows that the prediction quality of our approach substantially transcends that of state-of-the-art prediction methods adopted for the pseudo-feedback-based retrieval setting -- the practice in prior work on QPP for pseudo-feedback-based retrieval [6, 14, 15].",null,null
21,2 RELATED WORK,null,null
22,"In prior work on QPP for pseudo-feedback-based retrieval, existing predictors were applied either to the nal retrieved list [6, 14] or to the initially retrieved list [15]. We show that our prediction model, which incorporates prediction for both lists and accounts for their association, substantially outperforms these prior approaches.",null,null
23,The selective query expansion task,null,null
24,"In several prediction methods, a result list retrieved using a pseudofeedback-based query model is used to predict the performance of the initially retrieved list [15, 20]. In contrast, our goal is to predict the e ectiveness of the nal result list; to that end, we also use prediction performed for the initial list.",null,null
25,3 PREDICTION FRAMEWORK,null,null
26,Suppose that some initial search is applied in response to a query q over a document corpus D. Let Dinit be the list of the k most highly ranked documents. Information induced from the top documents in Dinit is used for creating a new query model,null,null
27,"Our goal is to predict the e ectiveness of Dscnd . To this end, we appeal to a recently proposed query performance prediction",null,null
28,"We can use reference document lists to derive an estimate for p(Dscnd |q, r ) [16]:",null,null
29,"1This is post-retrieval prediction which relies on analyzing the retrieved list. The relevance of a retrieved list is a notion that generalizes that for a single document [16]. At the operational level, a binary relevance judgment for a list can be obtained by thresholding any list-based evaluation measure.",null,null
30,,null,null
31,1261,null,null
32,,null,null
33,Short Research Papers 3C: Search,null,null
34,,null,null
35,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
36,,null,null
37,p^(Dsc,null,null
38,,null,null
39,nd,null,null
40,,null,null
41,"|q,",null,null
42,,null,null
43,r,null,null
44,,null,null
45,),null,null
46,,null,null
47,def,null,null
48,=,null,null
49,,null,null
50,"p^(Dscnd |q, L, r )p^(L|q, r );",null,null
51,,null,null
52,(1),null,null
53,,null,null
54,L,null,null
55,,null,null
56,"L is a document list retrieved for q; herein, p^ is an estimate for p. The underlying idea is that strong association",null,null
57,"It was shown that numerous existing post-retrieval prediction methods can be instantiated from Equation 1 where a single reference list is used. Similarly, here we use Dinit as a reference list:",null,null
58,,null,null
59,"p^(Dscnd |q, r )  p^(Dscnd |q, Dinit , r )p^(Dinit |q, r ).",null,null
60,,null,null
61,(2),null,null
62,,null,null
63,"That is, by the virtue of the way Dscnd is created -- i.e., using information induced from Dinit -- we assume that Dinit is the",null,null
64,"most informative reference list with respect to Dscnd 's e ectiveness. A case in point, an expanded query constructed from a poor",null,null
65,,null,null
66,initial list,null,null
67,,null,null
68,not likely to result in e ective retrieval.,null,null
69,,null,null
70,3.1 Instantiating Predictors,null,null
71,,null,null
72,"Equation 2 can be instantiated in various ways, based on the choice",null,null
73,,null,null
74,"of estimates, to yield a speci c prediction method. To begin with,",null,null
75,,null,null
76,"any post-retrieval predictor, P, can be used to derive p^(Dinit |q, r )",null,null
77,,null,null
78,[16].,null,null
79,,null,null
80,"For p^(Dscnd |q, Dinit , r ) in Equation 2, we use logarithmic inter-",null,null
81,,null,null
82,polation:,null,null
83,,null,null
84,p^(D s c n d,null,null
85,,null,null
86,"|q,",null,null
87,,null,null
88,Dini,null,null
89,,null,null
90,"t,",null,null
91,,null,null
92,r,null,null
93,,null,null
94,),null,null
95,,null,null
96,def,null,null
97,=,null,null
98,,null,null
99,"p^[P](Dscnd |q, r ) p^(Dscnd |Dinit , r )(1- );",null,null
100,,null,null
101,(3),null,null
102,,null,null
103,"( [0, 1]) is a free parameter. The estimate p^[P](Dscnd |q, r ) corre-",null,null
104,,null,null
105,"sponds to the predicted e ectiveness of Dscnd , where the predic-",null,null
106,,null,null
107,"tion, performed using the post-retrieval predictor P, ignores the",null,null
108,,null,null
109,knowledge that Dscnd was produced using information induced from Dinit .,null,null
110,"The estimate p^(Dscnd |Dinit , r ) from Equation 3, of the association between Dscnd and Dinit , is usually devised based on some symmetric inter-list similarity measure sim(Dscnd , Dinit ) [16]. However, as Roitman [11] has recently suggested, a more e ective esti-",null,null
111,,null,null
112,mate can be derived by exploiting the asymmetric co-relevance rela-,null,null
113,,null,null
114,tionship between the two lists,null,null
115,,null,null
116,is the likelihood of Dscnd given that a relevance event has hap-,null,null
117,,null,null
118,pened and Dinit was observed:,null,null
119,,null,null
120,p^(D s c nd,null,null
121,,null,null
122,|Dinit,null,null
123,,null,null
124,",",null,null
125,,null,null
126,r,null,null
127,,null,null
128,),null,null
129,,null,null
130,def,null,null
131,=,null,null
132,,null,null
133,p^(D s c nd,null,null
134,,null,null
135,|Dinit,null,null
136,,null,null
137,),null,null
138,,null,null
139,d,null,null
140,,null,null
141,Dscnd,null,null
142,,null,null
143,p^(d,null,null
144,,null,null
145,|Dscnd,null,null
146,,null,null
147,) p^(d,null,null
148,,null,null
149,"p^(d, r |Dinit",null,null
150,,null,null
151,|Dinit ) )p^(r |Dinit,null,null
152,,null,null
153,),null,null
154,,null,null
155,;,null,null
156,,null,null
157,(4),null,null
158,,null,null
159,d,null,null
160,,null,null
161,is,null,null
162,,null,null
163,a,null,null
164,,null,null
165,document.,null,null
166,,null,null
167,Following,null,null
168,,null,null
169,Roitman,null,null
170,,null,null
171,"[11],",null,null
172,,null,null
173,we,null,null
174,,null,null
175,use,null,null
176,,null,null
177,p^(D s c nd,null,null
178,,null,null
179,|Dinit,null,null
180,,null,null
181,),null,null
182,,null,null
183,def,null,null
184,=,null,null
185,,null,null
186,"sim(Dscnd , Dinit ). Similarly to some prior work [7, 11], for p^(r |Dinit )",null,null
187,,null,null
188,we use the entropy of the centroid,null,null
189,,null,null
190,"language models of documents in Dinit . We further assume that p^(d |Dscnd ) and p^(d |Dinit ) are uniformly distributed over Dscnd and Dinit , respectively. Finally, to derive p^(d, r |Dinit ), we follow",null,null
191,Roitman [11] and use the corpus-based regularized cross entropy,null,null
192,,null,null
193,"(CE) between a relevance model, R [Dinit ], induced from Dinit , and",null,null
194,,null,null
195,"a language model, pd",null,null
196,,null,null
197,"p^(d, r |Dinit )",null,null
198,,null,null
199,def,null,null
200,=,null,null
201,,null,null
202,CE(R [Dinit ] ||pd,null,null
203,,null,null
204,(5),null,null
205,,null,null
206,p^D,null,null
207,,null,null
208,4 EVALUATION,null,null
209,4.1 Experimental setup,null,null
210,4.1.1 Datasets. We used for evaluation the following TREC corpora and topics: WT10g,null,null
211,,null,null
212,4.1.2 Pseudo-feedback based retrieval. Let cx,null,null
213,,null,null
214,currence,null,null
215,,null,null
216,count,null,null
217,,null,null
218,of,null,null
219,,null,null
220,a,null,null
221,,null,null
222,term,null,null
223,,null,null
224,w,null,null
225,,null,null
226,in,null,null
227,,null,null
228,a,null,null
229,,null,null
230,text,null,null
231,,null,null
232,(or,null,null
233,,null,null
234,text,null,null
235,,null,null
236,collection),null,null
237,,null,null
238,x,null,null
239,,null,null
240,;,null,null
241,,null,null
242,let,null,null
243,,null,null
244,|x,null,null
245,,null,null
246,|,null,null
247,,null,null
248,def,null,null
249,=,null,null
250,,null,null
251,w x,null,null
252,,null,null
253,cx,null,null
254,,null,null
255,denote,null,null
256,,null,null
257,x 's,null,null
258,,null,null
259,length.,null,null
260,,null,null
261,Let,null,null
262,,null,null
263,px[µ ],null,null
264,,null,null
265,def,null,null
266,=,null,null
267,,null,null
268,cx,null,null
269,,null,null
270,de-,null,null
271,,null,null
272,note,null,null
273,,null,null
274,x 's,null,null
275,,null,null
276,Dirichlet-smoothed,null,null
277,,null,null
278,language,null,null
279,,null,null
280,"model,",null,null
281,,null,null
282,where pD,null,null
283,,null,null
284,def,null,null
285,=,null,null
286,,null,null
287,c,null,null
288,,null,null
289,D,null,null
290,,null,null
291,),null,null
292,,null,null
293,.,null,null
294,,null,null
295,For,null,null
296,,null,null
297,a,null,null
298,,null,null
299,query q,null,null
300,,null,null
301,and a,null,null
302,,null,null
303,set of,null,null
304,,null,null
305,pseudo-relevant,null,null
306,,null,null
307,documents F,null,null
308,,null,null
309,,null,null
310,,null,null
311,"Dinit , pF",null,null
312,,null,null
313,We use three state-of-the-art pseudo-feedback-based,null,null
314,,null,null
315,model induction methods. All three incorporate query anchoring,null,null
316,,null,null
317,as described below. The rst is the Relevance Model [8],null,null
318,,null,null
319,pF,null,null
320,,null,null
321,(w,null,null
322,,null,null
323,),null,null
324,,null,null
325,def,null,null
326,=,null,null
327,,null,null
328,pd[0],null,null
329,,null,null
330,(6),null,null
331,,null,null
332,d F,null,null
333,,null,null
334,where,null,null
335,,null,null
336,pq[µ,null,null
337,,null,null
338,],null,null
339,,null,null
340,(d,null,null
341,,null,null
342,),null,null
343,,null,null
344,def,null,null
345,=,null,null
346,,null,null
347,pd[µ ],null,null
348,,null,null
349,and,null,null
350,,null,null
351,pd[µ ],null,null
352,,null,null
353,def,null,null
354,=,null,null
355,,null,null
356,w q cd,null,null
357,,null,null
358,The second is the Generative Mixed Model [19],null,null
359,,null,null
360,estimated using the following EM algorithm iterative update rules:,null,null
361,,null,null
362,t,null,null
363,,null,null
364,(n)(w,null,null
365,,null,null
366,),null,null
367,,null,null
368,def,null,null
369,=,null,null
370,,null,null
371,(1-,null,null
372,,null,null
373,)p,null,null
374,,null,null
375,(n-1) F,null,null
376,,null,null
377,(w,null,null
378,,null,null
379,),null,null
380,,null,null
381,(1-,null,null
382,,null,null
383,)p,null,null
384,,null,null
385,(n-1) F,null,null
386,,null,null
387,(w,null,null
388,,null,null
389,)+,null,null
390,,null,null
391,pD,null,null
392,,null,null
393,(w,null,null
394,,null,null
395,),null,null
396,,null,null
397,",",null,null
398,,null,null
399,pF(n)(w ),null,null
400,,null,null
401,def,null,null
402,=,null,null
403,,null,null
404,d F cd,null,null
405,wV d F cd,null,null
406,,null,null
407,The third is the Maximum-Entropy Divergence Minimization Model [9],null,null
408,,null,null
409,(MEDMM): pF,null,null
410,,null,null
411,1,null,null
412,,null,null
413,d F p^q[µ](d) log pd[0](w) -,null,null
414,,null,null
415,,null,null
416,,null,null
417,p,null,null
418,,null,null
419,D,null,null
420,,null,null
421,(w,null,null
422,,null,null
423,),null,null
424,,null,null
425,.,null,null
426,,null,null
427,We,null,null
428,,null,null
429,applied,null,null
430,,null,null
431,query,null,null
432,,null,null
433,anchoring,null,null
434,,null,null
435,"[8,",null,null
436,,null,null
437,"9,",null,null
438,,null,null
439,19],null,null
440,,null,null
441,to,null,null
442,,null,null
443,all,null,null
444,,null,null
445,three,null,null
446,,null,null
447,models:,null,null
448,,null,null
449,pF,null,null
450,,null,null
451,",",null,null
452,,null,null
453,,null,null
454,,null,null
455,(w,null,null
456,,null,null
457,),null,null
458,,null,null
459,def,null,null
460,=,null,null
461,,null,null
462,pqMLE,null,null
463,,null,null
464,"timate of w with respect to q and   [0, 1].",null,null
465,,null,null
466,We used the n most highly ranked documents in the initial re-,null,null
467,,null,null
468,trieval for query-model induction,null,null
469,ond query qf was formed using the l terms w assigned the highest pF,null,null
470,,null,null
471,"4.1.3 Baseline predictors. As a rst line of baselines, we use Clarity [4], WIG [20] and NQC [17], which are commonly used post-retrieval QPP methods [2]. These baselines are also used for P in Eq. 3. Clarity [4] is the divergence between a language model induced from a retrieved list and that induced from the corpus.",null,null
472,,null,null
473,2 http://lucene.apache.org 3Expressed in Lucene's query parser syntax as: w1^pF,null,null
474,,null,null
475,1262,null,null
476,,null,null
477,Short Research Papers 3C: Search,null,null
478,,null,null
479,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
480,,null,null
481,Table 1: Prediction quality. Boldface: best results per basic QPP method and query-model induction method. Underlined: best results per query-model induction method. '' marks a statistically signi cant di erence between PFR-QPP and either the second best predictor,null,null
482,,null,null
483,Method,null,null
484,ListSim,null,null
485,NQC(Dscnd |qf ) NQC(Dscnd |q) NQC(Dinit |q) RefList(NQC) PFR-QPP(NQC),null,null
486,Clarity(Dscnd |qf ) Clarity(Dscnd |q) Clarity(Dinit |q) RefList(Clarity) PFR-QPP(Clarity),null,null
487,WIG(Dscnd |qf ) WIG(Dscnd |q) WIG(Dinit |q) RefList(WIG) PFR-QPP(WIG),null,null
488,WEG(Dscnd |qf ) WEG(Dscnd |q) WEG(Dinit |q) RefList(WEG) PFR-QPP(WEG),null,null
489,,null,null
490,RM,null,null
491,.442,null,null
492,.293 .071 .483 .535 .513,null,null
493,.292 .327 .363 .481 .408,null,null
494,.270 .253 .237 .338 .370,null,null
495,.231 .141 .353 .443 .456,null,null
496,,null,null
497,WT10g,null,null
498,,null,null
499,GMM MEDMM,null,null
500,,null,null
501,.532,null,null
502,,null,null
503,.337,null,null
504,,null,null
505,.228,null,null
506,,null,null
507,.182,null,null
508,,null,null
509,.051,null,null
510,,null,null
511,.092,null,null
512,,null,null
513,.397,null,null
514,,null,null
515,.424,null,null
516,,null,null
517,.531,null,null
518,,null,null
519,.415,null,null
520,,null,null
521,.557,null,null
522,,null,null
523,.410,null,null
524,,null,null
525,.325,null,null
526,,null,null
527,.316,null,null
528,,null,null
529,.227,null,null
530,,null,null
531,.368,null,null
532,,null,null
533,.350,null,null
534,,null,null
535,.314,null,null
536,,null,null
537,.567 .557,null,null
538,,null,null
539,.388 .398,null,null
540,,null,null
541,.307,null,null
542,,null,null
543,.388,null,null
544,,null,null
545,.105,null,null
546,,null,null
547,.153,null,null
548,,null,null
549,.221,null,null
550,,null,null
551,.224,null,null
552,,null,null
553,.384 .466,null,null
554,,null,null
555,.311 .353,null,null
556,,null,null
557,.205,null,null
558,,null,null
559,.331,null,null
560,,null,null
561,.134,null,null
562,,null,null
563,.239,null,null
564,,null,null
565,.311,null,null
566,,null,null
567,.313,null,null
568,,null,null
569,.483 .575,null,null
570,,null,null
571,.371 .436,null,null
572,,null,null
573,RM,null,null
574,.490,null,null
575,.599 .437 .486 .517 .596,null,null
576,.230 .278 .282 .480 .615,null,null
577,.263 .583 .562 .581 .630,null,null
578,.585 .513 .532 .527 .660,null,null
579,,null,null
580,GOV2,null,null
581,,null,null
582,GMM MEDMM,null,null
583,,null,null
584,.432,null,null
585,,null,null
586,.410,null,null
587,,null,null
588,.545,null,null
589,,null,null
590,.353,null,null
591,,null,null
592,.418,null,null
593,,null,null
594,.283,null,null
595,,null,null
596,.414,null,null
597,,null,null
598,.414,null,null
599,,null,null
600,.486,null,null
601,,null,null
602,.457,null,null
603,,null,null
604,.549 .550,null,null
605,,null,null
606,.157,null,null
607,,null,null
608,.130,null,null
609,,null,null
610,.200,null,null
611,,null,null
612,.084,null,null
613,,null,null
614,.261,null,null
615,,null,null
616,.264,null,null
617,,null,null
618,.469 .497,null,null
619,,null,null
620,.414 .490,null,null
621,,null,null
622,.301,null,null
623,,null,null
624,.448,null,null
625,,null,null
626,.424,null,null
627,,null,null
628,.276,null,null
629,,null,null
630,.498,null,null
631,,null,null
632,.498,null,null
633,,null,null
634,.562 .603,null,null
635,,null,null
636,.480 .575,null,null
637,,null,null
638,.548,null,null
639,,null,null
640,.432,null,null
641,,null,null
642,.504,null,null
643,,null,null
644,.390,null,null
645,,null,null
646,.470,null,null
647,,null,null
648,.409,null,null
649,,null,null
650,.481 .562,null,null
651,,null,null
652,.427 .481,null,null
653,,null,null
654,RM,null,null
655,.543,null,null
656,.653 .475 .635 .654 .671,null,null
657,.450 .412 .452 .582 .589,null,null
658,.424 .651 .649 .660 .665,null,null
659,.661 .566 .635 .654 .688,null,null
660,,null,null
661,ROBUST,null,null
662,,null,null
663,GMM MEDMM,null,null
664,,null,null
665,.528,null,null
666,,null,null
667,.436,null,null
668,,null,null
669,.637,null,null
670,,null,null
671,.622,null,null
672,,null,null
673,.492,null,null
674,,null,null
675,.620,null,null
676,,null,null
677,.605,null,null
678,,null,null
679,.602,null,null
680,,null,null
681,.631 .661,null,null
682,,null,null
683,.621 .642,null,null
684,,null,null
685,.393,null,null
686,,null,null
687,.409,null,null
688,,null,null
689,.350,null,null
690,,null,null
691,.349,null,null
692,,null,null
693,.441,null,null
694,,null,null
695,.401,null,null
696,,null,null
697,.575 .607,null,null
698,,null,null
699,.535 .566,null,null
700,,null,null
701,.361,null,null
702,,null,null
703,.381,null,null
704,,null,null
705,.455,null,null
706,,null,null
707,.430,null,null
708,,null,null
709,.618,null,null
710,,null,null
711,.578,null,null
712,,null,null
713,.638 .682,null,null
714,,null,null
715,.637 .648,null,null
716,,null,null
717,.656,null,null
718,,null,null
719,.693,null,null
720,,null,null
721,.571,null,null
722,,null,null
723,.674,null,null
724,,null,null
725,.619,null,null
726,,null,null
727,.616,null,null
728,,null,null
729,.633 .664,null,null
730,,null,null
731,.632 .688,null,null
732,,null,null
733,RM,null,null
734,.537,null,null
735,.655 .574 .550 .607 .670,null,null
736,.313 .236 .320 .589 .652,null,null
737,.159 .414 .554 .639 .650,null,null
738,.627 .560 .526 .580 .675,null,null
739,,null,null
740,AP GMM,null,null
741,.343,null,null
742,.617 .479 .536 .530 .640,null,null
743,.408 .350 .456 .519 .585,null,null
744,.281 .281 .614 .580 .634,null,null
745,.562 .491 .474 .467 .552,null,null
746,,null,null
747,MEDMM,null,null
748,.407,null,null
749,.454 .530 .502 .572 .650,null,null
750,.339 .270 .308 .511 .651,null,null
751,.285 .226 .505 .608 .643,null,null
752,.575 .575 .518 .555 .664,null,null
753,,null,null
754,WIG [20] and NQC [17] are the corpus-regularized4 mean and,null,null
755,"standard deviation of retrieval scores in the list, respectively. We",null,null
756,further compare with the Weighted Expansion Gain,null,null
757,­ a WIG alternative which regularizes with the mean score of doc-,null,null
758,uments at low ranks of the retrieved list instead of the corpus.,null,null
759,We use three variants of each of the four predictors described,null,null
760,above. The rst two directly predict the e ectiveness of the nal,null,null
761,retrieved list Dscnd using either,null,null
762,To evaluate the impact of our inter-list association measure in,null,null
763,"Eq. 4, we use two additional baselines. The rst, denoted ListSim",null,null
764,"[16], uses sim(Dscnd , Dinit ) to predict the performance of Dscnd . The second, denoted RefList(P) [7, 16], treats Dinit as a pseudoe ective list of Dscnd and estimates Dscnd 's performance by:",null,null
765,,null,null
766,p^Re,null,null
767,,null,null
768,f,null,null
769,,null,null
770,Li,null,null
771,,null,null
772,st,null,null
773,,null,null
774,(r,null,null
775,,null,null
776,|Dscnd,null,null
777,,null,null
778,",",null,null
779,,null,null
780,q),null,null
781,,null,null
782,def,null,null
783,=,null,null
784,,null,null
785,"sim(Dscnd , Dinit )p^[P](Dinit |q, r ),",null,null
786,,null,null
787,"where P is one of the four basic QPP methods described above. There are two important di erences between our proposed method and RefList. First, we use the query q in the list association measure in Eq. 3. Second, we use an asymmetric co-relevance measure between the two lists in Eq. 4 compared to the symmetric one used in RefList.",null,null
788,,null,null
789,"4.1.4 Setup. Hereinafter, we refer to our proposed QPP method from Eq. 2 as PFR-QPP: Pseudo-Feedback based Retrieval QPP.",null,null
790,,null,null
791,"4To this end, the corpus is treated as one large document.",null,null
792,,null,null
793,PFR-QPP(P) is a speci c predictor instantiated using the base predictor P. We predict for each query the e ectiveness of the 1000 documents,null,null
794,"Most prediction methods described above incorporate free parameters. Following the common practice [2], we set m  k ­ the number of documents in a given list",null,null
795,"Following [12, 17], we trained and tested all methods using a 2-fold cross validation approach. Speci cally, in each dataset, we generated 30 random splits of the query set; each split had two folds. We used the rst fold as the",null,null
796,,null,null
797,1263,null,null
798,,null,null
799,Short Research Papers 3C: Search,null,null
800,,null,null
801,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
802,,null,null
803,Pearson,null,null
804,,null,null
805,NQC,null,null
806,0.7,null,null
807,,null,null
808,0.6,null,null
809,,null,null
810,0.5,null,null
811,,null,null
812,0.4,null,null
813,,null,null
814,0.3 0,null,null
815,,null,null
816,0.2 0.4 0.6 0.8,null,null
817,,null,null
818,WIG,null,null
819,0.7,null,null
820,,null,null
821,0.6,null,null
822,,null,null
823,0.5,null,null
824,,null,null
825,0.4,null,null
826,,null,null
827,0.3 0,null,null
828,,null,null
829,0.2 0.4 0.6 0.8,null,null
830,,null,null
831,Pearson,null,null
832,,null,null
833,Pearson,null,null
834,,null,null
835,0.7 0.6 0.5 0.4 0.3,null,null
836,0,null,null
837,0.7 0.6 0.5 0.4 0.3,null,null
838,0,null,null
839,,null,null
840,Clarity,null,null
841,0.2 0.4 0.6 0.8,null,null
842,WEG,null,null
843,0.2 0.4 0.6 0.8,null,null
844,,null,null
845,Pearson,null,null
846,,null,null
847,Pearson,null,null
848,,null,null
849,NQC,null,null
850,0.7 0.6 0.5 0.4 0.3,null,null
851,10 30 50 70 90 l,null,null
852,WIG,null,null
853,0.7 0.6 0.5 0.4 0.3,null,null
854,10 30 50 70 90 l,null,null
855,,null,null
856,Pearson,null,null
857,,null,null
858,Pearson,null,null
859,,null,null
860,Clarity,null,null
861,0.7,null,null
862,0.6,null,null
863,0.5,null,null
864,0.4,null,null
865,0.3 10 30 50 70 90 l,null,null
866,WEG,null,null
867,0.7,null,null
868,0.6,null,null
869,0.5,null,null
870,0.4,null,null
871,0.3 10 30 50 70 90 l,null,null
872,,null,null
873,Pearson,null,null
874,,null,null
875,(a) Query anchoring,null,null
876,,null,null
877,(b) Number of terms,null,null
878,,null,null
879,Figure 1: Sensitivity to free-parameter values of the relevance model used for query-model induction.,null,null
880,,null,null
881,"over the 30 splits. Finally, we measured statistically signi cant differences of prediction quality using a two-tailed paired t-test with p < 0.05 computed over all 30 splits.",null,null
882,4.2 Results,null,null
883,"Table 1 reports the prediction quality of our method and the baselines. We can see that in the vast majority of cases, our PFR-QPP approach statistically signi cantly outperforms the baselines.",null,null
884,"Applying basic QPP methods. We rst compare the three variants of the four basic QPP methods. We observe that, in most cases, utilizing the PRF-induced query qf for predicting the performance of the nal list Dscnd",null,null
885,"PFR-QPP vs. reference-list based alternatives. First, in line with previous work [7, 15, 16], the high prediction quality of ListSim and RefList in our setting shows that the similarity between the two lists is an e ective performance indicator. Moreover, combining prediction for the performance of the initial list with its similarity with the nal list",null,null
886,Sensitivity to query-model induction tuning. Using the ROBUST dataset and the relevance model,null,null
887,,null,null
888,"more ""verbose"", with less emphasis on the original query q. Indeed, a recent study showed that existing QPP methods are less robust for long queries [12]. Finally, we see that for any value of  and l, PFR-QPP outperforms the baselines.",null,null
889,5 CONCLUSIONS,null,null
890,"We addressed the QPP task for pseudo-feedback-based retrieval, where the nal retrieved list depends on an initially retrieved list ­ e.g., via a query model induced from the latter and used to produce the former. Our approach accounts for the predicted e ectiveness of each of the two lists as well as to their asymmetric co-relevance relation. Empirical evaluation showed that our approach signi cantly outperforms a variety of strong baselines.",null,null
891,ACKNOWLEDGEMENT,null,null
892,We thank the reviewers for their comments. This work was supported in part by the Israel Science Foundation,null,null
893,REFERENCES,null,null
894,"[1] Giambattista Amati, Claudio Carpineto, and Giovanni Romano. Query di culty, robustness, and selective application of query expansion. In Proceedings of ECIR, pages 127­137, 2004.",null,null
895,"[2] David Carmel and Oren Kurland. Query performance prediction for ir. In Proceedings of SIGIR, pages 1196­1197, New York, NY, USA, 2012. ACM.",null,null
896,"[3] Claudio Carpineto and Giovanni Romano. A survey of automatic query expansion in information retrieval. ACM Comput. Surv., 44(1):1:1­1:50, January 2012.",null,null
897,"[4] Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. Predicting query performance. In Proceedings of SIGIR, pages 299­306, New York, NY, USA, 2002. ACM.",null,null
898,"[5] Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. A framework for selective query expansion. In Proceedings of CIKM, pages 236­237, New York, NY, USA, 2004. ACM.",null,null
899,"[6] Ahmad Khwileh, Andy Way, and Gareth J. F. Jones. Improving the reliability of query expansion for user-generated speech retrieval using query performance prediction. In CLEF, 2017.",null,null
900,"[7] Oren Kurland, Anna Shtok, Shay Hummel, Fiana Raiber, David Carmel, and Ofri Rom. Back to the roots: A probabilistic framework for query-performance prediction. In Proceedings of CIKM, pages 823­832, New York, NY, USA, 2012. ACM.",null,null
901,[8] Victor Lavrenko and W. Bruce Croft. Relevance based language models. In Proceedings of SIGIR.,null,null
902,[9] Yuanhua Lv and ChengXiang Zhai. Revisiting the divergence minimization feedback model. In CIKM '14.,null,null
903,"[10] Fiana Raiber, Oren Kurland, Filip Radlinski, and Milad Shokouhi. Learning asymmetric co-relevance. In Proceedings of ICTIR, pages 281­290, 2015.",null,null
904,"[11] Haggai Roitman. Enhanced performance prediction of fusion-based retrieval. In Proceedings of ICTIR, pages 195­198, New York, NY, USA, 2018. ACM.",null,null
905,"[12] Haggai Roitman. An extended query performance prediction framework utilizing passage-level information. In Proceedings of ICTIR, pages 35­42, New York, NY, USA, 2018. ACM.",null,null
906,"[13] Haggai Roitman, Ella Rabinovich, and Oren Sar Shalom. As stable as you are: Re-ranking search results using query-drift analysis. In Proceedings of HT, pages 33­37, New York, NY, USA, 2018. ACM.",null,null
907,"[14] Harrisen Scells, Leif Azzopardi, Guido Zuccon, and Bevan Koopman. Query variation performance prediction for systematic reviews. In Proceedings of SIGIR, pages 1089­1092, New York, NY, USA, 2018. ACM.",null,null
908,"[15] Anna Shtok, Oren Kurland, and David Carmel. Using statistical decision theory and relevance models for query-performance prediction. In Proceedings of SIGIR, pages 259­266, New York, NY, USA, 2010. ACM.",null,null
909,"[16] Anna Shtok, Oren Kurland, and David Carmel. Query performance prediction using reference lists. ACM Trans. Inf. Syst., 34(4):19:1­19:34, June 2016.",null,null
910,"[17] Anna Shtok, Oren Kurland, David Carmel, Fiana Raiber, and Gad Markovits. Predicting query performance by query-drift estimation. ACM Trans. Inf. Syst., 30(2):11:1­11:35, May 2012.",null,null
911,"[18] William Webber, Alistair Mo at, and Justin Zobel. A similarity measure for inde nite rankings. ACM Trans. Inf. Syst., 28(4):20:1­20:38, November 2010.",null,null
912,[19] Chengxiang Zhai and John La erty. Model-based feedback in the language modeling approach to information retrieval. In CIKM '01.,null,null
913,"[20] Yun Zhou and W. Bruce Croft. Query performance prediction in web search environments. In Proceedings of SIGIR, pages 543­550, New York, NY, USA, 2007. ACM.",null,null
914,,null,null
915,1264,null,null
916,,null,null
917,,null,null
