,sentence,label,data
0,Short Research Papers 1B: Recommendation and Evaluation,null,null
1,,null,null
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
3,,null,null
4,An Analysis of Query Reformulation Techniques for Precision Medicine,null,null
5,,null,null
6,"Maristella Agosti, Giorgio Maria Di Nunzio, Stefano Marchesin",null,null
7,"Department of Information Engineering University of Padua, Italy",null,null
8,"{maristella.agosti,giorgiomaria.dinunzio,stefano.marchesin}@unipd.it",null,null
9,,null,null
10,ABSTRACT,null,null
11,The Precision Medicine,null,null
12,CCS CONCEPTS,null,null
13,· Information systems  Specialized information retrieval; Ontologies; Query reformulation.,null,null
14,KEYWORDS,null,null
15,Medical IR; query reformulation; precision medicine,null,null
16,"ACM Reference Format: Maristella Agosti, Giorgio Maria Di Nunzio, Stefano Marchesin. 2019. An Analysis of Query Reformulation Techniques for Precision Medicine. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",null,null
17,1 MOTIVATIONS,null,null
18,Medical Information Retrieval,null,null
19,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331289",null,null
20,,null,null
21,"and journals, but can take a wide variety of other forms, including computerized media. Therefore, the design of effective tools to access and search textual medical information requires, among other things, enhancing the query through expansion and/or rewriting techniques that leverage the information contained within knowledge resources. In this context, Sondhi et al. [12] identified some challenges arising from the differences between general retrieval and medical case-based retrieval. In particular, state-of-the-art retrieval methods, combined with selective query term weighing based on medical thesauri and physician feedback, improve performance significantly [3, 13].",null,null
22,"In 2017 and 2018, the Precision Medicine",null,null
23,"The objective of our study is to take advantage of this opportunity and evaluate several state-of-the-art query expansion and reduction techniques to examine whether a particular approach can be helpful in both scientific literature and clinical trials retrieval. Given the large number of participating research groups to this TREC track, we are able to compare the best experiments submitted to the PM track based on the results which were obtained applying our approach in the last two years. The experimental analysis shows that there are some common patterns in query reformulation that allow the retrieval system to achieve top performing results in both tasks.",null,null
24,"The rest of the paper is organized as follows: Section 2 describes the approach used to evaluate different query reformulation techniques. Section 3 presents the experimental setup and compares the results obtained using our approach with the best performing runs from TREC PM 2017 and 2018. Finally, Section 4 reports some final remarks and concludes the paper.",null,null
25,2 APPROACH,null,null
26,"The approach we propose for query expansion/reduction in a PM task comprises three steps, plus an additional fourth step required only for the retrieval of clinical trials. The steps are:",null,null
27,1 http://www.trec- cds.org/ 2 https://trec.nist.gov/,null,null
28,,null,null
29,973,null,null
30,,null,null
31,Short Research Papers 1B: Recommendation and Evaluation,null,null
32,,null,null
33,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
34,,null,null
35,"Indexing Step. We create the following fields to index clinical trials collections: <docid>, <text>, <max_age>, <min_age> and <gender>. Fields <max_age>, <min_age> and <gender> contain information extracted from the eligibility section of clinical trials and are required for the filtering step. The <text> field contains the entire content of each clinical trial -- and therefore also the information stored within the fields described above.",null,null
36,"To index scientific literature collections, we create the following fields: <docid> and <text>. As for clinical trials, the <text> field contains the entire content of each target document.",null,null
37,Query Reformulation Step. The approach relies on two types of query reformulation techniques: query expansion and query reduction.,null,null
38,"Query expansion: We perform a knowledge-based a priori query expansion. First, we rely on MetaMap [2], a state-of-the-art medical concept extractor, to extract from each query field all the Unified Medical Language System",null,null
39,"Second, for each extracted concept, we consider all its name variants contained into the following knowledge sources: National Cancer Institute5",null,null
40,"The expanded queries consist in the union of the original terms with the set of name variants. For example, consider a query only containing the word ""melanoma"" -- which is mapped to the UMLS concept C0025202. The set of name variants for the concept ""melanoma"" contains, among many others: cutaneous melanoma; malignant melanoma; malignant melanoma",null,null
41,"Additionally, we expand queries that do not mention any kind of blood cancer",null,null
42,"Query reduction: We reduce original queries by removing, whenever present, gene mutations from the <gene> field. To clarify, consider a topic where the <gene> field mentions ""BRAF",null,null
43,3 https://www.nlm.nih.gov/research/umls/ 4 https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml 5 https://www.cancer.gov/ 6 https://www.ncbi.nlm.nih.gov/mesh/ 7 http://www.snomed.org/ 8 https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/,null,null
44,,null,null
45,"Additionally, we remove the <other> field from those collections that include it -- since it contains additional factors that are not necessarily relevant, thus representing a potential source of noise in retrieving precise information for patients.9",null,null
46,"Retrieval Step. We use BM25 [11] as retrieval model. Additionally, query terms obtained through query expansion are weighted lower than 1.0 to avoid introducing too much noise in the retrieval process [6].",null,null
47,"Filtering Step. The eligibility section in clinical trials comprises, among others, three important demographic aspects that a patient needs to satisfy to be considered eligible for the trial, namely: minimum age, maximum age and gender; where minimum age and maximum age are the minimum and the maximum age, respectively, required for a patient to be considered eligible for the trial, while gender is the required gender.",null,null
48,"Therefore, after the retrieval step, we filter out from the list of candidate trials those for which a patient is not eligible -- i.e. his/her demographic data",null,null
49,3 SETUP AND EVALUATION,null,null
50,"In this section, we describe the experimental collections and the setup used to conduct and evaluate our approach. Then, we compare the results obtained with our approach with those of the best performing systems from TREC PM 2017 and 2018. All these systems make use of external knowledge sources to enhance retrieval performance; moreover, most of them are complex multi-stage retrieval systems, like those proposed in [5, 8], while the approach we present is quite simple and straightforward ­ facilitating its reproducibility.10",null,null
51,"Experimental Collections. Both tasks in TREC PM use the same set of topics, but with two different collections: scientific literature, clinical trials.",null,null
52,"Topics consists of 30 and 50 synthetic cases created by precision oncologists in 2017 and 2018, respectively. In 2017, topics contain four key elements in a semi-structured format:",null,null
53,"Scientific Literature consists of a set of 26,759,399 MEDLINE11 abstracts, plus two additional sets of abstracts:",null,null
54,"9In a personal communication with the organizers of the track, we have been informed that it was difficult to convince the oncologists why the other field was even necessary. 10Source code available at: https://github.com/stefano-marchesin/TREC_PM_qreforms 11 https://www.nlm.nih.gov/bsd/pmresources.html",null,null
55,,null,null
56,974,null,null
57,,null,null
58,Short Research Papers 1B: Recommendation and Evaluation,null,null
59,,null,null
60,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
61,,null,null
62,"additional datasets were added to increase the set of potentially relevant treatment information. In fact, precision medicine is a fastmoving field where keeping up-to-date with the latest literature can be challenging due to both the volume and velocity of scientific advances. Therefore, when treating patients, it may be helpful to present the most relevant scientific articles for an individual patient. Relevant literature articles can guide precision oncologists to the best-known treatment options for the patient's condition.",null,null
63,"Clinical Trials consists of a total of 241,006 clinical trial descriptions, derived from ClinicalTrials.gov12 -- a repository of clinical trials in the U.S. and abroad. When none of the available treatments are effective on oncology patients, the common recourse is to determine if any potential treatments are undergoing evaluation in a clinical trial. Therefore, it would be helpful to automatically identify the most relevant clinical trials for an individual patient. Precision oncology trials typically use a certain treatment for a certain disease with a specific genetic variant",null,null
64,"Experimental Setup. We use Whoosh,13 a pure Python search engine library, for indexing, retrieval and filtering steps. For BM25, we keep the default values k1 = 1.2 and b = 0.75 provided by Whoosh ­ as we found them to be a good combination [1]. For query expansion, we rely on MetaMap to extract and disambiguate concepts from UMLS. We summarize the procedure used for each experiment below. Indexing",null,null
65,"· Index clinical trials using the following created fields: <docid>, <text>, <max_age>, <min_age> and <gender>;",null,null
66,· Index scientific abstracts using the following created fields: <docid> and <text>.,null,null
67,Query reformulation,null,null
68,"· Use MetaMap to extract from each query field the UMLS concepts restricted to the following semantic types: neop for <disease>, gngm/comd for <gene> and all for <other>;",null,null
69,"· Extract from the concepts all name variants belonging to NCI, MeSH, SNOMED CT and MTH knowledge sources;",null,null
70,· Expand,null,null
71,· Reduce,null,null
72,· Remove,null,null
73,Retrieval,null,null
74,"· Adopt any combination of the reformulation strategies; · Weigh expanded terms with a value k  {0, 0.1, 0.2, ..., 1}; · Perform a search using expanded queries with BM25.",null,null
75,Filtering,null,null
76,· Filter out clinical trials for which the patient is not eligible.,null,null
77,Evaluation Measures. We use the official measures adopted in the TREC PM track: inferred nDCG,null,null
78,12 https://clinicaltrials.gov/ 13 https://whoosh.readthedocs.io/en/latest/intro.html,null,null
79,,null,null
80,reported in this work for space reasons. The inferred nDCG was not computed for the task Clinical Trials 2017 since the sampled relevance judgments are not available.,null,null
81,"Comparison. In Table 1, we report the results of our experiments",null,null
82,"In 2018, there is a clear distinction in terms of performances among the combinations that achieve the best results for the sl and the ct tasks. For the sl task, considering the semantic type neop expansion without using the umbrella term solid provides the best performances for all the measures considered. On the other hand, two of the best three runs for the ct task",null,null
83,"In 2017, the situation is completely different. Lines 12 and 13 show two combinations that are in the top 3 performing runs for both sl and ct. These two runs use query reduction and a weighted 0.1 solid",null,null
84,Another element that shows how difficult these two tasks are is the fact that top performing systems in 2017 do not achieve the same results in 2018. Our study therefore helps researchers to select,null,null
85,4 CONCLUSIONS AND FINAL REMARKS,null,null
86,"In this paper, we proposed and evaluated several state-of-the-art query expansion and reduction techniques for scientific literature and clinical trials retrieval. The experimental analysis showed that no clear pattern emerges for both tasks. In general, a query expansion approach using a selected set of semantic types helps the",null,null
87,,null,null
88,975,null,null
89,,null,null
90,Short Research Papers 1B: Recommendation and Evaluation,null,null
91,,null,null
92,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
93,,null,null
94,Semantic Type,null,null
95,,null,null
96,Field Other,null,null
97,,null,null
98,line year neop comd gngm oth oth_exp orig solid,null,null
99,,null,null
100,1 2018 y,null,null
101,,null,null
102,y,null,null
103,,null,null
104,n,null,null
105,,null,null
106,·,null,null
107,,null,null
108,·,null,null
109,,null,null
110,y,null,null
111,,null,null
112,n,null,null
113,,null,null
114,2 2018 y,null,null
115,,null,null
116,n,null,null
117,,null,null
118,n,null,null
119,,null,null
120,·,null,null
121,,null,null
122,·,null,null
123,,null,null
124,y,null,null
125,,null,null
126,n,null,null
127,,null,null
128,3 2018 y,null,null
129,,null,null
130,n,null,null
131,,null,null
132,y,null,null
133,,null,null
134,·,null,null
135,,null,null
136,·,null,null
137,,null,null
138,y,null,null
139,,null,null
140,n,null,null
141,,null,null
142,4 2018 n,null,null
143,,null,null
144,n,null,null
145,,null,null
146,n,null,null
147,,null,null
148,·,null,null
149,,null,null
150,·,null,null
151,,null,null
152,y,null,null
153,,null,null
154,n,null,null
155,,null,null
156,5 2018 n,null,null
157,,null,null
158,n,null,null
159,,null,null
160,n,null,null
161,,null,null
162,·,null,null
163,,null,null
164,·,null,null
165,,null,null
166,y 0.1,null,null
167,,null,null
168,6 2018 n,null,null
169,,null,null
170,y,null,null
171,,null,null
172,n,null,null
173,,null,null
174,·,null,null
175,,null,null
176,·,null,null
177,,null,null
178,y,null,null
179,,null,null
180,n,null,null
181,,null,null
182,7 2018 y,null,null
183,,null,null
184,n,null,null
185,,null,null
186,n,null,null
187,,null,null
188,·,null,null
189,,null,null
190,·,null,null
191,,null,null
192,n,null,null
193,,null,null
194,n,null,null
195,,null,null
196,8 2018 n,null,null
197,,null,null
198,n,null,null
199,,null,null
200,y,null,null
201,,null,null
202,·,null,null
203,,null,null
204,·,null,null
205,,null,null
206,y,null,null
207,,null,null
208,n,null,null
209,,null,null
210,9 2018 n,null,null
211,,null,null
212,n,null,null
213,,null,null
214,n,null,null
215,,null,null
216,·,null,null
217,,null,null
218,·,null,null
219,,null,null
220,n 0.1,null,null
221,,null,null
222,10 2018 y,null,null
223,,null,null
224,n,null,null
225,,null,null
226,y,null,null
227,,null,null
228,·,null,null
229,,null,null
230,·,null,null
231,,null,null
232,n,null,null
233,,null,null
234,n,null,null
235,,null,null
236,11 2017 y,null,null
237,,null,null
238,n,null,null
239,,null,null
240,y,null,null
241,,null,null
242,n,null,null
243,,null,null
244,n,null,null
245,,null,null
246,n 0.1,null,null
247,,null,null
248,12 2017 n,null,null
249,,null,null
250,n,null,null
251,,null,null
252,y,null,null
253,,null,null
254,n,null,null
255,,null,null
256,n,null,null
257,,null,null
258,n 0.1,null,null
259,,null,null
260,13 2017 n,null,null
261,,null,null
262,n,null,null
263,,null,null
264,n,null,null
265,,null,null
266,n,null,null
267,,null,null
268,n,null,null
269,,null,null
270,n 0.1,null,null
271,,null,null
272,14 2017 y,null,null
273,,null,null
274,n,null,null
275,,null,null
276,n,null,null
277,,null,null
278,n,null,null
279,,null,null
280,n,null,null
281,,null,null
282,n 0.1,null,null
283,,null,null
284,15 2017 n,null,null
285,,null,null
286,n,null,null
287,,null,null
288,n,null,null
289,,null,null
290,n,null,null
291,,null,null
292,n,null,null
293,,null,null
294,n,null,null
295,,null,null
296,n,null,null
297,,null,null
298,16 2017 y,null,null
299,,null,null
300,n,null,null
301,,null,null
302,y,null,null
303,,null,null
304,n,null,null
305,,null,null
306,n,null,null
307,,null,null
308,y 0.1,null,null
309,,null,null
310,17 2017 n,null,null
311,,null,null
312,n,null,null
313,,null,null
314,y,null,null
315,,null,null
316,n,null,null
317,,null,null
318,n,null,null
319,,null,null
320,y,null,null
321,,null,null
322,n,null,null
323,,null,null
324,sl P_10 0.5660 0.5640 0.5480 0.5460 0.5440 0.5440 0.5420 0.5340 0.5300 0.5140 0.5033 0.4900,null,null
325,0.4800 0.4767 0.4733 0.4733 0.4633,null,null
326,,null,null
327,ct P_10 0.5540 0.5600 0.5660 0.5680 0.5740 0.5540 0.5700 0.5640,null,null
328,0.5820 0.5680 0.3759 0.3931,null,null
329,0.4034 0.3862 0.3931 0.3828 0.3862,null,null
330,,null,null
331,sl infNDCG,null,null
332,0.4912 0.4961 0.4941 0.4876 0.4877 0.4853 0.4636 0.4877 0.4635 0.4572 0.3984 0.3881 0.3931 0.3974 0.3943 0.3567 0.3442,null,null
333,,null,null
334,ct infNDCG,null,null
335,0.5266 0.5264 0.5292 0.5411 0.5403 0.5403 0.5345 0.5337,null,null
336,0.5446 0.5393,null,null
337,-,null,null
338,,null,null
339,sl Rprec 0.3288 0.3288 0.3266 0.3240 0.3247 0.3236 0.3180 0.3229 0.3148 0.3144 0.2697 0.2677,null,null
340,0.2728 0.2714 0.2732 0.2329 0.2254,null,null
341,,null,null
342,ct Rprec 0.4098 0.4138 0.4116 0.4197 0.4179 0.4130 0.4134 0.4106,null,null
343,0.4205 0.4122 0.3206 0.3263,null,null
344,0.3361 0.3202 0.3241 0.3253 0.3243,null,null
345,,null,null
346,18 2018 19 2018 20 2018 21 2018 22 2018,null,null
347,2018 2018 23 2017 24 2017 25 2017 26 2017 27 2017 2017 2017,null,null
348,,null,null
349,TREC PM Participant Identifier UTDHLTRI UCAS udel_fang NOVASearch Poznan,null,null
350,Top 10 threshold Best combination of our approach,null,null
351,UTDHLTRI udel_fang NOVASearch,null,null
352,Poznan UCAS Top 10 threshold Best combination of our approach,null,null
353,,null,null
354,0.6160 0.5980 0.5800,null,null
355,< < 0.5800,null,null
356,,null,null
357,0.5380 0.5460 0.5240 0.5520 0.5580 0.5240,null,null
358,< 0.3966 0.3690 0.3724 0.3586,null,null
359,,null,null
360,0.4797 0.5580 0.5081,null,null
361,< < 0.4710,null,null
362,,null,null
363,0.4794 0.5347 0.5057 0.4992 0.4894 0.4736,null,null
364,-,null,null
365,,null,null
366,< 0.3654 0.3289,null,null
367,< < 0.2992,null,null
368,,null,null
369,0.3920 0.4005 0.3967 0.3931 0.4101 0.3658,null,null
370,(13) 0.3361,null,null
371,,null,null
372,Table 1: Results for the TREC PM tasks 2017 and 2018. Details are reported in Section 3.,null,null
373,,null,null
374,"retrieval of scientific literature, while a query reduction approach without expansion, but a small weighted solid",null,null
375,ACKNOWLEDGMENTS,null,null
376,"The authors thank Ellen Vorhees and Kirk Roberts for their helpful insights regarding the interpretation of the data collection. The work was partially supported by the ExaMode project,14 as part of the European Union H2020 research and innovation program under grant agreement no. 825292.",null,null
377,REFERENCES,null,null
378,"[1] M. Agosti, G.M. Di Nunzio, and S. Marchesin. 2018. The University of Padua IMS Research Group at TREC 2018 Precision Medicine Track. In Proc. of the Twenty-Seventh Text REtrieval Conference, TREC 2018, Gaithersburg, Maryland, USA, Nov. 14-16, 2018.",null,null
379,"[2] A.R. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In Proc. of the AMIA Symposium. American Medical Informatics Association, 17­21.",null,null
380,"[3] L. Diao, H. Yan, F. Li, S. Song, G. Lei, and F. Wang. 2018. The Research of Query Expansion Based on Medical Terms Reweighting in Medical Information Retrieval. EURASIP Jour. on Wireless Communications and Networking 2018, 1",null,null
381,14 htttp://www.examode.eu/,null,null
382,,null,null
383,"[4] L. Goeuriot, G.J.F. Jones, L. Kelly, H. Müller, and J. Zobel. 2016. Medical Information Retrieval: Introduction to the Special Issue. Information Retrieval Journal 19, 1",null,null
384,"[5] T.R. Goodwin, M.A. Skinner, and S.M. Harabagiu. 2017. UTD HLTRI at TREC 2017: Precision Medicine Track. In Proc. of the Twenty-Sixth Text REtrieval Conference, TREC 2017, Gaithersburg, Maryland, USA, Nov. 15-17, 2017.",null,null
385,"[6] H. Gurulingappa, L. Toldo, C. Schepers, A. Bauer, and G. Megaro. 2016. SemiSupervised Information Retrieval System for Clinical Decision Support. In Proc. of the Twenty-Fifth Text REtrieval Conference, TREC 2016, Gaithersburg, Maryland, USA, Nov. 15-18, 2016.",null,null
386,"[7] W. Hersh. 2009. Information Retrieval: A Health and Biomedical Perspective. 2009 Springer Science + Business Media, LLC, New York, NY, USA.",null,null
387,"[8] M. Oleynik, E. Faessler, A. Morassi Sasso, A. Kappattanavar, B. Bergner, H. Freitas",null,null
388,"da Cruz, J.P. Sachs, S. Datta, and E. Böttinger. 2018. HPI-DHC at TREC 2018: Precision Medicine Track. In Proc. of the Twenty-Seventh Text REtrieval Conference, TREC 2018, Gaithersburg, Maryland, USA, Nov. 14-16, 2018. [9] K. Roberts, D. Demner-Fushman, E.M. Voorhees, W.R. Hersh, S. Bedrick, and A.J. Lazar. 2018. Overview of the TREC 2018 Precision Medicine Track. In Proc. of the Twenty-Seventh Text REtrieval Conference, TREC 2018, Gaithersburg, Maryland, USA, Nov. 14-16, 2018. [10] K. Roberts, D. Demner-Fushman, E.M. Voorhees, W.R. Hersh, S. Bedrick, A.J.",null,null
389,"Lazar, and S. Pant. 2017. Overview of the TREC 2017 Precision Medicine Track. In Proc. of the Twenty-Sixth Text REtrieval Conference, TREC 2017, Gaithersburg, Maryland, USA, Nov. 15-17, 2017. [11] S. Robertson and H. Zaragoza. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends® in Information Retrieval 3, 4",null,null
390,"[12] P. Sondhi, J. Sun, C. Zhai, R. Sorrentino, and M.S. Kohn. 2012. Leveraging Medical",null,null
391,"Thesauri and Physician Feedback for Improving Medical Literature Retrieval for Case Queries. Jour. of the American Medical Informatics Association: JAMIA 19, 5",null,null
392,"[13] D. Zhu, S. Wu, B. Carterette, and H. Liu. 2014. Using Large Clinical Corpora for Query Expansion in Text-Based Cohort Identification. Jour. of Biomedical Informatics 49",null,null
393,,null,null
394,976,null,null
395,,null,null
396,,null,null
