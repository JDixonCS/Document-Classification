,sentence,label,data
0,Evaluating Search Result Diversity using Intent Hierarchies,null,null
1,"Xiaojie Wang1,2, Zhicheng Dou,1,2, Tetsuya Sakai3, and Ji-Rong Wen1,2,4 1School of Information, Renmin University of China",null,null
2,"2Beijing Key Laboratory of Big Data Management and Analysis Methods, China 3Department of Computer Science and Engineering, Waseda University",null,null
3,"4Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China 2{wangxiaojie,dou}@ruc.edu.cn, 3tetsuyasakai@acm.org, 4jirong.wen@gmail.com",null,null
4,ABSTRACT,null,null
5,"Search result diversification aims at returning diversified document lists to cover different user intents for ambiguous or broad queries. Existing diversity measures assume that user intents are independent or exclusive, and do not consider the relationships among the intents. In this paper, we introduce intent hierarchies to model the relationships among intents. Based on intent hierarchies, we propose several hierarchical measures that can consider the relationships among intents. We demonstrate the feasibility of hierarchical measures by using a new test collection based on TREC Web Track 2009-2013 diversity test collections. Our main experimental findings are: (1) Hierarchical measures are generally more discriminative and intuitive than existing measures using flat lists of intents; (2) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more improvement in discriminative power; (3) Hierarchical measures are more intuitive in terms of diversity or relevance. The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.",null,null
6,Keywords,null,null
7,Ambiguity; Diversity; Evaluation; Novelty; Hierarchy,null,null
8,1. INTRODUCTION,null,null
9,"Nowadays, people tend to meet their daily information needs by typing keywords into search engines like Google and Bing. However, these keywords, also known as queries, are often ambiguous or broad [14, 15, 28, 10]. The queries usually have several interpretations or aspects, also known as subtopics or user intents. When users submit the same query to retrieval systems, they may want different information returned to fulfill their information needs. This poses",null,null
10,Corresponding author,null,null
11,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17 - 21, 2016, Pisa, Italy c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2911497",null,null
12,a challenge to search engines when the targeted user intent cannot be known in advance.,null,null
13,"To tackle this problem, a wide range of search result diversification algorithms ([1, 2, 5, 13, 18, 26, 27, 31, 25, 12, 11]) have been proposed over the past years. They aim at returning a diversified ranked document list that covers different intents of the queries. In the meantime, some researchers have introduced a variety of diversity measures, such as I-rec [22], -nDCG [9], Intent-Aware measures [1], D-measures [24], etc. These measures evaluate ranked lists in terms of both diversity and relevance, and indicate which diversification algorithms are better to use. Existing diversity measures assume that the users' information need could be represented by a single layer of intents and these intents are either independent or exclusive. However, some of the intents are not independent and are related to each other.",null,null
14,"We use the query ""bobcat"", which is a topic (No. 77) in Text Retrieval Conference(TREC) 2010 Web Track [8], as an example. This query is ambiguous because of the polysemy of ""bobcat"": one interpretation is a company called ""bobcat company"" whose core business is about tractors; another interpretation is a kind of wild animals called ""wild bobcat."" We show its official intents, marked by i1-i4, in Figure 1(a). The figure shows that except intent i2 that is about ""wild bobcat,"" the remaining ones, i1, i3, and i4, are all about ""bobcat company."" This indicates that i1, i3, and i4 are more related to each other, but are less related to i2. Even within the three intents about ""bobcat company,"" i1 and i3 are closer because they are about the trade involving tractors of the company, whereas i4 is about homepage the company. We argue that this kind of relationships among intents should be modeled when evaluating search result diversity. However, none of existing measures considers this.",null,null
15,"Specifically, we find two submitted runs for the query, cmuFuTop10D and THUIR10DvNov, in TREC Web Track 2010 diversity task. cmuFuTop10D covers i1, i3, and i4, while THUIR10DvNov covers i1, i2, and i4 in their top ten ranks. Since i1, i3, and i4 are all about ""bobcat company,"" cmuFuTop10D misses another interpretation of bobcat, i.e. ""wild bobcat,"" but THUIR10DvNov covers both interpretations. In this sense, the latter is more diversified but I-rec [22] treats them as equally good because they cover the same number of intents. Some other existing measures also have similar problems, which will be illustrated in Section 3.3.1. We think that this is due to their lack of recognition of the relationships among intents.",null,null
16,"In light of the above observation, we introduce intent hierarchies to represent the relationships among intents. We",null,null
17,415,null,null
18,"(a) Official intents of the query ""bobcat"".",null,null
19,"(b) LEFT: Intent Hierarchies OIH and EIH. OIH is comprised of the solid boxes, whereas EIH includes both solid",null,null
20,and dashed nodes. RIGHT: An example showing relevance assessments for the added nodes (under R in red) derived from relevance assessments for the official intents (under R in blue).,null,null
21,"Figure 1: The official intents, original intent hierarchy (OIH), and extended intent hierarchy (EIH) of No. 77 query ""bobcat"" in TREC Web Track 2010.",null,null
22,design hierarchical measures using the intent hierarchies to solve the problems mentioned above. The main contributions of this paper are:,null,null
23,"(1) To the best of our knowledge, this is the first work on modeling user intents as intent hierarchies and using the intent hierarchies for evaluating search result diversity.",null,null
24,"(2) We propose hierarchical measures using intent hierarchies, including Layer-Aware measures, N-rec, LD-measures, LAD-measures, and HD-measures. We show several cases where hierarchical measures outperform existing measures in terms of discriminative power and intuitiveness.",null,null
25,"(3) We present a method for creating intent hierarchies from existing diversity test collections, and reusing the relevance assessments. We create a new dataset based on the TREC Web Track 2009-2013 diversity test collections. The new dataset can be assessed online 1.",null,null
26,"(4) We compare our measures with existing measures. We find that (i) Hierarchical measures are generally more discriminative and intuitive than existing measures, especially when using the intent hierarchies whose leaf nodes have the same depth; (ii) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more improvement in discriminative power; (iii) The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.",null,null
27,"The remainder of this paper is organized as follows. Section 2 describes some existing diversity measures and the methods for testing evaluation measures. In Section 3, we introduce intent hierarchies, and our method for creating a new test collection based on TREC Web Track 2009-2013 diversity test collections. We then propose several new diversity measures that can utilize the intent hierarchies. Section 4 describes experimental results and analysis. We conclude our work in Section 5.",null,null
28,2. RELATED WORK,null,null
29,"Given a query q, most existing measures evaluate a ranked document list by modeling users' information need as a flat list of intents {i}. Some measures can handle intent probability P r(i|q) and graded relevance assessments but some cannot. In this section, we briefly summarize the previous work on designing and testing diversity measures.",null,null
30,1http://www.playbigdata.com/dou/heval/,null,null
31,2.1 Diversity Measures,null,null
32,2.1.1 Intent Recall,null,null
33,"Intent recall(I-rec) [22], also known as subtopic recall [30]",null,null
34,"is the proportion of intents covered by a ranking list. Let dr denote the document at rank r, and let I(dr) denote the set of intents to which document dr is relevant. Then, I-rec for a certain cutoff K can be expressed as:",null,null
35,I -rec@K,null,null
36,",",null,null
37,|,null,null
38,K,null,null
39,"r,1",null,null
40,I (dr )|,null,null
41,(1),null,null
42,|{i}|,null,null
43,"Note that I-rec does not take the positions of relevant documents into account, and cannot handle intent probability and graded relevance assessments.",null,null
44,2.1.2 -nDCG,null,null
45,"In order to balance both relevance and diversity of ranked lists, -nDCG [9] is defined as:",null,null
46,"-nDCG@K ,  K rK r,,11NNGG((rr))//lloogg((rr++11))",null,null
47,(2),null,null
48,"N G(r) ,",null,null
49,Ji(r)(1 - )Ci(r-1),null,null
50,i{i},null,null
51,where N G(r) is N G(r) in the ideal ranked list; Ji(r) is,null,null
52,"1othifertwheised;ocCuim(re)nt,atrrka,n1kJri",null,null
53,is (k),null,null
54,relevant to intent is the number of,null,null
55,"i, and 0 relevant",null,null
56,documents to intent i within top r; and  is a parameter.,null,null
57,-nDCG tends to disregard unpopular intents and hence can,null,null
58,be counterintuitive sometimes [24].,null,null
59,2.1.3 Intent-Aware measures,null,null
60,"Intent-Aware measures (IA measures) [1] is a general framework to evaluate ranked document lists. Assuming that i{i} P r(i|q) ,"" 1, M -IA can be computed as:""",null,null
61,"M -IA@K ,",null,null
62,P r(i|q)Mi@K,null,null
63,(3),null,null
64,i{i},null,null
65,"where Mi is the per-intent version of measure M. Measure M can be nDCG [16], ERR [4], nERR [7], etc.",null,null
66,2.1.4 D-measures,null,null
67,"D-measures [24] aim to boost intent recall, and to reward documents that are highly relevant to more popular intents. Assume that gi(r) is the gain value of the document at rank",null,null
68,416,null,null
69,"r for intent i, and gi(r) is calculated based on per-intent",null,null
70,relevance assessments. Then the global gain at rank r is,null,null
71,given by:,null,null
72,"GG(r) ,",null,null
73,P r(i|q)gi(r),null,null
74,(4),null,null
75,i{i},null,null
76,Let global,null,null
77,CGG(r) gain at,null,null
78,",",null,null
79,r,null,null
80,"k,1",null,null
81,"GG(k),",null,null
82,"rank r. Further,",null,null
83,which is the cumulative let GG(r) and CGG(r),null,null
84,denote the global gain and the cumulative global gain re-,null,null
85,spectively at rank r in the ideal ranked list. The ideal list is,null,null
86,obtained by listing up all relevant documents in descending,null,null
87,"order of global gains. Let J(r) , 1 if the document at rank r",null,null
88,"iLserteCle(vra)nt,toarkn,y1",null,null
89,"of the J (k),",null,null
90,"intents {i}, which is the",null,null
91,"and J(r) , 0 otherwise. number of relevant doc-",null,null
92,uments within top r. D-nDCG and D-Q at document cutoff,null,null
93,K are defined as:,null,null
94,"D-nDCG@K , K rK r,,11GGGG((rr))//lloogg((rr++11))",null,null
95,(5),null,null
96,1,null,null
97, K,null,null
98,C(r) + CGG(r),null,null
99,"D-Q@K ,",null,null
100,J (r),null,null
101,(6),null,null
102,"min(K, R)",null,null
103,r + CGG(r),null,null
104,"r,1",null,null
105,where R is the number of judged relevant documents. Then D-measure is defined as:,null,null
106,"D-measure@K , I-rec@K + (1 - )D-measure@K (7)",null,null
107,"where D-measure can be D-nDCG or D-Q, and  is a parameter controlling the tradeoff between diversity and relevance. D-measures are free of the under-normalization problem of -nDCG and IA measures.",null,null
108,"The diversity measures mentioned above are widely used in several tasks of TREC Web Track 2 or NII Testbeds and Community for Information access Research (NTCIR) 3, but they do not take the relationships among intents into consideration, which is what we aim to deal with in this paper.",null,null
109,2.2 Measure Evaluation,null,null
110,"Given a certain significance level, discriminative power measures the stability of measures across queries and experiments based on significance tests, e.g. paired bootstrap test [20], Tukey's Honestly Significant Differences(HSD) [3] test, etc. Discriminative power can be used to estimate the performance difference required to achieve statistical significance between two retrieval systems [21].",null,null
111,"Concordance test [21] is proposed to quantify the intuitiveness of diversity measures. In concordance test, one or more gold standard measures are chosen and assumed to truly represent intuitiveness. Given two diversity measures M1 and M2, the relative intuitiveness of M1 (or M2) is measured in terms of preference agreement with the gold standard measures. The preference agreement is that M1 (or M2) agrees with the gold standard measure(s) about which one of two ranked lists should be preferred.",null,null
112,"Rank correlation compares two rankings, which are two ranked system lists in our case. Kendall's  [17] is a widelyused statistic to measure rank correlation. However  lacks the property of top heaviness, which means the exchanges near the top of a ranked list and those near the bottom are treated equally, even though the swaps near the top is generally more important in the context of IR evaluation. ap [29] is proposed to deal with the problem. Note that  is symmetric but ap is not. However, a symmetric ap can",null,null
113,2http://plg.uwaterloo.ca/~trecweb/ 3http://research.nii.ac.jp/ntcir/index-en.html,null,null
114,"be obtained by averaging two ap values when each list is treated as the former one. Both  and ap range from -1, which implies two ranked lists perfectly disagree, to 1, which implies two ranked lists are identical.",null,null
115,"In this paper, we use discriminative power, concordance test, and rank correlation to evaluate diversity measures.",null,null
116,3. PROPOSED METHODS,null,null
117,"In this section, we define two types of intent hierarchies to represent the relationships among user intents and discuss their properties. We then introduce our method for creating such intent hierarchies and obtaining relevance assessments for the intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Last, we propose several diversity measures based on intent hierarchies, and demonstrate that in some cases, the new measures outperform their corresponding existing measures.",null,null
118,3.1 Intent Hierarchies,null,null
119,"Given a query q, the users' information need is represented as a set of intents {i}. We assume these intents cannot be further subdivided, and refer to them as atomic intents. We aim to build an intent hierarchy based on the semantic similarity or relatedness of the intents. The intent hierarchy should possess some basic properties as follows:",null,null
120,"Property 1. The intent hierarchy is in a tree structure, where every child has only one parent.",null,null
121,"Property 2. The root of intent hierarchy is denoted by q itself, which stands for the user's information need as a whole. The root is a dummy node only for the completeness of the tree, and is not considered in our measures.",null,null
122,"Property 3. When q is broad, the intent hierarchy is built in such a way that a parent node refers to a more general concept than its children, and a child node refers to one aspect of its parent. When q is ambiguous, each child node of the root is one interpretation of the query, and each of its subtrees is built in the same way as a broad query.",null,null
123,"Property 4. These atomic intents, i.e. {i}, correspond one to one with leaves of the intent hierarchy. This means the number of leaves in the intent hierarchy is the same as the number of the atomic intents.",null,null
124,We call an intent hierarchy that satisfies the properties specified above is called an original intent hierarchy (OIH). OIH can be extended so as to satisfy an extra property as:,null,null
125,"Property 5. These atomic intents are in the same layer of the intent hierarchy. In other words, all leaf nodes of the intent hierarchy have the same depth because the atomic intents correspond to leaves of the intent hierarchy (see Property 4).",null,null
126,"An intent hierarchies that satisfies all five properties are called an extended intent hierarchy (EIH). If a query's OIH satisfies Property 5, then its EIH is the same as the OIH.",null,null
127,"We consider the root of an intent hierarchy as the zeroth layer, the child nodes of the root as the first layer and so forth. If an intent hierarchy only has the zeroth layer and the first layer, the height of the intent hierarchy is one. In the paper, a single-layer intent hierarchy refers to an intent hierarchy whose height is one, while a multilayer intent hierarchy refers to that whose height is greater than one.",null,null
128,417,null,null
129,3.2 Creating Intent Hierarchies,null,null
130,"In this paper, we create intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Note that for each query in TREC Web Track 2010-2013, the description of its first intent is the same as the description of the query itself. We find that although the descriptions are the same, if a query has several different interpretations, the first intent is just one of these interpretations. A query's first intent does not refer to a more general concept than the other intents. So we do not treat the first intent differently.",null,null
131,"We use the official intents as atomic intents to avoid reassessing relevance of the documents. First we create original intent hierarchies (OIH) by manually grouping the official intents based on their semantic similarity or relatedness. Then, we extend them to extended intent hierarchies (EIH). Figure 1 illustrates how we create OIH and EIH for the query ""bobcat"" in TREC 2010 Web Track. It can be seen from Figure 1(a) that this query has four official intents and intent i1 and i3 are related to the trade involving tractors of the ""bobcat company."" So we create a new node n1 that stands for ""bobcat tractors"" as their parent node. Similarly, n1 and i4 are related to ""bobcat company,"" hence we create another new node n2 representing ""bobcat company"" as their parent. Finally, since n2 (""bobcat company"") and i2 (""wild bobcat"") are two distinct interpretations of query ""bobcat,"" they are considered as the child nodes of the root node. The resultant OIH is shown in solid boxes in the left of Figure 1(b). Further, we extend the OIH by adding more child nodes to i2 and i4 to make sure that all the leaf nodes have the same height. The resultant EIH is shown in solid boxes plus dashed boxes in the left of Figure 1(b).",null,null
132,"For a leaf node, we use its original weight of the corresponding official intent as its initial weight. For an intermediate node, we set its original weight to the sum of its child node weights. We then normalize the weights for each layer to make sure that these weights sum to 1. For TREC Web Track 2009-2013 test collections, because of the lack of official intent weights, we assume that each official intent for a query is equally important.",null,null
133,"As for the OIH or EIH shown in Figure 1(b): (1) It is in a tree structure (Property 1); (2) Its root is query ""bobcat"" itself (Property 2); (3) The query is ambiguous, so the child nodes of root are its two different interpretations, i.e. ""bobcat company"" and ""wild bobcat."" A parent node refers to a more general concept than its children (Property 3), e.g. ""bobcat company"" is more general than ""bobcat company homepage;"" (4) The leaf nodes are exactly the official intents of query ""bobcat"" (Property 4). Further, the depth of all the leaf nodes in EIH is three (Property 5).",null,null
134,"Note that we only have document relevance assessments for the original intents appeared in TREC Web Track diversity test collections. In other words, for the intent hierarchies we create, document relevance judgments are just available for their leaf intents. We do not have document relevance assessments for intermediate intents. As assessing document relevance is usually very time-consuming, it is not desirable to reassess the documents for intermediate nodes of the intent hierarchies. Fortunately, according to Property 3, a parent node of an intent hierarchy stands for a more general concept than its child nodes. Hence it is reasonable to assume that if a document is relevant to a node, it would be relevant to the node's parent. This means that we can derive relevance assessments for the intermediate nodes",null,null
135,"starting from the leaves. In this paper, we simply let:",null,null
136,"Ld(n) , max Ld(c)",null,null
137,(8),null,null
138,cC(n),null,null
139,"where Ld(n) is the relevance rating assigned to document d for node n, and C(n) is the set of child nodes of n.",null,null
140,"We show an actual document (denoted by d in the following) from TREC Web Track 2010 diversity test collection in Figure 1(b). In the table, the officially provided relevance assessments are marked in blue, e.g. the relevance rating of d for i1 is 1. Firstly, node n1 has two child nodes, i1 and i3, and the relevance ratings of d for them are 1 and 0. According to Equation (8), the relevance rating of d for n1 is 1. Similarly, we can derive the relevance rating for n2 based on its child node i4 and n1. These derived relevance assessments are shown in red in the table of Figure 1(b).",null,null
141,"To conclude, we create a new dataset containing intent hierarchies by manually grouping the official intents from TREC Web track test collections. The good news is that we do not need to reassess document relevance with regards to the intent hierarchies. We directly leverage document relevance assessments for the leaf intents, and automatically assign relevance ratings for the intermediate intents. This also implies that when we want to create hierarchical intents for evaluating diversity, we just need to assess document relevance for the leaf nodes or atomic intents.",null,null
142,"The new test collection has 250 queries, and 105 topics have multilayer intent hierarchies. Most of the time of creating the new dataset is spent on grouping the original intents. On average, we spend about three minutes per query mainly in understanding the original intents with the assistance of search engines such as Bing and Google.",null,null
143,3.3 Hierarchical Measures,null,null
144,3.3.1 Layer-Aware measures,null,null
145,"Given a query q and its intent hierarchy, our first proposal",null,null
146,for evaluating a ranked list is to first evaluate the ranked,null,null
147,"list for each layer using existing measures, then combine the",null,null
148,"evaluation scores. Let H denote the height of the intent hierarchy, and let",null,null
149,"L ,"" {l1, l2, ..., lH } denote its first layer to the last layer. We define Layer-Aware measures (LA measures) at document cutoff K as the follows.""",null,null
150, H,null,null
151,"M -LA@K , wi  Mi@K",null,null
152,(9),null,null
153,"i,1",null,null
154,"Here,",null,null
155,wi,null,null
156,is,null,null
157,the,null,null
158,weight,null,null
159,of,null,null
160,layer,null,null
161,"li,",null,null
162,where,null,null
163,H,null,null
164,"i,1",null,null
165,wi,null,null
166,",",null,null
167,"1,",null,null
168,and Mi is the evaluation score of measure M by using the,null,null
169,"intents of layer li. For example, ERR-IA-LA is computed as",null,null
170,"follows: (1) For each layer, compute the per-layer scores of",null,null
171,ERR-IA; (2) Compute the weighted average of the per-layer,null,null
172,scores using Equation (9).,null,null
173,We find that the combination of measures over layers of,null,null
174,intent hierarchies could outperform the original measures,null,null
175,"using a flat list of intents. We use the query ""defender"",",null,null
176,"which is a topic (No. 20) in TREC Web Track 2009 [6], as",null,null
177,an example. We choose this query because it has a relatively,null,null
178,simple intent hierarchy. Its extended intent hierarchy (EIH),null,null
179,is shown in the left of Figure 2(b). Suppose we have three,null,null
180,"documents, d1-d3, and each of them can be viewed as a",null,null
181,ranked list containing only one document. Their relevance,null,null
182,assessments for the EIH are displayed in blue in the right of,null,null
183,418,null,null
184,"(a) Official intents of the query ""defender"".",null,null
185,"(b) LEFT: Intent Hierarchies OIH and EIH. OIH is comprised of the solid boxes, whereas EIH includes both solid and dashed nodes. RIGHT: 1st column: document IDs (d: the ideal one), each document is equal to a ranked list of length 1. 2nd to",null,null
186,5th column (R and R ): relevance assessments for the official intents (in red) and derived relevance assessments for added,null,null
187,"nodes (in blue). 6th to 12th column (S): the measures are computed at rank 1 (subscript 1 means only using the first layer of EIH and subscript 2 means only using the second layer. subscript O means using OIH and subscript E means using EIH.), e.g. d2 get 0.35 when using D-nDCG on the first layer of EIH. Note that the original D-nDCG is equal to D-nDCG2 and the original I-rec is equal to I-rec2.",null,null
188,"Figure 2: The official intents, original intent hierarchy (OIH), and extended intent hierarchy (EIH) of No. 20 query ""defender"" in TREC Web Track 2009. In the right table, if two documents have the same scores under a measure (in green below), it means that this measure cannot tell which one is better, e.g. D-nDCG1@1 treats d2 and d3 as equally good, but d3 is better because of its relevance to an extra intent i5.",null,null
189,"Figure 2(b). Note that the nodes that receive no relevant documents within the documents are not displayed to save space. Assume d is the first document within the ideal rank list and it is relevant to every node displayed. In the right of Figure 2(b), D-nDCG1@1 is the evaluation score when only using the first layer of the EIH, D-nDCG2@1 means only using the second layer, and D-nDCG-LAE@1 is the average of D-nDCG1@1 and D-nDCG2@1. Note that the original D-nDCG is equal to D-nDCG2. We use the measures to score d1 to d3, which is equivalent of evaluating at document cutoff 1. We show the evaluation results in Figure 2(b), e.g. d2 gets 0.35 when using D-nDCG1@1.",null,null
190,"We find that d1>d2,""d3 in terms of D-nDCG1@1, d1"",""d2>d3 in terms of D-nDCG2@1, whereas d1>d2>d3 in terms of D-nDCG-LAE@1. Here, """">"""" means the former document is preferred compared with the latter when evaluating them at rank 1, and """""","" means neither is preferred. The real preference should be d1>d2>d3. This is because (1) d1 is more diversified than d2 because d1 refers to two interpretations of query defender"""", i.e. """"windows defender"""" and """"defender arcade game online,"""" while d2 only refers to the former; (2) d2 is more diversified than d3 because d2 refers to two aspects of """"windows defender"""", i.e. """"windows defender homepage"""" and """"windows defender reports"""" while d3 just refers to the former. Here, only D-nDCG-LAE@1 is consistent with the real preference. D-nDCG1@1 fails to tell the difference between d2 and d3, whereas D-nDCG2@1 fails to tell the difference between d1 and d2. This indicates that the combination over layers has higher potential to reflect real user satisfaction than the use of a flat list of intents in some cases.""",null,null
191,3.3.2 Node Recall,null,null
192,"Given a query q, let V denote the nodes in its intent hierarchy except for its root. Let dr denote the document at",null,null
193,"rank r, and let N (dr) denote the set of nodes in V to which dr is relevant. Given a document cutoff K, we define node recall (N -rec) as:",null,null
194,N -rec@K,null,null
195,",",null,null
196,|,null,null
197,K,null,null
198,"r,1",null,null
199,N,null,null
200,(dr,null,null
201,)|,null,null
202,|V |,null,null
203,(10),null,null
204,which is the proportion of nodes in the hierarchy covered by the top K documents. N-rec is a natural generalization of I-rec when using the intent hierarchy rather than a flat list of intents. They both are rank-insensitive and cannot handle graded relevance assessments.,null,null
205,"We use an example to show that N-rec is able to outperform I-rec in terms of discriminative power. In the right of Figure 2(b), I-rec1@1 means only using the first layer, I-rec2@1 means only using the second layer, and N-recE@1 means using the extended intent hierarchy (EIH) when computing N-rec. These measures are computed at rank 1. Note that the original I-rec is equal to I-rec2. We find that d1>d2,""d3 according to I-rec1@1, d1"",""d2>d3 according to I-rec2@1, whereas d1>d2>d3 according to N-recE@1. As we discussed in Section 3.3.1, The real preference should be d1>d2>d3. I-rec1@1 fails to tell the difference between d2 and d3, while I-rec2@1 fails to distinguish between d1 and d2. Only N-recE@1 can tell the difference between the three documents, and thus is more discriminative than I-rec.""",null,null
206,"Another point worth noting is that the types of intent hierarchies are crucial to N-rec. In the right of Figure 2(b), N-recO@1 means using the original intent hierarchy (OIH) instead of EIH. We find that N-recO@1 cannot determine which one of d1 and d2 is better because they have exactly the same score. This indicates that using EIH has higher discriminative power than using OIH.",null,null
207,"We aim to retrieve documents that cover as many nodes of intent hierarchies as possible. At the same time, we pre-",null,null
208,419,null,null
209,"fer the documents that are highly relevant to more popular nodes and layers. N-rec mainly rewards wide coverage of different nodes of intent hierarchies in the top ranks. In the following, we discuss some measures to complement N-rec.",null,null
210,3.3.3 LD-measures,null,null
211,"We use the leaf nodes of intent hierarchies to compute D-measures. Then, LD-measure is defined as:",null,null
212,"LD-measure@K , N -rec@K + (1 - )D-measure@K (11)",null,null
213,"where  is a parameter controlling the tradeoff between diversity and relevance. Since D-measures only use the leaves of intent hierarchies, LD-measures reward high relevance with more popular leaves, but do not reward high relevance with more popular intermediate nodes. Also, LD-measures cannot handle the weights of layers. To tackle these, we propose HD-measures and LAD-measures in the next section.",null,null
214,3.3.4 HD-measures and LAD-measures,null,null
215,"Inspired by D-measures, we define the global gain for an intent hierarchy at rank r as:",null,null
216," H GGh(r) , wi  GGi(r)",null,null
217,"i,1",null,null
218,(12),null,null
219,where wi is the gain for layer li,null,null
220,weight of layer at rank r. Let,null,null
221,li C,null,null
222,and GGh,null,null
223,"(Gr)G,i(r) irks,""t1hGeGghlo(bka),l""",null,null
224,which is the cumulative global gain for the intent hierarchy,null,null
225,"at rank r. Further, let GGh(r) and CGGh(r) denote the global gain and the cumulative global gain for the intent",null,null
226,hierarchy at rank r in the ideal ranked list. The ideal list,null,null
227,is obtained by listing up all the judged documents in de-,null,null
228,scending order of global gains for the intent hierarchy. Let,null,null
229,"J(r) ,"" 1 if the hierarchy, and""",null,null
230,"document at rank r J(r) , 0 otherwise.",null,null
231,"iLserteClev(ra)nt,totrkh,e1inJt(ekn)t.",null,null
232,We define HD-nDCG and HD-Q at document cutoff K as:,null,null
233,H D-nDC G@K,null,null
234,",",null,null
235,"K K r,1",null,null
236,"r,1",null,null
237,GGh(r)/ GGh(r)/,null,null
238,log(r log(r,null,null
239,+ +,null,null
240,1) 1),null,null
241,(13),null,null
242,H D-Q@K,null,null
243,",",null,null
244,"1 min(K, R)",null,null
245, K,null,null
246,"r,1",null,null
247,J,null,null
248,(r),null,null
249,C,null,null
250,(r) + CGGh(r) r + CGGh(r),null,null
251,(14),null,null
252,where R is the number of judged documents relevant to the,null,null
253,intent hierarchy. We define HD-measure as:,null,null
254,"HD-measure@K , N -rec@K +(1-)HD-measure@K (15)",null,null
255,"where HD-measure can be HD-nDCG or HD-Q, and  is a parameter controlling the tradeoff between diversity and relevance. Besides, We define LAD-measure as:",null,null
256,"LAD-measure@K , N -rec@K + (1 - )D-measure-LA@K",null,null
257,(16),null,null
258,"where  is a parameter balancing diversity with relevance,",null,null
259,and D-measure-LA is the LA version of D-measure.,null,null
260,"To measure the relevance of ranked lists, HD-measures",null,null
261,"use HD-measures, while LAD-measures use D-measures-LA.",null,null
262,HD-measures and D-measures-LA reward high relevance to,null,null
263,"more popular nodes, and can handle layer weights. The",null,null
264,difference between them is what to combine over layers:,null,null
265,HD-measures combine the global gain for each layer while,null,null
266,D-measures-LA combine D-measures for each layer. Take,null,null
267,HD-nDCG and D-nDCG-LA as an example:,null,null
268,H D-nDC G@K,null,null
269,",",null,null
270,"K Kr,1",null,null
271,"r,1",null,null
272,"[[ HiHi,,11",null,null
273,wi wi,null,null
274, GGi(r)]/ log2 (r + 1)  GGi (r)]/ log2 (r + 1),null,null
275," H D-nDCG-LA@K , wi  D-nDCGi@K",null,null
276,"i,1",null,null
277,"where GGi(r) is the global gain for layer li at rank r, and D-nDCGi means only using the nodes of layer li.",null,null
278,Figure 3:,null,null
279,"Relationships of D-measures,",null,null
280,"LD-measures, HD-measures, and LAD-measures.",null,null
281,3.3.5 Summarization,null,null
282,"Since our measures use intent hierarchies, we call them hierarchical measures. Each of D-measures, LD-measures, HD-measures and LAD-measures is a linear combination of two measures: one measure mainly rewards the diversity of ranked lists, whereas another measure mainly rewards the relevance. We show their relationships in Figure 3. It can be seen that (1) To reward the diversity, LD-measures, HD-measures and LAD-measures use the whole intent hierarchy, whereas D-measures only use the leaf nodes; (2) To reward the relevance, HD-measures and LAD-measures use the whole intent hierarchy, whereas D-measures and LD-measures only use the leaf nodes.",null,null
283,4. EXPERIMENTS,null,null
284,4.1 Settings,null,null
285,"We experiment with the proposed measures on the TREC Web Track 2009-2013 diversity test collections and the new test collection mentioned in Section 3.2. The new test collection has two types of intent hierarchies, i.e. the original intent hierarchies (OIH), and the extended intent hierarchies (EIH). The results of our measures using OIH are different from those using EIH. In the following, subscript O means using the OIH, while subscript E means using the EIH.",null,null
286,"We use uniform probabilities for official intents like in TREC Web Track 2009-2013 diversity task. We use uniform layer weights when computing our measures, and leave the investigation of nonuniform weights to future. Unless stated otherwise, we use document cutoff K ,"" 20 for all measures, and  "","" 0.5 in Equation (7, 11, 15, and 16).""",null,null
287,4.2 Discriminative Power Results,null,null
288,"Following the previous work [19, 20, 23, 24, 21], we use the paired bootstrap test and set B ,"" 1, 000 (B is the number of bootstrap samples). When the queries have single-layer intent hierarchies: (1) LA measures are reduced to their corresponding existing measures. For example, D-measures-LA are reduced to D-measures; (2) LD-measures, HD-measures, and LAD-measures are reduced to D-measures. We conduct the experiments as follows: (1) Sampling 20 submitted runs every year (2009-2013), which produces 950 pairs of""",null,null
289,420,null,null
290,Table 1: Discriminative power and performance  of diversity measures based on the paired bootstrap test at,null,null
291," , 0.05. The leftmost column shows existing measures' results; the middle column shows their corresponding",null,null
292,LA measures' results using original intent hierarchies (denoted by subscript O); the rightmost column shows,null,null
293,their corresponding LA measures' results using extended intent hierarchies (denoted by subscript E). For,null,null
294,"each row, the greatest value is in bold.",null,null
295,(a) 250 queries in TREC Web Track 2009-2013,null,null
296,existing measures,null,null
297,measures based on OIH,null,null
298,measures based on EIH,null,null
299,measure disc.power required ,null,null
300,measure disc.power required ,null,null
301,measure disc.power required ,null,null
302,I-rec -nDCG ERR-IA nDCG-IA,null,null
303,Q-IA D-nDCG,null,null
304,D-Q,null,null
305,49.1% 56.8% 52.0% 53.4% 43.1% 55.1% 52.7%,null,null
306,0.14,null,null
307,I-rec-LAO,null,null
308,48.5%,null,null
309,0.13,null,null
310,I-rec-LAE,null,null
311,0.11,null,null
312,-nDCG-LAO,null,null
313,56.4%,null,null
314,0.12,null,null
315,-nDCG-LAE,null,null
316,0.12,null,null
317,ERR-IA-LAO,null,null
318,51.1%,null,null
319,0.14,null,null
320,ERR-IA-LAE,null,null
321,0.07,null,null
322,nDCG-IA-LAO,null,null
323,52.4%,null,null
324,0.06,null,null
325,nDCG-IA-LAE,null,null
326,0.06,null,null
327,Q-IA-LAO,null,null
328,42.7%,null,null
329,0.06,null,null
330,Q-IA-LAE,null,null
331,0.09,null,null
332,D-nDCG-LAO,null,null
333,54.4%,null,null
334,0.10,null,null
335,D-nDCG-LAE,null,null
336,0.09,null,null
337,D-Q-LAO,null,null
338,52.7%,null,null
339,0.09,null,null
340,D-Q-LAE,null,null
341,(b) 105 queries that have multilayer intent hierarchies (out of 250),null,null
342,49.7% 56.0% 52.1% 53.5% 43.5% 55.3% 53.7%,null,null
343,0.13 0.11 0.14 0.06 0.06 0.09 0.08,null,null
344,I-rec -nDCG ERR-IA nDCG-IA,null,null
345,Q-IA D-nDCG,null,null
346,D-Q,null,null
347,36.4% 38.7% 31.9% 29.9% 20.2% 38.9% 38.7%,null,null
348,0.23 0.22 0.19 0.11 0.14 0.17 0.17,null,null
349,I-rec-LAO -nDCG-LAO ERR-IA-LAO nDCG-IA-LAO,null,null
350,Q-IA-LAO D-nDCG-LAO,null,null
351,D-Q-LAO,null,null
352,33.4% 37.8% 31.2% 29.2% 20.3% 36.4% 36.3%,null,null
353,0.26 0.26 0.23 0.13 0.13 0.19 0.16,null,null
354,I-rec-LAE -nDCG-LAE ERR-IA-LAE nDCG-IA-LAE,null,null
355,Q-IA-LAE D-nDCG-LAE,null,null
356,D-Q-LAE,null,null
357,36.6% 37.9% 32.9% 32.3% 22.4% 39.7% 39.3%,null,null
358,0.26 0.18 0.21 0.13 0.14 0.18 0.16,null,null
359,Table 2: Discriminative power (shown in columns A),null,null
360,and performance  (shown in columns B) of diver-,null,null
361,sity measures ranked by their discriminative power,null,null
362,"based on the paired bootstrap test at  , 0.05. Baseline measures are marked by .",null,null
363,(a) 250 queries in TREC Web Track 2009-2013,null,null
364,measure A,null,null
365,B,null,null
366,measure A,null,null
367,B,null,null
368,HD-nDCGE 55.9% 0.11 HD-QE 53.4%,null,null
369,0.09,null,null
370,LD-nDCGO 55.5% 0.10 LAD-QO 53.4%,null,null
371,0.09,null,null
372,LD-nDCGE 55.3% 0.09 LD-QO 53.3%,null,null
373,0.09,null,null
374,LAD-nDCGE 55.2% 0.10 HD-QO 53.1% D-nDCG 55.1% 0.09 LAD-QE 52.9%,null,null
375,0.09 0.10,null,null
376,HD-nDCGO 54.7% 0.10 LAD-nDCGO 54.5% 0.10,null,null
377,LD-QE 52.7% D-Q 52.7%,null,null
378,0.09 0.09,null,null
379,(b) 105 queries that have multilayer intent hierarchies (out of 250),null,null
380,HD-nDCGE LD-nDCGE LAD-nDCGE,null,null
381, D-nDCG,null,null
382,LD-nDCGO LAD-nDCGO,null,null
383,HD-nDCGO,null,null
384,40.5% 40.0% 39.1% 38.9% 38.1% 36.8% 36.5%,null,null
385,0.16 0.17 0.19 0.17 0.19 0.21 0.17,null,null
386,LD-QE LAD-QE,null,null
387,HD-QE  D-Q,null,null
388,HD-QO LD-QO LAD-QO,null,null
389,39.4% 39.4% 38.9% 38.7% 38.1% 37.3% 37.1%,null,null
390,0.19 0.19 0.17 0.17 0.17 0.19 0.15,null,null
391,"sampled runs in total; (2) With the 950 pairs of sampled runs, computing the discriminative power and performance  using all 250 queries in TREC Web Track 2009-2013 diversity test collections; (3) With the 950 pairs of sampled runs, computing the discriminative power and performance  using the 105 queries that have multilayer intent hierarchies. Performance  is the required value to achieve statistical significance, and is computed following [21]. The results are shown in Table 1 and Table 2.",null,null
392,"By comparing the discriminative power scores of existing measures and their corresponding LA measures based on OIH or EIH in each row of Table 1, we find that: (1) Except -nDCG-LA, LA measures using EIH are more discriminative than their corresponding existing measures, especially in the case of IA measures. For example, when experimenting with 105 queries that have multilayer intent hierarchies, Q-IA-LAE (22.4%) outperforms Q-IA (20.2%) in terms of discriminative power; (2) The measures using OIH are less discriminative than the measures using EIH. For example, nDCG-IA-LAO is 29.2% while nDCG-IA-LAE is 32.3% when experimenting with 105 queries that have multilayer intent hierarchies.",null,null
393,"By comparing the discriminative power results of D-measures, LD-measures, HD-measures, and LAD-measures (each block in Table 2), we find that: (1) The measures using EIH are generally more discriminative than the measures using OIH; (2) When using EIH, LD-measures, HD-measures and LAD-measures are better than (or at least as good as) D-measures in terms of discriminative power.",null,null
394,"By comparing the results using all 250 queries in TREC Web Track 2009-2013 (shown in Table 1(a) or Table 2(a)) and the results only using the queries that have multilayer intent hierarchies (shown in Table 1(b) or Table 2(b)), we find that hierarchical measures have greater improvement of discriminative power than existing measures for queries that have multilayer intent hierarchies. This is reasonable because our measures have potential to recognize the difference between ranked lists by utilizing the hierarchies whereas existing measures cannot. Another justification is that our measures are equivalent to existing measures when the queries only have single-layer intent hierarchies.",null,null
395,"The above observations suggest that it is preferable to use EIH when computing hierarchical measures. We think that the hierarchical measures using EIH have higher discriminative power than the hierarchical measures using OIH. For example, Figure 2(b) shows that d1 is more diversified than d2 because d1 refers to two interpretations of the query, while d2 only refers to one of them. N-recE agrees with this but N-recO cannot tell which one is more diversified.",null,null
396,4.3 Intuitiveness,null,null
397,4.3.1 Difference between using OIH and EIH,null,null
398,"The hierarchical measures using EIH are more intuitive than using OIH in terms of diversity. Following the previous work [21], we use I-rec as the gold standard measure for the diversity because it does not depend on intent hierarchies OIH and EIH. Table 3 shows the intuitiveness when using all the queries in TREC Web Track 2009-2013 diversity test collections. We find that for a document cutoff K ,"" 10, the hierarchical measures using EIH are more intuitive than using OIH. For a document cutoff K "","" 20, there is only one exception (LD-nDCG@20).""",null,null
399,"This is because the hierarchical measures using OIH may reward high relevance to some official intents, and fail to",null,null
400,421,null,null
401,Table 3: Intuitiveness based on preference agree-,null,null
402,ment with I-rec. For each measure pair (using OIH,null,null
403,"or EIH), the higher score is shown in bold and",null,null
404,the numbers of disagreements between this pair are,null,null
405,shown in parentheses below.,null,null
406,"(a) Document cutoff K , 10. Gold standard measure: I-rec",null,null
407,ERR-,null,null
408,nDCG-,null,null
409,Q-,null,null
410,LD-,null,null
411,HD-,null,null
412,IA-LA,null,null
413,IA-LA,null,null
414,IA-LA,null,null
415,nDCG,null,null
416,nDCG,null,null
417,OIH .663,null,null
418,.624,null,null
419,.653,null,null
420,.802,null,null
421,.025,null,null
422,EIH .724,null,null
423,.748,null,null
424,.696,null,null
425,.841,null,null
426,.999,null,null
427,(4973),null,null
428,(5492),null,null
429,(4660),null,null
430,(2601),null,null
431,(3421),null,null
432,"(b) Document cutoff K , 20. Gold standard measure: I-rec",null,null
433,OIH .692,null,null
434,.656,null,null
435,.677,null,null
436,.821,null,null
437,.823,null,null
438,EIH .732,null,null
439,.748,null,null
440,.729,null,null
441,.739,null,null
442,.837,null,null
443,(5362),null,null
444,(6688),null,null
445,(5273),null,null
446,(2511),null,null
447,(5329),null,null
448,LADnDCG .753 .886 (4948),null,null
449,.827 .840 (5645),null,null
450,"reward wide coverage of the official intents. Take the OIH in Figure 2 as an example. Since we assume that the documents that are relevant to a node are relevant to its parent node, the relevance assessments for intent i1 or i5 are reflected in the relevance assessments for their parent node n1. Though the first layer of the OIH excludes i1 or i5, it indirectly considers them through their parent node n1. By including the other four intents, the first layer considers all six official intents, but the second layer of the OIH only has i1 or i5. When combining the two layers, the relevance assessments for i1 or i5 are considered twice, once in the first layer and again in the second layer. However, the relevance assessments for the other four intents are only considered once in the first layer. This means that when using the OIH, hierarchical measures mainly reward higher relevance to i1 and i5 than other intents. The EIH in Figure 2 solves this problem by extending i2, i3, i4, and i6 to the second layer so that every official intent can be considered in each layer when evaluating the ranking quality.",null,null
451,"In the remaining part of the section, we will only report experimental results using EIH due to space limitation. In most experiments, using EIH yields higher discriminative power and intuitiveness than OIH.",null,null
452,4.3.2 Intuitiveness of Hierarchical Measures,null,null
453,"In Section 4.2, we show that LD-nDCGE, HD-nDCGE, and LAD-nDCGE are highly discriminative among hierarchical measures. In this section, we further compare their intuitiveness with some existing measures, including -nDCG, ERR-IA, and D-nDCG. We do the concordance test based on all the queries in TREC Web Track 2009-2013 diversity test collections, and show the results in Table 4. In Table 4(a) and Table 4(b), we use N-recE and Precision as the gold standard measure respectively, whereas in Table 4(c), both N-recE and Precision are used as the gold standard measures. We use N-recE as a gold standard measure in terms of the diversity because: (1) It is a simple binary measures; (2) It measures diversity better than I-rec, which is traditionally used as the gold standard measure for diversity.",null,null
454,"Table 4 shows that (1) In terms of the diversity, LD-nDCGE, HD-nDCGE, and LAD-nDCGE are more intuitive than existing measures. This is expected because these hierarchical measures directly depend on N-recE by means of Equation (11) and the like; (2) In terms of diversity, LD-nDCGE is most intuitive; (3) In terms of relevance, HD-nDCGE is most intuitive; (4) In terms of both diversity and relevance, LAD-nDCGE is the most intuitive measure.",null,null
455,Table 4 shows that using the whole intent hierarchies instead of only using the leaf nodes can improve the intuitiveness of measures. HD-nDCGE and LAD-nDCGE use the,null,null
456,Table 4: Intuitiveness based on preference agree-,null,null
457,ment with gold standard measures. For each mea-,null,null
458,"sure pair, the higher score is shown in bold and",null,null
459,the numbers of disagreements between this pair are,null,null
460,shown in parentheses below.,null,null
461,"(a) Gold standard measure: N-recE (""diversity"")",null,null
462,ERR-,null,null
463,D-,null,null
464,LD-,null,null
465,-nDCG,null,null
466,IA,null,null
467,nDCG,null,null
468,nDCGE,null,null
469,.988/.362 .661/.983 .656/.986,null,null
470,(14215),null,null
471,(43908),null,null
472,(44098),null,null
473,ERR-IA,null,null
474,-,null,null
475,.577/.987 .573/.991,null,null
476,-,null,null
477,(56060),null,null
478,(56011),null,null
479,D-nDCG,null,null
480,-,null,null
481,-,null,null
482,.428/.612,null,null
483,-,null,null
484,-,null,null
485,(2124),null,null
486,LD-nDCGE,null,null
487,-,null,null
488,-,null,null
489,-,null,null
490,-,null,null
491,-,null,null
492,-,null,null
493,HD-nDCGE -,null,null
494,-,null,null
495,-,null,null
496,-,null,null
497,-,null,null
498,-,null,null
499,"(b) Gold standard measure: Precision (""relevance"")",null,null
500,ERR-,null,null
501,D-,null,null
502,LD-,null,null
503,-nDCG,null,null
504,IA,null,null
505,nDCG,null,null
506,nDCGE,null,null
507,.749/.345 .359/.746 .358/.749,null,null
508,(14215),null,null
509,(43908),null,null
510,(44098),null,null
511,ERR-IA,null,null
512,-,null,null
513,.348/.754 .346/.756,null,null
514,-,null,null
515,(56060),null,null
516,(56011),null,null
517,D-nDCG,null,null
518,-,null,null
519,-,null,null
520,.488/.592,null,null
521,-,null,null
522,-,null,null
523,(2124),null,null
524,LD-nDCGE,null,null
525,-,null,null
526,-,null,null
527,-,null,null
528,-,null,null
529,-,null,null
530,-,null,null
531,HD-nDCGE -,null,null
532,-,null,null
533,-,null,null
534,-,null,null
535,-,null,null
536,-,null,null
537,(c) Gold standard measures: N-recE and Precision,null,null
538,ERR-,null,null
539,D-,null,null
540,LD-,null,null
541,-nDCG,null,null
542,IA,null,null
543,nDCG,null,null
544,nDCGE,null,null
545,.738/.085 .156/.731 .154/.735,null,null
546,(14215),null,null
547,(43908),null,null
548,(44098),null,null
549,ERR-IA,null,null
550,-,null,null
551,.126/.742 .124/.747,null,null
552,-,null,null
553,(56060),null,null
554,(56011),null,null
555,D-nDCG,null,null
556,-,null,null
557,-,null,null
558,.036/.217,null,null
559,-,null,null
560,-,null,null
561,(2124),null,null
562,LD-nDCGE,null,null
563,-,null,null
564,-,null,null
565,-,null,null
566,-,null,null
567,-,null,null
568,-,null,null
569,HD-nDCGE -,null,null
570,-,null,null
571,-,null,null
572,-,null,null
573,-,null,null
574,-,null,null
575,HDnDCGE .663/.984 (44522) .578/.990 (56245) .700/.741 (3822) .898/.799 (2356) -,null,null
576,HDnDCGE .358/.751 (44522) .345/.758 (56245) .502/.625 (3822) .523/.629 (2356) -,null,null
577,HDnDCGE .159/.734 (44522) .127/.748 (56245) .267/.371 (3822) .432/.438 (2356) -,null,null
578,LADnDCGE .661/.984 (44444) .577/.990 (56209) .677/.738 (3586) .895/.811 (2026) .724/.915 (330),null,null
579,LADnDCGE .357/.751 (44444) .345/.758 (56209) .499/.625 (3586) .518/.633 (2026) .603/.552 (330),null,null
580,LADnDCGE .157/.735 (44444) .127/.749 (56209) .247/.368 (3586) .424/.449 (2026) .370/.476 (330),null,null
581,"whole intent hierarchy to measure both diversity and relevance of ranked lists. LD-nDCGE uses the whole intent hierarchy to measure the diversity but only uses the leaf nodes to measure the relevance. D-nDCG only uses the leaf nodes to measure the diversity and relevance. Table 4 shows that LD-nDCGE, HD-nDCGE and LAD-nDCGE are more intuitive than D-nDCG in terms of diversity. HD-nDCGE and LAD-nDCGE are more intuitive than D-nDCG and LD-nDCGE in terms of relevance. We get the same result when both diversity and relevance are considered.",null,null
582,4.3.3 Case Studies,null,null
583,"D-nDCG, LD-nDCGE, HD-nDCGE, and LAD-nDCGE are closely related (shown in Section 3.3.5 and Section 4.4). We examine their differences in terms of intuitiveness by looking at some real examples from the submitted runs in TREC Web Track 2009-2013 diversity task.",null,null
584,"Specifically, we select five pairs of real ranked lists from TREC Web Track diversity runs in Table 5, and refer to them as Case A-E. For example, Case A stands for two runs cmuFuTop10D and THUIR10DvNov for No. 77 query; The middle column shows the relevance assessments of the top ten documents in each run (e.g. the first document retrieved by cmuFuTop10D is relevant to intent i4 with a relevance rating 1); The last four columns show the 's for each query (e.g. score of cmuFuTop10D minus that of THUIR10DvNov) where arrows indicate which run has higher score under each measure. Note that in this section, the measures are computed for a document cutoff K , 10 because we only have space to show top 10 documents in Table 5. We categorize five cases into two classes from the viewpoint of diversity (Case A-C) or relevance (Case D-E).",null,null
585,422,null,null
586,"Table 5: Five ranked list pairs from TREC Web Track 2009-2013 diversity test collections, document cutoff",null,null
587,"K , 10. 1st column: case IDs (query IDs). 2nd column: run IDs. 3rd column: number of official intents",null,null
588,covered by each run. 4th column: number of nodes in extended intent hierarchies covered by each run. 5th,null,null
589,column: relevance ratings for each intent at ranks 1-10. The rightmost column: performance differences,null,null
590,using each measure and arrows point to its preferred run.,null,null
591,A (77) B (77) C (77),null,null
592,cmuFuTop10D THUIR10DvNov THUIR10DvQEW UAMSD10aSRfu msrsv2div qirdcsuog3,null,null
593,D,null,null
594,qutir11a,null,null
595,(117),null,null
596,uwBBadhoc,null,null
597,E,null,null
598,2011SiftR2,null,null
599,(128),null,null
600,UWatMDSdm,null,null
601,1,null,null
602,3 6 i4L1 3 8 i4L1 2 5 i4L1 26,null,null
603,3 8 i4L1 3 7 i3L1,null,null
604,3 5 i1L1 i2 L1,null,null
605,3 5 i1L3 i2 L2 i3 L3,null,null
606,3 5 i1L2 i2 L2 i3 L1,null,null
607,3 5 i1L1 i2 L1,null,null
608,2,null,null
609,i2 L1 i3 L1 i1 L1,null,null
610,3,null,null
611,i2 L1 i3 L1,null,null
612,Document rank,null,null
613,(i: official intents),null,null
614,4,null,null
615,5,null,null
616,6,null,null
617,7,null,null
618,i2 L1 i1 L1 i3 L1,null,null
619,i1 L1 i3 L1,null,null
620,i3 L1,null,null
621,i2 L1 i1 L1,null,null
622,i1 L2 i2 L1 i3 L1,null,null
623,i1 L1 i3 L1 i4 L1 i2 L1,null,null
624,i2 L1,null,null
625,i1 L1 i3 L1,null,null
626,i1 L2 i2 L2,null,null
627,i1 L2 i3 L2,null,null
628,i1 L1 i3 L1,null,null
629,i1 L1,null,null
630,i1 L2 i2 L2,null,null
631,8,null,null
632,i1 L1 i1 L3 i2 L1,null,null
633,9,null,null
634,i2 L1 i3 L1 i2 L1 i2 L1,null,null
635,10 i1 L1 i2 L1,null,null
636,i2 L1,null,null
637,i2 L1,null,null
638,i1 L1 i2 L2 i3 L1,null,null
639,i1 L2 i2 L2,null,null
640, in DnDCG 0.0013  0.0300  -0.0329 ,null,null
641,-0.0030 ,null,null
642,0.0087 ,null,null
643, in LDnDCGE,null,null
644,-0.1098  -0.0256  0.0226 ,null,null
645, in HDnDCGE,null,null
646,-0.0977  0.0011  -0.0115 ,null,null
647, in LADnDCGE,null,null
648,-0.0988  -0.0019  -0.0085 ,null,null
649,-0.0030 ,null,null
650,0.0171 ,null,null
651,0.0148 ,null,null
652,0.0087 ,null,null
653,-0.0005 ,null,null
654,0.0004 ,null,null
655,"In Case A, we argue that D-nDCG is less intuitive than the other three. THUIR10DvNov covers both ""bobcat company"" and ""wild bobcat"" while cmuFuTop10D only covers the former (Please refer to the detailed description for the official intents of No. 77 query shown in Figure 1) although both runs cover three leaf intents. In this sense, THUIR10DvNov is more diversified than cmuFuTop10D and should be preferred. Note that this is also a case where I-rec cannot tell which run is better but N-recE can. The rightmost column of Table 5 shows that only D-nDCG disagrees with this intuition. In Case B, we argue that D-nDCG and HD-nDCGE are less intuitive than the other two. Similar to Case A, UAMSD10aSRfu covers both ""bobcat company"" and ""wild bobcat,"" whereas THUIR10DvQEW fails to cover the latter. So UAMSD10aSRfu should be preferred, and only LAD-nDCGE and LD-nDCGE agree with this. In Case C, we argue that LD-nDCGE is the most intuitive among the four measures. In this case, both msrsv2div and qirdcsuog3 cover ""bobcat company"" and ""wild bobcat"". However, Figure 1 shows that msrsv2div covers both ""bobcat tractors"" and ""bobcat company homepage,"" which are sub intents of ""bobcat company,"" while qirdcsuog3 does not cover ""bobcat company homepage."" Because of this, msrsv2div should be preferred and only LD-nDCGE agrees with this.",null,null
656,"In summary, from the viewpoint of diversity, LD-nDCGE is the most intuitive measure. HD-nDCGE is less intuitive than LAD-nDCGE, but is more intuitive than D-nDCG.",null,null
657,"The two runs in Case D and in Case E have the same I-rec and N-recE, hence the measures' preference is determined by their Precision part (e.g. D-nDCG if it is D-nDCG, and HD-nDCGE if it is HD-nDCGE). In Case D, we argue that D-nDCG and LD-nDCGE are less intuitive than the other two. No matter whether measuring by I-rec or by N-recE, qutir11a and uwBBadhoc are equally good in terms of diversity. However, qutir11a should be preferred because its top ten documents are all relevant, whereas uwBBadhoc only has three. From the rightmost column of Table 5, we find that D-nDCG and LD-nDCGE fail to reflect this. In Case E, we argue that HD-nDCGE is the most intuitive among the four measures. UWatMDSdm should be preferred because it returns much more relevant documents than 2011SiftR2. In this case, only HD-nDCGE successfully recognizes this.",null,null
658,Table 6: Kendall's  / Symmetric ap by averaging over TREC Web track 2009-2013. Values greater,null,null
659,than .950 are shown in bold.,null,null
660,(a) 250 queries in TREC Web Track 2009-2013,null,null
661,ERR-,null,null
662,D-,null,null
663,LD-,null,null
664,HD-,null,null
665,LAD-,null,null
666,-nDCG,null,null
667,IA,null,null
668,nDCG,null,null
669,nDCGE,null,null
670,nDCGE,null,null
671,nDCGE,null,null
672,.923/.870 .840/.796 .845/.796 .843/.792 .844/.793,null,null
673,ERR-IA,null,null
674,-,null,null
675,.772/.699 .780/.706 .779/.704 .779/.706,null,null
676,D-nDCG,null,null
677,-,null,null
678,-,null,null
679,.976/.959 .976/.957 .977/.960,null,null
680,LD-nDCGE,null,null
681,-,null,null
682,-,null,null
683,-,null,null
684,.991/.988 .995/.993,null,null
685,HD-nDCGE -,null,null
686,-,null,null
687,-,null,null
688,-,null,null
689,.995/.994,null,null
690,(b) 105 queries that have multilayer intent hierarchies (out of 250),null,null
691,ERR-,null,null
692,D-,null,null
693,LD-,null,null
694,HD-,null,null
695,LAD-,null,null
696,-nDCG,null,null
697,IA,null,null
698,nDCG,null,null
699,nDCGE,null,null
700,nDCGE,null,null
701,nDCGE,null,null
702,.872/.802 .812/.747 .821/.755 .821/.758 .822/.759,null,null
703,ERR-IA,null,null
704,-,null,null
705,.701/.609 .714/.624 .712/.626 .714/.628,null,null
706,D-nDCG,null,null
707,-,null,null
708,-,null,null
709,.964/.941 .959/.933 .958/.932,null,null
710,LD-nDCGE,null,null
711,-,null,null
712,-,null,null
713,-,null,null
714,.984/.977 .986/.981,null,null
715,HD-nDCGE -,null,null
716,-,null,null
717,-,null,null
718,-,null,null
719,.996/.995,null,null
720,"Generally, from the viewpoint of relevance, LAD-nDCGE is more intuitive than LD-nDCGE. LAD-nDCGE is able to measure the relevance of ranked lists more accurately by considering the whole intent hierarchy, and thus make the measures more consistent with Precision than LD-nDCGE.",null,null
721,4.4 Rank Correlation Results,null,null
722,"We compute Kendall's  and ap for different pairs of measures to check the correlation between these measures. Results are shown in Table 6. The table shows that: (1) LD-nDCGE, HD-nDCGE and LAD-nDCGE are less correlated to existing measures, especially when only using the queries that have multilayer intent hierarchies. This is because our measures are able to recognize the subtle difference between ranked lists when multilayer intent hierarchies are used, whereas the existing measures may not. This indicates that our measures are useful and could be supplementary to the existing measures; (2) LD-nDCGE, HD-nDCGE, as well as LAD-nDCGE are more correlated to D-nDCG than -nDCG and ERR-IA. This is because they are different kinds of extensions of D-nDCG. Similar to D-nDCG, they model diversity and relevance in different components separately. They yield the same evaluation results when the queries only have single-layer intent hierarchies. (3) LD-nDCGE and HD-nDCGE are less correlated. As discussed in 4.3, LD-nDCGE prefers highly diversified ranked lists, whereas HD-nDCGE prefers highly relevant ranked lists.",null,null
723,423,null,null
724,5. CONCLUSIONS AND FUTURE WORK,null,null
725,"In this paper, we argued that user intents of a query could be hierarchical. We described the concept of hierarchical intents and proposed hierarchical measures that could work with intent hierarchies. We created a new test collection containing intent hierarchies based on the existing TREC Web Track 2009-2013 diversity test collections by grouping the official intents into original intent hierarchies and extending them to extended intent hierarchies. Our experimental results showed that our proposed hierarchical measures can be more discriminative than existing measures which use a flat list of intents and assume the independence among intents. We revealed that LD-nDCG should be used when the diversity of search results is more valued than the relevance, whereas HD-nDCG should be used when the relevance is more important. LAD-nDCG is a better choice when both diversity and relevance are important.",null,null
726,"In this paper, we simply assume that the official intents provided in TREC Web Track 2009-2013 diversity test collections are atomic intents. It is possible that some of these intents can be further divided into sub intents. We will investigate this in the future.",null,null
727,6. ACKNOWLEDGMENTS,null,null
728,"This work was supported by the National Key Basic Research Program (973 Program) of China under grant No. 2014CB340403, and the Fundamental Research Funds for the Central Universities, the Research Funds of Renmin University of China No. 15XNLF03, the National Natural Science Foundation of China (Grant No. 61502501, 61502502, and 61502503)",null,null
729,7. REFERENCES,null,null
730,"[1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, 2009.",null,null
731,"[2] J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR, 1998.",null,null
732,"[3] B. A. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. TOIS, 2012.",null,null
733,"[4] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In CIKM, 2009.",null,null
734,"[5] H. Chen and D. R. Karger. Less is more: probabilistic models for retrieving fewer relevant documents. In SIGIR, 2006.",null,null
735,"[6] C. L. Clarke, N. Craswell, and I. Soboroff. Overview of the trec 2009 web track. In TREC, 2009.",null,null
736,"[7] C. L. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. A comparative analysis of cascade measures for novelty and diversity. In WSDM, 2011.",null,null
737,"[8] C. L. Clarke, N. Craswell, I. Soboroff, and G. V. Cormack. Overview of the trec 2010 web track. In TREC, 2010.",null,null
738,"[9] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Buttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In SIGIR, 2008.",null,null
739,"[10] C. L. Clarke, M. Kolla, and O. Vechtomova. An effectiveness measure for ambiguous and underspecified queries. In ICTIR, 2009.",null,null
740,"[11] V. Dang and B. W. Croft. Term level search result diversification. In SIGIR, 2013.",null,null
741,"[12] V. Dang and W. B. Croft. Diversity by proportionality: an election-based approach to search result diversification. In SIGIR, 2012.",null,null
742,"[13] Z. Dou, S. Hu, K. Chen, R. Song, and J.-R. Wen. Multi-dimensional search result diversification. In WSDM, 2011.",null,null
743,"[14] Z. Dou, R. Song, and J.-R. Wen. A large-scale evaluation and analysis of personalized search strategies. In WWW, 2007.",null,null
744,"[15] B. J. Jansen, A. Spink, and T. Saracevic. Real life, real users, and real needs: a study and analysis of user queries on the web. Information Processing & Management, 2000.",null,null
745,"[16] K. Jarvelin and J. Kekalainen. Ir evaluation methods for retrieving highly relevant documents. In SIGIR, 2000.",null,null
746,"[17] M. G. Kendall. A new measure of rank correlation. Biometrika, 1938.",null,null
747,"[18] F. Radlinski and S. Dumais. Improving personalized web search using result diversification. In SIGIR, 2006.",null,null
748,"[19] T. Sakai. Bootstrap-based comparisons of ir metrics for finding one relevant document. In AIRS, 2006.",null,null
749,"[20] T. Sakai. Evaluating evaluation metrics based on the bootstrap. In SIGIR, 2006.",null,null
750,"[21] T. Sakai. Evaluation with informational and navigational intents. In WWW, 2012.",null,null
751,"[22] T. Sakai, N. Craswell, R. Song, S. Robertson, Z. Dou, and C.-Y. Lin. Simple evaluation metrics for diversified search results. In EVIA, 2010.",null,null
752,"[23] T. Sakai and S. Robertson. Modelling a user population for designing information retrieval metrics. In EVIA, 2008.",null,null
753,"[24] T. Sakai and R. Song. Evaluating diversified search results using per-intent graded relevance. In SIGIR, 2011.",null,null
754,"[25] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting query reformulations for web search result diversification. In WWW, 2010.",null,null
755,"[26] R. L. Santos, C. Macdonald, and I. Ounis. Selectively diversifying web search results. In CIKM, 2010.",null,null
756,"[27] R. L. Santos, C. Macdonald, and I. Ounis. Intent-aware search result diversification. In SIGIR, 2011.",null,null
757,"[28] C. Silverstein, H. Marais, M. Henzinger, and M. Moricz. Analysis of a very large web search engine query log. SIGIR Forum, 1999.",null,null
758,"[29] E. Yilmaz, J. A. Aslam, and S. Robertson. A new rank correlation coefficient for information retrieval. In SIGIR, 2008.",null,null
759,"[30] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond independent relevance: methods and evaluation metrics for subtopic retrieval. In SIGIR, 2003.",null,null
760,"[31] X. Zhu, A. B. Goldberg, J. Van Gael, and D. Andrzejewski. Improving diversity in ranking using absorbing random walks. In HLT-NAACL, 2007.",null,null
761,424,null,null
762,,null,null
