,sentence,label,data
0,Exploiting Semantic Coherence Features for Information Retrieval,null,null
1,"Xinhui Tu1 Jimmy Xiangji Huang1,2 Jing Luo3 Tingting He1",null,null
2,"1School of Computer Science, Central China Normal University, Wuhan, China 2School of Information Technology, York University, Toronto, Canada",null,null
3,"3School of Computer Science, Wuhan University of Science and Technology, Wuhan, China",null,null
4,tuxinhui@mail.ccnu.edu.cn jhuang@yorku.ca luojing@wust.edu.cn tthe@mail.ccnu.edu.cn,null,null
5,ABSTRACT,null,null
6,"Most of the existing information retrieval models assume that the terms of a text document are independent of each other. These retrieval models integrate three major variables to determine the degree of importance of a term for a document: within document term frequency, document length and the specificity of the term in the collection. Intuitively, the importance of a term for a document is not only dependent on the three aspects mentioned above, but also dependent on the degree of semantic coherence between the term and the document. In this paper, we propose a heuristic approach, in which the degree of semantic coherence of the query terms with a document is adopted to improve the information retrieval performance. Experimental results on standard TREC collections show the proposed models consistently outperform the state-of-the-art models.",null,null
7,Keywords,null,null
8,Document ranking; Retrieval model; Term weighting,null,null
9,1. INTRODUCTION AND MOTIVATION,null,null
10,"Most of the existing information retrieval (IR) models assume that the terms of a text document are independent of each other. Generally, these retrieval models integrate three major variables to determine the degree of importance of a term for a document: within document term frequency, document length and the specificity of the term in the collection [4]. Though these approaches are reasonably simple and easy-to-use, the coherence aspect of a term's saliency in a document cannot be taken into account by the term independence assumption.",null,null
11,"The terms in a document can generally be classified into two groups: topical term and non-topical term. The topical terms will be highly associated with each other, while the non-topical terms will have very low association with the other terms within the document. Let us consider two arbitrary documents and as follows:",null,null
12,": So let's say you're out for a walk in the woods, with your iPhone handy, and you run into a grizzly bear ......",null,null
13,": Currently, Apple company has had to allocate massive resources to its iTunes and iPhone ......",null,null
14,"The first document is concerned about ""grizzly bear"" and the second document is related to ""Apple Company"". Suppose that the",null,null
15,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. SIGIR '16, July 17­21, 2016, Pisa, Italy. © 2016 ACM. ISBN 978-1-4503-4069-4/16/07...$15.00. DOI: http://dx.doi.org/10.1145/2911451.2914691",null,null
16,"two documents are equal in length. When we use ""iPhone"" as query, all the retrieval models mentioned above will give approximately the same score for the two documents. However, the word ""iPhone"" is a topical term in document and a nontopical term in document . Apparently, the document is more relevant to the query than document . As we can see from the example, the degree of importance of a term for a document is dependent not only on the three aspects mentioned before, but also dependent on the degree of semantic coherence between the term and the document.",null,null
17,"Humans can easily identify the topical terms and the non-topical terms of a document, because they have the knowledge of the ""word association"". In , the term ""iPhone"" appears with many other terms such as ""Apple"", ""iTunes"", which are associated with the term ""iPhone"". In , however, the term ""iPhone"" seems to be irrelevant to the other terms such as ""woods""and ""bear""'. For computational purposes, this knowledge can be discovered by analyzing the corpus. Semantic association measures based on corpus analysis have served this purpose for many applications related to natural language processing and IR [6].",null,null
18,"In this paper, we study how to efficiently use semantic coherence features to improve the information retrieval performance. We propose an approach to use the degree of semantic coherence between term and document for document ranking. First, each document is represented as a graph-of-word that corresponds to a weighted directed graph whose vertices represent unique terms, whose edges represent the translation probability between two terms. Then, a graph-based algorithm is adopted to calculate coherence-based weighting score of a term within a document. The coherence-based weight score of a term for a document is determined by the degree of semantic relatedness between the term and the other terms within the document. Finally, the coherence-based document score and the frequency-based score obtained by the existing retrieval function are integrated into a linear feature-based model for document ranking. Experimental results on standard TREC collections show the proposed model consistently outperform the state-of-the-art models.",null,null
19,2. RELATED WORK,null,null
20,"Over the decades, many different retrieval models have been proposed and studied, including the vector space model [16, 17], the classic probabilistic model [7, 13, 14] and the language modeling approach [12, 19]. Most of the existing retrieval models assume a ""bag-of-words"" representation of both documents and queries. A typical effective retrieval function involves a TF part, an IDF part, and a document length normalization part [4]. The TF part intents to give a higher score to a document that has more occurrences of a query term, while the IDF part is to penalize words that are popular in the whole collection. The document length normalization is to avoid favoring long documents.",null,null
21,837,null,null
22,"Most of the traditional retrieval models employ a single term frequency normalization mechanism that does not take into account various aspects of a term saliency in a document [11, 18]. Paik [11] proposes a novel TF-IDF term weighting schema (MATF) that employs two different within document term frequency normalizations to capture two different aspects of term saliency. The experimental results show that MATF achieves significantly better precision than the start-of-the-art models, such as BM25 [14] and LMDir (the language modeling approach with Dirichlet prior smoothing) [19].",null,null
23,"Intuitively, the degree of semantic coherence between a term and a document is an important factor to determine the importance of the term in the document. However, little work has been done around coherent-based term weighting. To the best of our knowledge, the model proposed in [6] is the only work closely related to ours. In the paper, the authors propose a neighborhood based document smoothing model by exploiting lexical association between terms. Different from their work, we adopt a linear feature-based model for final document ranking instead of modifying the traditional retrieval functions.",null,null
24,"Inspired by the success of graph-based ranking algorithms like TextRank [9], some researches attempt to adopt graph-based document representation for improving information retrieval performance [1, 15]. Generally, a graph based ranking algorithm is a way of deciding on the importance of a vertex within a graph, by taking into account global information recursively computed from the entire graph rather than relying only on local vertexspecific information. Our work is different from the existing graph-based retrieval methods in two aspects: (1) Each edge is weighted by the mutual information between the two terms, instead of by the number of co-occurrences of the two term in sliding windows; (2) The final ranking score of a document is determined by the combination of the graph-based term weighting score and the frequency-based score instead of by the graph-based term weighting score alone.",null,null
25,3. PROPOSED APPROACH,null,null
26,"In this section, we introduce a graph-based model to calculate weighting score for terms and then use these score for final document ranking.",null,null
27,3.1 Coherence-based Term Weighting,null,null
28,"The coherence-based weight score of a term for a document is determined by the degree of semantic relatedness between the term and the other terms within the document. Let us consider the example mentioned in section 1 again. Once the semantic relatedness has been calculated, ""iPhone"" will have a higher relatedness with the terms such as ""Apple, iTunes, company"" than the terms such as ""bear, woods, walk"". Therefore, ""iPhone"" will get a higher coherence-based weight score in document d2 than in document d1. When we use iPhone as query, document d2 will get a higher coherence-based score.",null,null
29,"In this paper, we adopt a graph-based ranking algorithm to calculate the coherence-based weight score of a term within a document. Each textual document is represented as a graph-ofword that corresponds to a weighted directed graph whose vertices represent unique terms, whose edges represent the translation probability between two terms. We prefer to use term rather than word because tokenization and feature selection algorithms (such as stop word removal) have already been applied. The coherence-based weight score of a term within a document is determined by the votes that are casting for it and the weight of the terms casting that votes. The weight of term t within",null,null
30,document d is initially set to 1 and the following PageRank function is run for several iterations,null,null
31,1,null,null
32,",",null,null
33,1,null,null
34,",",null,null
35,"where is a damping factor that can be set between 0 and 1,",null,null
36,which has the role of integrating into the model the probability of,null,null
37,jumping from a given vertex to another random vertex in the,null,null
38,"graph. In the context of the Web, this graph based ranking",null,null
39,"algorithm implements a random walk model, where a user clicks",null,null
40,"on links at random with a probability d, and jumps to a completely",null,null
41,new page with probability 1,null,null
42,[10]. We set the damping,null,null
43,"factor to 0.85, the convergence threshold to 0.0001, following [9,",null,null
44,10]. Our experiments showed that only a small number of,null,null
45,iterations (< 50) is required to obtain convergence.,null,null
46,"In formula (1),",null,null
47,", is the translation probability from term",null,null
48,to term in the graph of document . A simple way to,null,null
49,estimate,null,null
50,", is as follows:",null,null
51,where,null,null
52,",",null,null
53,",",null,null
54,",",null,null
55,2,null,null
56,", is the strength of association between two term",null,null
57,and .,null,null
58,To calculate,null,null
59,", in formula (2), we adopted a pairwise",null,null
60,"term similarity score, which is a combination of mutual information and a distance factor. The distance factor exponentially decreased as the distance between terms increased. The assumption behind this work is that semantically related words are usually located in proximity, and the distance between two words could indicate the strength of their association. The",null,null
61,pairwise term similarity score of terms and can be calculate,null,null
62,as follows:,null,null
63,",",null,null
64,",",null,null
65,",",null,null
66,3,null,null
67,",",null,null
68,",",null,null
69,4,null,null
70,where,null,null
71,", is the average distance between terms and",null,null
72,"in all the documents in the collection; is the decaying rate for the exponential function. In our experiments, the decaying rate is set to 0.8, following [5].",null,null
73,"In formula (3),",null,null
74,", denotes the mutual information between",null,null
75,"term and , which can be calculated as follows:",null,null
76,",",null,null
77,",",null,null
78,",",null,null
79,5,null,null
80,",",null,null
81,",",null,null
82,where and are binary variables indicating whether term or,null,null
83,is present or absent. The probabilities are estimated as follows:,null,null
84,1,null,null
85,1,null,null
86,0 1,null,null
87,1,null,null
88,1,null,null
89,1,null,null
90,01,null,null
91,1,null,null
92,"1, 1",null,null
93,"1, 1",null,null
94,"1, 0",null,null
95,1,null,null
96,"1, 1",null,null
97,"1, 0",null,null
98,1,null,null
99,"1, 1",null,null
100,"0, 0 1",null,null
101,"1, 1",null,null
102,"0, 1",null,null
103,"1, 0",null,null
104,838,null,null
105,where,null,null
106,1 and,null,null
107,1 are the numbers of documents,null,null
108,"containing term or , respectively,",null,null
109,"1, 1 is the",null,null
110,"number of documents that contain both or , and in the total",null,null
111,number of documents in the collection.,null,null
112,3.2 Retrieval Function,null,null
113,Coherence-based term weighting score itself may be not effective,null,null
114,to be used as the only scoring function for retrieval. It's a,null,null
115,potential way to incorporate coherence-based term weighting,null,null
116,score into the traditional retrieval functions for document ranking.,null,null
117,"However, it is not always possible to easily incorporate new",null,null
118,"feature into the traditional retrieval functions, which are built",null,null
119,"upon some underlying theoretical framework [8]. For example, it",null,null
120,proved non-trivial to include query independent features such as,null,null
121,PageRank into BM25 ranking formula [2]. Therefore we adopt a,null,null
122,"linear feature-based model for final document ranking, instead of",null,null
123,modifying the traditional retrieval functions. The linear feature-,null,null
124,based model has been proven to be an effective way to,null,null
125,incorporate different features into a united retrieval model [8].,null,null
126,The final retrieval function can be described as follows:,null,null
127,",",null,null
128,1,null,null
129,", ,",null,null
130,1  1,null,null
131,", ,",null,null
132,6,null,null
133,"where , is the document score calculate by the existing",null,null
134,"retrieval functions, such as BM25, LMDir, and MATF;",null,null
135,",",null,null
136,is the coherence-based weight scores of all query's term within a,null,null
137,"document, which can be calculate as follows:",null,null
138,",",null,null
139,St  t,null,null
140,7,null,null
141,where,null,null
142,can be calculated by formula (1);,null,null
143,inverse document frequency of term ,null,null
144,is the,null,null
145,4. EXPERIMENTS 4.1 Test Collections and Baseline Models,null,null
146,"Table 1 summarizes that statistics on test collections used in our experiments. These collections are different in size and genre. Each document is processed in a standard way for indexing. Words are stemmed (using porter-stemmer), and stop words are removed. In the experiments, we only use title of the queries. In order to evaluate our model and compare it to other models, we use the MAP and P@10 measure, which are widely accepted measure for evaluating effectiveness of ranked retrieval systems. The methods used in our experiments are as listed in Table 2.",null,null
147,4.2 Parameter Sensitivity Study,null,null
148,"An important issue that may affect the robustness of the proposed models is the sensitivity of their parameter (in Equation 6). The parameter controls weight of coherence-based weighting score in the final ranking function. In this section, we study how sensitive the parameter is to MAP measure. At the current stage of our work, the parameter is selected through grid search.",null,null
149,"In order to find the optimal value of parameter , we sweep the values from 0 to 1 with an interval of 0.1. When  equals to 0, we reach the baseline. When  equals to 1, the retrieval model use coherence-based weighting score only. The value of  controls the influence of coherence-based weighting score. Figure 1 shows the sensitivity of the value of parameter according to MAP measure. The experimental results show that parameter can greatly impact the performance of the proposed models. Generally, the performance of all models increases at the beginning when the value of grows up. The performance of each model starts to continually drop after a peak. However, this is no unique optimal",null,null
150,Collection AP88-89 TREC8,null,null
151,WT2G WT10G,null,null
152,Table 1. Test collection statistics,null,null
153,# of Docs,null,null
154,Topics,null,null
155,"164,597",null,null
156,51-100,null,null
157,"528,155",null,null
158,301-450,null,null
159,"247,491",null,null
160,401-450,null,null
161,"1,692,096",null,null
162,451-550,null,null
163,# of Topics 50 50 50,null,null
164,100,null,null
165,Table 2. The retrieval models used in the experiments,null,null
166,Model BM25 LMDir,null,null
167,MATF,null,null
168,ConRank-BM25,null,null
169,ConRank-LMDir,null,null
170,ConRank-MATF,null,null
171,Description,null,null
172,The classical probabilistic model [14],null,null
173,The language modeling approach with Dirichlet prior smoothing [19],null,null
174,A novel TF-IDF model with excellent retrieval performance [11].,null,null
175,"The proposed model using BM25 function to calculate ,",null,null
176,"The proposed model using LMDir function to calculate , .",null,null
177,"The proposed model using MATF function to calculate ,",null,null
178,"value of for all of them. For example, the best values on collection AP88-89 are 0.3, 0.4, and 0.3 for ConRank-BM25, ConRank-LMDir, and ConRank-MATF, respectively. For all models on all datasets, we can gain the best retrieval performance",null,null
179,when 0.2   0.4. The proposed models constantly perform,null,null
180,"better than the corresponding baseline while range from 0.1 to 0.6. When the value of is too large in the linear feature-based model, the performance is downward and even worse than that of the baseline.",null,null
181,4.3 Comparing with the State-of-the-art Models,null,null
182,"In order to make the comparison fair, we need to carefully choose suitable values for the parameters in all the models. To build strong baselines, we adopt a method proposed in [3] to find the optimal parameter settings for BM25 and LMDir. All parameters in BM25 and LMDir are respectively set to the optimal values in our experiments. As a parameter free model, MATF does not need parameter tuning. In the proposed models, parameter and k are respectively set to 0.8 and 0.85 following [5, 10]. The previous research work [20] has demonstrated that when a new feature is integrated into a traditional retrieval function under linear interpolation, the best retrieval performance can be obtained by assigning a relatively small weight (0.1-0.2) to the new feature. As we can see from the experiments presented in section 4.2, good performance can be archived with parameter are set to 0.3. Therefore, the parameter in the proposed models is set to 0.3 in the following experiments.",null,null
183,"Table 3 present the retrieval results of the six retrieval models on the four collections respectively. The results indicate that the proposed models constantly outperform the corresponding baseline on all collections. In most of the cases, the improvement of MAP and P@10 was statistically significant. The maximum average improvement is as high as 7.81% and 7.32% in terms of MAP and P@10, respectively. It is worth noting that MATF has obtained significant improvements over BM25 and LMDir, and is therefore a strong baseline. The significant performance improvements from such a strong baseline are very encouraging. The results confirm that semantic coherent features can be used to improve the retrieval performance.",null,null
184,839,null,null
185,Figure 1. Sensitivity of parameter to MAP measure,null,null
186,Table 3. Comparison of the performance of the six models in terms of MAP and P@10 (The values in the parentheses are the improvement over the model in the previous row in the table; * indicates a statistically,null,null
187,improvements over the model in the previous row according to the Wilcoxon signed-rank test at the 0.05 level),null,null
188,Model,null,null
189,AP88-89,null,null
190,P@10,null,null
191,MAP,null,null
192,TREC8,null,null
193,P@10,null,null
194,MAP,null,null
195,WT2G,null,null
196,P@10,null,null
197,MAP,null,null
198,WT10G,null,null
199,P@10,null,null
200,MAP,null,null
201,BM25 ConRank-BM25,null,null
202,0.4216,null,null
203,0.4489* (+6.48%),null,null
204,0.2702,null,null
205,0.2913* (+7.81%),null,null
206,0.4645,null,null
207,0.4853* (+4.48%),null,null
208,0.2552,null,null
209,0.2693* (+5.53%),null,null
210,0.4957,null,null
211,0.5320* (+7.32%),null,null
212,0.3128,null,null
213,0.3349* (+7.07%),null,null
214,0.3626,null,null
215,0.3747* (+3.34%),null,null
216,0.2107,null,null
217,0.2184* (+3.65%),null,null
218,LMDir ConRank-LMDir,null,null
219,0.4416,null,null
220,0.4595* (+4.05%),null,null
221,0.2768,null,null
222,0.2936* (+6.07%),null,null
223,0.4753,null,null
224,0.4918* (+3.47%),null,null
225,0.2509,null,null
226,0.2615* (+4.22%),null,null
227,0.5063,null,null
228,0.5409* (+6.83%),null,null
229,0.3057,null,null
230,0.3211* (+5.04%),null,null
231,0.3108,null,null
232,0.3154 (+1.48%),null,null
233,0.2094,null,null
234,0.2128 (+1.62%),null,null
235,MATF ConRank-MATF,null,null
236,0.4679,null,null
237,0.4872* (+4.12%),null,null
238,0.2994,null,null
239,0.3186* (+6.41%),null,null
240,0.4905,null,null
241,0.5097* (+3.91%),null,null
242,0.2671,null,null
243,0.2752* (+3.03%),null,null
244,0.5481,null,null
245,0.5594* (+2.06%),null,null
246,0.3241,null,null
247,0.3392* (+4.66%),null,null
248,0.3283,null,null
249,0.3327 (+1.34%),null,null
250,0.2226,null,null
251,0.2301* (+3.37%),null,null
252,5. CONCLUSIONS AND FUTURE WORK,null,null
253,"In this paper, a new term weighting approach is proposed to calculate the degree of semantic coherence of the query terms with a document. The coherence-based term weighting score can further be used in combined with the existing retrieval functions for document ranking. Experimental results on standard TREC collections show the proposed retrieval methods consistently outperform the corresponding strong baselines. The results confirm that semantic coherent features can be used to improve the retrieval performance. At the current stage of our work, only one type of distance measure is adopted to calculate semantic similarity between terms, and the values of the parameters in the proposed models are chosen empirically. For future work, we will investigate the effectiveness of other distance measures and study how to find the optimal parameter setting for further improving the retrieval performance.",null,null
254,6. ACKNOWLEDGMENTS,null,null
255,"This work was partially supported by the National Science Foundation of China under the grant number 61572223, a Discovery grant from the Natural Sciences & Engineering Research Council (NSERC) of Canada and an NSERC CREATE award. We thank anonymous reviewers for their thorough review comments.",null,null
256,7. REFERENCES,null,null
257,"[1] Blanco R. and Lioma C. Graph-based term weighting for information retrieval. Information Retrieval, 15(1), 54­92, 2012.",null,null
258,"[2] Craswell N., Robertson S. and Zaragoza H. Relevance weighting for query independent evidence. ACM SIGIR, 416-423, 2005.",null,null
259,"[3] Diaz, F. and Metzler, D. Improving the estimation of relevance models using large external corpora. ACM SIGIR, 154-161, 2006.",null,null
260,"[4] Fang, H., Tao, T. and Zhai, C. A formal study of information retrieval heuristics. ACM SIGIR, 49­56, 2004.",null,null
261,"[5] Gao, J., Zhou, M., Nie, J. Y., He, H., and Chen, W. Resolving query translation ambiguity using a decaying co-occurrence model and syntactic dependence relations. ACM SIGIR, 183-190, 2002.",null,null
262,"[6] Goyal, P., Behera, L. and McGinnity, T. M. A novel neighborhood based document smoothing model for information retrieval. Information retrieval, 16(3), 391-425, 2013",null,null
263,"[7] Jones, K. S., Walker, S. and Robertson, S. E. A probabilistic model of information retrieval: development and comparative experiments part 1. Information Processing Management, 36(6), 779­808, 2000.",null,null
264,"[8] Metzler, D. and Croft, W. B. Linear feature-based models for information retrieval. Information Retrieval, 10(3), 257-274, 2007.",null,null
265,"[9] Mihalcea, R. and Tarau, P. TextRank: bringing order into texts. EMNLP, 2004.",null,null
266,"[10] Page, L., Brin, S., Motwani, R. and Winograd, T. The PageRank citation ranking: bringing order to the Web. Technical report, Stanford Digital Library Technologies Project, 1998.",null,null
267,"[11] Paik, J. H. A novel TF-IDF weighting scheme for effective ranking. ACM SIGIR, 343-352, 2013.",null,null
268,"[12] Ponte, J. M. and Croft, W. B. A language modeling approach to information retrieval. ACM SIGIR, 275­281, 1998.",null,null
269,"[13] Robertson, S. E. Readings in information retrieval. Chapter The probability ranking principle in IR, pages 281­286. Morgan Kaufmann Publishers Inc., 1997.",null,null
270,"[14] Robertson, S. and Zaragoza, H. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends in Information Retrieval, 3(4), 333­389, 2009.",null,null
271,"[15] Rousseau, F. and Vazirgiannis, M. Graph-of-word and TW-IDF: new approach to ad hoc IR. ACM CIKM, 59-68, 2013.",null,null
272,"[16] Salton, G., Wong, A., and Yang. C. S. A vector space model for automatic indexing. Communications of the ACM, 18(11), 613­620, 1975.",null,null
273,"[17] Salton, G. McGill, M. J. Introduction to modern information retrieval. McGraw-Hill, Inc., 1986.",null,null
274,"[18] Ye, Z. and Huang, J. X. A simple term frequency transformation model for effective pseudo relevance feedback. ACM SIGIR, 323-332, 2014.",null,null
275,"[19] Zhai, C. and Lafferty, J. A study of smoothing methods for language models applied to information retrieval. ACM Transaction on Information System, 22(2), 179­214, 2004.",null,null
276,"[20] Zhao, J., Huang, J. X., and Ye, Z. Modeling term associations for probabilistic information retrieval. ACM Transactions on Information Systems, 32(2), 7, 2014.",null,null
277,840,null,null
278,,null,null
