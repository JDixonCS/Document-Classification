,sentence,label,data
0,A Simple Enhancement for Ad-hoc Information Retrieval via Topic Modelling,null,null
1,"Fanghong Jian1, Jimmy Xiangji Huang, Jiashu Zhao2, Tingting He3 and Po Hu3",null,null
2,"Information Retrieval and Knowledge Management Research Lab 1National Engineering Research Center for E-Learning, 3School of Computer Science, Central China Normal University, Wuhan, China; 2School of Information Technology, York University, Toronto, Canada",null,null
3,"jhuang@yorku.ca, jfhrecoba@mails.ccnu.edu.cn, jessie@cse.yorku.ca",null,null
4,ABSTRACT,null,null
5,"Traditional information retrieval (IR) models, in which a document is normally represented as a bag of words and their frequencies, capture the term-level and document-level information. Topic models, on the other hand, discover semantic topic-based information among words. In this paper, we consider term-based information and semantic information as two features of query terms and propose a simple enhancement for ad-hoc IR via topic modeling. In particular, three topic-based hybrid models, LDA-BM25, LDA-MATF and LDA-LM, are proposed. A series of experiments on eight standard datasets show that our proposed models can always outperform significantly the corresponding strong baselines over all datasets in terms of MAP and most of datasets in terms of P@5 and P@20. A direct comparison on eight standard datasets also indicates our proposed models are at least comparable to the state-of-the-art approaches.",null,null
6,Keywords,null,null
7,Probabilistic Model; Dirichlet Language Model; LDA,null,null
8,1. INTRODUCTION,null,null
9,"Many traditional IR models are based on the assumption that query terms are independent of each other, where a document is represented as a bag of words. Nevertheless this assumption may not hold in practice. Each document may contain several different topics and terms appeared in the document might belong to different topics, which represent different semantic information. Many researchers have been working on term topic information in IR [1, 10, 15, 16]. However, the nature of the associations among query terms still awaits further study. Some cluster-based approaches consider each document has only one topic [10], which is not reasonable to model large collection of documents. Topicbased document representation is effective in the language modeling (LM) framework [1, 15, 16]. But there is no generality in BM25 [2, 6, 20] and MATF (Multi Aspect TF) [13] based frameworks.",null,null
10,"In this paper, we present three hybrid models for enhanc-",null,null
11,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",null,null
12,"SIGIR '16, July 17-21, 2016, Pisa, Italy",null,null
13,c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00,null,null
14,DOI: http://dx.doi.org/10.1145/2911451.2914750,null,null
15,"ing traditional IR model via topic modelling. In our proposed approach, term-based information and semantic information are considered as two features of query terms. Latent Dirichlet Allocation (LDA) [3] is utilized to combine these two features and enhance three well-known traditional IR models BM25 [2], MATF [13] and Dirichlet LM [18]. In particular, three hybrid models, denoted as LDA-BM25, LDA-MATF and LDA-LM, are proposed respectively. The main contributions of this paper are as follows. First we propose three simple but effective IR models by combining traditional IR models with topic model. Second we conduct extensive experiments to confirm the effectiveness of our proposed models.",null,null
16,"The remainder of this paper is organized as follows. We describe the related work and propose three topic-based hybrid models for ad-hoc IR in Section 2 and 3 respectively. In Section 4, we set up our experimental environment on eight TREC collections. In Section 5, the experimental results are presented and discussed. Finally, we conclude our work briefly and present future research directions in Section 6.",null,null
17,2. RELATED WORK,null,null
18,"Since the 1990s, researchers started to investigate how to integrate term association into IR models [8, 12, 16, 19, 20]. The query-term associations have been modeled by different approaches according to the distance of the query terms in documents. For example, Buttcher et al. (2006) [4] used a proximity accumulator to associate each query term. Lv and Zhai (2009) [11] proposed a positional language model (PLM) that incorporated the term proximity in a modelbased approach using term-propagation functions. Metzler et al. (2005) [12] proposed a Markov Random Fields (MRF) model which modeled the joint distribution over queries and documents. Song et al. (2011) [14] proposed Proximity Probabilistic Model (PPM) which used a position-dependent term count to represent both the number of occurrences of a term and the term counts propagated from other terms. Recently, topic models have been widely used to explore latent term association in knowledge discovery and other related area. Liu and Croft (2004) [10] proposed cluster-based retrieval models under the language modeling framework, which were used to smooth the probabilities in the document model. In their approach, a document is supposed to contain only one topic, which is not reasonable to model large collection of documents. Azzopardi et al. (2004) [1] showed that it was effective to use the LDA model [3] to smooth the probabilities in the document model on several small collections. Wei and Croft (2006) [15] also discussed the applications of LDA in large collections, and presented a detailed evalua-",null,null
19,733,null,null
20,"tion of the effectiveness. Yi and Allan (2009) [17] explored the utility of Mixture of Unigrams (MU) model, LDA and Pachinko Allocation Model (PAM) [9] for IR. They showed that topic models were effective for document smoothing. More rigorous topic models like LDA provided gains over cluster-based models and more elaborate topic models that capture topic dependencies provided no additional gains. Although it is effective to integrate topic models into the language modeling framework, how to integrate topical information into other traditional IR models is not clear.",null,null
21,3. OUR APPROACH,null,null
22,"For enhancing performance, topic model is integrated into",null,null
23,"traditional retrieval models. First, the latent semantic in-",null,null
24,formation of query terms in a document is extracted via,null,null
25,"topic modeling. Then, the term-based information is ob-",null,null
26,tained through traditional retrieval models. The documents,null,null
27,that are more related to the query according to both seman-,null,null
28,tic topic-based information and term-based information are,null,null
29,"boosted in the ranking process. For clarification, Table 1",null,null
30,outlines the notations used throughout the paper.,null,null
31,Notations,null,null
32,c,null,null
33,d,null,null
34,q,null,null
35,qi dl,null,null
36,avdl,null,null
37,N,null,null
38,n,null,null
39,tf,null,null
40,qtf,null,null
41,z,null,null
42,Kt,null,null
43,"p, w ,",null,null
44,"wpm  ,l",null,null
45,w,null,null
46,"b, k1 , k3 µ",null,null
47,", ",null,null
48,Table 1: Notations,null,null
49,Description,null,null
50,collection document query query term length of document average document length number of indexed documents in collection number of indexed documents containing a term within-document term frequency within-query term frequency topic number of topics probability function,null,null
51,weighting function parameter in BM25 Dirichlet prior in Dirichlet LM hyperparameter in LDA,null,null
52,3.1 Topic-based Hybrid Model,null,null
53,Traditional retrieval models only capture term-based in-,null,null
54,"formation. On the other hand, topic models acquire seman-",null,null
55,"tic information between words. In this paper, we propose",null,null
56,enhanced retrieval models that consider not only term fre-,null,null
57,"quency, document frequency and document length, but also",null,null
58,term topics information. We treat term-based information,null,null
59,and semantic topic-based information as two features for,null,null
60,query terms. The enhanced retrieval models combine these,null,null
61,two features.,null,null
62,"Given a query q, for each term qi in query q, w(qi, d) is the",null,null
63,enhanced weight for document d. In order to capture the two,null,null
64,"kinds of information, we use a parameter  to balance their",null,null
65,importance. So the weight of a query term for a document,null,null
66,is as follows.,null,null
67,"w(qi, d) ,"" (1 - ) · w(qi, d) +  · w(qi, d)""",null,null
68,(1),null,null
69,"where w(qi, d) represents the explicit term-based related information in traditional retrieval model for document d, w(qi, d) is the implicit semantic information in topic model. Finally, a document's weight for a query is given by the sum of its weight for each term in the query. When  equals to 0, the hybrid models become traditional IR models such as BM25 and LM. When  equals to 1, the hybrid models become topic models. Because traditional IR models and topic models are normalized independently, the value of  changes with different combinations. It is well known that BM25, MATF and Dirichlet LM are the state-of-the-art traditional IR models and LDA is a simple but effective topic model. Therefore, we use BM25, MATF and Dirichlet LM as the traditional models and we use LDA as the topic model.",null,null
70,3.2 Topic Model,null,null
71,"In general, topic model is used to capture latent seman-",null,null
72,tic information of terms in document. There are a lot of,null,null
73,"topic models, such as probabilistic Latent Semantic Index-",null,null
74,"ing (pLSI) [7], LDA [3] and PAM [9]. LDA is a simple and",null,null
75,"effective topic model, and is broadly used. In this paper, we",null,null
76,use LDA as our topic model.,null,null
77,LDA model can generate the probability of topics in a doc-,null,null
78,"ument and the probability of words in a topic, which can ob-",null,null
79,tain the generated probability of words in a document. We,null,null
80,take the probability of a query term in a document as its,null,null
81,implicit semantic information in the document. The proba-,null,null
82,"bility is larger, the term is more related with the document.",null,null
83,In order to be the same magnitude with weights in tradi-,null,null
84,"tional models, the weight of a query term for a document in",null,null
85,LDA uses log value of the generated probability as follows.,null,null
86, Kt,null,null
87,"w(qi, d) , log p(qi|d) , log  p(qi|z)p(z|d)",null,null
88,(2),null,null
89,"z,1",null,null
90,The LDA model can not be solved by exact inference and use Gibbs Sampling for parameter estimation like in [5].,null,null
91,3.3 Traditional Information Retrieval Models,null,null
92,"Traditional information retrieval models are mainly classified into classic probabilistic model, vector space model and statistical language model. There are several well-known strong baselines in each class, considering BM25, MATF and Dirichlet LM respectively.",null,null
93,"In BM25, the weight of a query term is related to its within-document term frequency and query term frequency. The corresponding weighting function is as follows.",null,null
94,"w(qi, d) ,",null,null
95,(k1 + 1)  tf K + tf,null,null
96, log (N - n + 0.5)  (k3 + 1 )  qtf,null,null
97,(n - 0.5),null,null
98,k3 + qtf,null,null
99,(3),null,null
100,"where w is the weight of a query term, the kis are tuning constants and K equals to k1  ((1 - b) + b  dl/avdl).",null,null
101,"In 2013, Jiaul H. Paik [13] proposed a novel TF-IDF term weighting scheme MATF that employed two different within document term frequency normalizations to capture two different aspects of term saliency. One component of the term frequency is effective for short queries, while the other performs better on long queries. The final weight is measured by taking a weighted combination of these components, which is determined on the basis of the length of the corresponding query. Experiments carried out on a set of news and web datasets show that MATF outperforms several wellknown state-of-the-art TF-IDF baselines with significantly large margin.",null,null
102,"Dirichlet LM presented by Zhai and Lafferty in 2001 [18] used the likelihood probability of query terms in a document to rank relevance between query and document. In order to better computing, the weight of a query term uses the log value of the probability as follows.",null,null
103,"w (qi , d) , log p(qi |d), log",null,null
104,dl,null,null
105,µ,null,null
106,dl + µ pml (qi |d) + dl + µ pml (qi |c),null,null
107,(4),null,null
108,4. EXPERIMENTAL SETTING,null,null
109,"We conduct experiments on eight standard collections, which include AP88-89 with queries 51-100, AP88-90 with queries 51-150, FBIS with queries 351-450, FT(91-94) with queries 301-400, LA with queries 301-400, SJMN(1991) with queries 51-150, WSJ(87-92) with queries 151-200 and WT2G with queries 401-450. These datasets are different in size and genre [15, 19]. Queries without judgments are removed.",null,null
110,734,null,null
111,BM25 LDA-BM25,null,null
112,MATF LDA-MATF,null,null
113,LM LDA-LM,null,null
114,Eval Metric MAP P@5 P@20 MAP,null,null
115,P@5,null,null
116,P@20,null,null
117,MAP P@5 P@20 MAP,null,null
118,P@5,null,null
119,P@20,null,null
120,MAP P@5 P@20 MAP,null,null
121,P@5,null,null
122,P@20,null,null
123,AP88-89,null,null
124,0.2710 0.4360 0.3860 0.3021* (+11.476%) 0.5020 (+15.138%) 0.4388* (+13.679%) 0.2771 0.4531 0.3980 0.3041* (+9.744%) 0.4898 (+8.100%) 0.4378* (+10.000%) 0.2672 0.4571 0.4041 0.2980* (+11.527%) 0.5102* (+11.617%) 0.4276* (+5.815%),null,null
125,AP88-90,null,null
126,0.2198 0.4566 0.3894 0.2617* (+19.064%) 0.5232* (+14.595%) 0.4505* (+15.693%) 0.2238 0.4707 0.4086 0.2617* (+16.935%) 0.5131 (+9.008%) 0.4465* (+9.276%) 0.2157 0.4465 0.4146 0.2560* (+18.683%) 0.5010* (+12.206%) 0.4414* (+6.464%),null,null
127,FBIS,null,null
128,0.2606 0.3735,null,null
129,0.2685,null,null
130,0.2661,null,null
131,(+2.111%) 0.3679,null,null
132,(-1.499%) 0.2691,null,null
133,(+0.223%) 0.2553 0.3605 0.2673 0.2634*,null,null
134,(+3.173%) 0.3580,null,null
135,(-0.693%) 0.2784,null,null
136,(+4.153%) 0.2525 0.3506 0.2500 0.2628*,null,null
137,(+4.079%) 0.3630,null,null
138,(+3.537%) 0.2599*,null,null
139,(+3.960%),null,null
140,FT,null,null
141,0.2600 0.3726 0.2389 0.2769* (+6.500%) 0.3621 (-2.818%) 0.2416 (+1.130%) 0.2660 0.3789,null,null
142,0.2426 0.2781* (+4.549%),null,null
143,0.3621 (-4.434%),null,null
144,0.2453,null,null
145,(+1.113%) 0.2571 0.3684 0.2311 0.2774*,null,null
146,(+7.896%) 0.3600,null,null
147,(-2.280%) 0.2426*,null,null
148,(+4.976%),null,null
149,LA,null,null
150,0.2490 0.3571 0.2194 0.2592* (+4.96%) 0.3673 (+2.856%) 0.2291* (+5.105%) 0.2502 0.3571 0.2240 0.2586* (+3.357%) 0.3694,null,null
151,(+3.444%) 0.2337*,null,null
152,(+4.330%) 0.2427 0.3429 0.2235,null,null
153,0.2603* (+7.252%),null,null
154,0.3694* (+7.728%),null,null
155,0.2286 (+2.282%),null,null
156,SJMN,null,null
157,0.1965 0.3404 0.2564 0.2297* (+16.902%) 0.3809 (+11.889%) 0.2915 (+13.697%) 0.2095 0.3723 0.2809 0.2309* (+10.215%) 0.3915,null,null
158,(+5.157%) 0.2989,null,null
159,(+6.408%) 0.2009 0.3532 0.2697 0.2254*,null,null
160,(+12.195%) 0.3830*,null,null
161,(+8.437%) 0.2904*,null,null
162,(+7.675%),null,null
163,WSJ,null,null
164,0.3156 0.5240 0.4410 0.3471* (+9.981%) 0.5520,null,null
165,(+5.344%) 0.4640*,null,null
166,(+5.215%) 0.3029 0.5240 0.3950 0.3343*,null,null
167,(+10.366%) 0.5200,null,null
168,(-0.763%) 0.4300*,null,null
169,(+8.861%) 0.3047 0.5120 0.3910 0.3344*,null,null
170,(+9.747%) 0.5200,null,null
171,(+1.563%) 0.4320*,null,null
172,(+10.486%),null,null
173,WT2G,null,null
174,0.3156 0.5280 0.3930 0.3230 (+2.345%) 0.5360,null,null
175,(+1.515%) 0.4030,null,null
176,(+2.545%) 0.3340 0.5240 0.4110 0.3393,null,null
177,(+1.587%) 0.5360,null,null
178,(+2.290%) 0.4150,null,null
179,(+0.973%) 0.3118 0.5000 0.3920 0.3165*,null,null
180,(+1.507%) 0.5080,null,null
181,(+1.600%) 0.3950,null,null
182,(+0.765%),null,null
183,"Table 2: Comparison with baselines. The best result obtained on each dataset is in bold. ""*"" denotes statistically significant improvements over corresponding baselines (Wilcoxon signed-rank test with p < 0.05). The percentages below are the percentage improvement of proposed models over corresponding baselines.",null,null
184,"For all test collections used, each term is stemmed by using Porter's English stemmer. Standard English stopwords are removed. The official TREC evaluation measure is used in our experiments, namely Mean Average Precision (MAP). To investigate top retrieved documents, P@5 and P@20 are also used for evaluation. All statistical tests are based on Wilcoxon Matched-pairs Signed-rank test.",null,null
185,"For fair comparisons, we use the following parameter settings for both the baselines and our proposed models, which are popular in the IR domain for building strong baselines. First, in BM25, setting k1, k3 and b to 1.2, 8 and 0.35 respectively gave the best MAP for most datasets in [20]. Second, in Dirichlet LM, µ ,"" 1000 was shown in [15] to achieve best MAP for most datasets. Finally, in LDA model, we use symmetric Dirichlet priors with  "", 50/Kt and  ,"" 0.01, which are common settings in the literature and shown in [15] that retrieval results were not very sensitive to the values of these parameters. The number of topics Kt is set to be 400 as recommended in [15].""",null,null
186,5. EXPERIMENTAL RESULTS,null,null
187,5.1 Comparison with Baselines,null,null
188,"We first investigate the performance of our proposed topicbased models compared with the corresponding strong baselines BM25, MATF and Dirichlet LM. The experimental results are presented in Table 2. As shown by the results, our proposed models outperform the corresponding baselines on almost all datasets in terms of MAP, P@5 and P@20. Statistically significant improvement can be observed on most of datasets in terms of MAP and P@20. According to the results in Table 2, each hybrid model has its advantage on some aspects. However, there is no single hybird model that can achieve the best performance on all the datasets.",null,null
189,5.2 Parameter Sensitivity,null,null
190,"An important issue that may affect the robustness of our proposed models is the sensitivity of their parameter  to retrieval performance. Since the weights of query terms in traditional retrieval models and topic model are normalized independently, the value of  reflects the influence of using topic-based model. Figure 1 plots the evaluation metrics MAP obtained by the proposed hybrid models over  values ranging from 0 to 1 on all the datasets. It is clear that hybrid models perform better than either traditional models",null,null
191,"or topic model on all data sets. As we can see from Figure 1, our proposed models LDA-BM25, LDA-MATF and LDALM generally perform well over different datasets when  has a smaller value.",null,null
192,"We also study the performance of our proposed topicbased models with different number of topics compared with the corresponding baselines in terms of MAP. In Figure 2, the traditional models are shown as straight lines since the performance does not change over the number of topics. All the results are presented in Figure 2, which shows that our proposed models with different number of topics outperform corresponding baselines in terms of MAP over all datasets. Figure 2 shows that the proposed hybrid models tend to perform better when the number of topics increases. When the number of topics reaches a certain value, the retrieval performance tends to become more stable. The performance tendency of our proposed models with different number of topics is surprisingly consistent on all the datasets. Similar trends for  and with different number of topics can also be observed in terms of P@5 and P@20.",null,null
193,5.3 Comparison with CRTER2 and LBDM,null,null
194,"In addition, we compare our proposed models with two",null,null
195,"state-of-the-art approaches. Zhao etc. [19, 20] showed that",null,null
196,bigram cross term model (CRTER2) is at least comparable to,null,null
197,major probabilistic proximity models PPM [14] and BM25TP,null,null
198,"[4] in BM25-based framework. Xing and Allan [17], which",null,null
199,"is most close to our proposed model LDA-LM, showed their",null,null
200,LDA-based model (LBDM) [15] achieved the best performance,null,null
201,in topic-based LM framework. So we make a direct compar-,null,null
202,ison with CRTER2 and LBDM. The results in terms of MAP,null,null
203,"are presented in Table 3. """" denotes LDA-BM25 outper-",null,null
204,"forms CRTER2, while """" denotes LDA-LM outperforms LBDM.",null,null
205,"Among eight datasets, LDA-BM25 wins five times and LDA-",null,null
206,"LM wins four times. By comparison, we can conclude that",null,null
207,our proposed models LDA-BM25 and LDA-LM are at least,null,null
208,comparable to the state-of-the-art models CRTER2 and LBDM.,null,null
209,Table 3: Comparison with CRTER2 and LBDM,null,null
210,AP88-89 AP88-90,null,null
211,FBIS FT LA,null,null
212,SJMN WSJ WT2G,null,null
213,CRTER2 0.2789 0.2268 0.2738 0.2717 0.2604 0.2095 0.3406 0.3359,null,null
214,LDA-BM25 0.3021 0.2617 0.2661 0.2769 0.2592 0.2297 0.3471 0.3230,null,null
215,LBDM 0.3051 0.2535 0.2636 0.2750 0.2630 0.2234 0.3359 0.3108,null,null
216,LDA-LM 0.2980 0.2560 0.2628 0.2774 0.2603 0.2254 0.3344 0.3165,null,null
217,735,null,null
218,MAP,null,null
219,MAP,null,null
220,0.32,null,null
221,AP88-89,null,null
222,0.3,null,null
223,0.28,null,null
224,0.26,null,null
225,0.24,null,null
226,0.22 0.2,null,null
227,0.18 0,null,null
228,0.28,null,null
229,LDA-BM25 LDA-MATF LDA-LM,null,null
230,0.1,null,null
231,0.2,null,null
232,0.3,null,null
233,0.4,null,null
234,0.5,null,null
235,0.6,null,null
236,0.7,null,null
237,0.8,null,null
238,0.9,null,null
239,1.0,null,null
240,LA,null,null
241,0.26,null,null
242,0.24,null,null
243,0.22,null,null
244,0.2,null,null
245,0.18,null,null
246,0.16 0.14 0.12,null,null
247,0,null,null
248,LDA-BM25 LDA-MATF LDA-LM,null,null
249,0.1,null,null
250,0.2,null,null
251,0.3,null,null
252,0.4,null,null
253,0.5,null,null
254,0.6,null,null
255,0.7,null,null
256,0.8,null,null
257,0.9,null,null
258,1.0,null,null
259,MAP,null,null
260,MAP,null,null
261,0.28,null,null
262,AP88-90,null,null
263,0.26,null,null
264,0.24,null,null
265,0.22,null,null
266,0.2,null,null
267,0.18,null,null
268,0.16 0,null,null
269,0.24 0.23 0.22 0.21,null,null
270,0.2 0.19 0.18 0.17 0.16 0.15,null,null
271,0,null,null
272,LDA-BM25 LDA-MATF LDA-LM,null,null
273,0.1,null,null
274,0.2,null,null
275,0.3,null,null
276,0.4,null,null
277,0.5,null,null
278,0.6,null,null
279,0.7,null,null
280,0.8,null,null
281,0.9,null,null
282,1.0,null,null
283,SJMN,null,null
284,LDA-BM25 LDA-MATF LDA-LM,null,null
285,0.1,null,null
286,0.2,null,null
287,0.3,null,null
288,0.4,null,null
289,0.5,null,null
290,0.6,null,null
291,0.7,null,null
292,0.8,null,null
293,0.9,null,null
294,1.0,null,null
295,MAP,null,null
296,MAP,null,null
297,0.28 0.26 0.24 0.22,null,null
298,0.2 0.18 0.16 0.14 0.12,null,null
299,0.1 0.08,null,null
300,0,null,null
301,0.34 0.32,null,null
302,0.3 0.28 0.26 0.24 0.22,null,null
303,0.2 0.18 0.16,null,null
304,0,null,null
305,FBIS,null,null
306,LDA-BM25 LDA-MATF LDA-LM,null,null
307,0.1,null,null
308,0.2,null,null
309,0.3,null,null
310,0.4,null,null
311,0.5,null,null
312,0.6,null,null
313,0.7,null,null
314,0.8,null,null
315,0.9,null,null
316,1.0,null,null
317,WSJ,null,null
318,LDA-BM25 LDA-MATF LDA-LM,null,null
319,0.1,null,null
320,0.2,null,null
321,0.3,null,null
322,0.4,null,null
323,0.5,null,null
324,0.6,null,null
325,0.7,null,null
326,0.8,null,null
327,0.9,null,null
328,1.0,null,null
329,MAP,null,null
330,MAP,null,null
331,0.28 0.26 0.24 0.22,null,null
332,0.2 0.18 0.16 0.14 0.12,null,null
333,0.1 0,null,null
334,FT,null,null
335,LDA-BM25 LDA-MATF LDA-LM,null,null
336,0.1,null,null
337,0.2,null,null
338,0.3,null,null
339,0.4,null,null
340,0.5,null,null
341,0.6,null,null
342,0.7,null,null
343,0.8,null,null
344,0.9,null,null
345,1.0,null,null
346,WT2G,null,null
347,0.3,null,null
348,0.25,null,null
349,0.2,null,null
350,0.15 0.1,null,null
351,0.05 0,null,null
352,LDA-BM25 LDA-MATF LDA-LM,null,null
353,0.1,null,null
354,0.2,null,null
355,0.3,null,null
356,0.4,null,null
357,0.5,null,null
358,0.6,null,null
359,0.7,null,null
360,0.8,null,null
361,0.9,null,null
362,1.0,null,null
363,Figure 1: Parameter sensitivity of  on all data sets,null,null
364,0.315 0.31,null,null
365,0.305 0.3,null,null
366,0.295 0.29,null,null
367,0.285 0.28,null,null
368,0.275 0.27,null,null
369,0.265 100,null,null
370,200,null,null
371,300,null,null
372,0.265 0.26,null,null
373,0.255,null,null
374,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
375,AP88-89,null,null
376,400,null,null
377,500,null,null
378,Number of topics,null,null
379,LA,null,null
380,600,null,null
381,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
382,700,null,null
383,800,null,null
384,0.25,null,null
385,0.245,null,null
386,0.24 100,null,null
387,200,null,null
388,300,null,null
389,400,null,null
390,500,null,null
391,Number of topics,null,null
392,600,null,null
393,700,null,null
394,800,null,null
395,MAP,null,null
396,MAP,null,null
397,0.27,null,null
398,AP88-90,null,null
399,0.26,null,null
400,0.25 0.24 0.23,null,null
401,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
402,0.22,null,null
403,0.21 100,null,null
404,0.245 0.24,null,null
405,0.235 0.23,null,null
406,0.225 0.22,null,null
407,0.215 0.21,null,null
408,0.205 0.2,null,null
409,0.195 100,null,null
410,200,null,null
411,300,null,null
412,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
413,200,null,null
414,300,null,null
415,400,null,null
416,500,null,null
417,Number of topics,null,null
418,SJMN,null,null
419,600,null,null
420,400,null,null
421,500,null,null
422,Number of topics,null,null
423,600,null,null
424,700 700,null,null
425,800 800,null,null
426,MAP,null,null
427,MAP,null,null
428,0.275,null,null
429,0.27,null,null
430,0.265,null,null
431,0.26,null,null
432,0.255,null,null
433,0.25 100,null,null
434,0.35 0.345,null,null
435,0.34 0.335,null,null
436,0.33 0.325,null,null
437,0.32 0.315,null,null
438,0.31 0.305,null,null
439,0.3 100,null,null
440,200 200,null,null
441,FBIS,null,null
442,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
443,300,null,null
444,400,null,null
445,500,null,null
446,Number of topics,null,null
447,WSJ,null,null
448,600,null,null
449,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
450,300,null,null
451,400,null,null
452,500,null,null
453,Number of topics,null,null
454,600,null,null
455,700 700,null,null
456,800 800,null,null
457,MAP,null,null
458,MAP,null,null
459,0.285 0.28,null,null
460,0.275 0.27,null,null
461,0.265 0.26,null,null
462,0.255 100,null,null
463,0.345 0.34,null,null
464,0.335 0.33,null,null
465,0.325 0.32,null,null
466,0.315 0.31 100,null,null
467,FT,null,null
468,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
469,200,null,null
470,300,null,null
471,400,null,null
472,500,null,null
473,Number of topics,null,null
474,WT2G,null,null
475,600,null,null
476,LDA-BM25 LDA-MATF LDA-LM BM25 MATF LM,null,null
477,200,null,null
478,300,null,null
479,400,null,null
480,500,null,null
481,Number of topics,null,null
482,600,null,null
483,700 700,null,null
484,800 800,null,null
485,Figure 2: Parameter sensitivity of the number of topics on all data sets,null,null
486,MAP,null,null
487,MAP,null,null
488,6. CONCLUSIONS AND FUTURE WORK,null,null
489,"In this paper, a simple enhancement for ad-hoc IR is proposed by combining traditional retrieval model and topic model. Specifically, we present three hybrid models LDABM25, LDA-MATF and LDA-LM for enhancing traditional IR models via topic modeling. These three models capture both term-based information and latent semantic topicbased information at the same time. Experimental results on eight standard datasets show that the proposed models are effective, and outperform the corresponding strong baselines on most of datasets in terms of MAP, P@5 and P@20. Meanwhile, our proposed models are at least comparable to the state-of-the-art CRTER2 and topic-based model LBDM. Additionally, we carefully analyze the influence of  to our proposed models and the performance of our proposed models with different number of topics.",null,null
490,There are several interesting future research directions to further explore. We would like to study the optimal topic number on each dataset. It is also interesting to conduct an in-depth study on the combination traditional IR model with topic model and find the best combination. We also plan to evaluate our models on more datasets including some real datasets and apply our models into real world applications.,null,null
491,7. ACKNOWLEDGMENTS,null,null
492,"This research is supported by a Discovery grant from the Natural Sciences & Engineering Research Council (NSERC) of Canada, an NSERC CREATE award and also supported by the National Natural Science Foundation of China. We thank anonymous reviewers for their thorough comments.",null,null
493,8. REFERENCES,null,null
494,[1],null,null
495,[2] [3] [4],null,null
496,[5] [6],null,null
497,[7] [8],null,null
498,[9] [10] [11] [12] [13] [14] [15] [16],null,null
499,[17],null,null
500,[18] [19] [20],null,null
501,"L. Azzopardi, M. Girolami, and C. J. Van Rijsbergen. Topic Based Language Models for ad hoc Information Retrieval. In Proceedings of the International Joint Conference on Neural Networks, pages 3281­3286, 2004.",null,null
502,"M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker, and P. Williams. Okapi at TREC-5. In Proc. of TREC, pages 143­166, 1996.",null,null
503,"D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993­1022, 2003.",null,null
504,"S. Buttcher, C. L. A. Clarke, and B. Lushman. Term Proximity Scoring for Ad-hoc Retrieval on Very Large Text Collections. In Proceedings of the 29th ACM SIGIR, pages 621 ­ 622, 2006.",null,null
505,"T. L. Griffiths and M. Steyvers. Finding Scientific Topics. In Proceeding of the National Academy of Sciences, pages 5228­5235, 2004.",null,null
506,"B. He, J. X. Huang, and X. Zhou. Modeling term proximity for probabilistic information retrieval models. Information Sciences, 181(14):3017­3031, 2011.",null,null
507,"T. Hofmann. Probabilistic Latent Semantic Indexing. In Proceedings of the 22nd ACM SIGIR, pages 50­57, 1999.",null,null
508,"Q. Hu, J. X. Huang, and X. Hu. Modeling and Mining Term Association for Improving Biomedical Information Retrieval Performance. BMC Bioinformatics, 13(2):18 pages, 2012.",null,null
509,"W. Li and A. McCallum. Pachinko Allocation: DAG-Structured Mixture Models of Topic Correlations. In Proc. of ICML, pages 577­584, 2006.",null,null
510,"X. Liu and W. B. Croft. Cluster-Based Retrieval Using Language Models. In Proceedings of the 27th ACM SIGIR, pages 186­193, 2004.",null,null
511,"Y. Lv and C. Zhai. Positional Language Models for Information Retrieval. In Proceedings of the 32nd ACM SIGIR, pages 299­306, 2009.",null,null
512,"D. Metzler and W. B. Croft. A Markov Random Field Model for Term Dependencies. In Proceedings of the 28th ACM SIGIR, pages 472­479, 2005.",null,null
513,"J. H. Paik. A Novel TF-IDF Weighting Scheme for Effective Ranking. In Proc. of the 36th ACM SIGIR, pages 343­352, 2013.",null,null
514,"R. Song, L. Yu, J. R. Wen, and H. W. Hon. A Proximity Probabilistic Model for Information Retrieval. Tech. Rep., Microsoft Research, 2011.",null,null
515,"X. Wei and W. B. Croft. LDA-Based Document Models for Ad-hoc Retrieval. In Proc. of the 29th ACM SIGIR, pages 178­185, 2006.",null,null
516,"X. Wei and W. B. Croft. Modeling Term Associations for Ad-Hoc Retrieval Performance within Language Modeling Framework. In Proceedings of the 29th European Conference on IR research, pages 52­63, 2007.",null,null
517,"X. Yi and J. Allan. A Comparative Study of Utilizing Topic Models for Information Retrieval. In Proceedings of the 31st European Conference on IR Research on Advances in Information Retrieval (ECIR'09), pages 29­41, 2009.",null,null
518,"C. Zhai and J. Lafferty. A Study of Smoothing Methods for Language Models Applied to Information Retrieval. ACM TOIS, 22(2):179­214, 2004.",null,null
519,"J. Zhao, J. X. Huang, and B. He. CRTER: Using Cross Terms to Enhance Probabilistic IR. In Proc. of the 34th ACM SIGIR, pages 155­164, 2011.",null,null
520,"J. Zhao, J. X. Huang, and Z. Ye. Modeling Term Associations for Probabilistic Information Retrieval. ACM Trans. Inf. Syst., 32(2):1­47, 2014.",null,null
521,736,null,null
522,,null,null
