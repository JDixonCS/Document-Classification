,sentence,label,data
0,A General Linear Mixed Models Approach to Study System Component Effects,null,null
1,Nicola Ferro,null,null
2,"Department of Information Engineering University of Padua Padua, Italy",null,null
3,nicola.ferro@unipd.it,null,null
4,ABSTRACT,null,null
5,"Topic variance has a greater effect on performances than system variance but it cannot be controlled by system developers who can only try to cope with it. On the other hand, system variance is important on its own, since it is what system developers may affect directly by changing system components and it determines the differences among systems. In this paper, we face the problem of studying system variance in order to better understand how much system components contribute to overall performances. To this end, we propose a methodology based on General Linear Mixed Model (GLMM) to develop statistical models able to isolate system variance, component effects as well as their interaction by relying on a Grid of Points (GoP) containing all the combinations of analysed components. We apply the proposed methodology to the analysis of TREC Ad-hoc data in order to show how it works and discuss some interesting outcomes of this new kind of analysis. Finally, we extend the analysis to different evaluation measures, showing how they impact on the sources of variance.",null,null
6,1. INTRODUCTION,null,null
7,"The experimental results analysis is a core activity in Information Retrieval (IR) aimed at, firstly, understanding and improving system performances and, secondly, assessing our own experimental methods, such as robustness of experimental collection or properties of the evaluation measures. When it comes to explaining system performances and differences between algorithms, it is commonly understood [10, 17, 23] that system performances can be broken down to a reasonable approximation as",null,null
8,"system performances , topic effect + system effect+",null,null
9,topic/system interaction effect,null,null
10,"even though it is not always possible to estimate these effects separately, especially the interaction one.",null,null
11,"It is well-known that topic variability is greater than system variability [23, 26]. Therefore, a lot of effort has been",null,null
12,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17-21, 2016, Pisa, Italy",null,null
13,c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2911530,null,null
14,Gianmaria Silvello,null,null
15,"Department of Information Engineering University of Padua Padua, Italy",null,null
16,gianmaria.silvello@unipd.it,null,null
17,"put in better understanding this source of variance [17] as well as in making IR systems more robust to it, e.g. [25, 28], basically trying to improve on the interaction effect. Nevertheless, with respect to an IR system, topic variance is a kind of ""external source"" of variation, which cannot be controlled by developers, but can only be taken into account to better deal with it.",null,null
18,"On the other hand, system variance is a kind of ""internal source"" of variation, since it is originated by the choice of system components, may be directly affected by developers by working on them, and represents the intrinsic differences between algorithms. Its importance is witnessed by the wealth of research on how to compare systems performances in a reliable and robust way [1, 2, 4, 9, 20­23, 27].",null,null
19,"However, a limitation of the current experimental methodology is that it allows us to evaluate IR systems only as a kind of ""black-boxes"", without an understanding of how their different components interact with each other and contribute to the overall performances. In other terms, we consider system variance as a single monolithic contribution and we cannot break it down into the smaller pieces (the components) constituting an IR system.",null,null
20,"In order to estimate the effects of the different components of an IR system, we develop a methodology, based on General Linear Mixed Model (GLMM) and ANalysis Of VAriance (ANOVA) [13, 18], which makes us of a Grid of Points (GoP) containing all the possible combinations of inspected components. The proposed methodology allows us to break down the system effect into the contributions of stops lists, stemmers or n-grams and IR models, as well as to study their interaction.",null,null
21,"We experimented on standard Text REtrieval Conference (TREC) Ad-hoc collections and produced a GoP by using the Terrier1 open source IR system [12]. This gave us a very controlled experimental setting, which allowed us to systematically fit our General Linear Model (GLM) and break down the system variance. Note that such a controlled experimental setting is typically not available in evaluation campaigns, such as TREC, where participating systems do not constitute a systematic sampling of all the possible combinations of components and often are not even described in such a detail to know exactly what components have been used.",null,null
22,"We applied the proposed methodology to TREC 5, 6, 7, and 8 Ad-hoc collections and we employed different measures ­ AP, Precision at 10, RBP, nDCG@20, and ERR@20. This setup allows us not only to highlight how components contribute to the overall system variance but also to gain",null,null
23,1 http://www.terrier.org/,null,null
24,25,null,null
25,insights on how different evaluation measures impact on system and component variances.,null,null
26,"The paper is organized as follows: Section 2 presents related work; Section 3 introduces our methodology; Section 4 experiments the proposed methodology; and, Section 5 draws conclusions and discusses future work.",null,null
27,2. RELATED WORKS,null,null
28,"The impossibility of testing a single component by setting it aside from the complete IR system is a long-standing and well-known problem in IR experimentation, as early remarked by [16]. Component-based evaluation methodologies [6­8] have tried to tackle this issue by providing technical solutions for mixing different components without the need of building a whole IR system. However, even if these approaches allowed researchers to focus on the components of their own interest, they have not delivered yet estimates of the performance figures of each component.",null,null
29,"The decomposition of performances into system and topic effects has been exploited by [1, 23] to analyze TREC data; [4] proposed model-based inference, using linear models and ANOVA, as an approach to multiple comparisons; [10] used multivariate linear models to compare non-deterministic IR systems among them and with deterministic ones. In all these cases, the goal is a more accurate comparison among systems rather than an analysis and breakdown of system variance per se. [17] applied GLMM to the study of per-topic variance by using simulated data to generate more replicates for each (topic, system) pair in order to estimate also the topic/system interaction effect; however, they did not use real data nor did focus on breaking down the system effect.",null,null
30,"The idea of creating all the possible combinations of components has been proposed by [7], who noted that a systematic series of experiments on standard collections would have created a GoP, where (ideally) all the combinations of retrieval methods and components are represented, allowing us to gain more insights about the effectiveness of the different components and their interaction; this would have called also for the identification of suitable baselines with respect to which all the comparisons have to be made. Even though [7] introduced the idea of a GoP and how it could have been central to the decomposition of system component performances, they did not come up with an full-fledged methodology for analyzing such data and breaking down component performances, which is the contribution of the present work instead.",null,null
31,"More recently, the proliferation of open source IR systems [24] has greatly ameliorated the situation, allowing researchers to run systematic experiments more easily. This led the community to further investigate what reproducible baselines are [5, 11] and the ""Open-Source Information Retrieval Reproducibility Challenge"" provided several of these baselines, putting some points in the ideal GoP mentioned above. We move a step forward with respect to [11] since we propose an actual methodology for exploiting such GoPs to decompose system performances and we rely on a much finer-grained grid, in terms of number of components and IR models experimented.",null,null
32,3. METHODOLOGY,null,null
33,The goal of the proposed methodology is to decompose the effects of different components on the overall system perfor-,null,null
34,"mances. In particular, we are interested in investigating the effects of the following components: stop lists; Lexical Unit Generator (LUG), namely stemmers or n-grams; IR models, such as the vector space or the probabilistic model.",null,null
35,"We create a Grid of Points (GoP) on a standard experimental collection by running all the IR systems resulting from all the possible combinations of the considered components (stop list, LUG, IR model); we consider stemmers and n-grams as alternative LUG components, thus we do not consider IR systems using both stemmer and n-grams.",null,null
36,"Given a performance measure, such as Average Precision (AP), we produce a matrix Y , as the one shown in Figure 1, where each cell Yij represents a measurement on topic ti of the system sj. Note that the column average ­ i.e., µ·j ­ is the performance mean over all topics for a given system, e.g. Mean Average Precision (MAP); the row average ­ i.e., µi· ­ is the performance mean over all systems for a given topic.",null,null
37,"A GLMM explains the variation of a dependent variable Y (""Data"") in terms of a controlled variation of independent variables (""Model"") in addition to a residual uncontrolled variation (""Error"").",null,null
38,"Data , Model + Error",null,null
39,"The term ""General"" refers to the ability to accommodate distinctions on quantitative variables representing continuous measures (as in regression analysis) and categorical distinctions representing groups or experimental conditions (as in ANOVA). In our case, we deal with categorical independent variables, as for example different types of stemmers, which constitute the levels of such categorical variable. The term ""Linear"" indicates that the ""Model"" is expressed as a linear combination of factors, where the factors can be single independent variables or their combinations. In our case, we are interested both in single independent variables, i.e. the main effects of the different components alone, and their combinations, i.e. the interaction effects between components. The term ""Mixed"" refers to the fact that some independent variables are considered fixed effects ­ i.e. they have precisely defined levels, and inferences about its effect apply only to those levels ­ and some others are considered random effects ­ i.e. they describe a randomly and independently drawn set of levels that represent variation in a clearly defined wider population; a random factor is indicated by adding a single quote as superscript to the variable name. In our case, the different kinds of systems and components are fixed effects while topics are random effects.",null,null
40,"The experimental design determines how you compute the model and how you estimate its parameters. In particular, it is possible to have independent measures designs where different subjects participate to different experimental conditions (factors) or repeated measures designs, where each subject participates to all the experimental conditions (factors). In our case systems and their components are the experimental conditions (factors) while topics are the subjects and, since each topic is processed by each system, we have a repeated measure design.",null,null
41,"One advantage of repeated measures designs is a reduction in error variance due to the greater similarity of the scores provided by the same subjects; in this way, variability in individual differences between subjects is removed from the error. Basically, a repeated measure design increases the statistical power for a fixed number of subjects or, in other",null,null
42,26,null,null
43,"terms, it allows us to reach a desired level of power with less subjects than those required in the independent measures design.",null,null
44,"A final distinction is between crossed/factorial designs, where every level of one factor is measured in combination with every level of the other factors, and nested designs, where levels of a factor are grouped within each level of another nesting factor. In our case, we have a crossed/factorial design because in the generated GoP we experiment each possible combination of components.",null,null
45,3.1 Single Factor Repeated Measures Design,null,null
46,Subjects (Topics),null,null
47,Factor A (Systems) A1 A2 ... Ap T10 Y11 Y12 ... Y1p µ1·,null,null
48,T20 Y21 Y22 ... Y2p µ2·,null,null
49,...,null,null
50,... ... ...,null,null
51,Yij,null,null
52,µi·,null,null
53,Tn0 Yn1 Yn2 ... Ynp µn· µ·1 µ·2 µ·j µ·p µ··,null,null
54,Figure 1: Single factor repeated measures design.,null,null
55,"This design is the one typically used when ANOVA is applied to the analysis of the system performances in a track of an evaluation campaign, as in [1, 23], where the subjects are the topics and the factors are the system runs. Basically, in this context ANOVA is used to determine which experimental condition dependent variable score means differ, i.e. which systems are significantly different from others.",null,null
56,"In our case, we are interested also in a second aspect, i.e. to determine what proportion of variation in the dependent variable can be attributed to differences between specific experimental groups or conditions, as defined by the independent variables. This turns into determining which proportion of variation is due to the topics and which one to the systems.",null,null
57,3.1.1 Model,null,null
58,The full GLMM model for the one-way ANOVA with repeated measures is:,null,null
59,"Yij , µ·· + i + j + ij",null,null
60,(3.1),null,null
61,Model,null,null
62,Error,null,null
63,"where: Yij is the score of the i-th subject (topic) in the j-th factor (system); µ·· is the grand mean; i is the effect of the i-th subject i , µi· - µ·· where µi· is the mean of the i-th subject; j is the effect of the j-th factor j , µ·j - µ·· where µ·j is the mean of the j-th factor; ij is the error committed by the model in predicting the score of the i-",null,null
64,"th subject in the j-th factor. It consists of a term ( )ij which is the interaction between the i-th subject and the j-th factor2; and, a term ij which is any additional error due to uncontrolled sources of variance.",null,null
65,"2 In order to calculate interaction effects, you need to have several scores (repli-",null,null
66,cates) for each cell. The mean of the cell scores is taken as the best estimate of,null,null
67,3.1.2 Estimators,null,null
68,We have the following estimators for the parameters of the model above:,null,null
69,·,null,null
70,grand,null,null
71,mean:,null,null
72,µ^··,null,null
73,",",null,null
74,1 pn,null,null
75,"p j,1",null,null
76,"n i,1",null,null
77,Yij,null,null
78,·,null,null
79,mean of the i-th subject µ^i·,null,null
80,",",null,null
81,1 p,null,null
82,"p j,1",null,null
83,Yij,null,null
84,and,null,null
85,its,null,null
86,effect,null,null
87,"^i , µ^i· - µ^··",null,null
88,·,null,null
89,mean of the j-th factor µ^·j,null,null
90,",",null,null
91,1 n,null,null
92,"n i,1",null,null
93,Yij,null,null
94,and,null,null
95,its,null,null
96,effect,null,null
97,"^j , µ^·j - µ^··",null,null
98,"· score of the i-th subject in the j-th factor Y^ij , µ^·· + ^i + ^j , µ^i· + µ^·j - µ^··",null,null
99,"· prediction error of the i-th subject in the j-th experimental condition ^ij , Yij - Y^ij , Yij - µ^·· - ^i - ^j ,",null,null
100,Yij - (µ^i· + µ^·j - µ^··),null,null
101,3.1.3 Assessment,null,null
102,We can write the model of equation (3.1) introducing the estimated parameters as,null,null
103,"Yij , µ^·· + ^i + ^j + ^ij , µ^·· + (µ^i· - µ^··) + (µ^·j - µ^··) + (Yij - (µ^i· + µ^·j - µ^··))",null,null
104,which leads to the following decomposition of the effects,null,null
105,"Yij - µ^·· , µ^i· - µ^·· + µ^·j - µ^·· + Yij - (µ^i· + µ^·j - µ^··)",null,null
106,Total Effects Subject Effects Factor Effects,null,null
107,Error Effects,null,null
108,(3.2),null,null
109,"From equation (3.2), we can compute the sum of squares",null,null
110,"(SS), degrees of freedom (DF), and mean squares (MS) as",null,null
111,follows:,null,null
112,"· total effects SStot ,",null,null
113,"p j,1",null,null
114,"n i,1",null,null
115,(Yij,null,null
116,-,null,null
117,µ^··)2,null,null
118,with,null,null
119,mean,null,null
120,squares,null,null
121,M Stot,null,null
122,",",null,null
123,SStot dftot,null,null
124,where dftot,null,null
125,",",null,null
126,pn - 1 where,null,null
127,dftot comes from the fact that we are summing up pn,null,null
128,scores and one degree of freedom is lost because of the,null,null
129,grand mean µ^··;,null,null
130,· subject effects,null,null
131,pn,null,null
132,n,null,null
133,"SSsubj ,",null,null
134,"(µ^i· - µ^··)2 , p (µ^i· - µ^··)2",null,null
135,"j,1 i,1",null,null
136,"i,1",null,null
137,with,null,null
138,mean,null,null
139,squares,null,null
140,M Ssubj,null,null
141,",",null,null
142,SSsubj dfsubj,null,null
143,where dfsubj,null,null
144,",",null,null
145,n-1 where SSsubj considers that the quantity µ^i· -µ^··,null,null
146,is the same for all the p factors which the i-th sub-,null,null
147,ject experiences; dfsubj is calculated by summing up n,null,null
148,times the subject mean µ^i· where one degree of free-,null,null
149,dom is lost because of the grand mean µ^··;,null,null
150,· factor effects,null,null
151,pn,null,null
152,p,null,null
153,"SSfact ,",null,null
154,"(µ^·j - µ^··)2 , n (µ^·j - µ^··)2",null,null
155,"j,1 i,1",null,null
156,"j,1",null,null
157,with,null,null
158,mean,null,null
159,squares,null,null
160,M Sfact,null,null
161,",",null,null
162,SSf act dff act,null,null
163,where dffact,null,null
164,",",null,null
165,p-1 where SSfact considers that the quantity µ^·j -µ^··,null,null
166,"the cell score and is used to calculate interaction effects, with the discrepancy between the mean and the actual score providing the estimates of experimental error. If there is only one score per subject per factor, then a mean and its error cannot be calculated per subject per factor and without these estimates, the factor ij cannot be separated from the interaction effect ( )ij .",null,null
167,27,null,null
168,is the same for all the n subjects which experience the j-th factor; dffact is calculated by summing up p times the factor mean µ^·j where one degree of freedom is lost because of the grand mean µ^··;,null,null
169,· error effects,null,null
170,pn,null,null
171,"SSerr ,",null,null
172,(Yij - (µ^i· + µ^·j - µ^··))2,null,null
173,"j,1 i,1",null,null
174,with mean squares M Serr,null,null
175,",",null,null
176,SSerr dferr,null,null
177,where dferr,null,null
178,",",null,null
179,(p - 1) (n-1) where dferr is calculated by summing up,null,null
180,n times the scores where one degree of freedom is lost,null,null
181,in the subject scores because of the subject mean µ^i·,null,null
182,and one degree of freedom is lost in the factor scores,null,null
183,because of the factor mean µ^·j.,null,null
184,"Note that SStot ,"" SSsubj + SSfact + SSerr. In order to determine if the factor effect is statistically significant, we compute the F statistics defined as:""",null,null
185,Ff act,null,null
186,",",null,null
187,M Sfact M Serr,null,null
188,(3.3),null,null
189,"and compare it with the distribution F(dffact,dferr) under the null hypothesis H0 that there are not significant dif-",null,null
190,ferences in order to estimate the probability (p-value) that,null,null
191,Ffact has been observed by chance. We can set a significance,null,null
192,"level  (typically  ,"" 0.05) and, if p-value < , the factor""",null,null
193,effect is considered statistically significant.,null,null
194,"As introduced above, we are not only interested in de-",null,null
195,termining whether the factor effect is significant but also,null,null
196,"which proportion of the variance is due to it, that is we",null,null
197,need to estimate its effect-size measure or Strength of As-,null,null
198,"sociation (SOA). The SOA is a ""standardized index and es-",null,null
199,timates a parameter that is independent of sample size and,null,null
200,quantifies the magnitude of the difference between popula-,null,null
201,tions or the relationship between explanatory and response,null,null
202,"variables"" [15].",null,null
203,We,null,null
204,use,null,null
205,the,null,null
206,^,null,null
207,2 f,null,null
208,act,null,null
209,SOA:,null,null
210,^ 2f act,null,null
211,", dffact(Ffact - 1) dffact(Ffact - 1) + pn",null,null
212,(3.4),null,null
213,which is an unbiased estimator of the variance components associated with the sources of variation in the design.,null,null
214,"The common rule of thumb [14] when classifying ^2fact effect size is: 0.14 and above is a large effect, 0.06­0.14 is a medium effect, and 0.01­0.06 is a small effect. ^2fact values could happen to be negative and in such cases they are considered as zero.",null,null
215,"When you conduct experiments, two types of error may happen. A Type 1 error occurs when a true null hypothesis is rejected and the significance level  is the probability of committing a Type 1 error. A Type 2 error occurs when a false null hypothesis is accepted and it is concerned with the capability of the conducted experiment to actually detect the effect under examination. Type 2 errors are often overlooked because if they occur, although a real effect is missed, no misdirection occurs and further experimentation is very likely to reveal the effect.",null,null
216,The power is the probability of correctly rejecting a false null hypothesis when an experimental hypothesis is true,null,null
217,"Power , 1 - ",null,null
218,"where  (typically  , 0.2) is the Type 2 error rate.",null,null
219,"To determine the power of an experiment, we compute the effect size parameter:",null,null
220,",",null,null
221,n,null,null
222,·,null,null
223,1,null,null
224,^ 2f act - ^ 2fact,null,null
225,(3.5),null,null
226,and we compare it with its tabulated values for a given Type 1 error rate  to determine .,null,null
227,3.2 Factorial Repeated Measures Design,null,null
228,"While single factor designs manipulate a single variable, factorial designs take into account two or more factors as well as their interaction. As an example a two factors repeated measure design can be defined extending the design described above, where we manipulated one factor (A), by adding an additional factor (B) and the interaction between them (AB).",null,null
229,"We can therefore define a three factors design where we manipulate factors A, B and C which correspond to the stop lists, the LUG and the IR models respectively; with this design we can also study the interaction between component pairs as well as the third order interaction between them.",null,null
230,"In Figure 2 we can see a table which extends to three factors the design presented in Figure 1 for a single factor. We can see that the systems are now decomposed into three main constituents: (i) factor A (stop lists) with p levels where, for instance, A1 corresponds to the absence of a stop list, A2 to the indri stop list, A3 to the terrier stop list and so on; (ii) factor B (LUG) with q levels where B1 corresponds to the absence of a LUG, B2 to the Porter stemmer, B3 to the Krovetz stemmer and so on; (iii) factor C (IR models) with r levels where C1 corresponds to BM25, C2 to TF*IDF and so on. We call this design a p × q × r factorial design. Each cell of the table in Figure 2, say Ynpqr, reports the mea-",null,null
231,"surement (e.g., AP) on topic Tn, for the system composed by the stop list Ap, the LUG Bq and IR model Cr.",null,null
232,"The full GLMM model for the described factorial ANOVA for repeated measures with three fixed factors (A, B, C) and",null,null
233,a random factor (T ) is:,null,null
234,"Yijkl , µ···· + i + j + k + l +",null,null
235,Main Effects,null,null
236,jk + jl + kl + jkl,null,null
237,+ ijkl,null,null
238,(3.6),null,null
239,Interaction Effects,null,null
240,Error,null,null
241,"where: Yijkl is the score of the i-th subject in the j-th, k-th, and l-th factors; µ···· is the grand mean; i is the effect of the i-th subject i , µi··· - µ···· where µi··· is the mean of the i-th subject; j ,"" µ·j·· - µ···· is the effect of the j-th factor, where µ·j·· is the mean of the j-th factor; k "","" µ··k· - µ···· is the effect of the k-th factor, where µ··k· is the mean of the k-th factor; and, l "","" µ···l - µ···· is the effect of the l-th factor where µ···l is the mean of the l-th factor; ijkl is the error committed by the model in predicting the score of the i-th subject in the three factors j, k, l.""",null,null
242,It consists of all the interaction terms between the random,null,null
243,"subjects and the fixed factors, such as ( )ij, ( )ik and so on, plus the error ijkl which is any additional error due to uncontrolled sources of variance. As in the single factor",null,null
244,"design to calculate interaction effects with the subjects, you",null,null
245,need to have replicates; when there is only one score per,null,null
246,subject per factor the factor ijkl cannot be separated from the interaction effects with the random subjects.,null,null
247,28,null,null
248,Factor C (Models) Subjects (Topics),null,null
249,A1,null,null
250,B1 B2 · · ·,null,null
251,T10 Y1111 Y1121,null,null
252,C1,null,null
253,T20,null,null
254,Y2111 ...,null,null
255,Y2121 ...,null,null
256,···,null,null
257,Tn0 Yn111 Yn121,null,null
258,T10 Y1112 Y1122,null,null
259,C2 T20,null,null
260,Y2112 ...,null,null
261,Y2122 ...,null,null
262,···,null,null
263,Tn0 Yn112 Yn122,null,null
264,T10,null,null
265,XXX T20 XXX,null,null
266,XXX X X X,null,null
267,Tn0,null,null
268,T10 Y111r Y112r,null,null
269,Cr,null,null
270,T20,null,null
271,Y211r ...,null,null
272,Y212r ...,null,null
273,···,null,null
274,Tn0 Yn11r Yn12r,null,null
275,Factor A (Stop Lists),null,null
276,Factor B (Lexical Unit Generator),null,null
277,A2,null,null
278,···,null,null
279,Bq B1 B2 · · · Bq,null,null
280,Y11q1 Y1211 Y1221,null,null
281,Y12q1,null,null
282,Y21q1 Y2211 Y2221,null,null
283,...,null,null
284,...,null,null
285,...,null,null
286,···,null,null
287,Y22q1 ...,null,null
288,···,null,null
289,Yn1q1 Yn211 Yn221,null,null
290,Yn2q1,null,null
291,Y11q2 Y1212 Y1222,null,null
292,Y12q2,null,null
293,Y21q2 ...,null,null
294,Y2212 ...,null,null
295,Y2222 ...,null,null
296,···,null,null
297,Y22q2 ...,null,null
298,···,null,null
299,Yn1q2 Yn212 Yn222,null,null
300,Yn2q2,null,null
301,XXX XXX XXX X X X XXX,null,null
302,XXX,null,null
303,Y11qr Y121r Y122r,null,null
304,Y12qr,null,null
305,Y21qr ...,null,null
306,Y221r ...,null,null
307,Y222r ...,null,null
308,···,null,null
309,Y22qr ...,null,null
310,···,null,null
311,Yn1qr Yn21r Yn22r,null,null
312,Yn2qr,null,null
313,Ap,null,null
314,B1 B2 · · ·,null,null
315,Y1p11 Y1p21,null,null
316,Y2p11 Y2p21,null,null
317,...,null,null
318,...,null,null
319,···,null,null
320,Ynp11 Ynp21,null,null
321,Y1p12 Y1p22,null,null
322,Y2p12 ...,null,null
323,Y2p22 ...,null,null
324,···,null,null
325,Ynp12 Ynp22,null,null
326,Bq,null,null
327,Y1pq1 Y2pq1,null,null
328,... Ynpq1 Y1pq2 Y2pq2,null,null
329,... Ynpq2,null,null
330,XXX XXX X X X XXX,null,null
331,Y1p1r Y1p2r,null,null
332,Y1pqr,null,null
333,Y2p1r ...,null,null
334,Y2p2r ...,null,null
335,···,null,null
336,Y2pqr ...,null,null
337,Ynp1r Ynp2r,null,null
338,Ynpqr,null,null
339,Figure 2: Three factors repeated measures design.,null,null
340,The estimators of the main effects can be derived by exten-,null,null
341,"sion from those of the single factor design; for instance, the",null,null
342,grand,null,null
343,mean,null,null
344,is,null,null
345,µ^····,null,null
346,",",null,null
347,1 rqpn,null,null
348,"r l,1",null,null
349,"q k,1",null,null
350,"p j,1",null,null
351,"n i,1",null,null
352,"Yij kl ,",null,null
353,the,null,null
354,mean,null,null
355,of,null,null
356,the,null,null
357,k-th,null,null
358,effect,null,null
359,is,null,null
360,µ^··k·,null,null
361,",",null,null
362,1 rpn,null,null
363,"r l,1",null,null
364,"p j,1",null,null
365,"n i,1",null,null
366,Yijkl,null,null
367,"and its estimator is ^k , µ^··k· - µ^····.",null,null
368,The estimators of the interaction factors are calculated as,null,null
369,"follows, let us consider ()jk:",null,null
370,"jk , µ^·jk· - (µ^···· + ^j + ^k)",null,null
371,(3.7),null,null
372,where,null,null
373,µ^·jk·,null,null
374,",",null,null
375,1 nr,null,null
376,"n i,1",null,null
377,"r l,1",null,null
378,Yij kl ;,null,null
379,^j,null,null
380,",",null,null
381,µ^·j··,null,null
382,- µ^····;,null,null
383,"and,",null,null
384,"^k , µ^··k· - µ^····.",null,null
385,"Similarly, we calculate the estimators for all the other in-",null,null
386,teraction factors ­ i.e. jl and kl; jkl is calculated by extending equation (3.7):,null,null
387,"jkl , µ^·jkl - (µ^···· + ^j + ^k + ^l)",null,null
388,(3.8),null,null
389,where,null,null
390,µ^·jkl,null,null
391,",",null,null
392,1 n,null,null
393,"n i,1",null,null
394,Yijkl,null,null
395,and,null,null
396,^l,null,null
397,",",null,null
398,µ^···l,null,null
399,- µ^····.,null,null
400,"In this design the error ijkl , Yijkl - Y^ijkl contains the",null,null
401,variance not explained by the main and interaction effects,null,null
402,discussed above and it is composed by all the interactions,null,null
403,of the subjects j with the other factors in the model in,null,null
404,addition to the uncontrolled sources of variance.,null,null
405,"The sum of squares, mean squares and degrees of freedom",null,null
406,of the main effects can be derived by extension form those of,null,null
407,"the one factor design. As an example, the degrees of freedom",null,null
408,of factor A are p - 1 and its sum of squares is:,null,null
409,r q pn,null,null
410,p,null,null
411,"SSA ,",null,null
412,"^j2 , rqn (µ^·j·· - µ^····)2",null,null
413,"l,1 k,1 j,1 i,1",null,null
414,"j,1",null,null
415,"As an example of the computations for the interaction terms, we consider the term A × B whose degrees of freedom are (p - 1)(q - 1) and whose sum of squares is:",null,null
416,r q pn,null,null
417,2,null,null
418,"SSA×B ,",null,null
419,jk,null,null
420,"l,1 k,1 j,1 i,1",null,null
421,qp,null,null
422,", rn",null,null
423,(µ^·jk· - µ^·j·· - µ^··k· + µ^····)2,null,null
424,"k,1 j,1",null,null
425,"As in the single factor design case, the mean squares of a factor (both main and interaction) are calculated by dividing its sum of squares by its degrees of freedom, the F-test is calculated with equation (3.3), the SOA measure with equation (3.4), and the power with equation (3.5).",null,null
426,4. EXPERIMENTATION AND DISCUSSION,null,null
427,"We considered three main components of an IR system: stop list, LUG and IR model. We selected a set of alternative implementations of each component and by using the Terrier open source system we created a run for each system defined by combining the available components in all possible ways. The components we selected are:",null,null
428,"stop list: nostop, indri, lucene, smart, terrier;",null,null
429,"LUG: nolug, weak Porter, Porter, Krovetz, Lovins, 4grams, 5grams;",null,null
430,"model: BB2, BM25, DFRBM25, DFRee, DLH, DLH13, DPH, HiemstraLM, IFB2, InL2, InexpB2, InexpC2, LGD, LemurTFIDF, PL2, TFIDF.",null,null
431,"Note that the stemmers and n-grams of the LUG component are used as alternatives, this means that we end up with two distinct groups of runs, one using the stemmers and one using the n-grams; the nolug component is common to both these groups. The group using the stemmers defines a 5 × 5 × 16 factorial design with a grid of points consisting of 400 runs; the group using the n-grams defines a 5 × 3 × 16 factorial design with a grid of points consisting of 240 runs.",null,null
432,29,null,null
433,"Table 1: Single factor, ANOVA table for TREC 08",null,null
434,(stemmer group) using AP.,null,null
435,Source,null,null
436,SS,null,null
437,DF,null,null
438,MS,null,null
439,F,null,null
440,p-value,null,null
441,Topics,null,null
442,820.99,null,null
443,49 16.75 694.7235,null,null
444,0,null,null
445,Systems 36.44,null,null
446,399,null,null
447,0.09,null,null
448,7.4464,null,null
449,0,null,null
450,Error,null,null
451,88.20 19551 0.0045,null,null
452,Total,null,null
453,945.63 19999,null,null
454,"We conducted single factor and three-factors ANOVA tests for both the groups on TREC 05, 06, and 08 collections, and by employing the following five measures: AP, P@10, nDCG@20, RBP and ERR@20. All the test collections are composed by 50 different topics and have binary relevance judgments; the corpus of TREC 05 is the TIPSTER disk 2 and 4 counting 525K documents, the corpus of TREC 06 is TIPSTER disk 4 and 5 counting 556K documents and the corpus of TREC 07 and 08 is the TIPSTER disk 4 and disk 5 (minus Congressional Record) counting 528K documents.",null,null
455,"To ease reproducibility, the code for running the experiments is available at: http://gridofpoints.dei.unipd.it/.",null,null
456,4.1 Single Factor Repeated Measures Effects,null,null
457,We conducted 40 single factor ANOVA tests (4 collections,null,null
458,"× 5 measures × 2 run groups), so for space reasons we cannot",null,null
459,"report all the result; as an example, Table 1 reports the",null,null
460,synthesis data of the ANOVA test for TREC 08 using the,null,null
461,stemmer group of runs measured with AP.,null,null
462,"From the sum of squares (SS) and the mean squares (MS),",null,null
463,we can see that topics explain a large portion of the total,null,null
464,"variance. Nonetheless, the effect of the IR systems is statis-",null,null
465,tically significant (p-value 0). We can also see that the sum,null,null
466,of squares of the error is not negligible since it contains both,null,null
467,the variance of the unexplained topics/systems interaction,null,null
468,effect and the the other uncontrolled sources of variance.,null,null
469,From this table we can calculate the statistical power of,null,null
470,"the experiment, which is 1 with a Type 1 error probabil-",null,null
471,"ity  ,"" 0.05, indicating that we are observing effects in a""",null,null
472,reliable way.,null,null
473,Table,null,null
474,2,null,null
475,reports,null,null
476,the,null,null
477,^,null,null
478,2 system,null,null
479,SOA measure and the p-,null,null
480,value of the ANOVA test for the single factor models on all,null,null
481,the test collections for all the considered evaluation mea-,null,null
482,"sures. The ""LUG"" column indicates the runs group we are",null,null
483,considering (stemmers or n-grams). This table shows that,null,null
484,"despite the high variance of the topics, the system effect",null,null
485,sizes are generally large and this is consistent across all the,null,null
486,"collections and measures. Moreover, system effect sizes of",null,null
487,stemmer runs group systems are large (> 0.14) for all the,null,null
488,collections and measures with the solely exception of AP,null,null
489,"for TREC 05. Whereas, for the n-grams runs group we",null,null
490,can see that the system effect sizes are consistently smaller,null,null
491,"than those of the stemmer group; this, supports the obser-",null,null
492,"vation that ""for English, n-grams indexing has no strong",null,null
493,"impact"" [3].",null,null
494,Table 2 shows that measures impact on the amount of,null,null
495,"variance explained by the system effect. Generally, system",null,null
496,"effect sizes are higher when nDCG@20 is used, followed by",null,null
497,"RBP, P@10, AP and ERR@20. This could be related to two",null,null
498,characteristics of the measures: their discriminative power,null,null
499,"and their user model. Indeed, if a measure is less discrimi-",null,null
500,"native than another one, it could be able to grasp less vari-",null,null
501,"ance in the system effect; on the other hand, different user",null,null
502,models mean looking at (very) different angles of system,null,null
503,performances and this can change the explained variance.,null,null
504,"To explore a bit this hypothesis, in Table 3 we report the discriminative power of the five considered measures over the test collections calculated by employing the paired bootstrap test defined in [19]. We can see that there is some agreement between the system effect sizes for a measure and its discriminative power; for instance, ERR@20 explains less system variance than the other measures and this can be explained by its discriminative power which is the lowest amongst all measures; similarly, RBP and nDCG@20 have both comparable discriminative power and close system effect sizes. The main exception is AP which typically has the highest discriminative power but the smallest system effect size; this could be due to the user model behind AP, which is quite different from the one of the other measures and may counterbalance the higher discriminative power leading to a final lower system effect size.",null,null
505,4.2 Three Factors Repeated Measures Effects,null,null
506,In Table 4 we report the ANOVA table of a three factors test for the stemmer group of runs on TREC 08 measured with AP.,null,null
507,"We can see that the sum of squares of the topics is the same as the one determined with the single factor design, as well as the error and the total sum of squares. The main difference with the one factor design is that the variance of the systems is now decomposed into three main effects (stop list, stemmer and IR model) and four interaction effects. In this case all the main effects are statistically significant meaning that they have a role in explaining systems variance; in particular, the stop list explains more variance than the model and the stemmer is the component with the lowest impact in this design. Amongst the interaction effects, only the stoplist*model effect is significant explaining a tangible portion of the systems variance. The statistical power for the main effects is 0.97 for the stop list, 0.66 for the stemmer and 0.99 for the model with a Type 1 error probability  , 0.05.",null,null
508,Table 5 reports the estimated 2 SoA for all the main and interaction effects and the p-values for all the ANOVA three-way tests we conducted; from this this table we can see that main and interaction effect sizes are consistent across the different collections.,null,null
509,"Analyzing the main effect sizes reported in Table 5 we can see that for the stemmer group of runs the stop list has always a higher ^2 than the IR model and the stemmer and, with the solely exceptions of TREC 05 for AP and ERR@20, the stop list has a medium effect size. Whereas, n-grams tend to reduce the stop list effect and to increase the IR model one; this can be also seen from the n-grams*model interaction effect which is small but statistically significant, differently from the stemmer*model effect which is never significant.",null,null
510,"These observations cast a light on the importance of linguistic pre-processing and linguistic resources, given that the role of the stop list is significant in an IR system as well as choosing between stemmers or n-grams. We can further analyze these aspects by looking at Figure 3; the plot on the left reports the main effects for the TREC 08 stemmer group case and we show the marginal means (response means) described in Section 3.2 for the effect under investigation on the y-axis and the various components on the x-axis.",null,null
511,"From the first plot we see that the presence or absence of a stop list affects the system performances because the line connecting ""no stop"" and ""indri"" is not horizontal, whereas",null,null
512,30,null,null
513,marginal mean AP,null,null
514,nostop indri,null,null
515,lucene smart terrier nostem wkporter porter krovetz lovins,null,null
516,BB2 BM25 DFRBM25 DFRee,null,null
517,DLH DLH13,null,null
518,DPH HiemstraLM,null,null
519,IFB2 InL2 InexpB2 InexpC2 LGD LemurTFIDF PL2 TFIDF,null,null
520,0.26 0.25 0.24 0.23 0.22 0.21 0.20 0.19,null,null
521,Stop Lists,null,null
522,Stemmers,null,null
523,IR Models,null,null
524,"Main Effects of Stop Lists, Stemmers, and IR Models for AP on collection TREC 08",null,null
525,"Stop Lists,nostop",null,null
526,Tukey HSD Test for AP and Stop Lists on TREC 08,null,null
527,"Stop Lists,indri",null,null
528,"Stop Lists,lucene",null,null
529,"Stop Lists,smart",null,null
530,"Stop Lists,terrier",null,null
531,0.19,null,null
532,0.20,null,null
533,0.21,null,null
534,0.22,null,null
535,0.23,null,null
536,0.24,null,null
537,0.25,null,null
538,0.26,null,null
539,marginal mean AP,null,null
540,Tukey HSD Test for AP and Stemmers on TREC 08,null,null
541,"Stemmers,nostem",null,null
542,"Stemmers,wkporter",null,null
543,"Stemmers,porter",null,null
544,"Stemmers,krovetz",null,null
545,"Stemmers,lovins",null,null
546,0.21,null,null
547,0.22,null,null
548,0.23,null,null
549,0.24,null,null
550,0.25,null,null
551,marginal mean AP,null,null
552,Tukey HSD Test for AP and IR Models on TREC 08,null,null
553,"IR Models,BB2 IR Models,BM25 IR Models,DFRBM25 IR Models,DFRee",null,null
554,"IR Models,DLH IR Models,DLH13",null,null
555,"IR Models,DPH IR Models,HiemstraLM",null,null
556,"IR Models,IFB2 IR Models,InL2 IR Models,InexpB2 IR Models,InexpC2 IR Models,LGD IR Models,LemurTFIDF IR Models,PL2 IR Models,TFIDF",null,null
557,0.19 0.20 0.21 0.22 0.23 0.24 0.25 0.26 0.27 marginal mean AP,null,null
558,Figure 3: Main effects plots and Tukey HSD test plots for the stemmer group of runs on TREC 08 with AP.,null,null
559,Stop Lists,null,null
560,"Stop Lists , nostop Stop Lists , indri Stop Lists , lucene Stop Lists , smart Stop Lists , terrier",null,null
561,nostem wkporter porter krovetz lovins,null,null
562,BB2BM2D5FRDBFMRD2eL5eHDLHD1P3HHiemIFsBtr2InaLL2MInexInpeBx2LpGCDL2emPuLr2TTFFIDIDFF 0.25 0.20 0.15 0.10 0.05,null,null
563,marginal mean AP,null,null
564,0.25 0.20 0.15 0.10 0.05,null,null
565,Stemmers,null,null
566,"Stemmers , nostem Stemmers , wkporter Stemmers , porter Stemmers , krovetz Stemmers , lovins",null,null
567,0.25 0.20 0.15 0.10 0.05,null,null
568,marginal mean AP,null,null
569,0.25 0.20 0.15 0.10 0.05,null,null
570,nostop indri lucene smart terrier,null,null
571,IR Models,null,null
572,nostem wkporter porter krovetz lovins,null,null
573,"IR Models , BB2 IR Models , BM25 IR Models , DFRBM25 IR Models , DFRee IR Models , DLH IR Models , DLH13 IR Models , DPH IR Models , HiemstraLM IR Models , IFB2 IR Models , InL2 IR Models , InexpB2 IR Models , InexpC2 IR Models , LGD IR Models , LemurTFIDF IR Models , PL2 IR Models , TFIDF",null,null
574,Figure 4: Interaction plots for the stemmer group of runs on TREC 08 with AP.,null,null
575,31,null,null
576,Table 2: Summary of single factor models on TREC collections. Each cell reports the ^2 for the System,null,null
577,"effects and, within parentheses, the p-value for those effects. Large effect sizes (^2Systems > 0.14) are in bold.",null,null
578,Collection,null,null
579,LUG,null,null
580,Effects,null,null
581,AP,null,null
582,P@10,null,null
583,RBP,null,null
584,nDCG@20,null,null
585,ERR@20,null,null
586,TREC 05 TREC 06 TREC 07 TREC 08,null,null
587,Stemmers n-grams Stemmers n-grams Stemmers n-grams Stemmers n-grams,null,null
588,^ 2Systems ^ 2Systems,null,null
589,^ 2Systems ^ 2Systems,null,null
590,^ 2Systems ^ 2Systems,null,null
591,^ 2Systems ^ 2Systems,null,null
592,0.1223 (0.00) 0.0794 (0.00) 0.2108 (0.00) 0.1350 (0.00) 0.2155 (0.00) 0.1502 (0.00) 0.2774 (0.00) 0.1758 (0.00),null,null
593,0.2023 (0.00) 0.1178 (0.00) 0.2458 (0.00) 0.1496 (0.00) 0.2568 (0.00) 0.1658 (0.00) 0.2780 (0.00) 0.1907 (0.00),null,null
594,0.1970 (0.00) 0.1349 (0.00) 0.2716 (0.00) 0.1597 (0.00) 0.2894 (0.00) 0.1920 (0.00) 0.3025 (0.00) 0.2006 (0.00),null,null
595,0.1879 (0.00) 0.1200 (0.00) 0.2742 (0.00) 0.1725 (0.00) 0.2977 (0.00) 0.1898 (0.00) 0.3118 (0.00) 0.2135 (0.00),null,null
596,0.1406 (0.00) 0.1063 (0.00) 0.2377 (0.00) 0.1469 (0.00) 0.2445 (0.00) 0.1480 (0.00) 0.2484 (0.00) 0.1530 (0.00),null,null
597,Table 3: Discriminative power of the evaluation,null,null
598,"measures on TREC 05, TREC 06, TREC 07 and",null,null
599,TREC 08 for the stemmers and n-grams groups.,null,null
600,Group stemmer,null,null
601,n-grams,null,null
602,AP P@10 RBP nDCG@20 ERR@20,null,null
603,AP P@10 RBP nDCG@20 ERR@20,null,null
604,TREC 05 3011 .3774 .3152 .3448 .2014 .3180 .3025 .3852 .3260 .2832,null,null
605,TREC 06 .2748 .2687 .2589 .2698 .2235 .3553 .2656 .2539 .3130 .1978,null,null
606,TREC 07 .3591 .3222 .3302 .3169 .2096 .5184 .3660 .4193 .4292 .2549,null,null
607,TREC 08 .4743 .3171 .3422 .3834 .2388 .3498 .2977 .2797 .2938 .2416,null,null
608,"Table 4: Three factor, ANOVA table for TREC 08",null,null
609,(stemmer group) using AP.,null,null
610,Source Topics Stop list Stemmer Model Stop list*Stemmer Stop list*Model Stemmer*Model Stop list*Stemmer*Model Error Total,null,null
611,SS 820.99,null,null
612,9.89 4.16 5.16 0.05 17.01 0.07 0.09 88.20 945.63,null,null
613,DF 49 4 4 15 16 60 60,null,null
614,240 19551 19999,null,null
615,MS 16.75,null,null
616,2.47 1.04 0.3443 0.03 0.28 0.001 0.00 0.005,null,null
617,F 3713.90,null,null
618,548.06 230.76,null,null
619,76.32 0.67,null,null
620,62.84 0.26 0.08,null,null
621,p 0.00 0.00 0.00 0.00 0.83 0.00 1.00 1.00,null,null
622,"the lines connecting the different stop lists have much lower slope. In particular, we see that the choice of the stop list does not make a big difference with respect to use or not use a stop list; this can be further explored looking at the Tukey HSD test plot on the upper-right corner of the figure (in blue the selected component; in grey the components in the same group, i.e. not significantly different; in red the components in a different group, i.e. significantly different), where we can see that there are no significant differences between the ""indri"", ""smart"" and ""terrier"" stop lists, whereas the ""lucene"" stop list (which is composed by 15 words) is significantly different from the other three.",null,null
623,"The main effect of the stemmer is always significant even though its size is quite small; nevertheless, the central plot of Figure 3 shows that there is a tangible difference between systems using or not using a stemmer. This can be seen also from the Tukey HSD test plot on the right; in particular, we can observe that there is no significant difference between the Porter and the Krovetz stemmer which are the stemmers with the highest impact on variance followed by the weak Porter and the Lovins ones.",null,null
624,"Lastly, the plot on the right of Figure 3 reports the main effects of the IR models: they behave differently, as shown by several lines with high slopes, but the corresponding Tukey HSD shows that a many models are not significantly different one from the other. This can explain why the IR models effects are statistically significant but their effect sizes are not large.",null,null
625,"For all the collections, consistently across the measures and both for the stemmer and the n-grams group, the higher",null,null
626,"effect size is reported by the stop list*model interaction effect which is always of medium or large size. This effect shows us that the variance of the systems is explained for the bigger part by the stop list and the model components. For the stemmer group of TREC 08, this can be seen in the plots on the upper-right and lower-left corners of Figure 4 where the lines of the interaction between the stop lists and the models intersect quite often. Indeed, the interaction plots show how the relationship between one factor and a response depends on the value of the second factor. These plots display means for the levels of one factor on the x-axis and a separate line for each level of another factor; if two lines (or segments) are parallel then no interaction occurs, if the lines are not parallel then an interaction occurs and the more nonparallel the lines are, the greater the strength of the interaction.",null,null
627,The stop list*stemmer interaction effects are always not significant as we can see from the p-values of Table 5 and the interaction plots in the upper-left part of Figure 4 where the line segments are parallel. A very similar trend can be observed for the stemmer*model interaction effect.,null,null
628,"It is interesting to note that the second order interactions for the n-grams group are all statistically significant and that, in particular, we can see that n-grams, differently than the stemmers, have a bigger effect on the stop list than on the IR model.",null,null
629,"We observe that different measures see the stop lists in a comparable way in terms of effect size and this is consistent with what we have seen in the one factor analysis. This is valid also for the stemmer, with the exception of ERR@20 for which it has an almost negligible effect size even though it is statistically significant. In Table 5 we can see that AP and ERR@20 weight the effects in a similar way as it happened in the single factor analysis reported in Table 2. For the n-grams group all the measures are comparable and ERR@20 is not as low as it happens for the stemmers.",null,null
630,"Lastly, we can see that the third order interaction are never significant.",null,null
631,5. CONCLUSIONS AND FUTURE WORK,null,null
632,"In this paper we faced the issue of how system variance contributes to the overall performances and how to break it down into some of the main components constituting an IR system. To this end, we developed an analysis methodology consisting of two elements: a Grid of Points (GoP) created on standard experimental collections, where all the combinations of system components under examination are considered; and, a GLMM model to decompose the contribution of these components to the overall system variance, paired with some graphical tools for easily assessing the main and interaction effects.",null,null
633,32,null,null
634,Collection TREC 05 TREC 06,null,null
635,TREC 07 TREC 08,null,null
636,LUG Stemmers n-grams Stemmers n-grams Stemmers n-grams Stemmers n-grams,null,null
637,Effects,null,null
638,^ 2Stop Lists ^ 2Stemmers ^ 2IR Models ^ 2Stop Lists×Stemmers ^ 2Stop Lists×IR Models ^ 2Stemmers×IR Models ^ 2Stop Lists×Stemmers×IR Models ^ 2Stop Lists ^ 2n-grams ^ 2IR Models ^ 2Stop Lists×n-grams ^ 2Stop Lists×IR Models ^ 2n-grams×IR Models ^ 2Stop Lists×n-grams×IR Models ^ 2Stop Lists ^ 2Stemmers ^ 2IR Models ^ 2Stop Lists×Stemmers ^ 2Stop Lists×IR Models ^ 2Stemmers×IR Models ^ 2Stop Lists×Stemmers×IR Models ^ 2Stop Lists ^ 2n-grams ^ 2IR Models ^ 2Stop Lists×n-grams ^ 2Stop Lists×IR Models ^ 2n-grams×IR Models ^ 2Stop Lists×n-grams×IR Models ^ 2Stop Lists ^ 2Stemmers ^ 2IR Models ^ 2Stop Lists×Stemmers ^ 2Stop Lists×IR Models ^ 2Stemmers×IR Models ^ 2Stop Lists×Stemmers×IR Models ^ 2Stop Lists ^ 2n-grams ^ 2IR Models ^ 2Stop Lists×n-grams ^ 2Stop Lists×IR Models ^ 2n-grams×IR Models ^ 2Stop Lists×n-grams×IR Models ^ 2Stop Lists ^ 2Stemmers ^ 2IR Models ^ 2Stop Lists×Stemmers ^ 2Stop Lists×IR Models ^ 2Stemmers×IR Models ^ 2Stop Lists×Stemmers×IR Models ^ 2Stop Lists ^ 2n-grams ^ 2IR Models ^ 2Stop Lists×n-grams ^ 2Stop Lists×IR Models ^ 2n-grams×IR Models ^ 2Stop Lists×n-grams×IR Models,null,null
639,AP 0.0432 (0.00) 0.0178 (0.00) 0.0219 (0.00) -0.0005 (0.98) 0.0632 (0.00) -0.0019 (1.00) -0.0115 (1.00) 0.0165 (0.00) 0.0170 (0.00) 0.0208 (0.00) 0.0016 (0.00) 0.0296 (0.00) 0.0050 (0.00) -0.0063 (1.00) 0.0750 (0.00) 0.0112 (0.00) 0.0557 (0.00) -0.0007 (1.00) 0.1153 (0.00) -0.0020 (1.00) -0.0119 (1.00) 0.0241 (0.00) 0.0340 (0.00) 0.0404 (0.00) 0.0026 (0.00) 0.0465 (0.00) 0.0058 (0.00) -0.0033 (0.99) 0.0747 (0.00) 0.0227 (0.00) 0.0441 (0.00) 0.0001 (0.36) 0.1209 (0.00) -0.0018 (1.00) -0.0113 (1.00) 0.0237 (0.00) 0.0208 (0.00) 0.0563 (0.00) 0.00 (0.0001) 0.0517 (0.00) 0.0200 (0.00) -0.0055 (1.00) 0.0986 (0.00) 0.0439 (0.00) 0.0535 (0.00) -0.0003 (0.83) 0.1565 (0.00) -0.0022 (1.00) -0.0111 (1.00) 0.0396 (0.00) 0.0037 (0.00) 0.0550 (0.00) 0.0035 (0.00) 0.0928 (0.00) 0.0080 (0.00) -0.0038 (0.99),null,null
640,P@10 0.0632 (0.00) 0.0217 (0.00) 0.0458 (0.00),null,null
641,-0.00 (0.46) 0.1118 (0.00),null,null
642,-0.00 (0.49) -0.0099 (1.00) 0.0272 (0.00) 0.0105 (0.00) 0.0341 (0.00) 0.0015 (0.00) 0.0544 (0.00) 0.0047 (0.00) -0.0040 (0.99) 0.0852 (0.00) 0.0082 (0.00) 0.0596 (0.00) -0.0007 (0.99) 0.1483 (0.00) -0.0016 (0.99) -0.0109 (1.00) 0.0282 (0.00) 0.0144 (0.00) 0.0516 (0.00) 0.0034 (0.00) 0.0628 (0.00) 0.0091 (0.00) -0.0019 (0.94) 0.0830 (0.00) 0.0157 (0.00) 0.0525 (0.00) 0.0009 (0.00) 0.1624 (0.00) -0.0009 (0.95) -0.0103 (1.00) 0.0344 (0.00) 0.0059 (0.00) 0.0552 (0.00) 0.0014 (0.00) 0.0818 (0.00) 0.0126 (0.00) -0.0044 (1.00) 0.0913 (0.00) 0.0165 (0.00) 0.0615 (0.00) -0.0005 (0.98) 0.1765 (0.00) -0.0014 (0.99) -0.0105 (1.00) 0.0423 (0.00) 0.0031 (0.00) 0.0545 (0.00) 0.0023 (0.00) 0.1129 (0.00) 0.0050 (0.00) -0.0040 (0.99),null,null
643,RBP 0.0638 (0.00) 0.0116 (0.00) 0.0452 (0.00) -0.0004 (0.97) 0.1145 (0.00),null,null
644,-0.00 (0.48) -0.0109 (1.00) 0.0288 (0.00) 0.0211 (0.00) 0.0391 (0.00) 0.0020 (0.00) 0.0571 (0.00) 0.0049 (0.00) -0.0034 (0.99) 0.0904 (0.00) 0.0068 (0.00) 0.0692 (0.00) -0.0007 (0.99) 0.1709 (0.00) -0.0017 (1.00) -0.0116 (1.00) 0.0305 (0.00) 0.0126 (0.00) 0.0563 (0.00) 0.0036 (0.00) 0.0673 (0.00) 0.0111 (0.00) -0.0008 (0.72) 0.0997 (0.00) 0.0163 (0.00) 0.0601 (0.00) 0.0004 (0.09) 0.1856 (0.00) -0.0014 (0.99) -0.0111 (1.00) 0.0395 (0.00) 0.0132 (0.00) 0.0623 (0.00) 0.0023 (0.00) 0.0958 (0.00) 0.0116 (0.00) -0.0031 (0.99) 0.1000 (0.00) 0.0190 (0.00) 0.0666 (0.00) -0.0005 (0.98) 0.1969 (0.00) -0.0020 (1.00) -0.0110 (1.00) 0.0445 (0.00) 0.0008 (0.00) 0.0548 (0.00) 0.0024 (0.00) 0.1231 (0.00) 0.0059 (0.00) -0.0032 (0.99),null,null
645,nDCG@20 0.0605 (0.00) 0.0188 (0.00) 0.0409 (0.00) -0.0004 (0.94) 0.1047 (0.00) -0.0008 (0.95) -0.0107 (1.00) 0.0256 (0.00) 0.0288 (0.00) 0.0275 (0.00) 0.0019 (0.00) 0.0483 (0.00) 0.0050 (0.00) -0.0056 (1.00) 0.0932 (0.00) 0.0126 (0.00) 0.0696 (0.00) -0.0004 (0.94) 0.1671 (0.00) -0.0017 (1.00) -0.0112 (1.00) 0.0306 (0.00) 0.0249 (0.00) 0.0545 (0.00) 0.0033 (0.00) 0.0746 (0.00) 0.0093 (0.00) 0.0004 (0.36) 0.1023 (0.00) 0.0146 (0.00) 0.0653 (0.00) 0.0004 (0.08) 0.1919 (0.00) -0.0018 (1.00) -0.0110 (1.00) 0.0362 (0.00) 0.0154 (0.00) 0.0663 (0.00) 0.0025 (0.00) 0.0874 (0.00) 0.0145 (0.00) -0.0030 (0.99) 0.1006 (0.00) 0.0268 (0.00) 0.0707 (0.00) -0.0006 (0.99) 0.2006 (0.00) -0.0018 (1.00) -0.0110 (1.00) 0.0479 (0.00) 0.0023 (0.00) 0.0637 (0.00) 0.0029 (0.00) 0.1277 (0.00) 0.0050 (0.00) -0.0034 (0.99),null,null
646,ERR@20 0.0476 (0.00) 0.0000 (0.00) 0.0311 (0.00) -0.0005 (0.99) 0.0826 (0.00) 0.0009 (0.05) -0.0102 (1.00) 0.0225 (0.00) 0.0188 (0.00) 0.0308 (0.00) 0.0015 (0.00) 0.0424 (0.00) 0.0040 (0.00) -0.0048 (1.00) 0.0673 (0.00) 0.0015 (0.00) 0.0638 (0.00) -0.0001 (0.64) 0.1539 (0.00) -0.0013 (0.99) -0.0107 (1.00) 0.0296 (0.00) 0.0104 (0.00) 0.0494 (0.00) 0.0032 (0.00) 0.0646 (0.00) 0.0080 (0.00) -0.0010 (0.78) 0.0802 (0.00) 0.0056 (0.00) 0.0513 (0.00) 0.0002 (0.21) 0.1571 (0.00) 0.0007 (0.12) -0.0107 (1.00) 0.0290 (0.00) 0.0112 (0.00) 0.0382 (0.00) 0.0017 (0.00) 0.0793 (0.00) 0.0082 (0.00) -0.0034 (0.99) 0.0799 (0.00) 0.0071 (0.00) 0.0521 (0.00) -0.0004 (0.95) 0.1622 (0.00) -0.0016 (0.99) -0.0102 (1.00) 0.0304 (0.00) 0.0093 (0.00) 0.0307 (0.00) 0.0032 (0.00) 0.0940 (0.00) 0.0040 (0.00) -0.0028 (0.99),null,null
647,"Table 5: Summary of three factor models on the TREC Ad-hoc collections. Each cell reports the estimated 2 SoA for the specified effects and, within parentheses, the p-value for those effects. Medium and large",null,null
648,effect sizes are in bold; not significant effects are highlighted.,null,null
649,33,null,null
650,"We conducted a thorough experimentation on TREC collections and used different evaluation measures to show how the proposed approach works and to gain insights on the considered components, i.e. stop lists, stemmers and n-grams, and IR models.",null,null
651,"We found that the most prominent effects are those of stop lists and IR models, as well as their interactions, while stemmers and n-grams play a smaller role. Moreover, we have seen that stemmers produce more variation on system performances than n-grams. Overall, this highlights importance of linguistic resources.",null,null
652,"Finally, measures explain system and component effects differently one from the other and not all the measures seem to be suitable for all the cases as it happens for ERR@20 which almost does not detect the stemmer effect. These insights can be useful to understand where to invest effort and resources for improving components, since they give us an idea of the actual impact of a family of components on the overall performances.",null,null
653,"As far as future work is concerned, we plan to extend the proposed methodology in order to be able to capture also interaction between topics/systems and topics/components. Indeed, to estimate interaction effects, more replicates would be needed for each (topic, system) pair, as [17] simulated, and they are not possible in the present settings, since running more than once the same system on the same topics produces exactly the same results.",null,null
654,"Moreover, we plan to further investigate the impact of the measures on the determination of effect sizes. A possible approach could be to conduct a four-factor analysis, using measures as additional factor. However, even if the measure scores are normalized in the range [0, 1], they do not mean the exactly the same thing, i.e. AP , 0.20 is not exactly the same as ERR ,"" 0.20 because of their different user models. A possibility for smoothing these differences and make the scores more directly comparable could be to normalize them by the maximum value achieved on the dataset, thus reasoning in term of ratios.""",null,null
655,"Lastly, an open challenge is how to run this kind of analysis on the systems which participated to past TREC editions. A first obstacle is that often there is no precise description of all the components used in these systems and so their metadata should be enriched in the way we suggested in [5]. A second obstacle is that the GoP would be very sparse and many combinations would be missing; therefore, we would need to rely on unbalanced GLMM and, probably, to consider the components as random factors.",null,null
656,6. REFERENCES,null,null
657,"[1] D. Banks, P. Over, and N.-F. Zhang. Blind Men and Elephants: Six Approaches to TREC data. Information Retrieval, 1:7­34, May 1999.",null,null
658,"[2] L. Boytsov, A. Belova, and P. Westfall. Deciding on an Adjustment for Multiplicity in IR Experiments. In SIGIR 2013, pp. 403­412, 2013.",null,null
659,"[3] S. Bu¨ttcher, C. L. A. Clarke, and G. V. Cormack. Information Retrieval: Implementing and Evaluating Search Engines. The MIT Press, USA, 2010.",null,null
660,"[4] B. A. Carterette. Multiple Testing in Statistical Analysis of Systems-Based Information Retrieval Experiments. ACM TOIS, 30(1):4:1­4:34, 2012.",null,null
661,"[5] E. Di Buccio, G. M. Di Nunzio, N. Ferro, D. K. Harman, M. Maistro, and G. Silvello. Unfolding Off-the-shelf IR Systems for Reproducibility. In SIGIR RIGOR 2015, 2015.",null,null
662,"[6] N. Ferro, R. Berendsen, A. Hanbury, M. Lupu, V. Petras, M. de Rijke, and G. Silvello. PROMISE Retreat Report ­ Prospects and Opportunities for Information Access Evaluation. SIGIR Forum, 46(2):60­84, 2012.",null,null
663,"[7] N. Ferro and D. Harman. CLEF 2009: Grid@CLEF Pilot Track Overview. In CLEF 2009, pp. 552­565. LNCS 6241, 2010.",null,null
664,"[8] A. Hanbury and H. Mu¨ller. Automated Component-Level Evaluation: Present and Future. In CLEF 2010, pp. 124­135. LNCS 6360, 2010.",null,null
665,"[9] D. A. Hull. Using Statistical Testing in the Evaluation of Retrieval Experiments. In SIGIR 1993, pp. 329­338, 1993.",null,null
666,"[10] G. K. Jayasinghe, W. Webber, M. Sanderson, L. S. Dharmasena, and J. S. Culpepper. Statistical comparisons of non-deterministic IR systems using two dimensional variance. IPM, 51(5):677­694, 2015.",null,null
667,"[11] J. Lin, M. Crane, A. Trotman, J. Callan, I. Chattopadhyaya, J. Foley, G. Ingersoll, C. Macdonald, and S. Vigna. Toward Reproducible Baselines: The Open-Source IR Reproducibility Challenge. In ECIR 2016, pp. 357­368. LNCS 9626, 2016.",null,null
668,"[12] C. Macdonald, R. McCreadie, R. L. T. Santos, and I. Ounis. From Puppy to Maturity: Experiences in Developing Terrier. OSIR at SIGIR, pp. 60­63, 2012.",null,null
669,"[13] S. Maxwell and H. D. Delaney. Designing Experiments and Analyzing Data. A Model Comparison Perspective. Lawrence Erlbaum Associates, 2nd ed, 2004.",null,null
670,"[14] K. R. Murphy and B. Myors. Statistical power analysis: A Simple and General Model for Traditional and Modern Hypothesis Tests (2nd ed.). Lawrence Erlbaum, 2004.",null,null
671,"[15] S. Olejnik and J. Algina. Generalized Eta and Omega Squared Statistics: Measures of Effect Size for Some Common Research Designs. Psychological Methods, 8(4):434­447, 2003.",null,null
672,"[16] S. E. Robertson. The methodology of information retrieval experiment. In Information Retrieval Experiment, pp. 9­31. Butterworths, 1981.",null,null
673,"[17] S. E. Robertson and E. Kanoulas. On Per-topic Variance in IR Evaluation. In SIGIR 2012, pp. 891­900, 2012.",null,null
674,"[18] A. Rutherford. ANOVA and ANCOVA. A GLM Approach. John Wiley & Sons, 2nd ed, 2011.",null,null
675,"[19] T. Sakai. Evaluating Evaluation Metrics based on the Bootstrap. In SIGIR 2006, pp. 525­532, 2006.",null,null
676,"[20] T. Sakai. Statistical reform in information retrieval? SIGIR Forum, 48(1):3­12, 2014.",null,null
677,"[21] J. Savoy. Statistical Inference in Retrieval Effectiveness Evaluation. IPM, 33(44):495­512, 1997.",null,null
678,"[22] M. D. Smucker, J. Allan, and B. A. Carterette. A Comparison of Statistical Significance Tests for Information Retrieval Evaluation. In CIKM 2007, pp. 623­632, 2007.",null,null
679,"[23] J. M. Tague-Sutcliffe and J. Blustein. A Statistical Analysis of the TREC-3 Data. In Overview of TREC-3, pp. 385­398. NIST, SP 500-225, 1994.",null,null
680,"[24] A. Trotman, C. L. A. Clarke, I. Ounis, J. S. Culpepper, M.-A. Cartright, and S. Geva. Open Source Information Retrieval: a Report on the SIGIR 2012 Workshop. ACM SIGIR Forum, 46(2):95­101, 2012.",null,null
681,"[25] L. Wang, P. N. Bennett, and K. Collins-Thompson. Robust Ranking Models via Risk-Sensitive Optimization. In SIGIR 2012, pp. 761­770, 2012.",null,null
682,"[26] W. Webber, A. Moffat, and J. Zobel. Score Standardization for Inter-Collection Comparison of Retrieval Systems. In SIGIR 2008, pp. 51­58, 2008.",null,null
683,"[27] W. J. Wilbur. Non-parametric significance tests of retrieval performance comparisons. J. Inf. Science, 20(4):270­284, 1994.",null,null
684,"[28] P. Zhang, S. Dawei, J. Wang, and Y. Hou. Bias­variance analysis in estimating true query model for information retrieval. IPM, 50(1):199­217, 2014.",null,null
685,34,null,null
686,,null,null
