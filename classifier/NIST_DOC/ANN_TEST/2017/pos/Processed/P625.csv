,sentence,label,data
0,Session 5C: Efficiency and Scalability,null,null
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
2,Faster BlockMax WAND with Variable-sized Blocks,null,null
3,Antonio Mallia,null,null
4,"University of Pisa, Italy a.mallia@studenti.unipi.it",null,null
5,Giuseppe O aviano,null,null
6,"ISTI-CNR, Italy giuseppe.o aviano@isti.cnr.it",null,null
7,Elia Porciani,null,null
8,"University of Pisa, Italy e.porciani1@studenti.unipi.it",null,null
9,Nicola Tonello o,null,null
10,"ISTI-CNR, Italy nicola.tonello o@isti.cnr.it",null,null
11,ABSTRACT,null,null
12,"ery processing is one of the main bo lenecks in large-scale search engines. Retrieving the top k most relevant documents for a given query can be extremely expensive, as it involves scoring large amounts of documents. Several dynamic pruning techniques have been introduced in the literature to tackle this problem, such as BlockMaxWAND, which splits the inverted index into constantsized blocks and stores the maximum document-term scores per block; this information can be used during query execution to safely skip low-score documents, producing many-fold speedups over exhaustive methods.",null,null
13,"We introduce a re nement for BlockMaxWAND that uses variablesized blocks, rather than constant-sized. We set up the problem of deciding the block partitioning as an optimization problem which maximizes how accurately the block upper bounds represent the underlying scores, and describe an e cient algorithm to nd an approximate solution, with provable approximation guarantees.",null,null
14,"rough an extensive experimental analysis we show that our method signi cantly outperforms the state of the art roughly by a factor 2×. We also introduce a compressed data structure to represent the additional block information, providing a compression ratio of roughly 50%, while incurring only a small speed degradation, no more than 10% with respect to its uncompressed counterpart.",null,null
15,1 INTRODUCTION,null,null
16,"Web Search Engines [6, 19] manage an ever-growing amount of Web documents to answer user queries as fast as possible. To keep up with such a tremendous growth, a focus on e ciency is crucial.",null,null
17,"ery processing is one of the hardest challenges a search engine has to deal with, since its workload grows with both data size and query load. Although hardware is ge ing less expensive and more powerful every day, the size of the Web and the number of searches is growing at an even faster rate.",null,null
18,ery processing in search engines is a fairly complex process; queries in a huge collection of documents may return a large set of,null,null
19,"Author currently at Facebook, USA.",null,null
20,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-5022-8/17/08. . . $15.00. DOI: h p://dx.doi.org/10.1145/3077136.3080780",null,null
21,Rossano Venturini,null,null
22,"University of Pisa, Italy",null,null
23,rossano.venturini@unipi.it,null,null
24,"results, but users are o en interested the most relevant documents, usually a small number (historically, the ten blue links). e relevance of a document can be arbitrarily expensive to compute, which makes it prohibitive to evaluate all the documents that match the queried terms; query processing is thus usually divided in multiple phases. In the rst phase, the query is evaluated over an inverted index data structure [3, 29] using a simple scoring function, producing a medium-sized set of candidate documents, namely the top k scored; these candidates are then re-ranked using more complex algorithms to produce the nal set of documents shown to the user.",null,null
25,"In this work we focus on improving the e ciency of the rst query processing phase, which is responsible for a signi cant fraction of the overall work. In such phase, the scoring function is usually a weighted sum of per-term scores over the terms in the document that match the query, where the weights are a function of the query, and the scores a function of the occurrences of the term in the document. An example of such a scoring function is the widely used BM25 [24].",null,null
26,"An obvious way to compute the top k scored documents is to retrieve all the documents that match at least one query term using the inverted index, and compute the score on all the retrieved documents. Since exhaustive methods like this can be very expensive for large collections, several dynamic pruning techniques have been proposed in the last few years. Dynamic pruning makes use of the inverted index, augmented with additional data structures, to skip documents during iteration that cannot reach a su cient score to enter the top k. us, the nal result is the same as exhaustive evaluation, but obtained with signi cantly less work.",null,null
27,"ese techniques include MaxScore [30], WAND [4], and BlockMaxWAND (BMW) [10].",null,null
28,"We focus our a ention on the WAND family of techniques. WAND augments the posting list of each term with the maximum score of that term among all documents in the list. While processing the query by iterating on the posting lists of its terms, it maintains the top k scores among the documents evaluated so far; to enter the top k, a new document needs to have score larger than the current k-th score, which we call the threshold. WAND maintains the posting list iterators sorted by current docid; at every step, it adds up the maximum scores of the lists in increasing order, until the threshold is reached. It can be seen that the current docid of the rst list that exceeds the threshold is the rst docid that can reach a score higher than the threshold, so the other iterators can safely skip all the documents up to that docid.",null,null
29,"e core principle is that if we can upper-bound the score of a range of docids, and that upper bound is lower than the threshold,",null,null
30,625,null,null
31,Session 5C: Efficiency and Scalability,null,null
32,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
33,"then the whole range can be safely skipped. As such, WAND computes the upper bounds of document by using the maximum score of the terms appearing in the document. Nevertheless, it should be clear that the pruning e ectiveness is highly dependent on the accuracy of the upper bound: the more precise the upper bound, the more docids we can skip, and, thus, the faster the query processing.",null,null
34,"BMW improves the accuracy of the upper bounds by spli ing the posting lists into constant-sized blocks of postings, and storing the maximum score per block, rather than per list only. is way, the upper bound of a document is the sum of the maximum score of the blocks in which it may belong to. is approach gives more precise upper bounds because the scores of the blocks are usually much smaller than the maximum in their lists. Experiments con rm this intuition, and, indeed, BMW signi cantly outperforms WAND [10].",null,null
35,"However, the coarse partitioning strategy of BMW does not take into consideration regularities or variances of the scores that may occur in the posting lists and their blocks. As an example, consider a posting with a very high score surrounded by postings with much lower scores. is posting alone is responsible for a high inaccuracy in the upper bounds of all its neighbors in the same block. Our main observation is that the use of variable-sized blocks would allow to be er adapt to the distribution of the scores in the posting list.",null,null
36,"e bene ts of variable-sized blocks are apparent in the simple example above, where it is su cient to isolate the highly-scored posting in its own block to improve the upper bounds of several other postings, stored in di erent blocks. More formally, for a block of postings we de ne the block error as the sum of the individual posting errors, i.e., the sum of the di erences between the block maximum score and the actual score of the posting. Our goal is to nd a block partitioning minimizing the sum of block errors among all blocks in the partitioning. Clearly, this corresponds to minimizing the average block error. Na¨ively, the minimum cost partitioning would correspond to blocks containing only a single posting. However, if the blocks are too small, the average skip at query time will be short and, thus, this solution does not carry out any bene t. In this work we introduce the problem of nding a partition of posting lists into variable-sized blocks such that the the sum of block errors is minimized, subject to a constraint on the number of blocks of the partition. en, we will show that an approximately optimal partition can be computed e ciently. Experiments on standard datasets show that our Variable BMW (VBMW) signi cantly outperforms BMW and the other state-ofthe-art strategies.",null,null
37,Our Contributions. We list here our main contributions.,null,null
38,"(1) We introduce the problem of optimally partitioning the posting lists into variable-sized blocks to minimize the average block error, subject to a constraint on the number of blocks. We then propose a practical optimization algorithm which produces an approximately optimal solution in almost linear time. We remark that existing solutions for this optimization problem run in at least quadratic time, and, thus, they are unfeasible in a practical se ing. Experiments show that this approach is able to reduce the average score error up to 40%, con rming the importance of optimally partitioning posting list into variable-sized blocks.",null,null
39,"(2) We propose a compression scheme for the block data structures, compressing the block boundary docids with EliasFano and quantizing the block max scores, obtaining a maximum reduction of space usage w.r.t. the uncompressed data structures of roughly 50%, while incurring only a small speed degradation, no more than 10% with respect to its uncompressed counterpart.",null,null
40,(3) We provide an extensive experimental evaluation to compare our strategy with the state of the art on standard datasets of Web pages and queries. Results show that VBMW outperforms the state-of-the-art BMW by a factor of roughly 2×.,null,null
41,2 BACKGROUND AND RELATED WORK,null,null
42,"In the following we will provide some background on index organization and query processing in search engines. We will also summarize and discuss the state-of-the-art query processing strategies with a particular focus on the current most e cient strategy, namely BlockMaxWAND, leveraging block-based score upper bound approximations.",null,null
43,"Index Organization. Given a collection D of documents, each document is identi ed by a non-negative integer called a document identi er, or docid. A posting list is associated to each term appearing in the collection, containing the list of the docids of all the documents in which the term occurs. e collection of the posting lists for all the terms is called the inverted index of D, while the set of the terms is usually referred to as the dictionary. Posting lists typically contain additional information about each document, such as the number of occurrences of the term in the document, and the set of positions where the term occurs [5, 19, 32].",null,null
44,"e docids in a posting list can be sorted in increasing order, which enables the use of e cient compression algorithms and document-at-a-time query processing. is is the most common approach in large-scale search engines (see for example [8]). Alternatively, the posting lists can be frequency-sorted [30] or impactsorted [2], still providing a good compression rates as well as good query processing speed. However, there is no evidence of such index layouts in common use within commercial search engines [21].",null,null
45,"Inverted index compression is essential to make e cient use of the memory hierarchy, thus maximizing query processing speed. Posting list compression boils down to the problem of representing sequences of integers for both docids and frequencies. Representing such sequences of integers in compressed space is a fundamental problem, studied since the 1950s with applications going beyond inverted indexes. A classical solution is to compute the di erences of consecutive docids (deltas), and encode them with uniquelydecodable variable length binary codes; examples are unary codes, Elias Gamma/Delta codes, and Golomb/Rice codes [25]. More recent approaches encode simultaneously blocks of integers in order to improve both compression ratio and decoding speed. e underlying idea is to partition the sequence of integers into blocks of",null,null
46,"xed or variable length and to encode each block separately with di erent strategies (see e.g., [17, 22, 28] and references therein).",null,null
47,"More recently, the Elias-Fano representation of monotone sequences [11, 12] has been applied to inverted index compression [31], showing excellent query performance thanks to its e cient random",null,null
48,626,null,null
49,Session 5C: Efficiency and Scalability,null,null
50,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
51,"access and search operations. However, it fails to exploit the local clustering that inverted lists usually exhibit, namely the presence of long subsequences of close identi ers. Recently, O aviano and Venturini [23] described a new representation based on partitioning the list into chunks and encoding both the chunks and their endpoints with Elias-Fano, hence forming a two-level data structure.",null,null
52,"is partitioning enables the encoding to be er adapt to the local statistics of the chunk, thus exploiting clustering and improving compression. ey also showed how to minimize the space occupancy of this representation by se ing up the partitioning as an instance of an optimization problem, for which they present a linear time algorithm that is guaranteed to nd a solution at most (1 + ) times larger than the optimal one, for any given   (0, 1). In the following we will use a variation of their algorithm.",null,null
53,"ery Processing. In Boolean retrieval a query, expressed as a (multi-)set of terms, can be processed in conjunctive (AND) or",null,null
54,"disjunctive (OR) modes, retrieving the documents that contain respectively all the terms or at least one of them. Top-k ranked retrieval, instead, retrieves the k highest scored documents in the collection, where the relevance score is a function of the querydocument pair. Since it can be assumed that a document which",null,null
55,"does not contain any query term has score 0, ranked retrieval can",null,null
56,"be implemented by evaluating the query in disjunctive mode, and scoring the results. We call this algorithm RankedOR.",null,null
57,"In this work we focus on linear scoring functions, i.e., where the score of a query-document pair can be expressed as follows:",null,null
58,"s(q, d) ,",null,null
59,"wt st,d",null,null
60,t qd,null,null
61,"where the wt are query-dependent weights for each query term, and the st,d are scores for each term-document pair. Such scores are usually a monotonic function of the occurrences of the term in the document, which can be stored in the posting list alongside the docid (usually referred to as the term frequency).",null,null
62,"It can be easily seen that the widely used BM25 relevance score [24] can be cast in this framework. In BM25, the weights wt are derived from t's inverse document frequency (IDF) to distinguish between common (low value) and uncommon (high value) words, and the scores st,d are a smoothly saturated function of the term frequency. In all our experiments we will use BM25 as the scoring function.",null,null
63,"e classical query processing strategies to match documents to a query fall in two categories: in a term-at-a-time (TAAT) strategy, the posting lists of the query terms are processed one at a time, accumulating the score of each document in a separate data structure. In a document-at-a-time (DAAT) strategy, the query term postings lists are processed simultaneously keeping them aligned by docid. In DAAT processing the score of each document is fully computed considering the contributions of all query terms before moving to the next document, thus no auxiliary per-document data structures are necessary. We will focus on the DAAT strategy as it is is more amenable to dynamic pruning techniques.",null,null
64,"Solving scored ranked queries exhaustively with DAAT can be very ine cient. Various techniques to enhance retrieval e ciency have been proposed, by dynamically pruning docids that are unlikely to be retrieved. Among them, the most popular are MaxScore [30] and WAND [4]. Both strategies augment the index by",null,null
65,"storing for each term its maximum score contribution, thus allow-",null,null
66,ing to skip large segments of posting lists if they only contain terms,null,null
67,whose sum of maximum scores is smaller than the scores of the top k documents found up to that point.,null,null
68,"e alignment of the posting lists during MaxScore and WAND processing can be achieved by means of the NextGEQt (d) operator, which returns the smallest docid in the posting list t that is greater than or equal to d. is operator can signi cantly improve the posting list traversal speed during query processing, by skipping",null,null
69,"large amounts of irrelevant docids. e Elias-Fano compression scheme provides an e cient implementation of the NextGEQt (d) operator, which is crucial to obtain the typical subsecond response",null,null
70,times of Web search engines. Both MaxScore and WAND rely on upper-bounding the con-,null,null
71,"tribution that each term can give to the overall document score,",null,null
72,"allowing to skip whole ranges of docids [18]. However, both employ a global per-term upper bound, that is, the",null,null
73,"maximum score st,d among all documents d which contain the term t. Such maximum score could be signi cantly larger than the typical score contribution of that term, in fact limiting the opportunities",null,null
74,"to skip large amounts of documents. For example, a single outlier",null,null
75,for an otherwise low-score term can make it impossible to skip any,null,null
76,document that contains that term.,null,null
77,"To tackle this problem, Ding and Suel [10] propose to augment",null,null
78,the inverted index data structures with additional information to,null,null
79,store more accurate upper bounds: at indexing time each posting,null,null
80,"list is split into consecutive blocks of constant size, e.g., 128 postings",null,null
81,per block. For each block the score upper bound is computed and,null,null
82,"stored, together with largest docid of each block. ese local term upper bounds can then be exploited by adapting",null,null
83,"existing algorithms such as MaxScore and WAND to make use of the additional information. e rst of such algorithms is BlockMaxWAND (BMW) [10]. e authors report an average speedup of BMW against WAND of 2.78 ­ 3.04. Experiments in [9] report a speedup of 3.00 and 1.25 of BMW with respect to WAND and MaxScore, respectively. Several versions of Block-Max MaxScore (BMM), the MaxScore variant for block-max indexes, have been proposed in [7, 9, 26]. In [9], the authors implementation of BMM is 1.25 times slower than BMW on average.",null,null
84,3 VARIABLE BLOCK-MAX WAND,null,null
85,"As mentioned in the previous section, BMW leverages per-block upper bound information to skip whole blocks of docids during",null,null
86,query processing (we refer to the original paper [10] for a detailed,null,null
87,description of the algorithm). e performance of the algorithm,null,null
88,highly depends on the size of the blocks: if the blocks are too,null,null
89,"large, the likelihood of having at least one large value in each block",null,null
90,"increases, causing the upper bounds to be loose. If they are too",null,null
91,"small, the average skip will be short. In both cases, the pruning",null,null
92,e ectiveness may reduce signi cantly. A sweet spot can thus be,null,null
93,determined experimentally. e constant-sized block partitioning of BMW does not take,null,null
94,into consideration regularities or variances of the scores that may,null,null
95,occur in the posting lists and their blocks. e use of variable-sized,null,null
96,blocks allows to be er adapt to the distribution of the scores in the,null,null
97,posting list.,null,null
98,627,null,null
99,Session 5C: Efficiency and Scalability,null,null
100,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
101,8 4,null,null
102,7 7,null,null
103,2,null,null
104,2,null,null
105,2,null,null
106,2 1,null,null
107,3,null,null
108,"5 blocks, fixed size 3",null,null
109,"5 blocks, variable size",null,null
110,Figure 1: Block errors in constant (le ) and variable (right) block partitioning.,null,null
111,e improvement with this kind of partitioning is apparent from,null,null
112,the example in Figure 1. e gure shows a sequence of scores,null,null
113,"partitioned in constant-sized blocks and in variable-sized blocks. We de ne the error as the sum of the di erences between each value and its block's upper bound, the shaded area in the gure.",null,null
114,is example shows that a variable-sized partitioning can produce,null,null
115,"a much lower error, e.g., 28 in constant-sized partitioning (with",null,null
116,blocks of length 3) versus 10 in variable-sized partitioning.,null,null
117,"Problem de nition. To give a more formal de nition, for a partitioning of the sequence of scores in a posting list of n postings let B be the set of its blocks. Each block B  B is a sequence of consecutive postings in the posting list. We use b ,"" |B| and |B| to denote the number of blocks of the partition and the number of postings in B, respectively. e term-document scores are de ned above as st,d ; however, since in the following we will work on one posting list at a time, we can drop the t, so sd will denote the sequence of scores for each document d in the posting list.""",null,null
118,We de ne the error of a partitioning B as follows:,null,null
119,BB,null,null
120,|B|,null,null
121,max,null,null
122,d B,null,null
123,sd,null,null
124,-,null,null
125,d B,null,null
126,sd,null,null
127,.,null,null
128,(1),null,null
129,"Here for each block of postings we are accounting for the the sum of its individual posting errors, i.e., the sum of the di erences between the block maximum score and the score of the posting.",null,null
130,"To simplify the formula above we can notice that the right-hand side of the subtraction can be taken out of the sum, since the blocks form a partition of the list, and the resulting term does not depend on B. us, minimizing the error is equivalent to minimizing the following formula, which represents the perimeter of the envelope, for a given number of blocks b , |B|:",null,null
131,B,null,null
132,B,null,null
133,|B,null,null
134,|,null,null
135,max,null,null
136,d B,null,null
137,sd,null,null
138,.,null,null
139,(2),null,null
140,"Our goal is to nd a block partitioning that minimizes the sum of block errors among all blocks in the partitioning. Na¨ively, the minimum cost partitioning would correspond to blocks containing only a single posting. Since this solution clearly does not carry out any bene t, we x the number of blocks in the partition to be b. As we will show in Section 5 minimizing the error can signi cantly improve BMW performance over constant-sized blocks.",null,null
141,"Existing solutions. e problem of nding a partition that minimizes Equation (2) subject to a constraint b on the number of its blocks can be solved with a standard approach based on dynamic programming. e basic idea is to ll a b × n matrix M where entry M[i][j] stores the minimum error to partition the posting list up to position j with i blocks. is matrix can be lled top-down from le to right. e entry M[i][j] is computed by trying to place the jth posting in the optimal solutions that uses i - 1 blocks. Unfortunately, the time complexity of this solution is (bn2), which is (n3) since, given that the average block size n/b is small (e.g., 32­128), thus, the interesting values of b are (n). is algorithm is clearly unfeasible because n can easily be in the range of millions.",null,null
142,is optimization problem is similar in nature to the well-studied,null,null
143,problem of computing optimal histograms (see again Figure 1). e,null,null
144,complexity of nding the best histogram with a given number of,null,null
145,bars is the same as above. Several approximate solutions have,null,null
146,been presented. Halim et al. [16] describe several solutions and,null,null
147,introduce an algorithm that has good experimental performance,null,null
148,"but no theoretical guarantees. All such solutions are polynomial either in n or in b. Some have complexity O(nb). Guha et al. [15] introduce a (1 + ) approximation with O(n + b3 log n + b2/) time. While these techniques can be useful in cases where b is small, in our case b ,"" (n), which makes these algorithms unfeasible for us. Furthermore, the de nition of the objective function in these""",null,null
149,"works is di erent from ours, as it minimizes the variance rather",null,null
150,than the sum of the di erences.,null,null
151,Our solution. We rst present a practical and e cient algorithm,null,null
152,with weaker theoretical guarantees regarding the optimal solution,null,null
153,"than what would be expected. Indeed, xed the required number",null,null
154,"of blocks b and an approximation parameter , with 0 <  < 1,",null,null
155,the algorithm nds a partition with b  b blocks whose cost is,null,null
156,at most a factor 1 +  larger than the cost of the optimal partition,null,null
157,with b edges.,null,null
158,is algorithm runs in O(n log1+,null,null
159,1 ,null,null
160,"log(U n/b)) time,",null,null
161,where U is the largest cost of any block. e weakness is due to,null,null
162,the fact that there is no guarantee on how much b is close to the,null,null
163,"requested number of blocks b. Even with this theoretical gap, in all",null,null
164,our experiments the algorithm identi ed a solution with a number,null,null
165,"of blocks very close to the desired one. In the last part of the section,",null,null
166,we will ll this gap by showing how to re ne the solution to always identify a 1 +  approximated optimal solution with exactly b edges.,null,null
167,e rst solution is a variation of the approximate dynamic,null,null
168,programming algorithm introduced by O aviano and Venturini [23],null,null
169,to optimize the partitioning of Elias-Fano indexes.,null,null
170,It is convenient to look at the problem as a shortest path problem,null,null
171,over a directed acyclic graph (DAG). e nodes of the graph corre-,null,null
172,spond to the postings in the list; the edges connect each ordered,null,null
173,"pair i < j of nodes, and represent the possible blocks in the partition. e cost c(i, j) associated to the edge is thus (j - i) maxi d <j sd . In this graph, denoted as G, each path represents a possible",null,null
174,"partitioning, and the cost of the path is equal to the cost of the",null,null
175,"partitioning as de ned in (2). us, our problem reduces to an instance of constrained shortest path on this graph, that is, nding",null,null
176,"the shortest path with a given number of edges [13, 20].",null,null
177,We can compute the constrained shortest path with an approach,null,null
178,"similar to the one in [1, 13, 20]. e idea is to reduce the problem",null,null
179,"to a standard, unconstrained shortest path by using Lagrangian",null,null
180,628,null,null
181,Session 5C: Efficiency and Scalability,null,null
182,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
183,"relaxation: adding a xed cost   0 to every edge. We denote the relaxed graph as G . By varying , the shortest path in G will have a di erent number of edges: if  ,"" 0, the solution is the path of n - 1 edges of length one; at the limit  "","" +, the solution is a single edge of length n. It can be shown that, for any given , if the shortest path in G has edges, then that path is an optimal -constrained shortest path in G. us, our goal is to nd the value of  that give "","" b edges. However, notice that not every b can be""",null,null
184,"found this way, but in practice we can get close enough. us, our",null,null
185,"algorithm performs a binary search to nd the value of  that gives a shortest path with b edges, with b close enough to b. Each step",null,null
186,of the binary search requires a shortest-path computation.,null,null
187,"Each of these shortest-path computations can be solved in O(|V |+ |E|), where V are the vertices of G and E the edges; for our problem, unfortunately, this is (n2), which is still unfeasible. We can",null,null
188,however exploit two properties of our cost function to apply the,null,null
189,algorithm in [23] and obtain a linear-time approximate solution for,null,null
190,a given value of . ese properties are monotonicity and quasisubadditivity. e monotonicity property is stated as follows.,null,null
191,P,null,null
192,1. (Monotonicity) A function f : V × V  R is said,null,null
193,"monotone if for each pair of values i, j  V the following holds:",null,null
194,"· f (i, j + 1)  f (i, j), · f (i - 1, j)  f (i, j).",null,null
195,"It is easy to verify that our cost function c(i, j) satis es Property 1, because if a block B is contained in a block B , then it follows immediately from the de nition that the cost of B is greater than the cost of B. Monotonicity allows us to perform a rst pruning of G: for any given approximation parameter   (0, 1], we de ne G1 as the graph with the same nodes as G , and all the edges (i, j) of G that satisfy at least one of the following conditions.",null,null
196,(1) ere exists an integer h such that,null,null
197,"c(i, j)  (1 + )h < c(i, j + 1)",null,null
198,"(2) (i, j) is the last outgoing edge from i.",null,null
199,e,null,null
200,number,null,null
201,of,null,null
202,edges,null,null
203,in G1,null,null
204,is,null,null
205,n,null,null
206,log1+,null,null
207,(,null,null
208,U ,null,null
209,),null,null
210,where U,null,null
211,is,null,null
212,the,null,null
213,maxi-,null,null
214,mum cost of an edge (which is equal to n maxd sd ).,null,null
215,We denote as G the shortest path of the graph G and ex-,null,null
216,tend,null,null
217,c,null,null
218,to,null,null
219,denote,null,null
220,the,null,null
221,cost,null,null
222,of,null,null
223,a,null,null
224,path.,null,null
225,It,null,null
226,can,null,null
227,be,null,null
228,shown,null,null
229,that,null,null
230,c,null,null
231,(G,null,null
232,1 ,null,null
233,),null,null
234,"(1 +  )c(G ), that is, the optimal solution in G1 is a (1 +  ) approximation of the optimal solution in G; see [14] for the proof.",null,null
235,e complexity to nd the shortest path decreases from O(n2) to,null,null
236,O (n,null,null
237,log1+,null,null
238,(,null,null
239,U ,null,null
240,)).,null,null
241,is would be already applicable in many practical,null,null
242,"scenarios, but it depends on the value U of the maximum score. We",null,null
243,can further re ne the algorithm in order to decrease the complexity,null,null
244,"and drop the dependency on U by adding an extra approximation function (1 + ) for any given approximation parameter   (0, 1],",null,null
245,by leveraging the quasi-subadditivity property.,null,null
246,P,null,null
247,2. ( asi-subadditivity) A function f : V × V  R is,null,null
248,"said -quasi-subadditive if for any i, k and j  V , with 0  i < l <",null,null
249,j < |V | the following holds:,null,null
250,"f (i, k) + f (k, j)  f (i, j) + .",null,null
251,"It is again immediate to show that c(i, j) satis es Property 2: spli ing a block at any point can only lower the upper bound in",null,null
252,"the two resulting sub-blocks, so the only extra cost is the additional",null,null
253, of the new edge.,null,null
254,is property allows us to prune from G1 all the edges with cost,null,null
255,higher,null,null
256,than,null,null
257,L,null,null
258,",",null,null
259,+,null,null
260,2 ,null,null
261,;,null,null
262,we,null,null
263,call,null,null
264,the,null,null
265,resulting,null,null
266,graph,null,null
267,G2 .,null,null
268,e new,null,null
269,graph has O(n log1+,null,null
270,1 ,null,null
271,),null,null
272,",",null,null
273,(n),null,null
274,"edges,",null,null
275,thus,null,null
276,shortest,null,null
277,paths,null,null
278,can,null,null
279,be,null,null
280,computed in linear time. It can be shown (see [23]) that this pruning,null,null
281,incurs an extra (1 + ) approximation; the overall approximation,null,null
282,"factor is thus (1 + )(1 + ), which is 1 +  for any   (0, 1] by appropriately xing  ,  ,  .",null,null
283,3,null,null
284,"Clearly it is not feasible to materialize the graph G and prune it to obtain G2 , since the dominating cost would still be the initial quadratic phase. It is however possible to visit the graph G2 without",null,null
285,"constructing it explicitly, as described in [23].",null,null
286,"By using the above algorithm, every shortest path computation",null,null
287,requires O(n log1+,null,null
288,1 ,null,null
289,),null,null
290,", (n) time and linear space.",null,null
291,"Since we are binary searching on , the number of required",null,null
292,shortest path computations depends on the range of possible values,null,null
293,"of . It is easy to see that   0. Indeed, the shortest path in G0 has the largest possible number of edges, n - 1 and the smallest possible cost. We now prove that the shortest path in G with  > U n/(b -1) has less than b edges, where U is the largest cost on G. us, in",null,null
294,the binary search we can restrict our a ention to integer values of,null,null
295," in [0, U n/(b - 1)]. e proof is as follows. Consider the optimal path with one edge in G, and let O1 be its cost. By monotonicity, we know that O1 ,"" U . Let Ob be the cost of the best path with b edges in G. For any , the cost of these two paths in G are O1 +  and Ob + b. Observe that if  > U n/b, the former path has a cost""",null,null
296,which is smaller than the cost of the la er. is means that we do,null,null
297,"not need to explore values of  larger than U n/(b - 1) when we are looking for a path with b edges. us, the rst phase of the algorithm needs O(log(U n/b)) shortest path computations to nd the target value of . us, if we restrict our search to integer values of , the number of shortest path computations is O(log(U n/b)).",null,null
298,We can re ne the above solution to nd a provable good approximation of the shortest path with exactly b edges. e re nement,null,null
299,"uses the result in [13]. eorem 4.1 in [13] states that, given a DAG G with integer costs which satisfy the monotonicity property, we",null,null
300,can compute an additive approximation of the constrained shortest,null,null
301,"path of G. More precisely, we can compute a path with b edges such that its cost is at most Ob + U , where Ob is the cost of an optimal path with b edges and U is the largest cost on G. e algorithms",null,null
302,"works in two phases. In the rst phase, it reduces the problem",null,null
303,"to a standard, unconstrained shortest path by using Lagrangian",null,null
304,"relaxation as we have done in our rst solution. us, the rst",null,null
305,"phase binary searches for the value of  for which the shortest path on G with the least number of edges has at most b edges, while the one with the most edges has at least b edges. If one of these two paths has exactly b edges, this is guaranteed to be an optimal",null,null
306,"solution and we are done. Otherwise, we start the second phase",null,null
307,of the algorithm. e second phase is called path-swapping and its goal is to combine these two paths to nd a path with b edges,null,null
308,"whose cost is worse than the optimal one by at most an additive term A, which equals the largest cost in the graph. We refer to [1]",null,null
309,and [13] for more details.,null,null
310,629,null,null
311,Session 5C: Efficiency and Scalability,null,null
312,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
313,We cannot immediately apply the above optimization algorithm,null,null
314,because of two important issues. In the following we will introduce,null,null
315,and solve both of them.,null,null
316,"e rst issue is that the above optimization algorithm assumes that the costs in G are integers, while in our case are not. e",null,null
317,idea is to obtain a new graph with integer costs by rescaling and,null,null
318,"rounding the original costs of G. More precisely, we can obtain a new graph by replacing any cost c(i, j) with c(i, j)/ , where   (0, 1] is an approximation parameter. We can prove that this",null,null
319,"operation slightly a ects the cost of the optimal path. Indeed, let",null,null
320,"Ob the cost of the shortest path with b edges in G, the shortest path on the new graph as cost O~b which is Ob  O~b  Ob + b. Due to space limitations, we defer the proof of this inequality to",null,null
321,the journal version of the paper. Even if in general we cannot,null,null
322,"bound the additive approximation b in terms of Ob , in practice",null,null
323,the approximation is negligible because Ob is much larger that b.,null,null
324,Notice,null,null
325,that,null,null
326,this,null,null
327,approximation,null,null
328,increases U,null,null
329,to,null,null
330,U ,null,null
331,.,null,null
332,e second issue to address is the fact that additive approxima-,null,null
333,tion term A in the result of [13] is the largest edge cost U . In our,null,null
334,"problem this additive approximation term is the cost of the edge from 1 to n, which equals the cost of the worst possible path. is",null,null
335,"means that the obtained approximation would be trivial. However,",null,null
336,"we observe that, due to the approach of the previous paragraph,",null,null
337,the,null,null
338,largest,null,null
339,cost,null,null
340,on,null,null
341,the,null,null
342,approximated,null,null
343,graph,null,null
344,G,null,null
345,2 ,null,null
346,is,null,null
347,L,null,null
348,",",null,null
349,+,null,null
350,2 ,null,null
351,and,null,null
352,"we know that   U n/b. us, the additive approximation term A",null,null
353,is,null,null
354,O(,null,null
355,Un b,null,null
356,"),",null,null
357,which,null,null
358,is,null,null
359,negligible,null,null
360,in,null,null
361,practice.,null,null
362,"us, we obtained the following theorem.",null,null
363,T,null,null
364,"3.1. Given a sequence of scores S[1, n] and a xed num-",null,null
365,"ber of blocks b, we can compute a partition of S into b blocks whose",null,null
366,cost,null,null
367,is,null,null
368,at,null,null
369,most,null,null
370,(1+,null,null
371,)Ob,null,null
372,+O,null,null
373,(,null,null
374,Un b,null,null
375,),null,null
376,+b,null,null
377,in,null,null
378,O,null,null
379,(n,null,null
380,log1+,null,null
381,1 ,null,null
382,log(,null,null
383,Un b,null,null
384,)),null,null
385,time,null,null
386,"and linear space, where Ob is the cost of the optimal partition with",null,null
387,"b blocks, U ,",null,null
388,"n i ,1",null,null
389,S,null,null
390,[i,null,null
391,"],",null,null
392,"and , ",null,null
393,"(0, 1]",null,null
394,are,null,null
395,the,null,null
396,two,null,null
397,approximation,null,null
398,parameters.,null,null
399,4 REPRESENTING THE UPPER BOUNDS,null,null
400,"BlockMaxWAND is required to store additional information about the block upper bounds. is additional information must be stored together with the traditional inverted index data structures, and while these upper bounds can improve the time e ciency of query processing, they introduce a serious space overhead problem.",null,null
401,"e additional information required by BlockMaxWAND can be seen as two aligned sequences: the sequence of block boundaries, that is, the largest docid in each block, and the score upper bound for each block.",null,null
402,"In the original implementation, the sequences are stored uncompressed, using constant-width encodings (for example, 32-bit integers for the boundaries and 32-bit oats for the upper bounds), and are usually interleaved to favor cache locality. We can however use more e cient encodings to reduce the space overhead.",null,null
403,"First, we observe that the sequence of block boundaries is monotonic, so it can be e ciently represented with Elias-Fano. In addition to saving space, Elias-Fano provides an e cient NextGEQ operation that can be used to quickly locate the block containing the current docid at query execution time.",null,null
404,"Second, as far as the upper bounds are concerned, we can reduce space use by approximating their value. e only requirement to",null,null
405,preserve the correctness of the algorithm is that each approximate,null,null
406,"value is an upper bound for all the scores in its block. us, we",null,null
407,"can use the following quantization. First, we partition the score",null,null
408,space into xed size buckets. Any score is represented with the,null,null
409,"identi er of its bucket. Let us assume that the score space is [0, U ]",null,null
410,"and that we partition it into w buckets. en, instead of storing a",null,null
411,"block upper bound with value s  [0, U ], we store the identi er i",null,null
412,such,null,null
413,that,null,null
414,iU w,null,null
415,<s ,null,null
416,(i +1)U w,null,null
417,.,null,null
418,At,null,null
419,query,null,null
420,"time,",null,null
421,the,null,null
422,actual,null,null
423,score,null,null
424,s,null,null
425,will,null,null
426,"be approximated with the largest possible value in its bucket, i.e.,",null,null
427,(i +1)U,null,null
428,"w . Clearly, the representation of any score requires",null,null
429,log w + 1,null,null
430,"bits, a large space saving with respect to the 32 bits of the oat",null,null
431,"representation. Obviously, the value of w can be chosen to trade",null,null
432,o the space usage and the quality of the approximation.,null,null
433,A simple optimization to speed up access is to interleave the two,null,null
434,"sequences, by modifying of the Elias-Fano data structure. EliasFano stores a monotonic sequence by spli ing each value into its low bits, and the remaining high bits. e value of a constant for",null,null
435,"the sequence. While the high bits are encoded with variable-length,",null,null
436,"the low bits are encoded verbatim in exactly bits per element, thus the low bits of the i-th element are at the position i of the low",null,null
437,"bitvector. We can then interleave the low bits and the quantized score by using a bitvector of ( + w)-bit entries, so that when the",null,null
438,"block is located, its quantized upper bound is already in cache.",null,null
439,5 EXPERIMENTAL RESULTS,null,null
440,"In this section we analyze the performance of VBMW with an extensive experimental evaluation in a realistic and reproducible se ing, using state-of-the-art baselines, standard benchmark text collections, and a large query log.",null,null
441,Testing details. All the algorithms are implemented in C++11 and compiled with GCC 5.4.0 with the highest optimization se ings.,null,null
442,"e tests are performed on a machine with 8 Intel Core i7-4770K Haswell cores clocked at 3.50GHz, with 32GiB RAM, running Linux 4.4.0. e indexes are saved to disk a er construction, and memorymapped to be queried, so that there are no hidden space costs due to loading of additional data structures in memory. Before timing the queries we ensure that the required posting lists are fully loaded in memory. All timings are measured taking the results with minimum value of ve independent runs. All times are reported in milliseconds.",null,null
443,e source code is available at h ps://github.com/rossanoventurini/ Variable-BMW for the reader interested in further implementation details or in replicating the experiments.,null,null
444,Datasets. We performed our experiments on the following standard datasets.,null,null
445,"· ClueWeb09 is the ClueWeb 2009 TREC Category B collection, consisting of 50 million English web pages crawled between January and February 2009.",null,null
446,"· Gov2 is the TREC 2004 Terabyte Track test collection, consisting of 25 million .gov sites crawled in early 2004; the documents are truncated to 256 kB.",null,null
447,"For each document in the collection the body text was extracted using Apache Tika1, the words lowercased and stemmed using the",null,null
448,1h p://tika.apache.org,null,null
449,630,null,null
450,Session 5C: Efficiency and Scalability,null,null
451,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
452,Table 1: Basic statistics for the test collections,null,null
453,Documents Terms Postings,null,null
454,ClueWeb09,null,null
455,"50,131,015 92,094,694 15,857,983,641",null,null
456,Gov2,null,null
457,"24,622,347 35,636,425 5,742,630,292",null,null
458,Porter2 stemmer; no stopwords were removed. e docids were,null,null
459,assigned according to the lexicographic order of their URLs [27].,null,null
460,Table 1 reports the basic statistics for the two collections. If not,null,null
461,"di erently speci ed, the inverted index is compressed by using partitioned Elias-Fano (PEF) [23] in the ds2i library2.",null,null
462,"eries. To evaluate the speed of query processing we use Trec05 and Trec06 E ciency Track topics, drawing only queries whose terms are all in the collection dictionary and having more than 128",null,null
463,"postings. ese queries are, respectively, the 90% and 96% of the total Trec05 and Trec06 queries for the Gov2 collection and the 96% and 98% of the total Trec05 and Trec06 queries for the ClueWeb09 collection. From those sets of queries we randomly select 1 000",null,null
464,queries for each length.,null,null
465,"Processing strategies. To test the performance on query strategies that make use of the docids and the occurrence frequencies we perform BM25 top 10 queries using 5 di erent algorithms: RankedOR, which scores the results of a disjunctive query, WAND [4], MaxScore [30], BlockMaxWAND (BMW) [10], and the proposed Variable BMW (VBMW) in its uncompressed and compressed variants.",null,null
466,"We use BMWx to indicate that the xed block size in BMW is x postings, while we use VBMWx to indicate that the average block size in VBMW is x postings. e compressed version of VBMW as described in Section 4 is denoted as C-VBMWx.",null,null
467,Validating our BMW implementation. We implemented our version of BMW because the source code of the original implementation was not available. To test the validity of our implementation we,null,null
468,"compared its average query time with the ones reported in [10]. We replicated their original se ing by using the same dataset (Gov2), by compressing postings with the same algorithm (PForDelta), by using queries from the same collections (Trec05 and Trec06), and by using BMW64. However, since we are using a di erent faster machine, we cannot directly compare query times, but, instead, we compare the improving factors with respect to RankedOR, which is an easy-to-implement baseline.",null,null
469,Table 2 shows the query times reported in the original paper,null,null
470,(top) and the ones obtained with our implementation (bo om).,null,null
471,"Results show that the two implementations are comparable, with",null,null
472,"ours which is generally faster. For example, it is faster by a factor larger than 2.4 on queries with more than three terms in Trec06.",null,null
473,"e e ect of the block size in BMW. Although the most commonly used block sizes for BMW are 64 and 128, a more careful experimental evaluation shows that the best performance in terms of",null,null
474,query time is obtained with a block size of 40 postings. Table 3 shows the average query time of BMW with respect to,null,null
475,"Trec05 and Trec06 on both Gov2 and ClueWeb09, by varying the",null,null
476,2h ps://github.com/ot/ds2i,null,null
477,"Table 2: ery times (in ms) of RankedOR and BMW64 on Gov2 with queries in Trec05 and Trec06 as reported by Ding and Suel [10] (top) and the ones obtained with our implementation (bottom), for di erent query lengths.",null,null
478,Number of query terms,null,null
479,2,null,null
480,3,null,null
481,4,null,null
482,5,null,null
483,6+,null,null
484,Trec05 (from [10]),null,null
485,"RankedOR 62.1 (x17.7) 238.9 (x18.8) 515.2 (x20.4) 778.3 (x25.9) 1,501.4 (x14.4)",null,null
486,BMW64 3.5,null,null
487,12.7,null,null
488,25.2,null,null
489,30.0,null,null
490,104.0,null,null
491,Trec06 (from [10]),null,null
492,RankedOR 60.0 (x14.7) 159.2 (x13.8) 261.4 (x7.8) 376.0 (x6.9),null,null
493,BMW64 4.1,null,null
494,11.5,null,null
495,33.6,null,null
496,54.5,null,null
497,Trec05,null,null
498,646.4 (x5.7) 114.2,null,null
499,RankedOR 15.5 (x13.2) 51.3 (x17.3) 100.3 (x22.6) 158.0 (x22.7),null,null
500,BMW64 1.2,null,null
501,3.0,null,null
502,4.5,null,null
503,7.0,null,null
504,Trec06,null,null
505,275.1 (x17.3) 15.9,null,null
506,RankedOR 15.5 (x14.7) 57.6 (x16.9) 117.6 (x19.7) 178.0 (x18.5) 311.2 (x13.8),null,null
507,BMW64 1.1,null,null
508,3.4,null,null
509,6.0,null,null
510,9.6,null,null
511,22.5,null,null
512,"block size. We select the block size in the set {32, 40, 48, 64, 96, 128}. It is clear that in all cases, the best average query time is achieved with blocks size 40. BMW40 is 10% faster, on average, than BMW128.",null,null
513,"Table 3 also reports the space usage of the (uncompressed) additional information stored by BMW, namely the largest score in the block (as oat) and the last posting in the block (as unsigned",null,null
514,int). Posting lists with fewer postings than the block size do not,null,null
515,"store any additional information. e size of the inverted index of the Gov2 and ClueWeb09 collections (compressed with PEF) is 4.32 GiB and 14.84 GiB respectively. us, the space of the additional information required by BMW is not negligible, since it ranges between 15% and 42% of the compressed inverted index space on both Gov2 and ClueWeb09. As we will see later, this space usage can be reduced signi cantly by compressing the additional information.",null,null
516,"e e ect of the block size in VBMW. Now, we proceed by analyzing the behavior of VBMW. Instead of adopting the more sophisticated approximation approach detailed in Section 3, we use",null,null
517,the simpler optimization algorithm which has no theoretical guar-,null,null
518,"antees on the nal number of blocks. us, we cannot choose an exact block size for our partitioning but we binary search for the  in the parameter space that gives an average block size close to the values in {32, 40, 48, 64, 96, 128}.",null,null
519,"Table 4 reports the average block sizes and score errors for different block sizes w.r.t. BMW and VBMW on Gov2 and ClueWeb09, and optimal values for the Lagrangian relaxation parameter . Note that for BMW, the average block size is not perfectly identical to the desired block size due to the length of the last block in the",null,null
520,"posting lists, which may be smaller than the desired block size.",null,null
521,"Our optimization algorithm is able to nd an average block size for VBMW within 3% of the average block size for BMW. us, the weaker optimization algorithm of Section 3 su ces in practice",null,null
522,"to obtain the desired average block sizes. More importantly, the",null,null
523,631,null,null
524,Session 5C: Efficiency and Scalability,null,null
525,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
526,"Table 3: Space usage of the additional data required by BMW and average query times with queries in Trec05 and Trec06 on Gov2 and ClueWeb09, by varying the block size.",null,null
527,"Table 5: Average query times of VBMW with queries in Trec05 and Trec06 on Gov2 and ClueWeb09, by varying the block size.",null,null
528,Block size 32 40 48 64 96 128,null,null
529,Additional space (GiB),null,null
530,Gov2,null,null
531,1.83 1.55 1.38 1.15 0.92 0.85,null,null
532,ClueWeb09 5.04 4.14 3.62 3.04 2.40 2.24,null,null
533,ery time (ms) on Trec05,null,null
534,Gov2,null,null
535,3.6 3.6 3.7 3.8 3.9 4.2,null,null
536,ClueWeb09 12.8 12.6 12.6 12.8 13.3 13.9,null,null
537,ery time (ms) on Trec06,null,null
538,Gov2,null,null
539,8.3 8.2 8.3 8.5 8.9 9.2,null,null
540,ClueWeb09 26.4 26.3 26.5 27.0 28.0 29.4,null,null
541,"Table 4: Average block sizes and score errors for di erent block sizes w.r.t. BMW and VBMW on Gov2 and ClueWeb09, and optimal values for the Lagrangian relaxation parameter.",null,null
542,Block Size,null,null
543,32 40 48 64 96 128,null,null
544,Gov2,null,null
545,Average Block Size,null,null
546,BMW 31.94 39.90 47.87 63.74 95.35 127.14 VBMW 31.32 39.63 47.09 63.60 98.40 126.30,null,null
547,Average Score Error,null,null
548,BMW VBMW,null,null
549,1.47 0.82,null,null
550,1.55 0.91,null,null
551,1.61 0.98,null,null
552,1.70 1.09,null,null
553,1.83 1.26,null,null
554,1.92 1.35,null,null
555,VBMW 12.0 15.2 18.0 24.0 35.1 45.9,null,null
556,ClueWeb09,null,null
557,Average Block Size,null,null
558,BMW 31.96 39.94 47.91 63.83 95.65 127.29 VBMW 30.24 39.54 48.03 63.29 97.43 127.72,null,null
559,Average Score Error,null,null
560,BMW VBMW,null,null
561,1.94 1.20,null,null
562,2.05 1.34,null,null
563,2.15 1.45,null,null
564,2.29 1.60,null,null
565,2.49 1.83,null,null
566,2.63 1.98,null,null
567,VBMW 16.0 21.0 25.5 33.4 50.3 64.5,null,null
568,"average score error for VBMW is sensibly smaller than the average score error for BMW, with a reduction ranging from 40% for small blocks up to 25% for large blocks. is con rms the importance of",null,null
569,partitioning the posting lists with variable-sized blocks. In Table 5 we can see that VBMW reaches the best average query,null,null
570,"times with approximatively 32 - 40 elements per block, similar to the best block size for BMW reported in Table 3, i.e., 40 postings per block. As shown in Figure 2, the trade-o in choosing this block",null,null
571,size w.r.t. average query time is that we use more space to store,null,null
572,"block information, as reported in Table 3.",null,null
573,e e ect of compression in VBMW. Figure 2 shows how the choice of w a ects both query time and space usage of C-VBMW when the average number of blocks is xed to 40 elements. We,null,null
574,xed the number of buckets w to quantize the scores to the powers,null,null
575,Block size 32 40 48 64 96 128,null,null
576,ery time (ms) on Trec05,null,null
577,Gov2,null,null
578,2.1 2.1 2.1 2.2 2.5 2.8,null,null
579,ClueWeb09 7.2 7.2 7.4 8.1 9.7 11.0,null,null
580,ery time (ms) on Trec06,null,null
581,Gov2,null,null
582,4.6 4.7 4.8 5.3 6.1 6.9,null,null
583,ClueWeb09 14.7 15.2 16.1 17.8 21.2 23.7,null,null
584,of two from 32 to 512 and we reported the query time and the,null,null
585,space of the additional information on both datasets with both set,null,null
586,"of queries. For comparison, we also plot the results of the plain version of VBMW by varying the average size of the blocks.",null,null
587,"e rst conclusion is that the compression approach is very effective. Indeed, C-VBMW improves space usage by roughly a factor 2 with respect to VBMW40. We also notice that the compression approach is more e ective than simply increasing the block size in the uncompressed VBMW. Indeed, for example, C-VBMW with w , 32 uses almost the same space as VBMW128 but is faster by 20% - 40%.",null,null
588,e second conclusion is that compression does not decrease,null,null
589,"query time which actually sometimes even improves. For example, C-VBMW with w , 512 and w , 256 is faster that its uncompressed version (VBMW40) on both datasets with Trec05. is e ect may be the results to a be er cache usage resulting from the smaller size of additional information in C-VBMW.",null,null
590,"We observe that there are small di erences (less than 10%) in e ciency between the di erent values of w. us, for the next experiments we will x w to 512 to obtain the best time e ciency.",null,null
591,"Overall comparison. To carefully evaluate the performance of C-VBMW w.r.t. other processing strategies, we measured the query times of di erent query processing algorithms for di erent query",null,null
592,"lengths, from 2 terms queries to more than 5 terms queries, as well",null,null
593,as the overall average processing times and the space use of any,null,null
594,required additional data structure with respect the whole inverted indexes represented with PEF.,null,null
595,"In Table 6, next to each timing is reported in parenthesis the relative speedup of C-VBMW40 with respect to this strategy. Table 6 also reports, in GiB, the additional space usage required by the di erent query processing strategies. Next to each size mea-",null,null
596,sure is reported in parenthesis the relative percentage against the,null,null
597,"data structures used to compress posting lists storing docids and frequencies only, as used by RankedOR.",null,null
598,"Not very surprisingly, RankedOR is always at least 34 times slower than C-VBMW40, while both MaxScore and WAND are from 1.4 to 11 times slower than C-VBMW40. e maximum speedup of C-VBMW40 is achieved with queries of two terms where it ranges from 6.5 to 11. Space usage of MaxScore and WAND plainly store the score upper bounds for each term using the 4% - 5% of the inverted index.",null,null
599,632,null,null
600,Session 5C: Efficiency and Scalability,null,null
601,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
602,Figure 2: Space consumed vs. average query times of VBMW with di erent block sizes and C-VBMW with block size 40 by varying w for 32 to 512 with queries in Trec05 and Trec06 on Gov2 and ClueWeb09.,null,null
603,All block-based strategies report a minimal variance of query,null,null
604,times among di erent query lengths. For both the most common,null,null
605,"block size (128 postings per block) and the most e cient one (40 postings per block), VBMW strategies process queries faster than BMW strategies, with the same space occupancies. e corresponding compressed versions, C-VBMW128 and C-VBMW40, sensibly reduce the space occupancies (by 6% and 17% respectively) but while C-VBMW128 never processes queries faster than the corresponding uncompressed VBMW128, C-VBMW40 does not show relevant performance losses with respect to VBMW128, but exhibits some cache-dependent bene ts for short queries.",null,null
606,"With respect to the current state-of-the-art processing strategy BMW128, our best strategy in terms of query times is C-VBMW40, able to improve the average query time by a factor of roughly 2×, e ectively halving the query processing times for all query lengths, with a relative 3% - 5% gain in space occupancy. If space occupancy is the main concern, our best strategy is C-VBMW128, able to reduce the space by a relative 30% against BMW128, while still boosting the query times by a factor of roughly 1.5×.",null,null
607,6 CONCLUSIONS,null,null
608,"We introduced Variable BMW, a new query processing strategy built on top of BlockMaxWAND. Our strategy uses variable-sized blocks, rather than constant-sized. We formulated the problem of",null,null
609,partitioning the posting lists of a inverted index into variable-sized,null,null
610,"blocks to minimize the average block error, subject to a constraint",null,null
611,"on the number of blocks, and described an e cient algorithm to nd",null,null
612,"an approximate solution, with provable approximation guarantees.",null,null
613,"We also introduced a compressed data structure to represent the additional block information. Variable BMW signi cantly improves the query processing times, by a factor of roughly 2× w.r.t. the best state-of-the-art competitor. Our new compression scheme for the",null,null
614,"block data structures, compressing the block boundary docids with",null,null
615,"Elias-Fano and quantizing the block max score, provides a maximum",null,null
616,reduction of space usage w.r.t. the uncompressed data structures of,null,null
617,"roughly 50%, while incurring only a small speed degradation, no",null,null
618,more than 10% with respect to its uncompressed counterpart.,null,null
619,Future work will focus on exploring the di erent space-time,null,null
620,trade-o s that can be obtained by varying the quantization scheme,null,null
621,exploited in the compression of the additional data structures.,null,null
622,ACKNOWLEDGMENTS,null,null
623,is work was partially supported by the EU H2020 Program under,null,null
624,"the scheme INFRAIA-1-2014-2015: Research Infrastructures, grant agreement #654024 SoBigData: Social Mining & Big Data Ecosystem.",null,null
625,REFERENCES,null,null
626,"[1] Alok Aggarwal, Baruch Schieber, and Takeshi Tokuyama. 1994. Finding a",null,null
627,"Minimum-Weight k-Link Path Graphs with the Concae Monge Property and Applications. Discrete & Computational Geometry 12 (1994), 263­280. [2] Vo Ngoc Anh, Owen de Kretser, and Alistair Mo at. 2001. Vector-space ranking with e ective early termination. In SIGIR. 35­42. [3] Nima Asadi and Jimmy Lin. 2013. E ectiveness/E ciency Tradeo s for Candidate Generation in Multi-stage Retrieval Architectures. In SIGIR. 997­1000. [4] Andrei Z. Broder, David Carmel, Michael Herscovici, Aya So er, and Jason Y.",null,null
628,"Zien. 2003. E cient query evaluation using a two-level retrieval process. In CIKM. 426­434. [5] Stefan Bu¨ cher, Charles L.A. Clarke, and Gordon V. Cormack. 2010. Information retrieval: implementing and evaluating search engines. MIT Press. [6] Stefan Bu¨ cher and Charles L. A. Clarke. 2007. Index compression is good, especially for random access. In CIKM. 761­770. [7] Kaushik Chakrabarti, Surajit Chaudhuri, and Venkatesh Ganti. 2011. Intervalbased Pruning for Top-k Processing over Compressed Lists. In ICDE. 709­720. [8] Je rey Dean. 2009. Challenges in building large-scale information retrieval systems: invited talk. In WSDM. [9] Constantinos Dimopoulos, Sergey Nepomnyachiy, and Torsten Suel. 2013. Optimizing Top-k Document Retrieval Strategies for Block-max Indexes. In WSDM. 113­122.",null,null
629,[10] Shuai Ding and Torsten Suel. 2011. Faster top-k document retrieval using blockmax indexes. In SIGIR. 993­1002.,null,null
630,"[11] Peter Elias. 1974. E cient Storage and Retrieval by Content and Address of Static Files. J. ACM 21, 2 (1974), 246­260.",null,null
631,"[12] Robert M. Fano. 1971. On the number of bits required to implement an associative memory. Memorandum 61, Computer Structures Group, MIT, Cambridge, MA (1971).",null,null
632,"[13] Andrea Farruggia, Paolo Ferragina, Antonio Frangioni, and Rossano Venturini. 2014. Bicriteria data compression. In SODA. 1582­1595.",null,null
633,"[14] Paolo Ferragina, Igor Ni o, and Rossano Venturini. 2011. On Optimally Partitioning a Text to Improve Its Compression. Algorithmica 61, 1 (2011), 51­74.",null,null
634,"[15] Sudipto Guha, Nick Koudas, and Kyuseok Shim. 2006. Approximation and Streaming Algorithms for Histogram Construction Problems. ACM Trans. Database Syst. 31, 1 (2006), 396­438.",null,null
635,"[16] Felix Halim, Panagiotis Karras, and Roland H.C. Yap. 2009. Fast and E ective Histogram Construction. In CIKM. 1167­1176.",null,null
636,"[17] Daniel Lemire and Leonid Boytsov. 2015. Decoding Billions of Integers Per Second rough Vectorization. So w. Pract. Exper. 45, 1 (2015), 1­29.",null,null
637,"[18] Craig Macdonald, Iadh Ounis, and Nicola Tonello o. 2011. Upper-bound approximations for dynamic pruning. ACM Trans. Inf. Syst. 29, 4 (2011), 17.",null,null
638,"[19] Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schu¨lze. 2008. Introduction to Information Retrieval. Cambridge University Press.",null,null
639,[20] Kurt Mehlhorn and Mark Ziegelmann. 2000. Resource Constrained Shortest Paths. In ESA. 326­337.,null,null
640,"[21] Alistair Mo at, William Webber, Justin Zobel, and Ricardo Baeza-Yates. 2007. A pipelined architecture for distributed text query evaluation. Inf. Retr. 10, 3 (2007), 205­231.",null,null
641,"[22] Giuseppe O aviano, Nicola Tonello o, and Rossano Venturini. 2015. Optimal Space-time Tradeo s for Inverted Indexes. In WSDM. 47­56.",null,null
642,[23] Giuseppe O aviano and Rossano Venturini. 2014. Partitioned Elias-Fano Indexes. In SIGIR. 273­282.,null,null
643,633,null,null
644,Session 5C: Efficiency and Scalability,null,null
645,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
646,"Table 6: ery times (in ms) of di erent query processing strategies for di erent query lengths, average query times (Avg, in ms) and additional space (Space, in GiB) w.r.t. Trec05 and Trec06 on Gov2 and ClueWeb09.",null,null
647,Number of query terms,null,null
648,Avg Space,null,null
649,2,null,null
650,3,null,null
651,4,null,null
652,5,null,null
653,6+,null,null
654,Gov2 Trec05,null,null
655,RankedOR 23.6 (x32.89),null,null
656,WAND,null,null
657,5.1 (x7.11),null,null
658,MaxScore,null,null
659,4.7 (x6.61),null,null
660,BMW40 VBMW40 C-VBMW40 BMW128 VBMW128 C-VBMW128,null,null
661,1.2 (x1.62) 0.8 (x1.10) 0.7 1.4 (x1.99) 1.0 (x1.42) 1.1 (x1.53),null,null
662,76.5 (x44.39) 147.9 (x59.74) 235.4 (x60.47),null,null
663,5.9 (x3.43) 7.0 (x2.82) 8.8 (x2.27),null,null
664,6.0 (x3.45) 7.1 (x2.86) 9.2 (x2.37),null,null
665,2.9 (x1.65) 4.3 (x1.72) 6.7 (x1.72),null,null
666,1.7 (x1.01) 2.4 (x0.97) 3.8 (x0.97),null,null
667,1.7,null,null
668,2.5,null,null
669,3.9,null,null
670,3.5 (x2.01) 4.8 (x1.93) 7.2 (x1.85),null,null
671,2.4 (x1.40) 3.2 (x1.30) 4.9 (x1.26),null,null
672,2.5 (x1.47) 3.4 (x1.37) 5.1 (x1.32),null,null
673,Gov2 Trec06,null,null
674,418.7 (x50.18) 106.7 (x50.88) 0.00,null,null
675,17.8 (x2.13) 7.0 (x3.36) 0.22 (5%),null,null
676,14.2 (x1.70) 6.6 (x3.14) 0.22 (5%),null,null
677,14.8 (x1.78),null,null
678,3.6,null,null
679,1.55 (x1.74),null,null
680,(36%),null,null
681,8.1 (x0.97),null,null
682,2.1,null,null
683,1.55 (x1.00),null,null
684,(36%),null,null
685,8.3,null,null
686,2.1,null,null
687,0.82 (19%),null,null
688,15.9 (x1.90),null,null
689,4.2,null,null
690,0.85 (x1.98),null,null
691,(20%),null,null
692,10.7 (x1.28),null,null
693,2.8,null,null
694,0.85 (x1.34),null,null
695,(20%),null,null
696,11.3 (x1.36),null,null
697,3.0,null,null
698,0.58 (x1.42),null,null
699,(13%),null,null
700,RankedOR 23.1 (x34.72),null,null
701,WAND,null,null
702,4.7 (x7.12),null,null
703,MaxScore,null,null
704,4.5 (x6.78),null,null
705,BMW40 VBMW40 C-VBMW40 BMW128 VBMW128 C-VBMW128,null,null
706,1.1 (x1.58) 0.8 (x1.12) 0.7 1.2 (x1.88) 0.9 (x1.39) 1.0 (x1.48),null,null
707,83.3 (x42.20) 169.1 (x52.34) 261.3 (x52.20),null,null
708,8.0 (x4.06) 9.3 (x2.86) 12.4 (x2.47),null,null
709,7.8 (x3.97) 9.2 (x2.83) 11.7 (x2.34),null,null
710,3.2 (x1.62) 5.5 (x1.70) 8.7 (x1.74),null,null
711,2.0 (x1.02) 3.2 (x0.98) 4.9 (x0.98),null,null
712,2.0,null,null
713,3.2,null,null
714,5.0,null,null
715,3.9 (x1.98) 6.5 (x2.01) 10.1 (x2.03),null,null
716,3.1 (x1.56) 4.7 (x1.45) 7.3 (x1.46),null,null
717,3.2 (x1.64) 4.8 (x1.50) 7.6 (x1.52),null,null
718,ClueWeb09 Trec05,null,null
719,470.7 (x37.56) 212.0 (x44.41) 0.00,null,null
720,26.3 (x2.10) 12.9 (x2.69) 0.22 (5%),null,null
721,19.4 (x1.55) 11.3 (x2.37) 0.22 (5%),null,null
722,22.1 (x1.76),null,null
723,8.2,null,null
724,1.55 (x1.73),null,null
725,(36%),null,null
726,12.3 (x0.98),null,null
727,4.7,null,null
728,1.55 (x0.98),null,null
729,(36%),null,null
730,12.5,null,null
731,4.8,null,null
732,0.82 (19%),null,null
733,23.8 (x1.90),null,null
734,9.2,null,null
735,0.85 (x1.93),null,null
736,(20%),null,null
737,17.3 (x1.38),null,null
738,6.9,null,null
739,0.85 (x1.43),null,null
740,(20%),null,null
741,18.4 (x1.47),null,null
742,7.2,null,null
743,0.58 (x1.51),null,null
744,(13%),null,null
745,"RankedOR 77.9 (x36.01) 228.3 (x42.15) 429.3 (x55.20) 659.7 (x50.14) 1,214.0 (x41.72) 312.6 (x43.76) 0.00",null,null
746,WAND,null,null
747,23.8 (x10.98) 29.2 (x5.40) 25.7 (x3.31) 29.1 (x2.21) 57.1 (x1.96) 28.7 (x4.01) 0.53 (4%),null,null
748,MaxScore 19.3 (x8.91) 22.9 (x4.23) 22.7 (x2.92) 28.1 (x2.14) 42.2 (x1.45) 23.4 (x3.28) 0.53 (4%),null,null
749,BMW40 VBMW40 C-VBMW40 BMW128 VBMW128 C-VBMW128,null,null
750,4.2 (x1.93) 2.7 (x1.23) 2.2 3.9 (x1.80) 3.1 (x1.43) 3.3 (x1.53),null,null
751,10.2 (x1.89) 5.7 (x1.06) 5.4 11.2 (x2.06) 8.9 (x1.63) 9.6 (x1.77),null,null
752,14.7 (x1.89) 7.8 (x1.01) 7.8 16.3 (x2.10) 12.0 (x1.55) 12.8 (x1.65),null,null
753,22.5 (x1.71) 12.7 (x0.96) 13.2 25.6 (x1.94) 19.2 (x1.46) 20.4 (x1.55),null,null
754,49.7 (x1.71) 27.8 (x0.96) 29.1 54.0 (x1.85) 42.2 (x1.45) 45.4 (x1.56),null,null
755,12.6,null,null
756,4.14 (x1.76),null,null
757,(28%),null,null
758,7.2,null,null
759,4.14 (x1.01),null,null
760,(28%),null,null
761,7.1,null,null
762,2.12 (14%),null,null
763,13.9,null,null
764,2.24 (x1.94),null,null
765,(15%),null,null
766,11.0,null,null
767,2.24 (x1.54),null,null
768,(15%),null,null
769,12.0,null,null
770,1.48 (x1.67),null,null
771,(10%),null,null
772,ClueWeb09 Trec06,null,null
773,"RankedOR 60.6 (x33.63) 215.9 (x37.04) 439.1 (x41.46) 686.5 (x40.57) 1,270.5 (x32.81) 542.5 (x34.56) 0.00",null,null
774,WAND,null,null
775,14.2 (x7.86) 23.1 (x3.96) 27.3 (x2.58) 37.3 (x2.20) 73.8 (x1.91) 37.2 (x2.37) 0.53 (4%),null,null
776,MaxScore 12.7 (x7.04) 21.3 (x3.66) 27.1 (x2.56) 33.9 (x2.00) 55.0 (x1.42) 32.3 (x2.06) 0.53 (4%),null,null
777,BMW40 VBMW40 C-VBMW40 BMW128 VBMW128 C-VBMW128,null,null
778,3.2 (x1.77) 2.1 (x1.15) 1.8 3.6 (x1.99) 2.7 (x1.49) 2.9 (x1.59),null,null
779,10.0 (x1.72) 6.0 (x1.02) 5.8 12.0 (x2.06) 10.0 (x1.71) 10.6 (x1.83),null,null
780,17.5 (x1.65) 10.3 (x0.97) 10.6 20.9 (x1.97) 16.8 (x1.58) 18.0 (x1.69),null,null
781,28.1 (x1.66) 16.2 (x0.96) 16.9 32.5 (x1.92) 25.9 (x1.53) 28.0 (x1.65),null,null
782,65.9 (x1.70) 37.0 (x0.96) 38.7 71.0 (x1.83) 56.6 (x1.46) 61.0 (x1.58),null,null
783,26.3,null,null
784,4.14 (x1.68),null,null
785,(28%),null,null
786,15.2,null,null
787,4.14 (x0.96),null,null
788,(28%),null,null
789,15.7,null,null
790,2.12 (14%),null,null
791,29.4,null,null
792,2.24 (x1.87),null,null
793,(15%),null,null
794,23.6,null,null
795,2.24 (x1.50),null,null
796,(15%),null,null
797,25.2,null,null
798,1.48 (x1.60),null,null
799,(10%),null,null
800,"[24] Stephen E. Robertson and Karen S. Jones. 1976. Relevance weighting of search terms. Journal of the Am. Soc. for Information science 27, 3 (1976), 129­146.",null,null
801,"[25] David Salomon. 2007. Variable-length Codes for Data Compression. Springer. [26] Dongdong Shan, Shuai Ding, Jing He, Hongfei Yan, and Xiaoming Li. 2012.",null,null
802,Optimized Top-k Processing with Global Page Scores on Block-max Indexes. In WSDM. 423­432. [27] Fabrizio Silvestri. 2007. Sorting Out the Document Identi er Assignment Problem. In ECIR. 101­112.,null,null
803,[28] Fabrizio Silvestri and Rossano Venturini. 2010. VSEncoding: E cient Coding and Fast Decoding of Integer Lists via Dynamic Programming. In CIKM. 35­42.,null,null
804,"[29] Nicola Tonello o, Craig Macdonald, and Iadh Ounis. 2013. E cient and E ective Retrieval Using Selective Pruning. In WSDM. 63­72.",null,null
805,"[30] Howard Turtle and James Flood. 1995. ery evaluation: Strategies and optimizations. Information Processing & Management 31, 6 (1995), 831­850.",null,null
806,[31] Sebastiano Vigna. 2013. asi-succinct indices. In WSDM. 83­92. [32] Justin Zobel and Alistair Mo at. 2006. Inverted les for text search engines.,null,null
807,"ACM Comput. Surv. 38, 2 (2006).",null,null
808,634,null,null
809,,null,null
