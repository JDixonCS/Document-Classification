,sentence,label,data
0,Short Research Paper,null,null
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
2,Venue Appropriateness Prediction for Personalized Context-Aware Venue Suggestion,null,null
3,Mohammad Aliannejadi and Fabio Crestani,null,null
4,"Faculty of Informatics, Universita` della Svizzera italiana (USI) Lugano, Switzerland",null,null
5,"{mohammad.alian.nejadi,fabio.crestani}@usi.ch",null,null
6,ABSTRACT,null,null
7,"Personalized context-aware venue suggestion plays a critical role in satisfying the users' needs on location-based social networks (LBSNs). In this paper, we present a set of novel scores to measure the similarity between a user and a candidate venue in a new city.",null,null
8,"e scores are based on user's history of preferences in other cities as well as user's context. We address the data sparsity problem in venue recommendation with the aid of a proposed approach to predict contextually appropriate places. Furthermore, we show how to incorporate di erent scores to improve the performance of recommendation. e experimental results of our participation in the TREC 2016 Contextual Suggestion track show that our approach beats state-of-the-art strategies.",null,null
9,1 INTRODUCTION,null,null
10,"With the availability of location-based social networks (LBSNs), such as Yelp, TripAdvisor, and Foursquare, users can share check-in data using their mobile devices. LBSNs collect valuable information about users' mobility records with check-in data including user context and feedback, such as ratings and reviews. Being able to suggest personalized venues to a user, taking into account the user's context, plays a key role in satisfying the user needs on LBSNs, for example when exploring a new venue or visiting a city [6].",null,null
11,"ere are a number of di erent LBSNs that are widely used. However, a single LBSN does not have a comprehensive coverage over all venues and all types of information. Moreover, combining user's current context with multimodal information, e.g., ratings and reviews of previously visited venues from di erent LBSNs, improves the accuracy of venue suggestion [4].",null,null
12,"A major challenge for venue suggestion is how to model the user pro le, that should be built based on the user feedback on previously visited places. Relevant studies propose to model user pro les based on the venues content [9]. Other studies leverage the opinions of users about a place based on online reviews [6].",null,null
13,"Another challenge in venue suggestion is how to leverage the contextual information about users to improve suggestion. To this end, the main focus of the TREC Contextual Suggestion track in 2015 and 2016 [11] was to improve the venue suggestion with the",null,null
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 7-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080754",null,null
15,"aid of contextual suggestion. However, not many successful participants took into account context. is paper describes our a empt to utilize contextual information to enhance the performance of venue suggestion.",null,null
16,"In the e ort to face these challenges, our main contribution in this paper can be summarized as follows: (CO1) We propose a novel method to predict contextually appropriate venues given the user's current context. (CO2) We create a dataset to train our model for contextual appropriateness prediction1. (CO3) We present a set of scores to measure the similarity between a candidate venue and a user pro le based on venues contents and reviews. (CO4) We investigate two di erent ways of combining all the proposed context-, content-based similarity scores.",null,null
17,"e o cial results of the TREC 2016 Contextual Suggestion track, as well as the experiment we have done on the dataset, show that our proposed approach outperforms state-of-the-art strategies.",null,null
18,2 RELATED WORK,null,null
19,"Much work has been done to show that user data from LBSNs can signi cantly improve the e ectiveness of a context-aware recommender system. Several rating-based collaborative ltering approaches have been proposed in the literature, which are based on nding common features among users' preferences and recommending venues to people with similar interests. ese models are usually based on matrix factorization, exploiting check-in data for recommending places, such as the studies reported in [7, 10]. Factorization Machines generalize matrix factorization techniques to leverage not only user feedback but also other types of information, such as contextual information in LBSNs [13]. Also, some studies follow a review-based strategy, building enhanced user pro les based on their reviews [1]. When a user writes a review about a venue, there is a wealth of information which reveals the reasons why that particular user is interested in a venue or not. For example, Chen et al. [6] argued that reviews are helpful to deal with the sparsity problem in LBSNs. Our work consists of di erent similarity scores each of which is aimed at capturing a di erent aspect of information. More speci cally, our work combines information from venues content and online reviews.",null,null
20,"Another line of research tries to incorporate the contextual data to enhance the performance of a recommender system. Levi et al. [14] developed a weighted context-aware recommendation algorithm to address the cold start problem for hotel recommendation. More in details, they de ned context groups based on hotel reviews and followed a user's preferences in trip intent and hotel aspects as well as the user's similarity with other users (e.g., nationality)",null,null
21,"1 e contextual appropriateness dataset, as well as the additional, crawled data are available at h p://inf.usi.ch/phd/aliannejadi/data.html",null,null
22,1177,null,null
23,Short Research Paper,null,null
24,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
25,"to recommend hotels. Other works focused more on time as context [9, 18]. Yuan et al. [18] proposed a time-aware collaborative",null,null
26,"ltering approach. More speci cally, their proposed approach recommended venues to users at a speci c time of the day by mining historical check-ins of users in LBSNs. Deveaud et al. [9] modeled venues popularity in the immediate future utilizing time series.",null,null
27,"ey leveraged the model to make time-aware venue recommendation to users. e limitation in such line of works is that they only consider time and location as the context, whereas in our work we also take into account other aspects of context. Our work distinguishes itself from these approaches by considering not only time and location but also other contextual dimensions.",null,null
28,"e TREC Contextual Suggestion track [11] aimed to encourage the research on context-aware venue recommendation. In fact, the task was to produce a ranked list of venue suggestions for each user in a new city, given the user's context and history of preferences in 1-2 other cities. e contextual dimensions were the duration of the trip, the season in which the trip takes place, the type of the trip (i.e., business, holiday, and other), and the type of group with whom the user is traveling (i.e., alone, friends, etc.). ese contextual dimensions were introduced in the track in 2015. Since then, among the top runs, few approaches were trying to leverage such information. Yang and Fang [17] introduced some handcra ed rules for ltering venues based on their appropriateness to a user's current context. As they showed in their paper, applying such",null,null
29,"lters degrades the performance of the system. Hence, we conclude that contextual appropriateness is not a simple case of using some deterministic rules to lter venues.",null,null
30,"Manotumruksa et al. [15] proposed a set of categorical, temporal, and term-based features to train a set of classi ers to predict contextual appropriateness of venues. We believe that such features are very speci c to their dataset and problem and not all of them can be generalized to similar problems. Moreover, similar to our work, they collected the classi cation dataset using crowdsourcing, however, since they asked the workers to assess the appropriateness of a speci c venue to a particular user context, this could result in biased assessments. In contrast, we make sure that the assessments are not biased and our crowdsourced collection is general enough to be used in other similar problems.",null,null
31,3 CONTEXTUAL APPROPRIATENESS,null,null
32,PREDICTION,null,null
33,"In this section, we rst de ne the problem of predicting the contextual appropriateness of venues. We then present the set of features on which we train a classi er to predict the appropriate places. Finally, we describe the collection we used to train the classi er.",null,null
34,3.1 Problem De nition,null,null
35,"Given a set of venues V ,"" { 1, . . . , n } and contextual information Cx "","" {cx1, . . . , cxm }, the task is to predict if a venue i  V is appropriate to be visited by a user with context Cx . Contextual information expresses user's requirements or preferences and is limited to 3 of those introduced in TREC 2015 Contextual Suggestion track: Trip type (business, holiday, other), Trip duration (night out, day trip, weekend trip, longer) and Group type (alone, friends, family, other). Group type expresses the type of group user prefers""",null,null
36,"to go out with, while trip duration indicates how long the trip will last. We formulate the problem as a binary classi cation problem. Given a venue i and the set of its corresponding categories C i ,"" {c1, . . . , ck }, we consider each category cj  C i and the aforementioned contextual dimensions as features for classi cation.""",null,null
37,e classi er predicts whether the venue category is appropriate to be visited or not.,null,null
38,3.2 Contextual Features,null,null
39,"In this section, we discuss the contextual features we used to train a classi er to predict contextual appropriateness of venues. As features, we consider the appropriateness of each contextual dimension to a venue category. For example, assume we have a venue with category nightlife-spot, and we want to see if it is appropriate for an example context: trip type: holiday, group type: family, trip duration: weekend. We take the degree of appropriateness of the venue category with each of the contextual dimensions as features. Let Fapp (cat, cxt ) be a function returning the degree of appropriateness of a venue category, cat, to a contextual dimension, cxt, ranging from -1 to +1. Fapp (cat, cxt ) ,"" -1 indicates that a venue with category cat is absolutely inappropriate to be visited by a user with context cxt, whereas Fapp (cat, cxt ) "","" +1 indicates it is absolutely appropriate. erefore, the features in this example would be: Fapp (nightlife-spot, holiday-trip), Fapp (nightlife-spot, with-family), and Fapp (nightlife-spot, weekend-trip).""",null,null
40,"Determining such features may seem intuitive, however, we argue that in many cases determining the output of function Fapp (cat, cxt ) can be very challenging. For instance, in the previous example, the features can be de ned intuitively. On the other hand, de ning such features is not as intuitive as other ones: Fapp (o ce, with -friends), Fapp (food-and-drink-shop, business-trip), or Fapp (stadium, night-out-trip). Based on this observation, we classify the features into two classes: objective and subjective. As the terms suggest, objective features are those that are easily determined and are more objective. erefore, they can in uence a user's decision of visiting a venue or not. As in the previous example, supposedly, going to a nightlife spot with a family is not appropriate; hence, the user would not go to a nightlife spot even though he/she might like nightlife spots in general. erefore, objective features have a direct impact on users' decisions. Subjective features, in contrast, are less discriminative for they depend on each user's opinion and personal preferences.",null,null
41,"In the e ort to classify the features into objective and subjective and determine the degree of their objectivity/subjectivity, we designed a crowdsourcing task. In the task, we asked the workers to assess the features. More in detail, we showed them a venue category and a context dimension (e.g., cat , nightlife spot and cxt ,"" Group type: Family) and asked them to assess whether the pair is appropriate or not. We assigned at least ve assessors for each category-context pair. e outcome of the task was very interesting since we observed that the workers agreed on one answer when the task was objective, whereas they could not agree on subjective tasks. In this context, those pairs with high agreement rate between the assessors could be considered as objective, while those lacking assessors agreement could be seen as subjective. Table 1 lists some subjective and objective features in our dataset.""",null,null
42,1178,null,null
43,Short Research Paper,null,null
44,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
45,Table 1: Example contextual features,null,null
46,Category,null,null
47,Beach Zoo Museum Pet Store Medical Center,null,null
48,Context,null,null
49,Trip type: Holiday Trip type: Business Trip type: Business Trip duration: Weekend Trip type: Other,null,null
50,"Fapp (cat, cxt )",null,null
51,+1 -1 -0.66 -0.18 0.0,null,null
52,"As we can see in Table 1, the lower rows are more subjective pairs, in fact, we assign the 0.0 score to the last row. As we discussed earlier, we cannot determine if a venue is appropriate based on such subjective features and therefore we treat them as neutral. We computed the contextual features for all pairs of 11 contextual dimensions and the 177 most frequent categories of Foursquare category tree2. Overall we generated 1947 contextual features, leading to 11487 judgments. In fact, this dataset is general enough to be applied to other venue recommendation collections since it considers only place categories, including the most frequent category-context pairs. More details can be found in [3].",null,null
53,3.3 Training the Classi er,null,null
54,"As described in Section 3.1, we formulate the problem of contextual appropriateness of venues as a binary classi cation. We described the features that we use in the classi er in Section 3.2. In this section, we describe how we created the training dataset to train the classi er using the features we created. As training set, we randomly picked 10% of the data from TREC 2016 dataset. To annotate the data, we created another crowdsourcing task in which we asked workers to assess if a category (e.g. Bar) is appropriate to be visited by a user with a speci c context (e.g. Holiday, Friends, Weekend). We assigned at least three workers to assess each row in the dataset. Each row was considered appropriate only if at least two of the three assessors agreed on it [3]. erefore, we trained the contextual appropriateness classi er on 10% of the data from TREC 2016 to predict the rest. As classi er, we trained some widely used classi er, but since we got the best results using Support Vector Machines (SVM) [8], we only report the results of this classi er in this work due to space limitations.",null,null
55,4 CONTEXT-AWARE VENUE SUGGESTION,null,null
56,"In this section, we describe our approach of combining contextbased and user-based similarity scores to produce a ranked list of venues which ts users' preference and context.",null,null
57,"Context-Base Score. As context-based score (denoted as ScFxt ), we consider the value of SVM decision function described in Section 3. If a venue has more than one category, we will run the classi cation against each category. en, we consider the minimum value of the decision functions as the context-based similarity score because we observed whenever there are some venue categories from which one is not appropriate to the user's context, it acts as a barrier and leads to the inappropriateness of the venue.",null,null
58,2h ps://developer.foursquare.com/categorytree,null,null
59,"Frequency-Based Scores. e other set of scores is based on the frequencies of venue categories and taste tags. We rst explain how to calculate the score for venue categories. e score for tags is calculated analogously. Given a user u and a her history of rated venues, hu ,"" { 1, . . . , n }, to each venue is assigned a list of categories C ( i ) "","" {c1, . . . , ck }. We de ne the category index of a user as follows:""",null,null
60,"De nition 4.1. A Category Index consists of categories of venues a user has visited and their normalized frequency in a particular user's pro le. e category f requency (cf) is divided into two sub-frequencies: positive category frequency, denoted as cf+, and negative category frequency, denoted as cf-, representing the normalized frequency of a speci c category positively rated and negatively rate by the user, respectively.",null,null
61,"Given a user u and a candidate venue , the category-based",null,null
62,"similarity score Scat (u, ) between them is calculated as follows:",null,null
63,"Scat (u, ) ,",null,null
64,cfu+ (ci ) - cfu- (ci ) .,null,null
65,(1),null,null
66,ci C ( ),null,null
67,"We calculated the category similarity score from two sources of information, namely, Foursquare (ScFat ) and Yelp (ScYat ).",null,null
68,"Venue Tags Score. As another frequency-based score, we in-",null,null
69,dex the venue taste tags from Foursquare following De nition 4.1.,null,null
70,Venue taste tags are the most salient words extracted from the users',null,null
71,reviews. We leveraged them to have a crisper description of the,null,null
72,places and improve our suggestions. e tag similarity score is then,null,null
73,calculated similarly to Equation 1.,null,null
74,Review-Based Score. A further score uses the reviews to un-,null,null
75,derstand the motivation of the user behind a positive or negative,null,null
76,"rate. Indeed, modeling a user solely on venue's content is very",null,null
77,general and does not allow to understand the reasons why the user,null,null
78,enjoyed or disliked a venue. Our intuition is that a user's opinion,null,null
79,regarding an a raction could be learned based on the opinions,null,null
80,of other users who gave the same or similar rating to the same,null,null
81,a raction [1]. We created two TF-IDF indexes of reviews per user,null,null
82,of venues a user has visited per user: 1) positive review index con-,null,null
83,taining only positively rated reviews of venues that a particular,null,null
84,"user likes, 2) negative review index containing only negatively rated",null,null
85,reviews of places that a particular user does not like. For each,null,null
86,"user, we trained a binary classi er considering the positive and",null,null
87,"negative review indexes as positive and negative training examples, respectively3. As classi er, we used SVM with linear kernel and",null,null
88,consider the value of the SVM's decision function as the score since,null,null
89,it gives us an idea on how close and relevant a venue is to a user pro le4. We used the reviews from Yelp for this score and refer to it as SrYe .,null,null
90,Venue Ranking. We investigated two possible methods of com-,null,null
91,bining these similarity scores: linear interpolation and learning to,null,null
92,rank. Linear interpolation is an e ective yet simple way of combin-,null,null
93,ing multiple scores into one. We linearly combined all the similarity,null,null
94,scores into one [2]. We also adopted learning to rank techniques,null,null
95,as they have proved to be e ective in similar problems [4]. We,null,null
96,"3An alternative to binary classi cation would be a regression model, but we believe it is inappropriate since when users read online reviews, they make their minds by taking a binary decision (like/dislike). 4Note that we used other well known classi er but do not report the results due to space limitation.",null,null
97,1179,null,null
98,Short Research Paper,null,null
99,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
100,Table 2: Performance evaluation on TREC 2016 Contextual Suggestion track. Bold values denote the best scores.,null,null
101,P@5 nDCG@5 MAP MRR P@10,null,null
102,BASE1 BASE2 CS-Linear CS-L2Rank,null,null
103,0.4724 0.5069 0.5069 0.5379,null,null
104,0.3306 0.3281 0.3265 0.3603,null,null
105,0.4497 0.4536 0.4590 0.4682,null,null
106,0.6801 0.6501 0.6796 0.7054,null,null
107,0.4552 0.4500 0.4603 0.4828,null,null
108,"adopted ListNet [5] to rank the venues using non-contextual scores as features of ListNet. e contextual score was then used to rerank the initial ranked list to produce the nal list of venues. To nd the optimum se ing for the parameters of our models, we conducted a 5-fold cross validation, training the model using four folds and tuning the parameters using one fold. We denote our linear ranking model as CS-Linear and the one based on learning to rank as CS-L2Rank.",null,null
109,5 EXPERIMENTAL RESULTS,null,null
110,In this section we report the experimental results to demonstrate the e ectiveness of our approach.,null,null
111,Dataset. We report the result of our participation [2] in the TREC 2016 Contextual Suggestion track [11] as well as additional experiments carried out on our crawled dataset5 [3] and ground truth labels as released by the coordinators.,null,null
112,"Evaluation protocol. We follow the same evaluation metrics as in TREC 2016 to report the results, namely, P@5, nDCG@5, MAP, MRR, and P@10.",null,null
113,"Compared methods. We compare our approach with top performing systems in TREC 2016. In particular, BASE1 adopts a modi-",null,null
114,"ed Rocchio classi er to rank the venues given a query which is created by Rocchio relevance feedback method from places' descriptions and metadata [12]. BASE2, on the other hand, considers both the global trend and personal preference to recommend venues.",null,null
115,"e former is a regressor trained using the most visited category in the 2015 TREC dataset, while the la er adopts word embedding to capture individual user preferences [16].",null,null
116,"Results. Table 2 demonstrates the performance of our models against competitors for the TREC 2016. Table 2 shows that CS-L2Rank outperforms the competitors w.r.t. the ve evaluation metrics. is indicates that the proposed approach for joint personal-contextual venue suggestion improves the performance of venue suggestion. is happens because our model predicts the contextual appropriateness of venues e ectively. At the same time, it improves the ranking technique by capturing user preferences more accurately, thus addressing the data sparsity problem for venue suggestion. CS-Linear, however, beats the baselines w.r.t. MAP and P@10. It exhibits a comparable performance in terms of other evaluation metrics. It also con rms that the proposed similarity scores are able to capture contextual appropriateness and user interest. However, it indicates that combining multimodal information is a complex problem and thus more sophisticated techniques, such as learning to rank, perform be er.",null,null
117,5Available at h p://inf.usi.ch/phd/aliannejadi/data.html,null,null
118,6 CONCLUSION,null,null
119,"In this study, we presented an approach to predicting contextually appropriate venues as well as other similarity scores to model the personal preferences of users for venue suggestion. For contextual appropriateness prediction, we proposed a set of novel relevance features with which we trained a classi er. e features as well as the training data was created using crowdsourcing and is freely available on request. We studied two directions to combine the scores: linear interpolation and learning to rank. e proposed CS-L2Rank model exhibited the best performance beating stateof-the-art approaches in terms of all ve evaluation metrics. is con rms that the proposed approach, CS-L2Rank, solves the data sparsity problem and captures user context and preferences more accurately. As future work, we plan to extend our model to capture the time dimension and perform time-aware venue suggestion.",null,null
120,ACKNOWLEDGMENTS,null,null
121,is research was partially funded by the RelMobIR project of the Swiss National Science Foundation (SNSF).,null,null
122,REFERENCES,null,null
123,"[1] Mohammad Aliannejadi, Ida Mele, and Fabio Crestani. 2016. User Model Enrichment for Venue Recommendation. In AIRS. Springer, 212­223.",null,null
124,"[2] Mohammad Aliannejadi, Ida Mele, and Fabio Crestani. 2016. Venue Appropriateness Prediction for Contextual Suggestion. In TREC. NIST.",null,null
125,"[3] Mohammad Aliannejadi, Ida Mele, and Fabio Crestani. 2017. A Cross-Platform Collection for Contextual Suggestion. In SIGIR 2017. ACM.",null,null
126,"[4] Mohammad Aliannejadi, Dimitrios Rafailidis, and Fabio Crestani. 2017. Personalized Keyword Boosting for Venue Suggestion Based on Multiple LBSNs. In ECIR. Springer, 291­303.",null,null
127,"[5] Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to Rank: From Pairwise Approach to Listwise Approach. In ICML. ACM, 129­136.",null,null
128,"[6] Li Chen, Guanliang Chen, and Feng Wang. 2015. Recommender systems based on user reviews: the state of the art. User Modeling and User-Adapted Interaction 25, 2 (2015), 99­154.",null,null
129,"[7] Chen Cheng, Haiqin Yang, Irwin King, and Michael R. Lyu. 2012. Fused Matrix Factorization with Geographical and Social In uence in Location-Based Social Networks. In AAAI. AAAI Press, 17­23.",null,null
130,"[8] Corinna Cortes and Vladimir Vapnik. 1995. Support-Vector Networks. Machine Learning 20, 3 (1995), 273­297.",null,null
131,"[9] Romain Deveaud, M-Dyaa Albakour, Craig Macdonald, and Iadh Ounis. 2015. Experiments with a Venue-Centric Model for Personalised and Time-Aware Venue Suggestion. In CIKM. ACM, 53­62.",null,null
132,"[10] Jean-Beno^it Griesner, Talel Abdessalem, and Hubert Naacke. 2015. POI Recommendation: Towards Fused Matrix Factorization with Geographical and Temporal In uences. In RecSys. ACM, 301­304.",null,null
133,"[11] Seyyed Hadi Hashemi, Charles L. A. Clarke, Jaap Kamps, Julia Kiseleva, and Ellen M. Voorhees. 2016. Overview of the TREC 2016 Contextual Suggestion Track. In TREC. NIST.",null,null
134,"[12] Georgios Kalamatianos and Avi Arampatzis. 2016. Recommending Points-ofInterest via Weighted kNN, Rated Rocchio, and Borda Count Fusion. In TREC. NIST.",null,null
135,"[13] Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer 42, 8 (2009), 30­37.",null,null
136,"[14] Asher Levi, Osnat Mokryn, Christophe Diot, and Nina Ta . 2012. Finding a needle in a haystack of reviews: cold start context-based hotel recommender system. In RecSys. ACM, 115­122.",null,null
137,"[15] Jarana Manotumruksa, Craig MacDonald, and Iadh Ounis. 2016. Predicting Contextually Appropriate Venues in Location-Based Social Networks. In CLEF. Springer, 96­109.",null,null
138,"[16] Jian Mo, Luc Lamontagne, and Richard Khoury. 2016. Word embeddings and Global Preference for Contextual Suggestion. In TREC. NIST.",null,null
139,[17] Peilin Yang and Hui Fang. 2015. University of Delaware at TREC 2015: Combining Opinion Pro le Modeling with Complex Context Filtering for Contextual Suggestion. In TREC. NIST.,null,null
140,"[18] an Yuan, Gao Cong, Zongyang Ma, Aixin Sun, and Nadia Magnenat- almann. 2013. Time-aware point-of-interest recommendation. In SIGIR. ACM, 363­372.",null,null
141,1180,null,null
142,,null,null
