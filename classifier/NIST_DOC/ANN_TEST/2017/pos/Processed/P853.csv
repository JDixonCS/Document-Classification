,sentence,label,data
0,Short Research Paper,null,null
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
2,Generating Clinical eries from Patient Narratives,null,null
3,A Comparison between Machines and Humans,null,null
4,Bevan Koopman,null,null
5,"CSIRO Brisbane, Australia bevan.koopman@csiro.au",null,null
6,Liam Cripwell,null,null
7,"CSIRO Brisbane, Australia ljcripwell@gmail.com",null,null
8,Guido Zuccon,null,null
9,"eensland University of Technology Brisbane, Australia g.zuccon@qut.edu.au",null,null
10,ABSTRACT,null,null
11,"is paper investigates how automated query generation methods can be used to derive e ective ad-hoc queries from verbose patient narratives. In a clinical se ing, automatic query generation provides a means of retrieving information relevant to a clinician, based on a patient record, but without the need for the clinician to manually author a query. Given verbose patient narratives, we evaluated a number of query reduction methods, both generic and domain speci c. Comparison was made against human generated queries, both in terms of retrieval e ectiveness and characteristics of human queries. ery reduction was an e ective means of generating ad-hoc queries from narratives. However, human generated queries were still signi cantly more e ective than automatically generated queries. Further improvements were possible if parameters of the query reduction methods were set on a per-query basis and a means of predicting this was developed. Under ideal conditions, automated methods can exceed humans. E ective human queries were found to contain many novel keywords not found in the narrative. Automated reduction methods may be handicapped in that they only use terms from narrative. Future work, therefore, may be directed toward be er understanding e ective human queries and automated query rewriting methods that a empt to model the inference of novel terms by exploiting semantic inference processes.",null,null
12,CCS CONCEPTS,null,null
13,·Information systems  Expert search;,null,null
14,1 INTRODUCTION,null,null
15,"An electronic patient record is an invaluable source of information in clinical scenarios. Beyond its immediate use of describing a patient, it provides a reference for retrieving auxiliary information related to that patient such as relevant medical literature or clinical trials for which that patient may be eligible [4]. It is desirable to automatically initiate a search to retrieve such information from a patient record; however, patient records are verbose and using the entire record as an ad-hoc query is not e ective [6]. us, in this",null,null
16,Work completed as part of an internship at CSIRO while a student at QUT.,null,null
17,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080661",null,null
18,"paper, we investigate methods for automatically generating ad-hoc clinical queries from verbose patient reports.",null,null
19,Our main research questions are: 1) Can a verbose patient narrative be reduced to a more e ective ad-hoc query? and 2) How does the e ectiveness of this query compare with human generated ad-hoc queries?,null,null
20,2 RELATED WORK,null,null
21,"e clinical task: Generating clinical queries from verbose patient narratives has previously been a empted as part of the TREC Clinical Decision Support (CDS) track [11]: given a verbose patient narrative, retrieve PubMed articles in a clinical decision support se ing. E ective teams typically applied a form of implicit query reduction by weighting terms from the patient narrative [1].",null,null
22,"A similar task to TREC CDS involved using the same verbose patient narratives but retrieving clinical trials for which that patient may be eligible [6]. is test collection is of particular relevance as a number of query variations are provided for each topic: the verbose patient narrative, a human provided summary and a number of ad-hoc queries provided by clinicians. ese ad-hoc queries therefore provide us with the human benchmark against which any automatically generated query can be evaluated.",null,null
23,"Dealing with verbose queries: Previous work has speci cally tackled the problem of dealing with verbose queries. Kumaran and Carvalho [6] approached the problem by generating shorter subqueries from the initial query and training a classi er to predict the quality of a given subquery based on various predictive measures [9]. Bendersky and Cro [2] developed a technique for automatically extracting key concepts from verbose queries that had the most impact on retrieval e ectiveness. Both these two techniques relied on generating permutations of sub-queries. A key di erence between these previous methods and this study was the length of the original verbose queries: Kumaran and Carvalho used topics 3­30 terms in length, Bendersky and Cro used topics 12­49 terms in length, while our patient reports were 39­204 terms in length. For such long queries, some predictive measures were infeasible; for example, generating all possible sub-queries for a 200 term query is intractable (200! combinations). Finally, it is unclear how these general methods translate to the nuances of medical IR [4].",null,null
24,"Generating clinical queries: Speci c to the medical domain, Soldaini et al. experimented with query reduction techniques for searching medical literature [12], including some of those from Kumaran & Carvalho [9].",null,null
25,Koopman et al. [5] experimented with a concept-based information retrieval approach to medical record search using the UMLS medical thesaurus. e experiment showed that queries and documents that are reduced to contain only their medical concepts,null,null
26,853,null,null
27,Short Research Paper,null,null
28,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
29,proved e ective. is method relies on e ectively identifying medical concepts from free-text; a task that is possible using specialist medical information extraction systems [13].,null,null
30,"Understanding e ective clinical queries: In order to implement an automated query generation method, it is important to identify the hallmarks of an e ective query. is was investigated in [7] where the query generation process of humans was examined in detail. e results of that study showed that the most e ective queriers were those that inferred novel keywords not present in the original patient narrative. ese ndings suggest that automated methods which merely reduce the query to contain a subset of its original terms (like those of Kumaran&Carvalho [6] and Bendersky&Cro [2]) may be limited in terms of potential e ectiveness. Our empirical investigation answers whether this is the case.",null,null
31,3 METHODS,null,null
32,e rst sub-section outlines speci c methods for generating shorter ad-hoc queries from a verbose patient narrative. ese basic methods are extended to a per-query adaptive approach in the next sub-section. We also outline speci c methods for analysing queries to understand more about how automatically generated queries compare with human generated queries.,null,null
33,3.1 Automatic ery Reduction Methods,null,null
34,"Proportional Inverse Document Frequency (IDF-r): Terms in the original patient narrative were ranked according to inverse document frequency; a proportion of the top ranked IDF terms were retained. is proportion, denoted r , was varied from 1/|D | to 1 where |D| was the total number of terms in the patient narratives.1",null,null
35,e model was run and evaluated with r at all values between 0.01 and 1.0 with increments of 0.01. We denote this IDF-r. Reduce to only UMLS Medical Concepts (UMLS & TaskedUMLS): A model was developed that identi ed and retained only medical related terms from the original patient narrative. Medical terms were identi ed as those belonging to the UMLS medical thesaurus.2 Medical terms were identi ed using ickUMLS [13] -- an information extraction systems that maps free-text to UMLS concepts. We denote this model UMLS.,null,null
36,"A variant of the UMLS model was also implemented to perform a further reduction to contain only Diagnosis, Treatment or Test related terms. is choice is based on prior studies that show medical professionals typically pose clinical questions around these three types [3] and these form the basis of the queries in TREC CDS [11]. We denote this model Tasked-UMLS. Combined model UMLS+IDF-r: Here the original patient narrative was rst reduced to contain only medical terms using the UMLS model and then a proportion of terms retained using the IDF-r model. We denote this model UMLS+IDF-r.",null,null
37,"1A top-k variant to the IDF-r model was also implemented to reduce the topic to include a xed k terms with highest IDF values; however, the results for this were less reliable than IDF-r due to the fact that the lengths of the patient narratives di ered considerably. 2h ps://www.nlm.nih.gov/research/umls/",null,null
38,3.2 Per-query Reduction via ery,null,null
39,Performance Predictors,null,null
40,An important consideration for the aforementioned query reduc-,null,null
41,tion methods was how much to reduce the query by (as indicated,null,null
42,"by query reduction proportion parameter, r ). We hypothesised that",null,null
43,"because topics di ered considerably in both length and content,",null,null
44,a global se ing of r would have been sub-optimal (this was em-,null,null
45,"pirically validated in our experiments). us, it was desirable to",null,null
46,determine the query reduction proportion on a per-query basis.,null,null
47,To do this we utilised ery Performance Predictors (QPPs) [9].,null,null
48,"Speci cally, queries were generated for r , 0.01..1.0 in step of 0.01.",null,null
49,For each generated query a number of QPPs were calculated. e,null,null
50,speci c QPPs used were:,null,null
51,Inverse Document Frequency (IDF): is was calculated and,null,null
52,averaged across all query terms.,null,null
53,I DFw,null,null
54,",",null,null
55,log,null,null
56,1+N n(w ),null,null
57,where N,null,null
58,is,null,null
59,the total number of documents in the collection and n(w ) is the,null,null
60,collection frequency of term w.,null,null
61,SCQ: A measure of how similar a query was to the collection as a,null,null
62,whole;,null,null
63,averaged,null,null
64,across,null,null
65,all query,null,null
66,terms.,null,null
67,SCQw,null,null
68,",",null,null
69,(1 + ln,null,null
70,n,null,null
71,(w N,null,null
72,),null,null
73,),null,null
74,×,null,null
75,ln,null,null
76,(1,null,null
77,+,null,null
78,N Nw,null,null
79,),null,null
80,where,null,null
81,Nw,null,null
82,is,null,null
83,the,null,null
84,document,null,null
85,frequency,null,null
86,of w.,null,null
87,Inverse Collection Term Frequency (ICTF): is was calculated,null,null
88,and,null,null
89,averaged,null,null
90,across,null,null
91,all,null,null
92,terms.,null,null
93,ICT Fw,null,null
94,",",null,null
95,log2,null,null
96,n(w ) T,null,null
97,where T,null,null
98,is,null,null
99,the,null,null
100,total number of terms in the collection.,null,null
101,ery Scope (QS): A measure of the size of the retrieved document,null,null
102,set,null,null
103,relative,null,null
104,to,null,null
105,the,null,null
106,collection,null,null
107,size:,null,null
108,QS,null,null
109,",",null,null
110,-,null,null
111,log,null,null
112,nQ N,null,null
113,",",null,null
114,nQ,null,null
115,is,null,null
116,the,null,null
117,number,null,null
118,of documents that contain at least one of the query terms.,null,null
119,e correlation between these predictors and the retrieval ef-,null,null
120,"fectiveness of the queries was examined. In addition, the QPPs",null,null
121,"were used as features in a model to prediction the value of r ; i.e.,",null,null
122,"given a particular topic (patient narrative), determine what query",null,null
123,reduction proportion should be applied to it in order to maximise,null,null
124,"retrieval e ectiveness. Training data was obtained by selecting,",null,null
125,"for each query topic, the best se ing of r according to precision",null,null
126,"@ 5 (P5). is resulted in a total of 1289 topic, query pairs. (Note",null,null
127,that for many queries there were many values of r with the same,null,null
128,P5; hence the large number of training examples.) e training,null,null
129,data was strati ed into four folds according to topic id (60 topics,null,null
130,divided into folds of 15 topics). A Generalized Linear Model was,null,null
131,then trained to predict r based on the QPPs; this was done via,null,null
132,"4-fold cross validation. Finally, the predicted values of r were used",null,null
133,"in IDF-r and UMLS+IDF-r, and P5, mean reciprocal rank (MRR) and",null,null
134,INST calculated.,null,null
135,3.3 ery Understanding Methods,null,null
136,Analysis of how clinician formulate ad-hoc queries from patient,null,null
137,narratives has shown that they sometimes selected keywords from,null,null
138,the narrative and sometimes inferred novel terms not found in the,null,null
139,narrative [7] . Here we consider the overlap of keywords in the,null,null
140,clinician's ad-hoc query and corresponding narrative in order to,null,null
141,be er understand how clinicians formulated their queries.,null,null
142,e overlap of an ad-hoc query Q is de ned as the propor-,null,null
143,"tion of keywords in Q that were contained in its narrative text,",null,null
144,T: o,null,null
145,"erlap(T ,Q ) ,",null,null
146,|T Q |Q |,null,null
147,|,null,null
148,.,null,null
149,e automated query reduction meth-,null,null
150,ods outlined in this study clearing were limited to selecting only,null,null
151,854,null,null
152,Short Research Paper,null,null
153,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
154,0.15,null,null
155,INST,null,null
156,0.5,null,null
157,MRR 0.6,null,null
158,P5,null,null
159,0.4,null,null
160,0.10,null,null
161,0.4,null,null
162,0.3,null,null
163,0.05,null,null
164,0.2,null,null
165,0.2,null,null
166,0.1 ,null,null
167,0.00,null,null
168,0.0,null,null
169,NHaurSrmautamivnemAadry-hToaIDcsFkUe-UdMrM-LULSSM+LISDF-r,null,null
170,NHaurSrmautamivnemAadry-hToaIDcsFkUe-UdMrM-LULSSM+LISDF-r,null,null
171,NHaurSrmautamivnemAadry-hToaIDcsFkUe-UdMrM-LULSSM+LISDF-r,null,null
172,Figure 1: Results for baselines and reduction methods.,null,null
173,"keywords from the narrative (overlap ,"" 1.0). We, therefore, investigate how much of a handicap this was in comparison to human generated queries containing novel keywords.""",null,null
174,3.4 Experimental Setup,null,null
175,"Empirical evaluation was performed using a clinical trials test collection [6]. e collection contained 204,855 publicly available clinical trial documents, which we indexed using ElasticSearch with stemming and punctuation removal.3",null,null
176,"e collection also contained 60 query topics. Each topic contained three di erent query variations: i) verbose patient case narratives (78 terms per topic); ii) shorter patient case summaries of the patient case narrative (22 terms per topic); and iii) short ad-hoc queries (4.2 terms per topic) provided by clinicians [6]. e narratives represented the original patient narrative (to which query reduction was applied). e shorter summary represented a human benchmark for summarising the narrative. e ad-hoc queries (n,489) represented a human benchmark against which automated methods could be compared.",null,null
177,"A er query reduction was applied to the narrative, the reduced queries were issued to ElasticSearch and their e ectiveness evaluated using P5, MRR and INST (the evaluation measures for this test collection [6]). In addition, the full narrative, summary and ad-hoc queries were also evaluated as comparison baselines/benchmarks. Statistically signi cant di erences in retrieval e ectiveness was determined using a paired t-test.",null,null
178,4 RESULTS & DISCUSSION,null,null
179,"e retrieval results for the di erent query reduction methods and comparative baselines and benchmarks are shown in Figure 1. We observe that issuing the entire patient narrative exhibited the poorest retrieval e ectiveness. is motivates the develop of speci c query reduction methods. e shorter human-generated summaries were more e ective than the narrative (p ,"" 0.030). is nding highlights that a general reduction of query terms had a positive e ect on retrieval. However, the human ad-hoc queries proved far more e ective (statistically signi cant over all other methods). Humans were able to derive speci c query keywords that led to more relevant results being retrieved (more on this later). is""",null,null
180,3ElasticSearch version -- 5.2.0 h ps://www.elastic.co/downloads/elasticsearch.,null,null
181,"showed that although a summarisation method had the potential to improve e ectiveness, short, ad-hoc keyword queries were still the most e ective.",null,null
182,"ery reduction via IDF-r proved to be e ective for speci c se ings of r . IDF-r showed a signi cant increase in e ectiveness in comparison to the narratives (p ,"" 0.040) when an appropriate query reduction proportion (r ) was chosen. Note that the boxplot shows the e ectiveness for all se ings of r , many of which would obviously be sub-optimal (e.g., r "", 0.01 where only 1% of terms were retained). e results for IDF-r showed that the removal of less informative terms was a simple but e ective means of improving retrieval e ectiveness.",null,null
183,"Reducing the narrative to contain only medical terms via the UMLS method proved e ective over searching using the narrative (p , 0.031) but not over using the summary (p ,"" 0.395). e UMLS results showed that simply removing non-medical terms from the narrative was a very good reduction method. UMLS seemed to produce be er results than the IDF-r, although these were not signi cant (p "","" 0.088). Based on the positive results of the IDF-r and UMLS, a combined UMLS+IDF-r method was evaluated. However, UMLS+IDF-r was not statistically signi cantly di erent from UMLS (p "", 0.568) or IDF-r (p ,"" 0.072). However, the UMLS+IDF-r had the advantage of having similar e ectiveness but with far fewer query terms.""",null,null
184,4.1 Understanding human queries,null,null
185,"e results from Figure 1 also show that human ad-hoc queries were volatile: they had the greatest variation in e ectiveness. While all the best performing queries were ad-hoc, there were also ad-hoc queries that were among the worst performing. Additional analysis is required to determine the characteristics of good vs. bad ad-hoc queries. ese ndings may help in the development of e ective automatic query generation methods. is is le to future work.",null,null
186,"Comparing the keywords from ad-hoc queries with those of the patient narrative, it was found that 49% of all queries had an overlap of 0.00; i.e., the ad-hoc query contained no common terms with the narrative. e mean overlap was only 0.26. is indicated that clinicians chose to formulate their own query terms rather than select those from the patient narrative. e inferring of novel query terms, particularly those related to medical treatments, has been found to correlate with higher retrieval e ectiveness [7]. ery reduction methods may be handicapped, therefore, by the fact that they source keywords from the narrative alone. We empirically evaluate this in the coming sections and consider further the issue of inferring novel query keywords.",null,null
187,4.2 ery reduction proportion sensitivity,null,null
188,"Figure 2 shows the sensitivity to retrieval e ectiveness of the query reduction proportion parameter, r (r ,"" 1.0 represents the original patient narrative). In general, reduction via IDF proved e ective (over the narrative baseline) when the narrative was reduced to approximately 25% of its original size.""",null,null
189,"e results for both IDF-r and UMLS+IDF-r were all reported with a global reduction proportion, r , across all topics (i.e., across all patient narratives). Since narratives varied greatly in both length and in content, a global reduction proportion may have been quite",null,null
190,855,null,null
191,Short Research Paper,null,null
192,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
193,Query effectiveness,null,null
194,INST,null,null
195,MRR,null,null
196,P5,null,null
197,0.024,null,null
198,0.20,null,null
199,0.020,null,null
200,0.15,null,null
201,0.06,null,null
202,0.016,null,null
203,0.04,null,null
204,0.10,null,null
205,0.012 0.02,null,null
206,0.05 0.008,null,null
207,0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00,null,null
208,"Query reduction proporation, r",null,null
209,"Figure 2: ery e ectiveness for di erent query reduction proportions, r using the IDF-r.",null,null
210,Table 1: Retrieval results when predicting query reduction proportion. Percentages show improvements and  show signi cance when compared to best global r .,null,null
211,Human adhoc Narrative Summary Average global r Best global r Per-query r -- QPP Per-query r -- Oracle,null,null
212,P5,null,null
213,0.1521 0.0508 0.0949 0.0551 0.0881 0.0861 (-2%) 0.1457 (+65%),null,null
214,MRR,null,null
215,0.2878 0.1312 0.1790 0.1513 0.2220 0.2432 (+10%) 0.3679 (+66%),null,null
216,INST,null,null
217,0.0476 0.0149 0.0306 0.0184 0.0247 0.0268 (+9%) 0.0368 (+49%),null,null
218,"sub-optimal. us, we investigated the e ect of predicting r on a per-query basis.",null,null
219,4.3 Predicting query reduction proportion,null,null
220,"A Generalised Linear Regression Model was used to predict an appropriate value of r for a given query using the QPP measures of Section 3.2 as features. e results are shown in Table 1. We also report the ""oracle"" results indicating the retrieval e ectiveness if the best value of r was chosen on a per-query basis. Signi cant improvements in MRR were found when predicting r on a per query basis; no signi cant di erences were found for P5 and INST. is is in contrast to the oracle results that showed considerable improvement if the correct reduction proportion was chosen. Clearly, there is considerable room for improvement. e chief area of focus in this regard is the establishment of a richer set of features for the prediction of per-query r values. Particular points of inquiry would be in the evaluation of medical speci c features, such as mentions of particular diseases a ecting the patient, permanent demographic information (age, gender) and negated content (e.g., ""no fever""). A be er understanding of what constituted an e ective human query would help to inform such features.",null,null
221,"e oracle results showed signi cant improvement over those produced by maintaining a static, global r value. is highlights that query reduction should ideally be done on a per-query basis. In addition to this, the oracle results were much higher than those of the human generated summaries, showing that automated query generation can improve upon human summarisation. Finally, the oracle results show comparable performance with the human adhoc queries. In the case of MRR, the automated query generation methods was statistically signi cantly be er than the human ad-hoc queries (p ,"" 0.041). Even though the query reduction method only used terms from the original narrative, the oracle results showed that the right query reduction method was in line with human""",null,null
222,"generated queries that include novel terms. Given that human queries containing novel terms showed greater e ectiveness [7], it follows that automated methods for inferring such terms should be investigated. Common query expansion methods are relevant here. However, there are also a number of retrieval techniques, some speci c to the medical domain, that a empt to model the inference of novel terms by exploiting semantic inference processes [8, 10, 14].",null,null
223,5 CONCLUSION,null,null
224,"ery reduction was an e ective means of generating ad-hoc queries from verbose patient narratives. E ective query reduction methods included those that retained only medical terms and a proportion of high ranking IDF terms. ery reduction could be even more e ective if the query reduction proportion was determined on a per-query basis. Using standard query performance predictors as features resulted in only minor improvements. However, if an e ective query reduction proportion can be found then signi cant improvements are possible, approaching or exceeding human generated queries.",null,null
225,"Human generated queries varied widely in e ectiveness. An analysis of human queries showed that many contained novel terms not found in the patient narrative. eries with novel terms have previously shown to be more e ective. ery reduction method may, therefore, be handicapped in that they only source keywords from the patient narrative. Future work, therefore, may be directed toward be er understanding e ective human queries and in automated retrieval methods that a empt to model the inference of novel terms by exploiting semantic inference processes.",null,null
226,REFERENCES,null,null
227,"[1] Saeid Balaneshinkordan, Alexander Kotov, and Railan Xisto. 2015. WSU-IR at TREC 2015 Clinical Decision Support Track: Joint Weighting of Explicit and Latent Medical ery Concepts from Diverse Sources. In TREC.",null,null
228,"[2] Michael Bendersky and W. Bruce Cro . 2008. Discovering Key Concepts in Verbose eries. In SIGIR. Singapore, 491­498.",null,null
229,"[3] J.W. Ely, J.A. Oshero , P.N. Gorman, M.H. Ebell, M.L. Chambliss, E.A. Pifer, and P.Z. Stavri. 2000. A taxonomy of generic clinical questions: classi cation study. BMJ 321, 7258 (2000), 429­432.",null,null
230,[4] William Hersh. 2008. Information retrieval: a health and biomedical perspective. Springer Science & Business Media.,null,null
231,"[5] Bevan Koopman, Peter Bruza, Laurianne Sitbon, and Michael Lawley. 2011. AEHRC & QUT at TREC 2011 Medical Track : a concept-based information retrieval approach. In TREC. NIST, Gaithersburg, USA, 1­7.",null,null
232,[6] Bevan Koopman and Guido Zuccon. 2016. A Test Collection for Mathcing Patient Trials. In SIGIR. Pisa.,null,null
233,"[7] Bevan Koopman, Guido Zuccon, and Peter Bruza. 2017. What makes an E ective Clinical ery and erier? JASIST To appear (2017).",null,null
234,"[8] Bevan Koopman, Guido Zuccon, Peter Bruza, Laurianne Sitbon, and Michael Lawley. 2015. Information Retrieval as Semantic Inference: A Graph Inference Model applied to Medical Search. Information Retrieval 19, 1 (2015), 6­37.",null,null
235,"[9] Giridhar Kumaran and Vitor R. Carvalho. 2009. Reducing Long eries Using ery ality Predictors. In SIGIR. Boston, USA, 564­571.",null,null
236,"[10] Nut Limsopatham, Craig Macdonald, and Iadh Ounis. 2013. A Task-Speci c ery and Document Representation for Medical Records Search. In ECIR. 747­",null,null
237,"751. [11] Kirk Roberts, Ma hew S Simpson, Ellen Voorhees, and William R Hersh. 2015.",null,null
238,"Overview of the TREC 2015 Clinical Decision Support Track. In TREC. [12] Luca Soldaini, Arman Cohan, Andrew Yates, Nazli Goharian, and Ophir Frieder.",null,null
239,"2015. Retrieving Medical Literature for Clinical Decision Support. In ECIR. [13] Luca Soldaini and Nazli Goharian. 2016. ickumls: a Fast, Unsupervised",null,null
240,"Approach for Medical Concept Extraction. In MedIR Workshop, SIGIR. [14] Wei Zhou, Clement Yu, Neil Smalheiser, Vetle Torvik, and Jie Hong. 2007.",null,null
241,Knowledge-intensive conceptual retrieval and passage extraction of biomedical literature. In SIGIR. 655­662.,null,null
242,856,null,null
243,,null,null
