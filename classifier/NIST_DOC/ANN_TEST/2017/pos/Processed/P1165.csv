,sentence,label,data
0,Short Research Paper,null,null
1,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
2,Layout and Semantics: Combining Representations for Mathematical Formula Search,null,null
3,Kenny Davila,null,null
4,Rochester Institute of Technology 1 Lomb Memorial Drive,null,null
5,"Rochester, New York 14623 kxd7282@rit.edu",null,null
6,ABSTRACT,null,null
7,"Math-aware search engines need to support formulae in queries. Mathematical expressions are typically represented as trees de ning their operational semantics or visual layout. We propose searching both formula representations using a three-layer model. e rst layer selects candidates using spectral matching over tree node pairs. e second layer aligns a query with candidates and computes similarity scores based on structural matching. In the third layer, similarity scores are combined using linear regression. e two representations are combined using retrieval in parallel indices and regression over similarity scores. For NTCIR-12 Wikipedia Formula Browsing task relevance rankings, we see each layer increasing ranking quality and improved results when combining representations as measured by Bpref and nDCG scores.",null,null
8,CCS CONCEPTS,null,null
9,·Information systems Similarity measures; Rank aggregation; Language models;,null,null
10,KEYWORDS,null,null
11,"Formula Retrieval; Operator Tree; Symbol Layout Tree ACM Reference format: Kenny Davila and Richard Zanibbi. 2017. Layout and Semantics: Combining Representations for Mathematical Formula Search. In Proceedings of SIGIR '17, Shinjuku, Tokyo, Japan, August 07-11, 2017, 4 pages. DOI: 10.1145/3077136.3080748",null,null
12,1 INTRODUCTION,null,null
13,"Math-aware search engines deal with information needs where documents containing particular math expressions are sought a er, or where document similarity is de ned by text and formulae. An expression can be represented semantically by its operations using an Operator Tree (OPT) or visually by a Symbol Layout Tree (SLT) [16]. Figure 1 shows an SLT and OPT for x - 2 , 0.",null,null
14,"Many researchers in Mathematical Information Retrieval (MIR) assume OPTs provide be er formula retrieval results than SLTs, but each has limitations for retrieval. For SLTs, mathematical notation",null,null
15,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 7-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: 10.1145/3077136.3080748",null,null
16,Richard Zanibbi,null,null
17,Rochester Institute of Technology 1 Lomb Memorial Drive,null,null
18,"Rochester, New York 14623 rlaz@cs.rit.edu",null,null
19,(a) Symbol Layout Tree,null,null
20,(b) Operator Tree,null,null
21,"Figure 1: Tree representations for x - 2 , 0",null,null
22,"can change meaning based on context - a symbol may be an operator in one context, and a variable in another, for example. In contrast, well-formed OPTs are mathematically unambiguous. Online, most write math expressions using SLT representations (e.g., LATEX). SLTs can be converted to OPTs using parsers, but semantics are o en unde ned or ambiguous, producing errors [3].",null,null
23,"Our previous work (Tangent-31 [1, 17]) uses a two-stage SLT model for formula retrieval. First, top-k candidates are identi ed using a bag-of-words model, using symbol pairs in SLTs as `words.'",null,null
24,"en, the top-k candidates are re-ranked a er aligning query and candidate SLTs. Candidates are re-ranked using the harmonic mean of symbol and relationship recall (the Maximum Subtree Similarity) and two tie-breakers: symbol precision a er uni cation, and symbol recall without uni cation.",null,null
25,"We present an extended model, Tangent-S, that works with OPTs and uses a stricter uni cation model to avoid matching functions to variable names. A third stage is added using a linear combination of the structure similarity scores for re-ranking. Stronger formula retrieval results are obtained by retrieving SLTs and OPTs independently, and then linearly combining their similarity scores.",null,null
26,is supports the view of OPTs and SLTs as complementary for formula retrieval.,null,null
27,2 BACKGROUND,null,null
28,"Approaches to formula search may be classi ed by the primitives used for indexing as text-based, tree-based, and spectral [17]. Detailed analysis of existing methods can be found elsewhere [3].",null,null
29,"Text-Based Approaches. Formulae are converted to a sequence of tokens using linearization of formula trees. To increase the likelihood of nding matches, some methods use canonicalization to simplify expressions, and to identify commutative operators and equivalences [8, 12]. It is also common to enumerate identi ers to support generalized variable matching and/or uni cation [2, 12­14].",null,null
30,1h ps://cs.rit.edu/ dprl/So ware.html#tangent,null,null
31,1165,null,null
32,Short Research Paper,null,null
33,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
34,"Converting math to text allows use of existing optimizations in text search engines, such as ranking by TF-IDF [10], topic modeling, and word embedding [13].",null,null
35,"Tree-Based Approaches. ese approaches index formulas as complete SLTs or OPTs. Typically, the hierarchical structures in formulae are mapped directly, and organized within tree-based indexing structures [4, 6, 18]. In these approaches, all subexpressions in formulae are indexed to support partial matching, with common subexpressions labeled and shared to reduce index sizes [6].",null,null
36,"Spectral Approaches. Here paths in OPTs/SLTs or features extracted from trees are used as retrieval primitives. Simpler primitives allow more partial matches, increasing recall. Path-based methods store sets of paths from the root to internal nodes [5] and leaves [18]. Paths may re ect operator commutativity by inserting symbols [18] or using unordered paths [7]. Some use hashing to encode subtrees [7, 11]. In Tangent-3 SLT symbol pairs along with their relative paths are used to index math expressions [1, 17].",null,null
37,"In this work, we extend the Tangent-3 system [17] to retrieve formulae using both SLTs and OPTs, and make additional improvements detailed below.",null,null
38,3 METHODOLOGY,null,null
39,"Tangent-3 [17] retrieval model has two stages, one for fast candidate selection using spectral matching, and the second for re-ranking top-k candidates. We add a third stage, using a linear combination of similarity scores computed from the second layer to produce a nal re-ranking of the top-k candidates. Rather than use a learning-to-rank technique [9], a simpler model was chosen for be er understanding of the relevance of each similarity factor.",null,null
40,3.1 Formula Representation,null,null
41,"To de ne and constrain the behavior of matching and uni cation algorithms in SLTs and OPTs, we assign each symbol a type. Edges between symbols are labeled by their order in OPTs, or by the visual location of a child symbol with respect to its parent (e.g., for superscript relationships) in SLTs (see Fig. 1).",null,null
42,"Common Symbol Types. ese include: Variables, Numbers, Groups (matrices, vectors, sets, lists, ...), Functions, Operators, Text, White Space, ery Wildcard and Error (e.g., for parsing errors). Real data o en provides strong clues for symbol types, but in some cases symbol type can be hard to infer without context, leading to incorrect symbol types and invalid uni cations.",null,null
43,"Symbol Layout Trees. is representation is built around writing lines (baselines), leading to deep trees with few branches. e children of a node in this representation are assigned to a spatial relationship class (edge label): Next, Above, Pre-above, Below, Pre-Below, Over, Under, Within, and Element.",null,null
44,"Operator Trees. is representation is built around the hierarchy of operators in a formula, resulting in shallow trees with many branches. We distinguish between commutative operators (e.g., `+') and non-commutative operators (e.g., `-'). We ignore the order of children for commutative operators. In Figure 1.b, all edges to children of the equals sign have the same label.",null,null
45,3.2 Pair-based Index Model,null,null
46,"A symbol pair is represented by the tuple (A,D,R) where A and D are the ancestor and descendant symbols, and R is the sequence of edge labels in the path from A to D. We use an inverted index, with symbol tuples as keys, and each posting list storing references to formulae containing the tuple. We use independent formula indices for SLTs and OPTs. Two parameters control the symbol tuple generation process: a window size w and an End-of-Baseline (EOB)",null,null
47,"ag. Window size w de nes the maximum path length between an indexed symbol pair. If EOB is true, the system creates dummy pairs between the last symbol on each baseline and null, to help with matching small expressions (depth <, 2). Details may be found elsewhere [17].",null,null
48,3.3 Formula Retrieval,null,null
49,"Applying detailed similarity metrics can be prohibitively expensive. For this reason, a three-layer retrieval process is used.",null,null
50,"Layer 1: Initial Candidate Selection. Candidates are selected by matching query symbol tuples in the index. For each candidate, the harmonic mean of precision and recall of matched symbol tuples is used to assign an initial score [17].",null,null
51,"Layer 2: Structural Match Scoring. e largest connected match between the query and candidates is obtained using a greedy algorithm, evaluating pairwise alignments between trees. Symbols (nodes) of similar type are uni ed, and query wildcards are matched to subtrees. Connected matches may contain holes (unmatched intermediate nodes) as long as edge labels between tree structures always match. For SLTs, matching works mostly as de ned for Tangent-3 [1], except that we now restrict uni cation to occur between single character identi ers, or within identi ers with two or more characters, but not between these two groups. is mitigates the issue of spurious uni cation matches between variables and functions leading to bad candidates being ranked too high.",null,null
52,"For OPTs, the order of arguments for commutative operators is ignored to capture matches between equivalent expressions such as x + , 0 and 0 ,"" + x. However, testing all possible permutations of children at matching time has a factorial time complexity. We use a greedy pair-wise matching algorithm that considers all pair-wise alignments between children of matching commutative operators, and greedily chooses 1-to-1 matches between children maximizing the predicted number of matches a er uni cation, breaking ties by preferring alignments with more exact matches. While suboptimal, this greedy approach can still be computed in polynomial time and it allows us to match x + "", 0 and 0 , + x perfectly.",null,null
53,"e output of matching is a subtree of the candidate formula that has been successfully aligned to the query. For re-ranking, we use the same three structural matching scores from Tangent-3 [17]: Maximum Subtree Similarity (MSS), negative count of candidate nodes matched with uni cation, and negative count of query nodes matched without uni cation. To be er support linear regression, we replace the negative counts by the equivalent uni ed precision and recall without uni cation, producing the same lexicographic ordering as before using values in the range [0, 1]. e recall and precision computed here di er from those used by other formula retrieval methods, in that they are computed from subtrees a er matching constraints are enforced.",null,null
54,1166,null,null
55,Short Research Paper,null,null
56,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
57,Table 1: NTCIR-12 optional MathIR Wikipedia Formula Browsing Task. Average Precision@K per topic,null,null
58,Table 3: Average nDCG@K of ranks per topic for judged NTCIR-12 Wikipedia Formulae.,null,null
59,Method MCAT [7] Tangent-3 [1] Core Matching SLT Core Matching Regression OPT Core Matching Regression Combined,null,null
60,P@5 0.4900,null,null
61,0.4150 0.4450,null,null
62,0.4000 0.4550 0.3900,null,null
63,0.3650 0.3550 0.3150 0.4400,null,null
64,Relevant P@10 P@15 0.3900 0.3317,null,null
65,0.3150 0.2650 0.2925 0.2517,null,null
66,0.3025 0.3450 0.2900,null,null
67,0.2567 0.2817 0.2450,null,null
68,0.2550 0.2475 0.2475 0.3150,null,null
69,0.2050 0.2017 0.2000 0.2583,null,null
70,P@20 0.2825,null,null
71,0.2200 0.2200,null,null
72,0.2125 0.2462 0.2000,null,null
73,0.1700 0.1787 0.1700 0.2162,null,null
74,P@5 0.9100,null,null
75,0.8100 0.8250,null,null
76,0.7900 0.8350 0.6300,null,null
77,0.6250 0.5550 0.6250 0.7000,null,null
78,Partially Relevant P@10 P@15 0.8400 0.8067,null,null
79,0.7450 0.7117 0.6825 0.6533,null,null
80,0.7275 0.7725 0.5525,null,null
81,0.6950 0.7400 0.5117,null,null
82,0.4825 0.4400 0.4975 0.6075,null,null
83,0.4200 0.3800 0.4317 0.5550,null,null
84,P@20 0.7687,null,null
85,0.6737 0.6100,null,null
86,0.6562 0.6913 0.4675,null,null
87,0.3662 0.3425 0.3850 0.5112,null,null
88,Table 2: NTCIR-12 optional MathIR Wikipedia Formula Browsing Task. Average Bpref per topic.,null,null
89,Matches Relevant Partially Relevant,null,null
90,Core SLT OPT 0.4207 0.4227 0.5126 0.4241,null,null
91,Matching SLT OPT 0.4786 0.4760 0.5351 0.4206,null,null
92,Regression,null,null
93,SLT OPT Comb. 0.5240 0.5127 0.5530 0.5569 0.5492 0.5620,null,null
94,"Layer 3: Linear Regression. Using relevance judgments data from the NTCIR-12 Wikipedia Formula Retrieval task, we train a least squares linear regressor to combine the three scores from Layer-2 and produce a nal rank score. While more complex functions could have been used in this step, we choose a simple method to avoid over- ing the limited training data available, and to clearly observe which re-ranking scores best predict relevance.",null,null
95,"Combined SLT/OPT Retrieval Approach. We combine results from SLTs and OPTs in a simple way. First, we perform symbol pair-based retrieval within a separate index for each representation.",null,null
96,"e top-k candidates obtained from each index are merged into a single list. en, for each candidate we apply the detailed matching and scoring processes using both SLTs and OPTs representations, and we concatenate the similarity scores into a single vector. Finally, a linear regressor assigns a relevance score for the formula. In our experiments, we see that this simple combination obtains be er rankings than using scores from just SLTs or OPTs.",null,null
97,4 EXPERIMENTS,null,null
98,"To evaluate our approach, we use data from the NTCIR-12 MathIR competition [15]. Speci cally, we use data from the optional MathIR Wikipedia Formula Browsing Task which has a corpus of 319,689 articles from English Wikipedia with more than half a million formulae. e task has 40 topics for isolated formula retrieval: 20 are concrete (without wildcards) and 20 include wildcards. Each wildcard query is a derived from a concrete query, with portions of the concrete query replaced by wildcards.",null,null
99,"At NTCIR-12, the top-20 results for each topic from 8 submissions were evaluated for relevance. Each result was assessed by two human evaluators who scored them from 0 (irrelevant) to 2 (relevant). ese scores were combined and each formula has a",null,null
100,nal relevance score between 0 and 4. A total of 2687 relevance assessments were produced by this method.,null,null
101,"We evaluated the ranks produced by the model for each representation (SLT, OPT) at each retrieval stage (Core, Matching, Regression).",null,null
102,"e combined SLT/OPT approach (Section 3.3) is also considered, for a total of seven conditions. At the rst stage, we select the",null,null
103,Condition SLT Core Matching Regression OPT Core Matching Regression Combined,null,null
104,All Topics @5 @20,null,null
105,0.7109 0.7534 0.7943,null,null
106,0.7002 0.7218 0.7723,null,null
107,0.6978 0.7459 0.7519 0.8136,null,null
108,0.7184 0.7446 0.7331 0.7908,null,null
109,Concrete Only @5 @20,null,null
110,0.7991 0.8033 0.8031,null,null
111,0.7727 0.7776 0.7958,null,null
112,0.7889 0.7889 0.8008 0.8131,null,null
113,0.7891 0.8018 0.7773 0.8088,null,null
114,Wildcard Only @5 @20,null,null
115,0.6236 0.7036 0.7855,null,null
116,0.6277 0.6659 0.7488,null,null
117,0.6066 0.7028 0.7031 0.8141,null,null
118,0.6478 0.6874 0.6888 0.7728,null,null
119,"top 1000 candidates for each query using w , All (all tuples) and EOB ,"" True. Given the limited number of relevance assessments available, for conditions using Linear Regression we grouped each concrete query with its corresponding wildcard version, and created 20 data folds. We then used cross-validation, repeatedly using one fold to test and the remaining 19 folds to train a linear regressor, until all queries have been processed.""",null,null
120,"Table 1 compares our three-stage ranking systems, and systems participating in the NTCIR-12 competition. We used the TREC eval tool to compute the values of Precision@K with K in {5, 10, 15, 20}. Unlike the Tangent-3 submissions at NTCIR-12 [1], we ensured that the lexicographic order used for ranking a er structural matching (the Matching conditions) was preserved by the TREC eval tool, by computing the ranks produced by the xed-order MSS and tie breaker scores, and then using the reciprocal rank (1/r ) of each score vector as the nal score. Formulae with identical score vectors are re-ranked by the TREC eval tool based on document id.",null,null
121,"Mainly because of a large number of unrated formulas that are unfairly assumed to be irrelevant, Precision@K scores for the proposed conditions, specially the OPT-based, are lower than those for systems in the competition, with the exception of SLT Matching which are higher than Tangent-3 Matching. However, Tangent-S is simpler and faster than MCAT [1, 7], the best performing system in the competition.",null,null
122,"e binary preference (Bpref) metric ignores unrated matches, and quanti es the ability of the ranking method to keep judged relevant matches ranked higher than irrelevant ones. Table 2 shows a comparison of Bpref values across di erent conditions of our own method. Unfortunately, Bpref values are not available for the original systems in the competition.",null,null
123,"In terms of Bpref, we can see that in most cases the values increase at each layer of the retrieval model. For partially relevant results, with SLTs Bpref goes from 0.4207 in the initial set of candidates to 0.5240 a er using linear regression, and from 0.4227 to 0.5127 for OPTs. When SLT and OPT scores are combined, Bpref increases to 0.5530. is con rms that each step of the pipeline improves the quality of the produced ranks, and that combining representations helps.",null,null
124,"As the number of expressions judged per topic is relatively small, and given that our new conditions produce many unrated results in the top-20, we have used a di erent approach to further analyze the rankings produced. We re-ranked all judged formulas for each topic using each stage of our retrieval model, and we compared these ranks against the ideal rankings using nDCG@K with K ,"" {5, 20} as shown in Table 3. Consistently, the Matching stage improves the""",null,null
125,1167,null,null
126,Short Research Paper,null,null
127,"SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan",null,null
128,Table 4: Top-5 formula results for ery-12 for each ranking stage for each representation,null,null
129,Core,null,null
130,1. O (mn log m) 2. O (mn) 3. O (mnp ) 4. O (m + log n),null,null
131, 5. O m n log n,null,null
132,S,null,null
133,L,null,null
134,T,null,null
135,Matching,null,null
136,"O (mn log m) O (V E log V ) O(V ElogV log (V C )) O (T m) , O n2m log n O (nk log k )",null,null
137,Regression,null,null
138,"O (mn log m) O (mn log p ) , O (n log n)",null,null
139,"O (mn) , O n3 log n",null,null
140,O d 5n log3 B,null,null
141,O,null,null
142,mnr 2,null,null
143,log,null,null
144,1 ,null,null
145,12: O (mn log m),null,null
146,O,null,null
147,T,null,null
148,Core,null,null
149,O (mn log m) O (mn) O (mnp )  (mnp ) O (mr ),null,null
150,Matching,null,null
151,O (mn log m) O (nk log (n)) O (V E log V ) O (n log n) O (nk log k ),null,null
152,Regression,null,null
153,"O (mn log m) O (mn log p ) , O (n log n)",null,null
154,O,null,null
155,mnr 2,null,null
156,log,null,null
157,1 ,null,null
158,O (pn (m+n log n)),null,null
159,"O (T m) , O n2m log n",null,null
160,Combined,null,null
161,Regression,null,null
162,"O (mn log m) O (mn log p ) , O (n log n)",null,null
163,"O M (m) log2 m , O (M (n) log n)",null,null
164,O,null,null
165,mnr 2,null,null
166,log,null,null
167,1 ,null,null
168,"O (mn) , O n3 log n",null,null
169,"ranking quality produced by the initial spectral symbol pair matching for both representations. While linear regression consistently increases nDCG for SLTs, it produces a small decrease for OPTs compared to the lexicographic order of the same scores from the Matching stage. is may be due to a greater collinearity between Recall of nodes and MSS in the OPT space. In general, nDCG values for Concrete topics are higher than for the Wildcard topics. In the current matching procedure, we have observed that allowing Wildcards to match subtrees in the presence of poor uni cations can cause bad partial matches to be ranked high.",null,null
170,"An analysis of relevance against similarity scores reveals that while the means of MSS and node recall increase with the relevance of judged matches on both representations, node precision a er uni cation is not well correlated with relevance and might hurt linear regression predictions and even re-ranking in general. is is not surprising since some bad partial matches have low recall but high precision. For example, a single query wildcard can be matched to an entire arbitrary expression tree with perfect precision.",null,null
171,"Table 4 illustrates the di erences in the Top-5 ranks for each stage of the model for the query O (mn log m), for both SLTs and OPTs. Di erences in structure for each representation change the initial set of candidates extracted from the collection. e Matching columns show how the uni cation process helps in increasing the rank of partial matches that become exact a er uni cation. is query illustrates how linear regression can sometimes produce less intuitive rankings than the simpler lexicographic match score ordering. It also shows how the OPT representation can give be er rankings to equivalent expressions that have a slightly di erent layout like the candidate O (nk log (n)) a er uni cation.",null,null
172,"It is important to acknowledge noise in the NTCIR-12 formula data. Many expressions are incorrectly but consistently converted into Content MathML from LATEX. For example, the sub expression f (x ) is almost always converted to the tree corresponding to f × x. Such errors in the source can lead to many undesirable partial matches for OPTs at retrieval time.",null,null
173,5 CONCLUSIONS,null,null
174,"We have presented a comparison of the performance for two math expression representations using a three-layer retrieval model. We also presented a simple way to combine Symbol Layout Tree (SLT) and Operator Tree (OPT) representations into a single retrieval model. Overall, this combined model produced be er rankings than the individual representations. Our results suggest that additional restrictions are needed for uni cation, to prevent undesirable matches and resulting rankings. In this study, we simply used the similarity scores proposed in the original retrieval model that we",null,null
175,"extended. However, the method proposed here may be used to in-",null,null
176,corporate and study additional similarity scores that may be be er,null,null
177,"predictors for relevance (e.g., symbol and structure recall before",null,null
178,uni cation). Similarity scores can also be combined with non-linear,null,null
179,models for more accurate candidate selection and relevance predic-,null,null
180,"tion, while maintaining fast retrieval.",null,null
181,ACKNOWLEDGMENTS,null,null
182,We thank Frank W. Tompa and the reviewers for their valuable feed-,null,null
183,back. is material is based upon work supported by the National,null,null
184,Science Foundation (USA) under Grant No. HCC-1218801.,null,null
185,REFERENCES,null,null
186,"[1] Kenny Davila, Richard Zanibbi, Andrew Kane, and Frank Wm Tompa. 2016. Tangent-3 at the NTCIR-12 MathIR task. In Proc. NTCIR-12. 338­345.",null,null
187,"[2] Liangcai Gao, Ke Yuan, Yuehan Wang, Zhuoren Jiang, and Zhi Tang. 2016. e math retrieval system of ICST for NTCIR-12 MathIR task. Proc. NTCIR-12 (2016), 318­322.",null,null
188,"[3] Ferruccio Guidi and Claudio Sacerdoti Coen. 2015. A survey on retrieval of mathematical knowledge. In Proc. CICM. Springer, 296­315.",null,null
189,"[4] Radu Hambasan, Michael Kohlhase, and Corneliu-Claudiu Prodescu. 2014. MathWebSearch at NTCIR-11. In Proc. NTCIR-11. 114­119.",null,null
190,[5] H. Hiroya and H. Saito. 2013. Partial-match Retrieval with Structure-re ected Indices at the NTCIR-10 Math Task. In Proc. NTCIR-10. 692­695.,null,null
191,"[6] Shahab Kamali and Frank Wm Tompa. 2013. Structural similarity search for mathematics retrieval. In Intelligent Computer Mathematics, LNCS vol. 7961. Springer, 246­262.",null,null
192,"[7] Giovanni Yoko Kristianto, G Topic´, and A Aizawa. 2016. e MCAT math retrieval system for NTCIR-12 MathIR task. In Proc. NTCIR-12. 323­330.",null,null
193,"[8] Xiaoyan Lin, Liangcai Gao, Xuan Hu, Zhi Tang, Yingnan Xiao, and Xiaozhong Liu. 2014. A Mathematics Retrieval System for Formulae in Layout Presentations. In SIGIR. ACM, New York, NY, USA, 697­706.",null,null
194,"[9] Tie-Yan Liu. 2009. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval vol. 3 (2009), 225­331.",null,null
195,"[10] Bruce R Miller and Abdou Youssef. 2003. Technical aspects of the digital library of mathematical functions. Annals of Mathematics and Arti cial Intelligence vol. 38, 1-3 (2003), 121­136.",null,null
196,"[11] Shunsuke Ohashi, Giovanni Yoko Kristianto, Goran Topic´, and Akiko Aizawa. 2016. E cient Algorithm for Math Formula Semantic Search. IEICE TRANSACTIONS on Information and Systems 99, 4 (2016), 979­988.",null,null
197,"[12] M Ru^zicka, Petr Sojka, and M Liska. 2016. Math indexer and searcher under the hood: Fine-tuning query expansion and uni cation strategies. In Proc. NTCIR-12. 331­337.",null,null
198,"[13] Abhinav anda, Ankit Agarwal, Kushal Singla, Aditya Prakash, and Abhishek Gupta. 2016. A document retrieval system for math queries. (2016), 346­353.",null,null
199,"[14] Ke Yuan, Liangcai Gao, Yuehan Wang, Xiaohan Yi, and Zhi Tang. 2016. A mathematical information retrieval system based on RankBoost. In Proc. JCDL. IEEE, 259­260.",null,null
200,"[15] Richard Zanibbi, Akiko Aizawa, Michael Kohlhase, Iadh Ounis, Goran Topic´, and Kenny Davila. 2016. NTCIR-12 MathIR Task Overview. In Proc. NTCIR-12. 299­308.",null,null
201,"[16] Richard Zanibbi and Dorothea Blostein. 2012. Recognition and retrieval of mathematical expressions. IJDAR 15, 4 (2012), 331­357.",null,null
202,"[17] Richard Zanibbi, Kenny Davila, Andrew Kane, and Frank Tompa. 2016. MultiStage Math Formula Search: Using Appearance-Based Similarity Metrics at Scale. SIGIR (2016), 145­154.",null,null
203,"[18] Wei Zhong and Hui Fang. 2016. OPMES: A Similarity Search Engine for Mathematical Content. In ECIR. Springer, 849­852.",null,null
204,1168,null,null
205,,null,null
