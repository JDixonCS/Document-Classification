,sentence,label,data
0,A Hybrid Model for Ad-hoc Information Retrieval,null,null
1,"Zheng Ye, Jimmy Xiangji Huang",null,null
2,Information Retrieval and Knowledge Management Research Lab,null,null
3,"School of Information Technology York University Toronto, Canada",null,null
4,"{yezheng, jhuang}@yorku.ca",null,null
5,Jun Miao,null,null
6,Information Retrieval and Knowledge Management Research Lab,null,null
7,"Department of Computer Science & Engineering York University Toronto, Canada",null,null
8,jun@cse.yorku.ca,null,null
9,ABSTRACT,null,null
10,"Many information retrieval (IR) techniques have been proposed to improve the performance, and some combinations of these techniques has been demonstrated to be effective. However, how to effectively combine them is largely unexplored. It is possible that a method reduces the positive influence of the other one even if both of them are effective separately. In this paper, we propose a new hybrid model which can simply and flexibly combine components of three different IR techniques under a uniform framework. Extensive experiments on the TREC standard collections indicate that our proposed model can outperform the best TREC systems consistently in the ad-hoc retrieval. It shows that the combination strategy in our proposed model is very effective. Meanwhile, this method is also re-useable for other researchers to test whether their new methods are additive to the current technologies.",null,null
11,Categories and Subject Descriptors,null,null
12,"H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback",null,null
13,General Terms,null,null
14,"Algorithms, Performance, Experimentation",null,null
15,Keywords,null,null
16,"Hybrid Model, Rocchio's Relevance Feedback",null,null
17,1. INTRODUCTION,null,null
18,"In the past thirty years, researchers make great progress in the Information Retrieval (IR) area. A plenty of new technologies, e.g., stemming, query expansion and smoothing methods, have been introduced and help to obtain better performance in retrieving relevant documents. Some attempts to combine these technologies show that the strategy of combination is very important because one technology can counteract the affects of others. However, how to make an effective combination is still largely unexplored, especially under a unified framework.",null,null
19,"In this paper, we propose a hybrid model to incorporate three different retrieval techniques that have proven to be effective for the ad-hoc retrieval on the TREC collections.",null,null
20,"Copyright is held by the author/owner(s). SIGIR'12, August 12­16, 2012, Portland, Oregon, USA. ACM 978-1-4503-1472-5/12/08.",null,null
21,"We analyze the best TREC systems for ad-hoc retrieval, and extend the Rocchio's feedback method by incorporating three kinds of IR techniques, which are proximity, feedback document quality estimation and query performance prediction techniques, under the pseudo relevance feedback (PRF) framework to boost the overall performance. We mainly focus on how to refine the representation of the query under the PRF framework in order to avoid the drawbacks of traditional PRF methods. Experimental results on various TREC datasets show that our hybrid model consistently obtains better results over the best TREC systems. Because our proposed model is component-based, it is very flexible to import different techniques in the future. Meanwhile, the hybrid model can help researchers to test whether their methods are additive to improve the overall performance of ad-hoc retrieval which was mentioned in [1].",null,null
22,2. A HYBRID RETRIEVAL MODEL,null,null
23,"Rocchio's algorithm [4] is a classic framework for implementing (pseudo) relevance feedback via improving the query representation. When the negative feedback documents are ignored, the traditional Rocchio's model is as follows:",null,null
24,r,null,null
25,"Q1 ,   Q0 +  ",null,null
26,|R|,null,null
27,(1),null,null
28,rR,null,null
29,"where Q0 and Q1 represent the original and first iteration query vectors, R is the set of (pseudo) relevance documents, and r is the expansion term weight vector.",null,null
30,"Although the Rocchio's model has been introduced for many years, it is still effective in obtaining relevant documents. According to [7], ""BM25 term weighting coupled with Rocchio feedback remains a strong baseline which is at least as competitive as any language modeling approach for many tasks"". Meanwhile, it is very flexible to adapt additional components. However, the traditional Rocchio's model can still be reformed to be better. First, the query term proximity information which has proven to be useful is not considered. Second, Rocchio's algorithm views terms from different feedback documents equally. Intuitively, a candidate expansion term in a document with better quality is more likely to be relevant to the query topic. Third, the interpolation parameter  is always fixed across a group of queries. In fact, for a well expressed query, the candidate feedback documents are always more reliable for relevance feedback. In this paper, we use a regression model to predict this interpolation parameter. In order to alleviate influence of these problems, we extend Rocchio's algorithm which re-",null,null
31,1025,null,null
32,"Table 1: Direct comparison with the best MAP results in each TREC year. In the Hybrid (Fixed) method, proximity and",null,null
33,"feedback document quality are utilized. In the Hybrid (Regression) method, all the three techniques are adapted. A ""*""",null,null
34,indicates a statistically significant improvement when a component technique is added in our algorithm.,null,null
35,Method,null,null
36,TREC1 TREC2 TREC3 TREC6 TREC7 TREC8 TREC2004 TREC2005,null,null
37,BM25 BM25+Prox Hybrid-Fixed Hybrid-Reg,null,null
38,0.2292 0.2461 0.2938,null,null
39,0.3012,null,null
40,0.2058 0.2111 0.2913,null,null
41,0.2971,null,null
42,0.2787 0.2929 0.3811 0.3912,null,null
43,0.2397 0.2507 0.2763 0.2886,null,null
44,0.1819 0.1936 0.2576,null,null
45,0.2611,null,null
46,0.2471 0.2582 0.2909 0.3103,null,null
47,0.2672 0.3148 0.3375 0.3431,null,null
48,0.3403 0.3661 0.4083 0.4193,null,null
49,BEST TREC 0.2062 0.2475 0.3231 0.2876 0.2614 0.3063,null,null
50,0.3052,null,null
51,0.4056,null,null
52,TREC2006,null,null
53,0.2965 0.3459 0.3944,null,null
54,0.3921,null,null
55,0.3737,null,null
56,fines the query representation as follows.,null,null
57,"Q1 ,   (  Q0 + (1 - )  Qp) + (1 - ) ",null,null
58,r  q(dr) (2) |R|,null,null
59,rR,null,null
60,"where  controls how much we rely on the query term proximity information [5],  controls how much we rely on the original query, Qp is an n-gram of original query terms and q(dr) is the quality score of document d.",null,null
61,"As we can see from Equation 2, our proposed algorithm is very flexible and can evaluate different techniques. In this paper, we adopt the co-occurrence interpretation of term proximity to compute Qp, where the proximity among query terms is represented by the n-gram frequencies and BM25 is used as the weighting model [2].",null,null
62,"Full dependencies of query terms are taken into account. For the document quality factor q(dr), we simple use the scores from the first-pass retrieval for approximation as in [6]. For the prediction to , we use the same features as in [3] to train the regression model. The difference is that we do it within Rocchio's framework.",null,null
63,3. EXPERIMENTS AND ANALYSIS,null,null
64,"We conduct experiments on three representative test collections: disk1&2, disk4&5, and GOV2, which are used in different TREC years. We present the results for each TREC year such that we can directly compare our results with the best TREC systems. Detailed information about the TREC datasets and the evaluation criteria, please refer to http://trec.nist.gov. For the preprocessing of the collections, we use the Porter Stemmer and a stopword list. In addition, we only use the title part of the topics to retrieve.",null,null
65,"In our experiments, we first empirically evaluate different combinations of our implemented component techniques, then evaluate how these techniques perform when they are integrated in our hybrid model. We set the parameters to fixed values in a parsimonious way such that each component technique gets considerable improvements on most collections. In other words, there is still room for improvement if the parameters are tuned on a collection-by-collection basis. Particularly, for the basic retrieval model, we use the Okapi BM25 model, and set b in BM25 to 0.3. When only the query term proximity technique is added, denoted as ""BM25+Prox"", we set  to 0.3. In addition, when query expansion and document quality estimation techniques are added, denoted as ""Hybrid-Fixed"", we empirically set , |R| to 0.5 and 30. However, when the query performance prediction technique is used, denoted as ""Hybrid-Reg"",  is not fixed. But it is obtained from a regression model that is trained as in [3]. When evaluating our hybrid model for a particular TREC year, the queries in the remainder TREC years on the same collection are used as training data.",null,null
66,"From Table 1, we can see that our hybrid model with different component techniques can significantly outperforms",null,null
67,"the basic retrieval model, which reconfirms the effectiveness of these techniques. In addition, when all these component techniques are used in our hybrid model, the retrieval performance can be further improved. It indicates that performance gains from these two component techniques can be added up in our proposed hybrid model. However, when we use a regression component to predict , the performance gain is not very obvious compared with other components. We conjecture the main reason is as follows: when the feedback document set is more reliable for relevance feedback, the regression component is less useful.",null,null
68,"When compared with the best TREC systems, our proposed model obviously outperforms the best TREC systems on most collections . It is of note that the results in our paper are obtained in a uniform setting across all collections while the best TREC results were from different participants independently. We believe the significant improvement is mainly from our successful integration of different IR techniques in the proposed model. In addition, according to Armstrong et al.'s survey, very few published results are better than the best TREC systems, mostly below medium systems. Our proposed model is promising, which provides a good avenue for future IR research, especially for evaluating the overall performance of a system (not a particular component of a system).",null,null
69,4. CONCLUSIONS,null,null
70,"In this paper, we propose a hybrid model which can successfully integrate three effective techniques in a uniform model. Extensive experiments show that our approach obviously outperforms the best TREC systems in most cases. In the future, we will investigate more effective techniques in IR and incorporate them into our framework to conduct this research in details.",null,null
71,5. ACKNOWLEDGMENTS,null,null
72,"This research is supported by the research grant from the Natural Sciences & Engineering Research Council (NSERC) of Canada and the Early Researcher Award/ Premier's Research Excellence Award, Zhejiang Provincial Natural Science Foundation, Q12F020016.",null,null
73,6. REFERENCES,null,null
74,"[1] T. G. Armstrong, A. Moffat, W. Webber, and J. Zobel. Improvements that don't add up: ad-hoc retrieval results since 1998. In CIKM, pages 601­610, 2009.",null,null
75,"[2] B. He, J. X. Huang, and X. Zhou. Modeling term proximity for probabilistic information retrieval models. Inf. Sci., 181(14):3017­3031, 2011.",null,null
76,"[3] Y. Lv and C. Zhai. Adaptive relevance feedback in information retrieval. In CIKM, pages 255­264, 2009.",null,null
77,"[4] J. Rocchio. Relevance feedback in information retrieval, pages 313­323. Prentice-Hall Englewood Cliffs, 1971.",null,null
78,"[5] C. J. van Rijsbergen. A theoretical basis for the use of co-occurence data in information retrieval. Journal of Documentation, 1977.",null,null
79,"[6] Z. Ye, B. He, X. Huang, and H. Lin. Revisiting rocchio's relevance feedback algorithm for probabilistic models. In AAIRS, pages 151­161, 2010.",null,null
80,"[7] C. Zhai. Statistical language models for information retrieval a critical review. Found. Trends Inf. Retr., 2:137­213, 2008.",null,null
81,1026,null,null
82,,null,null
