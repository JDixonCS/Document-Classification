,sentence,label,data
,,,
0,Efficient Partial-Duplicate Detection Based on Sequence Matching,null,null
,,,
1,"Qi Zhang, Yue Zhang, Haomin Yu, Xuanjing Huang",null,null
,,,
2,"School of Computer Science, Fudan University 825 Zhangheng Road, Shanghai, P.R.China",null,null
,,,
3,"{qi_zhang, 09210240052, 09210240086, xjhuang}@fudan.edu.cn",null,null
,,,
4,ABSTRACT,null,null
,,,
5,"With the ever-increasing growth of the Internet, numerous copies of documents become serious problem for search engine, opinion mining and many other web applications. Since partial-duplicates only contain a small piece of text taken from other sources and most existing near-duplicate detection approaches focus on document level, partial duplicates can not be dealt with well. In this paper, we propose a novel algorithm to realize the partial-duplicate detection task. Besides the similarities between documents, our proposed algorithm can simultaneously locate the duplicated parts. The main idea is to divide the partial-duplicate detection task into two subtasks: sentence level near-duplicate detection and sequence matching. For evaluation, we compare the proposed method with other approaches on both English and Chinese web collections. Experimental results appear to support that our proposed method is effectively and efficiently to detect both partial-duplicates on large web collections.",null,null
,,,
6,Categories and Subject Descriptors,null,null
,,,
7,"H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - Information Search and Retrieval; H.3.7 [Digital Libraries]: Collection, Systems Issues",null,null
,,,
8,General Terms,null,null
,,,
9,"Algorithms, Experimentation.",null,null
,,,
10,Keywords,null,null
,,,
11,"Partial-Duplicate Detection, Sequence Matching, MapReduce",null,null
,,,
12,1. INTRODUCTION,null,null
,,,
13,"Because of the explosion of Internet and the fact that digital documents can be easily replicated, enormous duplicated web pages and mirrored documents cause serious problem",null,null
,,,
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10, July 19­23, 2010, Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",null,null
,,,
15,"for search engine, product review, and many other Web applications. Along with the increasing requirements, nearduplicate detection has received much attentions in recent years [24, 25, 11, 26, 20].",null,null
,,,
16,"Existing studies on near-duplicate detection usually focus on the whole document level to figure out web pages that have the same content but only differ in the framing, navigation bar, advertisements, footer, and so on. Thus there are several factors that can not be well processed by existing methods.",null,null
,,,
17,"Collection: Figure 1 shows a pair of Web pages1 2 which both of contain the article ""Droid is No. 2 in Android traffic: Admob"". Besides this article, the page in Figure 1.(a) contains another nine related ones. Thus, the similarity between the pages in Figure 1.(a) and (b) is low in the document level.",null,null
,,,
18,"Multiple-page: In order to facilitate user's browsing, some articles are divided into multiple pages. Websites may use different strategies to split articles. Moveover, a number of websites may display the article in one page according to their own styles. It also leads to the similarities between the pages are low in document level.",null,null
,,,
19,"Threads in Forum: Millions of people contribute more than 10 gigabytes content everyday through forums, blogs and other consumer-generated mediums [21]. However, user generated content often contains a couple of sentences/pragraphs copied from news sites or other users [14]. Since the duplications are usually only a small piece of text, they can not be effectively detected by existing methods.",null,null
,,,
20,"Besides the factors listed above, there are a number of problems like, plagiarize sentences, non-cleaned web pages, sentences/paragraphs quotation, can also be generalized to partial duplicate. If a pair of documents are partial-duplicate with each other, it means they contain a number of sentences or paragraphs with similar content. With requirements of applications such as plagiarism detection, information flow tracking, opinion mining, and so on, partial-duplicate detection task is proposed and studied in this paper. Local text reuse detection [23] can be used to partially address this task. However, we argue that only similarities and category types do not provide sufficient information for all applica-",null,null
,,,
21,1http://iphandroid.com/ 2http://www.chinapost.com.tw/business/companyfocus/2009/11/25/234147/Droid-is.htm,null,null
,,,
22,675,null,null
,,,
23,tions and are not convenient enough for user to easily find the duplications in dozens of lines.,null,null
,,,
24,Type here your search,null,null
,,,
25,Home,null,null
,,,
26,DroidisNo. 2in Andoridtraffci: Amdo b,null,null
,,,
27,"Posted Novemb er24,2009 ­ 9:39pm in:Android Updates",null,null
,,,
28,"MotorolaInc.'s Droid handled the snedc-o largest share of traffciamong mo bile phones equippde withGoogleInc.'s Android operating systemtwo weeks after the nhdaset's introduction, according toma rket researcherAdmo b Inc.",null,null
,,,
29,Share,null,null
,,,
30,"Droid,introduced on Nov.6 to comp ete againstApple In.c's iPhone and Research InMotionLtd.'s BalckBerry,had 24 percentofallrequestsfrom Android phonesasofNov.18,according toestima tesby teh San Mateo, Calfiorni-abased resaerch firm.",null,null
,,,
31,"That's second toHTC Corp.'sDream phone taht handled 36 percent oAfndroid traffci, according to Amdo b,which cmop iels thedatafrom requestsfor asdon its neotrwk ofmo bile Web sitesand iPhone and Android applications.",null,null
,,,
32,Motorolaintroduced theDroid tomeetdema nd for smart phones tahtallowuserstobrowse the,null,null
,,,
33,(a),null,null
,,,
34,Subcrbie vaiRSS,null,null
,,,
35,Subcrbie via Em ail,null,null
,,,
36,Blac k Fr id ay Amaz in g Dea l Hu rry and check out these am azing Black Friday deals for Ch ristma s ww w.am azon.com,null,null
,,,
37,"Make Mo ne y Fr om 3G Ap ps Profitfrom the 3G APPS trend, create apps & ma ke mo ney today www. appleipho neapps.co.uk",null,null
,,,
38,3G Millio na ir es Club EasilyJointhem Today CreatingSelling3G apps Huge Cash Income 3 g-appcash.co m,null,null
,,,
39,"Yo ur Smartp ho ne , Ho ts po t Turn your Wind ow s Mob ilephone intoan internet Ho tspot.Try for free! ww w.WM WifRio uter.com",null,null
,,,
40,Categoreis,null,null
,,,
41,AndroidUpdates iPhandroid News iPhone Updates,null,null
,,,
42,Monthly archives,null,null
,,,
43,Nov-09,null,null
,,,
44,News Opinion Taiwan Living Learn English The China Post Subscribe,null,null
,,,
45,RSS Feeds,null,null
,,,
46," Search

Business
Updated Wednesday, November 25, 2009 11:00 am TWN, By Jason Clenfield, Bloomberg
Droid is No. 2 in Android traffic: Admob

Motorola Inc.'s Droid handled the second-largest share of traffic among mobile phones equipped with Google Inc.'s Android operating system two weeks after the handset's introduction, according to market researcher Admob Inc.

Le ar n Chin es e On li ne 1,300+ audio and video lessons Speaking practice by phone Ch inesePo d.co m

~¢...

g

 ´,,·­ ~ R ,, ... ¨,,¨

¤

www .MarsEnglihs.cn

In du ct io n Ligh ti ng SO LARA Probably themo st environm entallamp inthe wo rld www .amk o.com.tw/SOL AR A

Droid, introduced on Nov. 6 to compete against Apple Inc.'s iPhone and Research In Motion Ltd.'s BlackBerry, had 24 percent of all requests from Android phones as of Nov. 18, according to estimates by the San Mateo, California-based research firm.
That's second to HTC Corp.'s Dream phone that handled 36 percent of Android traffic, according to Admob, which compiles the data from requests for ads on its network of mobile Web sites and iPhone and Android applications.

Motorola introduced the Droid to meet demand for smart phones that allow users to browse the Internet, send e-mails and download software, the fastest-growing part of the mobile-phone industry.

(b)

Global Markets Asia Americas Europe Middle East Africa
Company Focus Breaking News Updated Wednesday, November 25, 2009 11:40 am TWN
Toyota said to plan moving some U.S. jobs from Calif. Cadbury shares rise on report of Nestle interest

Figure 1: Examples of partial-duplicate web pages

In this paper, we present an efficient algorithms for detecting partial-duplicates and locating their positions. Figure 2 shows an example on partial-duplicates. As shown in the graph, a sequence of sentences in Page A are similar with a number of sentences in Page B. Page A and C also contains duplicated text. From these pairs, we try to get the following results:
· Page A (Seni to Senj) Page B (Senk to Senl).
· Page A (Senm to Senn) Page C (Senp to Senq).
Since the proposed method can not only detect duplicates but also locate their positions, the near-duplicates of the whole document level can also be precisely detected. As the Web collections contain hundreds of millions pages, the algorithm is explored with MapReduce [8], which is a framework for large-scale distributed computing. We implement our method and compare it with the state-of-the-art approaches on four web collections and one manually constructed evaluation corpus. The experimental results show that it achieves good performance, both effectiveness and efficiency are significantly improved.
The contributions of this work are as follows: 1) We convert the partial-duplicate detection task into sentence level near-duplicate detection task and sequence matching task. 2) In order to handle hundreds of millions documents, the algorithm is designed and implemented under the MapReduce framework. 3) Shingles, I-Match, and Spotsigs are compared and evaluated in experiments, and experimental analyses of the signatures for sentences are provided. 4) Evaluations on manually labeled Oracle Set"" and four large web collections are used to measure the effectiveness and efficiency.",null,null
,,,
47,"The remaining of the paper is organized as follows: In section 2, we review a number of related work and the stateof-the-art approaches in related areas. Section 3 provides an brief introduction of MapReduce. Section 4 presents the proposed method. Experimental results in test collections",null,null
,,,
48,"2,CA)",null,null
,,,
49,"2,CA*",null,null
,,,
50,"2,CA+",null,null
,,,
51,Figure 2: Partial-duplicate content,null,null
,,,
52,and analyses are shown in section 5. Section 6 concludes this paper.,null,null
,,,
53,2. RELATED WORK,null,null
,,,
54,"Near-duplicate detection has received considerable attentions over the past several years. Previous studies on duplicate and near-duplicate detection can be roughly divided into two research directions: document representation and efficient detection. The first one focuses on representing documents with or without linguistic knowledge. Since collection contains hundreds of millions of documents, the second one, efficiency, has also received lots of attentions. This section introduces related approaches briefly.",null,null
,,,
55,"Broder [3] defined the resemblance and containment between two documents. He used shingles to represent documents and Jaccard overlap to calculate the similarity between documents. In order to reduce the complexity of shingling, Broder [4] proposed to use meta-sketches for this task.",null,null
,,,
56,"Indyk and Motwani[15] proposed the notion of localitysensitive hashing and applied it to sublinear-time similarity searching. LSH maintains a number of hash tables, which each of is parameterized by the number of hashed dimensions. Points close to each other in some metric space have the same hash value with high probability. Gionis et al. [11] also used LSH for approximate similarity search.",null,null
,,,
57,I-Match [7] hinges on the premise that removal of very infrequent terms and very common terms results in good document representations for the near-duplicate detection task. They filter the input document based on collection statistics and compute a single hash value for the remainder text. The documents with same hash value are duplicates.,null,null
,,,
58,"Schleimer et al. [22] proposed a local document fingerprinting algorithm, which is called winnowing. They described and analyzed the winnowing algorithm for selecting fingerprints from hashes of k-grams. They also presented the complexity of any local document fingerprinting algorithm and gave the non-trivial lower bound.",null,null
,,,
59,"Henzinger [13] performed an evaluation of Border et al.'s [4] shingling and Charikar's [6] random projection near-duplicate algorithms on 1.6B web pages. The results showed that neither of the algorithms works well for detecting near-duplicate pairs on the same site, while both of them achieve high precision for near-duplicate pairs on different sites.",null,null
,,,
60,"Manku et al. [19] proposed an approach for both online and batch types near-duplicate detection. They used Charikar's fingerprinting technique [6] and demonstrated it's effectiveness. They also presented an algorithmic technique for identifying existing f-bit fingerprints that differ from a given fingerprint in at most k bit-positions, for small k.",null,null
,,,
61,"Theobald et al. [26] presented their work SpotSigs, which combine stopword antecedents with short chains of adjacent content terms. Through demonstrating the upper bounds of Jaccard similarity, they also proposed several pruning conditions, which could ignore all pairs of documents safely during",null,null
,,,
62,676,null,null
,,,
63,the matching process when SpotSig vectors exceed a certain difference in length.,null,null
,,,
64,"Besides the approaches focused on Web pages or documents, Muthmann et al. [20] proposed their work to identify threads with near-duplicate content and to group these threads in the search results. They incorporated text-based features, features based on extracted entities for products, and structure-based features to capture the near-duplicate threads.",null,null
,,,
65,"Local text reuse detection proposed by Seo and Croft [23] is also related to our method. Different from duplicate detection, text reuse tries to capture the loose restatements of the information from the previous sources [2]. They defined six categories of text reuse and a general framework for text reuse detection. Several fingerprinting techniques for the framework were evaluated under the framework.",null,null
,,,
66,"Lin [18] explored the problem of pairwise similarity on large document collections and introduced three MapReduce algorithms to solve this problem, which are based on brute force, large-scale ad hoc retrieval, and the Cartesian product of postings lists. Different with us, the granularity of this work is also document level.",null,null
,,,
67,"Kolak and Schilit [16] described an approach to mine popularly quoted passages and add links among them on a digital library. They use shingle table method to find repeated sequences between different books. Since the storage complexity of shingle methods is huge and extracting shared shingles is timing consuming tasks, the method can not be directly used for partial-duplicate detection task.",null,null
,,,
68,"In order to handle hundreds of millions web collections, we also use MapReduce framework in this work, which is introduced by Dean and Ghemawat [8]. It is used an associated implementation for processing and generating large data sets. The MapReduce programming model has been successfully used at Google for many different purposes.",null,null
,,,
69,3. MAPREDUCE,null,null
,,,
70,"As number of data such as web pages, web request logs, and so on grows rapidly, applications have to be distributed across thousands of machines in order to finish in time. Bulk-synchronous parallel (BSP) model [27] and some higherlevel abstractions(MPI [12]) have been supported programmers to write parallel programs. However, because of its higher-level abstractions, programmers usually spend too much time on details. MapReduce [8], which is difference from these systems, exploits a restricted programming model to parallelize the user program automatically. And the transparent fault-tolerance and load balancing are also provided, because of the restrictions.",null,null
,,,
71,"The key concept behind MapReduce is inspired by the map and reduce primitives present in many functional languages. Dean and Ghemawat [8] presented the observation that most information processing computations share the same two-stage structure, which contains map and reduce operations. The map operation is applied to every logical ""record"" of input to compute a set of intermediate key/value pairs. Then the reduce operation is applied to all the values that shared the same key, in order to combine the derived data. Figure 3 shows the two-stage structure.",null,null
,,,
72,"Under this framework, the computation takes a set of input key/value pairs, and produces a set of output key/value pairs. A programmer only needs to implement two opera-",null,null
,,,
73,input input input input,null,null
,,,
74,map map map map,null,null
,,,
75,key-value pairs,null,null
,,,
76,key-value pairs,null,null
,,,
77,key-value pairs,null,null
,,,
78,key-value pairs,null,null
,,,
79,Group &,null,null
,,,
80,Sort,null,null
,,,
81,reduce reduce reduce,null,null
,,,
82,output output output,null,null
,,,
83,Figure 3: The basic structure of MapReduce,null,null
,,,
84,tions: map and reduce. The intermediate key/value pairs will be grouped and sorted by the key automatically.,null,null
,,,
85,"Many different implementations of MapReduce interface are available now. Google's MapReduce implementation is coupled with Google File System (GFS) [10], a kind of distributed file system. Apache's MapReduce implementation, Hadoop3, which follows the same architecture, uses a distributed file system named Hadoop Distributed File System (HDFS) to store data and the intermediate results. Hadoop tries to schedule the MapReduce computation tasks to the node where the data locates in order to reduce the overall network I/O. Besides Hadoop, MapReduce has also been implemented by many corporations, such as Greenplum, GridGain, Cell Broadband Engine, and so on.",null,null
,,,
86,"In this paper, we implement our algorithms under the open-source implementation Hadoop 0.20. HDFS is used to provide the distributed storage.",null,null
,,,
87,4. OUR APPROACH,null,null
,,,
88,"A partial-duplicate is a pairwise relationship. Given a pair of documents, we need to identify and locate the duplicated parts between them. To make questions simple, we limit granularity to sentence level. Based on this assumption, we propose the algorithm PDC-MR, which converts the partial-duplicate detection task into three MapReduce jobs (illustrated in Figure 4 and Figure 5).",null,null
,,,
89,"1) Indexing: We use a MapReduce job to build a standard inverted index [9] for collections. Signatures used as terms in the inverted index are extracted from each sentences in map procedure. The map procedures emit the signature as the key, and a tuple consists of the document id and sentence id. After grouping and sorting, the reduce procedures take the tuples as input and write out the inverted index to the disk. Since signatures would highly impact the final result, a detail description of it will be given in the Section 4.1.",null,null
,,,
90,"2) Sentence Duplication Detecting: Jaccard coefficient is used to measure the similarities between sentences. If the Jaccard similarity between a sentence pair is over a threshold, they are considered duplicates. Another MapReduce job is used to detect the sentence duplicates. The map procedures read the inverted index from disks and emit a pair of sentences which both contain a same signature as the key. After grouping and sorting, all signature ids belonging to the same sentence pair are brought together. The reduce procedures take them as inputs, and emit the sentence duplications. The procedure is shown in the right of Figure 4.",null,null
,,,
91,3http://hadoop.apache.org/,null,null
,,,
92,677,null,null
,,,
93,d 1,null,null
,,,
94,map,null,null
,,,
95,d 2,null,null
,,,
96,map,null,null
,,,
97,d 3,null,null
,,,
98,map,null,null
,,,
99,ds 11,null,null
,,,
100,ds 12,null,null
,,,
101,ds 13,null,null
,,,
102,ds 14,null,null
,,,
103,f ff 1 23,null,null
,,,
104,ff 3 4,null,null
,,,
105,fff 1 4 8,null,null
,,,
106,f 2,null,null
,,,
107,ds 21,null,null
,,,
108,ds 22,null,null
,,,
109,ds 23,null,null
,,,
110,ff 5 6,null,null
,,,
111,f ff 2 37,null,null
,,,
112,ff 1 4,null,null
,,,
113,ds 31,null,null
,,,
114,ds 32,null,null
,,,
115,ds 33,null,null
,,,
116,ds 34,null,null
,,,
117,f 8,null,null
,,,
118,f ff 3 79,null,null
,,,
119,ff 3 4,null,null
,,,
120,ff 2 10,null,null
,,,
121,Group &,null,null
,,,
122,Sort,null,null
,,,
123,f,null,null
,,,
124,ds ds ,null,null
,,,
125,1,null,null
,,,
126,11 13,null,null
,,,
127,f,null,null
,,,
128,ds ds ,null,null
,,,
129,2,null,null
,,,
130,11 14,null,null
,,,
131,f,null,null
,,,
132,ds ds ,null,null
,,,
133,3,null,null
,,,
134,11 12,null,null
,,,
135,f,null,null
,,,
136,ds ds ,null,null
,,,
137,4,null,null
,,,
138,12 13,null,null
,,,
139,f ds,null,null
,,,
140,5,null,null
,,,
141,21,null,null
,,,
142,f ds,null,null
,,,
143,6,null,null
,,,
144,21,null,null
,,,
145,f ds ds,null,null
,,,
146,7,null,null
,,,
147,22 32,null,null
,,,
148,f ds ds,null,null
,,,
149,8,null,null
,,,
150,31 13,null,null
,,,
151,f ds,null,null
,,,
152,9,null,null
,,,
153,32,null,null
,,,
154,f ds,null,null
,,,
155,10,null,null
,,,
156,34,null,null
,,,
157,reduce reduce reduce reduce reduce,null,null
,,,
158,f ds ds ,null,null
,,,
159,1,null,null
,,,
160,11 13,null,null
,,,
161,f,null,null
,,,
162,ds ds ,null,null
,,,
163,2,null,null
,,,
164,11 14,null,null
,,,
165,f,null,null
,,,
166,ds ds ,null,null
,,,
167,3,null,null
,,,
168,11 12,null,null
,,,
169,f,null,null
,,,
170,ds ds ,null,null
,,,
171,4,null,null
,,,
172,12 13,null,null
,,,
173,f ds,null,null
,,,
174,5,null,null
,,,
175,21,null,null
,,,
176,f ds,null,null
,,,
177,6,null,null
,,,
178,21,null,null
,,,
179,f ds ds,null,null
,,,
180,7,null,null
,,,
181,22 32,null,null
,,,
182,f ds ds,null,null
,,,
183,8,null,null
,,,
184,31 13,null,null
,,,
185,f ds,null,null
,,,
186,9,null,null
,,,
187,32,null,null
,,,
188,f ds,null,null
,,,
189,10,null,null
,,,
190,34,null,null
,,,
191,Indexing,null,null
,,,
192,map map map map map map map map map map,null,null
,,,
193,(d s d s ) 11 13,null,null
,,,
194,(d s d s ) 11 22,null,null
,,,
195,(d s d s ) 13 22,null,null
,,,
196,(d s d s ) 11 14,null,null
,,,
197,(d s d s ) 11 34,null,null
,,,
198,(d s d s ) 14 34,null,null
,,,
199,(d s d s ) 11 12,null,null
,,,
200,(d s d s ) 11 22,null,null
,,,
201,(d s d s ) 11 32 ,null,null
,,,
202,Group &,null,null
,,,
203,Sort,null,null
,,,
204,(d s d s ) 1 11 12,null,null
,,,
205,(d s d s ) 1 11 13,null,null
,,,
206,(d s d s ) 1 11 14,null,null
,,,
207,(d s d s ) 0 11 21,null,null
,,,
208,(d s d s ) 2 11 22,null,null
,,,
209,(d s d s ) 1 11 23,null,null
,,,
210,(d s d s ) 0 11 31,null,null
,,,
211,(d s d s ) 1 11 32,null,null
,,,
212,(d s d s ) 1 11 33,null,null
,,,
213,(d s d s ) 1 11 34,null,null
,,,
214,reduce reduce,null,null
,,,
215,Sentence Duplication Detecting,null,null
,,,
216,Figure 4: Detecting sentence duplication of a toy collection of 3 documents.,null,null
,,,
217,d 2,null,null
,,,
218,d 1,null,null
,,,
219,d 3,null,null
,,,
220,d 1,null,null
,,,
221,d 3,null,null
,,,
222,d 2,null,null
,,,
223,dj,null,null
,,,
224,S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S1,null,null
,,,
225,S2,null,null
,,,
226,S3,null,null
,,,
227,S4,null,null
,,,
228,di S5,null,null
,,,
229,S6,null,null
,,,
230,S7,null,null
,,,
231,S8,null,null
,,,
232,S9,null,null
,,,
233,Figure 5: The sequence matching strategy,null,null
,,,
234,"3) Sequence Matching: With the results of sentence duplicate detection, matrixes representing sentence duplicates for each pair of documents are generated. Figure 5 shows an example of the sentence duplicates between page di and page dj. The dot plots in the figure represents duplicated sentence pairs. The sequences of duplicated sentences are partial duplications we try to extract and locate. Based on that, the problem can be straightly converted to the sequence matching task, which aims to find all diagonals in the matrix. We also use a MapReduce job to do that. The outputs of the job include partial duplicates among documents and their locations. Since numerous of document pairs are needed to be processed, Section 4.3 gives detail descriptions about the efficient sequence matching method.",null,null
,,,
235,4.1 Signatures,null,null
,,,
236,"As described in the Section 2, a number of signature extraction methods have been proposed for document level near-duplicate detections. Since the average number of words per sentence is much fewer than document, we introduce several signature methods in this section.",null,null
,,,
237,4.1.1 Shingles,null,null
,,,
238,"Shingles is the simplest method, which is proposed by Broder et al. [5]. It tokenizes documents into a list of words and extracts all word sequences of adjacent words to represent the document. ""n-shingles"" represents the number of n adjacent words in a shingle. As the shingles uses all chunks, it might not be suitable for large collections because of too many signatures.",null,null
,,,
239,4.1.2 I-Match,null,null
,,,
240,"I-Match [7] uses SHA1 hash function over concatenation of terms filtered by stopwords and infrequent terms. It hinges on the assumption that removal of very infrequent terms and stop words results in good document representations for the near-duplicate detection task. Although the computationally of I-Match is attractive, it usually unstable even to small perturbations of content.",null,null
,,,
241,4.1.3 SpotSigs,null,null
,,,
242,"SpotSigs [26] combines stopword antecedents with short chains of adjacent content terms. A spotsig si of a location in a document consists of a chain of words that follow an antecedent word ai at a fixed spot distance di. Antecedent words are predefined and typically chosen to be stop words. Experimental results in [26] show that SpotSigs with five common terms as antecedent achieve better result than a full stopword list. However, we observe that signatures can not be extracted from more than 15.2% sentences in English collection with the five common terms. The experimental results about selecting the number of antecedents are shown in Section 5.3.",null,null
,,,
243,4.2 Sentence Duplication Detection,null,null
,,,
244,"As shown in Figure 4, the sentence duplicate detection algorithm, which is implemented by a MapReduce job, extracts near duplicated sentence pairs whose Jaccard similarity are higher than a threshold. Sentences are represented by a group of signatures. The upper bounds for Jaccard similarity [26] is",null,null
,,,
245,"J(A, B)",null,null
,,,
246,",",null,null
,,,
247,|A |A,null,null
,,,
248,B| B|,null,null
,,,
249,"min (|A|, |B|) max (|A|, |B|)",null,null
,,,
250,-1,null,null
,,,
251,"For |A|  |B|, we can get:",null,null
,,,
252,"J(A, B)",null,null
,,,
253,|A| |B|,null,null
,,,
254,-2,null,null
,,,
255,With the upper bound and vector representation of docu-,null,null
,,,
256,"ments, we observe that only similar length sentence pairs",null,null
,,,
257,"can be near duplicate. If we set the threshold to  , sen-",null,null
,,,
258,tence,null,null
,,,
259,pairs,null,null
,,,
260,where,null,null
,,,
261,|A| |B|,null,null
,,,
262,  can be safely removed.,null,null
,,,
263,Based,null,null
,,,
264,"on that, the pseudo-code of this method is show in Algo-",null,null
,,,
265,rithm 1. The input of the procedure map is the signature,null,null
,,,
266,"id (sigi) and associated postings list ([d1s1, d2s2, ...], where disj represents document id and sentence id). Inside each mapper, all candidate sentence pairs, which follow the upper",null,null
,,,
267,678,null,null
,,,
268,"bound of the Jaccard similarity, are emitted to the key-value pair ( disj, dksl , sigi). After grouping and sorting, all signature ids belonging to the same sentence pair are brought together. With the list, Jaccard similarity can be easily calculated. The procedure reduce takes the sentence pair and corresponding list as input and emit the duplication judgments based on the Jaccard similarity and predefined threshold  .",null,null
,,,
269,Algorithm 1 Pseudo-code of sentence duplication detection algorithm in MapReduce,null,null
,,,
270,"MAP(sigi, [d1s1, d2s2, ...])",null,null
,,,
271,"1: for all disj  [d1s1, d2s2, ...] do",null,null
,,,
272,"2: for all dksl  [d1s1, d2s2, ...] do",null,null
,,,
273,3:00,null,null
,,,
274,"if disj , dksl then",null,null
,,,
275,4:00,null,null
,,,
276,if,null,null
,,,
277,(,null,null
,,,
278,|disj |  |dksl|,null,null
,,,
279,and,null,null
,,,
280,|dk sl| |disj |,null,null
,,,
281,),null,null
,,,
282,or,null,null
,,,
283,(,null,null
,,,
284,|disj |  |dksl|,null,null
,,,
285,and,null,null
,,,
286,|disj | |dk sl|,null,null
,,,
287,),null,null
,,,
288,then,null,null
,,,
289,5:00,null,null
,,,
290,"EMIT( disj , dksl , sigi)",null,null
,,,
291,6:00,null,null
,,,
292,end if,null,null
,,,
293,7:00,null,null
,,,
294,end if,null,null
,,,
295,8: end for,null,null
,,,
296,9: end for,null,null
,,,
297,"REDUCE( disj , dksl , [sig1, sig2, ...])",null,null
,,,
298,1: if,null,null
,,,
299,|di sj |di sj,null,null
,,,
300,dk sl| dk sl|,null,null
,,,
301,<,null,null
,,,
302,then,null,null
,,,
303,"2: EMIT( di, dk , sj , sl )",null,null
,,,
304,3: end if,null,null
,,,
305,4.3 Sequence Matching,null,null
,,,
306,"As described in the previous sections, the sequence matching procedure aims to find all diagonals in the matrix. Algorithm 2 shows the pseudo-code of the MapReduce job. Inputs to the procedure map consists document pairs (keys, di, dj ) and a corresponding list of duplicated sentence pairs between these documents (values, [ sk, sl , sp, sq , ...]). For each duplicated sentence pair, the longest diagonal whose root is the pair is extracted and emitted. Extracted sentence pairs will be eliminated.  is used as the threshold for the diagonal length. The final output, which contains document pair, respective start positions, and length, are generated in the procedure reduce. In practical, the reducer can also be merged into the mapper to trim the intermediate data.",null,null
,,,
307,5. EXPERIMENTS,null,null
,,,
308,5.1 Collections,null,null
,,,
309,"We evaluate our methods with four corpora WT10g, TREC Blogs064, SogouT 2.05, and ClueWeb09-T09B6. Table 1 shows the statistics of the four collections. WT10g is used by TREC Web tracks, which contains more than 1.6 million documents collected from about 11,000 servers. Besides that, BLOGS06 corpus, which is used by TREC 2006 and TREC 2007 blog tracks, is also selected to evaluate systems. It is a big sample of the blogsphere, and contains more than 3.2 millions documents including spam as well as",Y,null
,,,
310,4http://ir.dcs.gla.ac.uk/test collections 5http://www.sogou.com/labs/dl/t.html 6http://boston.lti.cs.cmu.edu/Data/clueweb09/,null,null
,,,
311,Algorithm 2 Pseudo-code of sequence matching algorithm in MapReduce,null,null
,,,
312,"MAP( di, dj , [ sk, sl , sp, sq , ...])",null,null
,,,
313,"1: P  [ sk, sl , sp, sq , ...]",null,null
,,,
314,2:03,null,null
,,,
315,forDall DsiIsAj GinOPNAdLoEXTRACT(sisj ),null,null
,,,
316,4: if |D| >  then,null,null
,,,
317,5:00,null,null
,,,
318,"EMIT( di, dj , D)",null,null
,,,
319,6:00,null,null
,,,
320,P P -D,null,null
,,,
321,7: end if,null,null
,,,
322,8: end for,null,null
,,,
323,DIAGONALEXTRACT(sisj ),null,null
,,,
324,1: while sisj in P do 2: D  D sisj 3: si  si+1 4: sj  sj+1 5: end while,null,null
,,,
325,"REDUCE( di, dj , [D1, D2, ...])",null,null
,,,
326,"1: for all D  [D1, D2, ...] do 2: EMIT( di, dj , Start.di, Start.dj, D.Length ) 3: end for",null,null
,,,
327,"possibly non-blogs. SogouT 2.0 corpus is made up of 24.8M Chinese Web pages and crawled from all domains. TREC Category B dataset(ClueWeb09-T09B), which is a subset of the ClueWeb09, contains 50 million English pages and has been used in various TREC tracks.",Y,null
,,,
328,Table 1: Statistics of the evaluation corpora,null,null
,,,
329,Corpus WT10g Blogs06 SogouT 2.0 ClueWeb09-T09B,Y,null
,,,
330,Language English English Chinese English,null,null
,,,
331,"#Docs 1,692,096 3,215,171 24,833,521 50,220,423",null,null
,,,
332,Size 11GB 88.8GB 372.5GB 490.4GB,null,null
,,,
333,5.2 Implementation and Setup,null,null
,,,
334,"All the MapReduce jobs were implemented in Java for Hadoop framework. HDFS was used to provide the distributed storage. All experiments were evaluated on a 16 machines cluster. Each machine contains two Xeon quad core CPUs (2.0GHz), and 32GB RAM. Software stack of the experiments used Java 1.6 and Hadoop version 0.20. For web page cleaning, we just removed all HTML markup tags from the collections. Since the impact of sentence boundary detection's performance would not be heavy and a number of manually written rules can achieve good result [1] with little attractive computational consumption, we used around 50 rules to do that in our experiment.",null,null
,,,
335,5.3 Comparison of Signatures,null,null
,,,
336,"In order to compare the performances of different signatures, we manually select 2000 documents, which contain 57135 sentences totaly, from ClueWeb09-T09B (Oracle Eng is used to represent the corpus in the following section for simple). For Chinese corpus SogouT, we also constructed a manually labeled corpus (Oracle Chn), which contains",Y,null
,,,
337,679,null,null
,,,
338,F1 Score F1 Score,null,null
,,,
339,F1 Score,null,null
,,,
340,5 10 20 30 40 50 60 70 80 90 100 200 500,null,null
,,,
341,F1 Score,null,null
,,,
342,10 100 500 1K 2K 5K 10K 15K 20K,null,null
,,,
343,Oracle Chn,null,null
,,,
344,1,null,null
,,,
345,0.9,null,null
,,,
346,0.8,null,null
,,,
347,0.7,null,null
,,,
348,0.6,null,null
,,,
349,0.5,null,null
,,,
350,0.4,null,null
,,,
351,2-Shingles,null,null
,,,
352,0.3,null,null
,,,
353,3-Shingles,null,null
,,,
354,4-Shingles 0.2,null,null
,,,
355,0.1 1,null,null
,,,
356,0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
357,Oracle Eng,null,null
,,,
358,1,null,null
,,,
359,0.9,null,null
,,,
360,0.8,null,null
,,,
361,0.7,null,null
,,,
362,0.6,null,null
,,,
363,0.5,null,null
,,,
364,0.4,null,null
,,,
365,2-Shingles,null,null
,,,
366,0.3,null,null
,,,
367,3-Shingles,null,null
,,,
368,4-Shingles 0.2,null,null
,,,
369,0.1 1,null,null
,,,
370, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
371,Figure 6: Shingles' performances of varying the threshold  for corpora Oracle Eng and Oracle Chn,null,null
,,,
372,F1 Score F1 Score,null,null
,,,
373,Oracle Chn,null,null
,,,
374,1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
375,0,null,null
,,,
376,Oracle Eng,null,null
,,,
377,1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
378,0,null,null
,,,
379,0.0-1.0 0.1-1.0 0.2-1.0 0.3-1.0 0.4-1.0 0.5-1.0 0.6-1.0 0.7-1.0 0.8-1.0 0.9-1.0 0.0-1.0 0.1-1.0 0.2-1.0 0.3-1.0 0.4-1.0 0.5-1.0 0.6-1.0 0.7-1.0 0.8-1.0 0.9-1.0,null,null
,,,
380,IDF,null,null
,,,
381,IDF,null,null
,,,
382,Figure 7: I-Match' performances of varying IDF for corpora Oracle Eng and Oracle Chn,null,null
,,,
383,80516 sentences extracted from 2000 documents. Six in-,null,null
,,,
384,dividuals were asked to label them. The average Kappa,null,null
,,,
385,"statistic among them is around 91.6%, which shows good",null,null
,,,
386,agreement.,null,null
,,,
387,"Figure 6 shows the performances comparison of 2-Shingles,",null,null
,,,
388,"3-Shingles, and 4-Shingles. We observe that 4-Shingles con-",null,null
,,,
389,sistently performs better than 2-Shingles and 3-Shingles in,null,null
,,,
390,both English and Chinese collections. Different with results,null,null
,,,
391,"in document level [18, 26], threshold  , 0.9 achieves the",null,null
,,,
392,best performance in both of the collections. The reason is,null,null
,,,
393,that around 91% of duplicated sentences in Oracle Chn and,null,null
,,,
394,89% of them in Oracle Eng are exactly same with each other,null,null
,,,
395,"in our evaluation collections. However, this kind of factor is",null,null
,,,
396,rare in the document level.,null,null
,,,
397,Figure 7 shows the performances of I-Match with different,null,null
,,,
398,IDF ranges. Tokens exceeding IDF range were filtered. We,null,null
,,,
399,use,null,null
,,,
400,idfi,null,null
,,,
401,",",null,null
,,,
402,log(N/dfj ) log(N ),null,null
,,,
403,to,null,null
,,,
404,calculate,null,null
,,,
405,the,null,null
,,,
406,IDF,null,null
,,,
407,value,null,null
,,,
408,for,null,null
,,,
409,token,null,null
,,,
410,"i,",null,null
,,,
411,"where N is the corpus size, dfj is the document frequency",null,null
,,,
412,of the token. Since the similarities calculated by I-Match,null,null
,,,
413,"are either 0 or 1, the threshold  does not need to adjusted.",null,null
,,,
414,"The best result is achieved by [0.1, 1.0] in both Oracle Chn",null,null
,,,
415,and Oracle Eng. It means that most of the tokens should,null,null
,,,
416,be kept and used to calculate the hash result. The main,null,null
,,,
417,reason is that sentences usually contain a small number of,null,null
,,,
418,tokens and most of the duplicated sentences are same with,null,null
,,,
419,each other. When tokens whose IDF is lower than 0.4 are,null,null
,,,
420,"filtered, most of the sentences have less than 2 tokens left",null,null
,,,
421,"in Oracle Chn. Because of that, the recall for [0.4, 1.0] is",null,null
,,,
422,"almost perfect 100%, but the precision is only 1.4%.",null,null
,,,
423,The impacts of the number of antecedents for Spotsig are,null,null
,,,
424,shown in Figure 8. The x-axis represents the number of an-,null,null
,,,
425,tecedents and varies from 5 to 500 in Oracle Chn and 10 to,null,null
,,,
426,20K in Oracle Eng. The numbers below each point represent,null,null
,,,
427,the average number of signatures per sentences with corre-,null,null
,,,
428,sponding antecedents. It shows that the antecedents' num-,null,null
,,,
429,Oracle Chn,null,null
,,,
430,1,null,null
,,,
431,3.8 4.2 4.5 4.8 5.0 6.9 9.0 0.9,null,null
,,,
432,2.6 3.0 3.5,null,null
,,,
433,0.8,null,null
,,,
434,2.1 1.4,null,null
,,,
435,0.7 0.9,null,null
,,,
436,0.6,null,null
,,,
437,# Antecedent,null,null
,,,
438,Oracle Eng,null,null
,,,
439,1,null,null
,,,
440,0.9,null,null
,,,
441,3.4 3.7 3.8 3.9,null,null
,,,
442,0.8,null,null
,,,
443,3,null,null
,,,
444,0.7,null,null
,,,
445,2.6,null,null
,,,
446,0.6,null,null
,,,
447,2.2,null,null
,,,
448,0.5 0.7,null,null
,,,
449,1.5,null,null
,,,
450,0.4,null,null
,,,
451,0.3,null,null
,,,
452,0.2,null,null
,,,
453,0.1,null,null
,,,
454,# Antecedent,null,null
,,,
455,Figure 8: Spotsigs' performances of varying the number of antecedents for corpora Oracle Eng and Oracle Chn,null,null
,,,
456,F1 Score,null,null
,,,
457,Oracle Chn,null,null
,,,
458,1,null,null
,,,
459,0.9,null,null
,,,
460,0.8,null,null
,,,
461,0.7,null,null
,,,
462,0.6,null,null
,,,
463,0.5,null,null
,,,
464,0.4,null,null
,,,
465,"# Antecedent , 5",null,null
,,,
466,0.3,null,null
,,,
467,"# Antecedent, 60",null,null
,,,
468,"# Antecedent , 100",null,null
,,,
469,0.2,null,null
,,,
470,0.1 1,null,null
,,,
471, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
472,F1 Score,null,null
,,,
473,Oracle Eng,null,null
,,,
474,1,null,null
,,,
475,0.9,null,null
,,,
476,0.8,null,null
,,,
477,0.7,null,null
,,,
478,0.6,null,null
,,,
479,0.5,null,null
,,,
480,0.4,null,null
,,,
481,"# Antecedent , 1K",null,null
,,,
482,0.3,null,null
,,,
483,"# Antecedent , 5K",null,null
,,,
484,"# Antecedent, 10K",null,null
,,,
485,0.2,null,null
,,,
486,0.1 1,null,null
,,,
487, 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1,null,null
,,,
488,Figure 9: Spotsigs' performances of varying the threshold  for corpora Oracle Eng and Oracle Chn,null,null
,,,
489,"ber would highly impact the performance. We think that the main reason is that sentences cannot be well represented by a small number of signatures. By trading-off between efficiency and effectiveness, we choose # antecedent ,"" 60 to achieve 95.2% F1 score in Chinese collection. For English one, we choose # antecedent "","" 10K. We observe that the number of antecedents is much different between English and Chinese collections. However the best results are both achieved at the similar average number of signatures per sentence. It shows that a sentence can be well described by around 4 signatures. Figure 9 shows the performances with different thresholds. Comparing with shingles, spotsigs show the similar trends. We achieve the best result with  "", 0.9 in Oracle Chn and Oracle Eng.",null,null
,,,
490,"In summary, 4-Shingles achieve the best result in the sentence level duplicate detection. However, the performances of 2-Shingles, 3-Shingles, Spotsigs, and I-Match are comparable. The parameters used for sentence level are much different with document level ones. We think that it is caused by the characters of sentence collections, such as length, standard for labeling and so on. We also observe that although all three signature extraction methods are highly tunable, the results prove to be robust for a large variety of parameters.",null,null
,,,
491,5.4 Effectiveness Evaluation,null,null
,,,
492,"After evaluating three different methods to extract duplicated sentences, we now consider the impact of sequence matching. Table 2 summaries the sequence matching results with different signatures. The configurable parameters IDF range, similarity threshold  , and # antecedent are selected by the previous experiments and listed in the brackets. We use Precision, Recall, and F1-Score as our choice of evaluation metric to measure how accurately the dupli-",null,null
,,,
493,680,null,null
,,,
494,"Table 2: Summary of sequence matching results with Shingles, I-Match and Spotsigs for Oracle sets",null,null
,,,
495,Corpus Oracle Chn,null,null
,,,
496,Oracle Eng,null,null
,,,
497,Signature,null,null
,,,
498,"2-Shingles( , 0.9) 3-Shingles( , 0.9) 4-Shingles( , 0.9) I-Match(IDF,""[0.1,1.0]) Spotsigs(#A"",""60,  "", 0.9)",null,null
,,,
499,"2-Shingles( , 0.9) 3-Shingles( , 0.9) 4-Shingles( , 0.9) I-Match(IDF,""[0.1,1.0]) Spotsigs(#A"",""10K,  "", 0.9)",null,null
,,,
500,P,null,null
,,,
501,0.936 0.937 0.942 0.935 0.938,null,null
,,,
502,0.987 0.987 0.987 0.985 0.981,null,null
,,,
503,R,null,null
,,,
504,0.937 0.937 0.942 0.938 0.930,null,null
,,,
505,0.966 0.966 0.967 0.960 0.965,null,null
,,,
506,F1,null,null
,,,
507,0.936 0.937 0.942 0.937 0.934,null,null
,,,
508,0.977 0.977 0.977 0.972 0.973,null,null
,,,
509,"cation is located. From analyzing the Oracle collections, we observe that lengths of most duplications are bigger than three. Hence, , which is the threshold of diagonal length, is set to 3 in all the experiments. We observe that the final results are heavily related to the performances of sentence duplicate detection. Since the performances of 2-Shingles, 3-Shingles, 4-Shingles, I-Match and Spotsigs are similar, the final F1-scores do not have significant difference. In order to evaluate the impact of , we also evaluate the performances at  ,"" 1. In Oracle Eng, the F1-score of 2-Singles is only 0.952, which is significantly 7 different from the results shown in the Table 2. 3-Shingles, 4-Shingles, I-Match and Spotsigs have the similar results. By trading-off efficiency and effectiveness, we determine to use I-Match method to extract signatures in our method.""",null,null
,,,
510,"Figure 10 summarizes our results of PDC-MR versus the document level near-duplicate detection. For convenient comparison among copra, the top one million documents of each corpus are used in this experiment. For document level near-duplicate detection, the state-of-the-art method Spotsig is used, whose parameters are set up based on [26]. The y-axis represents the number of unique documents. The bottom parts of each bar represent results of Spotsig. The top parts represent the number of documents which can be detected by our PDC-MR method but can not be detected by document level Spotsig. In WT10g, Spotsig extracts around 31K documents which contain duplications in the same corpus. They compose more than 1.89 million duplication pairs. Besides those documents, through our method, another 94K documents which contain partial-duplicates are detected. In Blogs06, ClueWeb09-T09B, and Chinese corpus SogouT2.0, we get similar results. It shows that partial-duplications are common in web collections and our proposed method can effectively detect them.",Y,null
,,,
511,"In order to evaluate the validity of the extracted partial duplicates, we random select 200 documents from the detection results of each corpus and manually classify them into four types as listed in the Table 3. ""News Collection"" and ""Multiple Page"" are described in the Section 1. ""Partial Quotation"" represents all types of short piece of text quotation. Banner, copyright notice, navigation bar, and other non-content parts are classified into ""Other"". The results show that ""Partial quotation"" account for the majority of all instances. The average length of this kind of duplications",null,null
,,,
512,7The paired  -test (<0.05) is used to measure the significance.,null,null
,,,
513,Table 3: Partial duplicates in the web collections,null,null
,,,
514,Corpus,null,null
,,,
515,WT10g Blogs06 SogouT 2.0 ClueWeb09-T09B,Y,null
,,,
516,News Collection,null,null
,,,
517,4% 2.5% 10% 3%,null,null
,,,
518,Multiple Page,null,null
,,,
519,8.5% 5% 18% 7%,null,null
,,,
520,Partial Quotation,null,null
,,,
521,80% 79% 60% 58%,null,null
,,,
522,Other,null,null
,,,
523,7.5% 13.5% 12% 32%,null,null
,,,
524,140K 120K 100K,null,null
,,,
525,80K 60K 40K 20K,null,null
,,,
526,0K,null,null
,,,
527,"21,397 31,486 WT10g",null,null
,,,
528,"70,930",null,null
,,,
529,"12,261",null,null
,,,
530,"44,862",null,null
,,,
531,"58,134",null,null
,,,
532,"60,814",null,null
,,,
533,"13,657",null,null
,,,
534,Blogs06,null,null
,,,
535,SogouT 2.0,null,null
,,,
536,Spotsig(Doc Level),null,null
,,,
537,PDC-MR,null,null
,,,
538,ClueWeb09-T09B,Y,null
,,,
539,Figure 10: Summary of PDC-MR vs. document level Spotsig in four web collections,null,null
,,,
540,"is around 6 sentences. While the average length of document is more than 23 sentences in SogouT 2.0 and 26 sentences in WT10g. Thus those partial duplications can not be easily detected by the existing document level detection methods. The results show that most of extracted partial duplications are useful and meaningful. Except ClueWeb09T09B, the percentages of ""Other"" type in other collections are less than 15%. While, there are 32% instances belonging to this type in ClueWeb09-T09B. We think the main reason is that ClueWeb09-T09B is not well cleaned and contains lots of advertisements.",Y,null
,,,
541,5.5 Efficiency Evaluation,null,null
,,,
542,"Figure 11 plots the running times of spotsigs based nearduplicate detection and our proposed PDC-MR method for different corpus size. ClueWeb09-T09B is used in this experiment. All Hadoop jobs in the efficiency experiments were configured with 60 mappers and 60 reducers. The graph suggests that although the number of sentence is huger than the number of documents, our proposed method is more efficient than Spotsig. We think that it makes sense since I-match is efficient and its performance is also comparable in sentence level.",Y,null
,,,
543,6. CONCLUSIONS,null,null
,,,
544,"This paper presents our work on partial-duplicate detection task. A number of factors like news collection, multiple pages, threads in forums, plagiarize sentences, non-cleaned web pages, and sentences/paragraphs quotation belong to it. In order to address this problem, we propose a novel MapReduce algorithm, which converts the task into three MapReduce jobs. Except for the similarities between documents, the algorithm can simultaneously output the positions where the duplicated parts occur. The contributions of the work include both empirical analysis of signatures for",null,null
,,,
545,681,null,null
,,,
546,Runing TIme (seconds ),null,null
,,,
547,16K,null,null
,,,
548,14K 12K,null,null
,,,
549,Spotsig(Doc Level) PDC-MR,null,null
,,,
550,10K,null,null
,,,
551,8K,null,null
,,,
552,6K,null,null
,,,
553,4K,null,null
,,,
554,2K,null,null
,,,
555,0K,null,null
,,,
556,1,null,null
,,,
557,2,null,null
,,,
558,3,null,null
,,,
559,4,null,null
,,,
560,5,null,null
,,,
561,# DOC (millions),null,null
,,,
562,Figure 11: Running time of the PDC-MR and Spotsig with different corpus size,null,null
,,,
563,sentence and algorithm design. Experimental results in four real-world web collections show that the proposed method can be effectively and efficiently used to detect partial- and near-duplicate.,null,null
,,,
564,7. ACKNOWLEDGMENTS,null,null
,,,
565,"The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Program (2010CB327906), Shanghai Leading Academic Discipline Project (B114), Doctoral Fund of Ministry of Education of China (200802460066), and Shanghai Science and Technology Development Funds (08511500302).",null,null
,,,
566,8. REFERENCES,null,null
,,,
567,"[1] J. Aberdeen, J. Burger, D. Day, L. Hirschman, P. Robinson, and M. Vilain. Mitre: description of the alembic system used for muc-6. In Proceedings of MUC6, pages 141­155, Morristown, NJ, USA, 1995.",null,null
,,,
568,"[2] M. Bendersky and W. B. Croft. Finding text reuse on the web. In WSDM '09, pages 262­271, New York, NY, USA, 2009. ACM.",null,null
,,,
569,"[3] A. Z. Broder. On the resemblance and containment of documents. In Proceedings of SEQUENCES 1997, page 21, Washington, DC, USA, 1997. IEEE Computer Society.",null,null
,,,
570,"[4] A. Z. Broder. Identifying and filtering near-duplicate documents. In Proceedings of COM 2000, pages 1­10, London, UK, 2000.",null,null
,,,
571,"[5] A. Z. Broder, S. C. Glassman, M. S. Manasse, and G. Zweig. Syntactic clustering of the web. Comput. Netw. ISDN Syst., 29(8-13):1157­1166, 1997.",null,null
,,,
572,"[6] M. S. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings of STOC 2002, pages 380­388, New York, NY, USA, 2002. ACM.",null,null
,,,
573,"[7] A. Chowdhury, O. Frieder, D. Grossman, and M. C. McCabe. Collection statistics for fast duplicate document detection. ACM Trans. Inf. Syst., 20(2):171­191, 2002.",null,null
,,,
574,"[8] J. Dean and S. Ghemawat. Mapreduce: Simplified data processing on large clusters. In Proceedings of OSDI 2004, San Francisco, CA, USA, 2004.",null,null
,,,
575,"[9] W. B. Frakes and R. A. Baeza-Yates. Information Retrieval: Data Structures & Algorithms. Prentice-Hall, 1992.",null,null
,,,
576,"[10] S. Ghemawat, H. Gobioff, and S.-T. Leung. The google file system. SIGOPS Oper. Syst. Rev., 37(5):29­43, 2003.",null,null
,,,
577,"[11] A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In VLDB '99, pages 518­529, San Francisco, CA, USA, 1999.",null,null
,,,
578,"[12] W. Gropp, E. Lusk, and A. Skjellum. Using MPI: portable parallel programming with the message-passing interface. MIT Press, Cambridge, MA, USA, 1994.",null,null
,,,
579,"[13] M. Henzinger. Finding near-duplicate web pages: a large-scale evaluation of algorithms. In SIGIR '06, pages 284­291, New York, NY, USA, 2006. ACM.",null,null
,,,
580,"[14] S. C. Herring, L. A. Scheidt, I. Kouper, and E. Wright. A longitudinal content analysis of weblogs: 2003-2004. Blogging, Citizenship and the Future of Media, pages 3­20, 2006.",null,null
,,,
581,"[15] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse of dimensionality. In STOC '98, pages 604­613, New York, NY, USA, 1998. ACM.",null,null
,,,
582,"[16] O. Kolak and B. N. Schilit. Generating links by mining quotations. In Proceedings of HT 2008, pages 117­126, New York, NY, USA, 2008. ACM.",null,null
,,,
583,"[17] A. Kolcz, A. Chowdhury, and J. Alspector. Improved robustness of signature-based near-replica detection via lexicon randomization. In Proceedings of SIGKDD 2004, pages 605­610, New York, NY, USA, 2004. ACM.",null,null
,,,
584,"[18] J. Lin. Brute force and indexed approaches to pairwise document similarity comparisons with mapreduce. In Proceedings of SIGIR '09, pages 155­162, New York, NY, USA, 2009. ACM.",null,null
,,,
585,"[19] G. S. Manku, A. Jain, and A. Das Sarma. Detecting near-duplicates for web crawling. In WWW '07, pages 141­150, New York, NY, USA, 2007. ACM.",null,null
,,,
586,"[20] K. Muthmann, W. M. Barczyn´ski, F. Brauer, and A. L¨oser. Near-duplicate detection for web-forums. In IDEAS '09, pages 142­151, New York, NY, USA, 2009. ACM.",null,null
,,,
587,"[21] R. Ramakrishnan and A. Tomkins. Toward a peopleweb. Computer, 40(8):63­72, 2007.",null,null
,,,
588,"[22] S. Schleimer, D. S. Wilkerson, and A. Aiken. Winnowing: local algorithms for document fingerprinting. In SIGMOD '03, pages 76­85, New York, NY, USA, 2003. ACM.",null,null
,,,
589,"[23] J. Seo and W. B. Croft. Local text reuse detection. In SIGIR '08, pages 571­578, New York, NY, USA, 2008. ACM.",null,null
,,,
590,"[24] N. Shivakumar and H. Garcia-Molina. Scam: A copy detection mechanism for digital documents. In Digitial Library, 1995.",null,null
,,,
591,"[25] N. Shivakumar and H. Garcia-Molina. Finding near-replicas of documents and servers on the web. In Proceedings of WebDB 1998, pages 204­212, London, UK, 1999. Springer-Verlag.",null,null
,,,
592,"[26] M. Theobald, J. Siddharth, and A. Paepcke. Spotsigs: robust and efficient near duplicate detection in large web collections. In SIGIR '08, pages 563­570, New York, NY, USA, 2008. ACM.",null,null
,,,
593,"[27] L. G. Valiant. A bridging model for parallel computation. Commun. ACM, 33(8):103­111, 1990.",null,null
,,,
594,682,null,null
,,,
595,,null,null
