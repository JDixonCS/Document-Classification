,sentence,label,data
0,Scalability of Findability: Effective and Efficient IR Operations in Large Information Networks,null,null
1,Weimao Ke,null,null
2,School of Information and Library Science University of North Carolina at Chapel Hill,null,null
3,"Chapel Hill, NC 27599-3360, USA",null,null
4,wke@unc.edu,null,null
5,ABSTRACT,null,null
6,"It is crucial to study basic principles that support adaptive and scalable retrieval functions in large networked environments such as the Web, where information is distributed among dynamic systems. We conducted experiments on decentralized IR operations on various scales of information networks and analyzed effectiveness, efficiency, and scalability of various search methods. Results showed network structure, i.e., how distributed systems connect to one another, is crucial for retrieval performance. Relying on partial indexes of distributed systems, some level of network clustering enabled very efficient and effective discovery of relevant information in large scale networks. For a given network clustering level, search time was well explained by a polylogarithmic relation to network size (i.e., the number of distributed systems), indicating a high scalability potential for searching in a growing information space. In addition, network clustering only involved local self-organization and required no global control ­ clustering time remained roughly constant across the various scales of networks.",null,null
7,Categories and Subject Descriptors,null,null
8,"H.3.4 [Information storage and retrieval]: Systems and Software--Distributed systems, Information networks",null,null
9,General Terms,null,null
10,"Algorithms, Performance, Experimentation",null,null
11,Keywords,null,null
12,"distributed IR, scalability, network clustering, decentralized search, weak tie, strong tie, clustering paradox, connectivity",null,null
13,1. INTRODUCTION,null,null
14,"In today's digital environments, there exist a variety of information networks where information is distributed among dynamic systems. On the Web, for example, individual web",null,null
15,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10 July 19­23, 2010. Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",null,null
16,Javed Mostafa,null,null
17,School of Information and Library Science University of North Carolina at Chapel Hill,null,null
18,"Chapel Hill, NC 27599-3360, USA",null,null
19,jm@unc.edu,null,null
20,"sites host diverse information topics and form a network by means of hyperlinks. Likewise, digital libraries interoperate with one another and serve information distributed across collections in a network. For reasons such as copyright and privacy, lots of information cannot be fully collected and indexed in advance for retrieval purposes. In addition to this is the dynamics of many environments such as the deep web and peer-to-peer networks, in which it is not only difficult to gather information but also challenging to keep an index up to date.",null,null
21,"Centralized IR solutions can hardly survive the continued growth of today's information spaces ­ they are vulnerable to scalability demands [3]. A distributed architecture is desirable and, due to many constraints, is often the only choice. Distributed (federated) IR research is a response to the challenge of retrieving information from distributed sources. Recent distributed IR research has focused on intra-system retrieval fusion/federation, cross-system communication, and distributed information storage and retrieval algorithms [9, 23].",null,null
22,"Classic distributed information retrieval has shown some potential of efficiently and effectively bringing distributed information together. However, the reliance on centralization of a metasearch server will continue to suffer from critical problems such as scalability, single point failure, and fault tolerance. Further decentralization of meta search models will involve issues beyond the main focus of federated IR research.",null,null
23,"Research has been done under the theme of peer-to-peer information retrieval (P2P-IR) and, more recently, large scale distributed systems for IR (LSDS-IR) [5, 10, 16, 11]. While classic distributed IR often focuses on tens, if not hundreds, of distributed collections, P2P- or LSDS-IR usually envisions an IR problem situated in thousands and even millions of distributed, dynamic systems. The magnitude, distribution, and dynamics of information in such an environment remain a great challenge in IR. Applications of this research include not only search in peer-to-peer environments but also information retrieval in digital libraries, intelligent information discovery on the deep web, distributed desktop search, and agent-assisted web surfing etc.",null,null
24,"Finding relevant information in distributed networked environments transforms into a problem concerning information retrieval and complex networks. In this study, we focus on how relevant information can be effectively and efficiently found in large scale information networks, where no centralized index can possibly be built. We investigate the impact of network structure/topology on the effectiveness and effi-",null,null
25,74,null,null
26,ciency of decentralized IR operations relying on distributed indexes. We test the proposed retrieval methods in a growing information space and examine the scalability potential.,null,null
27,2. RELATED WORK,null,null
28,"While traditional IR and distributed IR research provides basic tools for attacking decentralized search problems, the evolving dynamics and heterogeneity of today's networked environments challenge the sufficiency of classic methods and call for new innovations [3]. Whereas peer-to-peer offers a new type of architecture for application-level questions and techniques to be tested, research on complex networks studies related questions in their basic forms [2, 23].",null,null
29,2.1 P2P Information Retrieval,null,null
30,"In an open, dynamic information space such as a peerto-peer network, people, information, and technologies are all mobile and changing entities. Identifying where relevant collections are for the retrieval of information is essential. Without global information, decentralized IR methods have to rely on individual indexes in distributed nodes and their limited local intelligence to collectively construct paths to desired information.",null,null
31,"Recent years have seen growing popularity of peer-to-peer (P2P) networks for large scale information sharing and retrieval [17]. There have been ongoing discussions on the applicability of existing P2P search models for IR, the efficiency and scalability challenges, and the effectiveness of traditional IR models in such environments [23]. Some researchers applied Distributed Hashing Tables (DHTs) techniques to structured P2P environments for distributed retrieval and focused on building an efficient indexing structure over peers [7, 18, 21].",null,null
32,"Others, however, questioned the sufficiency of DHTs for dealing with high dimensionality of IR (e.g., a large number of terms for document representation) in dynamic P2P environments [5, 17, 16]. For retrieval with a large feature space, which often requires frequent updates to cope with a transient population, it is challenging for distributed hashing to work in a traffic- and space-efficient manner. Unstructured overlay systems work in an nondeterministic manner and have received increased popularity for being fault tolerant and adaptive to evolving system dynamics [17].",null,null
33,2.2 Decentralized Search in Networks,null,null
34,"Research on complex networks provides valuable principles for searching/navigation in distributed systems. Not only do many information networks such as the Web share the common phenomenon of small world but they also appear to be searchable [2]. Particularly, studies showed that without global information about where targets are, members of a very large network are able to collectively construct short paths (if not the shortest) to destinations [15, 22, 8].",null,null
35,"The implication in IR is that relevant information, in various networked environments, is very likely a small number of connections/links away from the one who needs it and is potentially findable. This indicates potentials for decentralized retrieval algorithms to traverse an information network to find relevant information efficiently. However, this is not an easy task because not only relevant information is a few degrees/connects away but so is all information.",null,null
36,"To find relevance in a densely-packed ""small world"" network remains very challenging. Nonetheless, research has",null,null
37,"demonstrated how nodes connect to one another and the structure of the network they thus form have critical impacts on how searches function. Network clustering, sometimes by means of semantic overlay, can significantly improve effectiveness and efficiency of IR operations in an information network.",null,null
38,"Clustering, the process of bringing similar entities together, is useful for information retrieval. Traditional IR research utilized document-level clustering to support exploratory searching and to improve retrieval effectiveness. In large scale distributed IR, topical clustering techniques such as semantic overlay networks (SONs) have been widely used, in which systems containing similar information form semantic groups for efficient searches [5, 10, 16].",null,null
39,"Research indicated that a proper degree of network clustering with some presence of remote connections has to be maintained for efficient searches [15, 20]. Clustering reduces the number of ""irrelevant"" links and aids in creating topical segments useful for orienting searches. With very strong clustering, however, a network tends to be fragmented into local communities with abundant strong ties but few weak ties to bridge remote parts [12]. Although searches might be able to move gradually toward targets, necessary ""hops"" become unavailable. We refer to this phenomenon as the Clustering Paradox, in which neither strong clustering nor weak clustering is desirable. The Clustering Paradox has received attention in complex network research and requires further scrutiny in a decentralized IR context [15, 14].",null,null
40,3. EXPERIMENTAL SYSTEM,null,null
41,"We have developed a multi-agent decentralized search architecture named TranSeen for finding relevant information distributed in networked environments. We illustrate the conceptual model in Figure 1 (a) and major components in Figure 1 (b). The TranSeen system is an implementation in Java, based on two well-known open-source platforms: 1) JADE, a multi-agent system/middle-ware that complies with the FIPA (the Foundation for Intelligent Physical Agents) specifications [6], and 2) Lucene, a high-performance library for full-text search [13].",null,null
42,v d,null,null
43,c,null,null
44,?,null,null
45,b,null,null
46,u,null,null
47,(a) Global View,null,null
48,QQuuerey ry,null,null
49,Neighbor Prediction,null,null
50,Neighbor Representation,null,null
51,Query Representation,null,null
52,Neighbor Representation,null,null
53,Document Representation,null,null
54,Local Retrieval,null,null
55,Doc,null,null
56,document,null,null
57,Doc,null,null
58,Document,null,null
59,Doc,null,null
60,Document,null,null
61,(b) Agent Internal View,null,null
62,Figure 1: Conceptual Framework. (a) Global View of agents working together to route a query in the network space. (b) Agent Internal View of how components function within an agent.,null,null
63,"Assume that agents, representatives of distributed information systems, reside in an n dimensional (hypersphere) space. An agent's location in the space represents its information topicality. Therefore, finding relevant sources for an information need is to route the query to agents in the relevant topical space. To simplify the discussion, assume all",null,null
64,75,null,null
65,"agents can be characterized using a two-dimensional space. Figure 1 (a) visualizes a 2D circle (1-sphere) representation of the information space. Let agent Au be the system that receives a query from the user whereas agent Av has the relevant information. The problem becomes how agents in the connected society, without global information, can collectively construct a short path to Av so that relevant information can be retrieved from there. In Figure 1 (a), the query traverses a search path Au  Ab  Ac  Ad  Av to reach the target. While agents Ab and Ad help move the query toward the target gradually (through strong ties), agent Ac has a remote connection (weak tie) for the query to ""jump.""",null,null
66,3.1 Decentralized Search,null,null
67,"When an agent receives a query, it first conducts local search operations to retrieve relevant information from its individual document collection. If local results are unsatisfactory, e.g., relevance/similarity scores do not reach a predefined threshold, the agent will contact its neighbors for help. Therefore, there requires a mechanism for matching query representation with potential good neighbors ­ either the neighboring agent is more likely to have relevant information to answer the query directly or more likely to connected with relevant targets. Agents explore their neighborhoods through interactions (e.g., query-based sampling), develop some knowledge about neighbors' topicality and connectivity, and serve as local decision makers in the search process. They are essentially metasearch systems for one another.",null,null
68,3.2 Network Structure & Local Clustering,null,null
69,"As discussed earlier, network structure plays an important role in decentralized search. We used a parameter called the clustering exponent  to guide network clustering for decentralized search: the probability pr of two nodes being connected/linked is proportional to r-, where r is the pairwise topical distance and  the clustering exponent.",null,null
70,Figure 2: Function of Clustering Exponent ,null,null
71,"The clustering exponent , as shown in Figure 2, describes a correlation between the network (topological) space and the search (topical) space [15, 8]. When  is small, connectivity has little dependence on topical closeness ­ local segments become less visible as the network is built on increased randomness. As shown in Figure 3 (c), the network is a random graph given a uniform connectivity distribution",null,null
72,"at  ,"" 0. When  is large, weak ties (long-distance connections) are rare and strong ties dominate [12]. The network becomes highly segmented. As shown in Figure 3 (a), when   , the network is very regular (highly clustered) given that it is extremely unlikely for remote pairs to connect. Given a moderate  value, as shown in Figure 3 (b), the network becomes a narrowly defined small world, in which both local and remote connections present.""",null,null
73, (a) Segmented,null,null
74," , 2.5 (b) Small World",null,null
75,",0 (c) Random",null,null
76,Figure 3: Network Clustering: Impact of Clustering Exponent .,null,null
77,"The clustering exponent  influences the emergence of local segments and overall network clustering. In complex network research, it has been shown that only with some particular value of , search time (i.e., search path length) is optimal and bounded by a poly-logarithmic function of network size [15]. One important aspect of this research is to study the impact of network structure on decentralized IR effectiveness and efficiency.",null,null
78,4. ALGORITHMS,null,null
79,"This section elaborates on specific algorithms used in the research. Section 4.1 presents the basic functions for information representation, neighbor representation, and similarity measurement. Section 4.2 describes four search (neighbor selection) algorithms based on neighbor similarity and/or connectivity. Section 4.3 elaborates on the function for agent rewiring (clustering) based on the clustering exponent .",null,null
80,4.1 Basic Functions,null,null
81,4.1.1 TF*IDF Information Representation,null,null
82,"We used the Vector-Space Model (VSM) for information (document and query) representation [4]. Given that information was highly distributed, a global term space was not assumed. Instead, each agent processed information it individually had and produced a local term space, which was used to represent each information item using the TF*IDF (Term Frequency * Inverse Document Frequency) weighting scheme. An information item was then converted to a numerical vector where a item t was computed by:",null,null
83,"W (t) , tf (t) · log( N )",null,null
84,(1),null,null
85,df (t),null,null
86,where tf (t) is the frequency of the term t of the term space,null,null
87,"in the information item, N is the total number of informa-",null,null
88,"tion items (e.g., documents) in an agent's local collection,",null,null
89,and df (t) is the number of information items in the set con-,null,null
90,taining,null,null
91,the,null,null
92,term,null,null
93,t,null,null
94,of,null,null
95,the,null,null
96,term,null,null
97,space.,null,null
98,We,null,null
99,refer,null,null
100,to,null,null
101,log(,null,null
102,N df (t),null,null
103,),null,null
104,as IDF. IDF values were computed within the information,null,null
105,space of an agent given no global information.,null,null
106,76,null,null
107,4.1.2 DF*INF Agent Representation,null,null
108,"Following a simple federated IR model, we allowed agents to collect document frequency (DF) information from neighors (distributed systems) and to use it to create metadocuments for neighbor representation [19]. Treating each metadocument as a normal document, it was then straightforward to calculate neighbor frequency (NF) values of terms, i.e., the number of metadocuments (neighbors) containing a particular term. A metadocument (neighbor) was then represented as a vector where a term t was computed by:",null,null
109,W,null,null
110,(t),null,null
111,",",null,null
112,df,null,null
113,(t),null,null
114,·,null,null
115,log(,null,null
116,N nf (t),null,null
117,),null,null
118,(2),null,null
119,"where df (t) is the frequency of the term t of the term space in the metadocument, N is the total number of an agent's neighbors (metadocuments), and nf (t) is the number of neighbors containing the term t. We refer to this function as DF*INF, or document frequency * inverse neighbor frequency.",null,null
120,4.1.3 Similarity Scoring Function,null,null
121,"Based on the TF*IDF (or DF*INF) values obtained above, pair-wise similarity values can be computed. Given a query q, the similarity score of a document d matching the query was computed by :",null,null
122,"X tf (t) · idf 2(t) · coord(q, d) · queryN orm(q) (3)",null,null
123,tq,null,null
124,"where tf (t) is term frequency of term t in document d, idf(t) the inverse document frequency of t, coord(q, d) a coordination factor based on the number of terms shared by q and d, and queryN orm(q) a normalization value for query q given the sum of squared weights of query terms. The function is a variation of the well-known cosine similarity measure. Additional details can be found in [13, 4].",null,null
125,4.2 Search Methods,null,null
126,"When an agent found no sufficiently relevant information from its local collection, it forwarded the query to another agent. We proposed the following four neighbor selection strategies, i.e., search methods, to be tested and compared in experiments.",null,null
127,4.2.1 RW: Random Walk,null,null
128,"The Random Walk (RW) strategy ignores knowledge about neighbors and simply forwards a query to a random neighbor. Without any learning module, Random Walk is presumably neither efficient nor effective. Hence, the Random Walk served as the search performance lower-bound.",null,null
129,4.2.2 SIM: Similarity-based Search,null,null
130,"Let k be the number of neighbors an agent has and S ,"" [s1, .., sk] be the vector about neighbors' similarity scores to a query. The SIM method sorts the vector and forwards the query to the neighbor with the highest score. We assumed that agents were cooperative ­ that is, they shared with one another document frequency (DF) values of key terms in their collections, based on which a meta document were created as representative of a neighbor's topical area. A query was then compared with each meta document, represented by DF*INF (see Equation 2), to generate the similarity vector S.""",null,null
131,4.2.3 DEG: Degree-based Search,null,null
132,"In the degree-based strategy, information about neighbors' degrees, i.e., their numbers of neighbors, was known to the current agent. Let D ,"" [d1, .., dk] denote degrees of an agent's neighbors. The DEG method sorts the D vector and forwards the query to the neighbor with the highest degree, regardless of what a query is about [1].""",null,null
133,4.2.4 SimDeg: Similarity*Degree Search,null,null
134,"The SimDeg method combines information about neighbors' relevance to a query and their degrees. [20] reasoned that a navigation decision relies on the estimate of a neighbor's distance from the target, or the probability that the neighbor links to the target directly, and proposed a measure based on the product of a degree term (d) and a similarity term (s) to approximate the expected distance. Following the same formulation, the SimDeg method used a combined measure SD ,"" [s1 · d1, .., sk · dk] to rank neighbors, given neighbor relevance vector S "","" [s1, .., sk] and neighbor degree vector D "","" [d1, .., dk]. A query were forwarded to the neighbor with the highest sd value.""",null,null
135,4.3 Agent Rewiring and Network Clustering,null,null
136,"We used the clustering exponent  to guide agent selforganization and network clustering. For each agent, the first step was to determine how many neighbors it should have. Given the web collection (Section 5.1) used in this study, we obtained each agent's (i.e., a web domain) indegree based on hyperlink analysis and normalized the degree to a value d  [30, 60]. Once agent u determined its degree du, a number of random agents were selected for u such that the total number of random neighbors dT du (dT  150 in this study). Then, the current agent (u) used its metadocument to query each of the dT neighbors (v) to determine their topical distance ruv. Finally, the following probability function was used by the agent to decide who should remain as neighbors (overlay): puv  ru-v, where  is the clustering exponent and ruv pairwise topical distance.",null,null
137,5. EXPERIMENTAL SETUP,null,null
138,5.1 Data Collection,null,null
139,"We used the ClueWeb09 Category B collection created by the Language Technologies Institute at CMU for IR experiments, which contains a crawl of 50 million English pages during Jan - Feb 2009. Analysis of the hyperlink graph produced Figures 4 (a) in-degree frequency distribution and (b) Site size (#pages per site) distribution based on 50, 221, 776 pages extracted from 2, 777, 321 unique domains (treated as sites) (on log/log coordinates).",null,null
140,5.2 Task and Queries,null,null
141,"Given the large size of the data collection, it is nearly impossible to manually judge the relevance of every document and to establish a complete relevance base. While previous research on large scale distributed information retrieval mainly relied on similarity thresholds to do automatic relevance judgment, such an approach was rather arbitrary and was biased by the centralized IR system that served as the gold standard [5, 16].",null,null
142,77,null,null
143,1e+06,null,null
144,1e+08,null,null
145,Degree frequency f(k),null,null
146,1e+00,null,null
147,1e+02,null,null
148,1e+04,null,null
149,1e+06,null,null
150,1,null,null
151,10,null,null
152,100,null,null
153,10000,null,null
154,In-degree (k),null,null
155,(a) In-degree distribution,null,null
156,1e+00,null,null
157,1e+02,null,null
158,1e+04,null,null
159,1e+06,null,null
160,Web site size (# pages) (s),null,null
161,(b) Site size distribution,null,null
162,Figure 4: ClueWeb09 Category B Statistics,null,null
163,5.2.1 Documents as Queries,null,null
164,"Serving diverse users in an open, dynamic environment, implies that some queries are likely to be narrowly defined. We reasoned that relevant information is rare when a query is very specific. In this study, we used documents (web pages with title and content) as queries to simulate decentralized searches. We obtained a set of query documents by sampling documents from the 100 most popular web domains. Removing queries that were too broad or vague resulted in 85 queries.",null,null
165,5.2.2 Task: Exact/Rare Item Search,null,null
166,"To make searches more realistic/challenging and automatic evaluation more objective, we considered extreme rarity of relevant documents given very specific information needs. We decided that, given each query, there was only one relevant document among all documents distributed in the network and the task was to find that exact document. When a query document was issued to a random system/site in the network, the task involved finding the system who hosted it. The strength of this task is that relevance judgment was more objective provided the relative unambiguity of a ""hosting"" relationship. The extreme rarity, however, posed a great challenge on the proposed decentralized search methods.",null,null
167,5.3 Evaluation Metrics,null,null
168,This study focused on effectiveness and efficiency of IR operations in networks and scalability of decentralized search. We emphasized the finding of exact/rare information in large distributed environments and proposed the use of the following evaluation metrics.,null,null
169,5.3.1 Effectiveness,null,null
170,"Of various evaluation metrics used in TREC and IR, pre-",null,null
171,cision and recall are the basic forms. Whereas precision P,null,null
172,"measures the fraction of retrieved documents being relevant,",null,null
173,recall R evaluates the fraction of relevant documents being,null,null
174,"retrieved. The harmonic mean of precision and recall, known",null,null
175,as,null,null
176,"F1,",null,null
177,is,null,null
178,computed,null,null
179,by,null,null
180,F1,null,null
181,",",null,null
182,2·P ·R P +R,null,null
183,[4].,null,null
184,5.3.2 Efficiency,null,null
185,"In experiments, we measured the search path length L (i.e., the number of agents involved) and actual time  taken to find relevant information for each query. The average search length L¯ of all queries was calculated to measure efficiency. When fewer agents are involved, the entire dis-",null,null
186,Size frequency f(s),null,null
187,1e+00,null,null
188,1e+02,null,null
189,1e+04,null,null
190,"tributed system is considered to be more efficient. Likewise, average search time ¯ was calculated to evaluate efficiency.",null,null
191,5.3.3 Scalability,null,null
192,"One important objective of this research was to learn how decentralized IR systems can function and scale in very large information network. For scalability, we ran experiments on different network size scales N  [102, 103, 104]. First, we used the 100 most highly linked web domains to form a 100agent network and conducted experiments on it. Then, we extended the network to 1, 000 and 10, 000 systems/sites for additional experiments. Table 1 shows the total number of documents on each network scale. After experiments, we analyzed the functional relationships of effectiveness and efficiency to network size.",null,null
193,Network Size N 102 103 104 # Documents 0.5M 1.7M 4.4M,null,null
194,Table 1: Network Size and Total # Docs,null,null
195,5.4 Simulation Procedures and Setup,null,null
196,"Pseudo code in Algorithm 1 illustrates how different experimental parameters were combined for the simulations. Experiments were conducted on a Linux cluster of 10 PC nodes, each having Dual Intel Xeon e5405 (2.0 Ghz) Quad Core Processors (8 processors), 8 GB fully buffered system memory, and a Fedora 7 installation. The computer nodes were connected internally through a dedicated 1Gb network switch. Agents were distributed among the 80 processors. The Java Runtime Environment version was 1.6.0 07.",null,null
197,Algorithm 1 Simulation Experiments,null,null
198,"1: for each Network Size  [102, 103, 104] do 2: for each   [0, .., 15] do",null,null
199,3: rewire network with the  value,null,null
200,4: for each Search Method do,null,null
201,5:,null,null
202,for each Query do,null,null
203,6:,null,null
204,assign query to a random agent,null,null
205,7:,null,null
206,repeat,null,null
207,8:,null,null
208,forward query from one another,null,null
209,9:,null,null
210,until relevant agent found OR search path L ,null,null
211,Lmax,null,null
212,10:,null,null
213,if sufficient relevant information found then,null,null
214,11:,null,null
215,send the results back,null,null
216,12:,null,null
217,else,null,null
218,13:,null,null
219,send failure message back,null,null
220,14:,null,null
221,end if,null,null
222,15:,null,null
223,end for,null,null
224,16:,null,null
225,"measure effectiveness P , R, and F1",null,null
226,17:,null,null
227,measure efficiency ¯ and L¯,null,null
228,18: end for,null,null
229,19: end for,null,null
230,20: end for,null,null
231,6. RESULTS,null,null
232,"We conducted experiments on networks of 102, 103, and 104 systems. We set the max search length length Lmax to 20% of network population so that even less effective/efficient",null,null
233,methods will be able to persist in searches. Figures 5 and,null,null
234,78,null,null
235,Search Path Length (#hops),null,null
236,"6 present results on IR effectiveness (recall, precision, and F1) while Figures 7, 8, and 9 report on efficiency (search path length and time) against different network clustering conditions (guided by clustering exponent ).",null,null
237,6.1 Effectiveness,null,null
238,10,null,null
239,15,null,null
240,Network Size: 100 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
241,20,null,null
242,Search Time (s),null,null
243,400,null,null
244,600,null,null
245,800,null,null
246,Network Size: 100 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
247,5,null,null
248,200,null,null
249,1.0,null,null
250,1.0,null,null
251,0,null,null
252,0.8,null,null
253,0.8,null,null
254,0.6,null,null
255,RECALL,null,null
256,Network Size: 100 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
257,PRECISION,null,null
258,0.4,null,null
259,0.6,null,null
260,Network Size: 100 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
261,0,null,null
262,5,null,null
263,10,null,null
264,15,null,null
265,20,null,null
266,Clustering Exponent (ALPHA),null,null
267,(a) Search Length,null,null
268,0,null,null
269,5,null,null
270,10,null,null
271,15,null,null
272,20,null,null
273,Clustering Exponent (ALPHA),null,null
274,(b) Search Time,null,null
275,Figure 7: Efficiency on Network 100.,null,null
276,0.4,null,null
277,0.2,null,null
278,0.2,null,null
279,0.0,null,null
280,0,null,null
281,5,null,null
282,10,null,null
283,15,null,null
284,20,null,null
285,Clustering Exponent (ALPHA),null,null
286,(a) Recall,null,null
287,0,null,null
288,5,null,null
289,10,null,null
290,15,null,null
291,20,null,null
292,Clustering Exponent (ALPHA),null,null
293,(b) Precision,null,null
294,Figure 5: Effectiveness on Network 100,null,null
295,"As shown in Figures 5 and 6, the similarity-based search (SIM) and similarity*degree (SimDeg) method performed very well in terms of effectiveness, showing a very large advantage in recall over the degree-based (DEG) and randomwalk (RW) methods. When the network was under some proper clustering conditions (e.g., with   10 for network 10,000), the SIM and Sim*Deg methods achieved nearly 100% recall. Precision was 1.0 for all conditions because a document was retrieved only when it exactly matched the query.",null,null
296,0.0,null,null
297,Search Path Length (#hops),null,null
298,40,null,null
299,60,null,null
300,80,null,null
301,"5 hops and 150 milliseconds to find exact match for each query, it took RW more than 15 hops and 400 milliseconds to reach 20% of targets (a 3-time difference in efficiency). When the network size increased to 10, 000, RW search took 50 seconds and traversed about 1, 500 nodes on average to reach a < 0.4 recall whereas SIM search took less than 4 seconds and roughly 110 nodes to achieve a 1.0 recall ­ a more than 10-time difference in efficiency.",null,null
302,Network Size: 1000 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
303,Network Size: 1000 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
304,100,null,null
305,Search Time (s) 500 1000 1500 2000 2500 3000 3500 4000,null,null
306,20,null,null
307,1.0,null,null
308,1.0,null,null
309,0.6,null,null
310,0.8,null,null
311,F1,null,null
312,Network Size: 1000 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
313,F1,null,null
314,0.6,null,null
315,Network Size: 10000 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
316,0.4,null,null
317,0.4,null,null
318,0.2,null,null
319,0.0,null,null
320,0,null,null
321,5,null,null
322,10,null,null
323,15,null,null
324,20,null,null
325,Clustering Exponent (ALPHA),null,null
326,(a) F1 on network 103,null,null
327,0,null,null
328,5,null,null
329,10,null,null
330,15,null,null
331,20,null,null
332,Clustering Exponent (ALPHA),null,null
333,(b) F1 on network 104,null,null
334,Figure 6: Effectiveness on Larger Networks,null,null
335,"The DEG search method, biased toward highly linked (popular) sites in the searches, achieved moderate performance between SIM and RW methods and had improved performance in larger networks, e.g., a roughly 0.7 recall in the 10,000-system network. Random walk (RW) consistently performed below a 0.4 recall across all network sizes and  conditions.",null,null
336,6.2 Efficiency,null,null
337,"Figures 7, 8, and 9 show very high efficiency of the SIM and SimDeg search methods across the network sizes, especially under stronger clustering conditions. The efficiency gap between the SIM/SimDeg and RW/DEG methods increased dramatically as network size increased. For example, in the 100-node network, while SIM searched roughly",null,null
338,0.8,null,null
339,0,null,null
340,5,null,null
341,10,null,null
342,15,null,null
343,20,null,null
344,Clustering Exponent (ALPHA),null,null
345,(a) Search Length,null,null
346,0,null,null
347,5,null,null
348,10,null,null
349,15,null,null
350,20,null,null
351,Clustering Exponent (ALPHA),null,null
352,(b) Search Time,null,null
353,"Figure 8: Efficiency on Network 1,000.",null,null
354,"Figures 7 - 9 demonstrate that network structure had a great impact on decentralized IR performance, particularly on efficiency in larger networks. While search efficiency (in terms of search path length and search time) under different clustering conditions only differed slightly in the 100-agent network, the difference was much larger in the 10, 000-agent network (Figure 9). For example, the average search path length for the SIM method decreased from 6 to 5 (a 20% difference) when the clustering exponent was changed from 0 (random network) to 10 (strong clustering) in the 100 network. In the 10, 000-agent network, however, the same degree of change in network clustering led to a roughly 200% difference in search efficiency. Statistical tests indicated that SIM search achieved significantly better results with a balanced level of network clustering (i.e., at  ,"" 10) than with over- or weak-clustering networks. The significant differences not only appeared in the 10, 000-system network but also in the 100- and 1000-system networks.""",null,null
355,6.3 Scalability,null,null
356,"For each network size, we identified network clustering conditions under which superior performance was observed (i.e., at  , 10) and plotted average search path length (efficiency) against network size in Figure 10. As discussed ear-",null,null
357,79,null,null
358,Search Path Length (#hops),null,null
359,1000,null,null
360,500,null,null
361,Network Size: 10000 Similarity Search Similarity*Degree Degree Search Random Walk,null,null
362,200,null,null
363,100,null,null
364,0,null,null
365,5,null,null
366,10,null,null
367,15,null,null
368,20,null,null
369,Clustering Exponent (ALPHA),null,null
370,"Figure 9: Efficiency on Network 10, 000. Y is log transformed.",null,null
371,"lier, SIM and SimDeg searches consistently achieved nearly 1.0 recall and precision across the various network sizes, much better than DEG and RW methods. DEG search tended to perform slightly better in larger networks than in smaller ones. However, as shown in Figure 10, search path length for RW and DEG dramatically increased in larger networks, while the increases for SIM and SimDeg were relatively moderate.",null,null
372,Similarity Search Similarity*Degree Degree Search Random Walk,null,null
373,1500,null,null
374,1000,null,null
375,Efficiency: Search Path Length (#hops),null,null
376,500,null,null
377,0,null,null
378,100 200,null,null
379,500 1000 2000 Network Size: log(N),null,null
380,5000 10000,null,null
381,"Figure 10: Scalability of all search methods with  , 10. X denotes network size and is log transformed.",null,null
382,6.3.1 Scalability of SIM Search,null,null
383,"SIM and SimDeg methods appeared to be much more scalable than RW and DEG methods. To better understand the scalability of SIM search and to predict how it could perform in even larger networks (e.g., a network of millions of nodes), we conducted further analysis on the relationship of its efficiency to network size.",null,null
384,"Previous research on complex networks suggested that optimal network clustering supports scalable searches, in which search time is a poly-logarithmic function of network size [15]. We relied on a generalized regression model that modeled search path length L (and search time  ) against log-",null,null
385,transformed network size N . The model was specified to,null,null
386,"reach the origin (0, 0) because, when log(N ) ,"" 0 (i.e., N "",",null,null
387,"1), there is only one node and no effort is needed to search a network. The best fit for search path length L was produced by the model in Table 2, in which L , 0.0275 · log160(N ) with a nearly perfect R2 , 0.9971.",null,null
388,"Search Length: L  0 +  log610(N ), where N is network size.",null,null
389,Estimate Standard Error t P r(> |t|),null,null
390, 0.0275,null,null
391,0.0042,null,null
392,65.73 < 2E-16 ***,null,null
393,"R2 ,"" 0.997 (adj. 0.9968), F "", 4320 on 1 and 13 DF",null,null
394,Table 2: Search path length vs. Network size,null,null
395,"The same model was also applied to identify a poly-logarithmic function of search time  and network size N with a smaller R2 ,"" 0.752. Apparently, search time involves other factors such as machine load fluctuation and is less predictable than search path length.""",null,null
396,"Overall, the scalability analysis supports search time as a poly-logarithmic function of network size ­ so that when an information network continues to grow in magnitude, it is still promising to conduct effective IR and search operations within a manageable time limit. Although we found the order of the poly-logarithmic relationship to be roughly 6 in this study, a smaller exponent can be expected when other factors on network structure and search methods can be optimized.",null,null
397,6.3.2 Scalability of Network Clustering,null,null
398,"Our search methods relied on local indexes and a structure self-organized by distributed systems in the network. Without global information and centralized control, network clustering was performed locally ­ distributed systems formed the network structure in terms of their limited opportunities to interact and individual preferences and constraints on building indexes for others. This local mechanism for clustering demonstrated a high level of scalability. As shown in Figure 11, average clustering time c remained relatively constant, < 1 sec, across all network size scales N  [102, 103, 104, 105].",null,null
399,7. CONCLUSION,null,null
400,"We conducted experiments on decentralized IR operations on various scales of information networks and analyzed effectiveness, efficiency, and scalability of proposed search methods. Results showed network structure, i.e., how distributed systems connect to one another, is crucial for retrieval performance. With a balanced level of network clustering under local topical guidance, similarity-based search functions (i.e., SIM and SimDeg) were found to perform very efficiently while maintaining a high level of effectiveness even in very large networks. For example, in searches for single unique documents among the 4.4 million documents distributed among 10, 000 agents/systems, selectively involving only 110 agents within 4 seconds yielded 100% precision and 100% recall with a guiding clustering exponent  ,"" 10. Under these conditions, more importantly, search time was well""",null,null
401,1Each of the three X levels has multiple data points. Future work will integrate whether the relationship can be used to predict search efficiency on larger scales.,null,null
402,80,null,null
403,Clustering Time (milliseconds),null,null
404,100,null,null
405,1000,null,null
406,3000,null,null
407,50,null,null
408,1e+02,null,null
409,Individual clustering time Average clustering time,null,null
410,1e+03,null,null
411,1e+04,null,null
412,Network Size (N),null,null
413,1e+05,null,null
414,Figure 11: Scalability of Network Clustering,null,null
415,"explained by a poly-logarithmic function of network size, suggesting high scalability of the proposed methods.",null,null
416,"In addition, the network clustering function that supported very high effectiveness and efficiency of IR operations in large networks is itself scalable. Clustering only involved local self-organization and required no global control ­ clustering time remained roughly constant across the various network sizes N  [102, 103, 104, 105].",null,null
417,"This study provides guidance on how IR operations can function and scale when today's information spaces continue to grow in magnitude. Particularly, we have found that connectivity among distributed systems, based on local network clustering, is crucial to the scalability of decentralized methods. The clustering paradox on decentralized search performance appears to have a scaling effect and deserves special attention for IR operations in large scale networks.",null,null
418,Acknowledgment,null,null
419,"We appreciate valuable discussions with Gary Marchionini, Munindar P. Singh, Diane Kelly, Jeffrey Pomerantz, Jos´e R. P´erez-Agu¨era, and Simon Spero, and constructive comments from SIGIR'10 reviewers. We thank the NC Translational and Clinical Sciences (TraCS) Institute for support.",null,null
420,8. REFERENCES,null,null
421,"[1] L. Adamic and E. Adar. How to search a social network. Social Networks, 27(3):187 ­ 203, 2005.",null,null
422,"[2] R. Albert and A.-L. Barab´asi. Statistical mechanics of complex networks. Reviews of Modern Physics, 74(1):47­97, 2002.",null,null
423,"[3] R. Baeza-Yates, C. Castillo, F. Junqueira, V. Plachouras, and F. Silvestri. Challenges on distributed web retrieval. ICDE 2007: Data Engineering 2007., pages 6­20, April 2007.",null,null
424,"[4] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison Wesley Longman Publishing, 2004.",null,null
425,"[5] M. Bawa, G. S. Manku, and P. Raghavan. Sets: search enhanced by topic segmentation. In SIGIR '03, pages 306­313, 2003.",null,null
426,"[6] F. L. Bellifemine, G. Caire, and D. Greenwood. Developing Multi-Agent Systems with JADE (Wiley Series in Agent Technology). John Wiley & Sons, 2007.",null,null
427,"[7] M. Bender, S. Michel, P. Triantafillou, G. Weikum, and C. Zimmer. Improving collection selection with overlap awareness in p2p search engines. In SIGIR '05, pages 67­74, 2005.",null,null
428,"[8] M. Bogun~a´, D. Krioukov, and K. C. Claffy. Navigability of complex networks. Nature Physics, 5(1):74 ­80, 2009.",null,null
429,"[9] J. Callan, F. Crestani, and M. Sanderson. SIGIR 2003 workshop on distributed information retrieval. SIGIR Forum, 37(2):33­37, 2003.",null,null
430,"[10] A. Crespo and H. Garcia-Molina. Semantic overlay networks for p2p systems. In Agents and Peer-to-Peer Computing, pages 1­13, 2005.",null,null
431,"[11] C. Doulkeridis, K. Norvag, and M. Vazirgiannis. Peer-to-peer similarity search over widely distributed document collections. In LSDS-IR '08, pages 35­42, 2008.",null,null
432,"[12] M. S. Granovetter. The strength of weak ties. American Journal of Sociology, 78(6):1360­1380, May 1973.",null,null
433,"[13] E. Hatcher, O. Gospodneti´c, , and M. McCandless. Lucene in Action. Manning Publications, second edition edition, March 2010.",null,null
434,"[14] W. Ke and J. Mostafa. Strong ties vs. weak ties: Studying the clustering paradox for decentralized search. In LSDS-IR'08, pages 49­56, Boston, USA, July 23 2009.",null,null
435,"[15] J. M. Kleinberg. Navigation in a small world. Nature, 406(6798), August 2000.",null,null
436,"[16] J. Lu and J. Callan. User modeling for full-text federated search in peer-to-peer networks. In SIGIR '06, pages 332­339, 2006.",null,null
437,"[17] E. K. Lua, J. Crowcroft, M. Pias, R. Sharma, and S. Lim. A survey and comparison of peer-to-peer overlay network schemes. IEEE Communications Surveys and Tutorials, 7:72­93, 2005.",null,null
438,"[18] T. Luu, F. Klemm, I. Podnar, M. Rajman, and K. Aberer. Alvis peers: a scalable full-text peer-to-peer retrieval engine. In P2PIR '06, pages 41­48, 2006.",null,null
439,"[19] A. L. Powell and J. C. French. Comparing the performance of collection selection algorithms. ACM Transactions on Information Systems (TOIS), 21(4):412­456, October 2003.",null,null
440,"[20] O. Simsek and D. Jensen. Navigating networks by using homophily and degree. Proceedings of the National Academy of Sciences, 105(35):12758­12762, 2008.",null,null
441,"[21] G. Skobeltsyn, T. Luu, I. P. Zarko, M. Rajman, and K. Aberer. Web text retrieval with a p2p query-driven index. In SIGIR '07, pages 679­686, 2007.",null,null
442,"[22] D. J. Watts, P. S. Dodds, and M. E. J. Newman. Identity and Search in Social Networks. Science, 296(5571):1302­1305, 2002.",null,null
443,"[23] I. P. Zarko and F. Silvestri. The CIKM 2006 workshop on information retrieval in peer-to-peer networks. SIGIR Forum, 41(1):101­103, 2007.",null,null
444,81,null,null
445,,null,null
