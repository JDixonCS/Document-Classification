,sentence,label,data
,,,
0,Estimation of Statistical Translation Models Based on Mutual Information for Ad Hoc Information Retrieval,null,null
,,,
1,Maryam Karimzadehgan,null,null
,,,
2,Department of Computer Science University of Illinois at Urbana-Champaign,null,null
,,,
3,"Urbana, IL 61801",null,null
,,,
4,mkarimz2@illinois.edu,null,null
,,,
5,ABSTRACT,null,null
,,,
6,"As a principled approach to capturing semantic relations of words in information retrieval, statistical translation models have been shown to outperform simple document language models which rely on exact matching of words in the query and documents. A main challenge in applying translation models to ad hoc information retrieval is to estimate a translation model without training data. Existing work has relied on training on synthetic queries generated based on a document collection. However, this method is computationally expensive and does not have a good coverage of query words. In this paper, we propose an alternative way to estimate a translation model based on normalized mutual information between words, which is less computationally expensive and has better coverage of query words than the synthetic query method of estimation. We also propose to regularize estimated translation probabilities to ensure sufficient probability mass for self-translation. Experiment results show that the proposed mutual information-based estimation method is not only more efficient, but also more effective than the synthetic query-based method, and it can be combined with pseudo-relevance feedback to further improve retrieval accuracy. The results also show that the proposed regularization strategy is effective and can improve retrieval accuracy for both synthetic query-based estimation and mutual information-based estimation.",null,null
,,,
7,Categories and Subject Descriptors,null,null
,,,
8,H.3.3 [Information Search and Retrieval]: Retrieval Models,null,null
,,,
9,General Terms,null,null
,,,
10,"Algorithms, Theory",null,null
,,,
11,Keywords,null,null
,,,
12,"Statistical Machine Translation, Language Models, Estimation, Smoothing, Feedback",null,null
,,,
13,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10, July 19­23, 2010, Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",null,null
,,,
14,ChengXiang Zhai,null,null
,,,
15,Department of Computer Science University of Illinois at Urbana-Champaign,null,null
,,,
16,"Urbana, IL 61801",null,null
,,,
17,czhai@cs.illinois.edu,null,null
,,,
18,1. INTRODUCTION,null,null
,,,
19,"Designing effective retrieval models is central for information retrieval. In the past, many retrieval models such as vector space model [28, 29, 30] and probabilistic model [6, 22, 25, 27, 34] have been proposed and gained certain success. Recently, language modeling approaches have received considerable attentions because of its sound statistical foundation and good empirical performance [22, 42]. In language modeling approaches, documents are ranked according to how likely a query is generated from the corresponding document models. In basic language models, document models are estimated based on multinomial distribution and smoothing techniques are critical for document model estimation [42]. When ranking documents, the basic language modeling approach is primarily based on exact matching of terms between documents and queries. Since queries are generally succinct and relevant documents may use different vocabulary, such an approach can suffer from vocabulary gap problem.",null,null
,,,
20,"As a principled approach to capturing semantic word relations, statistical translation language models have been proposed for information retrieval to reduce the gap between documents and queries [2, 8]. Based on statistical machine translation [3], the basic idea of translation language models is to estimate the likelihood of translating a document to a query. Since a term has certain probability to be translated into a different term, translation language models can alleviate the vocabulary gap problem in a direct manner. As a result, translation language models have been successfully applied to different tasks such as cross-lingual information retrieval [12, 20, 39], question answering [40], sentence retrieval [19], and tracking information flow [18].",null,null
,,,
21,"Surprisingly, there has been little work on applying translation models to ad hoc retrieval. Indeed, the original paper [2] that proposed translation models for ad hoc retrieval appears to be the only study that we are aware of. One possible reason may be because of the difficulty in estimating translation models. In [2], authors solved the problem by generating synthetic queries. Unfortunately, this method has two deficiencies: (1) it is inefficient; (2) there is no guarantee that a query word is covered.",null,null
,,,
22,"In this paper, we propose a simpler method for estimating a translation model, which is based on normalized mutual information between words. Our Contributions are as follows:",null,null
,,,
23,1. We propose an efficient and effective way of estimating word-to-word translation probabilities based on mutual information.,null,null
,,,
24,323,null,null
,,,
25,"2. We propose regularization of self-translation probabilities, which can improve retrieval performance of translation models with both the existing estimation approach and the proposed mutual information-based approach.",null,null
,,,
26,3. We study the issue of smoothing in the context of translation language modeling and show that translation language models are less sensitive to the effect of smoothing.,null,null
,,,
27,"4. We show that with mutual information, the translation language model can be combined with pseudorelevance feedback to further improve the retrieval accuracy.",null,null
,,,
28,2. STATISTICAL TRANSLATION MODEL FOR RETRIEVAL,null,null
,,,
29,"In this section, we review basic language modeling approach, statistical translation language model and smoothing methods for statistical translation model. Finally, we discuss the estimation of translation model.",null,null
,,,
30,2.1 Basic Language Modeling Approach,null,null
,,,
31,"The language modeling approach to information retrieval was first introduced by Ponte and Croft [22]. The basic idea can be described as follows. We assume that a query q is generated by a probabilistic model based on a document d. Given a query q ,"" q1, q2, . . . , qm, and a document d, we are interested in estimating p(d|q) , i.e. the probability that document d has been used to generate query q. By applying Bayes' formula, we have:""",null,null
,,,
32,p(d|q)  p(q|d)p(d),null,null
,,,
33,"p(d) on the right hand side of the above formula is our prior belief that document d is relevant to any query. p(q|d) is the query likelihood for the given document d, which intuitively measures how well document d matches query q. p(d) is often assumed to be uniform and thus can be ignored for ranking documents. Further assuming that each query word is generated independently, we can rewrite the above formula as (in the form of log likelihood):",null,null
,,,
34,"log p(d|q) , rank",null,null
,,,
35,"c(w, q). log p(w|d)",null,null
,,,
36,wV,null,null
,,,
37,"where ,"" rank means equivalence for the purpose of ranking documents, c(w, q) is count of word w in query q, and V is the vocabulary set. The challenging part is to estimate a document model p(w|d). Based on multinomial distribution, the simplest way to estimate p(w|d) is the maximum likelihood estimator :""",null,null
,,,
38,"pml(w|d) ,",null,null
,,,
39,"c(w, d) w c(w , d)",null,null
,,,
40,"Where c(w, d) is count of word w in document d. Due to the data sparseness problem, maximum likelihood estimator under-estimates the probability of unseen words in a document. Smoothing techniques address this problem by assigning non-zero probabilities to the unseen words and thus improving the accuracy of probability estimation. Specifically, smoothing is to discount the probabilities of words seen in the text and then assign extra probability mass to the unseen words according to some fallback model. Usually, collection",null,null
,,,
41,language model is used as fallback model [42]. Two commonly used methods are Jelinek-Mercer and Dirichlet Prior smoothing methods:,null,null
,,,
42,"Jelinek-Mercer Method (JM Smoothing): This is a linear interpolation of maximum likelihood model with the collection model, using  as a coefficient weight.",null,null
,,,
43,"p(w|d) , (1 - )pml(w|d) + p(w|C)",null,null
,,,
44,-1,null,null
,,,
45,Where p(w|C) is probability of word w in collection C. Bayesian Smoothing using Dirichlet Prior (Dirichlet Prior,null,null
,,,
46,"Smoothing): Since the conjugate prior of a multinomial distribution is the Dirichlet distribution, we can specify a Dirichlet prior distribution parameterized as",null,null
,,,
47,"(p(w1|C), p(w2|C), . . . , p(wn|C))",null,null
,,,
48,where  is a parameter. The estimated document model based on the posterior mean is then:,null,null
,,,
49,p(w|d),null,null
,,,
50,",",null,null
,,,
51,|d| |d| +,null,null
,,,
52, pml(w|d),null,null
,,,
53,+,null,null
,,,
54, |d| +,null,null
,,,
55,p(w|C ) ,null,null
,,,
56,-2,null,null
,,,
57,2.2 Statistical Translation Language Model,null,null
,,,
58,"Another interesting way of estimating p(w|d) introduced by Berger and Lafferty [2] is based on statistical machine translation [3]. In order to assess the relevance of a document to a user's query, they have estimated the probability that the query would have been generated as a translation of the document. In other words, they allow the query likelihood to be computed based on a translation model of form p(w|u), which is the probability that word u is semantically translated to word w.",null,null
,,,
59,"To put it more formally, in their model, the query likelihood can be calculated by using the following ""translation document model"":",null,null
,,,
60,"pt(w|d) , pt(w|u)p(u|d)",null,null
,,,
61,ud,null,null
,,,
62,"where pt(w|u) is the probability of ""translating"" word u into word w and it allows us to score a document by counting the matches between a query word and semantically related words in the document. If pt(w|u) only allows a word to be translated into itself, the simple exact matching query likelihood would be achieved. However, pt(w|u) would in general allow us to translate u into other semantically related words with non-zero probabilities, thus achieving ""semantic smoothing"" of the document language model.",null,null
,,,
63,2.3 Smoothing for Translation Language Model,null,null
,,,
64,"In this section, we consider statistical machine translation when combined with two basic smoothing methods described in section 2.1.",null,null
,,,
65,"The basic component in the translation language model is pt(w|d) , ud pt(w|u)p(u|d) which can be used to replace pml(w|d) in all basic language model approaches. This will give us 1) translation language model with Dirichlet prior smoothing and 2) translation language model with Jelinek-Mercer smoothing. When we replace pml(w|d) with pt(w|d) ,"" ud p(u|d)pt(w|u) in equation 2, we have the following:""",null,null
,,,
66,pt(w|d),null,null
,,,
67,",",null,null
,,,
68,|d| |d| +,null,null
,,,
69,[,null,null
,,,
70,p(u|d),null,null
,,,
71,·,null,null
,,,
72,pt(w|u)],null,null
,,,
73,+,null,null
,,,
74, |d| +,null,null
,,,
75, p(w|C),null,null
,,,
76,-3,null,null
,,,
77,ud,null,null
,,,
78,324,null,null
,,,
79,"And when pt is replaced with pml in equation 1, we have the following:",null,null
,,,
80,"pt(w|d) , (1 - )[ p(u|d) · pt(w|u)] + p(w|C) (4)",null,null
,,,
81,ud,null,null
,,,
82,"Equations 3 and 4 give us Dirichlet prior smoothing and Jelinek-Mercer (JM) smoothing with translation language model, respectively.",null,null
,,,
83,Authors in [2] only considered translation language model with Jelinek-Mercer smoothing.,null,null
,,,
84,2.4 Estimation of Translation Model,null,null
,,,
85,The key part for translation language model is to learn,null,null
,,,
86,"the word-to-word translation probability, pt(w|u). It is clear",null,null
,,,
87,that the performance of the proposed smoothed translation,null,null
,,,
88,model depends on the quality of the word-to-word trans-,null,null
,,,
89,lation probabilities. In the scenario of statistical machine,null,null
,,,
90,"translation [3], a parallel corpus of two languages is often",null,null
,,,
91,"assumed to be available, and the EM algorithm [5] can be",null,null
,,,
92,used to estimate a translation model.,null,null
,,,
93,In order to gain word-to-word probabilities in monolingual,null,null
,,,
94,"scenario, ideally, we should have a sample of queries and rel-",null,null
,,,
95,"evant documents, but since we do not often have, Berger and",null,null
,,,
96,Lafferty [2] use the idea of synthetic queries as their training,null,null
,,,
97,data. The idea is to take a document and synthesize a query,null,null
,,,
98,to which the document would be relevant. They proposed,null,null
,,,
99,a sampling technique which distinguishes a document from,null,null
,,,
100,other documents.,null,null
,,,
101,In order to select words which are representative of a doc-,null,null
,,,
102,"ument, for each document d  D, they compute the mutual",null,null
,,,
103,information statistics [7] for each of its words according to:,null,null
,,,
104,"I(w, d)",null,null
,,,
105,",",null,null
,,,
106,"p(w, d) log",null,null
,,,
107,p(w|d) p(w|D),null,null
,,,
108,",",null,null
,,,
109,where,null,null
,,,
110,p(w|d),null,null
,,,
111,is,null,null
,,,
112,the,null,null
,,,
113,probabil-,null,null
,,,
114,"ity of word w in document d, and p(w|D) is the probabil-",null,null
,,,
115,ity of word w in the collection. Their proposed algorithm,null,null
,,,
116,"for generating synthetic queries is shown in figure 1, where",null,null
,,,
117,"synthetic queries are sampled based on normalized mutual information I~, and the Poisson parameter  is set to 15. The",null,null
,,,
118,"resulting (d, q) of documents and synthetic queries are used",null,null
,,,
119,to estimate the probabilities with the EM algorithm. More,null,null
,,,
120,details can be found in [2].,null,null
,,,
121,1. Begin,null,null
,,,
122,2,null,null
,,,
123,Do for each document d  D,null,null
,,,
124,3,null,null
,,,
125,"Do for x , 1 to 5",null,null
,,,
126,4,null,null
,,,
127,Begin,null,null
,,,
128,5,null,null
,,,
129,Select a length m for this query according to,null,null
,,,
130,Poisson distribution,null,null
,,,
131,6,null,null
,,,
132,"Do for i , 1 to m",null,null
,,,
133,7,null,null
,,,
134,Select the next query word by sampling the,null,null
,,,
135,scaled distribution: qi  I~,null,null
,,,
136,8,null,null
,,,
137,"Record (d, q)",null,null
,,,
138,9,null,null
,,,
139,End,null,null
,,,
140,10. End,null,null
,,,
141,Figure 1: A sampling for synthetic queries,null,null
,,,
142,"Although generating synthetic queries is a reasonable way to estimate the translation probabilities, this method has two deficiencies: (1) it is inefficient; (2) there is no guarantee that a query word is covered. In the next section, we propose a mutual information-based estimation which is more efficient than this method and has a better word coverage.",null,null
,,,
143,3. ESTIMATION OF TRANSLATION MODEL BASED ON MUTUAL INFORMATION,null,null
,,,
144,"In this section, we propose a more efficient way to estimate translation probabilities which can have a better coverage of query words than the existing method discussed in the previous section. We will also present a way to combine translation language model with pseudo-relevance feedback.",null,null
,,,
145,3.1 Mutual Information-Based Approach,null,null
,,,
146,"Mutual information [26] is a good measure to assess how two words are related. In our method, for each word in the collection, we compute all words which have high mutual information scores with it and normalize the computed mutual information scores as follows:",null,null
,,,
147,"First, we compute the mutual information scores for each pair of two words w and u in the collection. Informally, mutual information compares the probability of observing w and u together (the joint probability) with the probabilities of observing w and u independently. The mutual information between words w and u are calculated as follows:",null,null
,,,
148,I (w;,null,null
,,,
149,u),null,null
,,,
150,",",null,null
,,,
151,"Xw ,""0,1""",null,null
,,,
152,"Xu ,""0,1""",null,null
,,,
153,"p(Xw,",null,null
,,,
154,Xu),null,null
,,,
155,log,null,null
,,,
156,"p(Xw, Xu) p(Xw )p(Xu )",null,null
,,,
157,-5,null,null
,,,
158,where Xu and Xw are binary variables indicating whether u,null,null
,,,
159,or w is present or absent. The probabilities are estimated as follows:,null,null
,,,
160,"p(Xw , 1)",null,null
,,,
161,",",null,null
,,,
162,"c(Xw , 1) N",null,null
,,,
163,"p(Xw , 0) , 1 - p(Xw , 1)",null,null
,,,
164,"p(Xu , 1)",null,null
,,,
165,",",null,null
,,,
166,"c(Xu , 1) N",null,null
,,,
167,"p(Xu , 0) , 1 - p(Xu , 1)",null,null
,,,
168,"p(Xw ,"" 1, Xu "", 1)",null,null
,,,
169,",",null,null
,,,
170,"c(Xw ,"" 1, Xu "", 1) N",null,null
,,,
171,"p(Xw ,"" 1, Xu "", 0)",null,null
,,,
172,",",null,null
,,,
173,"(c(Xw , 1) - c(Xw ,"" 1, Xu "", 1)) N",null,null
,,,
174,"p(Xw ,"" 0, Xu "", 1)",null,null
,,,
175,",",null,null
,,,
176,"(c(Xu , 1) - c(Xw ,"" 1, Xu "", 1)) N",null,null
,,,
177,"p(Xw ,"" 0, Xu "", 0) , 1 - p(Xw ,"" 0, Xu "", 1)",null,null
,,,
178,#NAME?,null,null
,,,
179,"where c(Xw , 1) and c(Xu ,"" 1) are the numbers of documents containing word w and u, respectively, c(Xw "","" 1, Xu "","" 1) is the number of documents that contain both w and u, and N in the total number of documents in the collection.""",null,null
,,,
180,We then normalize the mutual information score to obtain a translation probability:,null,null
,,,
181,"pmi(w|u) ,",null,null
,,,
182,I(w; u) w I(w ; u),null,null
,,,
183,-6,null,null
,,,
184,"pmi(w|u) gives us the probability of translating word u to another word w; intuitively, the probability would be higher if the two words tend to co-occur with each other.",null,null
,,,
185,3.2 Optimizing Self-Translation Probability,null,null
,,,
186,"The approaches described in sections 3.1 and 2.4 might under-estimate the self-translation probabilities, i.e., it is possible that p(w|u) > p(w|w). This may lead to nonoptimal retrieval performance because it is possible that a document that matches a query word exactly (p(w|w)) gets",null,null
,,,
187,325,null,null
,,,
188,Table 1: Sample word translation probabilities using,null,null
,,,
189,synthetic queries (left) and mutual information (right).,null,null
,,,
190,Note that words are stemmed.,null,null
,,,
191,"w,everest",null,null
,,,
192,"w,everest",null,null
,,,
193,q,null,null
,,,
194,p(q|w),null,null
,,,
195,q,null,null
,,,
196,p(q|w),null,null
,,,
197,everest 0.079,null,null
,,,
198,everest 0.1051,null,null
,,,
199,climber 0.042,null,null
,,,
200,climber 0.0423,null,null
,,,
201,climb 0.0365,null,null
,,,
202,mount 0.0339,null,null
,,,
203,mountain 0.0359,null,null
,,,
204,28,null,null
,,,
205,0.0308,null,null
,,,
206,mount 0.033,null,null
,,,
207,expedit 0.0303,null,null
,,,
208,reach 0.0312,null,null
,,,
209,peak,null,null
,,,
210,0.0155,null,null
,,,
211,expedit summit,null,null
,,,
212,0.0314 0.0253,null,null
,,,
213,himalaya 0.01532,null,null
,,,
214,nepal,null,null
,,,
215,0.015,null,null
,,,
216,whittak 0.016,null,null
,,,
217,sherpa 0.01431,null,null
,,,
218,peak,null,null
,,,
219,0.0149,null,null
,,,
220,hillari 0.01431,null,null
,,,
221,MAP Precision at 10,null,null
,,,
222,0.29 0.28 0.27 0.26 0.25 0.24 0.23 0.22 0.21,null,null
,,,
223,0,null,null
,,,
224,0.44 Synthetic Queries Mutual Information,null,null
,,,
225,0.43,null,null
,,,
226,0.42,null,null
,,,
227,0.41,null,null
,,,
228,0.4,null,null
,,,
229,0.39,null,null
,,,
230,0.38,null,null
,,,
231,0.2,null,null
,,,
232,0.4,null,null
,,,
233,0.6,null,null
,,,
234,0.8,null,null
,,,
235,Alpha,null,null
,,,
236,0.37,null,null
,,,
237,1,null,null
,,,
238,0,null,null
,,,
239,Synthetic Queries Mutual Information,null,null
,,,
240,0.2,null,null
,,,
241,0.4,null,null
,,,
242,0.6,null,null
,,,
243,0.8,null,null
,,,
244,1,null,null
,,,
245,Alpha,null,null
,,,
246,Figure 2: Comparison of mutual information and synthetic queries according to MAP (Left) and Precision at 10 (right). (Both are according to Dirichlet prior smoothing).,null,null
,,,
247,"less score contribution from matching the query word exactly than a document that ""matches"" a query word through translation (p(w|u)). To overcome this bias, we introduce a parameter  to control the effect of self-translation. This is a general method that can be applied to adjust the estimated probabilities from any given estimation method.",null,null
,,,
248,"pt(w|u) ,",null,null
,,,
249, + (1 - )p(u|u) (1 - )p(w|u),null,null
,,,
250,"w,u w,u",null,null
,,,
251,"and p(w|u) is estimated either with mutual information or synthetic queries.  is a parameter that controls the effect of self-translation probability and when we set  ,"" 1, we recover the basic query likelihood method.""",null,null
,,,
252,"The ""regularized"" translation model pt(w|u) can then be used in Equations 3 and 4 to rank documents.",null,null
,,,
253,3.3 Translation Language Model with Feedback,null,null
,,,
254,"Feedback techniques have been shown to improve retrieval accuracy substantially[13, 27, 41]. A natural question with translation model is whether translation model can benefit from feedback techniques. In this section, we use pseudorelevance feedback to expand our query model [41] and then score the expanded query model with translation language model based on the negative cross entropy of the expanded query language model and the translation document model (also equivalent to scoring based on negative KL-divergence):",null,null
,,,
255,p(w|q). log pt(w|d),null,null
,,,
256,p(w|q )>0,null,null
,,,
257,where p(w|q) is the query model generated by pseudo-relevance feedback and pt(w|d) is a smoothed translation model and can be computed using either of equations 3 or 4.,null,null
,,,
258,4. EXPERIMENTS,null,null
,,,
259,4.1 Data Set,null,null
,,,
260,"The experiments in this section use four main document collections: (1) news articles (AP90) with TREC topics 51100 and 78,321 articles. (2) San Jose Mercury News (SJMN) articles with TREC topics 51-100 and 90,250 articles (3) ad hoc data in TREC7 with topics 351-400 and 528,155 articles and (4) TREC8 with topics 401-450 and 528,155 articles.",Y,null
,,,
261,"In the experiments, we only use title of the queries. As for preprocessing, we do stemming using Porter stemmer [23] and stop word removal. All experiments are done using the",null,null
,,,
262,Lemur toolkit 1. The performance is measured using two standard measures: MAP(mean average precision) and precision @10 (precision at 10).,null,null
,,,
263,The optimal value for Dirichlet prior smoothing for baseline is 1000 for all data sets and optimal value for JM smoothing for baseline method is gained when coefficient is set to 0.5 for AP90 data set and 0.3 for the rest of data sets.,null,null
,,,
264,"The methods used for experiments in the following sections are: BL (baseline), i.e., either Dirichlet prior smoothing or JM smoothing [42], TM-MI (translation language model with mutual information2 for word-to-word translation probabilities), TM-SYN (translation language model with synthetic queries), fb (pseudo-relevance feedback on baseline) and fb+TM(pseudo-relevance feedback combined with translation language model using mutual information).",null,null
,,,
265,4.2 Comparing Synthetic Queries with Mutual Information,null,null
,,,
266,"We first look into the question whether mutual information (MI) can be an alternative way of estimating translation model. Table 2 shows the results for both TM-SYN and TMMI methods with both Dirichlet prior smoothing and JM smoothing, respectively. The results indicate that TM-MI method is able to better capture word relatedness. Indeed, statistical significance tests indicate that the difference between TM-MI and TM-SYN is statistically significant. In addition, estimating translation probabilities by mutual information for all data sets is more efficient than learning translation probabilities by synthetic queries. Table 1 shows a document word together with ten most probable query words that it will translate to by both synthetic queries and mutual information estimation methods. The table shows that the related words for word ""everest"" in case of mutual information are more specific than for words learned via synthetic queries.",null,null
,,,
267,Figure 2 shows the sensitivity of mutual information and synthetic queries to  parameter according to MAP measure (left) and Precision@ 10 (right). The difference indeed makes clearer that mutual information works better than synthetic queries. (Our results for synthetic queries are comparable to those reported in [2].),null,null
,,,
268,"According to these results, we can conclude that mutual",null,null
,,,
269,1http://www.lemurproject.org/ 2We use mutual information throughout the paper for simplicity but we mean the normalized mutual information described in section 3.1.,null,null
,,,
270,326,null,null
,,,
271,Table 2: Performance of Translation Language model with synthetic queries and mutual information estimation,null,null
,,,
272,"according to Dirichlet prior smoothing (left) and JM smoothing (right), * means improvements over TM-SYN are",null,null
,,,
273,statistically significant with Wilcoxon signed-rank test. We only show the significance tests for MAP measure.,null,null
,,,
274,Data,null,null
,,,
275,MAP,null,null
,,,
276,Precision @10,null,null
,,,
277,Data,null,null
,,,
278,MAP,null,null
,,,
279,Precision @10,null,null
,,,
280,AP-90 SJMN,Y,null
,,,
281,TM-MI 0.272,null,null
,,,
282,0.2,null,null
,,,
283,TM-SYN 0.251 0.195,null,null
,,,
284,TM-MI 0.423 0.28,null,null
,,,
285,TM-SYN 0.404 0.266,null,null
,,,
286,AP-90 SJMN,Y,null
,,,
287,TM-MI 0.264* 0.197*,null,null
,,,
288,TM-SYN 0.25 0.189,null,null
,,,
289,TM-MI 0.381 0.252,null,null
,,,
290,TM-SYN 0.357 0.267,null,null
,,,
291,Table 3: Performance of Translation Language model on different datasets with Dirichlet Prior smoothing (left) and,null,null
,,,
292,"JM smoothing (right), * means improvements over baseline are statistically significant with Wilcoxon signed-rank test.",null,null
,,,
293,We only show the significance tests for MAP measure.,null,null
,,,
294,Data,null,null
,,,
295,AP-90 SJMN TREC7,Y,null
,,,
296,MAP,null,null
,,,
297,BL 0.248 0.195 0.183,null,null
,,,
298,TM-MI 0.272,null,null
,,,
299,0.2 0.187,null,null
,,,
300,Precision @10 BL TM-MI 0.398 0.423 0.266 0.28 0.412 0.404,null,null
,,,
301,Data,null,null
,,,
302,AP-90 SJMN TREC7,Y,null
,,,
303,MAP BL TM-MI 0.246 0.264* 0.188 0.197* 0.165 0.172,null,null
,,,
304,Precision @10 BL TM-MI 0.357 0.381 0.252 0.267 0.354 0.362,null,null
,,,
305,TREC8 0.248 0.249 0.452 0.456,Y,null
,,,
306,TREC8 0.236 0.244* 0.428 0.436,Y,null
,,,
307,information works better than synthetic queries and it is also more efficient.,null,null
,,,
308,"Because of the high computational complexity of synthetic queries, we cannot compare mutual information with it on larger collections, but later we will further experiment with mutual information on larger collections.",null,null
,,,
309,4.3 Comparing Translation Language Model with Standard Query Likelihood,null,null
,,,
310,We now look into how well a translation model with our mutual information-based estimation method performs as compared with the standard query likelihood method. Table 3 shows the results for BL and TM-MI methods according to two measures MAP and Precision @10.,null,null
,,,
311,Comparing the columns TM-MI with BL in both tables indeed indicates that the TM-MI outperforms method BL. Significant tests using Wilcoxon signed-rank test [37] show the difference between these two methods for cases marked in the tables are statistically significant. Comparing TM-MI with Dirichlet prior smoothing and TM-MI with JM smoothing shows that TM-MI with Dirichlet prior smoothing has higher MAP than TM-MI with JM smoothing.,null,null
,,,
312,"Stress Tests: In order to have a better understanding of the translation language model, we applied some stress tests on AP90 data set3. This experiment is to help us understand when exactly the translation language model would be most beneficial. For the stress test, we gradually and randomly remove query words from relevant documents and compare the performance of BL method with TM-MI method. The results of MAP and Precision @10 are shown in Figure 3.",Y,null
,,,
313,"The results indeed indicate that the baseline method (BL) is purely based on exact matching and the performance will drop significantly if the exact matching does not happen. On the other hand, translation language model (TM-MI) is still able to find relevant documents by translating query words to semantically related words in the documents. This indicates that the translation language model works significantly better than the baseline when there is a vocabulary gap between queries and documents.",null,null
,,,
314,"3We got the same trends on other data sets, but we only show the results for AP90 data set.",null,null
,,,
315,4.4 Effect of Smoothing on Translation Language Model,null,null
,,,
316,"Understanding the influence of smoothing on translation language model is important and no previous work has looked into this. We have a good understanding of smoothing methods for basic language models [42], but it is not clear how smoothing affects the performance of statistical translation language models. In this section, we look into how statistical translation model behaves with the smoothing parameters.",null,null
,,,
317,"We vary the smoothing parameters (both JM and Dirichlet prior smoothing) for both BL and TM-MI methods. Figure 4 (left and middle) shows the variation of the JM smoothing parameter and Dirichlet prior smoothing parameter on AP90, respectively (we do not show the results on other data sets since they are similar). The result of TM-MI with JM smoothing indicates that the translation model does need a very little smoothing. As shown, the optimal values for translation language model with Dirichlet prior smoothing is 1000 and with JM smoothing is 0.1. As a result, translation language model is less sensitive to the choice of smoothing parameter than the baseline method. And this is intuitively expected, as smoothing is implicitly gained by translating a document word to other semantically related words.",null,null
,,,
318,"Please note that in the translation language model, we have one other parameter to tune, i.e., the number of words used for translation. Figure 4 (right) shows the sensitivity of the number of the words according to MAP measure. As shown in the figure, the translation language model is not so sensitive to the number of words used for translation.",null,null
,,,
319,4.5 Results with Pseudo-Relevance Feedback,null,null
,,,
320,"Both statistical translation model and pseudo-relevance feedback are to capture word associations, so it would be interesting to see whether they are essentially taking advantage of the same associations or they can be combined to achieve even more improvement.",null,null
,,,
321,"Table 4 shows the pseudo-relevance feedback results for baseline (fb) and when pseudo-relevance feedback is combined with translation language model (fb+TM). For fb+TM method, we first apply pseudo-relevance feedback on initial results (i.e., KL-divergence retrieval model [11]), and then this new query model from pseudo-relevance feedback is used with translation language model to score documents. The feedback parameters are fixed to extract 20 expanded",null,null
,,,
322,327,null,null
,,,
323,Precision at 10,null,null
,,,
324,0.12 Baseline - Precision @10 Tanslation - Precision @10,null,null
,,,
325,0.1,null,null
,,,
326,0.08,null,null
,,,
327,0.06,null,null
,,,
328,0.04,null,null
,,,
329,0.02,null,null
,,,
330,0,null,null
,,,
331,1,null,null
,,,
332,1.5,null,null
,,,
333,2,null,null
,,,
334,2.5,null,null
,,,
335,3,null,null
,,,
336,3.5,null,null
,,,
337,4,null,null
,,,
338,4.5,null,null
,,,
339,5,null,null
,,,
340,Number of query words removed,null,null
,,,
341,MAP,null,null
,,,
342,0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01,null,null
,,,
343,0 1,null,null
,,,
344,Baseline - MAP Translation - MAP,null,null
,,,
345,1.5 2 2.5 3 3.5 4 4.5 5 Number of query words removed,null,null
,,,
346,Precision,null,null
,,,
347,0.25 0.2,null,null
,,,
348,0.15 0.1,null,null
,,,
349,0.05 0 0,null,null
,,,
350,Baseline Translation Model,null,null
,,,
351,0.2,null,null
,,,
352,0.4,null,null
,,,
353,0.6,null,null
,,,
354,0.8,null,null
,,,
355,1,null,null
,,,
356,Recall,null,null
,,,
357,"Figure 3: Stress Tests on AP90 Collection, Precision @10 (left) and MAP (middle). Precision-Recall curve when only ""one query word"" is removed from relevant documents (right)",Y,null
,,,
358,MAP,null,null
,,,
359,0.3 0.25,null,null
,,,
360,0.2 0.15,null,null
,,,
361,0.1 0.05,null,null
,,,
362,0 0,null,null
,,,
363,Baseline Translation - Mutual information,null,null
,,,
364,0.2,null,null
,,,
365,0.4,null,null
,,,
366,0.6,null,null
,,,
367,0.8,null,null
,,,
368,1,null,null
,,,
369,JM Parameter,null,null
,,,
370,MAP,null,null
,,,
371,0.3 0.25,null,null
,,,
372,0.2 0.15,null,null
,,,
373,0.1 0.05,null,null
,,,
374,0 0,null,null
,,,
375,Baseline Translation - Mutual information,null,null
,,,
376,2000,null,null
,,,
377,4000,null,null
,,,
378,6000,null,null
,,,
379,8000,null,null
,,,
380,Dirichlet Prior Parameter,null,null
,,,
381,10000,null,null
,,,
382,MAP,null,null
,,,
383,0.3 0.25,null,null
,,,
384,0.2 0.15,null,null
,,,
385,0.1 0.05,null,null
,,,
386,0 0,null,null
,,,
387,AP90 SJMN TREC7 TREC8,Y,null
,,,
388,20,null,null
,,,
389,40,null,null
,,,
390,60,null,null
,,,
391,80,null,null
,,,
392,100,null,null
,,,
393,Number of Words Used for Translation,null,null
,,,
394,"Figure 4: JM parameter variation on AP90 (left), Dirichlet prior parameter variation on AP90 (middle) and Sensitivity of number of words used for translation to MAP (right).",Y,null
,,,
395,"words from the top 10 retrieved documents in the initial run. As shown in table 4, fb-TM method indeed outperforms fb method when used with JM smoothing. Statistical significant tests reveal that the difference is indeed statistically significant. However, fb+TM method does not significantly outperform fb method when used with Dirichlet prior smoothing. An interesting observation is that although the performance of pseudo-feedback (fb) method with JM smoothing is lower than pseudo-feedback with Dirichlet prior smoothing, when pseudo-feedback (fb) is combined with translation language model, i.e., fb+TM method, the better performance is gained with JM smoothing. In fact, the performance of fb+TM with JM smoothing is consistently better than the fb+TM with Dirichlet prior smoothing.",null,null
,,,
396,"Figure 5 shows the P-R curves for BL, fb and fb+TM methods with JM Smoothing on AP904. This figure indeed indicates that the precision of fb+TM method at different recall points is higher than BL and fb methods. This is an interesting conclusion that translation language model brings in co-occurrence word knowledge that once combined with pseudo-relevance feedback, significant improvement is gained.",null,null
,,,
397,4.6 The Need for Self-Translation Regularization,null,null
,,,
398,"A potential problem of the estimated translation probabilities is that it is possible that p(w|u) > p(w|w). This may lead to non-optimal retrieval performance because it is possible that a document that matches a query word exactly (p(w|w)) gets less score contribution from matching the query word exactly than a document that ""matches"" a",null,null
,,,
399,4We do not show other curves due to their similarity.,null,null
,,,
400,Precision,null,null
,,,
401,0.7,null,null
,,,
402,Baseline,null,null
,,,
403,0.6,null,null
,,,
404,Feedback Feedback&Translation,null,null
,,,
405,0.5,null,null
,,,
406,0.4,null,null
,,,
407,0.3,null,null
,,,
408,0.2,null,null
,,,
409,0.1,null,null
,,,
410,0,null,null
,,,
411,0,null,null
,,,
412,0.2,null,null
,,,
413,0.4,null,null
,,,
414,0.6,null,null
,,,
415,0.8,null,null
,,,
416,1,null,null
,,,
417,Recall,null,null
,,,
418,Figure 5: Comparison of Baseline with Translation Language model combined with pseudo-feedback and pseudo-feedback alone on AP90 data set with JM smoothing,null,null
,,,
419,"query word through translation (p(w|u)). The interpolation formula (with ) can help alleviate this problem; indeed, if   0.5, we can always ensure that this constraint be satisfied. So, it would be interesting to see how  affects the performance. Figure 6 shows the sensitivity of  parameter according to MAP measure. We indeed observe that when  is very small (close to no interpolation) the performance is poor, suggesting that it is important to regulate the selftranslation probabilities to ensure that it is sufficiently large. In Figure 6, we can see that when 0.5    0.8 for most data sets, we can gain the optimal value. Note that when  ,"" 1, we reach the baseline.""",null,null
,,,
420,4.7 Findings,null,null
,,,
421,1. Translation language model is statistically significant bet-,null,null
,,,
422,328,null,null
,,,
423,Table 4: Performance of Translation Language model combined with pseudo-feedback with Dirichlet Prior smoothing,null,null
,,,
424,"(left) and JM smoothing (right), * and + mean improvements over baseline and fb, respectively, are statistically",null,null
,,,
425,significant with Wilcoxon signed-rank test. We only show the significance tests for MAP measure.,null,null
,,,
426,Data,null,null
,,,
427,AP-90 SJMN TREC7 TREC8,Y,null
,,,
428,BL 0.248 0.195 0.183 0.248,null,null
,,,
429,MAP fb 0.285 0.231 0.226 0.270,null,null
,,,
430,fb+TM 0.285 0.232 0.226 0.278,null,null
,,,
431,Precision @10,null,null
,,,
432,BL,null,null
,,,
433,fb fb+TM,null,null
,,,
434,0.3978 0.404 0.406,null,null
,,,
435,0.266 0.295,null,null
,,,
436,0.3,null,null
,,,
437,0.412 0.38,null,null
,,,
438,0.38,null,null
,,,
439,0.452 0.456 0.438,null,null
,,,
440,Data,null,null
,,,
441,AP-90 SJMN TREC7 TREC8,Y,null
,,,
442,BL 0.246 0.188 0.165 0.236,null,null
,,,
443,MAP,null,null
,,,
444,fb,null,null
,,,
445,fb+TM,null,null
,,,
446,0.271 0.298*+,null,null
,,,
447,0.229 0.234*+,null,null
,,,
448,0.209 0.222*+,null,null
,,,
449,0.240 0.281*+,null,null
,,,
450,Precision @10,null,null
,,,
451,BL,null,null
,,,
452,fb fb+TM,null,null
,,,
453,0.357 0.383 0.411,null,null
,,,
454,0.252 0.316 0.313,null,null
,,,
455,0.354 0.38 0.384,null,null
,,,
456,0.428 0.4,null,null
,,,
457,0.452,null,null
,,,
458,MAP,null,null
,,,
459,0.35 0.3,null,null
,,,
460,0.25 0.2,null,null
,,,
461,0.15 0.1,null,null
,,,
462,0.05 0,null,null
,,,
463,AP90 SJMN TREC7 TREC8,Y,null
,,,
464,0.2,null,null
,,,
465,0.4,null,null
,,,
466,0.6,null,null
,,,
467,0.8,null,null
,,,
468,1,null,null
,,,
469,Alpha,null,null
,,,
470,Figure 6: Sensitivity of  parameter to MAP measure,null,null
,,,
471,ter than the baseline query likelihood especially when there is a vocabulary gap. 2. Normalized mutual information can be used for wordto-word translation effectively and the results in the previous sections indicate that it is more accurate than synthetic queries. Synthetic queries are inefficient for a large collection such as TREC7 or TREC8. 3. The performance of translation language model combined with pseudo-relevance feedback outperforms pseudorelevance feedback alone; this indicates that translation language model brings in co-occurrence knowledge in addition. 4. Translation language model is less sensitive to the choice of smoothing parameter than the baseline. 5. Translation language model is robust as it improves over all individual queries.,Y,
,,,
472,5. RELATED WORK,null,null
,,,
473,"Language modeling approaches received considerable attentions recently [22]. One of the most important challenges in language model-based information retrieval is to estimate a better document model. Smoothing is an important approach for document model estimation and has been shown to be critical for information retrieval [42]. To further improve the estimation of document models, different heuristics have been proposed in the past. For example, cluster or topic-model based approaches have been studied in [16, 36]. Tao et al. [33] proposed a document expansion approach to enrich document representation before estimating document models.",null,null
,,,
474,"Statistical translation models were originally studied in machine translation with the goal of automatically translating sentences between different languages (e.g., French and English) [3] where authors proposed five different translation models. The simplest model (i.e., IBM 1) [3] ignores position information when learning word-to-word translation probabilities. This model has been adopted in information retrieval by Berger and Lafferty [2]. To train translation mod-",null,null
,,,
475,"els, they synthetically generated (query, document) pairs. An alternative way of estimating the translation model is based on document titles [8]. In this work, the authors proposed to use (title, document) pairs as training data. These estimation methods are inefficient and the coverage of query words is low. Our proposed mutual information-based estimation is more efficient and has a better query words coverage.",null,null
,,,
476,"Translation models have been naturally used in crosslingual information retrieval domain [20, 39]. For example, Nie et al. [20] used parallel corpus as training data to learn translation models. The work by Lavrenko et al. [12] has adapted the relevance model in two different ways based on KL-divergence retrieval models to perform cross-lingual information retrieval. The cluster-based query likelihood proposed in [10] can be regarded as a form of a translation model where the whole document is translated into the query. Recently, translation models have been applied in many applications including question answering, sentence retrieval and tracking information flow [18, 19, 40]. For example, Xue et al [40] has applied translation model on question-answer archives where question and answer pairs are used to train the translation model. In Contrary to all these works, we studied statistical translation model in ad hoc retrieval context.",null,null
,,,
477,"Vocabulary gap has also been studied in the past. Many studies have tried to bridge the vocabulary gap between documents and queries both based on co-occurrence thesaurus [1, 9, 14, 21, 24, 31, 32, 38] and hand-crafted thesaurus [15, 35]. Some other works have considered to combine both approaches [4, 17]. In this paper, we considered word co-occurrence relationship based on mutual information and incorporated it into translation language model in a more principled way.",null,null
,,,
478,6. CONCLUSIONS AND FUTURE WORK,null,null
,,,
479,"As a principled approach to capturing semantic relation of words in information retrieval, statistical translation models have been shown to outperform simple language models which rely on exact matching of words in the query and documents. In this paper, we propose a new simple way to estimate translation probabilities based on mutual information. Our experiment results indicate that the proposed mutual information estimation method is both more efficient and more effective than the existing synthetic query estimation method. We also proposed to regularize translation probability to ensure sufficient self-translation probability mass, which has been shown to be effective for both estimation methods we experimented with. Our results also show that the translation language model is not so sensitive to the effect of smoothing, and it can be combined with pseudorelevance feedback to further improve the performance.",null,null
,,,
480,329,null,null
,,,
481,"For future, it would be interesting to propose some other efficient estimation methods. It would also be interesting to explore other ways of incorporating the translation probabilities into the retrieval formula. Another interesting direction is to study how to transfer the knowledge learned from one collection to another collection.",null,null
,,,
482,7. ACKNOWLEDGMENTS,null,null
,,,
483,"We thank the anonymous reviewers for their useful comments. This material is based upon work supported by a Sohaib and Sara Abbasi Fellowship, Yahoo! Key Scientific Challenge Award, the National Science Foundation under Grant Numbers IIS-0347933, IIS-0713581, IIS-0713571, and CNS-0834709, and by NIH/NLM grant 1 R01 LM009153-01. Any opinions, findings, conclusions, or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsors.",null,null
,,,
484,8. REFERENCES,null,null
,,,
485,"[1] J. Bai, D. Song, P. Bruza, J. Y. Nie, and G. Cao. Query expansion using term relationships in language models for information retrieval. ACM CIKM, pages 688­695, 2005.",null,null
,,,
486,"[2] A. Berger and J. Lafferty. Information retrieval as statistical translation. ACM SIGIR, pages 222­229, 1999.",null,null
,,,
487,"[3] P. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. Mercer. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263­311, 1993.",null,null
,,,
488,"[4] G. Cao, J. Y. Nie, and J. Bai. Integrating word relationships into language models. ACM SIGIR, pages 298­305, 2005.",null,null
,,,
489,"[5] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. ACM SIGKDD, 39(B):1­38, 1997.",null,null
,,,
490,"[6] N. Fuhr. Probabilistic models in information retrieval. The Computer Journal, 35(3):243­255, 1992.",null,null
,,,
491,"[7] F. Jelinek. Statistical Methods for speech recognition. MIT Press., 1997.",null,null
,,,
492,"[8] R. Jin, A. G. Hauptmann, and C. X. Zhai. Title language model for information retrieval. In ACM SIGIR, pages 42­48, 2002.",null,null
,,,
493,"[9] Y. Jing and B. Croft. An association thesaurus for information retrieval. RIAO, pages 141­160, 1994.",null,null
,,,
494,"[10] O. Kurland and L. Lee. Corpus structure, language models, and ad hoc information retrieval. ACM SIGIR, pages 194­201, 2004.",null,null
,,,
495,"[11] J. Lafferty and C. Zhai. Document language models, query models and risk minimization for information retrieval. ACM SIGIR, pages 111­119, 2001.",null,null
,,,
496,"[12] V. Lavrenko, M. Choquette, and B. Croft. Cross-lingual relevance models. ACM SIGIR, pages 175­182, 2002.",null,null
,,,
497,"[13] V. Lavrenko and B. Croft. Relevance-based language models. ACM SIGIR, pages 120­127, 2001.",null,null
,,,
498,"[14] M. Lesk and B. Croft. Word-word associations in document retrieval systems. American Documentation, 20:20­27, 1969.",null,null
,,,
499,"[15] S. Liu, F. Lin, C. Yu, and W. Meng. An effective approach to document retrieval via utilizing wordnet and recognizing phrases. ACM SIGIR, pages 266­272, 2004.",null,null
,,,
500,"[16] X. Liu and W. B. Croft. Cluster-based retrieval using language models. In ACM SIGIR, pages 186­193, 2004.",null,null
,,,
501,"[17] R. Mandala, T. tokunaga, H. Tanaka, and K. Satoh. Ad hoc retrieval experiments using wordnet and automatically constructed thesauri. TREC-7, pages 475­481, 1998.",null,null
,,,
502,"[18] D. Metzler, Y. Bernstein, B. Croft, A. Moffat, and J. Zobel. Similarity measures for tracking information flow. ACM CIKM, pages 517­524, 2005.",null,null
,,,
503,"[19] V. Murdock and B. Croft. Simple translation models for sentence retrieval in factoid question answering. ACM SIGIR, pages 31­35, 2004.",null,null
,,,
504,"[20] J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web. In ACM SIGIR, pages 74­81, 1999.",null,null
,,,
505,"[21] H. J. Peat and P. Willett. The limitations of term co-occurrence data for query expansion in document retrieval systems. J. of Information science, 42(5):378­383, 1991.",null,null
,,,
506,"[22] J. Ponte and W. B. Croft. A language modeling approach to information retrieval. ACM SIGIR, pages 275­281, 1998.",null,null
,,,
507,"[23] M. Porter. An algorithm for suffix stripping. Program, 14(3), 1980.",null,null
,,,
508,"[24] Y. Qiu and H. Frei. Concept based query expansion. ACM SIGIR, pages 160­169, 1993.",null,null
,,,
509,"[25] C. J. V. Rijbergen. A theoretical basis for the use of co-occurrence data in information retrieval. Journal of Documentation, pages 106­119, 1977.",null,null
,,,
510,"[26] C. J. V. Rijsbergen. Information retrieval. Butterworths, 1979.",null,null
,,,
511,"[27] S. Robertson and K. Sparck. Relevance weighting of search terms. Journal of American Society for Information Science, 27:129­146, 1976.",null,null
,,,
512,"[28] G. Salton. Automatic Text Processing: The Transformation, Analysis and Retrieval of Information by Computer. Addison-Wesley, 1989.",null,null
,,,
513,"[29] G. Salton and M. McGill. Introduction to Modern Information Retrieval. McGraw-Hill., 1983.",null,null
,,,
514,"[30] G. Salton, C. S. Yang, and C. T. Yu. A theory of term importance in automatic text analysis. Journal of American Society for Information Science, 26(1):33­44, 1975.",null,null
,,,
515,"[31] H. Schutze and J. O. Pedersen. A co-occurrence based thesaurus and two applications to information retrieval. Information and processing management, 33(3):307­318, 1997.",null,null
,,,
516,"[32] A. F. Smeaton and C. J. V. Rijsbergen. The retrieval effects of query expansion on a feedback document retrieval system. The Computer Journal, 26(3):239­246, 1983.",null,null
,,,
517,"[33] T. Tao, X. Wang, Q. Mei, and C. Zhai. Language model information retrieval with document expansion. In HLT-NAACL, pages 407­ 414, 2006.",null,null
,,,
518,"[34] H. Turtle and W. B. Croft. Evaluation of an inference network-based retrieval model. ACM Transactions on Information Systems, 9(3):187­222, 1991.",null,null
,,,
519,"[35] E. M. Voorhess. Query expansion using lexical-semantic relations. ACM SIGIR, pages 61­69, 1994.",null,null
,,,
520,"[36] X. Wei and W. B. Croft. Lda-based document models for ad-hoc retrieval. In ACM SIGIR, pages 178­185, 2006.",null,null
,,,
521,"[37] F. Wilcoxon. Individual comparisons by ranking methods. Biometrics, 1:80­83, 1945.",null,null
,,,
522,"[38] J. Xu and B. Croft. Query expansion using local and global document analysis. ACM SIGIR, pages 4­11, 1996.",null,null
,,,
523,"[39] J. Xu, R. Weischedel, and C. Nguyen. Evaluating a probabilistic model for cross-lingual information retrieval. ACM SIGIR, pages 105­110, 2001.",null,null
,,,
524,"[40] X. Xue, J. Jeon, and W. B. Croft. Retrieval models for question and answer archives. In ACM SIGIR, pages 475­482, 2008.",null,null
,,,
525,"[41] C. Zhai and J. Lafferty. Model-based feedback in the language modeling approach to information retrieval. ACM CIKM, pages 403­410, 2001.",null,null
,,,
526,"[42] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to ad hoc information retrieval. ACM SIGIR, pages 334­342, 2001.",null,null
,,,
527,330,null,null
,,,
528,,null,null
