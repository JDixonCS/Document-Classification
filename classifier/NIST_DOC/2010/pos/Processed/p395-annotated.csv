,sentence,label,data
,,,
0,Mining the Blogosphere for Top News Stories Identification,null,null
,,,
1,Yeha Lee Hun-young Jung Woosang Song Jong-Hyeok Lee,null,null
,,,
2,Division of Electrical and Computer Engineering Pohang University of Science and Technology,null,null
,,,
3,"Pohang, Gyungbuk, Republic of Korea",null,null
,,,
4,"{sion, blesshy, woosang, jhlee}@postech.ac.kr",null,null
,,,
5,ABSTRACT,null,null
,,,
6,"The analysis of query logs from blog search engines show that news-related queries occupy a significant portion of the logs. This raises a interesting research question on whether the blogosphere can be used to identify important news stories. In this paper, we present novel approaches to identify important news story headlines from the blogosphere for a given day. The proposed system consists of two components based on the language model framework, the query likelihood and the news headline prior. For the query likelihood, we propose several approaches to estimate the query language model and the news headline language model. We also suggest several criteria to evaluate the news headline prior that is the prior belief about the importance or newsworthiness of the news headline for a given day. Experimental results show that our system significantly outperforms a baseline system. Specifically, the proposed approach gives 2.62% and 10.19% further increases in MAP and P@5 over the best performing result of the TREC'09 Top Stories Identification Task.",null,null
,,,
7,Categories and Subject Descriptors,null,null
,,,
8,H.3.3 [Information Search and Retrieval]: Information Search and Retrieval ­ Retrieval models,null,null
,,,
9,General Terms,null,null
,,,
10,"Algorithms, Experimentation, Performance",null,null
,,,
11,Keywords,null,null
,,,
12,"Blog Retrieval, Blogosphere, Top News Stories Identification",null,null
,,,
13,1. INTRODUCTION,null,null
,,,
14,"A blog, ""web log"", is a special type of website in which users (individuals or groups) express their opinions or thoughts on several subjects. Blog posts consist of a wide variety of topics. As the number of blog users increase, the popularity and the importance of blogs are growing, and several",null,null
,,,
15,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR'10, July 19­23, 2010, Geneva, Switzerland. Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.",null,null
,,,
16,commercial search engines such as Google1 and Technorati2 have provided blog search services.,null,null
,,,
17,"Users' information needs for blog search differ from those for general web search. A large portion of the query logs from blog search engines are news-related queries [21, 22]. In other words, many users find information about news stories in the blogosphere. This implies that the blogosphere may be helpful when locating news stories.",null,null
,,,
18,"A large number of news stories from various news channels are generated and updated day after day. However, a relatively few news among huge number of them receive attention from users. Therefore, it is one of the most important issues to evaluate the importance of news stories and rank them.",null,null
,,,
19,"We investigate how to take advantage of the blogosphere for identifying top news stories. To this end, given a certain day, we retrieve and rank news headlines according to their importance or newsworthiness, using the blogosphere. Furthermore, this task is worthwhile in that it identifies the top news stories from blog users' point of view, instead of the news providers. The task is also called Top Stories Identification Task (TSIT) which was first introduced at the TREC 2009 Blog Track [21].",null,null
,,,
20,"TSIT is a new pilot task that aims to ""address the news dimension in the blogosphere"" [21]. The task uses a date (day) as a query. For a date query, the system for the task ranks the news headlines in the order of their importance. Furthermore, for each news headline, the task requires a certain number of blog posts that capture diverse aspects relevant to the news headline.",null,null
,,,
21,"TSIT has some characteristics that distinguish it from previous news-related studies such as Topic Detection and Tracking (TDT). First, the data given for TSIT contains only news headlines but no news contents. Therefore, the system for the task should rank news headlines utilizing the blogosphere (i.e. Blog08 corpus) instead of the contents of news articles. Second, unlike the corpus of news stories, blog posts are generally neither well-written articles nor topically coherent. They also include a lot of non-topical contents such as spam blogs and blog comment spam that advertise commercial products and services [16], making the task difficult.",null,null
,,,
22,"In this paper, we present novel approaches to identify the top news stories in the blogosphere. The proposed approaches are based on the language model framework, which is widely used in information retrieval tasks. We propose a",null,null
,,,
23,1http://blogsearch.google.com/ 2http://www.technorati.com/,null,null
,,,
24,395,null,null
,,,
25,"series of approaches to estimate a query language model and a news headline language model based on the blogosphere, and to rank the news headlines according to the distance between two language models. We also suggest several criteria to evaluate the prior probability that a news headline will be a top news story for a given day, and verify that these criteria are useful to identify top news stories. The experimental results show that our approach significantly improves the best performance submitted in the TREC 2009 Top Stories Identification Task.",null,null
,,,
26,"The rest of the paper is organized as follows. In section 2, we briefly survey related work on new event detection. In section 3, we address the framework of our system, and propose several approaches to identify the top news headlines. In section 4, we conduct several experiments to evaluate the performances of our approach. Finally, we conclude the paper and discuss future work in section 5.",null,null
,,,
27,2. RELATED WORK,null,null
,,,
28,"As a new pilot task, TSIT aims to identify top news stories in the blogosphere, and to provide a ranked list of news headlines. There are few researches for identifying and ranking top news stories in the blogosphere. One of the research directions closely related to TSIT may be the New Event Detection.",null,null
,,,
29,"New Event Detection, one of the five tasks in TDT, aims to detect whether a given news story is concerned with already known events to a system or not. For the event detection problem, many approaches have been based on clustering or classification to estimate the similarity between the events and documents (e.g. the news stories); these approaches differ in the ways by which they evaluate the similarity [3, 5, 17, 25, 28, 29]. All of them compare each document with existing events. If the similarity between the document and the events is lower than some predefined criteria, the document is considered to address a new event. Otherwise, the document is assigned to the event to which it is most similar.",null,null
,,,
30,"Various features have been proposed, including timeline analysis, burstiness and named entities. Chen et al proposed an aging theory to capture the life cycle of a news event, and improved the performance for event detection [7]. Chen et al used an aging theory and a sentence modeling to extract hot topics from news documents [8]. They analyzed the timeline to identify the key terms. The burstiness of terms was used by many researchers for the event detection [9, 12, 15, 24]. Kleinberg proposed an approach to identify the bursty features for the event detection from e-mail streams [15]. They used the infinite-state automaton to model the stream. He et al identified bursts of (a)periodic features using a Gaussian distribution, and then used them to detect (a)periodic events [12]. Kumaran and Allan used named entities for the event detection [17]. They showed that the usefulness of named entities can change according to certain situations. Kuo et al classified terms within news stories based on named entity type and parts-of-speech tags, and assigned a different weight to each term according to the type and class of news story [28].",null,null
,,,
31,"The main difference between previous work for the event detection and our approach stems from the difference in source data for identifying events or news stories. In contrast with previous work, we identify the top news headlines",null,null
,,,
32,"using only the unorganized blogosphere, not the well-defined contents of news articles.",null,null
,,,
33,3. TOP STORIES RANKING MODEL,null,null
,,,
34,"To identify the top news stories, we rank them according to their importance or newsworthiness on a specific day. The newsworthiness of a news story can be decided by several criteria3 as follows:",null,null
,,,
35,· Timing News stories that is happening now are often more newsworthy than those that happened a week ago.,null,null
,,,
36,· Significance The number of people involved in a news story is important.,null,null
,,,
37,· Proximity News stories that occur near us are more important than distant ones.,null,null
,,,
38,· Prominence News stories about famous people are more newsworthy than stories about ordinary people.,null,null
,,,
39,· Human-Interest Human-interest stories are generally soft news. They appeal to emotions.,null,null
,,,
40,"We assume that a news story mentioned in more blog posts or comments is more important or newsworthy on a specific day, because a top news story satisfying the above criteria may receive attention from many blog users, who express their thoughts or opinions about the news story in their blogs.",null,null
,,,
41,"To measure the importance of a news story using the blogosphere, we adopt the language model framework, which is widely used in information retrieval tasks. Motivated by our assumption, we evaluate the importance of a news headline using the probability that blog posts published on a query day generate the headline. Let H be a news headline and let Qd and Qp be a given (date) query and a set of blog posts published on the query day Qd, respectively.",null,null
,,,
42,"Score(Qd, H)  P (H|Qp)  P (Qp|H) P (H) (1)",null,null
,,,
43,Importance score of a news headline,null,null
,,,
44,Query Headline Likelihood Prior,null,null
,,,
45,3.1 The Query Likelihood,null,null
,,,
46,"In the language model framework, the query likelihood means the probability that a document generates a given query. TSIT uses a date (day) as a query. Therefore, we regard the query likelihood as the probability that a news headline generates blog posts published on the query day (i.e. Qp).",null,null
,,,
47,"To this end, we should estimate two language models, the Query Language Model (QLM) and the News Headline Language Model (NHLM). Both of the language models are estimated, based on blog posts.",null,null
,,,
48,3.1.1 Query Language Model,null,null
,,,
49,"For a query day Qd, we estimate the QLM using blog posts Qp. However, the blog posts may discuss various topics from individual daily affairs to important events recently happened. If we model the blog posts using a single language model, the language model cannot correctly capture",null,null
,,,
50,3http://www.mediacollege.com/journalism/news/ newsworthy.html,null,null
,,,
51,396,null,null
,,,
52,"the contents of the blog posts. As a result, we will get the",null,null
,,,
53,wrong QLM.,null,null
,,,
54,"To solve this problem, we divide the documents into K",null,null
,,,
55,clusters. We assume that each cluster can accurately reflect,null,null
,,,
56,one of the various topics mixed in the blog posts. To esti-,null,null
,,,
57,"mate the QLM, we first gather blog posts which are pub-",null,null
,,,
58,"lished on a query day. Then, we cluster them using the",null,null
,,,
59,K-means algorithm. We represent each document using the,null,null
,,,
60,"term vector d : wi ,"" tfi × idfi, where tfi indicates the fre-""",null,null
,,,
61,quency,null,null
,,,
62,of,null,null
,,,
63,term,null,null
,,,
64,wi,null,null
,,,
65,within,null,null
,,,
66,a,null,null
,,,
67,document,null,null
,,,
68,"d,",null,null
,,,
69,and,null,null
,,,
70,idfi,null,null
,,,
71,",",null,null
,,,
72,log(,null,null
,,,
73,|T D| dfi,null,null
,,,
74,),null,null
,,,
75,means inverse document frequency: |T D| is the total number,null,null
,,,
76,of documents in a collection and dfi is document frequency of a term wi. We use the cosine similarity as the distance function between two documents.,null,null
,,,
77,"Similarity di, dj , di · dj",null,null
,,,
78,-2,null,null
,,,
79,|di| × |dj |,null,null
,,,
80,"where |di| and |dj | indicate the length of di and dj, respectively.",null,null
,,,
81,"After clustering, we can generate the QLMs from the K document sets. Let Dk ,"" {dk1 , dk2 , · · · , dkn } be the kth document set, QLMk be the kth QLM. The document set Dk contains information relevant to a topic of the document set, but also contains background information. We assume""",null,null
,,,
82,that the documents are generated by a mixture model of,null,null
,,,
83,QLMk and the collection language model C that reflects the background information.,null,null
,,,
84,"P (Dk) ,",null,null
,,,
85,{(1 - )P (w|QLMk ) + P (w|C )}c(w;dki ) (3),null,null
,,,
86,iw,null,null
,,,
87,where c(w; dki ) is the number of times term w occurred in,null,null
,,,
88,"a document dki , P (w|C ) ,",null,null
,,,
89,ctfw |C|,null,null
,,,
90,:,null,null
,,,
91,ctfw,null,null
,,,
92,is the number of,null,null
,,,
93,"times term w occurred in the entire collection, |C| is the",null,null
,,,
94,"length of the collection, and  is a weighting parameter. In",null,null
,,,
95,"our experiments, we set  as 0.8.",null,null
,,,
96,"Then, we can estimate QLMk using the EM algorithm [11]. The EM updates for p(w|QLMk ) are as follows:",null,null
,,,
97,tnw,null,null
,,,
98,",",null,null
,,,
99,(1 - )P n(w|QLMk ) (1 - )P n(w|QLMk ) + P n(w|C ),null,null
,,,
100,-4,null,null
,,,
101,"P n+1(w|QLMk ) ,",null,null
,,,
102,"n i,1",null,null
,,,
103,c(w;,null,null
,,,
104,dki,null,null
,,,
105,)tnw,null,null
,,,
106,w,null,null
,,,
107,"n i,1",null,null
,,,
108,c(w,null,null
,,,
109,;,null,null
,,,
110,dki,null,null
,,,
111,)tn w,null,null
,,,
112,-5,null,null
,,,
113,3.1.2 News Headline Language Model,null,null
,,,
114,"To estimate the NHLM, for each news headline, we first retrieve blog posts relevant to its topic using the news headline itself as query. To this end, we evaluate the relevance between a news headline H and a blog post d using the the KL-divergence language model [18] with Dirichlet smoothing [27].",null,null
,,,
115,"Score(H, d)  P (w|H) log P (w|d)",null,null
,,,
116,-6,null,null
,,,
117,w,null,null
,,,
118,where P (w|H) is the maximum likelihood estimates of the,null,null
,,,
119,"news headline, and P (w|d) ,",null,null
,,,
120,: c(w;d)+dP (w|C ) |d|+d,null,null
,,,
121,c(w; d) is,null,null
,,,
122,"the number of times a term w occurred in a blog post d, and",null,null
,,,
123,"d is a smoothing parameter, and |d| is the length of the",null,null
,,,
124,document d.,null,null
,,,
125,"Among the search results, we use only the blog posts",null,null
,,,
126,whose issued date is within a certain period from a query,null,null
,,,
127,"day, because the time gap between the issued day of a blog",null,null
,,,
128,"post and a query day often means that the blog post is mentioning an event different from those that happened on that day [25]. In other words, the blog post is likely to be relevant to a topically similar, but different news headline.",null,null
,,,
129,"We gather only the blog posts between -3 and +28 days from a query day. Then, we choose 10 blog posts that can provide as diverse aspects about the news headline as possible. We call the 10 blog posts the supporting relevant posts of the news headline.",null,null
,,,
130,"We propose two approaches to make the supporting relevant posts reflect the diverse aspects relevant to the news headline: Relevance-Based Selection (RBS), Feed-Based Selection (FBS).",null,null
,,,
131,RBS is an intuitive but naive approach to choose the supporting relevant posts. This approach selects the supporting relevant posts according to a relevance score of each blog post obtained from Eq. 6. We define this approach as a baseline for our experiments.,null,null
,,,
132,"FBS chooses the supporting relevant posts based on blog feeds which belong to each of them. Individual blog users may have different interests and tendencies for the same events, and these differences can be represented through their blog feed [19]. That is, for a given news headline, blog posts from different blog feeds can provide different aspects, even if they address information on the same news story. Therefore, to increase the diversity of the supporting relevant posts, we select them from as wide a range of blog feeds as possible. In a similar way to RBS, FBS also chooses blog posts according to their relevance score, but FBS selects only one blog post from one blog feed.",null,null
,,,
133,"We estimate the NHLM using the maximum likelihood estimate of the 10 supporting relevant posts and the Dirichlet smoothing [27]. Let NHLM and C be the NHLM and the collection language model, respectively, and let SRP be a set of the 10 supporting relevant posts.",null,null
,,,
134,P (w|NHLM ),null,null
,,,
135,",",null,null
,,,
136,c(w; SRP ) + hP (w|C ) |SRP | + h,null,null
,,,
137,-7,null,null
,,,
138,where c(w; SRP ) is the number of times a term w occurred in SRP and h is a smoothing parameter.,null,null
,,,
139,3.1.3 Score Function,null,null
,,,
140,"To evaluate the query likelihood, we use the KL-divergence language model [18], one of the-state-of-the-art information retrieval models, to rank news headlines in response to a given query. We use the maximum value among scores between the QLMs and the NHLM as the relevance score of a news headline.",null,null
,,,
141,"Let ScoreQLH (Qd, H) be the relevance score of a news headline H with respect to a given query Qd. We define ScoreQLH (Qd, H) as follows:",null,null
,,,
142,"ScoreQLH(Qd,H) , max k",null,null
,,,
143,P (w|QLMk) logP (w|NHLM) (8),null,null
,,,
144,w,null,null
,,,
145,3.2 The News Headline Piror,null,null
,,,
146,"We suggest two criteria to estimate the news headline prior P (H) that is the prior belief about the importance or newsworthiness of a news headline for a given day: Temporal Profiling and Term Importance. Although the proposed approaches depend on a date such as the query day, we re-",null,null
,,,
147,397,null,null
,,,
148,gard them as the priors of a news headline in that they are independent of the query language model.,null,null
,,,
149,3.2.1 Temporal Profiling,null,null
,,,
150,"The Temporal Profiling criterion uses the temporal information of blog posts relevant to a news headline. We assume that if a news headline is important for a query day, many blog posts relevant to its topic will be posted on that day.",null,null
,,,
151,"To generate the temporal profile of each news headline, we use a temporal profiling approach proposed in [14] with some modifications. The temporal profile of a news headline H is defined as follows:",null,null
,,,
152,"P (t|H) ,"" P (t|d) Score(H, d)""",null,null
,,,
153,-9,null,null
,,,
154,dR,null,null
,,,
155,"d R Score(H, d )",null,null
,,,
156,"where t is a date (day), and R is a document set that consists of 500 blog posts selected by an order of a relevance score Score(H, d) from Eq. 6, and",null,null
,,,
157,"P (t|d) ,",null,null
,,,
158,1 if t is equal to the document date 0 otherwise,null,null
,,,
159,We then smoothed the temporal profile P (t|H) using the background model as follows:,null,null
,,,
160,"P (t|H) , (1 - )P (t|H) + P (t|C)",null,null
,,,
161,-10,null,null
,,,
162,where,null,null
,,,
163,P (t|C),null,null
,,,
164,",",null,null
,,,
165,1 |T D|,null,null
,,,
166,dC P (t|d): |T D| is the total num-,null,null
,,,
167,"ber of documents in the collection, and  is a smoothing",null,null
,,,
168,"parameter. In our experiments, we set  , 0.5.",null,null
,,,
169,This temporal profile is defined on each single day. How-,null,null
,,,
170,"ever, if a news story is important for a query day Qd, the blog posts relevant to it may be published over a certain period",null,null
,,,
171,"following the day due to the bursty nature [15]. Therefore,",null,null
,,,
172,we smooth the temporal profile model with the model for,null,null
,,,
173,"adjacent days. Let ScoreT P (Qd, H) be a score of a news",null,null
,,,
174,headline estimated using the temporal profile of the news,null,null
,,,
175,headline.,null,null
,,,
176,"ScoreT P (Qd, H)",null,null
,,,
177,",",null,null
,,,
178,1 Zw,null,null
,,,
179,"w(t, Qd)P (t|H)",null,null
,,,
180,t,null,null
,,,
181,-11,null,null
,,,
182,"where  indicates a period from Qd, and Zw ,"" t w(t, Qd). We define a weight function for w(t, Qd) using the Cosine (Hamming) kernel function [20] as follows:""",null,null
,,,
183,"w(t, Qd) ,",null,null
,,,
184,1 2,null,null
,,,
185,1 + cos,null,null
,,,
186,|t-Qd |× ,null,null
,,,
187,0,null,null
,,,
188,t,null,null
,,,
189,-12,null,null
,,,
190,otherwise,null,null
,,,
191,3.2.2 Term Importance,null,null
,,,
192,"The Term Importance criterion uses term information of a news headline. We believe that each term has a different importance for a given day. If a news headline consists of important terms, it is likely to be a top news story and vice-versa. For example, a news headline that consists of common words or stopwords may not be a top news story.",null,null
,,,
193,"We only consider named entities, not all terms in a news headline. Named entities were used by many event detection systems, improving the performance of the systems [17, 26, 28]. We extract named entities from each news headline using the Stanford Named Entity Recognizer4. Then, we gather all n-gram (n  3) from the named entities.",null,null
,,,
194,4http://nlp.stanford.edu/software/CRF-NER.shtml,null,null
,,,
195,We evaluate the importance of the n-gram terms based on the T F · IDF approach that is widely used for term weighting in many information retrieval tasks.,null,null
,,,
196,"Let nt be the extracted n-gram term and T F (nt, Qd) be a term frequency of the term nt for a query day Qd. Intuitively, if a term nt occurs frequently within news headlines issued on a query day, it is likely to be important. In a similar way to the bursty nature of blog posts, news headlines relevant to important events that happen on the query day may be published over several subsequent days. Therefore, we define the term frequency T F (nt, Qd) as the number of a term nt within news headlines that are issued during a certain interval containing a query day Qd.",null,null
,,,
197,"T F (nt, Qd) , c(nt; t)",null,null
,,,
198,-13,null,null
,,,
199,t,null,null
,,,
200,"where  indicates the period, and c(nt; t) means the number of a term nt occurring in news headlines issued on day t.",null,null
,,,
201,"Let IDF (nt) be the inverse ""date"" frequency, and T N D be the total number of days that the news headline corpus spans. We define IDF (nt) as follows:",null,null
,,,
202,"IDF (nt) , T N D",null,null
,,,
203,-14,null,null
,,,
204,DF (nt) + ,null,null
,,,
205,"where DF (nt) indicates the number of days on which nt occurs in news headlines, and  is a constant which controls the influence of DF (nt) on IDF (nt).",null,null
,,,
206,"The inverse date frequency IDF (nt) corresponds to the inverse document frequency. In other words, a term nt with a high IDF (nt) value may be a keyword that distinguishes important events that happened on a query day from those that happened on other days.",null,null
,,,
207,"Let ScoreT I (Qd, H) be the importance of a news headline H evaluated using the term importance.",null,null
,,,
208,"ScoreT I (Qd, H) ,"" max (T F (nt, Qd) × IDF (nt)) (15) ntH""",null,null
,,,
209,3.3 Integration of Query Likelihood and News Headline Prior,null,null
,,,
210,"We proposed several approaches for the query likelihood and the news headline prior in section 3.1 and 3.2. They capture the different characteristics of important news headlines. For the query likelihood, we analyze the contents of the blog posts, and model the dominant topics buried in them. Then, we rank the news headlines according to the probability that each headline generates one of the topics. For the news headline prior, we proposed two criteria to reflect the properties of important news headlines, Temporal Profiling and Term Importance.",null,null
,,,
211,"To identify the top news headline, we integrate the query likelihood with the news headline prior. To achieve this, we first adjust each score from 0 to 1.",null,null
,,,
212,S corei (H ),null,null
,,,
213,",",null,null
,,,
214,Scorei(H) - mini maxi - mini,null,null
,,,
215,-16,null,null
,,,
216,"mini , min Scorei(H ) and maxi , max Scorei(H )",null,null
,,,
217,H,null,null
,,,
218,H,null,null
,,,
219,"where Scorei(H) indicates one score of ScoreQLH (Qd, H), ScoreT P (Qd, H) and ScoreT I (Qd, H).",null,null
,,,
220,398,null,null
,,,
221,"Finally, we define the ranking function as follows:",null,null
,,,
222,"Score(Qd,H),""(1 - 1)ScoreQLH(Qd, H)""",null,null
,,,
223,"+1 (1 - 2)ScoreTI(Qd,H)+2ScoreTP(Qd,H) (17)",null,null
,,,
224,"where 1 is the weighting parameter that adjusts the importance between the query likelihood and the news headline prior, and 2 is the parameter that controls the weights between two criteria for the news headline prior.",null,null
,,,
225,4. EXPERIMENTS,null,null
,,,
226,"We conducted several experiments to evaluate our system for TSIT. We measured the performance of the query likelihood and the news headline prior, respectively. We also investigated the influence of the combination of two components on the performance of TSIT, with a varying weight parameter 1.",null,null
,,,
227,4.1 Setup,null,null
,,,
228,4.1.1 Data Set,null,null
,,,
229,"The Blogs08 corpus and the news headline corpus from the New York Times (NYT) [21] were used for experiments. The Blogs08 corpus was created by monitoring 1 million blogs from January 14, 2008 to February 10, 2009, and consisted 808GB of feeds, 1445GB of permalink documents and 56GB of homepages. The news headline corpus consisted of headlines of articles published by NYT during the interval covered by the Blogs08 corpus.",Y,
,,,
230,"Our experiments were performed using only Blog08 and the news headline corpus without resorting to any other resources. For the evaluation, we used the 55 topics and relevance judgments from the TREC 2009 Top Stories Identification Task.",Y,
,,,
231,"We only used the permalinks (blog post) for the experiments. We discarded the HTML tags of each blog post, and applied the DiffPost algorithm [23] to remove non-relevant contents5 of each blog post. Each blog post was also processed by stemming using the Porter stemmer and eliminating stopwords using the INQUERY words stoplist [2].",null,null
,,,
232,4.1.2 Evaluation Method,null,null
,,,
233,"In response to each query, we retrieved 100 news headlines according to their importance on that day, and provide 10 supporting relevant posts for each news headline, as in TSIT.",null,null
,,,
234,"The evaluation consists of two phases. In the first phase, we assess the performances of the proposed approaches for identifying the top news headlines for a query day. For each query, we considered only the news headlines corresponding to Qd ± 1 days as ranking candidates, because of the time discrepancy between the day on which the headline was and the day Qd on which the news story actually happened [21]. We used the mean average precision (MAP) and the precision at rank 5 and 10 (P@5 and P@10) as the evaluation measures.",null,null
,,,
235,"In the second phase, the supporting relevant posts are evaluated. The posts should provide diverse aspects relevant to their news headline. To assess the diversity of the supporting relevant posts, we used the -nDCG [10] and IA-Precision [1] measures.",null,null
,,,
236,"5In [23], the non-relevant contents of a blog post means the",null,null
,,,
237,0.14,null,null
,,,
238,0.12,null,null
,,,
239,MAP of Query Likelihood,null,null
,,,
240,0.1,null,null
,,,
241,0.08,null,null
,,,
242,0.06 0.04,null,null
,,,
243,"Query Likelihood Baseline (K,0)",null,null
,,,
244,0.02 30,null,null
,,,
245,300,null,null
,,,
246,600,null,null
,,,
247,900,null,null
,,,
248,1200,null,null
,,,
249,The number of clusters K,null,null
,,,
250,1500,null,null
,,,
251,Figure 1: The MAP scores of the query likelihood according to varying the number of clusters K. The NHLM is estimated using the RBS.,null,null
,,,
252,Table 1: The performances of the query likelihood estimated using the RBS and the FBS approaches for the NHLM. The number of clusters K is set to 500 for the QLM estimation.,null,null
,,,
253,Model MAP P@5 P@10,null,null
,,,
254,QLHRBS 0.1303 0.2291 0.2255 QLHF BS 0.1315 0.2473 0.2355,null,null
,,,
255,4.2 Results and Discussion,null,null
,,,
256,4.2.1 The Query Likelihood,null,null
,,,
257,We conducted several experiments to evaluate the performance of the query likelihood for TSIT. The aim of the experiments is to determine (1) how correctly the QLMs reflect the various topics buried in blog posts; and (2) how the proposed approaches for NHLM estimation affect the performance of the query likelihood.,null,null
,,,
258,"The query likelihood has a few parameters, the number of clusters K for QLMs and the smoothing parameter h for NHLM. For our experiments, the smoothing parameter h is set to 2000 without further parameter tuning.",null,null
,,,
259,"To determine how correctly the QLMs the reflect various topics buried in blog posts, we evaluated the performance of the query likelihood according to varying K values.",null,null
,,,
260,"K : 1, 30, 50, 100, 300, 500, 1000, 1500",null,null
,,,
261,"For the NHLM estimation, the supporting relevant posts were chosen using the RBS approach.",null,null
,,,
262,"Figure 1 shows the MAP scores according to varying K values. We set the baseline using K , 1. This means that blog posts are modeled using a single QLM.",null,null
,,,
263,"Compared with the baseline, the performances for all K > 1 were significantly improved, and the best performance was obtained when using K ,"" 500. From these results, we can confirm that a single QLM cannot correctly capture the contents of the blog posts, because of the topical diversity of the blog posts. This weakness reduced its ability for identifying the top news headlines.""",null,null
,,,
264,"useless contents for the blog search, such as menu, banner and site description",null,null
,,,
265,399,null,null
,,,
266,Table 2: The performances of the news headline,null,null
,,,
267,"prior estimated using Temporal Profiling, Term Im-",null,null
,,,
268,"portance and their combination (2 , 0.8). The best performances are shown in bold.",null,null
,,,
269,Model Period MAP P@5 P@10,null,null
,,,
270,P RIT P,null,null
,,,
271,1,null,null
,,,
272,0.1410 0.2545 0.2691,null,null
,,,
273,2,null,null
,,,
274,0.1745 0.2982 0.3109,null,null
,,,
275,3 0.1800 0.3055 0.3273,null,null
,,,
276,P RIT I,null,null
,,,
277,1,null,null
,,,
278,0.0263 0.0400 0.0509,null,null
,,,
279,2,null,null
,,,
280,0.0448 0.1127 0.0873,null,null
,,,
281,3 0.0458 0.1273 0.0891,null,null
,,,
282,P RIT P +T I,null,null
,,,
283,3,null,null
,,,
284,0.1957 0.3673 0.3364,null,null
,,,
285,"As the number of clusters K increased to 500, the respective topics buried in the blog post were captured by the K clusters. The QLM estimated using each cluster led to the improved performance of the query likelihood. When K  500, the clusters have been overfitted, and did not provide enough information relevant to each topic. As a result, the performance decreased.",null,null
,,,
286,"To investigate how the proposed approaches for NHLM estimation affect the performance of the query likelihood, we measured the performances with two approaches to select the supporting relevant posts. For these experiments, we set K , 500 to estimate the QLMs.",null,null
,,,
287,"Let QLHRBS and QLHF BS be the query likelihood using the NHLM estimated using RBS and FBS approaches, respectively. Table 1 shows the performances of QLHRBS and QLHF BS. The performances of QLHF BS are better than those of QLHF BS for all measures. These results means that the supporting relevant posts selected using FBS provide more diverse aspects of a news headline than those chosen using RBS. As a result, the performance of the query likelihood increased.",null,null
,,,
288,4.2.2 The News Headline Prior,null,null
,,,
289,We proposed two criteria to estimate the news headline prior: Temporal Profiling and Term Importance. We experimentally confirmed the usefulness of the proposed criteria to estimate the news headline prior.,null,null
,,,
290,"First, we evaluated the performance of each approach according to varying the period . The approaches consider a certain period from a query day to gather evidence for the news headline prior. Generally, blog posts and news headlines related to events that happened on a query day are published on that day or in the following days. However, they can be published on preceding days, because of the time discrepancy described in section 4.1.2.",null,null
,,,
291,We defined several periods as follows:,null,null
,,,
292,· 1 :  is set between -1 and +1 days from Qd.,null,null
,,,
293,· 2 :  is set between -3 and +7 days from Qd.,null,null
,,,
294,· 3 :  is set between -3 and +14 days from Qd.,null,null
,,,
295,"Let P RIT P and P RIT I be the news headline prior estimated using the Temporal Profiling and Term Importance, respectively. Table 2 shows the performances of each approach according to varying periods and those obtained from the combination of the two approaches. For the experiments, we set the parameters,  in Eq.12 and  in Eq.14, by maximizing the MAP using an exhaustive search in the following",null,null
,,,
296,MAP of News Headline Prior,null,null
,,,
297,0.2,null,null
,,,
298,0.18,null,null
,,,
299,0.16,null,null
,,,
300,0.14,null,null
,,,
301,0.12,null,null
,,,
302,0.1,null,null
,,,
303,0.08,null,null
,,,
304,0.06,null,null
,,,
305,0.04,null,null
,,,
306,0,null,null
,,,
307,0.2,null,null
,,,
308,0.4,null,null
,,,
309,0.6,null,null
,,,
310,0.8,null,null
,,,
311,1,null,null
,,,
312,"The weighting parameter, 2",null,null
,,,
313,"Figure 2: The Map scores of the news headline prior according to varying the parameter 2 (1 , 1).",null,null
,,,
314,Table 3: The performances of systems integrating,null,null
,,,
315,"the query likelihood and the news headline prior,",null,null
,,,
316,"QLHRBS+P RIT P+T I and QLHF BS+P RIT P+T I (1 , 0.8 and 2 ,"" 0.8). uogTrTStimes: The best performance in TREC'09 Top Stories Identification Task,""",null,null
,,,
317,"QLHF BS: the best performance of the query likelihood, P RIT P +T I : the best performance of the news headline prior. The best performances are shown",null,null
,,,
318,in bold. Statistical significance at the 0.05 and 0.01,null,null
,,,
319,level is indicated by  and  for improvement from,null,null
,,,
320,"the query likelihood, respectively, § and ¶ for im-",null,null
,,,
321,"provement from the news headline prior, respec-",null,null
,,,
322,tively.,null,null
,,,
323,Model,null,null
,,,
324,MAP,null,null
,,,
325,P@5,null,null
,,,
326,P@10,null,null
,,,
327,uogTrTStimes,null,null
,,,
328,0.1862,null,null
,,,
329,0.3236,null,null
,,,
330,0.3127,null,null
,,,
331,QLHF BS P RIT P +T I QLHRBS+P RIT P+T I QLHF BS+P RIT P+T I,null,null
,,,
332,0.1315 0.1957 0.2081¶ 0.2124¶,null,null
,,,
333,0.2473 0.3673 0.4145¶ 0.4255¶,null,null
,,,
334,0.2255 0.3364 0.3455 0.3527§,null,null
,,,
335,values.,null,null
,,,
336,",  : 30, 40, 50, 60, 70",null,null
,,,
337,"For both approaches, as we consider a longer period, we obtain better results. This observation confirms our assumption that if a news story is important for a given day, blog posts and news headlines relevant to it will be posted during several days. Although Temporal Profiling resulted in good performance, the performances of the Term Importance were relatively low. For event detection, the usefulness of the named entities can change depending on which circumstances they are used in [17]. We think that the poor performance of Term Importance is because we used the named entities without considering the circumstances. However, the combination of the two approaches led to the best performance ( , 50 and  ,"" 40). Compared with the best performance of Temporal Profiling, we achieved 1.57% and 6.18% improvement in MAP and P@5, respectively. These results verify the usefulness of the named entities for identifying important news stories.""",null,null
,,,
338,"To explore the influence of two criteria when identifying the top news story, we measured the MAP score according",null,null
,,,
339,400,null,null
,,,
340,Table 4: The performances of the supporting relevant posts chosen using RBS and FBS.,null,null
,,,
341,Model,null,null
,,,
342,-nDCG@5 -nDCG@10 IA-P@5 IA-P@10,null,null
,,,
343,QLHRBS+P RIT P+T I QLHF BS+P RIT P+T I,null,null
,,,
344,0.479 0.485,null,null
,,,
345,0.486 0.492,null,null
,,,
346,0.169 0.171,null,null
,,,
347,0.145 0.147,null,null
,,,
348,"to varying the weighting parameter 2 (1 ,"" 1, i.e. we are utilizing only the news headline prior to evaluate the performance), in Figure 2. The weight parameter 2 controls the relative importance of Temporal Profiling and Term Importance as the news headline prior. The best performance was obtained when 2 "","" 0.8. From these results, we can again confirm that Temporal Profiling and Term Importance should be considered together to improve the performance.""",null,null
,,,
349,4.2.3 Integration of the Query Likelihood and the News Headline Prior,null,null
,,,
350,"Finally, we measured the performance of our system that integrates the query likelihood and the new headline prior. To integrate these components, we used QLHRBS and QLHF BS for the query likelihood, and P RIT P +T I for the news headline prior.",null,null
,,,
351,"Table 3 shows the performances of our systems, QLHRBS+ P RIT P+T I and QLHF BS + P RIT P+T I. In addition, for comparison purposes, we reported the best performing results of the TREC-2009 Top Stories Identification Task [21], and the best performances of the query likelihood and the news headline prior. We performed the Wilconxon signed rank test to examine whether the improvement of the performance over that of each component was statistically significant.",null,null
,,,
352,"Integrating the two components significantly improved the performance of TSIT. For the MAP, the best performance was 8.09% and 1.67% higher than those of the query likelihood and the news headline prior, respectively. Specifically, our system achieved 2.62%, 10.19% and 4.00% further increases in MAP, P@5 and P@10 over the best performance of TREC'09 TSIT.",null,null
,,,
353,"This result implies that the performance can be improved by combining the query likelihood and the news headline prior. They reflect different characteristics that important news headlines should be satisfying. The query likelihood identifies the important news headlines based on modeling the dominant topics in blog posts, but the news headline prior identifies them using various features such as the number of relevant posts, and the importance of terms within news headlines.",null,null
,,,
354,"Figure 3 shows the MAP scores of QLHF BS + P RIT P+T I according to varying the parameter 1 (2 , 0.8). The weight parameter 1 controls the relative importance of the query likelihood and the news headline prior. The best performance was obtained when 1 ,"" 0.8. From these results, we can again verify that the performance for TSIT can be improved when integrating the query likelihood and the news headline prior. We do not show the graph for QLHRBS+P RIT P+T I, because it was almost identical to that of QLHF BS + P RIT P+T I.""",null,null
,,,
355,4.2.4 Diversity of Supporting Relevant Posts,null,null
,,,
356,"The supporting relevant posts should provide the diverse aspects relevant to a news headline. We proposed two approaches to choose the supporting relevant posts, the RBS and the FBS. We evaluated the diversity of the supporting",null,null
,,,
357,MAP of integrated system,null,null
,,,
358,0.22,null,null
,,,
359,0.21,null,null
,,,
360,0.2,null,null
,,,
361,0.19,null,null
,,,
362,0.18,null,null
,,,
363,0.17,null,null
,,,
364,0.16,null,null
,,,
365,0.15,null,null
,,,
366,0.14,null,null
,,,
367,0.13,null,null
,,,
368,0,null,null
,,,
369,0.2,null,null
,,,
370,0.4,null,null
,,,
371,0.6,null,null
,,,
372,0.8,null,null
,,,
373,1,null,null
,,,
374,The weighting parameter ,null,null
,,,
375,1,null,null
,,,
376,"Figure 3: The Map scores of the integrated system according to varying the parameter 1 (2 , 0.8)",null,null
,,,
377,relevant posts selected by each approach and displayed the results in Table 4.,null,null
,,,
378,"FBS performed better than RBS. We can verify that the supporting relevant posts of FBS provided more diverse aspects of a news headline than those of RBS. These results confirm that the use of blog feeds can improve the diversity of the supporting relevant posts. Furthermore, these results agree with the results from identifying the top news headlines in Table 3. That is, compared with RBS, FBS chose the supporting relevant posts that provide more correct and diverse aspects of a news headline. As a result, QLHF BS + P RIT P+T I outperformed QLHRBS + P RIT P+T I.",null,null
,,,
379,5. CONCLUSION AND FUTURE WORK,null,null
,,,
380,"In this study, we presented several approaches for identifying top news stories in the blogosphere. Our system utilizes the query likelihood and the news headline prior, based on the language model framework. For the query likelihood, we proposed several approaches to estimate the QLM and the NHLM. The QLM can be estimated using blog posts issued on the query day. We divided the blog posts into K clusters so that each cluster can accurately contain one of the various topics buried in blog posts. Then, we estimated the K number of QLMs respective to their clusters. We also proposed two approaches to choose the supporting relevant posts for a news headline. The posts were also able to cover many different aspects of the news headline.",null,null
,,,
381,"Furthermore, for the news headline prior, we suggested two criteria, Temporal Profiling and Term Importance. They measure the importance of a news headline in two different ways. Temporal profiling measures it using the temporal information of blog posts relevant to the news headline. Term Importance measures it using the meaningfulness of terms in the news headline.",null,null
,,,
382,We obtained the best performance for TSIT by considering the query likelihood and the news headline prior at,null,null
,,,
383,401,null,null
,,,
384,"the same time. From experimental results, we can verify the the proposed approaches are effective in identifying top news headlines.",null,null
,,,
385,"Many studies remain for future work. We used K-means clustering to model various topics buried in blog posts. It would be interesting to utilize several approaches such as PLSA [13] and LDA [4] to capture topics of blog posts. To improve the diversity of the supporting relevant posts, various ways such as MMR [6] are also worthy of research. Furthermore, we believe that various features such as comments or tags can be used to improve the performance when identifying top news stories.",null,null
,,,
386,6. ACKNOWLEDGMENTS,null,null
,,,
387,This work was supported in part by MKE & IITA through IT Leading R&D Support Project and also in part by the BK 21 Project in 2010.,null,null
,,,
388,7. REFERENCES,null,null
,,,
389,"[1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of WSDM 2009, pages 5­14. ACM, 2009.",null,null
,,,
390,"[2] J. Allan, M. E. Connell, W. B. Croft, F.-F. Feng, D. Fisher, and X. Li. Inquery and trec-9. In Proceedings of TREC-9, pages 551­562, 2000.",null,null
,,,
391,"[3] J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. In Proceedings of SIGIR 1998, pages 37­45. ACM, 1998.",null,null
,,,
392,"[4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993­1022, 2003.",null,null
,,,
393,"[5] T. Brants, F. Chen, and A. Farahat. A system for new event detection. In Proceedings of SIGIR 2003, pages 330­337. ACM, 2003.",null,null
,,,
394,"[6] J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of SIGIR 1998, pages 335­336. ACM, 1998.",null,null
,,,
395,"[7] C. C. Chen, Y.-T. Chen, Y. Sun, and M. C. Chen. Life cycle modeling of news events using aging theory. In Proceedings of ECML 2003, pages 47­59, 2003.",null,null
,,,
396,"[8] K.-Y. Chen, L. Luesukprasert, and S.-c. T. Chou. Hot topic extraction based on timeline analysis and multidimensional sentence modeling. IEEE Trans. on Knowl. and Data Eng., 19(8):1016­1025, 2007.",null,null
,,,
397,"[9] H. L. Chieu and Y. K. Lee. Query based event extraction along a timeline. In Proceedings of SIGIR 2004, pages 425­432. ACM, 2004.",null,null
,,,
398,"[10] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Bu¨ttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In Proceedings of SIGIR 2008, pages 659­666, New York, NY, USA, 2008. ACM.",null,null
,,,
399,"[11] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):1­38, 1977.",null,null
,,,
400,"[12] Q. He, K. Chang, and E.-P. Lim. Analyzing feature trajectories for event detection. In Proceedings of SIGIR 2007, pages 207­214. ACM, 2007.",null,null
,,,
401,"[13] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of SIGIR 1999, pages 50­57. ACM, 1999.",null,null
,,,
402,"[14] R. Jones and F. Diaz. Temporal profiles of queries. ACM Trans. Inf. Syst., 25(3):14, 2007.",null,null
,,,
403,"[15] J. Kleinberg. Bursty and hierarchical structure in streams. In Proceedings of SIGKDD 2002, pages 91­101. ACM, 2002.",null,null
,,,
404,"[16] P. Kolari, A. Java, and T. Finin. Characterizing the splogosphere. In Proceedings of 3rd Annl. Workshop on Weblogging Ecosystem: Aggregation, Analysis and Dynamics, 15th Word Wide Web Conf., 2006.",null,null
,,,
405,"[17] G. Kumaran and J. Allan. Text classification and named entities for new event detection. In Proceedings of SIGIR 2004, pages 297­304. ACM, 2004.",null,null
,,,
406,"[18] J. Lafferty and C. Zhai. Document language models, query models, and risk minimization for information retrieval. In Proceedings of SIGIR 2001, pages 111­119. ACM, 2001.",null,null
,,,
407,"[19] Y. Lee, S.-H. Na, and J.-H. Lee. An improved feedback approach using relevant local posts for blog feed retrieval. In Proceeding of CIKM 2009, pages 1971­1974. ACM, 2009.",null,null
,,,
408,"[20] Y. Lv and C. Zhai. Positional language models for information retrieval. In Proceedings of SIGIR 2009, pages 299­306. ACM, 2009.",null,null
,,,
409,"[21] C. Macdonald, I. Ounis, and I. Soboroff. Overview of the TREC-2009 Blog Track. In Proceedings of TREC 2009, 2010.",null,null
,,,
410,"[22] G. Mishne and M. de Rijke. A study of blog search. In Proceedings of ECIR 2006, pages 289­301. Springer, 2006.",null,null
,,,
411,"[23] S.-H. Nam, S.-H. Na, Y. Lee, and J.-H. Lee. Diffpost: Filtering non-relevant content based on content difference between two consecutive blog posts. In Proceedings of ECIR 2009, pages 791­795. Springer-Verlag, 2009.",null,null
,,,
412,"[24] C. Wang, M. Zhang, L. Ru, and S. Ma. Automatic online news topic ranking using media focus and user attention based on aging theory. In Proceeding of CIKM 2008, pages 1033­1042. ACM, 2008.",null,null
,,,
413,"[25] Y. Yang, T. Pierce, and J. Carbonell. A study of retrospective and on-line event detection. In Proceedings of SIGIR 1998, pages 28­36. ACM, 1998.",null,null
,,,
414,"[26] Y. Yang, J. Zhang, J. Carbonell, and C. Jin. Topic-conditioned novelty detection. In Proceedings of SIGKDD 2002, pages 688­693. ACM, 2002.",null,null
,,,
415,"[27] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to information retrieval. ACM Trans. Inf. Syst., 22(2):179­214, 2004.",null,null
,,,
416,"[28] K. Zhang, J. Zi, and L. G. Wu. New event detection based on indexing-tree and named entity. In Proceedings of SIGIR 2007, pages 215­222. ACM, 2007.",null,null
,,,
417,"[29] Y. Zhang, J. Callan, and T. Minka. Novelty and redundancy detection in adaptive filtering. In Proceedings of SIGIR 2002, pages 81­88. ACM, 2002.",null,null
,,,
418,402,null,null
,,,
419,,null,null
