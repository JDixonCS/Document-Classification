,sentence,label,data
0,Learning Hidden Variable Models for Blog Retrieval,null,null
1,Mengqiu Wang,null,null
2,Computer Science Department Stanford University,null,null
3,"Stanford, CA 94305, USA",null,null
4,mengqiu@cs.stanford.edu,null,null
5,ABSTRACT,null,null
6,"We describe probabilistic models that leverage individual blog post evidence to improve blog seed retrieval performances. Our model offers a intuitive and principled method to combine multiple posts in scoring a whole blog site by treating individual posts as hidden variables. When applied to the seed retrieval task, our model yields state-of-the-art results on the TREC 2007 Blog Distillation Task dataset.",null,null
7,Categories and Subject Descriptors,null,null
8,H.3.3 [Information Storage and Retrieval]: Retrieval Models,null,null
9,General Terms,null,null
10,"Design, Algorithms, Experimentation, Performance",null,null
11,Keywords,null,null
12,"Learning to Rank, Passage Retrieval, Blog Retrieval",null,null
13,1. INTRODUCTION,null,null
14,"In blog seed retrieval tasks, we are interested in finding blogs with relevant and recurring interests for given topics. Rather than ranking individual blog posts, whole sites are ranked (i.e. all posts within a blog). We propose two discriminatively trained probabilistic models that model individual posts as hidden variables.",null,null
15,2. PROBABILISTIC PASSAGE MODELS,null,null
16,"We make a modeling assumption that given a set of topranked passages of a document, the document is relevant if any one of the passages is relevant.",null,null
17,The first independent model (IND) assumes that the relevance of a specific top-ranked passage si is independent of the relevance of any other passage in s. We use the logistic function to model the relevance of a passage. Our second model (RBM) takes a step further and exploit the correlations among individual passages in a Restricted Boltzmann Machine framework.,null,null
18,"P (z , 0|s) , e-f(s)",null,null
19,1+e-f (s),null,null
20,P (z^|s)),null,null
21,",",null,null
22,1 Z,null,null
23,exp(Pi<j,null,null
24,f,null,null
25,(si,null,null
26,",",null,null
27,sj,null,null
28,",",null,null
29,"zi,",null,null
30,zj,null,null
31,),null,null
32,+,null,null
33,P|s|,null,null
34,"i,1",null,null
35,g(si,null,null
36,",",null,null
37,zi,null,null
38,)),null,null
39,"Copyright is held by the author/owner(s). SIGIR'10, July 19­23, 2010, Geneva, Switzerland. ACM 978-1-60558-896-4/10/07.",null,null
40,"where f (s) is a feature vector of the passage s, and  is",null,null
41,"the corresponding weight vector. Z is the partition function computed by summing over all possible relevance assignments. f (si, sj, zi, zj) are passage correlation features (cosine-sim, URL overlapping) and g(si, zi) are passage relevance feature (e.g., rank, score).",null,null
42,3. BLOG SEED RETRIEVAL,null,null
43,"We evaluated our models on TREC 2007 Blog Distillation Track dataset. We would first obtain top 5 ranked passages for each document using Indri's LM-based retrieval system, and then apply our model to re-rank each document. Training and testing is done by performing 5-fold cross-validation. We compare our models with four strong baselines. The first two are the Indri language model passage and document retrieval systems (Indri-psg, Indri-doc). The third one is the CMU system, which gives the best performance in TREC 2007 and 2008 evaluations [1]. The last one is the ReDDE federated search algorithm used in [2]. Our IND model showed significant improvements over the Indri passage and document retrieval baselines (58.5% and 9.4% relative improvements). The RBM model gained a small improvement over the IND model, and significantly outperformed the baseline CMU and ReDDE models.",null,null
44,Baseline,null,null
45,This work,null,null
46,Indri-psg 0.2267,null,null
47,IND,null,null
48,0.3596,null,null
49,Indri-doc 0.3284,null,null
50,RBM,null,null
51,0.3702,null,null
52,CMU 0.3385 RBM+cosine sim 0.3779,null,null
53,ReDDE 0.3150 RBM+url 0.3685,null,null
54,4. CONCLUSIONS,null,null
55,"In this paper, we introduced two probabilistic models that model individual blog posts as hidden variables for blog seed retrieval tasks. Our models produced state-of-the-art results on TREC 2007 Blog Distillation dataset.",null,null
56,5. REFERENCES,null,null
57,"[1] J. Elsas, J. Arguello, J. Callan, and J. Carbonell. Retrieval and feedback models for blog distillation. In Proceedings of TREC, 2007.",null,null
58,"[2] J. Elsas, J. Arguello, J. Callan, and J. Carbonell. Retrieval and feedback models for blog feed search. In Proceedings of SIGIR, 2008.",null,null
59,922,null,null
60,,null,null
