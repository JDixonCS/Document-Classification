,sentence,label,data
,,,
0,High Precision Opinion Retrieval using Sentiment-Relevance Flows,null,null
,,,
1,Seung-Wook Lee swlee@nlp.korea.ac.kr,null,null
,,,
2,Jung-Tae Lee jtlee@nlp.korea.ac.kr,null,null
,,,
3,Young-In Song yosong@microsoft.com,null,null
,,,
4,Hae-Chang Rim rim@nlp.korea.ac.kr,null,null
,,,
5," Dept. of Computer & Radio Comms. Engineering, Korea University, Seoul, South Korea  Microsoft Research Asia, Beijing, China",null,null
,,,
6,ABSTRACT,null,null
,,,
7,"Opinion retrieval involves the measuring of opinion score of a document about the given topic. We propose a new method, namely sentiment-relevance flow, that naturally unifies the topic relevance and the opinionated nature of a document. Experiments conducted over a large-scaled Web corpus show that the proposed approach improves performance of opinion retrieval in terms of precision at top ranks.",null,null
,,,
8,Categories and Subject Descriptors,null,null
,,,
9,H.3.3 [Information Search and Retrieval]: Retrieval Models,null,null
,,,
10,General Terms,null,null
,,,
11,"Algorithms, Measurement, Experimentation",null,null
,,,
12,Keywords,null,null
,,,
13,"opinion retrieval, sentiment analysis, sentiment-relevance flow",null,null
,,,
14,1. INTRODUCTION,null,null
,,,
15,"Opinion retrieval is a new retrieval task which involves locating documents that express opinions about a topic of interest. With the rapid growth of user-centric media such as blogs and forums, opinion retrieval has been gaining considerable attention in recent years from academia and industry motivated by the huge business opportunities.",null,null
,,,
16,"A key to success in opinion retrieval is to leverage both the topical relevance and the opinionated nature of documents simultaneously in ranking. However, most opinion retrieval systems separate the two components independently by adopting a re-ranking approach [1]. This approach involves finding as many relevant documents with regard to a given topic as possible regardless of their opinionated nature at first and then re-ranking them by combining the topical relevance scores with the opinion scores computed using some opinion detection techniques. Although a few approaches have shown attempts to unify the two components, for example, by using the proximity between topic words and opinion words within a document [3], the results are not yet conclusive and require more investigation.",null,null
,,,
17,"Copyright is held by the author/owner(s). SIGIR'10, July 19­23, 2010, Geneva, Switzerland. ACM 978-1-60558-896-4/10/07.",null,null
,,,
18,Figure 1: Illustration of various flows.,null,null
,,,
19,"In this paper, we present a new opinion retrieval method that adopts a very recently proposed technique involving relevance flow graphs [2]. A relevance flow graph of a document is a graphical plot of the topic relevance degree of individual sentences (with regard to a query) versus their positions in the document. The line graph labeled ""Relevance"" in Figure 1 illustrates an example; it visually shows the fluctuation of topic relevance levels within a document in regard to the query. [2] demonstrates that topically relevant documents have distinguishable flows from non-relevant ones in terms of the variance of relevance levels or the positions of high relevance levels (namely peaks), by designing a regression model based on such information and applying it to re-rank the retrieved results of conventional document ranking. Such method has shown promising results in improving the accuracy at top ranks.",null,null
,,,
20,"Motivated by this achievement, we hypothesize that a truly relevant document in opinion retrieval not only has opinion sentences regarding the topic but does have them in predictable patterns within the document. Our idea is to create a new flow graph, namely sentiment flow, that plots the opinionated nature of individual sentences using some opinion scoring method, and then merge it with the topic relevance flow to generate a whole new flow graph, called sentiment-relevance flow. The dotted line graph labeled ""Sent-Rel"" in Figure 1 illustrates an example. The following section will elaborate on such technique.",null,null
,,,
21,2. SENTIMENT-RELEVANCE FLOW,null,null
,,,
22,The sentiment-relevance flow of a document (SRF) is a sequence of scores that reflect both the topic relevance with regard to the query and the opinionated nature of individual,null,null
,,,
23,817,null,null
,,,
24,"sentences, ordered by the sentence positions. Given a query Q, we calculate the score of a sentence si at position i as follows:",null,null
,,,
25,"score(Q, si) ,"" topic(Q, si) · opinion(si)""",null,null
,,,
26,-1,null,null
,,,
27,"where topic(Q, si) refers to the topic relevance score of si for Q calculated using some conventional relevance scoring function, such as the BM25 function. opinion(si) represents the opinion score of si computed as follows:",null,null
,,,
28,i+W |O|,null,null
,,,
29,"opinion(si) ,",null,null
,,,
30,"f req(sj, owk)",null,null
,,,
31,-2,null,null
,,,
32,"j,i-W k,1",null,null
,,,
33,"where W is the half size of the context window (empirically set to 15), O is a set of opinion word lexicon, and f req(sj, owk) is a function that returns the frequency of opinion word owk in sentence sj. When computing this score, we look at not only the sentence at hand but also its context, because we have observed that opinions often appear not in the same sentence where topic words occur but in preceding or succeeding sentences.",null,null
,,,
34,"We normalize the individual sentence scores and the sentence positions in range 0 to 1 as in [2]. The graphical plot of such SRF, as shown in Figure 1, indicates the fluctuation of both topic relevance and opinionated nature within the document in a comprehensive way. As in [2], we refer to sentences that have scores higher than 0.5 as peaks.",null,null
,,,
35,"In order to infer document relevance from SRFs, we use maximum entropy modeling to train a regression model that is able to predict the relevance of a document based on its SRF. The main features extracted from the SRFs for regression are the ones found useful in [2], which include the following: the variance of sentence scores, the fraction of peaks, and the first peak position.",null,null
,,,
36,"For opinion retrieval, we rank documents by linearly combining the topic relevance scores with the new relevance scores inferred from their SRFs as follows:",null,null
,,,
37,"score(Q, D) ,""  · topic(Q, D) + (1 - ) · srf (Q, D) (3)""",null,null
,,,
38,"where topic(Q, D) is the topic relevance of document D with regard to Q, and srf (Q, D) is the prediction score of the classifier for D.  is a weight parameter where 0    1.",null,null
,,,
39,3. EXPERIMENT,null,null
,,,
40,"We conduct our experiments over Blogs06, a large-scaled Web blog collection. We use the title queries of 150 topics used in 2006, 2007, and 2008 TREC Blog Tracks. We validate our method in a re-ranking scheme. In other words, we initially retrieve the top n (,""15) documents using two popular ranking models, the BM25 model and the query likelihood (QL) language model with dirichlet smoothing1, and then re-rank the results using Equation 3. When evaluating one query set (50 topics), other two query sets (100 topics) are used to train a regression model. 15 top ranked documents for every training query are divided into positive and negative training instance groups based on their relevance judgments. The main evaluation measures are P@1, P@3, and P@5 since our method aims to achieve high accuracy at top ranks via re-ranking. The relevance judgement set consists of two distict aspects, relevance and opinionated""",Y,null
,,,
41,"1We empirically tuned k1,""1.2, b"",0.1 for BM25 and µ,5000 for QL smoothing parameter.",null,null
,,,
42,Table 1: Performance of topical retrieval,null,null
,,,
43,Method,null,null
,,,
44, P@1 P@3 P@5,null,null
,,,
45,BM25,null,null
,,,
46,N/A 0.5800 0.6334 0.6041,null,null
,,,
47,BM25+RF 0.15 0.6333 0.6422 0.6427,null,null
,,,
48,BM25+SRF 0.00 0.7200 0.7089 0.6907,null,null
,,,
49,QL,null,null
,,,
50,N/A 0.5933 0.6200 0.6160,null,null
,,,
51,QL+RF,null,null
,,,
52,0.02 0.6333 0.6711 0.6587,null,null
,,,
53,QL+SRF 0.01 0.7600 0.6956 0.6933,null,null
,,,
54,Table 2: Performance of opinion retrieval,null,null
,,,
55,Method,null,null
,,,
56, P@1 P@3 P@5,null,null
,,,
57,BM25,null,null
,,,
58,N/A 0.4400 0.4556 0.4320,null,null
,,,
59,BM25+SRF 0.01 0.5800 0.5800 0.5573,null,null
,,,
60,QL,null,null
,,,
61,N/A 0.4800 0.4756 0.4640,null,null
,,,
62,QL+FULL N/A 0.5600 0.5222 0.5373,null,null
,,,
63,QL+PROX N/A 0.5800 0.5556 0.5547,null,null
,,,
64,QL+SRF,null,null
,,,
65,0.01 0.6333 0.5689 0.5520,null,null
,,,
66,"relevance. Thus, we report the topic P@Ns and the opinion P@Ns of the system separately. For sentence boundary detection, we use a public sentence splitter software2. We use the sentiment word list in the General Inquirer3, which is a public opinion dictionary in the linguistics field. We only collect adjectives, adverbs, and verbs from the opinion and emotion categories; as a result, the lexicon is made up of 1,496 entries.",null,null
,,,
67,"Table 1 shows the performance of topical retrieval for the two initial results, relevance flow based re-ranking (RF) and our sentiment-relevance flow based re-ranking (SRF). As mentioned from previous study, RF successfully re-ranks high position documents. It is notable that our SRF also improves the performance of traditional topical retrieval since it basically aims to capture the pattern of relevant sentences.",null,null
,,,
68,"In aspect of opinion retrieval, as shown in Table 2, SRF shows significant and consistant improvement. We compare our method with two previous re-ranking approaches for opinion retrieval with QL setting (since it outperforms BM25). Opinion score measured by QL+FULL is dominated by a number of opinion words that appeared in a whole document, while QL+PROX only considers opinion words located within W sentences from the query terms. We can observe that proximity is a helpful feature for opinion retrieval. It is remarkable that our sentiment-relevance flow based re-ranking scheme achieves better improvement. Note that the maximum performance are acheived on low  values which implies that the trained regression model based on SRF features are very accurate and reliable.",null,null
,,,
69,4. REFERENCES,null,null
,,,
70,"[1] I. Ounis, C. Macdonald, and I. Soboroff. Overview of the TREC-2008 blog track. In Proc. of TREC 2008.",null,null
,,,
71,[2] J. Seo and J. Jeon. High precision retrieval using relevance-flow graph. In Proc. of SIGIR 2009.,null,null
,,,
72,[3] M. Zhang and X. Ye. A generation model to unify topic relevance and lexicon-based sentiment for opinion retrieval. In Proc. of SIGIR 2008.,null,null
,,,
73,2http://l2r.cs.uiuc.edu/~ecogcomp/tools.php 3http://www.wjh.harvard.edu/~inquirer/,null,null
,,,
74,818,null,null
,,,
75,,null,null
