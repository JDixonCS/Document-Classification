,sentence,label,data
,,,
0,Mining Adjacent Markets from a Large-scale Ads Video Collection for Image Advertising,null,null
,,,
1,Guwen Feng,null,null
,,,
2,"Nanjing University Nanjing, Jiangsu, P.R.China",null,null
,,,
3,linvondepp@gmail.com,null,null
,,,
4,"Xin-Jing Wang, Lei Zhang, Wei-Ying Ma",null,null
,,,
5,"Microsoft Research Asia Beijing, P.R.China",null,null
,,,
6,"{xjwang,leizhang,wyma}@microsoft.com",null,null
,,,
7,ABSTRACT,null,null
,,,
8,"The research on image advertising is still in its infancy. Most previous approaches suggest ads by directly matching an ad to a query image, which lacks the power to identify ads from adjacent market. In this paper, we tackle the problem by mining knowledge on adjacent markets from ads videos with a novel Multi-Modal Dirichlet Process Mixture Sets model, which is a unified model of (video frames) clustering and (ads) ranking. Our approach is not only capable of discovering relevant ads (e.g. car ads for a query car image), but also suggesting ads from adjacent markets (e.g. tyre ads). Experimental results show that our proposed approach is fairly effective.",null,null
,,,
9,Categories and Subject Descriptors,null,null
,,,
10,I.5.4 [Pattern Recognition]: Applications ­ computer vision. G.3 [Probability and Statistics]: Nonparametric statistics.,null,null
,,,
11,General Terms,null,null
,,,
12,"Algorithms, Performance.",null,null
,,,
13,Keywords,null,null
,,,
14,"Image advertising, adjacent marketing, video retrieval.",null,null
,,,
15,1. INTRODUCTION,null,null
,,,
16,"Though image has become an important media in the Web, how to monetize web images is a seldom touched problem. Few research works have been published in the literature. Among them, most of the works suggest directly mapping an ad to an image [2]. They suffer from the vocabulary impedance problem so that if a term does not appear in both an image and an ad' features, no connections will be built between them. The approach of Wang et al. [4] improves this by leveraging the ODP ontology to bridge the vocabulary gap, but it is still limited by the available texts.",null,null
,,,
17,"Adjacent marketing means to develop additional items which compliment a customer's needs in some manner, e.g. suggest insurance when one buys a car. The insurance package thus makes up of qualified adjacent markets of cars. A key challenge is to discover the potential adjacent market (e.g. insurance) of a certain",null,null
,,,
18, This work was performed in Microsoft Research Asia.,null,null
,,,
19,"Copyright is held by the author/owner(s). SIGIR'10, July 19­23, 2010, Geneva, Switzerland. ACM 978-1-60558-896-4/10/07.",null,null
,,,
20,Retrieved And Expanded Frames,null,null
,,,
21,... ...,null,null
,,,
22,Query,null,null
,,,
23,Ranking Results,null,null
,,,
24,Advertise,null,null
,,,
25,Benz,null,null
,,,
26,Insurance,null,null
,,,
27,Tires,null,null
,,,
28,Figure 1. Key idea: the story frames (in red blocks) and ads frames (cyan blocks) of video ads suggest adjacent markets.,null,null
,,,
29,product/object (e.g. car).,null,null
,,,
30,"In this paper we propose a solution of adjacent marketing for image advertising based on a large-scale ads video collection. It is motivated by the fact that generally a video ad contains two types of frames ­ story frames and ads frames, as shown in Figure 1. Story frames in general provide the main concepts (e.g. cars) that are related to the corresponding ads (e.g. insurance, tires). They imply certain human knowledge on the adjacent markets, e.g. showing tire ads on car images. A novel Multi-Modal Dirichlet Process Mixture Sets (MoM-DPM Sets) model is proposed as the key technique behind.",null,null
,,,
31,2. SYSTEM OVERVIEW,null,null
,,,
32,"Figure 2 shows the system overview. In the offline stage, we extract video keyframes and perform auto-tagging on them. The online stage contains three steps: 1) multimodal search on keyframes of ads videos given a query image (or query images). Both visual and textual similarities are taken into consideration. The texts come from three resources: image auto-tagging, OCR and surrounding texts; 2) search result expansion. Since the search step tends to find video frames of similar content, to incorporate the adjacent information between objects, we expand the retrieved frames with the rest frames in corresponding videos. For example, given the pizza image in Figure 2, the retrieved frames are generally about food, but by expanding them with the rest frames from the same ads videos, we are able to retrieve those soft drink and restaurant video frames which suggest the adjacent markets; and 3) ads clustering and ranking. The disadvantage brought by frame expansion is that the search results become noisy and with scattered topics. We propose the MoM-DPM Sets model to automatically learn the key topics from the expanded search results, and rank an ads database with the learnt topics. The top-",null,null
,,,
33,893,null,null
,,,
34,Query Image,null,null
,,,
35,Pizza 1. Search,null,null
,,,
36,Advertise,null,null
,,,
37,Annotate Using Arista,null,null
,,,
38,Visutal Features Detection Using ColorDescriptor,null,null
,,,
39,Large-Scale Video Frames DB,null,null
,,,
40,2. Cosine Measurement,null,null
,,,
41,Expanded Video Frames 3. Expand,null,null
,,,
42,Suggested Ads,null,null
,,,
43,Pizza,null,null
,,,
44,Pepsi Restaurant,null,null
,,,
45,6. Sorting Approach,null,null
,,,
46,Ads DB,null,null
,,,
47,MoM-DPM Sets,null,null
,,,
48,Clusters,null,null
,,,
49,5. Ranking,null,null
,,,
50,4. Clustering,null,null
,,,
51,...,null,null
,,,
52,...,null,null
,,,
53,Figure 2. System Overview.,null,null
,,,
54,ranked ads will be output. Therefore we find ads of Pepsi Cola and restaurants for the pizza image.,null,null
,,,
55,3. THE MoM-DPM SETS MODAL,null,null
,,,
56,"The MoM-DPM Sets model addresses four challenges: 1) discover the latent topics shared among the frames, 2) automatically determine the number of topics, 3) leverage both the visual and textual features to ensure a better performance of topic discovery, and 4) unify the approaches of topic mining and ads ranking.",null,null
,,,
57,"Let be the th latent topic and , be the visual and textual features of a query image respectively. Let , , denote the",null,null
,,,
58,"concentration parameter and base distributions of visual and textual features respectively. Let , be model parameters and",null,null
,,,
59,", be the visual and textual features of the observed video",null,null
,,,
60,frames labeled by the topic respectively. The general form of is MoM-DPM Sets is given in Eq(1).,null,null
,,,
61,"| , ,, ,",null,null
,,,
62,",",null,null
,,,
63,|,null,null
,,,
64,",",null,null
,,,
65,|,null,null
,,,
66,"|,",null,null
,,,
67,-1,null,null
,,,
68,if,null,null
,,,
69,for some ;,null,null
,,,
70,|,null,null
,,,
71,|,null,null
,,,
72,|,null,null
,,,
73,|,null,null
,,,
74,if,null,null
,,,
75,for all .,null,null
,,,
76,"where and are the observed video frames corresponding to topic . is the normalization factor. is the number of observed video frames and , is the number of observed video frames (except the th) which belong to topic . We use Gibbs sampling to solve the model, which generally converges in 30 iterations.",null,null
,,,
77,"MoM-DPM Sets has two key features which make it different from previous multimodal DP Mixture processes [3]. Firstly, rather than to learn an optimal parameter set of , , it intends to figure out the membership of each video frame given the observed video frames , . In our approach, , , and",null,null
,,,
78,"are known ( and are learnt from the clustering step), while",null,null
,,,
79,"the model parameters are going to be integrated out analytically. Such a set-based reasoning strategy [1] is more powerful in discovering analogical objects, e.g. given a frame set of Pepsi-cola and Coca-cola, this model is able to discover soda because they share the same concept of soft drinks. Secondly, since the model does not rely on certain parameter set, the clustering (topic mining) step and ranking step shares the same model formulation. The ranking process is as Eq.(2).",null,null
,,,
80,Average Precision,null,null
,,,
81,0.8,null,null
,,,
82,0.7,null,null
,,,
83,0.6,null,null
,,,
84,0.5,null,null
,,,
85,0.4,null,null
,,,
86,0.3,null,null
,,,
87,0.2,null,null
,,,
88,1,null,null
,,,
89,3,null,null
,,,
90,5,null,null
,,,
91,Our Approach,null,null
,,,
92,7,null,null
,,,
93,10,null,null
,,,
94,15,null,null
,,,
95,20,null,null
,,,
96,top N,null,null
,,,
97,Argo [4] DM [2],null,null
,,,
98,Figure 3. Average precision performance @ top N.,null,null
,,,
99,"| .. , ,",null,null
,,,
100,max,null,null
,,,
101,|,null,null
,,,
102,",",null,null
,,,
103,-2,null,null
,,,
104,|,null,null
,,,
105,",",null,null
,,,
106,where ..,null,null
,,,
107,", , ... , defines the latent topic space.",null,null
,,,
108,4. EXPERIMENTS,null,null
,,,
109,"We crawled about 32k videos from Youtube.com initiated by 30 popular concepts for advertising. In total 327,889 key frames were extracted, which make up of the ads videos collection for frame search. We randomly selected 450 ads as a separate ads DB for the ranking purpose. 100 Flickr images were used as queries.",Y,null
,,,
110,"Figure 3 illustrates the average precision at top 20 ads of our approach compared with those of the baselines Argo [4] and direct match [2]. It can be seen that our approach consistently outperforms the baselines. The gap between the blue curve and the green one indicates that our approach is able to identify the relevant ads from potential adjacent market, which have little overlap with the query image in both visual and textual features. And the gap between the red curve and the green one indicates that Argo [4] also tackles the adjacent marketing problem to a certain extent but it is not effective enough.",null,null
,,,
111,"There are big gaps between our methods and the baselines in top 3 results, while the gap narrows down from top 5 to top 20. This may due to the limited size of our ads DB. Considering that generally a publisher such as Google shows less than five targeted ads, our method suggests a promising research direction for adjacent marketing.",null,null
,,,
112,5. CONCLUSION,null,null
,,,
113,Web image is an uncovered gold mine. Our method is the first work to tackle the adjacent marketing problem for image advertising. It leverages the human intelligence embedded in video ads to build the connections among ads objects based on a novel Multi-Modal Dirichlet Process Mixture Sets model.,null,null
,,,
114,6. REFERENCES,null,null
,,,
115,"[1] Z. Ghahramani, and K. A. Heller. Bayesian Sets. Neural Information Processing Systems (NIPS). 2005.",null,null
,,,
116,"[2] T. Mei, X.-S. Hua, and S.-P. Li. Contextual In-Image Advertising. 2008.",null,null
,,,
117,"[3] A. Velivelli, and T.S. Huang. Automatic Video Annotation Using Multimodal Dirichlet Process Mixture Model. ICNSC 2008.",null,null
,,,
118,"[4] X.-J. Wang, M. Yu, et al. Argo: Intelligent Advertising by Mining a User's Interest from His Photo Collections, in conjunction with SIGKDD (ADKDD), Paris, 2009.",null,null
,,,
119,894,null,null
,,,
120,,null,null
