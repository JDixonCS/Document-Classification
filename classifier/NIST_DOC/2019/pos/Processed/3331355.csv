,sentence,label,data
0,Short Research Papers 1B: Recommendation and Evaluation,null,null
1,,null,null
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
3,,null,null
4,Unbiased Low-Variance Estimators for Precision and Related Information Retrieval Effectiveness Measures,null,null
5,,null,null
6,Gordon V. Cormack,null,null
7,University of Waterloo,null,null
8,ABSTRACT,null,null
9,"This work describes an estimator from which unbiased measurements of precision, rank-biased precision, and cumulative gain may be derived from a uniform or non-uniform sample of relevance assessments. Adversarial testing supports the theory that our estimator yields unbiased low-variance measurements from sparse samples, even when used to measure results that are qualitatively different from those returned by known information retrieval methods. Our results suggest that test collections using sampling to select documents for relevance assessment yield more accurate measurements than test collections using pooling, especially for the results of retrieval methods not contributing to the pool.",null,null
10,ACM Reference Format: Gordon V. Cormack and Maura R. Grossman. 2019. Unbiased Low-Variance Estimators for Precision and Related Information Retrieval Effectiveness Measures. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,null,null
11,1 INTRODUCTION,null,null
12,The thesis of this work is that information retrieval,null,null
13,When used to estimate mean P@k,null,null
14,"dyn is a Horvitz-Thompson estimator [3] for the difference between the true value of P@k and a learned prior estimate. In the special case where the prior estimate is fixed at 0, dyn P@k is equivalent to stat P@k, which is also unbiased but, according to the theory underlying this work, higher variance.",null,null
15,1See open source dyn_eval implementation at cormack.uwaterloo.ca/sample.,null,null
16,"Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). SIGIR '19, July 21­25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-6172-9/19/07. https://doi.org/10.1145/3331184.3331355",null,null
17,,null,null
18,Maura R. Grossman,null,null
19,University of Waterloo,null,null
20,,null,null
21,"inf P@k and xinf P@k, in contrast, compute a separate esti-",null,null
22,,null,null
23,"mate for each stratum of sampled assessments. However, no such",null,null
24,,null,null
25,estimate is possible whenever a retrieval result to be measured,null,null
26,,null,null
27,contains none of the assessed documents from a particular stratum.,null,null
28,,null,null
29,"To resolve this singularity, inf uses Lindstone smoothing, which",null,null
30,,null,null
31,effectively substitutes a default constant value c when the estimate,null,null
32,,null,null
33,would otherwise be 0 . The published descriptions of inf and xinf,null,null
34,0,null,null
35,,null,null
36,use c = 1 ; the reference implementation used for this study uses,null,null
37,2,null,null
38,,null,null
39,c,null,null
40,,null,null
41,=,null,null
42,,null,null
43,1 3,null,null
44,,null,null
45,.,null,null
46,,null,null
47,The,null,null
48,,null,null
49,net,null,null
50,,null,null
51,effect,null,null
52,,null,null
53,is,null,null
54,,null,null
55,that,null,null
56,,null,null
57,inf,null,null
58,,null,null
59,measurements are biased toward,null,null
60,,null,null
61,"the value c, with small values of P@k being overestimated, and",null,null
62,,null,null
63,large values underestimated.,null,null
64,,null,null
65,The theory that an estimator is unbiased may be falsified by iden-,null,null
66,,null,null
67,"tifying any possible combination of topics, documents, relevance",null,null
68,,null,null
69,"assessment sample, and retrieval results, for which it yields a biased",null,null
70,,null,null
71,estimate. The experiment described here takes as ground truth the,null,null
72,,null,null
73,"documents, topics, and relevance assessments from the TREC 8",null,null
74,,null,null
75,"Ad Hoc test collection [6], assuming the topics to be a random",null,null
76,,null,null
77,sample drawn from a population of topics with precisely the same,null,null
78,,null,null
79,"mean and sample variance, and the assessments to be complete and",null,null
80,,null,null
81,"infallible. To measure bias, we consider two sets of retrieval results:",null,null
82,,null,null
83,"the 129 ""TREC runs"" submitted to TREC for evaluation, and 129",null,null
84,,null,null
85,"""dual runs"" engineered to have precisely the same true P@k as the",null,null
86,,null,null
87,"TREC runs, in 1-1 correspondence. The dual runs were formed by",null,null
88,,null,null
89,randomly permuting the ranks of the relevant documents in each,null,null
90,,null,null
91,"run, while preserving the ranks of non-relevant documents.",null,null
92,"The results of this adversarial testing show no bias for dyn or stat, small but significant bias for xinf",null,null
93,,null,null
94,"very large bias, both within and between the TREC and dual runs,",null,null
95,,null,null
96,for depth-k pooling and hedge. To address the argument that biased,null,null
97,,null,null
98,"measurements do not matter as long as they accurately rank the relative effectiveness of the runs, we calculate median  correla-",null,null
99,,null,null
100,tion between the rankings achieved by repeated measurements of,null,null
101,,null,null
102,"MP@k versus ground truth, for the TREC runs, the dual runs, and",null,null
103,,null,null
104,their union.,null,null
105,,null,null
106,2 MEASURING P@K,null,null
107,,null,null
108,"Given a document d  D and a topic t  T , binary relevance",null,null
109,,null,null
110,rel(d) = 1 indicates that an infallible assessor would judge d rel-,null,null
111,,null,null
112,evant to t; rel(d) = 0 indicates otherwise. Given a ranked list of,null,null
113,,null,null
114,"documents r = r1r2 · · · rn from D and a topic t, our concern is how",null,null
115,,null,null
116,1,null,null
117,best to measure P@k = k,null,null
118,,null,null
119,"min(k , n ) i =1",null,null
120,,null,null
121,rel(ri,null,null
122,,null,null
123,"),",null,null
124,,null,null
125,understanding,null,null
126,,null,null
127,that,null,null
128,,null,null
129,the,null,null
130,,null,null
131,infallible assessor is a hypothetical entity whose judgments can at,null,null
132,,null,null
133,"best be approximated by real assessors, under controlled conditions,",null,null
134,,null,null
135,"rendering rel(d) for a subset J of all possible d. In this work, we",null,null
136,,null,null
137,assume the fiction that rel(d) =,null,null
138,,null,null
139,rel(d ),null,null
140,,null,null
141,(d  J ) .,null,null
142,,null,null
143,0,null,null
144,,null,null
145,(d / J ),null,null
146,,null,null
147,If J is a statistical sample of D drawn without replacement such,null,null
148,,null,null
149,that each d  D is drawn with prior probability ,null,null
150,,null,null
151,945,null,null
152,,null,null
153,Short Research Papers 1B: Recommendation and Evaluation,null,null
154,,null,null
155,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
156,,null,null
157,"0, we have the unbiased stat estimator:",null,null
158,,null,null
159,stat P@k,null,null
160,,null,null
161,=,null,null
162,,null,null
163,1 k,null,null
164,,null,null
165,"min(k , n ) i =1",null,null
166,,null,null
167,rel(ri ) ,null,null
168,,null,null
169,.,null,null
170,,null,null
171,The dyn estimator harnesses a model M(d) estimating Pr[rel(d) =,null,null
172,,null,null
173,1]:,null,null
174,,null,null
175,"min(k , n )",null,null
176,,null,null
177,1,null,null
178,,null,null
179,1,null,null
180,,null,null
181,dyn P@k = k,null,null
182,,null,null
183,i=1 M(ri ) + ,null,null
184,,null,null
185,rel(ri ) - M(ri ) 0,null,null
186,,null,null
187,(ri  J ) .,null,null
188,,null,null
189,"Provided M(d) is independent of the outcome d  J , dyn P@k is unbiased. If J is a stratified sample drawn without replacement, this constraint is met when M(d) is derived from {rel(d )|d   J \ strat(d)}, where strat(d) is the stratum from which d is drawn.",null,null
190,A given IR method yields a different ranking r,null,null
191,MP@k is,null,null
192,1 dyn MP@k = |T | t T dyn P@k(t) .,null,null
193,,null,null
194,3 STRATIFIED SAMPLING,null,null
195,"The simplest sampling strategy that we consider divides J into equal-sized strata with equal sampling rates. For this strategy, M is learned using cross-validation, holding out each stratum in turn,",null,null
196,and using the remaining strata for training. In the present study we used logistic regression to maximize,null,null
197,,null,null
198,1 M(d) = 1 + exp(-(p + L(d))) . p was determined numerically to solve,null,null
199,,null,null
200,M(d) =,null,null
201,d,null,null
202,,null,null
203,r el,null,null
204,,null,null
205,d,null,null
206,,null,null
207,"rel(d) ,",null,null
208,,null,null
209,so that the predicted number of relevant documents in the training examples would match the sample estimate.,null,null
210,,null,null
211,4 PROPORTIONAL TO SIZE SAMPLING,null,null
212,Variance can be reduced using a model P(d) that predicts Pr[rel(d)] prior to determining ,null,null
213,the present study we used reciprocal-rank fusion of the rankings submitted to TREC. We partitioned D into N strata of exponentially,null,null
214,"increasing size, so that higher-ranked documents were assigned to smaller strata. An equal number of documents n were drawn from each stratum Si , and the exponential growth rate  calculated numerically to cover D when the size of the smallest stratum |S0|= s:",null,null
215,N -1,null,null
216,= min  . s · s ·,null,null
217,i =0,null,null
218,|Si |= s ·,null,null
219,N -2,null,null
220,|SN -2 |= |D|- |Si | .,null,null
221,i =0,null,null
222,,null,null
223,5 TESTING BIAS AND VARIANCE,null,null
224,Error err is the difference between a measurement est and ground,null,null
225,"truth tru. Bias b is the average of err over repeated measurements. MSE is the average of err2. Variance e2rr = MSE - b2. To test our claim that dyn MP@k is unbiased, ground truth need not be perfect,",null,null
226,"and the retrieval results to be measured need not be derived from real IR systems, as long as they are independent of J .",null,null
227,"In evaluating an estimator, it is necessary to consider that MP@k is defined over a population T , whereas dyn MP@k and other estimators are derived from a set of topics T , deemed to be a random sample of T . The expectation, and therefore the bias of an estimate, is the same, whether we consider it to be an estimate of MP@k = E P@k(T ) or of E P@k(T ). On the other hand, even ground truth for T has non-zero variance T2 when used as an estimator for MP@k :",null,null
228,,null,null
229,T2,null,null
230,,null,null
231,=,null,null
232,,null,null
233,1 |T |,null,null
234,,null,null
235,Var P@k(T ),null,null
236,,null,null
237,1 |T |-1,null,null
238,,null,null
239,Var P@k(T ) .,null,null
240,,null,null
241,"The inequality holds in expectation, and for the purposes of ground",null,null
242,,null,null
243,"truth, we deem it equal:",null,null
244,,null,null
245,T2,null,null
246,,null,null
247,=,null,null
248,,null,null
249,1 |T |-1,null,null
250,,null,null
251,Var P@k(T ) .,null,null
252,,null,null
253,The overall variance of an estimator is therefore,null,null
254,,null,null
255,"e2st = e2rr + T2 . Similarly, RMSE depends on what is being estimated:",null,null
256,,null,null
257,RMSerr =,null,null
258,,null,null
259,2,null,null
260,b,null,null
261,,null,null
262,+e2rr,null,null
263,,null,null
264,",",null,null
265,,null,null
266,"RMSET = T ,",null,null
267,,null,null
268,RMSEest = b2 +e2rr + T2 .,null,null
269,6 EXPERIMENT,null,null
270,"Using the TREC 8 data as ground truth, we compared the bias and variance of dyn MP@10 to competing statistical and non-statistical estimators with two different assessment budgets: 100 assessments per topic, and 400 assessments per topic. We also compared the effect of quadrupling the number of topics, as an alternative to quadrupling the per-topic assessment budget, given a larger assessment budget.",null,null
271,"Ground truth was derived from the 86, 830 relevance assessments",null,null
272,"To compute dyn, stat, and trec_eval2 estimates, we used our own implementation, available for download as the dyn_eval toolkit,1 which is input/output compatible with trec_eval, and has",null,null
273,2See trec.nist.gov/trec_eval/.,null,null
274,,null,null
275,946,null,null
276,,null,null
277,Short Research Papers 1B: Recommendation and Evaluation,null,null
278,,null,null
279,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
280,,null,null
281,Estimator,null,null
282,xinf stat dyn xinf stat dyn depth-5 hedge,null,null
283,xinf stat dyn xinf stat dyn depth-20 hedge,null,null
284,TREC,null,null
285,,null,null
286,Sample,null,null
287,Uniform Uniform Uniform,null,null
288,PPS PPS PPS Non-random Non-random,null,null
289,Uniform Uniform Uniform,null,null
290,PPS PPS PPS Non-random Non-random,null,null
291,Exhaustive,null,null
292,,null,null
293,Systematic Bias RMS Summary over TREC Runs,null,null
294,,null,null
295,b,null,null
296,,null,null
297,,null,null
298,,null,null
299,b,null,null
300,,null,null
301,err,null,null
302,,null,null
303,b,null,null
304,,null,null
305,100 assessments per topic,null,null
306,,null,null
307,RMSerr,null,null
308,,null,null
309,-0.0041 0.0004 0.0707 0.0443 0.0834,null,null
310,,null,null
311,0.0019 0.0010 0.0078 0.1154 0.1156,null,null
312,,null,null
313,-0.0006 0.0008 0.0061 0.0941 0.0943,null,null
314,,null,null
315,0.0427 0.0001 0.0859 0.0103 0.0865,null,null
316,,null,null
317,0.0008 0.0003 0.0029 0.0311 0.0312,null,null
318,,null,null
319,0.0002 0.0002 0.0031 0.0282 0.0284,null,null
320,,null,null
321,-0.0258 0.0000 0.0349 0.0000 0.0349,null,null
322,,null,null
323,-0.0296 0.0000 0.0330 0.0000 0.0330,null,null
324,,null,null
325,400 assessments per topic,null,null
326,,null,null
327,0.0017 0.0003 0.0113 0.0365 0.0382,null,null
328,,null,null
329,0.0002 0.0005 0.0032 0.0514 0.0515,null,null
330,,null,null
331,-0.0002 0.0003 0.0027 0.0383 0.0384,null,null
332,,null,null
333,0.0277 0.0001 0.0517 0.0065 0.0521,null,null
334,,null,null
335,0.0002 0.0001 0.0011 0.0107 0.0107,null,null
336,,null,null
337,0.0000 0.0001 0.0007 0.0082 0.0082,null,null
338,,null,null
339,-0.0011 0.0000 0.0034 0.0000 -0.0014 0.0000 0.0029 0.0000,null,null
340,1737 assessments per topic 0.0000 0.0000 0.0000 0.0000,null,null
341,,null,null
342,0.0034 0.0029,null,null
343,0.0000,null,null
344,,null,null
345,RMSE |T |= 50 |T |= 200,null,null
346,,null,null
347,0.0928 0.1226 0.1027 0.0955 0.0513 0.0496 0.0535 0.0523,null,null
348,,null,null
349,0.0768 0.0616 0.0515 0.0883 0.0256 0.0248 0.0403 0.0386,null,null
350,,null,null
351,0.0558 0.0656 0.0559 0.0661 0.0420 0.0415 0.0408 0.0407,null,null
352,,null,null
353,0.0294 0.0328 0.0280 0.0556 0.0209 0.0206 0.0205 0.0204,null,null
354,,null,null
355,0.0402 0.0202,null,null
356,,null,null
357,Table 1: TREC Runs,null,null
358,,null,null
359,Estimator,null,null
360,xinf stat dyn xinf stat dyn depth-5 hedge,null,null
361,xinf stat dyn xinf stat dyn depth-20 hedge,null,null
362,TREC,null,null
363,,null,null
364,Sample,null,null
365,Uniform Uniform Uniform,null,null
366,PPS PPS PPS Non-random Non-random,null,null
367,Uniform Uniform Uniform,null,null
368,PPS PPS PPS Non-random Non-random,null,null
369,Exhaustive,null,null
370,,null,null
371,Systematic Bias RMS Summary over Dual Runs,null,null
372,,null,null
373,b,null,null
374,,null,null
375,,null,null
376,b,null,null
377,,null,null
378,b,null,null
379,,null,null
380,err,null,null
381,,null,null
382,100 assessments per topic,null,null
383,,null,null
384,RMSerr,null,null
385,,null,null
386,-0.0043 0.0004 0.0709 0.0454 0.0842,null,null
387,,null,null
388,-0.0001 0.0010 0.0112 0.1163 0.1168,null,null
389,,null,null
390,-0.0018 0.0009 0.0093 0.0997 0.1001,null,null
391,,null,null
392,-0.0653 0.0001 0.1311 0.0116 0.1316,null,null
393,,null,null
394,0.0018 0.0006 0.0071 0.0734 0.0008 0.0004 0.0045 0.0465,null,null
395,,null,null
396,0.0737 0.0468,null,null
397,,null,null
398,-0.2202 0.0000 0.2381 0.0000 0.2381,null,null
399,,null,null
400,-0.1277 0.0000 0.1375 0.0000 0.1375,null,null
401,,null,null
402,400 assessments per topic,null,null
403,,null,null
404,0.0006 0.0003 0.0114 0.0356 0.0374,null,null
405,,null,null
406,-0.0020 0.0004 0.0049 0.0510 0.0512,null,null
407,,null,null
408,-0.0012 0.0004 0.0036 0.0405 0.0407,null,null
409,,null,null
410,-0.0261 0.0001 0.0698 0.0092 0.0704,null,null
411,,null,null
412,-0.0006 0.0002 0.0027 0.0264 0.0266,null,null
413,,null,null
414,-0.0003 0.0001 0.0016 0.0162 0.0163,null,null
415,,null,null
416,-0.1088 0.0000 0.1196 0.0000 0.1196,null,null
417,,null,null
418,-0.0526 0.0000 0.0574 0.0000 0.0574,null,null
419,,null,null
420,1737 assessments per topic 0.0000 0.0000 0.0000 0.0000,null,null
421,,null,null
422,0.0000,null,null
423,,null,null
424,RMSE |T |= 50 |T |= 200,null,null
425,,null,null
426,0.0935 0.1237 0.1081 0.1377 0.0842 0.0619 0.2415 0.1434,null,null
427,,null,null
428,0.0772 0.0626 0.0546 0.1327 0.0425 0.0311 0.2389 0.1390,null,null
429,,null,null
430,0.0552 0.0654 0.0575 0.0813 0.0485 0.0438 0.1263 0.0703,null,null
431,,null,null
432,0.0292 0.0329 0.0288 0.0728 0.0243 0.0218 0.1213 0.0609,null,null
433,,null,null
434,0.0402 0.0202,null,null
435,,null,null
436,Table 2: Dual Runs,null,null
437,,null,null
438,"been verified to produce identical results. To render xinf estimates, we used the reference implementation from TREC.3",null,null
439,3See trec.nist.gov/data/clinical/sample_eval.pl.,null,null
440,,null,null
441,"For statistical estimation, we considered two sampling strategies: equal-probability sampling, and probability proportional-to-size sampling",null,null
442,,null,null
443,947,null,null
444,,null,null
445,Short Research Papers 1B: Recommendation and Evaluation,null,null
446,,null,null
447,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
448,,null,null
449,Measure,null,null
450,MRBP,null,null
451,NDCG,null,null
452,,null,null
453,b 0.0000 0.0015 0.0032,null,null
454,,null,null
455,dyn,null,null
456,b,null,null
457,0.0001 0.0000 0.0001,null,null
458,,null,null
459,RMSE 0.0360 0.0283 0.0323,null,null
460,,null,null
461,TREC RMSE 0.0351 0.0280 0.0312,null,null
462,,null,null
463,"Table 3: dyn MRBP, MAP, and NDCG using PSS and 400 assessments per topic, compared to TREC ground truth.",null,null
464,,null,null
465,"and hedge, a best-of-breed dynamic pooling method. For depth-k pooling, we were not able to enforce a strict budget of 100 or 400 assessments per topic; as proxies we used k = 5 and k = 20, with 110 and 385 assessments per topic, on average.",null,null
466,"For each of the 129 TREC runs and each of 129 dual runs, we measured MP@10 100 times using each statistical estimation strategy, calculating bias, variance, and error as described in Section 5 above. For the non-statistical strategies, we measured MP@10 only once, since er r = 0.",null,null
467,Results over sets of runs are summarized by:,null,null
468,"· b: The mean bias over all runs, an indicator of systematic bias;",null,null
469,·  : the,null,null
470,b,null,null
471,"· RMS b: run-specific bias, over and above systematic bias; · RMS err : the",null,null
472,"Tables 1 and 2 shows these summary statistics for the TREC and dual runs. The results before the top break in each table use a budget of 100 assessments per topic; the results after the break use a budget of 400 assessments per topic, and the TREC gold standard uses 1, 737 assessments per topic.",null,null
473,"We see that, as predicted, the stat and dyn estimates are unbiased, while xinf shows small but significant bias, and the non-statistical methods show substantial bias in favour of the TREC runs. PPS improves the dyn and stat estimates, but harms xinf. For a total assessment budget of 20, 000 documents, which is at the low end of typical TREC efforts, a budget of 100 assessments per topic for 200 topics allows dyn to surpass the accuracy of exhaustive assessment for 50 topics, for less than a quarter of the assessment effort. A budget of 400 assessments per topic for 50 topics, yields insubstantially different accuracy from exhaustive assessment. A budget of 400 assessments per topic for 200 topics yields insubstantially different accuracy from exhaustive assessment for 200 topics, with less than half the effort of exhaustive assessment for 50 topics.",null,null
474,"7 RBP, MAP, AND NDCG",null,null
475,"The dyn MRBP estimator is a straightforward modification to dyn MP@k. dyn MAP and dyn NDCG are somewhat biased because they divide by a normalization factor, which is also an estimate. But the normalization factor is invariant between runs, and therefore has minimal impact. Table 3 shows the results for these estimators compared to exhaustive assessment. As expected, the dyn MRBP shows no significant bias, while dyn MAP and dyn MNDCG show",null,null
476,,null,null
477,"significant but insubstantial bias, with the net effect that all estimates have comparable accuracy to exhaustive assessment.",null,null
478,8 DISCUSSION AND CONCLUSION,null,null
479,"It has been argued that bias does not matter as long as runs are properly ranked. We combined the TREC and dual runs, and ranked them using dyn MP@10, depth-20 pooling, and hedge, achieving rank correlations  = 0.934,  = 0.715, and  = 0.826, respectively. In contrast, when only the TREC runs are considered, the correlations are  = 0.972,  = 0.996, and  = 0.995. These results call into question the viability of using rank correlation over known runs as a measure of test collection accuracy.  , like RMSE and other proposed measures, conflates bias and variance. We really have no idea whether differences in these measures reflect bias or variance.",null,null
480,"An unbiased estimator like dyn MP@k, dyn MRBP, or dyn DCG imposes no limit on the number of topics that could be assessed, splitting the assessment budget among them. Practical considerations like the overhead of obtaining and vetting topics are likely to dominate. A minimally biased estimator like dyn MAP or dyn NDCG constrains the number of topics that may be used to a number such that its bias is insubstantial compared to variance. Even so, the optimal number of topics appears to be substantially higher than 50.",null,null
481,"xinf, the most commonly used estimator, shows significant bias, occasioning substantial effort to discover amenable sampling strategies [7]. stat, on the other hand, shows substantial variance. Our design of dyn was directly inspired by these estimators, adopting the ""default value""",null,null
482,"There is no limit on the number of documents or the number of relevant documents per topic to which dyn may be applied. To keep variance reasonable, it is necessary to identify a sample space that contains substantially all of the relevant documents. Twenty years ago, depth-100 pooling was found to be adequate--if imperfect--for a collection of one-half million documents and topics with 100 or fewer relevant documents. Since that time, the number of documents and the number of relevant documents have increased, while assessment budgets have decreased. Statistical sampling offers a solution.",null,null
483,REFERENCES,null,null
484,"[1] Aslam, J. A., Pavlu, V., and Savell, R. A unified model for metasearch and the efficient evaluation of retrieval systems via the hedge algorithm. In SIGIR 2003.",null,null
485,"[2] Cormack, G. V., and Grossman, M. R. Beyond pooling. In SIGIR 2018. [3] Horvitz, D. G., and Thompson, D. J. A generalization of sampling without",null,null
486,"replacement from a finite universe. Journal of the American Statistical Association 47, 260",null,null
487,,null,null
488,948,null,null
489,,null,null
490,,null,null
