,sentence
0,Session 1A: Learning to Rank 1
1,
2,"SIGIR '19, July 21­25, 2019, Paris, France"
3,
4,A General Framework for Counterfactual Learning-to-Rank
5,
6,Aman Agarwal
7,"Cornell University Ithaca, NY"
8,aman@cs.cornell.edu
9,Ivan Zaitsev
10,"Cornell University Ithaca, NY"
11,iz44@cornell.edu
12,ABSTRACT
13,Implicit feedback
14,KEYWORDS
15,"Learning to rank, presentation bias, counterfactual inference"
16,"ACM Reference Format: Aman Agarwal, Kenta Takatsu, Ivan Zaitsev, and Thorsten Joachims. 2019. A General Framework for Counterfactual Learning-to-Rank. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval"
17,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331202"
18,
19,Kenta Takatsu
20,"Cornell University Ithaca, NY"
21,kt426@cornell.edu
22,Thorsten Joachims
23,"Cornell University Ithaca, NY"
24,tj@cs.cornell.edu
25,1 INTRODUCTION
26,Implicit feedback from user behavior is an attractive source of data in many information retrieval
27,A counterfactual inference approach for learning-to-rank
28,The key technique in counterfactual learning is to incorporate the propensity of obtaining a particular training example into an Empirical Risk Minimization
29,"To demonstrate the effectiveness of the general framework, we fully develop two learning-to-rank methods that optimize the Discounted Cumulative Gain"
30,
31,5
32,
33,Session 1A: Learning to Rank 1
34,
35,"SIGIR '19, July 21­25, 2019, Paris, France"
36,
37,"these convex sub-problems have the convenient property of being a Quadratic Program analogous to a generalized Ranking SVM. This allows the CCP to work by invoking an existing and fast SVM solver in each iteration until convergence. The second method we develop is Deep PropDCG, which further generalizes the approach to deep networks as non-linear ranking functions. Deep PropDCG also optimizes a bound on the DCG, and we show how the resulting optimization problem can be solved via stochastic gradient descent for any network architecture that shares neural network weights across candidate documents for the same query."
38,"In addition to the theoretical derivation and the justification, we also empirically evaluate the effectiveness of both SVM PropDCG and Deep PropDCG, especially in comparison to the existing SVM PropRank method [15]. We find that SVM PropDCG performs significantly better than SVM PropRank in terms of DCG, and that it is robust to varying degrees of bias, noise and propensity-model misspecification. In our experiments, CCP convergence was typically achieved quickly within three to five iterations. For Deep PropDCG, the results show that DCG performance is further improved compared to SVM PropDCG when using a neural network, thus demonstrating that the counterfactual learning approach can effectively train non-linear ranking functions. SVM PropDCG and Deep PropDCG are also seen to outperform LambdaRank in terms of DCG."
39,2 RELATED WORK
40,"Generative click models are a popular approach for explaining the bias in user behavior and for extracting relevance labels for learning. For example, in the cascade model [9] users are assumed to sequentially go down a ranking and click on a document, thus revealing preferences between clicked and skipped documents. Learning from these relative preferences lowers the impact of some biases [13]. Other click models"
41,The counterfactual approach uses inverse propensity score
42,"Recently, inspired by the IPS correction approach for unbiased LTR, some algorithms"
43,
44,Metric
45,
46,(rank)
47,
48,AvRank DCG P r ec @k
49,RBP-p [20]
50,
51,rank -1/log(1 + rank) -1rankk /k -(1 - p)/prank
52,
53,Table 1: Some popular linearly decomposable IR metrics that can be directly optimized by Propensity-Weighted ERM. 
54,
55,the propensity estimation step. While our focus is on directly optimizing ranking performance
56,"in the implicit feedback partial-information setting, several approaches have been proposed for the same task in the full-information supervised setting, i.e. when the relevances of all the documents in the training set are known. A common strategy is to use some smoothed version of the ranking metric for optimization, as seen in SoftRank [30] and others [6, 14, 35, 36]. In particular, SoftRank optimizes the expected performance metric over the distribution of rankings induced by smoothed scores, which come from a normal distribution centered at the query-document mean scores predicted by a neural net. This procedure is computationally expensive with an O(n3) dependence on the number of documents for a query. In contrast, our approach employs an upper bound on the performance metric, whose structure makes it amenable to the Convex Concave Procedure for efficient optimization, as well as adaptable to non-linear ranking functions via deep networks."
57,"Finally, several works exist [4, 5, 23, 30] that have proposed neural network architectures for learning-to-rank. We do not focus on a specific network architecture in this paper, but instead propose a new training criterion for learning-to-rank from implicit feedback that in principle allows unbiased network training for a large class of architectures."
58,
59,3 UNBIASED ESTIMATION OF RANK-BASED
60,IR METRICS
61,We begin by developing a counterfactual learning framework that covers the full class of linearly decomposable metrics as defined below
62,
63,"(y|xi , ri ) ="
64,
65,(rank(y|y)) · ri
66,
67,(1)
68,
69,y y
70,
71,"y denotes a ranking of results, and "
72,
73,tion that depends on the rank rank(y|y) of document y in ranking y.
74,
75,"A broad range of commonly used ranking metrics falls into this class,"
76,
77,"and Table 1 lists some of them. For instance, setting "
78,
79,gives the sum of relevant ranks metric
80,
81,"when normalized) considered in [15], and "
82,
83,=
84,
85,-1 log(1+rank)
86,
87,6
88,
89,Session 1A: Learning to Rank 1
90,
91,"SIGIR '19, July 21­25, 2019, Paris, France"
92,
93,gives the DCG metric. Note that we consider negative values wherever necessary to make the notation consistent with risk minimization.
94,"A ranking system S maps a query instance xi to a ranking y. Aggregating the losses of individual rankings over the query distribution, we can define the overall risk"
95,
96,
97,
98,R(S) =
99,
100,(2)
101,
102,A key problem when working with implicit feedback data is that
103,"we cannot assume that all relevances ri are observed. In particular, while a click"
104,"not have observed that result. From a machine learning perspective,"
105,"this implies that we are in a partial-information setting, which we"
106,"will deal with by explicitly modeling missingness in addition to relevance. Let oi  P(o|xi , y¯i , ri ) denote the 0/1 vector indicating which relevance values are revealed. While oi is not necessarily fully observed either, we can now model its distribution, which"
107,"we will find below is sufficient for unbiased learning despite the missing data. In particular, the propensity of observing ri"
108,"Using this counterfactual setup, an unbiased estimate of"
109,
110,^ I PS
111,
112,=
113,
114,(rank(y|y)) . y:oi
115,
116,(3)
117,
118,ri
119,
120,"This is an unbiased estimator since,"
121,
122,Eoi [^ I P S
123,
124,(4)
125,
126,=
127,
128,Eoi
129,
130,y:oi
131,
132,(y )=1
133,
134,(rank(y|y))·ri
135,
136,
137,
138,=
139,
140,Eoi
141,y y
142,
143,oi
144,
145,=
146,
147,Q(oi
148,
149,y y
150,
151,Q(oi
152,
153,=
154,
155,(rank(y|y)) ri
156,
157,y y
158,
159,=
160,
161,assuming Q(oi
162,sums only over the results where the feedback is observed
163,lack of a click) is due to a lack of relevance or due to missing the
164,observation
165,
166,"Using this unbiased estimate of the loss function, we get an unbiased estimate of the risk of a ranking system S"
167,
168,R^I P S
169,
170,=
171,
172,1 N
173,
174,N i =1
175,
176,y :oi
177,
178,(y )=1
179,
180,(rank(y|S(xi ))) Q(oi
181,
182,)
183,
184,.
185,
186,(5)
187,
188,ri
189,
190,Note that the propensities Q(oi
191,
192,4 UNBIASED EMPIRICAL RISK MINIMIZATION FOR LTR
193,The propensity-weighted empirical risk from Equation
194,S^ = argminS S R^I PS
195,"Under the standard uniform convergence conditions [31], the unbiasedness of the risk estimate implies consistency in the sense that given enough training data, the learning algorithm is guaranteed to find the best system in S. We have thus obtained a theoretically justified training objective for learning-to-rank with additive metrics like DCG. However, it remains to be shown that this training objective can be implemented in efficient and practical learning methods. This section shows that this is indeed possible for a generalization of Ranking SVMs and for deep networks as ranking functions."
196,Consider a dataset of n examples of the following form. For each query-result pair
197,"Given this propensity-scored click data, we would like to learn a scoring function f"
198,
199,Sf
200,
201,(6)
202,
203,Since rank(y|Sf
204,
205,rank(yi |y) - 1 =
206,
207,1f
208,
209,y Yi
210,
211,y yi
212,
213,max(1 -
214,y Yi y yi
215,
216,"Using this upper bound, we can also get a bound for any IR metric that can be expressed through a monotonically increasing weighting function "
217,
218,7
219,
220,Session 1A: Learning to Rank 1
221,
222,"SIGIR '19, July 21­25, 2019, Paris, France"
223,
224,applying the weighting function 
225,
226,(rank(yi |y))   1 + max(1 -
227,y Yi y yi
228,This provides the following continuous and subdifferentiable upper bound R^hI PinSe
229,
230,=1 n 1 n i=1 qi
231,
232,
233,
234,1+ max(1 -
235,y Yi
236,
237,(7)
238,
239,y yi
240,
241,"Focusing on the DCG metric, we show in the following how this upper bound can be optimized for linear as well as non-linear neural network scoring functions. For the general class of additive IR metrics, the optimization depends on the properties of the weighting function "
242,
243,4.1 SVM PropDCG
244,
245,"The following derives an SVM-style method, called SVM PropDCG, for learning a linear scoring function f"
246,
247,w^
248,
249,=
250,
251,"argminw,"
252,
253,1w 2
254,
255,·w
256,
257,+
258,
259,C n
260,
261,n i =1
262,
263,1 qi
264,
265,
266,
267,iy + 1
268,y Yi
269,
270,"s.t . y  Y1 \{y1} : w · [(x1, y1) -"
271,
272,...
273,
274,"y  Yn \{yn } : w · [(xn, yn ) -"
275,
276,C is a regularization parameter. The training objective optimizes the L2-regularized hinge-loss upper bound on the empirical risk estimate
277,
278,1 + max(1 -
279,y Yi y yi
280,
281,"=  1+ max(1 - w · [(xi , yi ) -"
282,
283,y Yi y yi
284,
285,y Yi
286,
287,"As shown in [15], for the special case of using the sum of relevant ranks as the metric to optimize, i.e. "
288,
289,Moving to the case of DCG as the training metric via the weight-
290,
291,ing function 
292,
293,=
294,
295,-1 log(1+r
296,
297,)
298,
299,","
300,
301,we
302,
303,get
304,
305,the
306,
307,following
308,
309,optimization
310,
311,problem for SVM PropDCG
312,
313,w^
314,
315,=
316,
317,"argminw,"
318,
319,1w 2
320,
321,·w
322,
323,-
324,
325,C n
326,
327,n i =1
328,
329,1 qi
330,
331,log(
332,
333,1 y Yi iy + 2)
334,
335,"s.t . jy  Yi \{yi } : w · [(xi , yi ) -"
336,
337,jy : iy  0.
338,
339,This optimization problem is no longer a convex Quadratic Pro-
340,
341,"gram. However, all constraints are still linear inequalities in the"
342,
343,"variables w and  , and the objective can be expressed as the dif-"
344,
345,ference of two convex functions h an . Let h(w)
346,
347,=
348,
349,1 2
350,
351,w
352,
353,2 and
354,
355,( )
356,
357,=
358,
359,C n
360,
361,n1 j=1 qi log(
362,
363,1
364,y Yi
365,
366,iy +2) .
367,
368,Then
369,
370,the
371,
372,function
373,
374,h
375,
376,is
377,
378,the
379,
380,L2
381,
382,norm of the vector w and is thus a convex function. As for the func-
383,
384,"tion , the function k"
385,
386,:x
387,
388,
389,
390,1 log x
391,
392,is convex as it is the composition
393,
394,of a
395,
396,a convex
397,
398,decreasing
399,
400,function
401,
402,(x
403,
404,
405,
406,1 x
407,
408,)
409,
410,with
411,
412,a concave function
413,
414,"(x  log x). So, since the sum of affine transformations of a convex"
415,
416,"function is convex,  is convex."
417,
418,Such an optimization problem is called a convex-concave problem1 and a local optimum can be obtained efficiently via the Convex-
419,
420,Concave Procedure
421,
422,by repeatedly approximating the second convex function with its
423,
424,first order Taylor expansion which makes the optimization problem
425,
426,convex in each iteration. The Taylor expansion is first done at some
427,
428,"chosen initial point in the feasible region, and then the solution of"
429,
430,the convex problem in a particular iteration is used as the Taylor
431,
432,approximation point for the next iteration. It can be shown that
433,
434,"this procedure converges to a local optimum [18]. Concretely, let wk ,  k be the solution in the kth iteration. Then,"
435,
436,we have the Taylor approximation
437,
438,^( ;  k ) =
439,
440,=
441,
442,( k ) - C n 1 n j=1 qi
443,
444,y Yi iy - iky y Yi iky + 2 log2 y Yi iky + 2
445,
446,"Letting qi = qi y Yi iky + 2 log2 y Yi iky + 2 , and dropping the additive constant terms from ^, we get the following convex"
447,program that needs to be solved in each CCP iteration.
448,
449,"argminw,"
450,
451,1w 2
452,
453,·w
454,
455,+
456,
457,C n
458,
459,n i =1
460,
461,1 qi
462,
463,y Yi
464,
465,iy
466,
467,"s.t . iy  Yi \{yi } : w · [(xi , yi ) -"
468,
469,iy : iy  0
470,
471,"Observe that this problem is of the same form as SVM PropRank, the Propensity Ranking SVM for the average rank metric, i.e. "
472,
473,"1More generally, the inequality constraints can also be convex-concave and not just convex"
474,
475,8
476,
477,Session 1A: Learning to Rank 1
478,
479,"SIGIR '19, July 21­25, 2019, Paris, France"
480,
481,"experiments, CCP convergence was achieved within a few itera-"
482,
483,"tions ­ as detailed in the empirical section. For other IR metrics,"
484,
485,the complexity and feasibility of the above Ranking SVM optimiza-
486,
487,tion procedure will depend on the form of the target IR metric. In
488,
489,"particular, if the rank weighting function "
490,
491,solved directly as a convex program. If 
492,
493,CCP may be employed as shown for the DCG metric above.
494,
495,An attractive theoretical property of SVM-style methods is the
496,
497,ability to switch from linear to non-linear functions via the Kernel
498,
499,"trick. In principle, kernelization can be applied to SVM PropDCG"
500,
501,"as is evident from the representer theorem [27]. Specifically, by"
502,
503,"taking the Lagrange dual, the problem can be kernelized analogous"
504,
505,to [13]. While it can be shown that the dual is convex and strong
506,
507,"duality holds, it is not clear that the optimization problem has"
508,
509,a convenient and compact form that can be efficiently solved in
510,
511,"practice. Even for the special case of the average rank metric, "
512,
513,"r , the associated kernel matrix Kiy, jy has a size equal to the total"
514,
515,number of candidates
516,
517,n i =1
518,
519,|Yi
520,
521,|
522,
523,"squared,"
524,
525,making
526,
527,the
528,
529,kernelization
530,
531,approach computationally infeasible or challenging at best. We
532,
533,therefore explore a different route for extending our approach to
534,
535,non-linear scoring functions in the following.
536,
537,4.2 Deep PropDCG
538,"Since moving to non-linear ranking functions through SVM kernelization is challenging, we instead explore deep networks as a class of non-linear scoring functions. Specifically, we replace the linear scoring function f"
539,
540,f
541,
542,(8)
543,
544,This network is generally non-linear in both the weights w and the features
545,
546,1 n
547,
548,j
549,
550,n =1
551,
552,1 qi
553,
554,
555,
556,1+ max(1 -
557,y Yi
558,
559,y yi
560,
561,"During training, we need to minimize this function with respect to"
562,
563,"the network parameters w. Unlike in the case of SVM PropDCG,"
564,
565,this function can no longer be expressed as the difference of a con-
566,
567,"vex and a concave function, since N Nw [(xi , yi )] is neither convex nor concave in general. Nevertheless, the empirical success of opti-"
568,
569,"mizing non-convex N Nw [(xi , yi )] via gradient descent to a local"
570,
571,"optimum is well documented, and we will use this approach in the"
572,
573,following. This is possible since the training objective is subdif-
574,
575,ferentiable as long as the weighting function 
576,
577,"However, the non-linearity of "
578,
579,"stochastic gradient descent methods to our training objective, since"
580,
581,the objective no longer decomposes into a sum over all
582,
583,handle this situation to arrive at an efficient stochastic-gradient
584,
585,procedure.
586,
587,"For concreteness, we again focus on the case of optimizing DCG"
588,
589,via 
590,
591,=
592,
593,-1 log(1+r
594,
595,)
596,
597,.
598,
599,In
600,
601,"particular,"
602,
603,plugging
604,
605,in
606,
607,the
608,
609,weighting
610,
611,function
612,
613,11 11 11
614,
615,+
616,
617,+ /
618,
619,
620,
621,2 6
622,
623,6
624,
625,+ 11
626,
627,Figure 1: Deep PropDCG schema for computing the loss from one query instance. The blue document is the positive
628,
629,"for DCG, we get the Deep PropDCG minimization objective"
630,
631,1 n
632,
633,n j =1
634,
635,-1 qi
636,
637,log-1
638,
639,2+ max(1-(N
640,y Yi
641,
642,Nw
643,
644,"[(xi , yi )]-N Nw"
645,
646,"[(xi , y)]),"
647,
648,0)
649,
650,y yi
651,
652,to which a regularization term can be added
653,"Since the weighting function ties together the hinge losses from pairs of documents in a non-linear way, stochastic gradient descent"
654,"While this Majorization-Minimization scheme in analogy to the SVM approach is possible also for deep networks, we chose a different approach for the reasons given below. In particular, given the success of stochastic-gradient training of deep networks in other settings, we directly perform stochastic-gradient updates at the level of query instances, not individual"
655,"For SGD at the level of query instances, a forward pass of the neural network ­ with the current weights fixed ­ must be performed on each document y in candidate set Yi in order to compute the loss from training instance"
656,
657,9
658,
659,Session 1A: Learning to Rank 1
660,
661,"SIGIR '19, July 21­25, 2019, Paris, France"
662,
663,each input instance
664,"This process is most easily understood via the network architecture illustrated in Figure 1. The scoring function N Nw [(xi , yi )] is replicated for each result in the candidate set using shared weights w. In addition there is a hinge-loss node H"
665,"Note that we have outlined a very general method which is agnostic about the size and architecture of the neural network. As a proof-of-concept, we achieved superior empirical results over a linear scoring function even with a simple two layer neural network, as seen in Section 5.8. We conjecture that DCG performance may be enhanced further with deeper, more specialized networks. Moreover, in principle, the hinge-loss nodes can be replaced with nodes that compute any other differentiable loss function that provides an upper bound on the rank without fundamental changes to the SGD algorithm."
666,5 EMPIRICAL EVALUATION
667,"While the derivation of SVM PropDCG and Deep PropDCG has provided a theoretical justification for both methods, it still remains to show whether this theoretical argument translates to improved empirical performance. To this effect, the following empirical evaluation addresses three key questions."
668,"First, we investigate whether directly optimizing DCG improves performance as compared to baseline methods, in particular, SVM PropRank as the most relevant method for unbiased LTR from implicit feedback, as well as LambdaRank, a common strong nonlinear LTR method. Comparing SVM PropDCG to SVM PropRank is particularly revealing about the importance of direct DCG optimization, since both methods are linear SVMs and employ the same software machinery for the Quadratic Programs involved, thus eliminating any confounding factors. We also experimentally analyze the CCP optimization procedure to see whether SVM PropDCG is practical and efficient. Second, we explore the robustness of the generalized counterfactual LTR approach to noisy feedback, the severity of the presentation bias, and misspecification of the propensity model. And, finally, we compare the DCG performance of Deep PropDCG with a simple two layer neural network against the linear SVM PropDCG to understand to what extent non-linear models can be trained effectively using the generalized counterfactual LTR approach."
669,5.1 Setup
670,"We conducted experiments on synthetic click data derived from two major LTR datasets, the Yahoo Learning to Rank Challenge corpus and LETOR4.0 [22]. LETOR4.0 contains two separate corpora: MQ2007 and MQ2008. Since MQ2008 is significantly smaller than"
671,
672,Dataset # Avg. train clicks # Train queries # Features
673,
674,Yahoo LETOR4.0
675,
676,"173,986 25,870"
677,
678,"20,274"
679,
680,699
681,
682,"1,484"
683,
684,46
685,
686,Table 2: Properties of the two benchmark datasets.
687,
688,Model
689,
690,Avg. DCG
691,
692,SVM Rank LambdaRank SVM PropRank SVM PropDCG Deep PropDCG
693,
694,0.6223 ± 8e-4 0.6435 ± 4e-4 0.6410± 1e-3 0.6468± 2e-3 0.6517 ± 4e-4
695,
696,0.6841 ± 2e-3 0.6915 ± 4e-3 0.7004 ± 1e-2 0.7043 ± 1e-2 0.7244 ± 4e-3
697,
698,Table 3: Performance comparison of different methods on two benchmark datasets
699,
700,"Yahoo Learning to Rank Challenge, with only 784 queries, we follow"
701,
702,"the data augmentation approach proposed in [21], combining the"
703,
704,MQ2007 and MQ2008 train sets for training and using the MQ2008
705,
706,validation and test sets for validation and testing respectively.
707,
708,Our experiment setup matches [15] for the sake of consistency
709,
710,"and reproducibility. Briefly, the training and validation click data"
711,
712,were generated from the respective full-information datasets
713,
714,relevances binarized) by simulating the position-based click model.
715,
716,"Following [15], we use propensities that decay with presented rank"
717,
718,of the result as pr =
719,
720,1 r
721,
722,. The rankings that generate the clicks are
723,
724,"given by a ""production ranker"" which was a conventional Ranking"
725,
726,SVM trained on 1 percent of the full-information training data.
727,
728,"The parameter  controls the severity of bias, with higher values"
729,
730,causing greater position bias.
731,
732,We also introduced noise into the clicks by allowing some irrele-
733,
734,"vant documents to be clicked. Specifically, an irrelevant document"
735,
736,ranked at position r by the production ranker is clicked with prob-
737,
738,"ability pr times -. When not mentioned otherwise, we used the parameters  = 1, - = 0.1 and + = 1, which is consistent with"
739,
740,the setup used in [15]. Other bias profiles are also explored in the
741,
742,following.
743,
744,Both the SVM PropRank and SVM PropDCG models were trained
745,
746,and cross-validated to pick the regularization constant C. For cross-
747,
748,"validation, we use the partial feedback data in the validation set and"
749,
750,select based on the IPS estimate of the DCG [29]. The performance
751,
752,of the models is reported on the binarized fully labeled test set
753,
754,which is never used for training or validation.
755,
756,5.2 How do SVM PropDCG and Deep PropDCG compare against baselines?
757,"We begin the empirical evaluation by comparing our counterfactual LTR methods again standard methods that follow a conventional ERM approach, namely LambdaRank and SVM-Rank. We generate synthetic click data using the procedure describe above, iterating over the training set 10 times for the Yahoo dataset and 100 times for MQ2008. This process was repeated over 6 independent runs, and we report the average performance along with the standard deviation over these runs. The regularization constant C for all SVM methods was picked based on the average DCG performance across the validation click data sampled over the 6 runs. Table 2"
758,
759,10
760,
761,Session 1A: Learning to Rank 1
762,
763,"SIGIR '19, July 21­25, 2019, Paris, France"
764,
765,0.66
766,
767,SVM PropDCG
768,
769,0.65
770,
771,SVM PropRank
772,
773,Noise-free Full-info Skyline
774,
775,0.64
776,
777,Production Ranker
778,
779,Avg. DCG of Relevant Results
780,
781,0.63
782,
783,0.62
784,
785,0.61
786,
787,0.6
788,
789,0.59
790,
791,0.58
792,
793,0.57
794,
795,0.56 1.7E3
796,
797,1.7E4 Number of Training Clicks
798,
799,1.7E5
800,
801,Figure 2: Test set Avg DCG performance for SVM PropDCG and SVM PropRank
802,
803,13.5
804,
805,SVM PropDCG
806,
807,SVM PropRank
808,
809,13
810,
811,Noise-free Full-info Skyline Production Ranker
812,
813,12.5
814,
815,Avg. Rank of Relevant Results
816,
817,12
818,
819,11.5
820,
821,11
822,
823,10.5
824,
825,10 1.7E3
826,
827,1.7E4 Number of Training Clicks
828,
829,1.7E5
830,
831,Figure 3: Test set Avg Rank performance for SVM PropDCG and SVM PropRank
832,
833,shows the average number of clicks along with other information about the training sets.
834,"As a representative for non-linear LTR methods that use a conventional ERM approach, we also conducted experiments with LambdaRank as one of the most popular tree-based rankers. We use the LightGBM implementation [16]. During training, LambdaRank optimizes Normalized Discounted Cumulative Gain"
835,"As shown in in Table 3, the counterfactual ERM approach via IPS weighting and directly optimizing for the target metric DCG yield superior results for SVM PropDCG and Deep PropDCG. The best results on both benchmarks are achieved by Deep PropDCG,"
836,
837,0.7
838,
839,SVM PropDCG
840,
841,SVM PropRank
842,
843,SVM PropDCG-5x
844,
845,SVM PropRank-5x
846,
847,0.65
848,
849,Avg. DCG of Relevant Results
850,
851,0.6
852,
853,0.55
854,
855,0.5
856,
857,0
858,
859,0.5
860,
861,1
862,
863,1.5
864,
865,2
866,
867,Severity of Presentation Bias
868,
869,Figure 4: Test set Avg DCG performance for SVM PropDCG and SVM PropRank as presentation bias becomes more severe in terms of 
870,
871,which learns a two-layer neural network ranker. We conjecture that more sophisticated network architectures can further improve performance.
872,5.3 How does ranking performance scale with training set size?
873,"Next, we explore how the test-set ranking performance changes as the learning algorithm is given more and more click data. The resulting learning curves are given in Figures 2 and 3. The click data has presentation bias with  = 1 and noise with - = 0.1. For small datasets, results are averaged over 3 draws of the click data. Both curves show the performance of the Production Ranker used to generate the click data, and the SVM skyline performance trained on the full-information training set. Ideally, rankers trained on click data should outperform the production ranker and approach the skyline performance."
874,"Figure 2 shows that the DCG performance of both SVM PropDCG and SVM PropRank. As expected, both improve with increasing amounts of click data. Moreover, SVM PropDCG performs substantially better than the baseline SVM PropRank in maximizing test set DCG."
875,"More surprisingly, Figure 3 shows both methods perform comparably in minimizing the average rank metric, with SVM PropDCG slightly better at smaller amounts of data and SVM PropRank better at larger amounts. We conjecture that this is due the variancelimiting effect of the DCG weights in SVM PropDCG when substituting the propensity weights qi with the new constants qi in the SVM PropDCG CCP iterations. This serves as implicit variance control in the IPS estimator similar to clipping [15] by preventing propensity weights from getting too big. Since variance dominates estimation error at small amounts of data and bias dominates at large amounts, our conjecture is consistent with the observed trend."
876,5.4 How much presentation bias can be tolerated?
877,We now vary the severity of the presentation bias via  ­ higher values leading to click propensities more skewed to the top positions
878,
879,11
880,
881,Session 1A: Learning to Rank 1
882,
883,"SIGIR '19, July 21­25, 2019, Paris, France"
884,
885,0.7
886,
887,SVM PropDCG
888,
889,SVM PropRank
890,
891,0.65
892,
893,Avg. DCG of Relevant Results
894,
895,0.6
896,
897,0.55
898,
899,0.5 0
900,
901,0.05
902,
903,0.1
904,
905,0.15
906,
907,0.2
908,
909,0.25
910,
911,0.3
912,
913,Noise Level
914,
915,Figure 5: Test set Avg DCG performance for SVM PropDCG and SVM PropRank as the noise level increases in terms of 
916,
917,0.7
918,
919,SVM PropDCG
920,
921,SVM PropRank
922,
923,0.65
924,
925,Avg. DCG of Relevant Results
926,
927,0.6
928,
929,0.55
930,
931,0.5
932,
933,0
934,
935,0.5
936,
937,1
938,
939,1.5
940,
941,2
942,
943,Assumed Propensity Model
944,
945,Figure 6: Test set Avg DCG performance for SVM PropDCG and SVM PropRank as propensities are misspecified
946,
947,­ to understand its impact on the learning algorithm. Figure 4 shows the impact on DCG performance for both methods. We report performance for two training set sizes that differ by a factor of 5
948,5.5 How robust is SVM PropDCG to noise?
949,"Figure 5 shows the impact of noise on DCG performance, as noise levels in terms of - increase from 0 to 0.3. The latter results in click data where 59.8% of all clicks are on irrelevant documents. As expected, performance degrades for both methods as noise in-"
950,
951,"creases. However, there is no evidence that SVM PropDCG is less robust to noise than the baseline SVM PropRank."
952,5.6 How robust is SVM PropDCG to misspecified propensities?
953,"So far all experiments have had access to the true propensities that generated the synthetic click data. However, in real-world settings propensities need to be estimated and are necessarily subject to modeling assumptions. So, we evaluate the robustness of the learning algorithm to propensity misspecification."
954,"Figure 6 shows the performance of SVM PropDCG and SVM PropRank when the training data is generated with  = 1, but the propensities used in learning are misspecified according to the  on the x-axis. The results show that SVM PropDCG is at least as robust to misspecified propensities as SVM PropRank. Both methods degrade considerably in the high bias regime when small propensities are underestimated ­ this is often tackled by clipping [15]. It is worth noting that SVM PropDCG performs better than SVM PropRank when misspecification leads to propensities that are underestimated, further strengthening the implicit variance control conjecture for SVM PropDCG discussed above."
955,5.7 How well does the CCP converge?
956,"Next, we consider the computational efficiency of employing the CCP optimization procedure for training SVM PropDCG. Recall that the SVM PropDCG objective is an upper bound on the regularized"
957,"In Figure 7, optimization progress vs number of iterations as indicated by the change in objective value as well as the training DCG SNIPS estimate [29] is shown for 17K training clicks and the full range of regularization parameter C used in validation. The figure shows that the objective value usually converges in 3-5 iterations, a phenomenon observed in our experiments for other amounts of training data as well. In fact, the convergence tends to take slightly fewer iterations for larger amounts of data. The figure also shows that progress in objective is well-tracked with progress in the training DCG estimate, which suggests that the objective is a suitable upper bound for DCG optimization."
958,"It is worth noting that restarting the optimizer across multiple CCP iterations can be substantially less time consuming than the initial solution that SVM PropRank computes. Since only the coefficients of the Quadratic Program change, the data does not need to be reloaded and the optimizer can be warm-started for quicker convergence in subsequent CCP iterations."
959,5.8 When does the non-linear model improve over the linear model?
960,"We have seen that SVM PropDCG optimizes DCG better than SVM PropRank, and that it is a robust method across a wide range of biases and noise levels. Now we explore if performance can be improved further by introducing non-linearity via neural networks. Since the point of this paper is not a specific deep architecture but"
961,
962,12
963,
964,Session 1A: Learning to Rank 1
965,
966,"SIGIR '19, July 21­25, 2019, Paris, France"
967,
968,"Figure 7: Optimization progress with respect to the number of CCP iterations. The objective value is shown in the left plots, and the training set DCG estimate on the right plots. Each plot corresponds to a particular value of regularization constant C"
969,
970,0.66 SVM PropDCG
971,0.65 Deep PropDCG
972,
973,Avg. DCG of Relevant Results
974,
975,0.64
976,
977,0.63
978,
979,0.62
980,
981,0.61
982,
983,0.6
984,
985,0.59
986,
987,0.58
988,
989,0.57
990,
991,0.56 1.7E3
992,
993,1.7E4 Number of Training Clicks
994,
995,1.7E5
996,
997,Figure 8: Test set Avg DCG performance for SVM PropDCG and Deep PropDCG
998,
999,"a novel training objective, we used a simple two-layer neural network with 200 hidden units and sigmoid activation. We expect that specialized deep architectures will further improve performance."
1000,"Figure 8 shows that Deep PropDCG achieves improved DCG compared to the linear SVM PropDCG given enough training data. For small amounts of training data, the linear model performs better, which is to be expected given the greater robustness to overfitting of linear models."
1001,"We also expect improved performance from tuning the hyperparameters of Deep PropDCG. In fact, we only used default parameters for Deep PropDCG, while we optimized the hyperparameters of SVM PropDCG on the validation set. In particular, Adam was used for stochastic gradient descent with weight decay regularizer at 10-6, minibatch size of 1000 documents and 750 epochs. The learning rate began at 10-6 for the first 300 epochs, dropping by one order of magnitude in the next 200 epochs and another order of"
1002,
1003,magnitude in the remaining epochs. We did not try any other hyperparameter settings and these settings were held fixed across varying amounts of training data.
1004,6 CONCLUSION
1005,"In this paper, we proposed a counterfactual learning-to-rank framework that is broad enough to cover a broad class of additive IR metrics as well as non-linear deep network models. Based on the generalized framework, we developed the SVM PropDCG and Deep PropDCG methods that optimize DCG via the Convex-Concave Procedure"
1006,"There are many directions for future work. First, it is open for which other ranking metrics it is possible to develop efficient and effective methods using the generalized counterfactual framework. Second, the general counterfactual learning approach may also provide unbiased learning objectives for other settings beyond ranking, like full-page optimization and browsing-based retrieval tasks. Finally, it is an open question whether non-differentiable"
1007,7 ACKNOWLEDGMENTS
1008,"This research was supported in part by NSF Awards IIS-1615706 and IIS-1513692, an Amazon Research Award, and the Criteo Faculty Research Award program. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors."
1009,
1010,13
1011,
1012,Session 1A: Learning to Rank 1
1013,
1014,"SIGIR '19, July 21­25, 2019, Paris, France"
1015,
1016,REFERENCES
1017,"[1] Aman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, and Thorsten Joachims. 2019. Estimating Position Bias without Intrusive Interventions. In International Conference on Web Search and Data Mining"
1018,"[2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W. Bruce Croft. 2018. Unbiased Learning to Rank with Unbiased Propensity Estimation. In The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval"
1019,"[3] Alexey Borisov, Ilya Markov, Maarten de Rijke, and Pavel Serdyukov. 2016. A Neural Click Model for Web Search. In Proceedings of the 25th International Conference on World Wide Web"
1020,"[4] Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to Rank Using Gradient Descent. In Proceedings of the 22Nd International Conference on Machine Learning"
1021,"[5] Christopher J Burges, Robert Ragno, and Quoc V Le. 2007. Learning to rank with nonsmooth cost functions. In Advances in Neural Information Processing Systems"
1022,"[6] Olivier Chapelle and Mingrui Wu. 2010. Gradient Descent Optimization of Smoothed Information Retrieval Metrics. Information Retrieval 13, 3"
1023,[7] Olivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In International Conference on World Wide Web
1024,"[8] Aleksandr Chuklin, Ilya Markov, and Maarten de Rijke. 2015. Click Models for Web Search. Morgan & Claypool Publishers."
1025,"[9] Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An Experimental Comparison of Click Position-bias Models. In International Conference on Web Search and Data Mining"
1026,"[10] Zhichong Fang, A. Agarwal, and T. Joachims. 2019. Intervention Harvesting for Context-Dependent Examination-Bias Estimation. In ACM Conference on Research and Development in Information Retrieval"
1027,"[11] D. G. Horvitz and D. J. Thompson. 1952. A Generalization of Sampling Without Replacement from a Finite Universe. J. Amer. Statist. Assoc. 47, 260"
1028,"[12] Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2018. A Novel Algorithm for Unbiased Learning to Rank."
1029,[13] T. Joachims. 2002. Optimizing Search Engines Using Clickthrough Data. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining
1030,"[14] T. Joachims, T. Finley, and Chun-Nam Yu. 2009. Cutting-Plane Training of Structural SVMs. Machine Learning 77, 1"
1031,"[15] Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In ACM International Conference on Web Search and Data Mining"
1032,"[16] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Advances in Neural Information Processing Systems"
1033,"[17] Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. 2011. Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms. In International Conference on Web Search and Data Mining"
1034,
1035,297­306. [18] Thomas Lipp and Stephen Boyd. 2016. Variations and extension of the convex­
1036,"concave procedure. Optimization and Engineering 17, 2"
1037,"Trends in Information Retrieval 3, 3"
1038,of Retrieval Effectiveness. ACM Transactions on Information Systems
1039,
1040,14
1041,
1042,
