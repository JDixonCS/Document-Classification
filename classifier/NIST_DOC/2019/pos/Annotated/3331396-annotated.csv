,sentence,label,data
,,,
0,Demonstration Papers 3: Applications,null,null
,,,
1,,null,null
,,,
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
3,,null,null
,,,
4,An Experimentation Platform for Precision Medicine,null,null
,,,
5,,null,null
,,,
6,Vincent Nguyen,null,null
,,,
7,vincent.nguyen@anu.edu.au CSIRO Data61 & Australian National University,null,null
,,,
8,"Canberra, ACT, Australia",null,null
,,,
9,ABSTRACT,null,null
,,,
10,"Precision medicine--where data from patients, their genes, their lifestyles and the available treatments and their combination are taken into account for finding a suitable treatment--requires searching the biomedical literature and other resources such as clinical trials with the patients' information. The retrieved information could then be used in curating data for clinicians for decisionmaking. We present information retrieval researchers with an online system which enables experimentation in search for precision medicine within the framework provided by the TREC Precision Medicine",Y,TREC
,,,
11,CCS CONCEPTS,null,null
,,,
12,· Information systems  Learning-to-rank; Query reformulation; Specialized information retrieval;,null,null
,,,
13,KEYWORDS,null,null
,,,
14,"Health informatics, Literature search, Domain-Specific Search",null,null
,,,
15,"ACM Reference Format: Vincent Nguyen, Sarvnaz Karimi, and Brian Jin. 2019. An Experimentation Platform for Precision Medicine. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",null,null
,,,
16,1 INTRODUCTION,null,null
,,,
17,"Improving the treatment success of cancer patients relies on providing the right information to practising clinicians. While some of this information is published in the biomedical literature, searching among over 27 million MEDLINE abstracts, with new articles added each minute, makes it difficult if not impossible to know all the latest treatment options. Similarly, it is not straightforward to find clinical trials that a patient is eligible for. The goal of the TREC Precision Medicine",Y,TREC
,,,
18,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/3331184.3331396",null,null
,,,
19,,null,null
,,,
20,Sarvnaz Karimi Brian Jin,null,null
,,,
21,firstname.lastname@csiro.au CSIRO Data61,null,null
,,,
22,"Sydney, NSW, Australia",null,null
,,,
23,,null,null
,,,
24,disease,null,null
,,,
25,,null,null
,,,
26,Acute lymphoblastic leukemia,null,null
,,,
27,,null,null
,,,
28,gene,null,null
,,,
29,,null,null
,,,
30,"ABL1, PTPN11",null,null
,,,
31,,null,null
,,,
32,demographic 12-year-old male,null,null
,,,
33,,null,null
,,,
34,Figure 1: A sample topic from TREC PM 2018,null,null
,,,
35,,null,null
,,,
36,their corresponding clinical trials1 as well as treatment options in MEDLINE and abstracts from The American Association for Cancer Research,null,null
,,,
37,"We provide a platform for researchers to experiment with some of the most popular query expansion and ranking methods for the PM track. We also implement learning-to-rank using the latest deep learning-based methods in text classification, including a language representation model called Bidirectional Encoder Representations from Transformers",null,null
,,,
38,2 RELATED SYSTEMS,null,null
,,,
39,"Literature on search for precision medicine is limited, with most relevant studies reported by the TREC PM 2017 and 2018 participants [13, 14]. These reports however often are work in progress and lack enough details on the methods and implementation details, making it difficult to reproduce the results.",null,null
,,,
40,There are other related systems in place. One is proposed by Koopman et al. [9] with a task-based search engine to assist in clinical search. Another platform is EvALL [1] where the output of different systems can be compared in the same setting. An information retrieval experimentation platform that uses Domain Specific Language,null,null
,,,
41,"Marshall et al. [11] release an open-source web-based system, RobotReviewer, which takes input biomedical articles or clinical trials and processes them for extraction and synthesis of evidence for the practice of Evidence-Based Medicine. We see our system",null,null
,,,
42,1 https://clinicaltrials.gov/ 2 https://www.vizie.csiro.au/trec-eval,null,null
,,,
43,,null,null
,,,
44,1357,null,null
,,,
45,,null,null
,,,
46,Demonstration Papers 3: Applications,null,null
,,,
47,,null,null
,,,
48,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
49,,null,null
,,,
50,as a complementary first step before RobotReviewer to find the articles to be processed for evidence.,null,null
,,,
51,3 INDEXING,null,null
,,,
52,"Our system provides the index of three collections: MEDLINE abstracts, AACR and ASCO abstracts, and clinical trials that were part of the TREC PM supplied data collections. All documents in the MEDLINE collection are stemmed with stopwords removed automatically at index time by Solr3. Medline abstracts documents have the following fields indexed: pmid",Y,TREC
,,,
53,4 QUERY PROCESSING TECHNIQUES,null,null
,,,
54,"We provide query expansion options as shown on the left-handside of Figure 2. Apart from standard query expansion techniques, such as pseudo-relevance feedback, expansion with domain-specific terminology from Unified Medical Language System",null,null
,,,
55,Gene Expansion. Gene expansion uses genes identified by Metamap [2] to expand the topics using one of the four available options:,null,null
,,,
56,Users can also use a combination of these options.,null,null
,,,
57,Disease Expansion. Disease expansion relies on Metamap to identify the disease names. They can then be expanded using one the three options:,null,null
,,,
58,"· Metamap filtering, which uses UMLS concepts restricted to the semantics types of: Disease or Syndrome, Sign or Symptom, Pathologic Function, Anatomical Abnormality,",null,null
,,,
59,3Solr version 6.6.0 http://lucene.apache.org/solr/ 4 https://pypi.python.org/pypi/wikipedia 5http://www.geneontology.org/,null,null
,,,
60,,null,null
,,,
61,"Clinical Drug, Clinical Attribute and Neoplastic Process. Using these semantics types, we extract UMLS concepts using MetamapLite [3] which we denote as TM , and extract terms using the Wikipedia API which we denote as TW . We use the set intersection, TM  TW , in order to produce a final set of expansion terms. · Semantic variation, in which disease mentions are expanded by finding semantically relevant words",null,null
,,,
62,"Demographic Attribute Expansion and Filtering. Clinical trials documents present demographic attributes transparently. As such, we are able to normalise demographic attributes found within queries to exact matches found within the clinical trial corpus. If Normalize demographics is chosen, queries containing strings indicating a child",null,null
,,,
63,-gender:male AND maximum_age:[0 TO 5110] This operation excludes documents that are either for males or individuals over the age of 15,null,null
,,,
64,5 RANKING MODELS,null,null
,,,
65,"We provide BM25 and language modelling ranking models from Apache Solr. For the case of BM25, we provide the option of tuning the b and k1 parameters. Language model uses Dirichlet similarity.",null,null
,,,
66,Learning-to-rank. We have four different implementations of learning-to-rank,null,null
,,,
67,"(1) SVM with Word Embedding: We use word embeddings created by Chiu et al. [4] from PubMed, where they released their best hyper-parameters that are empirically identified. Mean word embeddings are used to represent documents.",null,null
,,,
68,"(2) SVM with LETOR [12] features: Features are TF-IDF of each term in the query in each of the document facets, including title, abstract, and the full text",null,null
,,,
69,(3) ULMFit [7]: We use a language-model encoder for the generic WikiText-103 model and then fine-tune a Recurrent Neural Network,null,null
,,,
70,(4) BERT [5]: The pre-trained bert-base-uncased model is finetuned with default BertConfig settings with a BERT classifier and a scaled loss function based on label frequency,null,null
,,,
71,6 https://radimrehurek.com/gensim/models/word2vec.html,null,null
,,,
72,,null,null
,,,
73,1358,null,null
,,,
74,,null,null
,,,
75,Demonstration Papers 3: Applications,null,null
,,,
76,,null,null
,,,
77,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
78,,null,null
,,,
79,"frequent label loss is scaled down, while less frequent label loss is scaled up).7",null,null
,,,
80,Training for the LTR models is based on the training source that the users select,null,null
,,,
81,,null,null
,,,
82,6 RE-RANKING USING CITATIONS,null,null
,,,
83,"Clinical trials documents often cite MEDLINE articles. We implement a heuristic in order to utilise these relationships between clinical trial and MEDLINE articles. Given a query, if a MEDLINE article is referenced in a highly relevant or high scoring clinical trial, it receives a small boost based on the rank of that clinical trial document. We also applied the same boost such that clinical trials received a boost to their scores if they are linked to a high scoring MEDLINE document. These boosts were small and decreased exponentially with reciprocal rank:",null,null
,,,
84,,null,null
,,,
85,Sd = Sd + b(Rd ),null,null
,,,
86,,null,null
,,,
87,-1,null,null
,,,
88,,null,null
,,,
89,"where Sd is the score of a document, and b is a boosting function that uses reciprocal ranking of a matched document in the second",null,null
,,,
90,"or paired document set,",null,null
,,,
91,,null,null
,,,
92,b(Rd ),null,null
,,,
93,,null,null
,,,
94,=,null,null
,,,
95,,null,null
,,,
96,1 exp(Rd ),null,null
,,,
97,,null,null
,,,
98,-2,null,null
,,,
99,,null,null
,,,
100,Merging search results using federated search. A user can choose to only search on clinical trials or only literature,null,null
,,,
101,"However, a limitation of GDS is that it can only be applied to one field at a time or the entire document at once, which is undesirable as the most important parts of the document are limited to only a few facets such as title, abstract and article keywords for MEDLINE documents, brief/official title, brief summary, detailed description and abstract for clinical trial and title and abstract for AACR & ASCO articles. We hence apply GDS to each field if they exist. Otherwise, we take the rank score detailed by the equation below as fallback:",null,null
,,,
102,,null,null
,,,
103,RS,null,null
,,,
104,,null,null
,,,
105,f,null,null
,,,
106,,null,null
,,,
107,),null,null
,,,
108,,null,null
,,,
109,=,null,null
,,,
110,,null,null
,,,
111,1-,null,null
,,,
112,,null,null
,,,
113,r ankd |D|  10,null,null
,,,
114,,null,null
,,,
115,-3,null,null
,,,
116,,null,null
,,,
117,"where RS is the rank score function, d is a document in all retrieved",null,null
,,,
118,,null,null
,,,
119,"documents D, f is the facet that doesn't exist on the current docu-",null,null
,,,
120,,null,null
,,,
121,ment and rankd denotes the rank of the document.,null,null
,,,
122,,null,null
,,,
123,7We use and modify the code provided in: https://github.com/huggingface/ pytorch- pretrained- BERT.,null,null
,,,
124,,null,null
,,,
125,"The facets for each document are normalized using weights; this ensures that when comparing collections with a different number of fields, for example, AACR & ASCO which do not have a keyword field while MEDLINE does, we are able to fairly compare between collections.",null,null
,,,
126,"Alternatively, we use another more simple merging strategy called Randomized Round Robin",null,null
,,,
127,7 EVALUATION METRICS,null,null
,,,
128,"The system generates the results offline and creates an email notification. The execution time depends on the load of the system as well as what combination of the methods have been selected. For simple runs which use standard ranking models, it can be on the order of minutes. The retrieved results are evaluated using TREC standard scripts",Y,TREC
,,,
129,8 DEMONSTRATION SYSTEM,null,null
,,,
130,A screenshot of the experimental design page is shown in Figure 2. It shows a setting where a list of topics can be chosen as well as some of the implemented techniques.,null,null
,,,
131,"At this point in time, the learning-to-rank models are fixed to our trained models. However, these will get expanded with the options of selecting between the features",null,null
,,,
132,9 ACKNOWLEDGEMENT,null,null
,,,
133,Authors would like to acknowledge the contributions of Maciej Rybinski,null,null
,,,
134,REFERENCES,null,null
,,,
135,"[1] E. Amigó, J. Carrillo-de Albornoz, M. Almagro-Cádiz, J. Gonzalo, J. RodríguezVidal, and F. Verdejo. 2017. EvALL: Open Access Evaluation for Information Access Systems. In SIGIR. 1301­1304.",null,null
,,,
136,"[2] A. Aronson and F. Lang. 2010. An overview of MetaMap: Historical perspective and recent advances. Journal of the American Medical Informatics Association 17, 3",null,null
,,,
137,"[3] A. Aronson, W. Rogers, and D. Demner-Fushman. 2017. MetaMap Lite: an evaluation of a new Java implementation of MetaMap. Journal of the American Medical Informatics Association 24, 4",null,null
,,,
138,,null,null
,,,
139,1359,null,null
,,,
140,,null,null
,,,
141,Demonstration Papers 3: Applications,null,null
,,,
142,,null,null
,,,
143,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
144,,null,null
,,,
145,Figure 2: System interface showing some of the options provided for the users.,null,null
,,,
146,,null,null
,,,
147,"[4] B. Chiu, G. Crichton, A. Korhonen, and S. Pyysalo. 2016. How to Train good Word Embeddings for Biomedical NLP. In ACL Workshop on Biomedical Natural Language Processing. 166­174.",null,null
,,,
148,"[5] J. Devlin, M. Chang, K. Lee, and K. Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. CoRR abs/1810.04805",null,null
,,,
149,"[6] T. Goodwin, M. Skinner, and S. Harabagiu. 2017. UTD HLTRI at TREC 2017: Precision Medicine Track. In TREC. Gaithersburg, MD.",null,null
,,,
150,"[7] J. Howard and S. Ruder. 2018. Universal Language Model Fine-tuning for Text Classification. In The 56th Annual Meeting of the Association for Computational Linguistics. Melbourne, Australia, 328­339.",null,null
,,,
151,"[8] S. Karimi, V. Nguyen, F. Scholer, B. Jin, and S. Falamaki. 2018. A2A: Benchmark Your Clinical Decision Support Search. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. Ann Arbor, MI, 1277­1280.",null,null
,,,
152,"[9] B. Koopman, G. Zuccon, and J. Russell. 2017. A Task-oriented Search Engine for Evidence-based Medicine. In SIGIR. Shinjuku, Tokyo, Japan, 1329­1332.",null,null
,,,
153,"[10] P. Li, P. Thomas, and D. Hawking. 2013. Merging Algorithms for Enterprise Search. In ADCS. 42­49.",null,null
,,,
154,,null,null
,,,
155,"[11] I. Marshall, J. Kuiper, E. Banner, and B. Wallace. 2017. ""Automating Biomedical Evidence Synthesis: RobotReviewer. In ACL. Vancouver, Canada, 7­12.",null,null
,,,
156,"[12] T. Qin, T-Y Liu, J. Xu, and H. Li. 2010. LETOR: A Benchmark Collection for Research on Learning to Rank for Information Retrieval. Information Retrieval 13, 4",null,null
,,,
157,"[13] K. Roberts, D. Demner-Fushman, E. Voorhees, W. Hersh, S. Bedrick, and A. Lazar. 2018. Overview of the TREC 2018 Precision Medicine Track. In TREC. Gaithersburg, MD.",null,null
,,,
158,"[14] K. Roberts, D. Demner-Fushman, E. Voorhees, W. Hersh, S. Bedrick, A. Lazar, and S. Pant. 2017. Overview of the TREC 2017 Precision Medicine Track. In TREC. Gaithersburg, MD.",null,null
,,,
159,"[15] H. Scells, D. Locke, and G. Zuccon. 2018. An Information Retrieval Experiment Framework for Domain Specific Applications. In SIGIR. Ann Arbor, MI, 1281­ 1284.",null,null
,,,
160,[16] E. Yilmaz and J.A. Aslam. 2006. Estimating Average Precision with Incomplete and Imperfect Judgments. In CIKM. 102­111.,null,null
,,,
161,"[17] X. Zhou, X. Chen, J. Song, G. Zhao, and J. Wu. 2018. Team Cat-Garfield at TREC 2018 Precision Medicine Track. In TREC. Gaithersburg, MD.",null,null
,,,
162,,null,null
,,,
163,1360,null,null
,,,
164,,null,null
,,,
165,,null,null
