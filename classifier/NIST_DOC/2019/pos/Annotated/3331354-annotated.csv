,sentence,label,data
,,,
0,Short Research Papers 3B: Recommendation and Evaluation,null,null
,,,
1,,null,null
,,,
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
3,,null,null
,,,
4,Dynamic Sampling Meets Pooling,null,null
,,,
5,,null,null
,,,
6,"Gordon V. Cormack, Haotian Zhang, Nimesh Ghelani, Mustafa Abualsaud, Mark D. Smucker, Maura R. Grossman, Shahin Rahbariasl, and Amira Ghenai",null,null
,,,
7,"University of Waterloo, Ontario, Canada",null,null
,,,
8,,null,null
,,,
9,ABSTRACT,null,null
,,,
10,A team of six assessors used Dynamic Sampling,null,null
,,,
11,"ACM Reference Format: Gordon V. Cormack, Haotian Zhang, Nimesh Ghelani, Mustafa Abualsaud, Mark D. Smucker, Maura R. Grossman, Shahin Rahbariasl, and Amira Ghenai. 2019. Dynamic Sampling Meets Pooling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",null,null
,,,
12,1 INTRODUCTION,null,null
,,,
13,This work evaluates the first in situ application of Dynamic Sampling,null,null
,,,
14,"In preparation for the TREC 2018 Common Core Track [2], we built a test collection by employing a combination of Continuous Active Learning",Y,TREC
,,,
15,"Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). SIGIR '19, July 21­25, 2019, Paris, France © 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-6172-9/19/07. https://doi.org/10.1145/3331184.3331354",null,null
,,,
16,,null,null
,,,
17,"again assessed, along with 8,902 documents identified by depth-10 pooling, and 1,010 identified by move-to-front",null,null
,,,
18,"A primary concern was the speed with which we could render the assessments necessary to form a viable test collection, so as to conform to our particular resource constraints, as well as those of anyone else who might wish to employ our method. After an exploratory phase in which one author used a rudimentary CAL tool and search engine to find as many relevant documents as possible in about 13 minutes per topic, a separate team of five of the authors spent about 45 minutes per topic using HiCAL 1 [1, 12], which we adapted for this purpose, to conduct further searches and to draw a dynamic stratified sample of 300 additional documents per topic for assessment. In total, about 50 person-hours",null,null
,,,
19,"To evaluate the outcome of our DS effort, we consider the following five questions:",null,null
,,,
20,"· How nearly all of the relevant documents were included in the universe of documents identified using DS, from which the sample was drawn?",null,null
,,,
21,"· What is the accuracy of MAP estimates derived from the sample, measured by the average difference",null,null
,,,
22,"· What is the accuracy with which systems are ranked according to MAP estimates, measured by the rank correlation",null,null
,,,
23,· How do these outcomes compare to the NIST depth-10 and MTF pooling efforts?,null,null
,,,
24,"· How might our or NIST's efforts have yielded better outcomes, with a different allocation of assessment effort?",null,null
,,,
25,"Overall, our results indicate that assessment budgets would be better spent if allocated to DS rather than to pooling.",null,null
,,,
26,2 SPEEDY ASSESSMENT,null,null
,,,
27,"In the first of three distinct assessment phases, one of the authors used CAL, as implemented in the TREC 2015 Total Recall Track Baseline Implementation",Y,TREC
,,,
28,1See https://github.com/hical. 2See http://cormack.uwaterloo.ca/trecvm/. 3See http://stefan.buettcher.org/cs/wumpus/index.html.,null,null
,,,
29,,null,null
,,,
30,1217,null,null
,,,
31,,null,null
,,,
32,Short Research Papers 3B: Recommendation and Evaluation,null,null
,,,
33,,null,null
,,,
34,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
35,,null,null
,,,
36,Method: DS NIST Depth-10 Depth-10 + MTF,null,null
,,,
37,,null,null
,,,
38,Avg. Coverage: 0.88 0.82 0.47,null,null
,,,
39,,null,null
,,,
40,0.49,null,null
,,,
41,,null,null
,,,
42,Min. Coverage: 0.58 0.48 0.11,null,null
,,,
43,,null,null
,,,
44,0.13,null,null
,,,
45,,null,null
,,,
46,Max. Coverage: 1.00 1.00 1.00,null,null
,,,
47,,null,null
,,,
48,1,null,null
,,,
49,,null,null
,,,
50,Table 1: Coverage of document-selection methods.,null,null
,,,
51,,null,null
,,,
52,documents for 20 topics. Phase 1 consumed a total of 11.1 hours,null,null
,,,
53,"The second and third phases were conducted by a team of five different authors, who used the HiCAL system to render assessments for 10 topics each. Phase 2 involved the use of HiCAL's search and full-document-display mode to find more documents relevant to the 20 topics for which the first phase had found fewer than 10. Phase 2 was allocated 30 minutes of assessment time for each of these 20 topics",null,null
,,,
54,"Phase 3 involved the use of HiCAL's CAL and paragraph-onlydisplay mode to present paragraphs, excerpted from potentially relevant documents, for assessment. HiCAL was modified to present excerpts from only a sample of documents, selected using DS with strategy D25 [3]",null,null
,,,
55,3 COVERAGE,null,null
,,,
56,"We define coverage to be the fraction of all relevant documents in the DS universe. In other words, coverage is the recall of the DS effort, before sampling and before relevance assessment. In order to estimate coverage of our assessment strategy compared to others, it is necessary to estimate the number of relevant documents for each topic. To this end, DS provides an unbiased statistical estimate of the number of relevant documents in the universe it identifies as the sample space from which its sample is drawn. Here, the size of the universe was 39,214 documents, from which a sample of 19,161 was drawn. Pooling and MTF independently identified 1,305 documents--of which 503 were relevant--from the DS universe, which were counted directly and removed from the sample space. Pooling and MTF identified 404 additional relevant documents outside the universe. Overall, our best estimate indicates that there are 5,457 relevant documents in the corpus.",null,null
,,,
57,"Table 1 shows the average, minimum, and maximum coverage over 50 topics achieved by the construction methods under consideration. The DS universe covers 88% of all relevant documents, on average, and 58%, in the worst case, for this collection. The NIST qrels have lower coverage because, although they include more assessments, they do not constitute a statistical sample and cannot be extrapolated to a larger population. The depth-10 pool, whether augmented or not by MTF, has substantially inferior recall.",null,null
,,,
58,"4Due to a system misconfiguration, assessors spent several additional minutes in a false start for phase 3, the results of which were discarded.",null,null
,,,
59,,null,null
,,,
60,4 ACCURACY,null,null
,,,
61,,null,null
,,,
62,Figure 1 shows scatterplots and summary statistics comparing the MAP estimates afforded by DS using the xinfAP estimator5 [11],null,null
,,,
63,,null,null
,,,
64,"to the official TREC results, for each of the runs submitted to the",null,null
,,,
65,,null,null
,,,
66,"TREC 2018 Common Core Track. Points denoted ""M"" represent",null,null
,,,
67,,null,null
,,,
68,"so-called manual runs; points denoted ""R"" indicate runs that relied",null,null
,,,
69,,null,null
,,,
70,on legacy relevance assessments for the same topics but a different,null,null
,,,
71,,null,null
,,,
72,"corpus; points denoted "" "" indicate fully automatic runs. We see",null,null
,,,
73,,null,null
,,,
74,that our DS assessments yield low bias6,null,null
,,,
75,,null,null
,,,
76,(RMSE,null,null
,,,
77,,null,null
,,,
78,=,null,null
,,,
79,,null,null
,,,
80,"0.02),",null,null
,,,
81,,null,null
,,,
82,with,null,null
,,,
83,,null,null
,,,
84,negligible,null,null
,,,
85,,null,null
,,,
86,variance,null,null
,,,
87,,null,null
,,,
88,( 2,null,null
,,,
89,,null,null
,,,
90,=,null,null
,,,
91,,null,null
,,,
92,2,null,null
,,,
93,b,null,null
,,,
94,,null,null
,,,
95,-,null,null
,,,
96,,null,null
,,,
97,RMSE2,null,null
,,,
98,,null,null
,,,
99,,null,null
,,,
100,,null,null
,,,
101,0).,null,null
,,,
102,,null,null
,,,
103,= 0.88 and AP = 0.83 correlation scores [10] are typical of those,null,null
,,,
104,,null,null
,,,
105,arising from inter-assessor disagreement.,null,null
,,,
106,,null,null
,,,
107,The top right panel shows the result of substituting NIST as-,null,null
,,,
108,,null,null
,,,
109,"sessments in place of our own, to eliminate inter-assessor disagreement.  = 0.95 and AP = 0.92 are substantially higher, while bias essentially vanishes, exposing a small variance as evidenced by RMSE = 0.01.",null,null
,,,
110,,null,null
,,,
111,"The bottom two panels show results for depth-10 pooling, and",null,null
,,,
112,,null,null
,,,
113,depth-10 pooling augmented by MTF. Rank correlations are slightly,null,null
,,,
114,,null,null
,,,
115,"lower, while bias and error are substantially higher.",null,null
,,,
116,,null,null
,,,
117,5 STATISTICAL GROUND TRUTH,null,null
,,,
118,The method we employed to estimate coverage,null,null
,,,
119,"We can evaluate the extent to which the statistical and official ground truths agree. The left panel of Figure 2 shows strong but imperfect agreement. The right panel of Figure 2 and the top-right panel of Figure 1, evaluate accuracy of the same NIST-assessed DS sample, according to the statistical and official ground truth, respectively. The statistical ground truth indicates much higher accuracy. If the statistical ground truth is indeed the gold standard, this result suggests that the dynamic sample alone--without any documents discovered by pooling or MTF--may also yield ground truth more accurate than the official ground truth.",null,null
,,,
120,,null,null
,,,
121,6 INCREASING COVERAGE,null,null
,,,
122,"We used a fixed budget of 300 assessments for the third phase of our assessments, which had previously been shown to achieve good results for the D25 sampling strategy [3]",null,null
,,,
123,"Figure 3 shows coverage for each of the 50 topics, as well as the average, as a function of the total number of assessments for the three phases. We see that the slope for most of the curves is near-zero when the budget is exhausted. But for several of the topics--notably those with coverage of less than about 80%--the slope is noticeably positive, indicating that, had the budget been extended",null,null
,,,
124,5,null,null
,,,
125,trec.nist.gov/data/clinical/sample_eval.pl 6The arithmetic mean of error.,null,null
,,,
126,,null,null
,,,
127,1218,null,null
,,,
128,,null,null
,,,
129,Short Research Papers 3B: Recommendation and Evaluation,null,null
,,,
130,,null,null
,,,
131,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
132,,null,null
,,,
133,0.5,null,null
,,,
134,,null,null
,,,
135,0.5,null,null
,,,
136,,null,null
,,,
137,q Automatic R Feedback M Manual,null,null
,,,
138,,null,null
,,,
139,q Automatic R Feedback M Manual,null,null
,,,
140,,null,null
,,,
141,0.4,null,null
,,,
142,,null,null
,,,
143,"infAP as per DS irels, NIST assessments",null,null
,,,
144,,null,null
,,,
145,0.4,null,null
,,,
146,,null,null
,,,
147,infAP as per DS irels and assessments,null,null
,,,
148,,null,null
,,,
149,0.3,null,null
,,,
150,,null,null
,,,
151,0.2,null,null
,,,
152,,null,null
,,,
153,Tau = 0.88 Tau AP = 0.83 RMSE = 0.02 Bias = -0.02,null,null
,,,
154,,null,null
,,,
155,MM,null,null
,,,
156,,null,null
,,,
157,q,null,null
,,,
158,,null,null
,,,
159,RMRRRRRRRRRR,null,null
,,,
160,,null,null
,,,
161,q q q,null,null
,,,
162,,null,null
,,,
163,q RqqRqqqRqRRRRRqqRRqqq q qRqRqRRRR R,null,null
,,,
164,,null,null
,,,
165,q R,null,null
,,,
166,,null,null
,,,
167,R,null,null
,,,
168,,null,null
,,,
169,qq,null,null
,,,
170,,null,null
,,,
171,qqq,null,null
,,,
172,,null,null
,,,
173,0.1,null,null
,,,
174,,null,null
,,,
175,0.2,null,null
,,,
176,,null,null
,,,
177,0.3,null,null
,,,
178,,null,null
,,,
179,M M,null,null
,,,
180,,null,null
,,,
181,Tau = 0.95,null,null
,,,
182,,null,null
,,,
183,Tau AP = 0.92 RMSE = 0.01 Bias = 0.00,null,null
,,,
184,,null,null
,,,
185,RMRRRRRRRRR qqq,null,null
,,,
186,,null,null
,,,
187,qRqqRqRRRRqRqRqqqRqRRRRqqRR,null,null
,,,
188,,null,null
,,,
189,qR,null,null
,,,
190,,null,null
,,,
191,q,null,null
,,,
192,,null,null
,,,
193,qq,null,null
,,,
194,,null,null
,,,
195,R qR,null,null
,,,
196,,null,null
,,,
197,qq,null,null
,,,
198,,null,null
,,,
199,qqq,null,null
,,,
200,,null,null
,,,
201,0.1,null,null
,,,
202,,null,null
,,,
203,0,null,null
,,,
204,,null,null
,,,
205,0,null,null
,,,
206,,null,null
,,,
207,0.5,null,null
,,,
208,,null,null
,,,
209,0.4,null,null
,,,
210,,null,null
,,,
211,MAP as per qrels Depth-10 + MTF,null,null
,,,
212,,null,null
,,,
213,0.3,null,null
,,,
214,,null,null
,,,
215,MAP as per qrels Depth-10,null,null
,,,
216,,null,null
,,,
217,0,null,null
,,,
218,,null,null
,,,
219,0.1,null,null
,,,
220,,null,null
,,,
221,0.2,null,null
,,,
222,,null,null
,,,
223,0.3,null,null
,,,
224,,null,null
,,,
225,0.4,null,null
,,,
226,,null,null
,,,
227,0.5,null,null
,,,
228,,null,null
,,,
229,MAP as per NIST qrels and assessments,null,null
,,,
230,,null,null
,,,
231,q Automatic R Feedback M Manual,null,null
,,,
232,MM,null,null
,,,
233,,null,null
,,,
234,Tau = 0.93 Tau AP = 0.89 RMSE = 0.05 Bias = 0.04,null,null
,,,
235,q qq qR R,null,null
,,,
236,,null,null
,,,
237,qqq RqqRqRRRRqRqqRqqqqRqqRRRRqRR q,null,null
,,,
238,q q R,null,null
,,,
239,,null,null
,,,
240,RMRRRRRRRRRR,null,null
,,,
241,,null,null
,,,
242,0.2,null,null
,,,
243,,null,null
,,,
244,0.3,null,null
,,,
245,,null,null
,,,
246,0.4,null,null
,,,
247,,null,null
,,,
248,0.5,null,null
,,,
249,,null,null
,,,
250,0,null,null
,,,
251,,null,null
,,,
252,0.1,null,null
,,,
253,,null,null
,,,
254,0.2,null,null
,,,
255,,null,null
,,,
256,0.3,null,null
,,,
257,,null,null
,,,
258,0.4,null,null
,,,
259,,null,null
,,,
260,0.5,null,null
,,,
261,,null,null
,,,
262,MAP as per NIST qrels and assessments,null,null
,,,
263,,null,null
,,,
264,q Automatic R Feedback M Manual,null,null
,,,
265,Tau = 0.94 Tau AP = 0.91 RMSE = 0.05 Bias = 0.05,null,null
,,,
266,,null,null
,,,
267,M M MRRRRRRRRRR R,null,null
,,,
268,RqqRqRRRRqRqqRqqqqRqqRRRRqqRRqqqq q q R,null,null
,,,
269,,null,null
,,,
270,q qq,null,null
,,,
271,,null,null
,,,
272,qR R,null,null
,,,
273,,null,null
,,,
274,0.2,null,null
,,,
275,,null,null
,,,
276,0.1,null,null
,,,
277,,null,null
,,,
278,0.1,null,null
,,,
279,,null,null
,,,
280,q q,null,null
,,,
281,qqq,null,null
,,,
282,,null,null
,,,
283,q q,null,null
,,,
284,qqq,null,null
,,,
285,,null,null
,,,
286,0,null,null
,,,
287,,null,null
,,,
288,0,null,null
,,,
289,,null,null
,,,
290,0,null,null
,,,
291,,null,null
,,,
292,0.1,null,null
,,,
293,,null,null
,,,
294,0.2,null,null
,,,
295,,null,null
,,,
296,0.3,null,null
,,,
297,,null,null
,,,
298,0.4,null,null
,,,
299,,null,null
,,,
300,0.5,null,null
,,,
301,,null,null
,,,
302,MAP as per NIST qrels and assessments,null,null
,,,
303,,null,null
,,,
304,0,null,null
,,,
305,,null,null
,,,
306,0.1,null,null
,,,
307,,null,null
,,,
308,0.2,null,null
,,,
309,,null,null
,,,
310,0.3,null,null
,,,
311,,null,null
,,,
312,0.4,null,null
,,,
313,,null,null
,,,
314,0.5,null,null
,,,
315,,null,null
,,,
316,MAP as per NIST qrels and assessments,null,null
,,,
317,,null,null
,,,
318,"Figure 1: Accuracy of MAP estimates using DS vs. pooling methods, compared to official TREC 2018 Common Core Track evaluation. The top-left panel shows results for DS with relevance assessments by the authors; the top-right panel shows results for DS with official relevance assessments by NIST. The bottom-left panel shows results for the depth-10 pool with relevance assessments by NIST; the bottom-right shows results for the depth-10 pool augmented by MTF, with relevance assessments by NIST.",Y,TREC 
,,,
319,,null,null
,,,
320,0.5,null,null
,,,
321,,null,null
,,,
322,0.5,null,null
,,,
323,,null,null
,,,
324,q Automatic R Feedback M Manual,null,null
,,,
325,,null,null
,,,
326,q Automatic R Feedback M Manual,null,null
,,,
327,,null,null
,,,
328,0.4,null,null
,,,
329,,null,null
,,,
330,"infAP as per DS irels, NIST assessments",null,null
,,,
331,,null,null
,,,
332,0.4,null,null
,,,
333,,null,null
,,,
334,MAP as per NIST qrels and assessments,null,null
,,,
335,,null,null
,,,
336,0.3,null,null
,,,
337,,null,null
,,,
338,0.2,null,null
,,,
339,,null,null
,,,
340,Tau = 0.96 Tau AP = 0.94 RMSE = 0.01 Bias = 0.00,null,null
,,,
341,,null,null
,,,
342,M M,null,null
,,,
343,RMRRRRRRRRR,null,null
,,,
344,qqq qRRqRRqRRRqRqqRqRqqRqRRRqRq Rq,null,null
,,,
345,,null,null
,,,
346,R qR,null,null
,,,
347,,null,null
,,,
348,q qq,null,null
,,,
349,,null,null
,,,
350,q q,null,null
,,,
351,,null,null
,,,
352,qq,null,null
,,,
353,,null,null
,,,
354,0.1,null,null
,,,
355,,null,null
,,,
356,0.2,null,null
,,,
357,,null,null
,,,
358,0.3,null,null
,,,
359,,null,null
,,,
360,M M,null,null
,,,
361,,null,null
,,,
362,Tau = 0.98,null,null
,,,
363,,null,null
,,,
364,Tau AP = 0.97 RMSE = 0.00 Bias = 0.00,null,null
,,,
365,,null,null
,,,
366,MRRRRRRRR R qq,null,null
,,,
367,,null,null
,,,
368,qRRqRRqRRRqRqqRqRqqRqRRRqRq,null,null
,,,
369,,null,null
,,,
370,Rq,null,null
,,,
371,,null,null
,,,
372,q,null,null
,,,
373,,null,null
,,,
374,qq,null,null
,,,
375,,null,null
,,,
376,R qR,null,null
,,,
377,,null,null
,,,
378,qq,null,null
,,,
379,,null,null
,,,
380,qq,null,null
,,,
381,,null,null
,,,
382,0.1,null,null
,,,
383,,null,null
,,,
384,0,null,null
,,,
385,,null,null
,,,
386,0,null,null
,,,
387,,null,null
,,,
388,0,null,null
,,,
389,,null,null
,,,
390,0.1,null,null
,,,
391,,null,null
,,,
392,0.2,null,null
,,,
393,,null,null
,,,
394,0.3,null,null
,,,
395,,null,null
,,,
396,0.4,null,null
,,,
397,,null,null
,,,
398,0.5,null,null
,,,
399,,null,null
,,,
400,"infAP as per DS+NIST irels, NIST assessments",null,null
,,,
401,,null,null
,,,
402,0,null,null
,,,
403,,null,null
,,,
404,0.1,null,null
,,,
405,,null,null
,,,
406,0.2,null,null
,,,
407,,null,null
,,,
408,0.3,null,null
,,,
409,,null,null
,,,
410,0.4,null,null
,,,
411,,null,null
,,,
412,0.5,null,null
,,,
413,,null,null
,,,
414,"infAP as per DS+NIST irels, NIST assessments",null,null
,,,
415,,null,null
,,,
416,Figure 2: Accuracy of official NIST qrels,null,null
,,,
417,,null,null
,,,
418,1219,null,null
,,,
419,,null,null
,,,
420,Short Research Papers 3B: Recommendation and Evaluation,null,null
,,,
421,,null,null
,,,
422,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
423,,null,null
,,,
424,1,null,null
,,,
425,,null,null
,,,
426,0.9,null,null
,,,
427,,null,null
,,,
428,0.8,null,null
,,,
429,,null,null
,,,
430,0.7,null,null
,,,
431,,null,null
,,,
432,System Recall,null,null
,,,
433,,null,null
,,,
434,0.6,null,null
,,,
435,,null,null
,,,
436,0.5,null,null
,,,
437,,null,null
,,,
438,0.4,null,null
,,,
439,,null,null
,,,
440,0.3,null,null
,,,
441,,null,null
,,,
442,0.2,null,null
,,,
443,,null,null
,,,
444,0.1,null,null
,,,
445,0.0 0.0,null,null
,,,
446,,null,null
,,,
447,0.2,null,null
,,,
448,,null,null
,,,
449,0.4,null,null
,,,
450,,null,null
,,,
451,0.6,null,null
,,,
452,,null,null
,,,
453,Review Effort,null,null
,,,
454,,null,null
,,,
455,50 topics Averaged,null,null
,,,
456,,null,null
,,,
457,0.8,null,null
,,,
458,,null,null
,,,
459,1,null,null
,,,
460,,null,null
,,,
461,Figure 3: Coverage as a function of overall assessment effort.,null,null
,,,
462,,null,null
,,,
463,"for these topics, higher coverage would have been achieved. We also note that several topics achieving ostensibly high coverage have substantial slope when the budget is exhausted, suggesting a shortfall in the ground truth estimate of the number of relevant documents. These results suggest that using the ""Knee Method"" as a stopping criterion, which has been shown to work well for CAL [4], might be preferable to a fixed assessment budget.",null,null
,,,
464,"A similar approach might also have yielded better results for MTF, which was constrained by a restrictive assessment budget [2].",null,null
,,,
465,7 DISCUSSION AND LIMITATIONS,null,null
,,,
466,"For brevity, we present MAP results estimated by xinfAP, consistent with common practice. In a companion article [6], Cormack and Grossman show that better estimates of MAP, as well as precision at cutoff",null,null
,,,
467,"Estimates derived from DS assume that the DS universe includes substantially all relevant documents; DS yields an unbiased, nonuniform statistical sample from which MAP and other evaluation measures are derived. Hence, the effectiveness of any run--not just a member of an evaluation pool--may be evaluated using a DS collection.",null,null
,,,
468,"One can increase coverage by increasing the size of the universe, at the expense of higher variance. The evidence presented here suggests the the DS universe does indeed contain a substantial majority of the relevant documents. Future work may explore the influence of three parameters that balance the tension between coverage, sampling budget, and skew of the sampling rate in favour of likely relevant documents. The sampling budget of 300 was occasioned by our target of one hour of assessment time per topic. Given the fact that we had no pool of runs, we were further constrained to use content-only features for the learner. Within these constraints, strategies D12, D25, and D50, reflecting different tradeoffs between coverage and sampling rate, appeared equally good [3], and we chose the median. Further investigation might yield a better tradeoff. If it were logistically feasible, a flexible assessment budget with an average of 300 documents per topic, and an amenable stopping criterion, might have yielded better results, for the same overall assessment budget.",null,null
,,,
469,We have measured the effect of assessor disagreement only on the MAP estimates derived from identical sets of assessments. Our,null,null
,,,
470,,null,null
,,,
471,results show that DS conducted by one set of assessors,null,null
,,,
472,"Finally, we note that the relevance determinations of assessors are influenced by context; in particular, the order and richness of the documents they are shown [8]. DS assessors are shown the most-likely relevant documents first, which suggests they are likely be more stringent in their judgment of relevance, at least at the outset. As the density of relevant documents inevitably decreases, some assessors may have a tendency to ""reach"" and thus, be more likely to judge a document relevant than at the outset. Our design controls for this possible effect with respect to the NIST assessments for the DS sample, because the NIST assessors were unaware of the order in which the DS documents were discovered, or, indeed, whether a document was identified by pooling, by DS, or both. Our assessments with respect to the DS sample, and NIST's assessments with respect to MTF, might have been so influenced.",null,null
,,,
473,8 CONCLUSION,null,null
,,,
474,"Independent of NIST assessments or any pool of submitted runs, a small team of researchers spent 50 hours to create a set of sampled relevance assessments that effectively scores and ranks systems according to MAP over 50 topics. This level of effort represents an order-of-magnitude reduction in human effort, compared to typical efforts like TREC, and does not rely on pooling, which is both logistically challenging and a potential source of bias against systems not contributing to the pool. DS avoids this source of bias and, as both theory and empirical evidence show, does not introduce bias against the TREC runs that had no influence on the DS selection strategy, or our relevance assessments.",Y,TREC
,,,
475,ACKNOWLEDGMENTS,null,null
,,,
476,Special thanks to Ellen M. Voorhees for integrating the results of our DS process into the official NIST assessment effort.,null,null
,,,
477,REFERENCES,null,null
,,,
478,"[1] Abualsaud, M., Ghelani, N., Zhang, H., Smucker, M. D., Cormack, G. V., and Grossman, M. R. A system for efficient high-recall retrieval. In SIGIR 2018.",null,null
,,,
479,"[2] Allan, J., Harman, D., Kanoulas, E., and Voorhees, E. TREC 2018 Common Core Track overview. In TREC 2018.",Y,TREC
,,,
480,"[3] Cormack, G. V., and Grossman, M. R. Beyond pooling. In SIGIR 2018. [4] Cormack, G. V., and Grossman, M. R. Engineering quality and reliability in",null,null
,,,
481,"technology-assisted review. In SIGIR 2016. [5] Cormack, G. V., and Grossman, M. R. Evaluation of machine-learning protocols",null,null
,,,
482,"for technology-assisted review in electronic discovery. In SIGIR 2014. [6] Cormack, G. V., and Grossman, M. R. Unbiased low-variance estimators for",null,null
,,,
483,precision and related information retrieval effectiveness measures. In SIGIR 2019,null,null
,,,
484,,null,null
,,,
485,1220,null,null
,,,
486,,null,null
,,,
487,,null,null
