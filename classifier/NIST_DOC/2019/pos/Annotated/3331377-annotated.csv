,sentence,label,data
,,,
0,Short Research Papers 3C: Search,null,null
,,,
1,,null,null
,,,
2,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
3,,null,null
,,,
4,LIRME: Locally Interpretable Ranking Model Explanation,null,null
,,,
5,,null,null
,,,
6,Manisha Verma,null,null
,,,
7,"Verizon Media, New York, USA manishav@verizonmedia.com",null,null
,,,
8,ABSTRACT,null,null
,,,
9,Information retrieval,null,null
,,,
10,CCS CONCEPTS,null,null
,,,
11,· Information systems  Information retrieval; Content analysis and feature selection; Retrieval models and ranking;,null,null
,,,
12,KEYWORDS,null,null
,,,
13,"Interpretability, Ranking, Point-wise explanations",null,null
,,,
14,"ACM Reference format: Manisha Verma and Debasis Ganguly. 2019. LIRME: Locally Interpretable Ranking Model Explanation. In Proceedings of Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, Paris, France, July 21­25, 2019",null,null
,,,
15,1 INTRODUCTION,null,null
,,,
16,It has been shown that complex machine learning,null,null
,,,
17,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '19, July 21­25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn",null,null
,,,
18,,null,null
,,,
19,Debasis Ganguly,null,null
,,,
20,"IBM Research, Dublin, Ireland debasis.ganguly1@ie.ibm.com",null,null
,,,
21,"features [3, 10], or a weighted distribution of feature importance [6, 9]. While the explanation space itself and methods to generate explanations are widely known in practise for classification tasks, their utility is largely unexplored for ranking tasks. There is little existing work in the IR community to systematically investigate ways of generating explanations for an IR model. Given that IR models involve complex variations in term weighting functions for scoring query-document pairs, some models may not be easy to `explain' to a search engine user, who may have questions such as `Why does a search engine retrieve document D at rank k?'.",null,null
,,,
22,"In this work, with the motivation of `explanations' in IR, we explore ways of generating and evaluating explanations. We focus on model-agnostic point-wise explanations, i.e. estimating `explanation vectors' with respect to a retrieval model without any knowledge about its internals. The weight of each token in the term importance vector indicates its contribution to a ranking model's output for a given query-document pair. This vector can then be analyzed to see the relative importance of terms contributing positively",null,null
,,,
23,To estimate the explanation vector for a query-document pair,null,null
,,,
24,"We propose two metrics for evaluating the stability and correctness of the generated explanations. The first metric evaluates the sensitivity of the explanation model, i.e. the scale of change in explanations with change in model parameters. The second evaluation metric is more specific to IR, in which we evaluate the effectiveness of the explanations in terms of document relevance. Our experiments on the TREC ad hoc dataset indicate that sampling methods that are biased with tf-idf or positional information produce weaker explanations than those generated by uniformly sampling words from documents. We also found that explanation stability decreases with an increase in the number of explanation words; and that this effect is more pronounced for non-relevant documents.",Y,TREC
,,,
25,,null,null
,,,
26,1281,null,null
,,,
27,,null,null
,,,
28,Short Research Papers 3C: Search,null,null
,,,
29,,null,null
,,,
30,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
31,,null,null
,,,
32,2 RELATED WORK,null,null
,,,
33,"Singh et. al. [12] investigate methods to train an explanation model for a given base ranker. The document rankings generated from the explanation model are then compared to those generated by the base model. Contrastingly, in our work, the focus is to evaluate different sampling strategies and automatically evaluate the consistency and effectiveness of explanation models. Specifically, our work explores methods to generate data for explanation model training and evaluate its effectiveness across queries. The metrics and sampling methods explored in this work can be adapted easily to train and evaluate new explanation models such as those proposed in [11, 12]. We do not investigate ways of transforming document scores into class probabilities [13], as explanation models can be trained directly on `scores' assigned by any ranker",null,null
,,,
34,3 LOCAL EXPLANATION OF IR MODELS,null,null
,,,
35,"In classification tasks, model predictions can be understood by analyzing the predictions of simpler",null,null
,,,
36,"Since the working principle of a ranking task is different from that of classification, in this work we investigate different ways of generating model-agnostic interpretable explanations for ranked lists. Formally, given a set of documents D and a query Q, the ranking function S(D, Q) induces a total order on the set D. For traditional IR models, such as BM25 or language models",Y,BM25
,,,
37,"To generate explanations, it is required to select set of simple instances or sub-instances, where each sub-instance is comprised of partial information extracted from a particular document. We employ a weighted squared loss to predict the score of the entire document D with respect to the input query. We call this method locally interpretable ranking model explanation",null,null
,,,
38,,null,null
,,,
39,M,null,null
,,,
40,"L(D, Q,  ; ) =",null,null
,,,
41,,null,null
,,,
42,i =1,null,null
,,,
43,,null,null
,,,
44,M,null,null
,,,
45,,null,null
,,,
46,p,null,null
,,,
47,,null,null
,,,
48,=,null,null
,,,
49,,null,null
,,,
50,i =1,null,null
,,,
51,,null,null
,,,
52,j =1,null,null
,,,
53,,null,null
,,,
54,-1,null,null
,,,
55,,null,null
,,,
56,"In Equation 1, Di = i",null,null
,,,
57,,null,null
,,,
58,document D comprised of p unique terms;  is an L1 regularization,null,null
,,,
59,,null,null
,,,
60,term; and   Rp denotes a vector of p real-valued parameters used,null,null
,,,
61,,null,null
,,,
62,"to approximate the score query Q. Additionally, the",null,null
,,,
63,,null,null
,,,
64,of the sub-sample weight of the loss,null,null
,,,
65,,null,null
,,,
66,"D(iD w, Ditih),riessapseicmt itloartihtye",null,null
,,,
67,,null,null
,,,
68,between the document D and its sub-sample Di. A standard way to define  in Equation 1 is with a kernel function of the form,null,null
,,,
69,,null,null
,,,
70,"(D, D)",null,null
,,,
71,,null,null
,,,
72,=,null,null
,,,
73,,null,null
,,,
74,exp(-,null,null
,,,
75,,null,null
,,,
76,x2 h,null,null
,,,
77,,null,null
,,,
78,"),",null,null
,,,
79,,null,null
,,,
80,x,null,null
,,,
81,,null,null
,,,
82,#NAME?,null,null
,,,
83,,null,null
,,,
84,-2,null,null
,,,
85,,null,null
,,,
86,"where arccos(D, D) denotes the cosine-distance",null,null
,,,
87,,null,null
,,,
88,"document D and a sub-document sampled from it, and h denotes",null,null
,,,
89,,null,null
,,,
90,the width of a Gaussian kernel.,null,null
,,,
91,,null,null
,,,
92,"The weighted loss function of Equation 1 predicts S(D, Q) using",null,null
,,,
93,,null,null
,,,
94,the given samples. Since a retrieval model computes the score of an,null,null
,,,
95,,null,null
,,,
96,"entire document and also the scores of its sub-samples, the predicted vector ^  Rp estimates the importance of each term, e.g. the jth component of ^ denotes the likelihood of term tj in contributing positively to the overall score S(D, Q).",null,null
,,,
97,It is expected that weights in ^ that correspond to a query term,null,null
,,,
98,,null,null
,,,
99,will have larger weights,null,null
,,,
100,,null,null
,,,
101,semantically related to the query and hence are likely to be relevant,null,null
,,,
102,,null,null
,,,
103,to its underlying information need. A visualization of these terms,null,null
,,,
104,,null,null
,,,
105,may then provide the desired explanation of an observed score of a,null,null
,,,
106,,null,null
,,,
107,document D with respect to Q,null,null
,,,
108,,null,null
,,,
109,3.1 Sampling of Explanation Instances,null,null
,,,
110,,null,null
,,,
111,We now describe three different ways to define the sampling func-,null,null
,,,
112,,null,null
,,,
113,tion ,null,null
,,,
114,,null,null
,,,
115,"neighbourhood of D for the purpose of predicting the parameter vector, ^ , to explain a retrieval model.",null,null
,,,
116,,null,null
,,,
117,Uniform Sampling:. A simple way to sample from the neigh-,null,null
,,,
118,,null,null
,,,
119,bourhood of an given document D is to sample terms with a uniform,null,null
,,,
120,,null,null
,,,
121,likelihood,null,null
,,,
122,,null,null
,,,
123,towards term selection leading to likely generation of a diverse set,null,null
,,,
124,,null,null
,,,
125,of samples for a document.,null,null
,,,
126,,null,null
,,,
127,Biased Sampling:. Another way to sample terms is to set the,null,null
,,,
128,,null,null
,,,
129,sampling probability of a term proportional to its tf-idf weight,null,null
,,,
130,,null,null
,,,
131,seeking to generate sub-samples with informative terms.,null,null
,,,
132,,null,null
,,,
133,Masked Sampling:. In contrast to a bag-of-words based sam-,null,null
,,,
134,,null,null
,,,
135,"pling approach, an alternative way is to extract segments of text",null,null
,,,
136,,null,null
,,,
137,"from a document, somewhat analogous to selecting regions from",null,null
,,,
138,,null,null
,,,
139,"an image [9]. More specifically, in this sampling method we first",null,null
,,,
140,,null,null
,,,
141,"specify a segment size, say k, and then segment a document D",null,null
,,,
142,,null,null
,,,
143,prised of,null,null
,,,
144,,null,null
,,,
145,|D|,null,null
,,,
146,,null,null
,,,
147,tokens) into,null,null
,,,
148,,null,null
,,,
149,|D | k,null,null
,,,
150,,null,null
,,,
151,number of chunks. A,null,null
,,,
152,,null,null
,,,
153,chunk is then,null,null
,,,
154,,null,null
,,,
155,made visible in the sub-sample with probability v,null,null
,,,
156,,null,null
,,,
157,4 EXPLANATION EVALUATION METRIC,null,null
,,,
158,"We now consider ways of automatically evaluating the quality of an explanations generated using different sampling methods. Since it is costly and laborious to manually label the quality of explanations for each query-document pair, we propose two metrics that exploit relevance judgments to measure explanation quality at scale. We focus on 2C's ­ consistency and correctness for evaluating explanations described in following sections.",null,null
,,,
159,,null,null
,,,
160,4.1 Explanation Consistency,null,null
,,,
161,"An explanation vector ^ Q,D can be used to determine which terms are important for explaining the score of a document D with respect to a query Q, i.e. S(D, Q). The first desirable quality of an explanation method is that the relative ranking of important terms should",null,null
,,,
162,,null,null
,,,
163,1282,null,null
,,,
164,,null,null
,,,
165,Short Research Papers 3C: Search,null,null
,,,
166,,null,null
,,,
167,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
168,,null,null
,,,
169,"not change significantly with variations in the parameters of the model, or in other words, a particular choice of samples around the pivot document, D, should not result in considerable differences in the predicted explanation vector.",null,null
,,,
170,Variances in term rankings,null,null
,,,
171,,null,null
,,,
172,R(Q)(w) =,null,null
,,,
173,,null,null
,,,
174,f,null,null
,,,
175,v R(Q ),null,null
,,,
176,,null,null
,,,
177,R,null,null
,,,
178,,null,null
,,,
179,+,null,null
,,,
180,,null,null
,,,
181,(1,null,null
,,,
182,,null,null
,,,
183,-,null,null
,,,
184,,null,null
,,,
185,") cf(w) , cs",null,null
,,,
186,,null,null
,,,
187,-3,null,null
,,,
188,,null,null
,,,
189,"where R(Q) denotes the set of relevant terms extracted from R(Q), f and cf respectively denote term and collection frequencies, and",null,null
,,,
190,cs denotes collection size. We then assume that an ideal explanation,null,null
,,,
191,system should seek to predict the same ranking of terms as induced,null,null
,,,
192,"by the decreasing order of term weights. Formally speaking, if ",null,null
,,,
193,respect to the ground-truth ranking of terms as,null,null
,,,
194,,null,null
,,,
195,"(Q, D)",null,null
,,,
196,,null,null
,,,
197,=,null,null
,,,
198,,null,null
,,,
199,1 ||,null,null
,,,
200,,null,null
,,,
201,(,null,null
,,,
202,,null,null
,,,
203,"^ Q, D",null,null
,,,
204,,null,null
,,,
205,-4,null,null
,,,
206,,null,null
,,,
207,ECON = 1,null,null
,,,
208,,null,null
,,,
209,"(Q, D),",null,null
,,,
210,,null,null
,,,
211,|Q|,null,null
,,,
212,,null,null
,,,
213,Q  Q D TOP(Q ),null,null
,,,
214,,null,null
,,,
215,"where  represents the set of different explanation vectors obtained with different samples, e.g. variations in the L1-regularization and kernel widths of LIRME",null,null
,,,
216,,null,null
,,,
217,4.2 Explanation Correctness,null,null
,,,
218,"Intuitively, an explanation may be considered to be effective if it attributes higher weights to the components of ^ Q,D that correspond to relevant terms, i.e. the terms occurring in documents that are",null,null
,,,
219,"judged relevant by assessors. We measure explanation correctness by computing similarity between explanation vector terms ^ Q,D and relevant terms R(Q). In particular, for a query-document pair",null,null
,,,
220,,null,null
,,,
221,ECOR,null,null
,,,
222,,null,null
,,,
223,=,null,null
,,,
224,,null,null
,,,
225,1 |Q|,null,null
,,,
226,,null,null
,,,
227,Q  Q D TOP(Q ),null,null
,,,
228,,null,null
,,,
229,"^ Q,D · R(Q) |^ Q,D ||R(Q)|",null,null
,,,
230,,null,null
,,,
231,-5,null,null
,,,
232,,null,null
,,,
233,(a) Consistency,null,null
,,,
234,,null,null
,,,
235,(b) Correctness,null,null
,,,
236,,null,null
,,,
237,Figure 1: ECON and ECOR for top-5 retrieved documents.,null,null
,,,
238,,null,null
,,,
239,(a) Relevant documents,null,null
,,,
240,,null,null
,,,
241,(b) Non-relevant documents,null,null
,,,
242,,null,null
,,,
243,Figure 2: ECON for relevant and non-relevant documents.,null,null
,,,
244,,null,null
,,,
245,(a) Relevant documents,null,null
,,,
246,,null,null
,,,
247,(b) Non-relevant documents,null,null
,,,
248,,null,null
,,,
249,Figure 3: ECOR for relevant and non-relevant documents. where R(Q) represents the distribution of terms in the judged relevant documents. Similar to consistency ECON. we aggregate the relevance similarity values over a set of queries and number of top documents retrieved for each query.,null,null
,,,
250,,null,null
,,,
251,5 EXPERIMENTS,null,null
,,,
252,The objectives of our experiments are to investigate - a) what term sampling approaches are effective in terms of the metrics consistency and ECOR,null,null
,,,
253,"For our experiments, we use a standard benchmark dataset, namely the TREC-8, comprising 50 topics. To generate different sub-samples for explanation, we also employ uniform kernel in addition to Gaussian kernel, i.e. apply",Y,TREC-8
,,,
254,"In Figure 1a, we report expected consistency",null,null
,,,
255,,null,null
,,,
256,1283,null,null
,,,
257,,null,null
,,,
258,Short Research Papers 3C: Search,null,null
,,,
259,,null,null
,,,
260,"SIGIR '19, July 21­25, 2019, Paris, France",null,null
,,,
261,,null,null
,,,
262,(a) Uniform sampling,null,null
,,,
263,,null,null
,,,
264,(b) Tf-idf sampling,null,null
,,,
265,,null,null
,,,
266,(c) Masked samples,null,null
,,,
267,,null,null
,,,
268,Figure 4: Visualization of explanation vectors ^,null,null
,,,
269,,null,null
,,,
270,query,null,null
,,,
271,,null,null
,,,
272,"higher consistency than the masking-based sampling. This indicates that on an average the relative ranks of the term weights in the explanation vector ^ are more stable for these two sampling methods in comparison to the masking based sampler. Our experiments indicate that samples generated from a masking-based sampler exhibit less diversity because of a smaller degree of freedom in choosing individual terms independent of its context. Moreover, in the case of bag-of-words, uniform sampling yields higher consistency",null,null
,,,
273,Biased sampling with tf-idf weights results in higher ECOR,null,null
,,,
274,"For each sampling strategy investigated, Figure 4 plots the terms with their associated weights from explanation vectors, ^ , as histograms for a document judged relevant for the query `counterfeiting money'",null,null
,,,
275,,null,null
,,,
276,the local explanations generated by any LIRME. Another observation is that sampling approaches were mostly able to find terms,null,null
,,,
277,6 CONCLUSION,null,null
,,,
278,"While research in explaining outputs of classification models exists, there is little work on explaining results of a ranking model. In this work, we addressed the research question: Why does an IR model assign a certain score",null,null
,,,
279,REFERENCES,null,null
,,,
280,"[1] E. Alepis, E. Politou, and C. Patsakis. Forgetting personal data and revoking consent under the GDPR: Challenges and proposed solutions. Journal of Cybersecurity, 4(1), 03 2018.",null,null
,,,
281,"[2] T. Bolukbasi, K. Chang, J. Y. Zou, V. Saligrama, and A. Kalai. Man is to computer programmer as woman is to homemaker? debiasing word embeddings. CoRR, abs/1607.06520, 2016.",null,null
,,,
282,"[3] J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan. Learning to explain: An information-theoretic perspective on model interpretation. arXiv preprint arXiv:1802.07814, 2018.",null,null
,,,
283,"[4] L. Dixon, J. Li, J. Sorensen, N. Thain, and L. Vasserman. Measuring and mitigating unintended bias in text classification. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pages 67­73. ACM, 2018.",null,null
,,,
284,"[5] Z. C. Lipton. The mythos of model interpretability. arXiv:1606.03490, 2016. [6] S. M. Lundberg and S.-I. Lee. A unified approach to interpreting model predictions.",null,null
,,,
285,"In Advances in Neural Information Processing Systems, pages 4765­4774, 2017. [7] D. Metzler and W. Bruce Croft. Linear feature-based models for information",null,null
,,,
286,"retrieval. Inf. Retr., 10(3):257­274, June 2007. [8] G. Montavon, W. Samek, and K. Müller. Methods for interpreting and under-",null,null
,,,
287,"standing deep neural networks. CoRR, abs/1706.07979, 2017. [9] M. T. Ribeiro, S. Singh, and C. Guestrin. Why should i trust you?: Explaining the",null,null
,,,
288,"predictions of any classifier. In Proc. of KDD'16, pages 1135­1144, 2016. [10] M. T. Ribeiro, S. Singh, and C. Guestrin. Anchors: High-precision model-agnostic",null,null
,,,
289,"explanations. In AAAI Conference on Artificial Intelligence, 2018. [11] J. Singh and A. Anand. Interpreting search result rankings through intent model-",null,null
,,,
290,"ing. arXiv preprint arXiv:1809.05190, 2018. [12] J. Singh and A. Anand. Posthoc interpretability of learning to rank models using",null,null
,,,
291,"secondary training data. arXiv preprint arXiv:1806.11330, 2018. [13] J. Singh and A. Anand. EXS: Explainable Search Using Local Model Agnostic",null,null
,,,
292,"Interpretability. In Proc. of WSDM '19, pages 770­773, 2019.",null,null
,,,
293,,null,null
,,,
294,1284,null,null
,,,
295,,null,null
,,,
296,,null,null
