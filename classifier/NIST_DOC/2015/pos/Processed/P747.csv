,sentence,label,data
0,The Best Published Result is Random: Sequential Testing and its Effect on Reported Effectiveness,null,null
1,Ben Carterette,null,null
2,Department of Computer and Information Sciences University of Delaware,null,null
3,"Newark, DE, USA 19716",null,null
4,carteret@udel.edu,null,null
5,ABSTRACT,null,null
6,"Reusable test collections allow researchers to rapidly test different algorithms to find the one that works ""best"". But because of randomness in the topic sample, or in relevance judgments, or in interactions among system components, extreme results can be seen entirely due to chance, particularly when a collection becomes very popular. We argue that the best known published effectiveness on any given collection could be measured as much as 20% higher than its ""true"" intrinsic effectiveness, and that there are many other systems with lower measured effectiveness that could have substantially higher intrinsic effectiveness.",null,null
7,Categories and Subject Descriptors: H.3.4 [Information Storage and Retrieval] Performance Evaluation,null,null
8,"General Terms: Experimentation, Measurement",null,null
9,Keywords: information retrieval; test collections; evaluation; statistical analysis,null,null
10,1. INTRODUCTION,null,null
11,"Statistical significance testing is an important aspect of experimentation in IR. Without it, differences in effectiveness on the order of 5% would be difficult to interpret: they could represent a ""real"" improvement in effectiveness, or they could be the product of random noise. Significance testing helps us differentiate between the two [4, 5, 3].",null,null
12,"That we use significance testing implies that we accept there is randomness in measuring effectiveness. There is randomness due to a topic sample, due to documents in a collection, due to relevance judgments, and other factors of a test collection. Significance testing asks whether the variance in effectiveness that can be ascribed directly to differences in the systems being tested outweighs those other sources of variance [1].",null,null
13,"A full accounting of variance (such as that done for an ANOVA) could compute the total variance due to collection factors, suggesting that there is a ""baseline"" level of effectiveness for a given collection close to which we should expect",null,null
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. SIGIR'15, August 09 - 13, 2015, Santiago, Chile. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3621-5/15/08 ...$15.00. DOI: http://dx.doi.org/10.1145/2766462.2767812.",null,null
15,Density 0 5 10 15 20 25 30 35,null,null
16,0.24,null,null
17,0.26,null,null
18,0.28,null,null
19,0.30,null,null
20,0.32,null,null
21,0.34,null,null
22,maximum MAP in sample,null,null
23,Figure 1: The distribution of the maximum of 100 samples from a normal distribution with mean 0.20 and standard deviation 0.027.,null,null
24,"to find most reasonable IR systems. It is the systems that are well above that baseline that we are most interested in, and in particular, the one with the maximum measured effectiveness is widely considered the best possible system to compare against.",null,null
25,"But just as two systems can have different measured effectiveness due to chance, a system can have effectiveness higher than the expected collection baseline due to chance. This randomness in turn means that there must be randomness in our determination of which system has produced the maximum value. It is actually likely that whatever method produces the largest measured effectiveness on a given collection has lower intrinsic effectiveness than reported. This is because of sequential testing: the more tests are done with a given collection, the more likely it becomes that an extreme effectiveness value will be observed.",null,null
26,"Rather than take the maximum value at face value, we argue that we should analyze it in the context of other known results and the likelihood that such a value could be produced by a system whose intrinsic effectiveness is much lower simply due to random factors. Of course, the opposite is true as well: any given result could be produced by a system whose intrinsic effectiveness is much higher. We investigate both sides to argue that the intrinsic effectiveness of the best known system could be as much as 20% lower than reported, and systems as much as 20% less effective than the best could have intrinsic effectiveness much higher.",null,null
27,"In Section 2 we introduce extreme value theory, and in Sections 3 and 4 we show how we can use it for deeper analysis of IR experiments. We conclude in Section 5 with some discussion about the implications of this work.",null,null
28,747,null,null
29,expected maximum value 0.24 0.25 0.26 0.27 0.28,null,null
30,10,null,null
31,20,null,null
32,50,null,null
33,100,null,null
34,200,null,null
35,number of samples,null,null
36,500,null,null
37,1000,null,null
38,Figure 2: Increase in the expected maximum as the number of samples increases.,null,null
39,2. EXTREME VALUE DISTRIBUTIONS,null,null
40,"Suppose we have 100 normal distributions, each of which has an identical population mean µ and population standard deviation . From each of these we sample 50 values and average them so that we have 100 sample means µ1 · · · µ100. We can think of these as 100 measures of mean effectiveness over 50 topics from systems with the same intrinsic effectiveness. Each of them will be ""close to"" the population mean. But some will be further away than others, and in particular, one of them must be the maximum of the 100. Given that we've sampled 100 values, it is likely that whatever the maximum is, it will be more than two standard deviations above the population mean; that is, it will ""look like"" a significant improvement over the population mean even though it was sampled from exactly the same distribution.",null,null
41,"Figure 1 shows the distribution of maximum MAP when 100 values are sampled from normal distributions with mean 0.20 and standard deviation 0.027. The mean of the distribution of maximums is 0.267, which, if taken at face value, would look like a 34% improvement over the mean of 0.2! Furthermore, 0.267 is outside of the 95% confidence interval around 0.2; in fact only 0.6% of the distribution is greater than 0.267. A full 99% of the distribution of maximums is greater than the upper bound of the 95% confidence interval, meaning it is a near-certainty that out of 100 systems with identical intrinsic effectiveness, at least one will be measured above the 95% confidence interval around the mean.",null,null
42,"Figure 2 shows the increase in expected maximum MAP as the number of samples increases. From this we argue that as the number of experiments performed on a particular collection increases, the expected maximum effectiveness reported on that collection will increase logarithmically, even if the ""real"" effectiveness of the systems being experimented on is not significantly different from the overall mean.",null,null
43,2.1 Extreme value theory,null,null
44,Extreme value theory is the area of statistics devoted to distributions of maximum and minimum sampled values [2]. The Gumbel distribution is an example of an extreme value distribution (EVD) that is useful for normally-distributed random variables. Its cumulative density function is:,null,null
45,"P (X  x|, ) , e-e-(x-)/",null,null
46,"This could be the distribution of random variable X representing the maximum value of N samples from a normal distribution with mean µ and variance 2. In that case, the",null,null
47,"parameter  is equivalent to µ, and the parameter  is an increasing function of both 2 and N . The expected value of the maximum is then given as  + , where  is Euler's constant, which has a value of about 0.5772. Since  ,"" µ,  is constant, and  is an increasing function of N , this means that the expected maximum increases with the number of identically-distributed samples.""",null,null
48,2.2 Estimating an extreme value distribution,null,null
49,"The exact relationship between , 2, N has no closed form1. It is easy enough to estimate a Gumbel distribution using sampling, however. Given a population mean µ and population standard deviation , we sample n values from a normal distribution with those parameters N times (n represents the number of topics; N the number of systems), average those n values for each of the N samples, and take the maximum average. Over many trials, this produces an approximation of the Gumbel distribution.",null,null
50,"We can simplify this further by just taking N samples from a normal distribution with mean µ and standard deviation / n--the latter is known as the standard error or the sampling distribution of the mean. Figure 1 was generated this way, as was Figure 2.",null,null
51,3. ANALYSIS USING EVD,null,null
52,"We typically answer statistical questions such as ""is one algorithm better than another?"" using statistical hypothesis testing. Procedures for hypothesis testing start by forming a reference distribution for the statistic in question (say, difference in mean effectiveness), then checking whether the measured value is in the tail of that distribution. If so, we say the systems are significantly different.",null,null
53,"The extreme value question is ""is this algorithm's effectiveness better than the maximum expected among N algorithms with the same intrinsic effectiveness on the same collection?"" 2 Note that the question includes the number of samples N ; this is a key difference between a one-off test of significance versus a test that accounts for the history of experiments done.",null,null
54,"We would answer that question by forming a reference distribution for maximum effectiveness rather than mean effectiveness. That distribution must be based on variation across a sample of systems as well as topics, and must also be based on the number of systems N . It must be specific to a collection and an effectiveness measure, since different collections and measures exhibit different variability --average precision typically has low variance compared to other measures, while P@10 has high variance; more recent collections (which tend to be larger and more heterogeneous) like ClueWeb12 tend to exhibit higher variance than older (smaller and less heterogeneous) collections like WSJ or AP.",null,null
55,"To form a reference distribution for a given collection and measure, we will first need to obtain a set of mean effectiveness values. Once obtained, we will assume that all of those values came from the same distribution: a normal distribution centered at their means, with variance equal to the variance of those means divided by the number of topics in",null,null
56,"1Closed forms exist only for N  5 [7]. 2We use the phrase ""intrinsic effectiveness"" as a shorthand for ""population effectiveness"", which refers to the system's effectiveness measured over the full population of queries. In practice there may not be a finite population of queries that could be measured even in principle.",null,null
57,748,null,null
58,"the collection (this is the variance of the sampling distribution). Then the maximum mean effectiveness has a Gumbel distribution, parameterized by  (the mean of the original normal distribution) and  (which is a function of the original variance as well as the number of means in the set); we estimate that distribution as described above.",null,null
59,"Though we have described how to estimate a reference distribution that could be used in a significance test, we are not actually going to propose a significance test. Instead, we will use a reference distribution to analyze results reported using different collections.",null,null
60,3.1 TREC-7 run analysis,null,null
61,"There were 103 submissions to TREC-7, so we have N ,"" 103 mean average precisions (MAPs). The mean of means, which we will use for µ, is about 0.2; we consider this the """"baseline"""" effectiveness by MAP for the collection. The standard deviation among means, which we will use for , is 0.08. We assume that each mean is drawn from a normal distribution with mean 0.2 and standard deviation 0.08/ 50, which is the standard deviation of the sampling distribution of the mean, also known as the standard error. To generate the reference maximum value distribution (MxVD), we repeatedly sample 103 values from a normal distribution with those parameters and take the maximum of those values.""",null,null
62,"One possible analysis similar to a significance test is as follows: identify the MAP in the MxVD such that 5% of the distribution is greater than or equal to that value. That represents the minimum MAP a system would need for us to conclude with high confidence that it is not just a random extreme value from a distribution with mean 0.2. In TREC7, that value is about 0.2375. 35 of the 103 submitted runs have a MAP greater than 0.2375; we would say that it is likely 33 (95% of 35, since we expect 5% to be false positives) of those have intrinsic effectiveness above the overall mean. We could do the same for minimum MAP. We find that 5% of the minimum value distribution (MnVD) is less than 0.1625, and 34 TREC-7 submissions have MAPs lower than that. This leaves 34 systems with MAPs within the bounds of what would be expected given that we've sampled 103 total MAPs, the highest and lowest of which are nearly 20% different from the mean.",null,null
63,"For the systems outside those bounds, we might also ask what distribution they could have reasonably come from. What is the minimum mean that could generate the maximum observed MAP with high enough probability that we do not consider it significant? Let us take the maximum MAP of any automatic TREC-7 run, since we expect a priori that manual runs will have higher MAPs. That is 0.303 for the ok7ax run [6]. Then the question is how low a population mean could produce an extreme value of 0.303 or higher (with the same variance and N ) with probability 0.2. Applying a linear search, we find that value to be 0.2705, which is 11% lower than 0.303.",null,null
64,"We might also ask how low a MAP we could measure when 103 are sampled from a distribution centered at 0.2705 rather than 0.2, or, what is the minimum MAP that we could observe with probability greater than 0.2 sampled from that distribution? It turns out that it could be as low as 0.2378. Therefore any MAP between 0.2378 and 0.303 could have come from a distribution centered at 0.27 if 103 values are sampled, and the probability of observing a MAP between those values is 60%.",null,null
65,20 40 60 80,null,null
66,60% interval containing likely non-extreme values 95% confidence interval,null,null
67,Density,null,null
68,0,null,null
69,0.22,null,null
70,0.24,null,null
71,0.26,null,null
72,0.28,null,null
73,0.30,null,null
74,0.32,null,null
75,MAP,null,null
76,"Figure 3: A normal distribution with mean 0.2705 and standard deviation 0.0114 (solid line), along with its maximum value distribution and minimum value distribution for N , 103. Blue lines show the 95% confidence interval of the normal distribution; red lines show the 60% interval in which non-extreme values are likely to fall.",null,null
77,venue SIGIR ECIR CIKM,null,null
78,years 1995­2014 2005­2014 2005­2014,null,null
79,"papers 2,413 759 2,620",null,null
80,"stats 1,159 short, 1,254 long 346 short, 413 long 1,015 short, 1,605 long;",null,null
81,Table 1: IR research paper corpora.,null,null
82,"To summarize, if we sample 103 mean average precisions from a distribution centered at 0.2705, there is a 20% chance the maximum sampled MAP would be greater than 0.303, and a 20% chance the minimum sampled MAP would be less than 0.2378. These bounds are outside of the 95% confidence interval around 0.2705, so would likely be considered statistically significantly different than 0.2705, even if the systems turned out to be equivalent over a much larger sample of topics. Figure 3 illustrates this, comparing the normal distribution and its 95% confidence interval to its extreme value distributions and the corresponding 60% interval in which non-extreme values are likely to fall.",null,null
83,"The conclusion of this example is that there is a wide range of possible MAPs that are likely to be observed when sampling 100 from this distribution, significantly wider than is implied from its 95% confidence interval. The fact that the largest of them is 0.303 is random; under slightly different conditions that same system could have produced a MAP closer to 0.2378, and a system with a MAP of 0.24 could have produced a MAP of 0.3. Yet the change from 0.2378 to 0.303 represents a 27% improvement in effectiveness.",null,null
84,4. ANALYSIS OF IR EXPERIMENTS,null,null
85,"In this section we analyze the IR literature to find distributions of effectiveness for different standard collections. We have a corpus of IR conference papers from 1995­2014, some statistics of which are shown in Table 1.We searched this corpus for papers using some standard collections: the Wall Street Journal (WSJ) and Associate Press (AP) collections on TREC disks, the GOV2 collection, the WT10g collection, and the TREC Robust 2004 track collection. We transcribed results from these papers, specifically mean effectiveness results. Then for a collection and a measure, we have a set of mean effectiveness values that we can analyze.",null,null
86,749,null,null
87,collection N,null,null
88,µ,null,null
89, max,null,null
90,Robust '04 55 0.2660 0.0024 0.3591,null,null
91,WSJ,null,null
92,31 0.2577 0.0108 0.4033,null,null
93,AP,null,null
94,31 0.2091 0.0096 0.2982,null,null
95,GOV2,null,null
96,17 0.2523 0.0144 0.3806,null,null
97,WT10g,null,null
98,17 0.1721 0.0059 0.2352,null,null
99,Table 2: Summary statistics on mean average precisions reported in published IR papers for different standard reusable collections.,null,null
100,collection Robust '04 WSJ AP GOV2 WT10g,null,null
101,µ 0.3448 0.3768 0.2747 0.3489 0.2227,null,null
102,"±20% c.i. (0.3384, 0.3591) (0.3502, 0.4033) (0.2513, 0.2982) (0.3170, 0.3806) (0.2096, 0.2352)",null,null
103,# above l.b. 3 5,null,null
104,12 6 1,null,null
105,Table 3: Means of distributions that could produce the maximum values in Table 2 along with the 60% confidence interval for non-extreme values. The final column is the number of MAPs greater than the lower bound.,null,null
106,"Table 2 shows summary statistics about data sets. Each row gives the number of results we transcribed (N ), the mean of those results (µ), their standard deviation (), and the maximum MAP in our sample. Our N s are fairly low, and necessarily a lower bound on the actual value of N . (In fact N cannot be known, since it includes experiments done but never published.)",null,null
107,Table 3 shows results of the analysis we described in Section 3.1. For each collection we report the mean µ of the normal distribution for which the maximum value reported in Table 2 has 80% cumulative probability in the MxVD--so the upper 20th percentile value in this table is the same as the maximum in Table 2. The lower 20th percentile is the value of MAP at the 20th percentile in the MnVD for the distibution centered at µ . These numbers are essentially a mean and 60% confidence bound (like the one in Figure 3) for a distribution that reasonably could have produced the maximum observed value for each collection.,null,null
108,"The lower limit of the confidence interval is the value we are most interested in, as it gives an idea of how low measured effectiveness could be while intrinsic effectiveness is still competitive with the best observed effectiveness. Note that the ranges are wide, with the upper bound up to 20% higher than the lower (for GOV2) and over 15% for three of the collections (WSJ, AP, GOV2). The range is lowest for Robust '04, because that collection has a much larger number of topics (249) and therefore lower standard error.",null,null
109,"The last column in Table 3 gives the number of systems in our sample with effectiveness greater than or equal to the minimum value. In all but WT10g there is more than one system that could reasonably be a candidate for ""best performing"" on the collection. If one performs slightly worse than another, it is most likely due to randomness.",null,null
110,5. CONCLUSION,null,null
111,We have argued that the best known result on any given test collection has a component of randomness due to the number of times the collection has been experimented with-- something that is out of the control of and unknown to most,null,null
112,"researchers. Moreover, we have shown that the best known result could come from a system whose intrinsic effectiveness is as much as 20% lower than its observed mean, while a system with much lower observed effectiveness could have intrinsic effectiveness up to 20% greater. This means that there is a wide range of possible overlap in effectiveness, more than what is implied by the standard deviation normally computed for significance testing, due solely to the effect of reusing the collection, and enough that results that are statistically significantly different may actually not be once the extreme value distributions are taken into account.",null,null
113,"This means there are extra considerations when reusing test collections and when comparing to best known results. The danger of reusable test collections is that the longer they are used, the more likely it is that an extreme value will be observed by chance alone. This implies that we must mentally adjust reported results downward some, particularly for older or very popular collections, and especially for methods that have not been shown to consistently work across collections. A relatively simple retrieval approach like BM25 that we know to work well in many different settings, is likely to be a better point of comparison than a much more complex model that happens to have the highest effectiveness on a single collection.",null,null
114,"It also suggests that it is not always beneficial to rely on reusable test collections to advance the field. Proprietary collections can be beneficial in that they will not be used by as many different researchers, and thus their N may remain relatively small. Strictly non-reusable collections can never have N > 1, and therefore will never have an issue with extreme values being observed due to large N . Therefore it is probably best for the field to publish a portfolio of results across reusable test collections (which will always be good for unit testing, for prototyping, for training, and for failure analysis), proprietary collections (which can include data unavailable outside of the group that owns it, and therefore suggest new avenues of discovery), and non-reusable collections (which should be considered the true ""test set"").",null,null
115,"Acknowledgments This material is based upon work supported by the National Science Foundation under Grant No. IIS-1350799. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.",null,null
116,6. REFERENCES,null,null
117,"[1] B. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. ACM TOIS, 30(1), 2012.",null,null
118,"[2] S. Coles. An Introduction to Statistical Modeling of Extreme Values. Springer, 2001.",null,null
119,"[3] M. Smucker, J. Allan, and B. Carterette. A comparison of statistical significance tests for information retrieval evaluation. In Proceedings of CIKM, pages 623­632, 2007.",null,null
120,"[4] J. Tague. The pragmatics of information retrieval evaluation. pages 59­102. Buttersworth, 1981.",null,null
121,"[5] C. J. van Rijsbergen. Information Retrieval. Butterworths, London, UK, 1979.",null,null
122,"[6] E. M. Voorhees and D. Harman. Overview of the Seventh Text REtrieval Conference (TREC-7). In Proceedings of the Seventh Text REtrieval Conference (TREC-7), pages 1­24, 1999.",null,null
123,[7] E. W. Weisstein. Gumbel distribution. From MathWorld­A Wolfram Web Resource. http://mathworld.wolfram.com/GumbelDistribution.html.,null,null
124,750,null,null
125,,null,null
