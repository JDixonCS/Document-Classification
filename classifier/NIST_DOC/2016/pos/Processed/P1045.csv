,sentence,label,data
0,Two Sample T-tests for IR Evaluation: Student or Welch?,null,null
1,Tetsuya Sakai,null,null
2,"Waseda University, Japan.",null,null
3,tetsuyasakai@acm.org,null,null
4,ABSTRACT,null,null
5,"There are two well-known versions of the t-test for comparing means from unpaired data: Student's t-test and Welch's t-test. While Welch's t-test does not assume homoscedasticity (i.e., equal variances), it involves approximations. A classical textbook recommendation would be to use Student's t-test if either the two sample sizes are similar or the two sample variances are similar, and to use Welch's t-test only when both of the above conditions are violated. However, a more recent recommendation seems to be to use Welch's t-test unconditionally. Using past data from both TREC and NTCIR, the present study demonstrates that the latter advice should not be followed blindly in the context of IR system evaluation. More specifically, our results suggest that if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's t-test may not be reliable.",null,null
6,Keywords,null,null
7,statistical significance; test collections; topics; variances,null,null
8,1. INTRODUCTION,null,null
9,"The present study concerns IR evaluation where two means from different samples need to be compared. The classical approach for this would be to employ a two-sample (i.e., unpaired) t-test to discuss whether, given the observed sample means, the population means may be different. There are two well-known versions of the two-sample t-test: Student's t-test and Welch's t-test. While Welch's t-test does not assume homoscedasticity (i.e., equal variances), it involves approximations. A classical textbook recommendation would be to use Student's t-test if either the two sample sizes n1, n2 are similar or the two sample variances V1, V2 are similar, and to use Welch's t-test only when both of the above conditions are violated [3]. However, a more recent recommendation seems to be to use Welch's t-test unconditionally. For example, Daniel Laken's blog posted on January 26, 2015 recommends researchers to ""Always use Welch's t-test instead of Student's t-test,"" while demonstrating the superiority of Welch's t-test using simu-",null,null
10,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '16, July 17 - 21, 2016, Pisa, Italy",null,null
11,c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2914684,null,null
12,"lated data1. The t.test function provided in the stats library of the R language uses Welch's t-test by default2; hence researchers who use this function as a black box may well be using Welch's t-test all the time. In fact, in as far back as 1981, Gans [1] recommended ""the automatic use of the Welch test alone"" as an option, based on simulations. The present study seeks to obtain the right recommendations for the purpose of IR system evaluation using real data from TREC and NTCIR.",null,null
13,2. PRIOR ART,null,null
14,"In the IR evaluation literature, researchers have focussed mainly on the paired data setting, because the most basic method for comparing two IR systems is to use the same test collection with a single topic set to compare two systems. For example, Smucker et al. [7] compared the sign test, the Wilcoxon signed rank test, the paired t-test, the bootstrap test and the randomisation test from the viewpoint of how similar the p-values of different test types are to one another, and concluded that the use of the two nonparametric tests (sign and Wilcoxon) should be discontinued. Urbano et al. [8] conducted a follow-up study on the same set of paired significance tests, using repeated topic set splitting experiments in a way similar to earlier studies (e.g. [10]) to quantify the discrepancies across the pairs of topic sets for comparing two systems. Contrary to the recommendation by Smucker et al., Urbano et al. report that ""the permutation test is not optimal under any criterion.""",null,null
15,"In contrast to the aforementioned studies, the present study concerns two-sample t-tests for comparing two means, with sample sizes n1, n2. Possible applications of two-sample tests in IR include comparing sets of clicks from two different search engines, between-subject design user experiments, and comparing the ""hardness"" of two test collections using the same IR system. Sakai [4] used the two-sample bootstrap test (in addition to the paired bootstrap test) for the purpose of comparing different evaluation measures in terms of ""discriminative power.""",null,null
16,3. T-TEST: STUDENT'S AND WELCH'S,null,null
17,The common assumptions are as follows. We have scores,null,null
18,"x11, . . . , x1n1 that each obey N (1, 12), as well as x21, . . . , x2n1",null,null
19,"that each obey N (2, 22). The population means and variances",null,null
20,"(·'s and ·2's) are unknown, and we want to test if 1 ,"" 2,""",null,null
21,given sample means x¯1,null,null
22,",",null,null
23,1 n1,null,null
24,"n1 j,1",null,null
25,x1j,null,null
26,and x¯2,null,null
27,",",null,null
28,1 n2,null,null
29,"n2 j,1",null,null
30,x2j,null,null
31,.,null,null
32,"Let S1 ,",null,null
33,"n1 j,1",null,null
34,(x1j,null,null
35,"- x¯1)2, S2",null,null
36,",",null,null
37,"n2 j,1",null,null
38,(x2j,null,null
39,-,null,null
40,x¯2)2,null,null
41,for,null,null
42,later,null,null
43,purposes.,null,null
44,1http://daniellakens.blogspot.nl/2015/01/ always-use-welchs-t-test-instead-of.html 2http://127.0.0.1:27533/library/stats/html/t.test.html,null,null
45,1045,null,null
46,3.1 Student's t-test,null,null
47,"Student's two-sample t-test further assumes homoscedasticity: 12 ,"" 22. While this is a strong assumption, it is also known that this test is quite robust to assumption violations. For this test, we""",null,null
48,"first define a pooled variance V , (S1 + S2)/ where  is the degree of freedom for V given by  ,"" 1 +2, 1 "","" n1 -1, 2 "", n2 - 1. The test statistic is:",null,null
49,"t0 ,",null,null
50,x¯1 - x¯2 V (1/n1 + 1/n2),null,null
51,(1),null,null
52,"which is compared against t(; ), the critical t value for  , n1 + n2 - 2 degrees of freedom with the significance level of .",null,null
53,3.2 Welch's t-test,null,null
54,"The good news about Welch's t-test is that it does not assume homoscedasticity; the bad news is that it involves approximations [3], as briefly discussed below. Let V1 ,"" S1/1, V2 "","" S2/2. For this test, the test statistic is""",null,null
55,"tw0 ,",null,null
56,x¯1 - x¯2 V1/n1 + V2/n2,null,null
57,(2),null,null
58,"which is compared against t(; ), where",null,null
59,",",null,null
60,(,null,null
61,V1 n1,null,null
62,+,null,null
63,V2 n2,null,null
64,)2/{,null,null
65,(V1/n1 1,null,null
66,)2,null,null
67,+,null,null
68,(V2/n2 2,null,null
69,)2,null,null
70,},null,null
71,.,null,null
72,(3),null,null
73,Welch's t-test approximates the distribution of the following statistic by a 2 distribution with 0 degrees of freedom:,null,null
74,W,null,null
75,",",null,null
76,0(,null,null
77,V1 n1,null,null
78,+,null,null
79,V2 n2,null,null
80,)/(,null,null
81,12 n1,null,null
82,+,null,null
83,22 n2,null,null
84,),null,null
85,.,null,null
86,(4),null,null
87,"Furthermore, it estimates 0 as ^0 ,  using Eq. 3. Do these approximations have any consequences for IR evaluation?",null,null
88,3.3 Analytical Relationships,null,null
89,"Nagata [3] clarifies the relationship between the above two ttests analytically. Let a ,"" n2/n1, b "", V2/V1. Then it is easy to derive that the ratio of the two test statictics tw0/t0 is given by:",null,null
90,tw0 t0,null,null
91,","" g(a, b) "",",null,null
92,(a,null,null
93,+ 1){n1(ab + 1) - (b + 1)} (a + b)(n1(a + 1) - 2),null,null
94,.,null,null
95,(5),null,null
96,"Note that g(1, b) ,"" g(a, 1) "","" 1. Hence, if either n1 "", n2 or V1 ,"" V2 holds, then t0 "","" tw0 holds. In practice, if the larger sample is no larger than 1.5 times the other, or if the larger variance is no larger than 1.5 times the other, t0 and tw0 will differ by at most 20% or so [3]. As for the degrees of freedom, it can be shown that:""",null,null
97,","" h(a, b)""",null,null
98,",",null,null
99,{a2(an1,null,null
100,(a + b)2(n1 - 1)(an1 - 1) - 1) + b2(n1 - 1)}{(a + 1)n1,null,null
101,- 2},null,null
102,.,null,null
103,(6),null,null
104,"Since h(1, 1) ,"" 1 holds, having n1 "", n2 and V1 , V2 is a sufficient condition for obtaining  ,"" . Also, it can be verified that h(a, b) "", / is much smaller than one if b , V2/V1 is close to one and a ,"" n2/n1 is far from one. That is, Welch's t-test""",null,null
105,has relatively low statistical power (due to its degree of freedom  being much smaller than Student's ) when the variances are,null,null
106,roughly equal but the sample sizes are quite different.,null,null
107,4. EXPERIMENTS,null,null
108,"In order to compare Student's and Welch's t-tests in terms of reliability, we adopt a method similar to that of Webber et al. [11]: given a topic set of size n, with m runs that processed these topics,",null,null
109,Table 1: Test collections and runs used in this study.,null,null
110,TREC99,null,null
111,NTCIR97,null,null
112,"Topics (n) 601-700 minus 672 (99) T41-385 minus 86, 331, 362 (97)",null,null
113,Runs (m) TREC 2004 robust (110) NTCIR-7 IR4QA Chinese (40),null,null
114,Qrels,null,null
115,L2: relevant; L1: partially relevant; L0: judged nonrelevant,null,null
116,Table 2: Sample size ratios experimented in this study.,null,null
117,Target ratio,null,null
118,Actual ratio (TREC99) Actual ratio (NTCIR97),null,null
119,"50:50 (a , 1.0)",null,null
120,50:49,null,null
121,50:47,null,null
122,"40:60 (a , 1.5)",null,null
123,40:59,null,null
124,40:57,null,null
125,"30:70 (a , 2.3) 10:90 (a , 9.0)",null,null
126,30:69 10:89,null,null
127,30:67 10:87,null,null
128,"randomly partition the topics into two sets of size n1 and n2, respectively. For each of the m runs and a given evaluation measure, conduct a two-sided, two-sample test to see if the two means for the same run are statistically significant. The ground truth is that they are not, since the scores actually come from the same system. The random partitioning is done B ,"" 1000 times, so a test collection with m runs will yield Bm "", 1000m p-values for each significance test type with a given evaluation measure.",null,null
129,"Table 1 shows a summary of the two data sets used in this study. We chose them because (a) we wanted about n ,"" 100 topics (or more if available) with graded relevance assessments; (b) we wanted data (with many runs) from different evaluation conferences to ensure generalisability. """"TREC99"""" comprises 110 runs from the TREC 2004 robust track [9], with 99 robust track topics. While this data set has many runs, the 99 topics come from two robust track rounds: 50 from TREC 2003 and 49 from 2004. In contrast, """"NTCIR97,"""" which comprises 40 Simplified Chinese runs from the NTCIR-7 ACLIA IR4QA task [6], uses 97 topics that originate from a single round of the task.""",null,null
130,"For each data set with a given evaluation measure, we experimented with four different sample size ratios a ,"" n2/n1 as shown in Table 2 to obtain a total of 4000m p-values. Recall that, according to Nagata [3], Student's and Welch's t statistics should not be vastly different for the a "", 1 (n1 : n2 , 50 : 50) and a , 1.5 (n1 : n2 ,"" 40 : 60) settings, regardless of how the two sample variances differ. We experimented with four evaluation measures: (binary) Average Precision (AP), Q-measure (Q), normalised Discounted Cumulative Gain (nDCG) and normalised Expected Reciprocal Rank (nERR). Unlike the other three measures, nERR is known to be suitable for navigational information needs due to its diminishing return property; for this very reason, it is known to be statistically less stable than the other measures [5].""",null,null
131,5. RESULTS AND DISCUSSIONS,null,null
132,"Figure 1 plots Welch's p-values against Student's p-values for the 110,000 two-sample t-tests conducted with the TREC99 data, for nDCG ((a)-(d)) and nERR ((e)-(h)) with different target sample size ratios. The graphs for TREC99 with AP and Q, as well all all graphs for NTCIR97, are omitted due to lack of space. However, the overall picture is the same for all evaluation measures and across the two data sets, and we believe that our findings are general. In each graph, the blue rectangle represents the situation where Student's t-test obtains a p-value smaller than  ,"" 0.05 (i.e., a false positive) while Welch's t-test does not; the red rectangle represents the opposite situation; the bottom left square represents the situation where both tests obtain a false alarm at  "", 0.05. It can be observed that when the target sample size ratio is a , 1 (n1 : n2 ,"" 50 : 50), the two tests are indeed virtually identical and false alarms are very rare; as we gradually increase the sample size ratio until it reaches a "", 9.0 (n1 : n2 ,"" 10 : 90), we obtain more and more false alarms on both sides of the diagonal.""",null,null
133,1046,null,null
134,Figure 1: Welch's vs. Student's p-values: TREC99; 110 runs; nDCG (top) and nERR (bottom).,null,null
135,"Tables 3 and 4 show the false positive rates for all of our TREC99 and NTCIR97 experiments, respectively. Based on the discussion provided in Section 3.3, we categorised the observations into three classes: the first is for those where the variance ratio satisfies 2/3  b  3/2: recall that Student's and Welch's t statistics are expected to be similar to each other in this situation. The other two classes (b < 2/3 and b > 3/2) represent the situations where the sample variances are very different. For example, Table 3 Section (III) Column (d) provides the following information about our TREC99 experiments for nDCG with the sample size ratio a , 9.0 (with the actual sample sizes n1 ,"" 10, n2 "", 89 as shown in Table 1):",null,null
136,"· For 64,447 out of the 110,000 observations, the sample variance ratio b ,"" V2/V1 satisfied 2/3  b  3/2; for these observations, the false positive rate was 4.0% for Student's t-test and 2.6% for Welch's t-test;""",null,null
137,"· For 16,614 out of the 110,000 observations, b < 2/3; for these observations, the false positive rate was 4.9% for Student's t-test and 0.7% for Welch's t-test;",null,null
138,"· For 28,939 out of the 110,000 observations, b > 3/2; for these observations, the false positive rate was 5.6% for Student's t-test and 14.1% for Welch's t-test;",null,null
139,"· Overall, for the 110,000 observations, the false positive rate was 4.6% for Student's t-test and 5.3% for Welch's t-test. Thus, Welch's t-test slightly underperforms Student's, due to its very high false positive rate for the b > 3/2 setting.",null,null
140,"More generally, we can observe the following consistent trends from Tables 3 and 4:",null,null
141,"· When the two sample sizes are equal (Column (a)), Student's and Welch's t-tests perform equally well, regardless of the range of b3. The overall false positive rates are 4.9-5.2%.",null,null
142,"3When n1 ,"" n2, note that the variance ratio conditions b < 2/3""",null,null
143,"· When the two variances are similar (2/3  b  3/2), the false positive rates of the two tests are very small (1.0-4.8%), although, as discussed immediately below, Student's t-test yields more false positive than Welch's when the sample size ratio a , n2/n1 is extreme (Column (d));",null,null
144,"· As we increase the sample size ratio a ,"" n2/n1, Welch's ttest yields more and more false positives when b "","" V2/V1 > 3/2. That is, if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's ttest may not be reliable for two-sample IR evaluation. In particular, when a "", n2/n1 ,"" 9 (Column (d)), the false positive rates for Welch's t-test are 14.1-24.6% whereas those for Student's t-test are only 4.4-13.5%. Whereas, as we increase the sample size ratio a, Student's t-test yields more and more false positives when b  3/2 (i.e., 2/3  b  3/2 or b < 2/3), but this tendency is not as marked as Welch's for the b > 3/2 range. As a result, in terms of the overall false positive rates, Welch's t-test is actually slightly less reliable than the Student's t-test when a is very large.""",null,null
145,"The above results, based on real IR system runs from both TREC and NTCIR, suggest that the advice ""Always use Welch's t-test instead of Student's t-test"" should not be followed blindly in IR system evaluation.",null,null
146,6. CONCLUSIONS,null,null
147,"For the purpose of reliable IR system evaluation, we compared two versions of two-sample t-tests: Student's t-test (which assumes homoscedasticity) and Welch's t-test (which relies on approximated distributions). Our topic set splitting experiments with runs from",null,null
148,"and b > 3/2 are equivalent: it is just a matter of swapping the two samples, since the two tests are symmetric with respect to the two samples. So we should expect similar results in Column (a) for these two ranges of b. The slight caveat is that we actually have n1 n2 rather than n1 ,"" n2, as n1 + n2 "", 99 or 97.",null,null
149,1047,null,null
150,"Table 3: TREC99 false positives at  , 0.05: Student/Welch.",null,null
151,The higher false positive rate in each condition is shown in,null,null
152,bold. The total number of observations for each variance ra-,null,null
153,tio is shown in parentheses.,null,null
154,"(a) 50:50 a , 1.0",null,null
155,"(b) 40:60 a , 1.5",null,null
156,"(c) 30:70 a , 2.3",null,null
157,"(d) 10:90 a , 9.0",null,null
158,2/3  b  3/2 b < 2/3,null,null
159,b > 3/2,null,null
160,All,null,null
161,2/3  b  3/2 b < 2/3,null,null
162,b > 3/2,null,null
163,All,null,null
164,2/3  b  3/2 b < 2/3,null,null
165,b > 3/2,null,null
166,All,null,null
167,2/3  b  3/2 b < 2/3,null,null
168,b > 3/2,null,null
169,All,null,null
170,"3.5%/3.5% (91,286)",null,null
171,"11.9%/12.0% (9,192)",null,null
172,"15.0%/14.7% (9,522)",null,null
173,"5.2%/5.2% (110,000)",null,null
174,"3.7%/3.7% (90,299)",null,null
175,"11.1%/11.1% (9,620)",null,null
176,"13.3%/13.2% (10,081)",null,null
177,"5.2%/5.2% (110,000)",null,null
178,"4.4%/4.4% (94,936)",null,null
179,"7.7%/7.7% (7,640)",null,null
180,"8.4%/8.3% (7,424)",null,null
181,"4.9%/4.9% (110,000)",null,null
182,"4.8%/4.7% (107,590) 10.5%/10.8% (1,165) 13.9%/13.5% (1,245) 4.9%/4.9% (110,000)",null,null
183,(I) AP 3.4%/3.4%,null,null
184,"(90,405) 10.9%/8.5%",null,null
185,"(8,887) 13.0%/15.7%",null,null
186,"(10,708) 4.9%/5.0% (110,000)",null,null
187,(II) Q 3.5%/3.5%,null,null
188,"(89,563) 10.5%/7.9%",null,null
189,"(9,252) 11.6%/14.3%",null,null
190,"(11,185) 4.9%/5.0% (110,000)",null,null
191,(III) nDCG 4.4%/4.4%,null,null
192,"(94,480) 7.0%/5.4%",null,null
193,"(7,076) 7.9%/9.5%",null,null
194,"(8,444) 4.9%/4.9% (110,000)",null,null
195,"(IV) nERR 4.4%/4.4% (107,161) 10.4%/8.3%",null,null
196,"(1,126) 14.4%/16.8%",null,null
197,"(1,713) 4.6%/4.7% (110,000)",null,null
198,"3.2%/3.1% (87,833)",null,null
199,"9.7%/5.7% (9,374)",null,null
200,"9.9%/15.9% (12,793)",null,null
201,"4.5%/4.8% (110,000)",null,null
202,"3.5%/3.4% (86,872)",null,null
203,"8.9%/4.9% (9,763)",null,null
204,"8.5%/14.2% (13,365)",null,null
205,"4.6%/4.8% (110,000)",null,null
206,"4.2%/4.2% (90,837)",null,null
207,"6.6%/4.0% (7,710)",null,null
208,"7.6%/12.1% (11,453)",null,null
209,"4.7%/5.0% (110,000)",null,null
210,"4.3%/4.3% (105,953) 6.0%/3.1% (1,196) 14.1%/20.6% (2,851) 4.6%/4.7% (110,000)",null,null
211,"2.8%/1.6% (62,674)",null,null
212,"7.7%/0.7% (16,938)",null,null
213,"6.0%/18.4% (30,388)",null,null
214,"4.5%/6.1% (110,000)",null,null
215,"3.2%/1.9% (61,402)",null,null
216,"7.6%/0.7% (17,285)",null,null
217,"5.5%/16.9% (31,313)",null,null
218,"4.5%/6.0% (110,000)",null,null
219,"4.0%/2.6% (64,447)",null,null
220,"4.9%/0.7% (16,614)",null,null
221,"5.6%/14.1% (28,939)",null,null
222,"4.6%/5.3% (110,000)",null,null
223,"3.0%/2.1% (87,017)",null,null
224,"1.7%/0.1% (7,485)",null,null
225,"13.5%/24.2% (15,498)",null,null
226,"4.4%/5.1% (110,000)",null,null
227,"both TREC and NTCIR are consistent across different evaluation measures and across these two different IR venues. While neither our equal variance settings nor our equal sample size settings do not demonstrate any advantages of Student's t-test over Welch's t-test, our results do suggest that if the sample sizes differ substantially and if the larger sample has a substantially larger variance, Welch's t-test may be less reliable. Hence we argue that the advice ""Always use Welch's t-test instead of Student's t-test"" should not be followed blindly in IR system evaluation.",null,null
228,"In practice, we recommend IR researchers to examine the sample sizes n1, n2 and the sample variances V1, V2 first and then make a conscious decision, rather than (say) relying on a default setting in the t.test function provided in R. We also recommend IR researchers to report explicitly which version of the two-sample ttest was used in their experiments, even if we may be able to spot a Welch's t-test when the degree of freedom reported is not an integer (Eq. 3).",null,null
229,Acknowledgement,null,null
230,I would like to thank Professor Yasushi Nagata for his helpful comments on my results.,null,null
231,7. REFERENCES,null,null
232,"[1] D. J. Gans. Use of a preliminary test in comparing two sample means. Communications in Statistics - Simuation and Computation, 10(2):163­174, 1981.",null,null
233,"Table 4: NTCIR97 false positives at  , 0.05: Student/Welch.",null,null
234,The higher false positive rate in each condition is shown in,null,null
235,bold. The total number of observations for each variance ra-,null,null
236,tio is shown in parentheses.,null,null
237,"(a) 50:50 a , 1.0",null,null
238,"(b) 40:60 a , 1.5",null,null
239,"(c) 30:70 a , 2.3",null,null
240,"(d) 10:90 a , 9.0",null,null
241,2/3  b  3/2 b < 2/3,null,null
242,b > 3/2,null,null
243,All,null,null
244,2/3  b  3/2 b < 2/3,null,null
245,b > 3/2,null,null
246,All,null,null
247,2/3  b  3/2 b < 2/3,null,null
248,b > 3/2,null,null
249,All,null,null
250,2/3  b  3/2 b < 2/3,null,null
251,b > 3/2,null,null
252,All,null,null
253,"4.3%/4.3% (33,683) 8.8%/9.2% (3,233) 9.7%/8.9% (3,084) 5.1%/5.0% (40,000)",null,null
254,"3.9%/3.9% (33,043) 9.0%/9.3% (3,575) 10.4%/9.9% (3,382) 4.9%/4.9% (40,000)",null,null
255,"1.8%/1.8% (29,136) 12.9%/13.5% (5,578) 13.7%/13.0% (5,286) 4.9%/4.9% (40,000)",null,null
256,"2.0%/2.0% (32,698) 17.9%/18.5% (3,715) 20.1%/19.2% (3,587) 5.1%/5.1% (40,000)",null,null
257,(I) AP 4.3%/4.3%,null,null
258,"(33,587) 9.3%/6.1%",null,null
259,"(2,965) 9.0%/11.8%",null,null
260,"(3,448) 5.0%/5.1%",null,null
261,"(40,000) (II) Q",null,null
262,"4.1%/4.1% (33,085)",null,null
263,"10.3%/7.1% (3,203)",null,null
264,"9.5%/11.9% (3,712)",null,null
265,"5.1%/5.1% (40,000) (III) nDCG",null,null
266,"1.8%/1.8% (29,193)",null,null
267,"14.2%/11.1% (5,076)",null,null
268,"12.6%/16.1% (5,731)",null,null
269,"4.9%/5.0% (40,000) (IV) nERR",null,null
270,"1.7%/1.7% (32,303)",null,null
271,"18.0%/14.7% (3,498)",null,null
272,"18.7%/23.2% (4,199)",null,null
273,"4.9%/5.1% (40,000)",null,null
274,"4.2%/4.2% (32,716)",null,null
275,"10.7%/5.1% (2,949)",null,null
276,"7.5%/14.8% (4,335)",null,null
277,"5.0%/5.4% (40,000)",null,null
278,"4.1%/4.0% (32,135)",null,null
279,"10.7%/5.6% (3,300)",null,null
280,"8.1%/15.4% (45,65)",null,null
281,"5.1%/5.4% (40,000)",null,null
282,"1.8%/1.7% (27,739)",null,null
283,"14.9%/8.2% (5,318)",null,null
284,"9.9%/17.7% (6,943)",null,null
285,"4.9%/5.3% (40,000)",null,null
286,"1.5%/1.4% (31,171)",null,null
287,"18.2%/10.7% (3,625)",null,null
288,"15.1%/24.5% (5,204)",null,null
289,"4.8%/5.3% (40,000)",null,null
290,"3.6%/2.3% (24,263)",null,null
291,"7.2%/0.4% (6,277)",null,null
292,"6.8%/23.4% (9,460)",null,null
293,"4.9%/7.0% (40,000)",null,null
294,"3.5%/2.2% (23,172)",null,null
295,"7.6%/0.4% (6,766)",null,null
296,"6.4%/23.2% (10,062)",null,null
297,"4.9%/7.2% (40,000)",null,null
298,"2.2%/1.1% (18,548)",null,null
299,"11.7%/1.1% (8,533)",null,null
300,"4.4%/22.4% (12,919)",null,null
301,"4.9%/8.0% (40,000)",null,null
302,"2.2%/1.0% (21,570)",null,null
303,"12.4%/1.7% (7,159)",null,null
304,"5.0%/24.6% (11,270)",null,null
305,"4.9%/7.8% (40,000)",null,null
306,"[2] D. Hawking and N. Craswell. The very large collection and web tracks. In E. M. Voorhees and D. K. Harman, editors, TREC: Experiment and Evaluation in Information Retrieval, chapter 9. The MIT Press, 2005.",null,null
307,"[3] Y. Nagata. How to Understand Statistical Methods (in Japanese). Nikkagiren, 1996.",null,null
308,"[4] T. Sakai. Evaluating evaluation metrics based on the bootstrap. In Proceedings of ACM SIGIR 2006, pages 525­532, 2006.",null,null
309,"[5] T. Sakai. Metrics, statistics, tests. In PROMISE Winter School 2013: Bridging between Information Retrieval and Databases (LNCS 8173), pages 116­163, 2014.",null,null
310,"[6] T. Sakai, N. Kando, C.-J. Lin, T. Mitamura, H. Shima, D. Ji, K.-H. Chen, and E. Nyberg. Overview of the NTCIR-7 ACLIA IR4QA task. In Proceedings of NTCIR-7, pages 77­114, 2008.",null,null
311,"[7] M. D. Smucker, J. Allan, and B. Carterette. A comparison of statistical significance tests for information retrieval evaluation. In Proceedings of ACM CIKM 2007, pages 623­632, 2007.",null,null
312,"[8] J. Urbano, M. Marrero, and D. Martín. A comparison of the optimality of statistical significance tests for information retrieval evaluation. In Proceedings of ACM SIGIR 2013, pages 925­928, 2013.",null,null
313,"[9] E. M. Voorhees. Overview of the TREC 2004 robust retrieval track. In Proceedings of TREC 2004, 2005.",null,null
314,"[10] E. M. Voorhees. Topic set size redux. In Proceedings of ACM SIGIR 2009, pages 806­807, 2009.",null,null
315,"[11] W. Webber, A. Moffat, and J. Zobel. Score standardization for inter-collection comparison of retrieval systems. In Proceedings of ACM SIGIR 2008, pages 51­58, 2008.",null,null
316,1048,null,null
317,,null,null
