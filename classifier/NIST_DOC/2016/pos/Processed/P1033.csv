,sentence,label,data
0,Toward Estimating the Rank Correlation between the Test Collection Results and the True System Performance,null,null
1,Julián Urbano,null,null
2,"Universitat Pompeu Fabra Barcelona, Spain",null,null
3,urbano.julian@gmail.com,null,null
4,Mónica Marrero,null,null
5,"National Supercomputing Center Barcelona, Spain",null,null
6,monica.marrero@bsc.es,null,null
7,ABSTRACT,null,null
8,"The Kendall  and AP rank correlation coefficients have become mainstream in Information Retrieval research for comparing the rankings of systems produced by two different evaluation conditions, such as different effectiveness measures or pool depths. However, in this paper we focus on the expected rank correlation between the mean scores observed with a test collection and the true, unobservable means under the same conditions. In particular, we propose statistical estimators of  and AP correlations following both parametric and non-parametric approaches, and with special emphasis on small topic sets. Through large scale simulation with TREC data, we study the error and bias of the estimators. In general, such estimates of expected correlation with the true ranking may accompany the results reported from an evaluation experiment, as an easy to understand figure of reliability. All the results in this paper are fully reproducible with data and code available online.",null,null
9,Keywords,null,null
10,Evaluation; Test Collection; Correlation; Kendall; Average Precision; Estimation,null,null
11,1. INTRODUCTION,null,null
12,"The Kendall  [3] and AP [8] rank correlation coefficients are widely used in Information Retrieval to compare rankings of systems produced by different evaluation conditions, such as different assessors [6], effectiveness measures [4] or topic sets [1]. One reason for this success is their simplicity: they provide a single score that is easy to understand.",null,null
13,"In this paper we tackle the problem of estimating the correlation between the ranking of systems obtained with a test collection and the true ranking under the same conditions. Such estimates can make a nice companion to a set of evaluation results, as a single figure of the reliability of the experiment. Voorhees and Buckley [7] proposed to report a similar figure in terms of sensitivity, that is, the minimum",null,null
14,"Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",null,null
15,"SIGIR '16, July 17 - 21, 2016, Pisa, Italy",null,null
16,c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00,null,null
17,DOI: http://dx.doi.org/10.1145/2911451.2914752,null,null
18,"difference required between two systems to ensure a maximum error rate in relative comparisons. Common practice nowadays is to report the p-value of a statistical significance test run either for each pair of systems (e.g. t-test) or for the whole set (e.g. ANOVA and F -test). They provide a sense of confidence about individual pairs of systems or about a swap somewhere in the ranking, but they do not give a general idea of how similar the observed ranking is to the truth.",null,null
19,"We propose parametric and non-parametric approaches to estimate the  and AP correlations. Through large scale simulation with TREC data, we show that they have very low bias and small error even for mid-sized collections.",null,null
20,2. CORRELATION BETWEEN,null,null
21,TWO RANKINGS,null,null
22,"Let A ,"" a1, . . . , am and B "","" b1, . . . , bm be the mean scores of the same set of m systems as observed under two different evaluation conditions, such that ai and bi refer to the i-th system. In many situations we are interested in the distance between the two rankings. Considering systems in pairs, a distance can be computed by counting how many pairs are concordant or discordant between the two rankings: a pair is concordant if their relative order is the same in both rankings, and discordant if it is the opposite. Kendall [3] followed this idea to define his  correlation coefficient""",null,null
23," , #concordants-#discordants ,"" 1-2 #discordants , (1)""",null,null
24,total,null,null
25,total,null,null
26,"which evaluates to -1 when the rankings are reversed, +1 when they are the same, and 0 when there are as many concordant pairs as there are discordant. Note that the term #discordants/total can be interpreted as the expected value of a random experiment: pick two arbitrary systems and return 1 if they are discordant, or 0 if they are concordant. The Kendall  coefficient can thus be interpreted in terms of the probability of discordance.",null,null
27,"Yilmaz et al. [8] followed this idea to define a correlation coefficient with the same rationale as Average Precision. It is similar to Kendall  , but it penalizes more if swaps occur between systems at the top of the ranking, much like AP penalizes more if the non-relevant documents appear at the top of the results. In particular, they considered that one of the rankings, say B, is the true ranking and the other one is an estimate of it. The random experiment is now as follows: pick one system at random from A and another one ranked above it, and return 1 if they are discordant, or 0 if they are concordant. Their AP correlation coefficient can then be defined just as in (1) as follows:",null,null
28,1033,null,null
29,AP,null,null
30,",",null,null
31,1,null,null
32,-,null,null
33,2 m-,null,null
34,1,null,null
35,m,null,null
36,#discordants above i i-1,null,null
37,.,null,null
38,(2),null,null
39,"i,2",null,null
40,Note that AP also ranges between -1 and +1.,null,null
41,3. EXPECTED CORRELATION,null,null
42,WITH THE TRUE RANKING,null,null
43,"The previous section contemplated the case where we compute the correlation between two given rankings A and B. In this section we study the case where we are given a ranking A obtained with the sample of topics in the test collection, and want to estimate its correlation with the true ranking B over the population of topics, which is of course unknown. For simplicity, let us first assume that the systems are already sorted in descending order by their mean score. Let us further define Dij as the random variable that equals 1 if systems i and j are discordant and 0 otherwise, that is, whether they are swapped in the true ranking. Both  and AP can be re-defined from (1) and (2) in terms of Dij alone:",null,null
44,",",null,null
45,1,null,null
46,-,null,null
47,4 m(m -,null,null
48,1),null,null
49,m-1,null,null
50,m,null,null
51,"Dij ,",null,null
52,(3),null,null
53,"i,1 j,i+1",null,null
54,AP,null,null
55,",",null,null
56,1,null,null
57,-,null,null
58,2 m-1,null,null
59,m-1,null,null
60,i-1,null,null
61,Dij i-1,null,null
62,.,null,null
63,(4),null,null
64,"i,1 j,1",null,null
65,"Since they are just a linear combination of random variables, their expectations are as in (3) and (4) but replacing Dij with E[Dij]. Note that each Dij is a Bernoulli random variable, so its expectation is just the probability of discordance E[Dij] , P (µi - µj < 0) , pij. The problem of estimating the correlation with the true ranking thus boils down to estimating the probability that any two systems are swapped. The next subsection presents four ways of achieving this.",null,null
66,3.1 Estimating the Probability of Discordance,null,null
67,"Since each pij is estimated independently from the other systems, let us simplify notation here to just p. In addition, let X1, . . . , Xn be the differences in effectiveness between the two systems and for each of the n topics in the collection. The problem is therefore to estimate p ,"" P (µ < 0) from these n observations. Recall that systems are assumed to be ranked by mean observed scores, so X > 0.""",null,null
68,In the following we present two parametric estimators based on the Central Limit Theorem (CLT) and then two non-parametric estimators based on resampling.,null,null
69,3.1.1 Maximum Likelihood (ML),null,null
70,"The CLT tells us that X is approximately normally distributed with mean µ and variance 2/n as n  . Using the cdf of the normal distribution we can therefore estimate the probability of discordance. However, our estimates are likely off with small samples (see Section 3.1.2), so we assume Xi  N (µ, 2) and employ the t distribution to account for the uncertainty in estimating 2. Standardizing, we have that n(X - µ)/  t(n - 1), so",null,null
71,"p , P (µ < 0)  Tn-1",null,null
72, -n,null,null
73,µ^ ^,null,null
74,",",null,null
75,(5),null,null
76,where Tn-1 is the cdf of the t distribution with n - 1 degrees of freedom. The estimates µ^ and ^ are computed via Maximum Likelihood as,null,null
77,"µ^ ,",null,null
78,X,null,null
79,",",null,null
80,1 n,null,null
81,"Xi,",null,null
82,(6),null,null
83,"^ ,"" s · Cn,""",null,null
84,(7),null,null
85,"s,",null,null
86,1 n-1,null,null
87,"(Xi - X)2,",null,null
88,"Cn ,",null,null
89,n,null,null
90,- 2,null,null
91,1,null,null
92,((n - 1)/2) (n/2),null,null
93,",",null,null
94,where s is the sample standard deviation. The Cn factor [2],null,null
95,"ensures that E[^] ,"" . This bias correction is applied because, even though s2 is an unbiased estimator of 2, by""",null,null
96,Jensen's inequality s is not an unbiased estimator of .,null,null
97,3.1.2 Minimum Squared Quantile Deviation (MSQD),null,null
98,The problem when estimating  from a small sample is,null,null
99,that the observations are likely to be concentrated around,null,null
100,"the mean and seldom occur near the tails. As a consequence,",null,null
101,(7) is likely to underestimate the true dispersion in the pop-,null,null
102,ulation. If the sample contains a few dozen observations this,null,null
103,"is not expected to be a problem, but with very small samples",null,null
104,"of, say, just 10 topics, it might be.",null,null
105,We propose a new and generic estimator to avoid this,null,null
106,problem. Let us consider a distribution function F with,null,null
107,parameter . A random sample from this distribution is,null,null
108,"expected to uniformly cover the quantile space, that is, all",null,null
109,"quantiles are equally likely to appear in the sample. Thus,",null,null
110,when we are given a sample we may force them to uniformly,null,null
111,cover the quantile space and then select the  that minimizes,null,null
112,"the observed deviations. For instance, if our sample contains",null,null
113,"only one observation, we force it to correspond to the quan-",null,null
114,tile 1/2; if we have two observations then we force them to,null,null
115,"be the quantiles 1/3 and 2/3. In general, if Ri is the rank of",null,null
116,"Xi within the sample, it will correspond to the Ri/(n + 1)",null,null
117,"quantile, which is F -1",null,null
118,Ri n+1,null,null
119,;,null,null
120,. The squared quantile devi-,null,null
121,ation of an observation Xi is therefore,null,null
122,"SQD(Xi; ) ,",null,null
123,F -1,null,null
124,Ri n+,null,null
125,1,null,null
126,;,null,null
127,2,null,null
128,- Xi .,null,null
129,The Minimum Squared Quantile Deviation estimator is then the one that minimizes the sum of squared deviations:,null,null
130,"^MSQD , arg min SQD (Xi; ).",null,null
131,"Let us assume again a normal distribution, so that",null,null
132,F -1,null,null
133,Ri n+,null,null
134,1,null,null
135,;,null,null
136,"µ,",null,null
137," ,"" µ +  2ei,""",null,null
138,"ei , erf-1",null,null
139,2,null,null
140,Ri n+,null,null
141,1,null,null
142,-,null,null
143,1,null,null
144,.,null,null
145,The sum of squared deviations is thus,null,null
146,µ2,null,null
147,-,null,null
148,2µ2e i,null,null
149,0,null,null
150,+,null,null
151,22e2i,null,null
152,-,null,null
153,2Xiµ,null,null
154,-,null,null
155, 2Xi 2ei,null,null
156,+,null,null
157,"Xi2,",null,null
158,"and the second term cancels out because ei ,"" 0. To find the µ and  that minimize this expression, we simply differentiate, equal to 0, and solve. The partial derivatives are""",null,null
159,dSQD dµ,null,null
160,",",null,null
161,dSQD d,null,null
162,",",null,null
163,"2µ - 2Xi , 2nµ - 2",null,null
164,4e2i,null,null
165,-,null,null
166," 2 2Xiei,",null,null
167,Xi and,null,null
168,"and therefore, the estimators are",null,null
169,1034,null,null
170,µ^,null,null
171,",",null,null
172,1 n,null,null
173,2,null,null
174,"^ ,",null,null
175,2,null,null
176,"Xi ,"" X,""",null,null
177,Xi · erf-1,null,null
178,2,null,null
179,Ri n+1,null,null
180,-,null,null
181,1,null,null
182,erf -1,null,null
183,2,null,null
184,Ri n+1,null,null
185,-,null,null
186,1,null,null
187,2,null,null
188,.,null,null
189,(8) (9),null,null
190,"As above, the probability of discordance is estimated with the cdf of the t distribution as in (5), but using estimators (8) and (9) instead of (6) and (7).",null,null
191,3.1.3 Resampling (RES),null,null
192,In both the ML and MSQD estimators above we assumed,null,null
193,"that scores are normally distributed, but this is clearly not",null,null
194,strictly true. A non-parametric alternative is the use of re-,null,null
195,sampling to estimate the sampling distribution of the mean,null,null
196,and from there the probability of discordance.,null,null
197,"Suppose we draw a random sample X1, . . . , Xn with re-",null,null
198,"placement from our original observations, and compute their",null,null
199,"sample mean X. This experiment is replicated T ,"" 1, 000""",null,null
200,"times,",null,null
201,yielding,null,null
202,sample,null,null
203,means,null,null
204,X,null,null
205,"1 ,",null,null
206,.,null,null
207,.,null,null
208,.,null,null
209,",",null,null
210,X,null,null
211, T,null,null
212,.,null,null
213,By the law of,null,null
214,"large numbers, the distribution of these sample means con-",null,null
215,verges to the sampling distribution of X as T  . The,null,null
216,probability of discordance can thus be estimated as the frac-,null,null
217,tion,null,null
218,of,null,null
219,times,null,null
220,that,null,null
221,X,null,null
222, i,null,null
223,is,null,null
224,negative:,null,null
225,p,null,null
226,",",null,null
227,P (µ,null,null
228,<,null,null
229,0),null,null
230,1 T,null,null
231,I,null,null
232,X,null,null
233, i,null,null
234,<,null,null
235,0,null,null
236,.,null,null
237,(10),null,null
238,3.1.4 Kernel Density (KD),null,null
239,"A potential problem with resampling from the original observations is again that estimates from very small samples are likely off. An alternative is to approximate the true pdf via Kernel Density Estimation, and use it to estimate the probability of discordance. The estimated pdf has the form",null,null
240,"f^(x) ,",null,null
241,1 nh,null,null
242,k,null,null
243,x - Xi h,null,null
244,",",null,null
245,"where k is the pdf of the kernel and h is the bandwidth. Next, we need to estimate the sampling distribution of the mean, which is basically the distribution of the sum of n variables drawn from f^. For n , 2 this requires the evaluation of the self-convolution of f^ as follows:",null,null
246,f^X+X (x),null,null
247,",",null,null
248,1 n2h2,null,null
249,ij,null,null
250,k,null,null
251,x-z -Xi h,null,null
252,k,null,null
253,z -Xj h,null,null
254,"dz,",null,null
255,"which involves the sum of n2 terms. In general, for n vari-",null,null
256,"ables this requires the evaluation of nn terms, which is clearly",null,null
257,"unfeasible even for small samples, so instead we resort to",null,null
258,"Monte Carlo methods. As with the RES estimator, we gen-",null,null
259,erate mean,null,null
260,"aXra.ndAomftesramT prleepXlic1a, t.i.o.n,sX, nthferopmrof^baabnidlitcyomofpudtiesctohre-",null,null
261,dance,null,null
262,is,null,null
263,estimated,null,null
264,as,null,null
265,the,null,null
266,fraction,null,null
267,of,null,null
268,times,null,null
269,that,null,null
270,X,null,null
271, i,null,null
272,is,null,null
273,nega-,null,null
274,"tive. We set T ,"" 1, 000 replications and use gaussian kernels.""",null,null
275,4. EVALUATION,null,null
276,4.1 Criteria,null,null
277,"There are two properties of the correlation estimators that we are interested in, namely error and bias. Error refers to the expected difference between the estimate and the truth. Here we measure absolute error, thus quantifying the expected magnitude of the error when estimating the correlation of a given collection:",null,null
278,"error ,"" E |^(A) -  (A, µ)| .""",null,null
279,"Even if the error is small, it could tend to be in the same direction, that is, over- or underestimating the correlation. Bias refers to this tendency, measured as the expected difference between the estimated and the true correlation:",null,null
280,"bias ,"" E ^(A) -  (A, µ) .""",null,null
281,"If the bias is positive it means that the estimator tends to overestimate the correlations. In general, we seek estimators with small error and zero bias.",null,null
282,"4.2 Methods, Data and Baselines",null,null
283,"From the above definitions it is evident that we need to know the true ranking of systems µ, but this is of course unknown. To solve this problem we resort to the simulation method proposed by Urbano [5]. Given the topic-by-system matrix of scores B from an existing collection, it generates a new matrix A with the scores by the same set of systems over a new and random set of topics. There are two important characteristics of this method that are appealing for us. First, the simulated scores are realistic, as they maintain the same distributions and correlations among systems as in the original collection. Second, it is designed to ensure that the expected mean score of a system is equal to the mean score in the original collection, that is, E As ,"" Bs. For us, this means that the true mean scores are fixed to be the mean scores in the original collection, that is, µs :"","" Bs. This allows us to analyze the error and bias of the estimators with a large number of simulated, yet realistic test collections.""",null,null
284,"We use the TREC 6, 7 and 8 ad hoc collections as evaluated with Average Precision. As is common practice, we first drop the bottom 25% of results to avoid effects of possibly buggy systems. From each original collection, we simulate 1, 000 new collections of sizes n ,"" 10, 20, . . . , 100 topics, leading to a total of 30, 000 simulated collections. For each of them, we estimate  and AP using each of the estimators defined above, and also compute the true correlations (recall that this is possible because the true system scores are fixed upfront when simulating new collections). Finally, for each correlation coefficient, original collection, topic set size and estimator, we compute expected error and bias.""",null,null
285,"Two baselines are used to compare our estimators to. They are based on a split-half method that randomly splits the available topic set in two subsets, and then computes the correlations as if one was the truth and the other one the estimate. This is replicated a number of times for different subset sizes, up to a maximum of n/2 topics. The observations are then used to fit a model and extrapolate the expected correlation with n topics. This simple estimator is found for instance in [7, 4]. Here we run 2, 000 replicates to fit the model y ,"" a·eb·x, and sample topics with and without replacement, leading to baselines SH(w) and SH(w/o).""",null,null
286,4.3 Results,null,null
287,"Figure 1 shows that the error of the estimators is larger with small collections. This is somewhat expected, because collections with too few topics are unstable and the rankings of systems vary too much to begin with. The error seems to plateau at about 0.025 in all our estimators, though with small collections of just 10 topics they are expected to be off by about 0.065. With the usual 50 topics, the expected error is 0.035. We can finally observe that the typical SH",null,null
288,1035,null,null
289,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
290,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
291,tau - adhoc6,null,null
292,ML,null,null
293,RES,null,null
294,MSQD KD,null,null
295,SH(w/o) SH(w),null,null
296,tauAP - adhoc6,null,null
297,topic set size tau - adhoc7,null,null
298,topic set size tauAP - adhoc7,null,null
299,Bias,null,null
300,0.00,null,null
301,0.04,null,null
302,0.08,null,null
303,10,null,null
304,20,null,null
305,30,null,null
306,tau - adhoc6,null,null
307,ML,null,null
308,RES,null,null
309,MSQD KD,null,null
310,SH(w/o) SH(w),null,null
311,0.08,null,null
312,tauAP - adhoc6,null,null
313,0.04,null,null
314,Bias,null,null
315,0.00,null,null
316,70,null,null
317,60,null,null
318,50,null,null
319,40,null,null
320,30,null,null
321,20,null,null
322,10,null,null
323,100,null,null
324,90,null,null
325,80,null,null
326,70,null,null
327,60,null,null
328,50,null,null
329,40,null,null
330,topic set size tau - adhoc7,null,null
331,topic set size tauAP - adhoc7,null,null
332,100,null,null
333,90,null,null
334,80,null,null
335,0.08,null,null
336,0.08,null,null
337,0.04,null,null
338,Bias,null,null
339,0.04,null,null
340,Bias,null,null
341,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
342,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
343,0.00,null,null
344,0.00,null,null
345,100,null,null
346,90,null,null
347,80,null,null
348,70,null,null
349,60,null,null
350,50,null,null
351,40,null,null
352,30,null,null
353,20,null,null
354,10,null,null
355,100,null,null
356,90,null,null
357,80,null,null
358,70,null,null
359,60,null,null
360,50,null,null
361,40,null,null
362,30,null,null
363,20,null,null
364,10,null,null
365,topic set size tau - adhoc8,null,null
366,topic set size tauAP - adhoc8,null,null
367,topic set size tau - adhoc8,null,null
368,topic set size tauAP - adhoc8,null,null
369,0.08,null,null
370,0.08,null,null
371,0.04,null,null
372,Bias,null,null
373,0.04,null,null
374,Bias,null,null
375,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
376,Error 0.02 0.04 0.06 0.08 0.10 10 20 30 40 50 60 70 80 90 100,null,null
377,0.00,null,null
378,0.00,null,null
379,100,null,null
380,90,null,null
381,80,null,null
382,70,null,null
383,60,null,null
384,50,null,null
385,40,null,null
386,30,null,null
387,20,null,null
388,10,null,null
389,100,null,null
390,90,null,null
391,80,null,null
392,70,null,null
393,60,null,null
394,50,null,null
395,40,null,null
396,30,null,null
397,20,null,null
398,10,null,null
399,topic set size,null,null
400,topic set size,null,null
401,Figure 1: Error of the estimators of  (left) and AP (right) for each of the three original collections.,null,null
402,"estimators are clearly outperformed by all our proposed estimators. In general, with 30­40 topics they behave almost the same, but with small samples MSQD is slightly better.",null,null
403,"Figure 2 shows that the correlations tend to be overestimated, especially with small collections, but this time we see clear differences among estimators. MSQD behaves much better than the others, especially with very small collections. With only 10 topics ML outperforms KD because there is just too little data to properly approximate the pdf , but with 20 or more topics it does a very good job at approximating the true distribution. ML, on the other hand, assumes a normal distribution and can therefore be less faithful to the data. Even at around 40­50 topics KD gets to slightly outperform MSQD for the same reason. Overall, they seem to plateau at about 0.004, and RES always performs worse than the others. Finally, the SH estimator with replacement has a roughly constant bias of about 0.055. The SH estimator without replacement shows a clearly biased behavior probably due to the choice of model.",null,null
404,5. CONCLUSION,null,null
405,"In this paper we present two estimators of the Kendall  and AP rank correlation coefficients between the mean system scores produced by a test collection and the true, unobservable means. We proposed parametric and nonparametric alternatives, and through large scale simulation with realistic collections we showed that even with small topic sets the estimators have little bias and the errors are generally small with collections of medium size. These estimators may prove useful as an easy to understand indicator",null,null
406,topic set size,null,null
407,topic set size,null,null
408,Figure 2: Bias of the estimators of  (left) and AP (right) for each of the three original collections.,null,null
409,"of reliability in the results of an evaluation experiment. In light of the expected error with individual collections,",null,null
410,our future work will mainly focus on the development of interval estimates. We also plan to study other estimators of discordance as well as the application of a fully bayesian approach to estimate correlations. All the results in this paper are fully reproducible with data and code available online at http://github.com/julian-urbano/sigir2016-correlation.,null,null
411,"Acknowledgments. Work supported by the Spanish Government: JdC postdoctoral fellowship, and projects TIN201570816-R and MDM-2015-0502. Florentino dimisi´on.",null,null
412,References,null,null
413,"[1] B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. If I Had a Million Queries. In ECIR, 2009.",null,null
414,"[2] W. H. Holtzman. The Unbiased Estimate of the Population Variance and Standard Deviation. Am. J. Psychology, 1950.",null,null
415,"[3] M. G. Kendall. A New Measure of Rank Correlation. Biometrika, 1938.",null,null
416,"[4] T. Sakai. On the Reliability of Information Retrieval Metrics Based on Graded Relevance. Inf. Proc. & Mngmnt, 2007.",null,null
417,"[5] J. Urbano. Test Collection Reliability: A Study of Bias and Robustness to Statistical Assumptions via Stochastic Simulation. Information Retrieval, 2016.",null,null
418,"[6] E. M. Voorhees. Variations in Relevance Judgments and the Measurement of Retrieval Effectiveness. In SIGIR, 1998.",null,null
419,"[7] E. M. Voorhees and C. Buckley. The Effect of Topic Set Size on Retrieval Experiment Error. In SIGIR, 2002.",null,null
420,"[8] E. Yilmaz, J. Aslam, and S. Robertson. A New Rank Correlation Coefficient for Information Retrieval. In SIGIR, 2008.",null,null
421,1036,null,null
422,,null,null
