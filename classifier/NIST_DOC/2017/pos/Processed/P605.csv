,sentence,label,data
0,",sentence,label,data",null,null
1,"0,Session 5C: Efficiency and Scalability,null,null",null,null
2,"1,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
3,"2,BitFunnel: Revisiting Signatures for Search,null,null",null,null
4,"3,Bob Goodwin,null,null",null,null
5,"4,Microsoft,null,null",null,null
6,"5,Alex Clemmer,null,null",null,null
7,"6,Heptio,null,null",null,null
8,"7,Michael Hopcroft,null,null",null,null
9,"8,Microsoft,null,null",null,null
10,"9,Mihaela Curmei,null,null",null,null
11,"10,Microsoft,null,null",null,null
12,"11,Dan Luu,null,null",null,null
13,"12,Microsoft,null,null",null,null
14,"13,Sameh Elnikety,null,null",null,null
15,"14,Microsoft,null,null",null,null
16,"15,Yuxiong He,null,null",null,null
17,"16,Microsoft,null,null",null,null
18,"17,ABSTRACT,null,null",null,null
19,"18,""Since the mid-90s there has been a widely-held belief that signature files are inferior to inverted files for text indexing. In recent years the Bing search engine has developed and deployed an index based on bit-sliced signatures. This index, known as BitFunnel, replaced an existing production system based on an inverted index. The driving factor behind the shift away from the inverted index was operational cost savings. This paper describes algorithmic innovations and changes in the cloud computing landscape that led us to reconsider and eventually field a technology that was once considered unusable. The BitFunnel algorithm directly addresses four fundamental limitations in bit-sliced block signatures. At the same time, our mapping of the algorithm onto a cluster offers opportunities to avoid other costs associated with signatures. We show these innovations yield a significant efficiency gain versus classic bit-sliced signatures and then compare BitFunnel with Partitioned Elias-Fano Indexes, MG4J, and Lucene."",null,null",null,null
20,"19,CCS CONCEPTS,null,null",null,null
21,"20,· Information systems  Search engine indexing; Probabilistic retrieval models; Distributed retrieval; · Theory of computation  Bloom filters and hashing;,null,null",null,null
22,"21,KEYWORDS,null,null",null,null
23,"22,Signature Files; Search Engines; Inverted Indexes; Intersection; Bitvector; Bloom Filters; Bit-Sliced Signatures; Query Processing,null,null",null,null
24,"23,1 INTRODUCTION,null,null",null,null
25,"24,""Commercial search engines [2, 5, 19, 24] traditionally employ inverted indexes. In this work, we show how to use signatures, or bit-strings based on Bloom filters [1], in a large-scale commercial search engine for better performance. Prior work comparing inverted files to signature files established that inverted files outperformed signature files by almost every criterion [28]. However, recent software and hardware trends (e.g., large Web corpora with"",null,null",null,null
26,"25,""Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery. ACM ISBN 978-1-4503-5022-8/17/08. . . $15.00 https://doi.org/10.1145/3077136.3080789"",null,null",null,null
27,"26,""of billions of documents, large main memory systems) motivated us to reconsider signature files."",null,null",null,null
28,"27,""In our signature-based approach, known as BitFunnel, we use a Bloom filter to represent the set of terms in each document as a fixed sequence of bits called a signature. Bloom filters are reasonably space efficient and allow for fast set membership, forming the basis for query processing."",null,null",null,null
29,"28,""Using this approach, however, poses four major challenges. First, determining the matches for a single term requires examining one signature for each document in the corpus. This involves considerably more CPU and memory cycles than the equivalent operation on an inverted index. Second, term frequency follows a Zipfian distribution, implying that signatures must be long to yield an acceptable false positive rate when searching for the rarest terms. Third, the size of web documents varies substantially, implying that signatures must be long to accommodate the longest documents. Fourth, the configuration of signature-based schemes is not a well-understood problem."",null,null",null,null
30,"29,We develop a set of techniques to address these challenges: (1) we introduce higher rank rows to reduce query execution time; (2) we employ frequency-conscious signatures to reduce the memory footprint; (3) we shard the corpus to reduce the variability in document size; (4) we develop a cost model for system performance; and (5) we use this model to formulate a constrained optimization to configure the system for efficiency.,null,null",null,null
31,"30,""These techniques are used in the Microsoft Bing search engine, which has been running in production for the last four years on thousands of servers. Compared to an earlier production search engine based on inverted lists that it replaced, BitFunnel improved server query capacity by a factor of 10."",null,null",null,null
32,"31,2 BACKGROUND AND PRIOR WORK,null,null",null,null
33,"32,We focus on the problem of identifying those documents in a corpus that match a conjunctive query of keywords. We call this the Matching Problem.,null,null",null,null
34,"33,""Let corpus C be a set of documents, each of which consists of a set of text terms:"",null,null",null,null
35,"34,""C , {documents D} D , {terms t }"",null,null",null,null
36,"35,Define query Q as a set of text terms:,null,null",null,null
37,"36,""Q , {terms t }"",null,null",null,null
38,"37,605,null,null",null,null
39,"38,Session 5C: Efficiency and Scalability,null,null",null,null
40,"39,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
41,"40,""Query Q is said to match document D when every term t  Q is also an element of D. This happens when Q  D or Q , Q  D. Define match set M as the set of documents matching Q:"",null,null",null,null
42,"41,""M , {D  C | Q , D  Q}"",null,null",null,null
43,"42,""The goal of the Matching Problem is to identify the match set M, given corpus C and query Q."",null,null",null,null
44,"43,""In Sections 2.2-2.4 we examine conservative probabilistic algorithms that never miss a match, but might falsely report matches. The goal for these algorithms is to identify a conservative filter set M "",null,null",null,null
45,"44,""M  M  C where the false positive set F , M  \ M is small."",null,null",null,null
46,"45,2.1 Inverted Indexes,null,null",null,null
47,"46,""Perhaps the most common approach to the Matching Problem is the inverted index [4, 11]. This approach maintains a mapping from each term in the lexicon to the the set of documents containing the term. In other words,"",null,null",null,null
48,"47,""Postins(t) , {D  C | t  D}"",null,null",null,null
49,"48,""With this approach, M can be formed by intersecting the posting sets associated with the terms in the query:"",null,null",null,null
50,"49,""M , Postins(t)"",null,null",null,null
51,"50,t Q,null,null",null,null
52,"51,""In practice, the posting sets are usually sorted, allowing fast intersection. They also draw on a large bag of tricks [4, 20] to compress and decompress posting sets [17, 23] while improving intersection time [6, 7]. This is a rich area with ongoing research into novel data structures such as treaps [16] and semi-bitvectors [13]."",null,null",null,null
53,"52,""Inverted indexes find the exact match set, M, every time. Signaturebased approaches [8­10, 15, 25], on the other hand, use probabilistic algorithms, based on superimposed coding [1, 21, 22] and newer approaches, like TopSig [12] to identify a conservative filter set M . BitFunnel is based on classical bit-sliced signatures which are, in turn, based on bit-string signatures."",null,null",null,null
54,"53,2.2 Bit-String Signatures,null,null",null,null
55,"54,""The key idea is that each document in the corpus is represented by its signature. In BitFunnel, the signature is essentially the sequence of bits that make up a Bloom filter representing the set of terms in the document. In constructing the Bloom filter, each term in the document is hashed to a few bit positions, each of which is set to 1."",null,null",null,null
56,"55,""Let n denote the number of bit positions in the Bloom filter. Define H (n, t) as a function that returns the set of bit positions in the range [0..n) corresponding to the hashes of term t. Define s#»t , the signature of term t, as the bit-vector of length-n where bit position i is set to 1 iff i  H (n, t). We can then define the signature of document D as the logical-or of the signatures of its terms:"",null,null",null,null
57,"56,""s#D» , s#»t"",null,null",null,null
58,"57,t D,null,null",null,null
59,"58,""In a similar manner, we can define the signature of query Q as the logical-or of the signatures of its terms:"",null,null",null,null
60,"59,""s#Q» , s#»t"",null,null",null,null
61,"60,t Q,null,null",null,null
62,"61,""Document D is said to be a member of M  when s#Q»  s#D» , s#Q»"",null,null",null,null
63,"62,""Given the signatures of the documents in the corpus, one can easily compute M  by identifying those documents whose signatures match the query's signature:"",null,null",null,null
64,"63,""M  , {D  C | s#Q»  s#D» , s#Q»}"",null,null",null,null
65,"64,Here's the pseudocode to search a corpus for documents matching,null,null",null,null
66,"65,a query:,null,null",null,null
67,"66,""M ,"",null,null",null,null
68,"67,for,null,null",null,null
69,"68,all D if s#D»,null,null",null,null
70,"69,""s#CQ»d,os#Q»"",null,null",null,null
71,"70,then,null,null",null,null
72,"71,""M  , M   {D}"",null,null",null,null
73,"72,end if end for,null,null",null,null
74,"73,""Bit-string signatures are elegant, but their uniform encoding of terms, independent of frequency, leads to poor memory utilization. Section 4.2 explains how BitFunnel uses Frequency Conscious Signatures to improve memory efficiency in signatures."",null,null",null,null
75,"74,2.3 Bit-Sliced Signatures,null,null",null,null
76,"75,If all of the signatures have the same length and share a common,null,null",null,null
77,"76,""hashing scheme, H (n, t), one can achieve significant performance"",null,null",null,null
78,"77,""gains by using a bit-sliced arrangement [9, 26, 27]. This approach"",null,null",null,null
79,"78,transposes signature vectors from rows to columns in order to,null,null",null,null
80,"79,allow multiple documents to be searched simultaneously while,null,null",null,null
81,"80,eliminating the bit masks and shifting necessary to perform Boolean,null,null",null,null
82,"81,operations on individual bits.,null,null",null,null
83,"82,""Suppose we have a corpus C , {A..P } and a query Q. The matrix"",null,null",null,null
84,"83,in Figure 1 shows these documents and the query encoded as bit-,null,null",null,null
85,"84,sliced signatures. Each document corresponds to a column which,null,null",null,null
86,"85,holds its 16-bit signature. Each row corresponds to a bit position in,null,null",null,null
87,"86,the document signature.,null,null",null,null
88,"87,""In this example the signature for document B has bit positions 2,"",null,null",null,null
89,"88,""5, 9, and 13 set. The signature for the query Q has bit positions 2, 5,"",null,null",null,null
90,"89,""and 9 set. Therefore, document B will match the query. It turns out"",null,null",null,null
91,"90,that document F also matches the query.,null,null",null,null
92,"91,""With the bit-sliced layout, we need only inspect the rows corre-"",null,null",null,null
93,"92,""sponding to bit positions in Q that are set. These rows, which we"",null,null",null,null
94,"93,""call the query's rows, are shaded in Figure 1 and isolated in Figure"",null,null",null,null
95,"94,2. Each bit position in the query's rows corresponds to a document.,null,null",null,null
96,"95,The document matches if its bit position is set in all of the query's,null,null",null,null
97,"96,rows. We determine which documents match by intersecting the,null,null",null,null
98,"97,""query's rows and looking for set bits. In Figure 2, columns B and F"",null,null",null,null
99,"98,are the only columns without zeros. Therefore documents B and F,null,null",null,null
100,"99,are the only matches.,null,null",null,null
101,"100,Here's the bit-sliced algorithm:,null,null",null,null
102,"101,""#a» , 0"",null,null",null,null
103,"102,for,null,null",null,null
104,"103,""all i #a» ,"",null,null",null,null
105,"104,w#a»h&erre#osw#Q»»i[i],null,null",null,null
106,"105,"",,"",null,null",null,null
107,"106,1,null,null",null,null
108,"107,do,null,null",null,null
109,"108,""end for M  , {i | #a»[i] 0}"",null,null",null,null
110,"109,606,null,null",null,null
111,"110,Session 5C: Efficiency and Scalability,null,null",null,null
112,"111,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
113,"112,Q,null,null",null,null
114,"113,00 10 21 30 40 51 60 70 80 91 10 0 11 0 12 0 13 0 14 0 15 0,null,null",null,null
115,"114,0A B 0C D 0E F 0G H 0I J 0K L M0 N 0O P 0 0 0 01 0 0 01 0 01 0 0 0 0 01 01 0 01 1 01 0 0 0 01 0 0 0 0 01 0 0 0 0 0 01 2 0 01 0 0 0 01 0 0 01 0 0 0 01 0 0 0 3 0 0 0 01 0 0 01 0 0 0 01 0 0 0 01 0 4 0 0 0 0 01 0 0 01 0 01 0 0 0 01 0 0 5 01 01 0 0 0 01 0 01 0 0 01 0 0 0 0 01 6 0 0 01 0 0 0 0 0 0 0 0 0 0 01 0 0 7 01 0 0 01 0 0 01 0 01 0 0 01 0 0 01 0 8 0 0 0 0 0 0 0 01 0 01 0 01 0 0 0 0 9 0 01 0 01 0 01 0 0 0 0 0 0 0 01 0 01 10 0 0 01 0 01 0 0 0 01 0 0 0 01 0 0 0 11 01 0 01 0 0 0 01 0 0 0 0 01 0 0 0 0 12 0 0 0 01 0 0 0 01 01 0 0 0 0 0 01 0 13 0 01 0 0 0 01 0 0 0 0 01 0 0 0 0 0 14 0 0 01 0 0 0 01 0 0 0 0 0 01 01 0 01 15 01 0 0 0 0 0 0 0 01 0 0 01 0 0 0 0,null,null",null,null
116,"115,""Figure 1: Layout with bit-sliced signatures, in which each column is a document signature. Q is the signature of the query."",null,null",null,null
117,"116,0A B 0C D 0E F 0G H 0I J 0K L M0 N 0O P 2 0 01 0 0 0 01 0 0 01 0 0 0 01 0 0 0 5 01 01 0 0 0 01 0 01 0 0 01 0 0 0 0 01 9 0 01 0 01 0 01 0 0 0 0 0 0 0 01 0 01,null,null",null,null
118,"117,2  5  9 0 01 0 0 0 01 0 0 0 0 0 0 0 0 0 0 0A B 0C D 0E F 0G H 0I J 0K L M0 N 0O P,null,null",null,null
119,"118,""Figure 2: Bit-sliced signature layout. Rows 2, 5, and 9 yield documents B and F ."",null,null",null,null
120,"119,2.4 Bit-Sliced Blocked Signatures,null,null",null,null
121,"120,""While bit-sliced signatures offer a significant performance advantage over bit-string signatures, they still suffer from poor performance when searching for rare terms. The problem is that every document's bit position must be scanned, even in the case where only a handful of documents actually match."",null,null",null,null
122,"121,""The idea behind blocked signatures [14] is to create shorter rows by assigning multiple documents to each column in the signature matrix. The number of documents that share a column is called the blocking factor. Shorter rows improve performance because they can be scanned more quickly, but they introduce noise which increases the false positive rate."",null,null",null,null
123,"122,""Prior to BitFunnel, bit-sliced block signatures were used primarily as a single-level index into a set of bit-string signature files on disk. At the time the main concern with this approach was reducing the probability of an unsuccessful block match which occurred when a column signature matched the query but none of the documents contained all the terms in the query. Suppose, for example, a column held two documents, one containing the word """"dog"""" and the other containing the word """"cat"""". This column would match the query {""""do"""", """"cat""""} even though neither document contains both terms. At least one paper proposed a solution to the problem of unsuccessful block matches [14], however [28] argued that blocking increases"",null,null",null,null
124,"123,""complexity while offering little benefit. In Section 4.1, we introduce Higher Rank Rows to address these problems."",null,null",null,null
125,"124,3 THE BITFUNNEL SYSTEM,null,null",null,null
126,"125,""For the past 4 years, BitFunnel has powered Bing's fresh index of recently crawled documents. During this time the system, which runs on thousands of machines, spread across several data centers, has processed the entire query load sent to Bing."",null,null",null,null
127,"126,3.1 Architectural Overview,null,null",null,null
128,"127,""Bing maintains multiple, georeplicated copies of the web index, each of which is sharded across a cluster of BitFunnel nodes. Figure 3 shows a single cluster. Queries are distributed, round robin, across the cluster. A node, upon receiving a query, parses it into an abstract syntax tree, rewrites the tree into an execution plan and then compiles the plan locally before broadcasting the compiled plan to the rest of the cluster. The nodes in the cluster run the compiled plan in parallel, returning results to the planning node for aggregation. These results are then passed on to other systems that score the matching documents and generate captions to display on the search results web page."",null,null",null,null
129,"128,Query,null,null",null,null
130,"129,Parse Plan Compile,null,null",null,null
131,"130,Execute Execute Execute,null,null",null,null
132,"131,Execute,null,null",null,null
133,"132,Aggregate,null,null",null,null
134,"133,Figure 3: BitFunnel cluster.,null,null",null,null
135,"134,Rank &,null,null",null,null
136,"135,Capon,null,null",null,null
137,"136,3.2 The Cost of False Positives,null,null",null,null
138,"137,""One criticism specific to the signature file approach is the introduction of false positives into the result set. For scenarios like database queries where the identifying exact match set is the goal, the cost of filtering out the false positives can be prohibitive. In the case of web search, the cost of filtering out false positives is negligible. To see why, it is important to understand that the goal of web search is not to find documents matching Boolean expressions of keywords ­ rather it is to find the documents that best match the user's intent when issuing a query. In Bing, we employ a ranking system that, given a document and a query, will generate a score predicting how well the document matches the user's intent for the query. This system relies on many signals beyond keywords and to some extent its inner workings are opaque to us because it is configured by machine learning."",null,null",null,null
139,"138,""If we had unlimited resources, we could process each query by submitting every single document in the corpus to our ranking oracle and then return the top-n ranked documents. Since we don't have unlimited resources, we insert inexpensive filters upstream of the oracle to discard documents that the oracle would score low. The filters are designed to reject, with high probability, those"",null,null",null,null
140,"139,607,null,null",null,null
141,"140,Session 5C: Efficiency and Scalability,null,null",null,null
142,"141,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
143,"142,documents that score low while never rejecting documents that score high. BitFunnel is such a filter.,null,null",null,null
144,"143,""In this context, the performance of BitFunnel is judged by its impact on the end-to-end system. BitFunnel wins when its time savings in the Boolean matching phase is greater than the time the oracle spends scoring false positives."",null,null",null,null
145,"144,We turn our attention now to a single BitFunnel node to describe the techniques that enable fast query processing.,null,null",null,null
146,"145,4 BITFUNNEL INNOVATIONS,null,null",null,null
147,"146,""In this section, we describe three innovations that address speed and space problems associated with bit-string and bit-sliced signatures."",null,null",null,null
148,"147,4.1 Higher Rank Rows,null,null",null,null
149,"148,BitFunnel generalizes the idea of blocking so that each term simultaneously hashes to multiple bit-sliced signatures with different blocking factors. The key to making this approach work is the ability to efficiently intersect rows with different blocking factors.,null,null",null,null
150,"149,""4.1.1 Mapping Columns Across Ranks. In BitFunnel, we restrict"",null,null",null,null
151,"150,""blocking factors to be powers of 2. We define a concept of row rank, where a row of rank r  0 has a blocking factor of 2r ."",null,null",null,null
152,"151,The BitFunnel blocking scheme is specific to the size of the,null,null",null,null
153,"152,""machine word used for the bit-slice operations. Let w be the log2 of the number of bits in a machine word, so for example, a 64-bit"",null,null",null,null
154,"153,""processor would have w , 6. Then the document in column i0 at rank 0 will be associated with column ir at rank r as follows:"",null,null",null,null
155,"154,ir,null,null",null,null
156,"155,"","",null,null",null,null
157,"156,i0 2r +w,null,null",null,null
158,"157,+ (i0 mod 2r ),null,null",null,null
159,"158,(1),null,null",null,null
160,"159,""Figure 4 gives a small example for a 4-bit machine word (w , 2) and"",null,null",null,null
161,"160,""ranks 0, 1, and 2. We can see that position 4 at rank 1 is associated with documents {4, 12} while position 0 at rank 2 is associated with documents {0, 4, 8, 12}."",null,null",null,null
162,"161,Rank 0 0 01 0 0 0 01 0 0 01 0 0 0 01 0 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
163,"162,Rank 1 01 01 0 0 01 01 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
164,"163,Rank 2 01 01 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
165,"164,Figure 4: Forming higher rank equivalents of a single row.,null,null",null,null
166,"165,""Note that higher rank rows will, in general, magnify the bit density of their lower rank equivalents. This is because the value of each bit at a higher rank is the logical-or of multiple bits at a lower rank. In order to maintain a constant bit density of d across all signatures in BitFunnel, we must use longer signatures at higher ranks. Therefore, a single row at rank 0 will translate into multiple shorter rows at a higher rank. In most cases, a rank zero row and its higher rank equivalents will consume roughly the same amount of"",null,null",null,null
167,"166,memory. We will derive an expression for the memory consumption in higher rank rows in Section 5.4.,null,null",null,null
168,"167,""Now suppose we have a query, Q, that maps to the three rows shown in Figure 5. To evaluate the query, we need some way of intersecting rows with different ranks. The mapping in Equation (1) is designed to make this operation easy and efficient."",null,null",null,null
169,"168,Rank 2 01 0 01 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
170,"169,Rank 1 0 01 0 0 01 0 0 01 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
171,"170,Rank 0 01 0 0 0 01 0 0 01 0 0 0 0 01 0 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
172,"171,Figure 5: Intersecting different rows with different ranks.,null,null",null,null
173,"172,Logically we convert each row to its rank-0 equivalent by concatenating 2r copies of the row as shown in Figure 6. Then we are free to intersect the rank-0 equivalent rows to produce the result vector.,null,null",null,null
174,"173,0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15 Rank 2 01 0 01 0 01 0 01 0 01 0 01 0 01 0 01 0 Rank 1 0 01 0 0 01 0 0 01 0 1 0 0 1 0 0 1 Rank 0 01 0 0 0 01 0 0 01 0 0 0 0 01 0 0 0,null,null",null,null
175,"174,Matches 0 0 0 0 01 0 0 0 0 0 0 0 01 0 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
176,"175,Figure 6: Rank-0 equivalent rows.,null,null",null,null
177,"176,""4.1.2 Optimizing Higher Rank Row Intersection. At a logical level, our approach is to intersect rank-0 equivalent rows. Were we to generate rank-0 equivalents for intersection, we would lose all of the performance gains that come from scanning shorter rows at higher ranks. Mapping (1) was structured specifically to provide opportunities to reuse intermediate results at every rank. As an example, in Figure 6, bits [0..3] of the rank 2 row need only be read once, even though they will be used for positions [4..7], [8..11], and [12..15]. Similarly, the intersection of the first two rows in positions [0..3] will be computed once and used again for positions [8..11]. We will leverage this insight in Section 5.3 where we derive an expression for the expected number of operations required to combine a set of rows with different ranks."",null,null",null,null
178,"177,""In BitFunnel, each term in a query maps to a set of rows that may include higher rank rows."",null,null",null,null
179,"178,4.2 Frequency Conscious Signatures,null,null",null,null
180,"179,We saw in Section 2.2 how Bloom filter signatures can be used to encode the set of terms in a document. One shortcoming with this,null,null",null,null
181,"180,608,null,null",null,null
182,"181,Session 5C: Efficiency and Scalability,null,null",null,null
183,"182,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
184,"183,approach is inefficient memory usage when terms in the lexicon,null,null",null,null
185,"184,have widely varying frequencies in the corpus.,null,null",null,null
186,"185,""The problem stems from the fact that, in its classical formulation [1], the Bloom filter is configured with an integer constant, k, which represents the number of hashes for each term1. This value of k is the same for all terms in lexicon L. In other words"",null,null",null,null
187,"186,""|H (n, t)| ,"""" k, t L"""""",null,null",null,null
188,"187,""To get an intuition for the problem of the one-size-fits-all k, it"",null,null",null,null
189,"188,""helps to think of the quantity of false positives in terms of signalto-noise ratio. Let's consider a single set membership test for t  D. In the context of the test, define the signal s to be the probability that term t is actually a member of document D. This is just the frequency of t in the corpus."",null,null",null,null
190,"189,Define noise  to be the probability that the Bloom filter will incorrectly report t as a member. Assume the Bloom filter has been configured to have an average bit density of d. Since d is the fraction,null,null",null,null
191,"190,""of the bits expected to be set, we can treat it as the probability that a random bit is set. A set membership test involves probing k bit positions. If all k probes find bits that are set to one, the algorithm"",null,null",null,null
192,"191,will report a match. Therefore the noise is just the probability that k probes all hit ones when t D:,null,null",null,null
193,"192,"" , (1 - s)dk"",null,null",null,null
194,"193,The signal-to-noise ratio  is then,null,null",null,null
195,"194,"","",null,null",null,null
196,"195,(1,null,null",null,null
197,"196,s - s)dk,null,null",null,null
198,"197,""We can rearrange this and take the ceiling to get an expression for k as a function of d, s, and :"",null,null",null,null
199,"198,""k,"",null,null",null,null
200,"199,lod,null,null",null,null
201,"200,s (1 - s),null,null",null,null
202,"201,This is the minimum value of k that will ensure a signal-to-noise ratio of at least . The main take away is that k increases as s,null,null",null,null
203,"202,""decreases. In other words, rare terms require more hashes to ensure a given signal-to-noise level. The following table shows values of k without the ceiling, for select values of s when d , 0.1 and  , 10:"",null,null",null,null
204,"203,signal (s) 0.1 0.01 0.001 0.0001 0.00001,null,null",null,null
205,"204,hashes (k) 1.954242509 2.995635195 3.999565488 4.999956568 5.999995657,null,null",null,null
206,"205,""Now consider a Bloom filter that stores a typical document from the Gov2 corpus2. If we were to configure the Bloom filter with k ,"""" 2 we could just barely maintain a signal-to-noise ratio of 10 when testing for the term """"""""picture"""""""" which appears with frequency 0.1. To test for the term """"""""rotisserie"""""""", which appears with frequency 0.0001, we would need k """", 5 to drive the noise down to a tenth of the signal."",null,null",null,null
207,"206,""With classical Bloom filters, one must configure for the rarest term in the lexicon, even though the vast majority of common terms could be stored more efficiently. Recent work in Weighted Bloom"",null,null",null,null
208,"207,1In Bloom's original paper [1] this constant was the letter d ; more contemporary,null,null",null,null
209,"208,descriptions [3] use the letter k . 2Term frequencies are from Corpus D described in Section 6.,null,null",null,null
210,"209,Filters [3] shows that it is possible to adjust the number of hash functions on a term-by-term basis within the same Bloom filter.,null,null",null,null
211,"210,BitFunnel applies these ideas to reduce memory usage and determine the number of rows needed for each term.,null,null",null,null
212,"211,4.3 Sharding by Document Length,null,null",null,null
213,"212,""Bit-sliced signatures have another one-size-fits-all problem resulting from the requirement that all of the document signatures have the same configuration (i.e. their bit lengths, n, must all be the same, and they must all use the same hashing scheme H (n, t))."",null,null",null,null
214,"213,""The problem is that real world documents vary greatly in length. In Wikipedia, for example, the shortest documents have just a handful of unique terms while the longest ones may have many thousands of terms. The dynamic range of document lengths on the internet is even higher because of files containing DNA sequences, phone numbers, and GUIDs. To avoid overfilling our Bloom filters and generating excessive false positives, it is necessary to configure the Bloom filters for the longest document expected, even if such a document is very rare. Unfortunately, such a configuration would waste enough memory as to offset all of the other benefits of the bit-sliced arrangement."",null,null",null,null
215,"214,""A workaround [28] suggested in the late 90s was to shard the index into pieces containing documents with similar lengths. This approach was rejected at the time because, on a single machine, the introduction of length sharding would multiply the number of disk seeks by the number of shards."",null,null",null,null
216,"215,""This concern is not a factor when the index is many times larger than the capacity of a single machine. As soon as the index is sharded across a large cluster, one must pay for the overhead of sharding. At this point sharding by document length costs the same as sharding by any arbitrary factor."",null,null",null,null
217,"216,""Even on a single machine, the cost of length sharding is greatly reduced on modern hardware where the index can be stored in RAM or on SSD because the access cost is dominated by fixed-sized block transfers (512-bit cache line for RAM, 4096 byte block for SSD), rather than hard disk seeks."",null,null",null,null
218,"217,""In BitFunnel, we partition the corpus according to the number of unique terms in each document such that each instance of BitFunnel manages a shard in which documents have similar sizes."",null,null",null,null
219,"218,5 PERFORMANCE MODEL AND OPTIMIZATION,null,null",null,null
220,"219,""Signature-based approaches have historically been hard to configure because of a large number of design parameters that impact performance [10, 26, 28]. In this section we present an algorithm that optimizes the BitFunnel configuration, given a desired signalto-noise ratio. The algorithm performs a constrained optimization, over relevant configuration parameters, of a cost function that expresses the system efficiency as DQ, the product of the corpus size D and query processing rate Q. The configuration parameters include the mapping from terms with various frequencies to their corresponding number of rows at each rank. The constraint is a lower limit on the allowable signal-to-noise ratio, ."",null,null",null,null
221,"220,""In order to develop the cost function and constraint, we derive expressions for the signal-to-noise ratio, query processing speed, and memory consumption in BitFunnel. We then combine these"",null,null",null,null
222,"221,609,null,null",null,null
223,"222,Session 5C: Efficiency and Scalability,null,null",null,null
224,"223,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
225,"224,""expressions into a cost function and constraint used by the algorithm that identifies an optimized set of blocking factors and hash functions for each equivalence class of terms, based on frequency in the lexicon."",null,null",null,null
226,"225,5.1 Prerequisites,null,null",null,null
227,"226,""Before deriving these fundamental equations, we discuss the impact of row rank on bit densities and noise. We then characterize two different components of noise in rank-0 equivalent rows. This will form the basis for the noise, speed, and storage equations in Sections 5.2, 5.3, and 5.4."",null,null",null,null
228,"227,5.1.1 Signal in a Higher Rank Row. Because each bit in a higher,null,null",null,null
229,"228,""rank row corresponds to multiple documents, the bit density con-"",null,null",null,null
230,"229,tributed by a single term will nearly always be greater in higher,null,null",null,null
231,"230,rank rows. We can see this in Figure 4 where densities in the rank-0,null,null",null,null
232,"231,row,null,null",null,null
233,"232,and,null,null",null,null
234,"233,its,null,null",null,null
235,"234,rank,null,null",null,null
236,"235,1,null,null",null,null
237,"236,equivalent,null,null",null,null
238,"237,are,null,null",null,null
239,"238,4 16,null,null",null,null
240,"239,and,null,null",null,null
241,"240,8 16,null,null",null,null
242,"241,"","",null,null",null,null
243,"242,respectively.,null,null",null,null
244,"243,Let s0 denote the signal in a rank-0 row and sr denote the signal,null,null",null,null
245,"244,at rank r . We can express sr as a function of s0 and r . The probability,null,null",null,null
246,"245,that a bit at rank r is set due to signal is the probability that at least,null,null",null,null
247,"246,one of the 2r corresponding rank-0 bits is signal. This is just one,null,null",null,null
248,"247,minus the probability that all of the 2r rank-0 bits are zero:,null,null",null,null
249,"248,""sr , 1 - (1 - s0)2r"",null,null",null,null
250,"249,(2),null,null",null,null
251,"250,5.1.2 Noise in a Rank-0 Equivalent Row. Processing a query in,null,null",null,null
252,"251,BitFunnel is logically equivalent to intersecting the rank-0 equiva-,null,null",null,null
253,"252,lents of each row associated with the query. Converting a rank-r,null,null",null,null
254,"253,row to its rank-0 equivalent increases noise. The intuition behind,null,null",null,null
255,"254,this is simple -- each bit set in a rank-r row means that at least one of 2r documents is a match. It could be one document or all 2r --,null,null",null,null
256,"255,we can't tell and this is the source of higher noise.,null,null",null,null
257,"256,Let's look at a simple example. Suppose we have a corpus of,null,null",null,null
258,"257,16 documents and would like to search for a term that happens,null,null",null,null
259,"258,to appear in documents 4 and 8. We hash our term to find its,null,null",null,null
260,"259,""corresponding rows, and we get the set of rows R ,"""" {R2, R1, R0} with ranks 2, 1, and 0, respectively. We define the signal, s0 as the"""""",null,null",null,null
261,"260,fraction of the bit positions at rank-0 corresponding to a match. In,null,null",null,null
262,"261,""the case of a term that appears in only 2 documents, s0"",null,null",null,null
263,"262,"","",null,null",null,null
264,"263,2 16,null,null",null,null
265,"264,.,null,null",null,null
266,"265,In,null,null",null,null
267,"266,""Figure 7, the green squares labeled 'S' correspond to the signal."",null,null",null,null
268,"267,R2 0S 0 0N 0 R1 0S 0N 0 0 0S 0 0 0N R0 0 0N 0N 0 0S 0 0N 0 0S 0N 0 0 0N 0 0N 0,null,null",null,null
269,"268,S0 0 0 0 0 0S 0 0 0 0S 0 0 0 0 0 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
270,"269,""Figure 7: A term maps to three rows with different ranks. Since a row is shared with other terms, it contains signal and noise bits but has constant bit density."",null,null",null,null
271,"270,R2,null,null",null,null
272,"271,""has one signal bit, so its signal is"",null,null",null,null
273,"272,1 4,null,null",null,null
274,"273,"","",null,null",null,null
275,"274,4 16,null,null",null,null
276,"275,.,null,null",null,null
277,"276,We've,null,null",null,null
278,"277,arbitrarily,null,null",null,null
279,"278,""added one noise bit, marked with an 'N' and shaded black. This bit"",null,null",null,null
280,"279,is contributed from another term that also maps to R2. The density,null,null",null,null
281,"280,of R2,null,null",null,null
282,"281,is,null,null",null,null
283,"282,2 4,null,null",null,null
284,"283,"","",null,null",null,null
285,"284,8 16,null,null",null,null
286,"285,.,null,null",null,null
287,"286,Row R1 has two signal bits and two arbitrary noise bits so its,null,null",null,null
288,"287,signal is,null,null",null,null
289,"288,2 8,null,null",null,null
290,"289,"","",null,null",null,null
291,"290,4 16,null,null",null,null
292,"291,and its density is,null,null",null,null
293,"292,4 8,null,null",null,null
294,"293,"","",null,null",null,null
295,"294,8 16,null,null",null,null
296,"295,.,null,null",null,null
297,"296,""Finally, in row R0, the signal is equal to s0 because each signal"",null,null",null,null
298,"297,""bit maps directly to a single document. As with the other rows, R0"",null,null",null,null
299,"298,contains,null,null",null,null
300,"299,random,null,null",null,null
301,"300,noise,null,null",null,null
302,"301,bits,null,null",null,null
303,"302,from,null,null",null,null
304,"303,other,null,null",null,null
305,"304,""terms,"",null,null",null,null
306,"305,yielding,null,null",null,null
307,"306,8 16,null,null",null,null
308,"307,density.,null,null",null,null
309,"308,""To process our query, we intersect the rank-0 equivalents of"",null,null",null,null
310,"309,rows R2 and R1 with R0. Figure 8 shows how the process of creating,null,null",null,null
311,"310,rank-0 equivalents increases noise.,null,null",null,null
312,"311,0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15 R2 0C 0 0U 0 0S 0 0U 0 S0 0 0U 0 0C 0 0U 0 R1 0C 0U 0 0 0S 0 0 0U S0 U 0 0 C 0 0U R0 0 0U 0U 0 0S 0 0U 0 S0 0U 0 0 0U 0 0U 0,null,null",null,null
313,"312,Results 0 0 0 0 0S 0 0 0 0S 0 0 0 0U 0 0 0 0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15,null,null",null,null
314,"313,Figure 8: Noise in rank-0 equivalent rows.,null,null",null,null
315,"314,""Continuing with our example, the signal bit from position 0 in"",null,null",null,null
316,"315,""R2 maps to bit positions 0, 4, 8, and 12 at rank 0. Of these four"",null,null",null,null
317,"316,""positions, only positions 4 and 8 correspond to signal bits. The"",null,null",null,null
318,"317,others are noise bits introduced by the construction of the rank-0,null,null",null,null
319,"318,""equivalent, and they are colored yellow and marked with the letter"",null,null",null,null
320,"319,""'C'. In a similar manner, R2 bit position 2 introduces noise in rank-0"",null,null",null,null
321,"320,""positions 2, 6, 10, and 14. These bits are colored black and marked"",null,null",null,null
322,"321,""with the letter 'U'. In the case of R2, we went from a rank-2 row"",null,null",null,null
323,"322,with,null,null",null,null
324,"323,1 4,null,null",null,null
325,"324,signal,null,null",null,null
326,"325,and,null,null",null,null
327,"326,1 4,null,null",null,null
328,"327,noise,null,null",null,null
329,"328,to,null,null",null,null
330,"329,a,null,null",null,null
331,"330,rank-0,null,null",null,null
332,"331,row,null,null",null,null
333,"332,with,null,null",null,null
334,"333,2 16,null,null",null,null
335,"334,signal,null,null",null,null
336,"335,and,null,null",null,null
337,"336,6 16,null,null",null,null
338,"337,noise. The noise increase is entirely due to the signal bits in R2. In,null,null",null,null
339,"338,""contrast, the noise bits in R2 contribute their same density without"",null,null",null,null
340,"339,""amplification, and therefore do not increase noise in the rank-0"",null,null",null,null
341,"340,equivalent row.,null,null",null,null
342,"341,Now let's look at the rank-0 equivalent of R1. We go from a rank-,null,null",null,null
343,"342,1 row,null,null",null,null
344,"343,with,null,null",null,null
345,"344,2 8,null,null",null,null
346,"345,signal,null,null",null,null
347,"346,and,null,null",null,null
348,"347,2 8,null,null",null,null
349,"348,noise,null,null",null,null
350,"349,to a rank-0,null,null",null,null
351,"350,row,null,null",null,null
352,"351,with,null,null",null,null
353,"352,2 16,null,null",null,null
354,"353,signal,null,null",null,null
355,"354,and,null,null",null,null
356,"355,6 16,null,null",null,null
357,"356,noise.,null,null",null,null
358,"357,As,null,null",null,null
359,"358,with,null,null",null,null
360,"359,""R2,"",null,null",null,null
361,"360,the,null,null",null,null
362,"361,noise,null,null",null,null
363,"362,increase,null,null",null,null
364,"363,is,null,null",null,null
365,"364,due,null,null",null,null
366,"365,entirely,null,null",null,null
367,"366,to,null,null",null,null
368,"367,signal,null,null",null,null
369,"368,in,null,null",null,null
370,"369,rank-1 row.,null,null",null,null
371,"370,""5.1.3 Correlated and Uncorrelated Noise. We turn to computing the noise resulting from the intersection of a set of the rows. The noise in any rank-0 row is the difference between the row's density and the signal s0. If row R has density d, then its rank-0 equivalent has density d because it consists of the concatenation of 2r copies of the R. Therefore, the noise in R's rank-0 equivalent is d - s0."",null,null",null,null
372,"371,""Noise is made up of two components, one which is correlated and one which is not. In Figure 8, uncorrelated noise bits are shaded black while correlated noise bits are colored yellow. Row intersections are very effective at reducing uncorrelated noise, but they have less impact on correlated noise."",null,null",null,null
373,"372,""To better illustrate this, let's look at a simple, but extreme example. Suppose our query matches documents 2 and 13 and consists of the three rank-1 rows depicted in Figure 9. In the rank-0 equivalent"",null,null",null,null
374,"373,Ra 0 0 0S 0 0 0S 0N 0 Rb 0 0N 0S 0 0 0S 0 0 Rc 0 0 0S 0N 0 0S 0 0,null,null",null,null
375,"374,Figure 9: Three rank-2 rows.,null,null",null,null
376,"375,""rows, shown in Figure 10, noise has two components: correlated and"",null,null",null,null
377,"376,610,null,null",null,null
378,"377,Session 5C: Efficiency and Scalability,null,null",null,null
379,"378,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
380,"379,0 1 02 3 04 5 06 7 08 9 100 11 102 13 104 15 R2 0 0 0S 0 0 0C 0U 0 0 0 0C 0 0 S0 0U 0 R1 0 0U 0S 0 0 0C 0 0 0 U 0C 0 0 S0 0 0 R0 0 0 0S 0U 0 0C 0 0 0 0 0C N0U 0 S0 0 0,null,null",null,null
381,"380,RaRbRc 0 0 0S 0 0 0C 0 0 0 0 0C 0 0 0S 0 0,null,null",null,null
382,"381,Figure 10: Correlated and uncorrelated noise in rank-0 equivalent rows.,null,null",null,null
383,"382,""uncorrelated. The uncorrelated noise, shown in black and marked"",null,null",null,null
384,"383,""with the letter 'U', is completely eliminated in three row intersec-"",null,null",null,null
385,"384,""tions, but the correlated noise, shown in yellow and marked with"",null,null",null,null
386,"385,the letter 'C' remains at the same level despite the intersections.,null,null",null,null
387,"386,Effectively managing the impact of higher rank rows requires,null,null",null,null
388,"387,an understanding of the correlated noise in rank-0 equivalent rows.,null,null",null,null
389,"388,In the following we derive expressions for noise components. Let nr denote noise in a rank-r row R and n0 denote noise in,null,null",null,null
390,"389,""its rank-0 equivalent. We express n0 as a function of r , s0, and nr . Row R will contribute nr density due to noise already in R and sr in density due to signal in R. A portion of the density in sr corresponds to bonified signal. The remaining density is correlated"",null,null",null,null
391,"390,noise introduced by the conversion to rank-0. Thus we compute noise at rank-0 by subtracting s0 from the density contributed by R:,null,null",null,null
392,"391,""n0 , nr + sr - s0"",null,null",null,null
393,"392,""To compute the correlated noise, we subtract nr from n0 and substitute sr , 1 - (1 - s0)2r :"",null,null",null,null
394,"393,""n0 - nr , sr - s0 , 1 - (1 - s0)2r - s0"",null,null",null,null
395,"394,(3),null,null",null,null
396,"395,""Note that the number of correlated noise bits in a rank-0 equivalent is a function of the original rank. The higher the row rank, the greather the contribution in correlated noise to its rank-0 equivalent. Also, correlated noise remaining after intersecting a set of rank-0 equivalents is the correlated noise of the lowest rank row in the set. The other correlated noise is converted to uncorrelated noise."",null,null",null,null
397,"396,It is important to note that the correlated noise bits in a lower rank equivalent always form a subset of the correlated noise bits in a higher rank equivalent. Our equations for noise and speed in Sections 5.2 and 5.3 make use of this fact.,null,null",null,null
398,"397,5.2 Signal-to-Noise Ratio,null,null",null,null
399,"398,""We're now ready to write expressions for the noise components after a sequence of row intersections. For this derivation, we will perform the intersections in order from high rank to low rank. We will start with an accumulator, a, which has an initial bit density of 1.0 and then intersect in each row in turn."",null,null",null,null
400,"399,""Let ai denote the total noise in the accumulator at the end of iteration i. Let ci and ui denote the amount of correlated and uncorrelated noise, respectively, on iteration i and let ri denote the rank. The first iteration is effectively loading the first row into the accumulator so, u1 ,"""" n1. The correlated noise in the accumulator is always equal to the correlated noise in the last row intersected, so"""""",null,null",null,null
401,"400,""ci , 1 - (1 - s0)2ri - s0"",null,null",null,null
402,"401,""Since the rows are ordered by non-increasing rank, subsequent rows will never have more correlated noise. In the case where the rank decreases, the amount of correlated noise will decrease. When this happens, some of the correlated noise in the accumulator will become uncorrelated noise, moving forward. This new amount of uncorrelated noise in the accumulator will then be multiplied by the current row's total noise density ni+1:"",null,null",null,null
403,"402,""ui+1 , (ui + ci - ci+1)ni+1"",null,null",null,null
404,"403,""At any given point, the total accumulator noise ai is just the sum of the correlated and uncorrelated noise:"",null,null",null,null
405,"404,""ai , ci + ui"",null,null",null,null
406,"405,""The signal-to-noise ratio, , on iteration i is then"",null,null",null,null
407,"406,i,null,null",null,null
408,"407,"","",null,null",null,null
409,"408,s0 ai,null,null",null,null
410,"409,"","",null,null",null,null
411,"410,s0 ci + ui,null,null",null,null
412,"411,(4),null,null",null,null
413,"412,5.3 Query Execution Time,null,null",null,null
414,"413,""When modelling running time, we use the number of machine word accesses of unique memory addresses as our proxy for time. On a real computer, row intersections are typically performed in chunks that match the machine register size. As an example, if the machine register size is 64 bits, and the rank-0 rows are 256 bits long, a pairwise row intersection would require 4 register-sized logical-and operations. When intersecting a set of rows, the outer loop is typically over the register-sized chunks in each row and the inner loop is over the set of rows."",null,null",null,null
415,"414,""This ordering of the loops is desirable because intermediate results of row intersections can reside in the accumulator instead of being written to memory. In many cases, the accumulator will become zero in the inner loop before all of the rows have been examined. Since additional intersections cannot change the result, it is possible to break out of the inner loop at this point."",null,null",null,null
416,"415,""In practice, breaking out of the inner loop offers a significant performance improvement. To quantify this impact, we'll focus on the innermost loop which intersects a set of n machine words that reside in memory. Our goal is to write an expression for the expected number of machine words loaded from memory."",null,null",null,null
417,"416,""If we know the probability that a bit remains set after intersecting the first n rows, we can derive a formula for the expected number of machine words accessed when intersecting a set of rows."",null,null",null,null
418,"417,Let N be a random variable denoting the machine words intersected and define PBZ (N > i) to be the probability that a random bit in the accumulator is zero after iteration i. PBZ (N > i) is the probability that the bit was not set by noise and not set by signal:,null,null",null,null
419,"418,""PBZ (N > i) , 1 - s0 - ai"",null,null",null,null
420,"419,Define PA(N > i) to be the probability that at least one bit in the accumulator remains set after i intersections If b denotes the number of bits in a machine word then,null,null",null,null
421,"420,""PA(N > i) , 1 - (PBZ (N > i))b"",null,null",null,null
422,"421,If we were to actually perform intersections on the rank-0 equiv-,null,null",null,null
423,"422,""alent rows, the expected number of machine words accessed during"",null,null",null,null
424,"423,one iteration of the outer loop would be,null,null",null,null
425,"424,n,null,null",null,null
426,"425,n,null,null",null,null
427,"426,""E(N ) , PA(N > i) , 1 - (1 - s0 - ai )b"",null,null",null,null
428,"427,""i ,1"",null,null",null,null
429,"428,""i ,1"",null,null",null,null
430,"429,611,null,null",null,null
431,"430,Session 5C: Efficiency and Scalability,null,null",null,null
432,"431,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
433,"432,""As we saw in Section 4.1.2, the mapping of columns across ranks"",null,null",null,null
434,"433,is structured in such a way that intermediate results from higher,null,null",null,null
435,"434,""rank intersections can be reused. Since each rank-0 equivalent is just the concatenation of 2r copies of a rank-r original, we need only load the accumulator once for each of the 2r machine word"",null,null",null,null
436,"435,positions in the rank-0 equivalent. This reduces the number of machine words accessed in each row by a factor of 2ri :,null,null",null,null
437,"436,E(N ),null,null",null,null
438,"437,"","",null,null",null,null
439,"438,""n i ,1"",null,null",null,null
440,"439,1,null,null",null,null
441,"440,-,null,null",null,null
442,"441,(1,null,null",null,null
443,"442,- s0 2ri,null,null",null,null
444,"443,-,null,null",null,null
445,"444,ai )b,null,null",null,null
446,"445,(5),null,null",null,null
447,"446,""A similar approach can be used to model block devices like CPU cache and SSD block transfers, but it is somewhat more involved than substituting a different value for b."",null,null",null,null
448,"447,5.4 Space Consumption,null,null",null,null
449,"448,We express memory consumption as the number of bits per docu-,null,null",null,null
450,"449,""ment required to store a term. Suppose we have a corpus, C, with"",null,null",null,null
451,"450,""target bit density, d, and we wish to store a term with signal, s0, in some row, q, that has rank r ."",null,null",null,null
452,"451,""Since the corpus has |C| documents, row q must have |C|2-r bit"",null,null",null,null
453,"452,""positions. Equation (2) shows that a term with frequency s0 will set sr of these bits. Therefore the term contributes b1 , sr |C|2-r set bits to row q. Let b0 denote the number of zero bits in row q. By"",null,null",null,null
454,"453,""definition,"",null,null",null,null
455,"454,d,null,null",null,null
456,"455,"","",null,null",null,null
457,"456,b1 b1 + b0,null,null",null,null
458,"457,""Rearranging, we get"",null,null",null,null
459,"458,b0,null,null",null,null
460,"459,"","",null,null",null,null
461,"460,b1 d,null,null",null,null
462,"461,- b1,null,null",null,null
463,"462,""Therefore, the total number of bits required in row q to maintain density of d with a signal of s0 is"",null,null",null,null
464,"463,b0,null,null",null,null
465,"464,+ b1,null,null",null,null
466,"465,"","",null,null",null,null
467,"466,b1 d,null,null",null,null
468,"467,"","",null,null",null,null
469,"468,sr |C| d 2r,null,null",null,null
470,"469,Dividing by the corpus size |C| gives the number of bits per docu-,null,null",null,null
471,"470,ment signature: sr d 2r,null,null",null,null
472,"471,""For a set of rows, Q, the total memory consumption per document"",null,null",null,null
473,"472,is therefore,null,null",null,null
474,"473,sr (q) q Q d2r,null,null",null,null
475,"474,(6),null,null",null,null
476,"475,5.5 Choosing Term Configurations,null,null",null,null
477,"476,""Given expressions for signal-to-noise ratio, machine word reads, and storage consumed, we can now develop an approach for identifying the optimal row configuration for each term. The problem is a constrained optimization over a cost function parameterized by speed and space. Our constraint is that the signal-to-noise ratio, , must exceed some fixed threshold. The cost function is proportional to DQ, the product of the number of documents per unit storage and the number of queries processed per unit of compute."",null,null",null,null
478,"477,D is inversely proportional to the amount of storage required per document. Q is inversely proportional to the number of machine,null,null",null,null
479,"478,words accessed while processing a query. Therefore,null,null",null,null
480,"479,DQ ,null,null",null,null
481,"480,1,null,null",null,null
482,"481,(7),null,null",null,null
483,"482,n 1-(1-s0-ai )b,null,null",null,null
484,"483,""i ,1"",null,null",null,null
485,"484,2ri,null,null",null,null
486,"485,sr (q) q Q d,null,null",null,null
487,"486,""Given the small number of possible row configurations, it is easy"",null,null",null,null
488,"487,""to enumerate all configurations and choose the one with the highest DQ where  exceeds the signal-to-noise threshold. For example,"",null,null",null,null
489,"488,""when considering configurations of 0 to 9 rows at each of seven ranks from 0 to 6, we need to examine 107 configurations for each s0 value. If we group s0 values into, say, 100 buckets correspondiong to IDF values from 0.1 to 10.0 in 0.1 increments, the entire optimization involves 109 evaluations of Equation 7. A modern multi-core"",null,null",null,null
490,"489,processor can perform this optimization in a matter of seconds.,null,null",null,null
491,"490,6 EXPERIMENATAL EVALUATION,null,null",null,null
492,"491,""Our experiments are based on the TREC Gov2 corpus. Apache Tikka3 was used to extract terms, which were then converted to lower case, but not stemmed. Since BitFunnel shards its index by document term count, we selected five representative shards for our tests. Shard A has relatively short documents with term counts ranging from 64 to 127. Shards B, C, D and E have progressively larger documents."",null,null",null,null
493,"492,Min terms Max terms Documents (M) Total terms (M) Postings (M) Matches/query Input text (GB),null,null",null,null
494,"493,Table 1: Corpora. ABC 64 128 256,null,null",null,null
495,"494,127 255 511 5.870 7.545 3.726 4.181 6.524 6.647,null,null",null,null
496,"495,""563 1,411 1,268 1,115 3,561 5,124 6.85 25.48 21.02"",null,null",null,null
497,"496,""D 1,024 2,047 0.494 10.109"",null,null",null,null
498,"497,""687 3,728 22.89"",null,null",null,null
499,"498,""E 2,048 4,095 0.157 9.697"",null,null",null,null
500,"499,""432 3,688 20.26"",null,null",null,null
501,"500,Our query log is based the TREC 2006 Efficiency Topics. We removed punctuations from each query and then filtered out those queries that contained terms not in the corpus.4 The resulting query log contains about 98k queries.,null,null",null,null
502,"501,""BitFunnel was implemented in C++14 and compiled with GCC 5.4.1 with the highest optimization level. Experiments were performed on a 4.0GHz 4-core i7-6700 with 32GB of 3.2GHz DDR4 RAM with Ubuntu 14.04 LTS on Windows Subsystem for Linux. BitFunnel was configured with lower bound signal-to-noise ratio  , 10."",null,null",null,null
503,"502,The source code to replicate our experiments is available at http://bitfunnel.org/sigir2017.,null,null",null,null
504,"503,6.1 Match Time vs. Quadwords,null,null",null,null
505,"504,""In Section 5.3 we developed a model for the number of machine words of row data accessed while processing a query. To verify that our model has predictive power, we examined the relationship between row intersection time and the number of quadwords accessed. Since BitFunnel has a significant per-match overhead that"",null,null",null,null
506,"505,3 https://tika.apache.org/ 4This filtering was necessary because the Partitioned Elias-Fano index we used requires all query terms be in the index.,null,null",null,null
507,"506,612,null,null",null,null
508,"507,Session 5C: Efficiency and Scalability,null,null",null,null
509,"508,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
510,"509,Median Intersection Time (µs),null,null",null,null
511,"510,200,null,null",null,null
512,"511,150,null,null",null,null
513,"512,IDF,null,null",null,null
514,"513,3,null,null",null,null
515,"514,100,null,null",null,null
516,"515,4,null,null",null,null
517,"516,5 50,null,null",null,null
518,"517,0,null,null",null,null
519,"518,0,null,null",null,null
520,"519,20000,null,null",null,null
521,"520,40000,null,null",null,null
522,"521,60000,null,null",null,null
523,"522,Quadwords Accessed,null,null",null,null
524,"523,Figure 11: Intersection time increases with quadwords.,null,null",null,null
525,"524,""is not part of the row intersection cost model, we modified the code to perform row intersections, but not report matches. A sample of 5000 queries with I DF > 3 were chosen, at random, from our TREC query log, and these queries were run, single-threaded, against corpus D. To control for system variances not in the model, we ran each query 10 times and recorded the median row intersection time. The scatterplot in Figure 11 shows that row intersection time tends to grow as the number of quadwords increases. The correlation is more pronounced at higher IDF values."",null,null",null,null
526,"525,6.2 Impact of Frequency Conscious Signatures and Higher Rank Rows,null,null",null,null
527,"526,""This experiment compares the time and space characteristics of (a) bit-sliced signatures configured with classical Bloom filters (BSS); (b) the same, but with Frequency Conscious Signatures as described in Section 4.2 (BSS-FC); and (c) Higher Ranked Rows as described in Section 4.1 and optimized per Section 5.5 (BTFNL).5"",null,null",null,null
528,"527,""Table 2 examines Corpus D, comparing the three configurations at each of 5 bit densities. The DQ values measure overall system efficiency, expressed as the ratio of QPS to Bits/Posting. We use DQ because it is inversely proportional to the number of servers required, given a particular corpus and a desired QPS"",null,null",null,null
529,"528,Table 2: Impact of BitFunnel Innovations.,null,null",null,null
530,"529,Treatment Density Bits/Posting kQPS DQ,null,null",null,null
531,"530,BSS,null,null",null,null
532,"531,0.05,null,null",null,null
533,"532,80.0,null,null",null,null
534,"533,14.0 175,null,null",null,null
535,"534,BSS,null,null",null,null
536,"535,0.10,null,null",null,null
537,"536,50.0,null,null",null,null
538,"537,11.3 225,null,null",null,null
539,"538,BSS,null,null",null,null
540,"539,0.15,null,null",null,null
541,"540,46.7,null,null",null,null
542,"541,9.1 194,null,null",null,null
543,"542,BSS,null,null",null,null
544,"543,0.20,null,null",null,null
545,"544,40.0,null,null",null,null
546,"545,8.2 204,null,null",null,null
547,"546,BSS,null,null",null,null
548,"547,0.25,null,null",null,null
549,"548,36.0,null,null",null,null
550,"549,6.9 191,null,null",null,null
551,"550,BSS-FC 0.05,null,null",null,null
552,"551,23.4,null,null",null,null
553,"552,""29.5 1,263"",null,null",null,null
554,"553,BSS-FC 0.10,null,null",null,null
555,"554,16.8,null,null",null,null
556,"555,""25.5 1,515"",null,null",null,null
557,"556,BSS-FC 0.15,null,null",null,null
558,"557,14.7,null,null",null,null
559,"558,""24.0 1,632"",null,null",null,null
560,"559,BSS-FC 0.20,null,null",null,null
561,"560,13.1,null,null",null,null
562,"561,""21.4 1,634"",null,null",null,null
563,"562,BSS-FC 0.25,null,null",null,null
564,"563,12.6,null,null",null,null
565,"564,""19.4 1,547"",null,null",null,null
566,"565,BTFNL 0.05,null,null",null,null
567,"566,22.1,null,null",null,null
568,"567,""65.2 2,954"",null,null",null,null
569,"568,BTFNL 0.10,null,null",null,null
570,"569,16.0,null,null",null,null
571,"570,""57.7 3,595"",null,null",null,null
572,"571,BTFNL 0.15,null,null",null,null
573,"572,13.7,null,null",null,null
574,"573,""57.0 4,163"",null,null",null,null
575,"574,BTFNL 0.20,null,null",null,null
576,"575,12.5,null,null",null,null
577,"576,""46.7 3,746"",null,null",null,null
578,"577,BTFNL 0.25,null,null",null,null
579,"578,11.9,null,null",null,null
580,"579,""41.6 3,510"",null,null",null,null
581,"580,""5The BSS Bloom filter targeted  , 0.1 for terms with IDF 4. The BSS-FC and BTFNL configurations set  ,"""" 0.1 for all terms, regardless of frequency."""""",null,null",null,null
582,"581,Frequency consciousness reduces storage consumption while,null,null",null,null
583,"582,""increasing speed. For example, at d ,"""" 0.15, the BSS configuration"""""",null,null",null,null
584,"583,uses 46.7 bits per posting while the BSS-FC configuration uses only,null,null",null,null
585,"584,14.7. This 3.2x reduction in storage is achieved while yielding a,null,null",null,null
586,"585,2.6x increase in speed. The intuition behind the improvement is,null,null",null,null
587,"586,that frequency consciousness allows each term to have the right,null,null",null,null
588,"587,""number of rows. With classical Bloom filters, every term has the"",null,null",null,null
589,"588,""same number of rows, meaning that more common terms get excess"",null,null",null,null
590,"589,rows as a side effect of providing sufficient rows to ensure the target,null,null",null,null
591,"590,signal-to-noise level for rare terms.,null,null",null,null
592,"591,""Higher Rank Rows mainly impact speed. For example, when"",null,null",null,null
593,"592,""d ,"""" 0.15, BSS-FC runs at 24K queries per second, while BTFNL"""""",null,null",null,null
594,"593,""runs at 57.0K, a 2.4x improvement. The intuition behind the speed"",null,null",null,null
595,"594,up is that higher rank rows can be scanned more quickly than,null,null",null,null
596,"595,""rank-0 rows. Generally speaking, processing a rank-r row involves"",null,null",null,null
597,"596,scanning,null,null",null,null
598,"597,1 2r,null,null",null,null
599,"598,of the quadwords necessary to process a rank-0 row.,null,null",null,null
600,"599,The DQ column captures the tradeoff between space and speed.,null,null",null,null
601,"600,""BSS-FC has a DQ of 1,632, while BTFNL has a DQ of 4,163, a 2.6x"",null,null",null,null
602,"601,improvement. Combining frequency consciousness with higher,null,null",null,null
603,"602,rank rows yields a 21x improvement over that BSS DQ of 194.,null,null",null,null
604,"603,""We found that a density of 0.15 yielded the best DQ for Corpora B,"",null,null",null,null
605,"604,""C, and D, while A and E performed best at 0.05 and 0.20, respectively."",null,null",null,null
606,"605,6.3 Comparison with Contemporary Indexes,null,null",null,null
607,"606,""The version of BitFunnel used by Bing includes a forward index with term frequencies used for BM25F ranking. Because this ranking code was not available to us at the time we designed our experiment, we limited our comparison to conjunctive boolean matching."",null,null",null,null
608,"607,""Our primary comparison system was Partitioned Elias-Fano or PEF[23]. This system is considered state-of-the-art, has excellent performance, and, like BitFunnel, is implemented in C++. We also compared with MG4J's Java implementation of PEF6. This implementation was the second fastest system in the SIGIR 2015 RIGOR workshop[18]. Our final comparison was with Lucene7, a popular Java-based search engine that outperformed MG4J at the RIGOR workshop, in an apples-to-apples comparison using BM25F."",null,null",null,null
609,"608,""Each of these systems was configured to use a memory-mapped index that was non-positional, with scoring disabled. In this configuration, PEF and MG4J pay no runtime penalty associated with term frequencies because the frequencies are stored in a separate data structure that is never consulted. It is unclear whether Lucene pays a cost associated with stepping past term frequency values."",null,null",null,null
610,"609,""For each system we used 8 threads to process the entire 98k query log twice, back-to-back, measuring performance on the second pass. This ensured that relevant portions of the index were paged in, as they would be under continuous production load."",null,null",null,null
611,"610,""We can see from Table 3 that BitFunnel is faster than PEF in all cases, but sometimes this comes at a significant cost, for example in Corpus A, BitFunnel uses 5x as many bits per posting while yielding a false positive rate of 1.62%. Across the 5 corpora, MG4J is slower than PEF, as expected since it implements the same algorithm, but in Java. MG4J is faster than Lucene in all but Corpus C."",null,null",null,null
612,"611,""BitFunnel's overall performance relative to PEF improves as document lengths increase. It first surpasses PEF in Corpus C, where it"",null,null",null,null
613,"612,6 http://mg4j.di.unimi.it/ 7 https://lucene.apache.org/,null,null",null,null
614,"613,613,null,null",null,null
615,"614,Session 5C: Efficiency and Scalability,null,null",null,null
616,"615,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
617,"616,""shows 3.2x the QPS of PEF while using only 2.6x the space. Examining DQ, the ratio of QPS to bits-per-posting, we see that BitFunnel outperforms PEF by factors of 1.3, 3.1, and 4.2 in Corpora C, D, and E, respectively, while PEF outperforms BitFunnel by factors of 3.4 and 1.6 in Corpora A and B."",null,null",null,null
618,"617,Table 3: Query Processing Performance.,null,null",null,null
619,"618,BitFunnel PEF MG4J Lucene,null,null",null,null
620,"619,QPS,null,null",null,null
621,"620,""21,427 14,675 6,866 6,310"",null,null",null,null
622,"621,False positives (%),null,null",null,null
623,"622,1.62 0.00 0.00 0.00,null,null",null,null
624,"623,A Bits per posting,null,null",null,null
625,"624,38.43 7.64 7.85,null,null",null,null
626,"625,­,null,null",null,null
627,"626,DQ,null,null",null,null
628,"627,""558 1,921 875"",null,null",null,null
629,"628,­,null,null",null,null
630,"629,QPS,null,null",null,null
631,"630,""8,674 5,049 3,636 3,011"",null,null",null,null
632,"631,False positives (%),null,null",null,null
633,"632,4.32 0.00 0.00 0.00,null,null",null,null
634,"633,B Bits per posting,null,null",null,null
635,"634,20.72 7.33 7.59,null,null",null,null
636,"635,­,null,null",null,null
637,"636,DQ,null,null",null,null
638,"637,419 689 479,null,null",null,null
639,"638,­,null,null",null,null
640,"639,QPS,null,null",null,null
641,"640,""12,722 3,959 3,096 4,120"",null,null",null,null
642,"641,False positives (%),null,null",null,null
643,"642,3.88 0.00 0.00 0.00,null,null",null,null
644,"643,C Bits per posting,null,null",null,null
645,"644,16.91 6.63 6.88,null,null",null,null
646,"645,­,null,null",null,null
647,"646,DQ,null,null",null,null
648,"647,752 598 450,null,null",null,null
649,"648,­,null,null",null,null
650,"649,QPS,null,null",null,null
651,"650,""57,014 8,268 5,900 3,632"",null,null",null,null
652,"651,False positives (%),null,null",null,null
653,"652,2.43 0.00 0.00 0.00,null,null",null,null
654,"653,D Bits per posting,null,null",null,null
655,"654,13.69 6.25 6.28,null,null",null,null
656,"655,­,null,null",null,null
657,"656,DQ,null,null",null,null
658,"657,""4,163 1,322 939"",null,null",null,null
659,"658,­,null,null",null,null
660,"659,QPS,null,null",null,null
661,"660,""105,782 13,151 7,349 4,991"",null,null",null,null
662,"661,False positives (%),null,null",null,null
663,"662,2.64 0.00 0.00 0.00,null,null",null,null
664,"663,E Bits per posting,null,null",null,null
665,"664,11.69 6.15 6.15,null,null",null,null
666,"665,­,null,null",null,null
667,"666,DQ,null,null",null,null
668,"667,""9,047 2,139 1,195"",null,null",null,null
669,"668,­,null,null",null,null
670,"669,""These results are consistent with the interpretation that the biggest factor in BitFunnel performance is row length, which is directly proportional to the number of documents in the corpus. As document lengths increase and the corpus size drops, BitFunnel performance improves relative to PEF."",null,null",null,null
671,"670,""It is unclear from these results, the extent to which BitFunnel's performance gains are the result of a careful implementation versus actual algorithmic gains. We can see from PEF vs MG4J that choice of implementation language can have a significant impact on performance. Since BitFunnel compiles each query into x64 machine code, it is likely that some of BitFunnel's gains come from highly optimized query code."",null,null",null,null
672,"671,7 CONCLUSION,null,null",null,null
673,"672,""This work revisits bit-sliced signatures and describes their use in a commercial search engine, which previously used inverted files. Signature-based approaches introduce several challenges and we develop a set of techniques to reduce the memory footprint and to process queries quickly. Furthermore, we derive a performance model that allows expressing the system configuration as an optimization problem. We evaluate the key techniques behind BitFunnel experimentally, and we provide the source code publicly to accelerate advances in this area."",null,null",null,null
674,"673,8 ACKNOWLEDGMENTS,null,null",null,null
675,"674,""We thank the following colleagues for their contributions to BitFunnel: Andrija Antonijevic, Tanj Bennett, Denis Deyneko, Utkarsh"",null,null",null,null
676,"675,""Jain, and Fan Wang. We also thank the anonymous reviewers for"",null,null",null,null
677,"676,their feedback which led to an improved experimental section.,null,null",null,null
678,"677,REFERENCES,null,null",null,null
679,"678,""[1] Burton H Bloom. 1970. Space/time trade-offs in hash coding with allowable errors. Commun. ACM 13, 7 (1970), 422­426."",null,null",null,null
680,"679,""[2] Sergey Brin and Lawrence Page. 1998. The Anatomy of a Large-Scale Hypertextual Web Search Engine. Computer Networks 30, 1-7 (1998), 107­117."",null,null",null,null
681,"680,""[3] Jehoshua Bruck, Jie Gao, and Anxiao Jiang. 2006. Weighted bloom filter. In 2006 IEEE International Symposium on Information Theory. IEEE."",null,null",null,null
682,"681,""[4] Stefan Büttcher, Charles LA Clarke, and Gordon V Cormack. 2016. Information retrieval: Implementing and evaluating search engines. Mit Press."",null,null",null,null
683,"682,[5] Berkant Barla Cambazoglu and Ricardo A. Baeza-Yates. 2015. Scalability Challenges in Web Search Engines. Morgan & Claypool Publishers.,null,null",null,null
684,"683,""[6] J Shane Culpepper and Alistair Moffat. 2010. Efficient set intersection for inverted indexing. ACM Transactions on Information Systems (TOIS) 29, 1 (2010), 1."",null,null",null,null
685,"684,""[7] Bolin Ding and Arnd Christian König. 2011. Fast set intersection in memory. Proceedings of the VLDB Endowment 4, 4 (2011), 255­266."",null,null",null,null
686,"685,""[8] Chris Faloutsos. 1985. Access methods for text. ACM Computing Surveys (CSUR) 17, 1 (1985), 49­74."",null,null",null,null
687,"686,""[9] Christos Faloutsos. 1992. Information retrieval: data structures and algorithms. Prentice Hall PTR, 44­65."",null,null",null,null
688,"687,[10] Christos Faloutsos and Stavros Christodoulakis. 1985. Design of a Signature File Method that Accounts for Non-Uniform Occurrence and Query Frequencies.. In VLDB. 165­170.,null,null",null,null
689,"688,""[11] Edward Fox, Donna Harman, w. Lee, and Ricardo Baeza-Yates. 1992. Information retrieval: data structures and algorithms. Prentice Hall PTR, 28­43."",null,null",null,null
690,"689,""[12] Shlomo Geva and Christopher M De Vries. 2011. Topsig: Topology preserving document signatures. In Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 333­338."",null,null",null,null
691,"690,""[13] Andrew Kane and Frank Wm Tompa. 2014. Skewed partial bitvectors for list intersection. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval. ACM, 263­272."",null,null",null,null
692,"691,""[14] A Kent, Ron Sacks-Davis, and Kotagiri Ramamohanarao. 1990. A signature file scheme based on multiple organizations for indexing very large text databases. Journal of the American Society for Information Science 41, 7 (1990), 508."",null,null",null,null
693,"692,""[15] Donald E Knuth. 1998. The Art of Computer Programming, Vol. 3, Sorting and Searching (2nd ed.). Vol. 3. Addison-Wesley, 567­573."",null,null",null,null
694,"693,""[16] Roberto Konow, Gonzalo Navarro, Charles LA Clarke, and Alejandro López-Ortíz. 2013. Faster and smaller inverted indices with treaps. In Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval. ACM, 193­202."",null,null",null,null
695,"694,""[17] Daniel Lemire and Leonid Boytsov. 2015. Decoding billions of integers per second through vectorization. Software: Practice and Experience 45, 1 (2015), 1­29."",null,null",null,null
696,"695,""[18] Jimmy Lin, Matt Crane, Andrew Trotman, Jamie Callan, Ishan Chattopadhyaya, John Foley, Grant Ingersoll, Craig Macdonald, and Sebastiano Vigna. 2016. Toward reproducible baselines: The open-source ir reproducibility challenge. In European Conference on Information Retrieval. Springer, 408­420."",null,null",null,null
697,"696,""[19] Sergey Melnik, Sriram Raghavan, Beverly Yang, and Hector Garcia-Molina. 2001. Building a distributed full-text index for the Web. In Proceedings of the Tenth International World Wide Web Conference, WWW 10, Hong Kong, China, May 1-5, 2001. 396­406."",null,null",null,null
698,"697,""[20] Alistair Moffat and Justin Zobel. 1996. Self-indexing inverted files for fast text retrieval. ACM Transactions on Information Systems (TOIS) 14, 4 (1996), 349­379."",null,null",null,null
699,"698,[21] Calvin N Mooers. 1948. Application of random codes to the gathering of statistical information. Ph.D. Dissertation. Massachusetts Institute of Technology.,null,null",null,null
700,"699,""[22] Calvin N Mooers. 1951. Zatocoding applied to mechanical organization of knowledge. American documentation 2, 1 (1951), 20­32."",null,null",null,null
701,"700,""[23] Giuseppe Ottaviano and Rossano Venturini. 2014. Partitioned elias-fano indexes. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval. ACM, 273­282."",null,null",null,null
702,"701,""[24] Knut Magne Risvik, Trishul M. Chilimbi, Henry Tan, Karthik Kalyanaraman, and Chris Anderson. 2013. Maguro, a system for indexing and searching over very large text collections. In Sixth ACM International Conference on Web Search and Data Mining, WSDM 2013, Rome, Italy, February 4-8, 2013. 727­736."",null,null",null,null
703,"702,""[25] Charles S Roberts. 1979. Partial-match retrieval via the method of superimposed codes. Proc. IEEE 67, 12 (1979), 1624­1642."",null,null",null,null
704,"703,""[26] Ron Sacks-Davis, A Kent, and Kotagiri Ramamohanarao. 1987. Multikey access methods based on superimposed coding techniques. ACM Transactions on Database Systems (TODS) 12, 4 (1987), 655­696."",null,null",null,null
705,"704,""[27] Harry KT Wong, Hsiu-Fen Liu, Frank Olken, Doron Rotem, and Linda Wong. 1985. Bit Transposed Files.. In VLDB, Vol. 85. Citeseer, 448­457."",null,null",null,null
706,"705,""[28] Justin Zobel, Alistair Moffat, and Kotagiri Ramamohanarao. 1998. Inverted files versus signature files for text indexing. ACM Transactions on Database Systems (TODS) 23, 4 (1998), 453­490."",null,null",null,null
707,"706,614,null,null",null,null
708,"707,,null,null",null,null
