,sentence,label,data
0,",sentence,label,data",null,null
1,"0,Short Research Paper,null,null",null,null
2,"1,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
3,"2,Term Proximity Constraints for Pseudo-Relevance Feedback,null,null",null,null
4,"3,Ali Montazeralghaem,null,null",null,null
5,"4,""School of ECE, College of Engineering University of Tehran, Iran ali.montazer@ut.ac.ir"",null,null",null,null
6,"5,Hamed Zamani,null,null",null,null
7,"6,""Center for Intelligent Information Retrieval,"",null,null",null,null
8,"7,University of Massachuse s Amherst zamani@cs.umass.edu,null,null",null,null
9,"8,Azadeh Shakery,null,null",null,null
10,"9,""School of ECE, College of Engineering University of Tehran, Iran"",null,null",null,null
11,"10,""School of Computer Science, Institute for Research in Fundamental Sciences"",null,null",null,null
12,"11,shakery@ut.ac.ir,null,null",null,null
13,"12,ABSTRACT,null,null",null,null
14,"13,""Pseudo-relevance feedback (PRF) refers to a query expansion strategy based on top-retrieved documents, which has been shown to be highly e ective in many retrieval models. Previous work has introduced a set of constraints (axioms) that should be satis ed by any PRF model. In this paper, we propose three additional constraints based on the proximity of feedback terms to the query terms in the feedback documents. As a case study, we consider the log-logistic model, a state-of-the-art PRF model that has been proven to be a successful method in satisfying the existing PRF constraints, and show that it does not satisfy the proposed constraints. We further modify the log-logistic model based on the proposed proximity-based constraints. Experiments on four TREC collections demonstrate the e ectiveness of the proposed constraints. Our modi cation to the log-logistic model leads to signi cant and substantial (up to 15%) improvements. Furthermore, we show that the proposed proximity-based function outperforms the well-known Gaussian kernel which does not satisfy all the proposed constraints."",null,null",null,null
15,"14,KEYWORDS,null,null",null,null
16,"15,""Term proximity, term position, axiomatic analysis, pseudo-relevance feedback, query expansion"",null,null",null,null
17,"16,""ACM Reference format: Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Term Proximity Constraints for Pseudo-Relevance Feedback. In Proceedings of SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages. DOI: 10.1145/3077136.3080728"",null,null",null,null
18,"17,1 INTRODUCTION,null,null",null,null
19,"18,""Pseudo-relevance feedback (PRF) is a query expansion strategy to address the vocabulary mismatch problem in information retrieval (IR). In PRF, a small set of top-retrieved documents (i.e., pseudo-relevant documents) are assumed to be relevant to the initial query. ese pseudo-relevant documents are further used for updating the query model in order to improve the retrieval performance. PRF has been proven to be highly e ective in many retrieval models [2, 10, 13, 14]."",null,null",null,null
20,"19,eoretical analysis of PRF models has shown that there are several constraints (axioms) that every PRF model should satisfy. Based,null,null",null,null
21,"20,""Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: 10.1145/3077136.3080728"",null,null",null,null
22,"21,""on these theoretical studies, several modi cations, e.g., [1, 3, 9, 10], have been made to the existing PRF models which lead to signi cant improvements in the retrieval performance. Although term proximity has been shown to be a strong evidence for improving the retrieval performance [5, 12], especially in the PRF task [6­8], none of the existing constraints for PRF takes term proximity into account.1"",null,null",null,null
23,"22,""In this paper, we provide a theoretical analysis for the use of term proximity in PRF models. To do so, we introduce three PRF constraints based on the proximity of candidate feedback terms and the query terms in the feedback documents. According to the rst constraint (""""proximity e ect""""), the candidate feedback terms that are positionally closer to the query terms in the feedback documents should be given higher weights in the feedback model. e second constraint (""""convexity e ect"""") decreases the e ect of term proximity when the distance between terms increases. e third constraint indicates that proximity to the less common query terms is more important than proximity to the query terms that are general."",null,null",null,null
24,"23,""Furthermore, previous work on leveraging term proximity for IR tasks, including the positional relevance model, showed that the Gaussian kernel is an e ective way for enhancing IR models with term proximity information [5, 6, 8]. In this paper, we show that the Gaussian kernel does not satisfy all the proposed constraints, and thus it could not be the best way for applying term proximity to PRF models."",null,null",null,null
25,"24,e primary contributions of this work can be summarized as follows:,null,null",null,null
26,"25,· Introducing three proximity-based constraints for theoretical analysis of PRF models.,null,null",null,null
27,"26,""· Studying and modifying the log-logistic feedback model [2], a state-of-the-art PRF model that outperforms many existing models, including the mixture model [14] and the geometric relevance model [11] (see [3] for more details)."",null,null",null,null
28,"27,· Introducing a variant of the Exponential kernel that satis es all the proposed constraints.,null,null",null,null
29,"28,""· Evaluating our models using four TREC collections which demonstrates signi cant improvements over the original log-logistic model as well as the model enriched with the Gaussian kernel, a widely used weighting function for enhancing IR models using term proximity [5, 6, 8]."",null,null",null,null
30,"29,2 METHODOLOGY,null,null",null,null
31,"30,""In this section, we rst introduce three proximity-based constraints that (pseudo-) relevance feedback methods should satisfy. We further analyze the log-logistic model [2], and show that this model"",null,null",null,null
32,"31,""1Tao and Zhai [12] proposed two proximity-based constraints for retrieval models, but not for PRF models."",null,null",null,null
33,"32,1085,null,null",null,null
34,"33,Short Research Paper,null,null",null,null
35,"34,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
36,"35,does not satisfy the proposed constraints. We nally modify the log-logistic feedback model in order to satisfy all the constraints.,null,null",null,null
37,"36,""We rst introduce our notation. Let FW (w; F , Pw , Q) denote the feedback weight function that assigns a real-valued weight to each feedback term w for a given query Q based on the feedback document set F . Pw is a set of term-dependent parameters. For simplicity, FW (w) is henceforth used as the feedback weight function. In the following equations, T F and I DF are term frequency and inverse document frequency, respectively. | · | represents the size of the given set."",null,null",null,null
38,"37,2.1 Constraints,null,null",null,null
39,"38,""In this subsection, we introduce three proximity-based constraints for PRF methods."",null,null",null,null
40,"39,""[Proximity e ect] Let d(w, q, D) denote the proximity weight of a candidate feedback term w and a given query term q in a feedback document D. en, the following constraint should hold:"",null,null",null,null
41,"40,""FW (w) d(w, q, D)"",null,null",null,null
42,"41,<,null,null",null,null
43,"42,0,null,null",null,null
44,"43,""According to this constraint, the candidate feedback terms that are closer to the query terms in the feedback documents should have higher weights. Intuitively, the closer terms to the query terms are more likely to be relevant to the query."",null,null",null,null
45,"44,[Convexity e ect] e feedback weight function should be convex with respect to the distance of candidate feedback terms from the query terms. We can formalize this constraint as follows:,null,null",null,null
46,"45,""2FW (w) d(w, q, D)2"",null,null",null,null
47,"46,>0,null,null",null,null
48,"47,e intuition behind this constraint is that decreasing the e ect of,null,null",null,null
49,"48,the proximity e ect should be less marked in high distance ranges.,null,null",null,null
50,"49,""[ ery IDF e ect] Let Q ,"""" {q1, q2} be a query with two query terms q1 and q2. Let D1 and D2 denote two feedback documents with equal length, such that q1 only appears in D1, and q2 only appears in D2. Let w1 and w2 be two candidate feedback terms, such that T F (w1, D1) """","""" T F (w2, D2), and w1 and w2 only appear in D1 and D2 in the feedback set, respectively. Also assume that d(w1, q1, D1) """","""" d(w2, q2, D2) where d is the function to compute the proximity between two terms in a given document. We can say"""""",null,null",null,null
51,"50,""if I DF (q1) > I DF (q2), then we should have:"",null,null",null,null
52,"51,FW (w1) > FW (w2),null,null",null,null
53,"52,""Intuitively, this constraint indicates that proximity to the query terms that are general is less important than proximity to the uncommon query terms. For instance, if a query contains a general term (let say a stopword) then proximity to this term should be less important than the discriminative terms that occur in the query."",null,null",null,null
54,"53,2.2 Modifying the Log-Logistic Model,null,null",null,null
55,"54,""As a case study, we analyze and modify the log-logistic feedback model [2]. e reason is that this method has been shown to outperform many strong baselines, including the mixture model [14] and the geometric relevance model [11]. It has been also shown that this method successfully satis es all the PRF constraints proposed in [3]. e log-logistic feedback weight function for each term w is"",null,null",null,null
56,"55,computed as:,null,null",null,null
57,"56,FW (w),null,null",null,null
58,"57,"","",null,null",null,null
59,"58,1 |F |,null,null",null,null
60,"59,D F,null,null",null,null
61,"60,log(1 +,null,null",null,null
62,"61,""t(w, D) ) w"",null,null",null,null
63,"62,(1),null,null",null,null
64,"63,where,null,null",null,null
65,"64,t,null,null",null,null
66,"65,""(w ,"",null,null",null,null
67,"66,d,null,null",null,null
68,"67,),null,null",null,null
69,"68,"","",null,null",null,null
70,"69,T,null,null",null,null
71,"70,F,null,null",null,null
72,"71,""(w,"",null,null",null,null
73,"72,D),null,null",null,null
74,"73,log(1,null,null",null,null
75,"74,+,null,null",null,null
76,"75,c,null,null",null,null
77,"76,a |D,null,null",null,null
78,"77,l,null,null",null,null
79,"78,|,null,null",null,null
80,"79,),null,null",null,null
81,"80,(a,null,null",null,null
82,"81,l denotes the average,null,null",null,null
83,"82,document length and c is a free hyper-parameter that controls,null,null",null,null
84,"83,the document length e ect). e document frequency term w is calculated as:,null,null",null,null
85,"84,""w , Nw /N"",null,null",null,null
86,"85,(2),null,null",null,null
87,"86,""where Nw and N denote the number of documents in the collection that contain w and the total number of documents in the collection,"",null,null",null,null
88,"87,respectively. FW (w) is then interpolated with the original query,null,null",null,null
89,"88,based on a free parameter (feedback coe cient)[2].,null,null",null,null
90,"89,It can be easily shown that the log-logistic feedback model does,null,null",null,null
91,"90,""not satisfy the proximity-based constraints, since its formulation"",null,null",null,null
92,"91,does not contain any proximity-based component. To the best of,null,null",null,null
93,"92,""our knowledge, this is the rst a empt to enrich the log-logistic"",null,null",null,null
94,"93,feedback model using term proximity information.,null,null",null,null
95,"94,""Regarding the query term independence assumption, we propose"",null,null",null,null
96,"95,to modify the log-logistic model as follows to satisfy the proximity-,null,null",null,null
97,"96,based constraints:,null,null",null,null
98,"97,""FWprox (w) , FW (w) "",null,null",null,null
99,"98,"" (w, q, D)"",null,null",null,null
100,"99,(3),null,null",null,null
101,"100,D F q Q,null,null",null,null
102,"101,""where q is a query term and  (w, q, D) is a function that computes the proximity of w and q in document D."",null,null",null,null
103,"102,""To de ne the function  , we propose to use the Exponential kernel that satis es the """"proximity e ect"""" and the """"convexity e ect"""" constraints. We modify the Exponential kernel by adding an IDF term to satisfy the """" ery IDF e ect"""" constraint, as well. e function  can be computed as follows:"",null,null",null,null
104,"103,"" (w, q, D) , exp"",null,null",null,null
105,"104,""-d(w, q, D) "",null,null",null,null
106,"105,. log 1 q,null,null",null,null
107,"106,(4),null,null",null,null
108,"107,""where d(w, q, D) denotes the distance function for two given terms w and q in document D. q is the document frequency component for the query term q (see Equation (2)) and  is a free parameter. Several approaches have been proposed to compute d(w, q, D), such as average, minimum, and maximum distances. Tao and Zhai [12] showed that using the minimum distance between the term w and the query term q in the feedback document outperforms other distance functions. We also use the minimum distance as follows:"",null,null",null,null
109,"108,""d(w, q, D) , min |wi - qj |"",null,null",null,null
110,"109,(5),null,null",null,null
111,"110,wi wì & qj qì,null,null",null,null
112,"111,""where wì and qì are two vectors containing the positions of term w and query term q in document D, respectively."",null,null",null,null
113,"112,3 EXPERIMENTS,null,null",null,null
114,"113,3.1 Experimental Setup,null,null",null,null
115,"114,""We used four standard TREC collections in our experiments: AP (Associated Press 1988-89), Robust (TREC Robust Track 2004 collection), WT2g (TREC Web Track 2000 collection), and WT10g (TREC Web Track 2001-2002 collection). e rst two are newswire collections, while the next two are web collections containing more noisy documents. e statistics of these collections are reported in Table 1. We considered the title of topics as queries. All documents"",null,null",null,null
116,"115,1086,null,null",null,null
117,"116,Short Research Paper,null,null",null,null
118,"117,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
119,"118,Table 1: Collections statistics.,null,null",null,null
120,"119,Collection AP,null,null",null,null
121,"120,Robust WT2g WT10g,null,null",null,null
122,"121,TREC topics 51-200,null,null",null,null
123,"122,301-450 & 601-700 401-450 451-550,null,null",null,null
124,"123,#docs 165k 528k 247k 1692k,null,null",null,null
125,"124,doc length 287 254 645 399,null,null",null,null
126,"125,#qrels 15838 17412 2279 5931,null,null",null,null
127,"126,were stemmed using the Porter stemmer and stopped using the standard INQUERY stopword list. We carried out the experiments using the Lemur toolkit2.,null,null",null,null
128,"127,""3.1.1 Parameter Se ing. e number of feedback documents, the feedback term count, and the feedback coe cient were set using 2-fold cross validation over the queries of each collection. We swept the number of feedback documents between {10, 25, 50, 75, 100}, the feedback term count between {10, 25, 50, 75, 100}, and the feedback coe cient between {0, 0.1, · · · , 1}. e parameters c and  were also selected using the same procedure from {2, 4, · · · , 10} and {25, 50, · · · , 500}, respectively. e parameter  in the Gaussian kernel is also set similarly."",null,null",null,null
129,"128,""3.1.2 Evaluation Metrics. To evaluate retrieval e ectiveness, we use mean average precision (MAP) of the top-ranked 1000 documents as the main evaluation metric. In addition, we also report the precision of the top 10 retrieved documents (P@10). Statistically signi cant di erences of average precisions are determined using the two-tailed paired t-test computed at a 95% con dence level. To evaluate robustness of methods, we consider the robustness index (RI) introduced in [4]."",null,null",null,null
130,"129,3.2 Results and Discussion,null,null",null,null
131,"130,""In this subsection, we rst empirically show that satisfying each of the introduced constraints improves the retrieval performance. Our experiments also demonstrate that the Gaussian kernel that has previously been used in the literature [5, 6, 8] is not as e ective as the proposed proximity weighting function, since the Gaussian kernel does not satisfy all the constraints."",null,null",null,null
132,"131,""3.2.1 Analysis of the Proximity-based Constraints. We consider two baselines: (1) the document retrieval method without feedback (NoPRF), and (2) the original log-logistic feedback model (LL). Although there are several e ective PRF methods, since in this paper we study the e ect of the proposed constraints in the log-logistic model, we do not consider other existing PRF methods."",null,null",null,null
133,"132,""To study the in uence of each of the proposed constraints on the retrieval performance, we consider three di erent proximity functions: (1) the quadratic function ( ad) that only satis es the """"proximity e ect"""" constraint, (2) the exponential function (Exp) that satis es both """"proximity e ect"""" and """"convexity e ect"""" constraints, and (3) a modi ed version of the exponential function (Exp*) that satis es all three constraints. More detail is reported Table 2."",null,null",null,null
134,"133,""e results of the baselines and the aforementioned methods are reported in Table 3. According to this table, modifying the loglogistic method using each of the proximity functions improves the retrieval performance, in all collections. e MAP improvements are statistically signi cant in nearly all cases. is indicates the necessity of taking term proximity into account for the PRF task."",null,null",null,null
135,"134,2h p://lemurproject.org/,null,null",null,null
136,"135,""Table 2: Summary of di erent proximity functions with respect to the proximity-based constraints (x ,"""" d(w, q, D))."""""",null,null",null,null
137,"136,""Func.  (w, q, D)"",null,null",null,null
138,"137,Gaus,null,null",null,null
139,"138,exp[,null,null",null,null
140,"139,-x 2,null,null",null,null
141,"140,2 2,null,null",null,null
142,"141,],null,null",null,null
143,"142,ad,null,null",null,null
144,"143,-(,null,null",null,null
145,"144,x ,null,null",null,null
146,"145,)2,null,null",null,null
147,"146,+,null,null",null,null
148,"147,1,null,null",null,null
149,"148,Exp,null,null",null,null
150,"149,exp[,null,null",null,null
151,"150,-x ,null,null",null,null
152,"151,],null,null",null,null
153,"152,Exp*,null,null",null,null
154,"153,exp[,null,null",null,null
155,"154,-x ,null,null",null,null
156,"155,].,null,null",null,null
157,"156,log,null,null",null,null
158,"157,N Nq,null,null",null,null
159,"158,Proximity Convexity e ect e ect,null,null",null,null
160,"159,Yes Partially,null,null",null,null
161,"160,Yes,null,null",null,null
162,"161,No,null,null",null,null
163,"162,Yes,null,null",null,null
164,"163,Yes,null,null",null,null
165,"164,Yes,null,null",null,null
166,"165,Yes,null,null",null,null
167,"166,ery IDF e ect,null,null",null,null
168,"167,No,null,null",null,null
169,"168,No,null,null",null,null
170,"169,No,null,null",null,null
171,"170,Yes,null,null",null,null
172,"171,""e results demonstrate that LL+Exp outperforms LL+ ad and LL+Exp* outperforms LL+Exp, in all collections. e improvements in the web collections are higher than those in the newswire collections. e reason is that these two collections are web crawls and contain more noisy documents compared to the newswire collections. e other reason is that the WT2g and WT10g documents are much longer than the AP and Robust documents on average (see Table 1). e in uence of proximity-based constraints can be highlighted in longer documents. Besides that, in terms of RI, LL+Exp* outperforms all the baselines in AP, WT2g and WT10g which shows the importance and robustness of ery IDF e ect and these improvements are impressive in WT2g and WT10g which shows that this e ect is important in noisy (web) collections."",null,null",null,null
173,"172,""3.2.2 Analysis of the Gaussian Kernel. In this set of experiments, we study the Gaussian kernel for computing the proximity weight, which has been shown to be the most e ective proximity function among the existing ones [5]. As reported in Table 2, employing the Gaussian kernel for PRF satis es the """"proximity e ect"""" constraint. e """"convexity e ect"""" constraint is only satis ed when d(w, q, D) >  . erefore, it does not satisfy the """"convexity e ect"""" for the candidate feedback terms that are close to the query terms. We evaluate the Gaussian kernel by considering it as a term proximity weight function (LL+Gaus). According to the results reported in Table 3, LL+Exp and LL+Gaus perform comparably in the newswire collections, but LL+Exp outperforms LL+Gaus in the web collections (WT2g and WT10g). LL+Exp* also outperforms LL+Gaus in all collections. e improvements in the web collections are statistically signi cant."",null,null",null,null
174,"173,""3.2.3 Parameter Sensitivity. In the last set of experiments, we study the sensitivity of the proposed method to the following hyperparameters: the number of feedback terms added to the query, (2) the feedback interpolation coe cient, and (3) the parameter  (see Equation (4)). To do so, we sweep one of the parameters and x the other ones to their default values: 50 for feedback term count, 0.5 for feedback coe cient, and 25 for . In these experiments, we report the result for LL+Exp* that achieves the best performance in Table 3."",null,null",null,null
175,"174,""e results are plo ed in Figure 1, in terms of MAP. In this gure, the rst plot shows that the performance of LL+Exp* is stable with respect to the changes in the number of feedback terms, when more than 25 terms are added to the query. In other words, 25 terms are enough for expanding the query in most collections. e second plot in Figure 1 demonstrates that the behaviour of LL+Exp* in newswire collections is similar to each other. LL+Exp* also behaves similarly in the web collections. Interestingly, the feedback model estimated by LL+Exp* does not need to be interpolated with the original query"",null,null",null,null
176,"175,1087,null,null",null,null
177,"176,Short Research Paper,null,null",null,null
178,"177,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
179,"178,Table 3: Performance of di erent proximity functions applied to the log-logistic model. Superscripts 0/1/2 denote that the MAP improvements over NoPRF/LL/LL+Gaus are statistically signi cant. e highest value in each column is marked in bold.,null,null",null,null
180,"179,Method,null,null",null,null
181,"180,AP MAP P@10 RI,null,null",null,null
182,"181,Robust MAP P@10 RI,null,null",null,null
183,"182,WT2g MAP P@10 RI,null,null",null,null
184,"183,WT10g MAP P@10 RI,null,null",null,null
185,"184,NoPRF LL,null,null",null,null
186,"185,LL+Gaus,null,null",null,null
187,"186,LL+ ad LL+Exp LL+Exp*,null,null",null,null
188,"187,0.2642 0.4260 ­,null,null",null,null
189,"188,0.3385 0.4622 0.15,null,null",null,null
190,"189,0.347101 0.4695 0.19,null,null",null,null
191,"190,0.344101 0.4682 0.18 0.346801 0.4688 0.19 0.347501 0.4702 0.21,null,null",null,null
192,"191,0.2490 0.4237 ­,null,null",null,null
193,"192,0.2829 0.4393 0.33,null,null",null,null
194,"193,0.292601 0.4454 0.27,null,null",null,null
195,"194,0.292001 0.4530 0.30 0.293601 0.4442 0.28 0.295001 0.4430 0.30,null,null",null,null
196,"195,0.3033 0.4480 ­,null,null",null,null
197,"196,0.3276 0.4820 0.36,null,null",null,null
198,"197,0.33510 0.4920 0.38,null,null",null,null
199,"198,0.33090 0.4920 0.34 0.3418012 0.4840 0.38 0.3449012 0.4820 0.47,null,null",null,null
200,"199,0.2080 0.3030 ­,null,null",null,null
201,"200,0.2127 0.3187 0.08,null,null",null,null
202,"201,0.239301 0.3157 0.16,null,null",null,null
203,"202,0.21950 0.3075 0.02 0.243501 0.3247 0.19 0.2461012 0.3278 0.24,null,null",null,null
204,"203,0.35,null,null",null,null
205,"204,0.30,null,null",null,null
206,"205,0.25,null,null",null,null
207,"206, AP Robust,null,null",null,null
208,"207,WT2g WT10g,null,null",null,null
209,"208,0.35,null,null",null,null
210,"209, AP Robust,null,null",null,null
211,"210,WT2g WT10g,null,null",null,null
212,"211,0.30,null,null",null,null
213,"212,0.25,null,null",null,null
214,"213, AP Robust,null,null",null,null
215,"214,WT2g WT10g,null,null",null,null
216,"215,0.35    ,null,null",null,null
217,"216,0.30,null,null",null,null
218,"217,0.25,null,null",null,null
219,"218,MAP MAP MAP,null,null",null,null
220,"219,0.20 0,null,null",null,null
221,"220,25,null,null",null,null
222,"221,50,null,null",null,null
223,"222,75,null,null",null,null
224,"223,100,null,null",null,null
225,"224,0.20,null,null",null,null
226,"225,0.0,null,null",null,null
227,"226,0.2,null,null",null,null
228,"227,0.4,null,null",null,null
229,"228,0.6,null,null",null,null
230,"229,0.8,null,null",null,null
231,"230,1.0,null,null",null,null
232,"231,0.20 25 75 150,null,null",null,null
233,"232,300,null,null",null,null
234,"233,400,null,null",null,null
235,"234,500,null,null",null,null
236,"235,# of feedback terms,null,null",null,null
237,"236,feedback coefficient,null,null",null,null
238,"237,""Figure 1: Sensitivity of LL+Exp* to the number of feedback terms, the feedback coe cient, and the parameter ."",null,null",null,null
239,"238,""model in the newswire collections. In the web collections (WT2g and WT10g), giving a small weight (i.e., 0.2) to the original query model can help to improve the retrieval performance. e reason could be related to the noisy nature of the web collections compared to the newswire collections. e last plot in Figure 1 shows that the proposed method is not highly sensitive to the parameter  when it is higher than 100. e results indicate that 25 and 50 would be proper values for this parameter. e results on the web collections are more sensitive to this parameter. e reason is that the documents in the web collections are much longer than those in the newswire collections (see Table 1)."",null,null",null,null
240,"239,4 CONCLUSIONS AND FUTURE WORK,null,null",null,null
241,"240,""In this paper, we proposed three constraints for the pseudo-relevance feedback models, that focus on the proximity of the candidate feedback terms and the query terms in the feedback documents. To show the e ectiveness of the proposed constraints, we considered the log-logistic model, a state-of-the-art feedback model, as a case study. We rst showed that the log-logistic model does not satisfy the proximity-based constraints. We further modi ed it based on the proposed constraints. Our experiments on four standard TREC newswire and web collections demonstrated the e ectiveness of the proposed constraints for the PRF task. e modi ed log-logistic model signi cantly outperforms the original log-logistic model, in all collections. We also showed that the Gaussian kernel that has been used in previous proximity-based methods does not satisfy all the constraints. We show that the performance of the proposed variant of the exponential kernel is superior to those obtained by employing the Gaussian kernel. As a future direction, the other existing PRF models could be analyzed and modi ed based on the introduced constraints."",null,null",null,null
242,"241,Acknowledgements. is work was supported in part by the Center for,null,null",null,null
243,"242,Intelligent Information Retrieval and in part by a grant from the Institute,null,null",null,null
244,"243,""for Research in Fundamental Sciences (No. CS1396-4-51). Any opinions,"",null,null",null,null
245,"244,ndings and conclusions or recommendations expressed in this material,null,null",null,null
246,"245,are those of the authors and do not necessarily re ect those of the sponsors.,null,null",null,null
247,"246,REFERENCES,null,null",null,null
248,"247,""[1] Mozhdeh Ariannezhad, Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2017. Iterative Estimation of Document Relevance Score for PseudoRelevance Feedback. In ECIR '17. 676­683."",null,null",null,null
249,"248,[2] Ste´phane Clinchant and Eric Gaussier. 2010. Information-based Models for Ad Hoc IR. In SIGIR '10. 234­241.,null,null",null,null
250,"249,[3] Ste´phane Clinchant and Eric Gaussier. 2013. A eoretical Analysis of PseudoRelevance Feedback Models. In ICTIR '13. 6­13.,null,null",null,null
251,"250,[4] Kevyn Collins- ompson. 2009. Reducing the Risk of ery Expansion via Robust Constrained Optimization. In CIKM '09. 837­846.,null,null",null,null
252,"251,[5] Yuanhua Lv and ChengXiang Zhai. 2009. Positional Language Models for Information Retrieval. In SIGIR '09. 299­306.,null,null",null,null
253,"252,[6] Yuanhua Lv and ChengXiang Zhai. 2010. Positional Relevance Model for Pseudorelevance Feedback. In SIGIR '10. 579­586.,null,null",null,null
254,"253,""[7] Yuanhua Lv, ChengXiang Zhai, and Wan Chen. 2011. A Boosting Approach to Improving Pseudo-relevance Feedback. In SIGIR '11. 165­174."",null,null",null,null
255,"254,""[8] Jun Miao, Jimmy Xiangji Huang, and Zheng Ye. 2012. Proximity-based Rocchio's Model for Pseudo Relevance. In SIGIR '12. 535­544."",null,null",null,null
256,"255,""[9] Ali Montazeralghaem, Hamed Zamani, and Azadeh Shakery. 2016. Axiomatic Analysis for Improving the Log-Logistic Feedback Model. In SIGIR '16. 765­768."",null,null",null,null
257,"256,""[10] Dipasree Pal, Mandar Mitra, and Samar Bha acharya. 2015. Improving Pseudo Relevance Feedback in the Divergence from Randomness Model. In ICTIR '15. 325­328."",null,null",null,null
258,"257,[11] Jangwon Seo and W. Bruce Cro . 2010. Geometric Representations for Multiple Documents. In SIGIR '10. 251­258.,null,null",null,null
259,"258,[12] Tao Tao and ChengXiang Zhai. 2007. An Exploration of Proximity Measures in Information Retrieval. In SIGIR '07. 295­302.,null,null",null,null
260,"259,""[13] Hamed Zamani, Javid Dadashkarimi, Azadeh Shakery, and W. Bruce Cro . 2016. Pseudo-Relevance Feedback Based on Matrix Factorization. In CIKM '16. 1483­ 1492."",null,null",null,null
261,"260,[14] Chengxiang Zhai and John La erty. 2001. Model-based Feedback in the Language Modeling Approach to Information Retrieval. In CIKM '01. 403­410.,null,null",null,null
262,"261,1088,null,null",null,null
263,"262,,null,null",null,null
