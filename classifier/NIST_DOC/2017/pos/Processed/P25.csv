,sentence,label,data
0,",sentence,label,data",null,null
1,"0,Session 1A: Evaluation 1,null,null",null,null
2,"1,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
3,"2,""The Probability That Your Hypothesis Is Correct, Credible Intervals, and E ect Sizes for IR Evaluation"",null,null",null,null
4,"3,Tetsuya Sakai,null,null",null,null
5,"4,""Waseda University, Tokyo, Japan tetsuyasakai@acm.org"",null,null",null,null
6,"5,ABSTRACT,null,null",null,null
7,"6,""Using classical statistical signi cance tests, researchers can only discuss P(D+|H ), the probability of observing the data D at hand or something more extreme, under the assumption that the hypothesis H is true (i.e., the p-value). But what we usually want is P(H |D), the probability that a hypothesis is true, given the data. If we use Bayesian statistics with state-of-the-art Markov Chain Monte Carlo (MCMC) methods for obtaining posterior distributions, this is no longer a problem. at is, instead of the classical p-values and 95% con dence intervals, which are o en misinterpreted respectively as """"probability that the hypothesis is (in)correct"""" and """"probability that the true parameter value drops within the interval is 95%,"""" we can easily obtain P(H |D) and credible intervals which represent exactly the above. Moreover, with Bayesian tests, we can easily handle virtually any hypothesis, not just """"equality of means,"""" and obtain an Expected A Posteriori (EAP) value of any statistic that we are interested in. We provide simple tools to encourage the IR community to take up paired and unpaired Bayesian tests for comparing two systems. Using a variety of TREC and NTCIR data, we compare P(H |D) with p-values, credible intervals with con dence intervals, and Bayesian EAP e ect sizes with classical ones. Our results show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for the e ect size in terms of Glass's ."",null,null",null,null
8,"7,CCS CONCEPTS,null,null",null,null
9,"8,·Information systems  Retrieval e ectiveness; Presentation of retrieval results;,null,null",null,null
10,"9,""Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan. © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080766"",null,null",null,null
11,"10,KEYWORDS,null,null",null,null
12,"11,Bayesian hypothesis tests; con dence intervals; credible intervals; e ect sizes; Hamiltonian Monte Carlo; Markov Chain Monte Carlo; p-values; statistical signi cance,null,null",null,null
13,"12,1 INTRODUCTION,null,null",null,null
14,"13,""In March 2016, the American Statistical Association (ASA) published an o cial statement about the limitations of classical significance tests and p-values, in response to their continued misuse and misinterpretations [33]. While ASA's main statement does not contain anything new (e.g., """"A p-value, or statistical signi cance, does not measure the size of an e ect or the importance of a result""""), the document mentions some alternatives to classical signi cance tests, including Bayesian methods. It goes on to say: """"All these [alternative] measures and approaches rely on further assumptions, but they may more directly address the size of an e ect (and its associated uncertainty) or whether the hypothesis is correct."""" In the IR community, similar warnings against classical signi cance tests have been given by Cartere e [4] and Sakai [22], amongst others."",null,null",null,null
15,"14,""e above quotations from the ASA statement may be paraphrased as follows. Classical signi cance tests can only give us P(D+|H ), the probability of observing the data D at hand or something more extreme under the assumption that the hypothesis H is true (i.e., the p-value). But what we usually want is P(H |D), the probability that a hypothesis is true, given the data. eoretically, the Bayesian framework proposed in the 18th century [2] can give us exactly this, but it was heavily criticised during the 19th and 20th centuries (See Section 2.1). However, with the recent advent of e ective and e cient sampling algorithms for obtaining posterior distributions known as Markov Chain Monte Carlo (MCMC) methods [15], Bayesian approaches to statistical testing are rapidly gaining popularity among statisticians [30, 31]. us, as alternatives to the classical p-values and 95% con dence intervals which are o en misinterpreted respectively as """"probability that the hypothesis is (in)correct"""" and """"probability that the true parameter value drops within the interval is 95%,"""" we can employ Bayesian tests to easily obtain P(H |D) and credible intervals, which represent exactly the above. Moreover, with Bayesian tests, we can easily handle virtually any hypothesis, not just """"equality of means,"""" as we shall demonstrate later."",null,null",null,null
16,"15,We provide simple tools to encourage the IR community to take up paired and unpaired Bayesian tests for comparing two systems; our tools are based on a state-of-the-art MCMC method called Hamiltonian Monte Carlo and a recently-proposed variant called No-U-Turn Sampler [13]. Using a variety of TREC1 and NTCIR2,null,null",null,null
17,"16,1h p://trec.nist.gov/ 2h p://research.nii.ac.jp/ntcir/,null,null",null,null
18,"17,25,null,null",null,null
19,"18,Session 1A: Evaluation 1,null,null",null,null
20,"19,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
21,"20,""data, we compare P(H |D) with p-values, credible intervals with con dence intervals, and Bayesian EAP e ect sizes with classical ones. Our results show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for the e ect size in terms of Glass's ."",null,null",null,null
22,"21,2 RELATED WORK,null,null",null,null
23,"22,2.1 Frequentists Versus Bayesians,null,null",null,null
24,"23,""It is well known that Ronald A. Fisher heavily and persistently criticised the Bayesian statistics since the 1960s: """"the theory of inverse probability [i.e., Bayesian statistics] is founded upon an error, and must be wholly rejected"""" [9] (p.9). During the 20th century, the de facto standard in statistical analysis was indeed the """"frequentist"""" approach founded upon Fisher's views, and the Bayesian approach was largely neglected."",null,null",null,null
25,"24,""e Bayesian approach had two weaknesses. e rst, which has not been resolved completely even to this day, is the fact that it relies on prior probabilities which nobody knows and therefore must be set based on researchers' subjective decisions or beliefs. However, given the lack of knowledge about priors, noninformative priors such as those that obey a uniform distribution can always be used, although this too is a subjective decision which may or may not re ect the true nature of the phenomenon under study3. In the present study, we simply follow the standard Bayesian practice of employing uniform distributions for obtaining priors."",null,null",null,null
26,"25,""e second weakness in the original Bayesian approach was that, despite the theoretical beauty of Bayes' eorem, it was o en di cult to obtain the posterior distributions as this o en involves computationally infeasible integrations. However, this second problem has actually been solved, with the recent advent of e ective and e cient sampling algorithms known as Markov Chain Monte Carlo (MCMC) methods [15]. Because of this, Bayesian statistics is now gaining popularity rapidly: for example, according to Toyoda [30], over one-half of Biometrika4 papers published in 2014 utilised Bayesian statistics. In the present study, we utilise a stateof-the-art MCMC method called Hamiltonian Monte Carlo [17] and a recently-proposed variant called No-U-Turn Sampler [13], which come with easy-to-use implementations."",null,null",null,null
27,"26,""Meanwhile, the classical signi cance testing approach of the frequentists have also received many criticisms over the past decades (e.g. [12]). Some even consider signi cance tests to be harmful. First, the practice of using the signi cance criterion  instead of the p-value o en leads to dichotomous thinking: """"Is the di erence statistically signi cant, or not?"""" Ziliak and McCloskey [35] hold"",null,null",null,null
28,"27,""3 In 2005, Efron remarked: """"What looks uninformative enough o en turns out to subtly force answers in one direction or another"""" while arguing that a combination of Bayesian and frequentist ideas is needed to handle modern problems [8]. 4 is is the journal in which William S. Gosset (or """"Student"""") published the famous paper on the t -test in 1908 [29]. h p://biomet.oxfordjournals.org/"",null,null",null,null
29,"28,""Fisher responsible for this5. Second, even if the p-value is reported, this is a function not only of the e ect size (the magnitude of the di erence that we are interested in; See Section 3.6) but also the sample size. at is, a small p-value (i.e., a statistically highly signi cant result) may just re ect a large sample size (e.g., number of topics used for computing mean retrieval e ectiveness scores) rather than a large e ect size [22]. Moreover, as was mentioned in Section 1, the outcomes of classical signi cance tests are o en misinterpreted. We believe that it is time for the IR community to start using Bayesian statistics regularly, perhaps along with classical signi cance tests if the community feels reluctant to let the la er go. Since the Bayesian approach is not only highly intuitive and exible but now also computationally feasible, there really is no reason to reject it."",null,null",null,null
30,"29,""In the eld of psychology, Kruschke [14] argues that the Bayesian approach is superior to the (unpaired) t-test: """"Some people may wonder which approach, Bayesian or NHST,6 is more o en correct."",null,null",null,null
31,"30,""is question has limited applicability because in real research we never know the ground truth; all we have is a sample of data. [. . .] the relevant question is asking which method provides the richest, most informative, and meaningful results for any set of data. e answer is always Bayesian estimation."""" In the present study, we empirically demonstrate the relationships between paired/unpaired t-tests and the corresponding state-of-the-art Bayesian methods using a variety of real IR evaluation data."",null,null",null,null
32,"31,2.2 Classical Signi cance Tests in IR,null,null",null,null
33,"32,""e limitations of classical signi cance tests have been pointed out in the eld of IR as well. Cartere e argues: """"we still believe p-values from paired t-tests provide a decent rough indicator that is useful for many of the purposes they are currently used for. We only argue that p-values and signi cance test results in general should be taken with a very large grain of salt, and in particular have an extremely limited e ect on publication decisions and community-wide decisions about """"interesting"""" research directions."""" Sakai [22] encourages IR researchers to report not only the p-values but also e ect sizes and con dence intervals. However, Sakai's more recent examination of over 1,000 SIGIR and TOIS papers [23] shows that about 30% of the entire papers lack signi cance testing, while about 65% of the papers with signi cance testing neither report p-values nor test statistics."",null,null",null,null
34,"33,""While computer-based, distribution-free alternatives to classical signi cance tests, namely, the bootstrap [20] and the randomisation test [27], have been advocated for IR evaluation, they have not been used as widely as the classical tests [23]. Moreover, these tests address the same limited question as the classical tests: what is the p-value?"",null,null",null,null
35,"34,2.3 Bayesian Inferences for IR,null,null",null,null
36,"35,""We are already beginning to see Bayesian approaches to IR evaluation. Cartere e [3, 5] have proposed to evaluate IR systems by modelling binary and graded relevance judgments directly instead"",null,null",null,null
37,"36,""5 """"Ronald A. Fisher would say, """" e potash manures are not statistically signi cant. Disregard them. [. . .] William S. Gosset would say, """"[. . .] If you want to know about the potash manures you have to consider their pecuniary value compared to the barley you're trying to make money with"""" [35]. 6Null Hypothesis Signi cance Testing"",null,null",null,null
38,"37,26,null,null",null,null
39,"38,Session 1A: Evaluation 1,null,null",null,null
40,"39,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
41,"40,""of using evaluation measure scores as the atomic unit. Using three di erent TREC data sets, he compared t-test p-values with the posterior probabilities of his four Bayesian models to argue the advantages of the la er. Cartere e uses JAGS (Just Another Gibbs Sampler), an open-source implementation of BUGS (Bayesian inference Using Gibbs Sampling) and its R interface rjags to conduct MCMC simulations."",null,null",null,null
42,"41,""Our present work is in a sense less ambitious than that of Cartere e in that we are adhering to using evaluation measure scores as the atomic unit (just like Cartere e's """"Model 2""""): we would like the IR community to take up the habit of using Bayesian approaches, and to do that, we believe that we need to move cautiously while clarifying how the transition from classical signi cance testing will a ect our research ndings. Cartere e demonstrates that the t-test (i.e., his """"Model 1"""") p-values and his Model 2 posterior probabilities are strinkingly similar; we generalise this in several ways, by using diverse data sets from NTCIR and TREC, and by comparing con dence intervals with credible intervals, and classical sample e ect sizes with their Bayesian counterparts."",null,null",null,null
43,"42,""Zhang et al. [34] propose to replace the use of classical signi cance tests with Bayesian tests with probabilistic graphical models tailored to a speci c problem in information retrieval, namely, text classi cation. Following Kruschke [14, 15], they propose to make a decision about two text classifers by comparing the High Density Interval (HDI) and the Region of Practical Importance (ROPE) of the performance di erence  . Zhang et al. use Metropolis-Hastings (MH) sampling for their MCMC simulations."",null,null",null,null
44,"43,""Regarding the implementation of MCMC, we employ the stateof-the-art Hamiltonian Monte Carlo (HMC) [17] and its variant NoU-Turn Sampler (NUTS) [13] using stan and its R interface rstan, which are gaining popularity. According to Ho man and Gelman [13], HMC's features """"allow it to converge to high-dimentional"",null,null",null,null
45,"44,""target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling""""; NUTS automatically sets a required parameter for HMC, namely the number of steps L for the leap-frog method (See Section 3.2). Also, according to Kruschke [15] (pp.399-400), """"HMC can be more e ective than the"",null,null",null,null
46,"45,""various samplers in JAGS and BUGS, especially for large complex models. [. . .] However, Stan is not universally faster or be er (at this stage in its development)."""""",null,null",null,null
47,"46,3 BAYESIAN TESTS 3.1 Bayesian Basics,null,null",null,null
48,"47,""To discuss Bayesian tests, let us start with the famous Bayes' rule:"",null,null",null,null
49,"48,""f ( |x) ,"",null,null",null,null
50,"49,f (x | )f ( ) f (x),null,null",null,null
51,"50,"","",null,null",null,null
52,"51,f (x | )f ( ),null,null",null,null
53,"52, +,null,null",null,null
54,"53,-,null,null",null,null
55,"54,f,null,null",null,null
56,"55,(x,null,null",null,null
57,"56,| )f,null,null",null,null
58,"57,(,null,null",null,null
59,"58,)d,null,null",null,null
60,"59,"","",null,null",null,null
61,"60,(1),null,null",null,null
62,"61,""where f ( ) is the prior probability distribution of a random variable  (e.g., a population mean), f (x | ) is the likelihood of data x given  , and f ( |x) is the posterior probability distribution of  having observed x. Note that this view is already strikingly di erent from that of classical statistics: in classical signi cance testing, population parameters ( 's) are constants; in Bayesian statistics, they are random variables that form distributions. Since f ( |x) is a probability distribution, f (x) can be viewed as a normalising constant that"",null,null",null,null
63,"62,ensures:,null,null",null,null
64,"63, +,null,null",null,null
65,"64,-,null,null",null,null
66,"65,f ( |x)d,null,null",null,null
67,"66,"","",null,null",null,null
68,"67,1 f (x),null,null",null,null
69,"68, +,null,null",null,null
70,"69,-,null,null",null,null
71,"70,f (x | )f ( )d,null,null",null,null
72,"71,"",1."",null,null",null,null
73,"72,(2),null,null",null,null
74,"73,""Hence, Eq. 1 implies that the property of the posterior distribution"",null,null",null,null
75,"74,""f ( |x) is governed by f (x | )f ( ), i.e., the kernel."",null,null",null,null
76,"75,""If somehow the posterior distribution f ( |x) has been obtained,"",null,null",null,null
77,"76,a point estimate of the population parameter  can be obtained as an expected a posteriori (EAP)7:,null,null",null,null
78,"77,"" ^EAP , E[ |x] ,"",null,null",null,null
79,"78,""  f ( |x)d ,"",null,null",null,null
80,"79,f,null,null",null,null
81,"80,(x | )f f (x),null,null",null,null
82,"81,(,null,null",null,null
83,"82,),null,null",null,null
84,"83,d,null,null",null,null
85,"84,.,null,null",null,null
86,"85,(3),null,null",null,null
87,"86,""Moreover, how the random variable  moves around ^EAP can be quanti ed by the posterior variance (or its square root, posterior"",null,null",null,null
88,"87,standard deviation):,null,null",null,null
89,"88,"" V [ |x] , E[( - ^EAP )2|x] , ( - ^EAP )2 f ( |x)d . (4)"",null,null",null,null
90,"89,""We can also obtain an interval estimate of  by removing an /2% area from either side of f ( |x). is is the 100(1 - )% credible interval (or Bayesian con dence interval), which is highly intuitive: the probability that the random variable  lies within the interval is 100(1 - )%. Recall that con dence intervals (CIs) used in classical statistics do not represent this probability: in the classical paradigm,  is a constant, and when (say) 100 CIs are created from 100 di erent samples, 100(1 -)% of them are expected to contain that particular ."",null,null",null,null
91,"90,""As we do not know f ( ), we employ a non-informative prior distribution to avoid subjectivity to the best of our ability. Our choice is to use a uniform distribution, in which case f ( |x) is governed solely by the likelihood f (x | ) in Eq. 1 and therefore the EAP reduces to the maximum likelihood estimate (MLE). at is, in our se ing, the EAP of any parameter  is not directly a ected by our subjective choice of f ( )."",null,null",null,null
92,"91,3.2 HMC and NUTS,null,null",null,null
93,"92,""In the above discussion, we assumed that f ( |x) can be computed as de ned in Eq. 1. However, in practice, it is usually not feasible to do this analytically. at is where MCMC methods, which try to sample  repeatedly according to f ( |x), come into play. MCMC methods construct Markov Chains of parameter values so that the underlying distribution eventually reaches a stationary distribution: a er a burn-in period (B), all of the values in the chain obey the target distribution f ( |x). us, if we collect T values sequentially and throw away the intial B values, the remaining T , T -B values can be regarded as realisations of  that obey f ( |x). Suppose that we managed to obtain T ,"""" 100, 000 realisations of  ; then, ^EAP (Eq. 3) can be obtained by simply averaging the T values. Similarly, the posterior variance (Eq. 4) can be obtained by averaging8 the squared di erence from ^EAP . A 95% credible interval for  can be obtained by sorting the T values in ascending order and then taking the 2,500th and 97,500th values as the lower and upper limits. e EAP values of other statistics such as e ect sizes (See Section 3.6) can be computed similarly. Moreover, for virtually any hypothesis H (e.g., """"""""mean 1 is higher than mean 2,"""""""" """"""""mean 1 is at least 0.2 points"""""",null,null",null,null
94,"93,""7 Alternatives would be a maximum a posteriori or a posterior median. ese three estimates represent the mean, mode and median of the posterior distribution, respectively. 8 Dividing by T su ces since T is large; there is no need for bias correction."",null,null",null,null
95,"94,27,null,null",null,null
96,"95,Session 1A: Evaluation 1,null,null",null,null
97,"96,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
98,"97,""higher than mean 2,"""" or """"the e ect size is greater than 0.5""""), the probability that H is correct can be obtained by just counting the instances in which H holds among the T realisations. It is clear that this approach is more versatile than classical signi cance tests."",null,null",null,null
99,"98,""Hamiltonian Monte Carlo (HMC) [17] and its variant No U-Turn Sampler (NUTS) [13] are state-of-the-art MCMC methods which we utilise for obtaining realisations of  from f ( |x). For details of HMC, we refer the reader to recent books on this topic [15, 17]. However, it would help for us IR researchers to have a general idea about its basic principles. In physics, Hamiltonian is the sum of potential energy and kinetic energy; given a curved surface in an ideal physical world, any object would move on the surface while keeping the Hamiltonian constant. e path of the moving object is governed by Hamilton's equations of motion, which can be solved by the leap-frog method with parameters  (stepsize) and L (leapfrog steps). To achieve sampling from a posterior distribution (which is our """"curved surface""""), an intuitive explanation of what HMC does is as follows: put an object somewhere on the surface and give it a push; a er L units of time, let it halt and record its position; give it another push, and so on, until we have recorded T positions."",null,null",null,null
100,"99,""Brie y, for a set of d parameters  ,"""" (1, 2, . . . , d ), the HMC algorithm looks like this:"""""",null,null",null,null
101,"100,""(1) Set  (1), , L,T , B (where T , T - B); Let t , 1; (2) Generate d independent values p(t ) ,"""" (p1t , p2t , . . . , pdt ) from"""""",null,null",null,null
102,"101,""a standard normal distribution; (3) Obtain candidates  (a), p(a) using the leap-frog method; (4) Let  (t +1) ,""""  (a) (i.e., accept the transition candidate) with"""""",null,null",null,null
103,"102,""probability min(1, r ); otherwise  (t +1) ,""""  (t ) (i.e., reject the candidate and stay at the current position); (5) End if T """", t; otherwise let t , t + 1 and go to Step 2."",null,null",null,null
104,"103,""e r in Step 4, which governs how o en we can accept new candidates, is given by [30]:"",null,null",null,null
105,"104,r,null,null",null,null
106,"105,"","",null,null",null,null
107,"106,""f ( (a), p(a) |x) f ( (t ), p(t ) |x)"",null,null",null,null
108,"107,"","",null,null",null,null
109,"108,(5),null,null",null,null
110,"109,""where f (, p|x) is a joint distribution of f ( |x) and an independent standard normal distribution f (p). One strength of HMC is that r is o en close to one, and therefore we can achieve e cient sampling through many successful transitions in Step 4 while preserving the Hamiltonian."",null,null",null,null
111,"110,""NUTS is a variant of HMC that automatically determines an appropriate value of L [13]; both HMC and NUTS utilise an algorithm called dual averaging to automatically set  [18]; hence, from the viewpoint of the users of HMC and NUTS for Bayesian tests, we do not have to worry about se ing these parameters ourselves."",null,null",null,null
112,"111,3.3 R^ and E ective Sample Size,null,null",null,null
113,"112,""For MCMC algorithms, methods for checking whether the values have converged to a stationary distribution and for measuring the sampling e ciency are available."",null,null",null,null
114,"113,""R^, a measure for checking convergence, assumes that the MCMC algorithm produces multiple Markov Chains, and compares the variance across the multiple chains with the variance within the chains9. According to Gelman [10], if R^ is less than 1.1 or 1.2, we"",null,null",null,null
115,"114,""9Zhang et al. [34] remark that """"it is perfectly right to do a single long sampling run and keep all samples."""" However, it is very easy to throw away burn-in's that may not yet"",null,null",null,null
116,"115,""can be assured that the chains have reached stationary distributions. MCMC produces Markov Chains and therefore the values in them are correlated to one another. If the chains produce very similar values repeatedly, then that is highly ine cient from the sampling point of view. E ective Sample Size (Ne ) is a measure available in stan for quantifying sampling e ciency, which means """"you have obtained a sample of size T , but that is worth a sample of size (approximately) Ne obtained when there is zero correlation within the chain."""" Hence, we should also check that Ne is a large value. Both of the above measures are computed a er removing the burn-in's from the chains. As our Bayesian test tools that we introduce in Section 3.7 rely on stan and its R interface rstan, the tools output R^ and Ne on the R console. Since all experiments reported in the paper use su ciently large sample sizes, namely T ,"""" 100, 000, we do not discuss these indicators henceforth."""""",null,null",null,null
117,"116,3.4 Classical versus Bayesian Tests for Comparing Two Means,null,null",null,null
118,"117,""As was discussed in Section 3.2, Bayesian tests are versatile. However, the present study focusses on the problems of comparing two means from paired and unpaired data, since these are the most common and basic problems in IR evaluation. While two-sided tests that ask """"are the two systems equally e ective or not?"""" are o en recommended in classical signi cance tests given lack of prior knowledge as to which system might be be er, this is not a very useful question from the Bayesian point of view, as two di erent systems are, by de nition, di erent. What is more practical to consider is the probability that System 1 is be er than System 2, P(S1 > S2|D) (or, alternatively, P(S1 < S2|D) ,"""" 1 - P(S1 > S2|D)). Hence we compare Bayesian tests with classical one-sided tests. To be more speci c, given two systems, we let S2 be the less e ective system according to the sample data and consider P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) based on the Bayesian test, while se ing the classical null and alternative hypotheses as H0 : S1 """","""" S2 and H1 : S1 > S2 so that the p-value represents """"""""P(D+|S1 """","""" S2)."""""""""""""",null,null",null,null
119,"118,3.5 Statistical Models,null,null",null,null
120,"119,""For unpaired data, we assume that S1's scores obey N (µ1, 12), while S2's scores obey N (µ2, 22), for both Bayesian and classical tests. Hence, the classical test we employ is the Welch's t-test, which does not assume homoscedasticity (i.e., equal variances). It is known that Student's and Welch's t-tests yield virtually identical p-values when the two sample sizes are equal [16, 24]; the experiments reported in this paper satisifes this condition and therefore our classical test results can be regarded as representing both types of unpaired t -test."",null,null",null,null
121,"120,""For paired data, the classical test we apply is the paired t-test, which relies on the same normal assumptions as described above and therefore the score di erences obey N (µ1 - µ2, 12 + 22). As for the Bayesian test, we can easily consider a bivariate normal"",null,null",null,null
122,"121,""obey the desired distribution and we prefer to do so. As for the number of chains, since R^ can be computed even for a single chain, by breaking it into multiple chains, we provide sample scripts for handling both multiple and single chains. e Bayesian test results are almost the same either way, but we report those based on multiple chains."",null,null",null,null
123,"122,28,null,null",null,null
124,"123,Session 1A: Evaluation 1,null,null",null,null
125,"124,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
126,"125,distribution [31]:,null,null",null,null
127,"126,f,null,null",null,null
128,"127,""(x1, x2 |µ1, µ2, 12, 22, )"",null,null",null,null
129,"128,"","",null,null",null,null
130,"129,1 2 12 (1,null,null",null,null
131,"130,-,null,null",null,null
132,"131,) e-q/2,null,null",null,null
133,"132,"","",null,null",null,null
134,"133,(6),null,null",null,null
135,"134,where,null,null",null,null
136,"135,""q,"",null,null",null,null
137,"136,1,null,null",null,null
138,"137,1 -,null,null",null,null
139,"138,2,null,null",null,null
140,"139,[(,null,null",null,null
141,"140,x1,null,null",null,null
142,"141,- 1,null,null",null,null
143,"142,µ1,null,null",null,null
144,"143,)2,null,null",null,null
145,"144,-,null,null",null,null
146,"145,2,null,null",null,null
147,"146,(,null,null",null,null
148,"147,x1,null,null",null,null
149,"148,- 1,null,null",null,null
150,"149,µ1,null,null",null,null
151,"150,)(,null,null",null,null
152,"151,x2,null,null",null,null
153,"152,- 2,null,null",null,null
154,"153,µ2,null,null",null,null
155,"154,),null,null",null,null
156,"155,+,null,null",null,null
157,"156,(,null,null",null,null
158,"157,x,null,null",null,null
159,"158,2,null,null",null,null
160,"159,- 2,null,null",null,null
161,"160,µ2,null,null",null,null
162,"161,)2],null,null",null,null
163,"162,.,null,null",null,null
164,"163,(7),null,null",null,null
165,"164,""Here,  is the population correlation coe cient for x1's and x2's. us, for paired data, we can discuss hypotheses about the corre-"",null,null",null,null
166,"165,lation between the two systems just as well as those about means and e ect sizes if we are interested in that aspect.,null,null",null,null
167,"166,3.6 E ect Sizes,null,null",null,null
168,"167,Sakai [22] stresses the importance of reporting e ect sizes and,null,null",null,null
169,"168,con dence intervals in the context of classical signi cance testing as,null,null",null,null
170,"169,a small p-value may just re ect a large sample size (See Section 2.2).,null,null",null,null
171,"170,""When comparing two means, the e ect size is usually given as"",null,null",null,null
172,"171,the di erence between the two measured in standard deviation,null,null",null,null
173,"172,units. We argue that Bayesian test results in IR should also be,null,null",null,null
174,"173,accompanied with e ect sizes as well as credible intervals.,null,null",null,null
175,"174,While there are several choices of e ect sizes for comparing,null,null",null,null
176,"175,""two means, we choose to avoid relying on the homoscedasticity"",null,null",null,null
177,"176,""assumption, to be consistent with the statistical models described in"",null,null",null,null
178,"177,Section 3.5. One of the simplest e ect size in such a case is Glass's,null,null",null,null
179,"178,"" [19]. at is, if System 1 is taken as the baseline run (or """"control"",null,null",null,null
180,"179,""group,"""") then its standard deviation is probably representative of"",null,null",null,null
181,"180,""an """"ordinary world"""" before the advent of System 2, and therefore:"",null,null",null,null
182,"181,Gl ass 1,null,null",null,null
183,"182,"","",null,null",null,null
184,"183,µ1 - µ2 1,null,null",null,null
185,"184,.,null,null",null,null
186,"185,(8),null,null",null,null
187,"186,""us, Glass's  measures the absolute di erence in """"ordinary"""" stan-"",null,null",null,null
188,"187,""dard deviation units. Alternatively, if System 2 is taken as the"",null,null",null,null
189,"188,baseline:,null,null",null,null
190,"189,Gl ass 2,null,null",null,null
191,"190,"","",null,null",null,null
192,"191,µ1 - µ2 2,null,null",null,null
193,"192,.,null,null",null,null
194,"193,(9),null,null",null,null
195,"194,""In our experiments, we focus on Eq. 9 since the second system is"",null,null",null,null
196,"195,""the less e ective one (i.e., """"baseline"""") according to the sample data."",null,null",null,null
197,"196,""For convenience, we will herea er refer to this version of e ect"",null,null",null,null
198,"197,""size simply as """"Glass2."""""",null,null",null,null
199,"198,""We can easily obtain the EAP and credible intervals for Glass2,"",null,null",null,null
200,"199,as well as the probability of a hypothesis about the e ect size,null,null",null,null
201,"200,""being true, in exactly the same way as described in Section 3.2."",null,null",null,null
202,"201,""For example, the EAP for Glass2 can be obtained by computing"",null,null",null,null
203,"202,""Eq. 9 T times using T realisations of µ1, µ2, 2 and then averaging them. Hence we propose that the IR community report the EAP,"",null,null",null,null
204,"203,the credible interval and the probablity of hypothesis being true,null,null",null,null
205,"204,not only for the raw di erence in means but also for e ect sizes.,null,null",null,null
206,"205,Note that this is applicable to both paired and unpaired tests.,null,null",null,null
207,"206,3.7 Implementation,null,null",null,null
208,"207,""Here, we brie y describe our Bayesian test tools for comparing two means. e sample R scripts are based on those developed by Hideki Toyoda [30]10. We have sample scripts for generating both multiple and single chains but discuss only the former here. We have added a few shell scripts for postprocessing the Bayesian"",null,null",null,null
209,"208,""10 Toyoda's original scripts are available from h p://www.asakura.co.jp/G 27 2.php? id,200. e present author is solely responsible for the modi cations and any errors introduced thereby."",null,null",null,null
210,"209,""realisations, to encourage researchers to use credibile intervals not only for the raw di erence in means but also for e ect sizes. e scripts and sample data are available from our website11. R with the rstan package12 and Rtools13 must be installed rst in order to use these scripts."",null,null",null,null
211,"210,""Figure 1 shows our sample R script for comparing paired data. It reads a stan le which describes the aforementioned bivariate normal distribution as well as generated quantities (the absolute di erence and Glass's 's), and a system score le wri en in R, and generates ve csv les that correspond to ve Markov chains."",null,null",null,null
212,"211,""Figure 2 shows an output of our UNIX shell script that summarises the Bayesian test results by reading the csv les. Here, the"",null,null",null,null
213,"212,""rst argument is """"1032"""" because this is the line number in each csv le where the realisations start a er the burn-in; the second argument is the number of realisations contained in the le (excluding the burn-in's); the third argument is the number of chains (i.e., number of csv les); the remaining arguments are the aforementioned Markov chain csv les. is script works for both multiple and single chains, by se ing the arguments appropriately14. e screenshot provides the following information about the paired data from run1 and run2:"",null,null",null,null
214,"213,""· e EAP for the di erence in means is 0.042, and the 95% credibile interval is [0.009, 0.074]. e probability that µ1 - µ2 is greater than the speci ed threshold (which is set to 0 by default within the script) is 99.4%;"",null,null",null,null
215,"214,""· e EAP for Glass2 (with run2 taken as the baseline) is 0.189 (i.e., about 19% of run2's standard deviation), and the 95% credible interval is [0.043, 0.345]. e probability that this e ect size is greater than the speci ed threshold (which is set to 0.2 by default) is 43.3%. Similar results with run1 taken as the baseline are also presented."",null,null",null,null
216,"215,""· e EAP for the correlation (i.e.,  in Eq. 6) between the scores of run1 and run2 is 0.857, and the 95% credible interval is [0.767, 0.920]. e probability that the correlation is greater than the speci ed threshold (which is set to 0.9 by default) is 12.2%."",null,null",null,null
217,"216,Note that thresholds can be altered arbitrarily within the shell script according to researchers' practical needs.,null,null",null,null
218,"217,Figures 3 and 4 provide similar screenshots of our scripts for comparing unpaired data.,null,null",null,null
219,"218,4 EXPERIMENTS,null,null",null,null
220,"219,""To encourage IR researchers to transition comfortably from the classical signi cance test paradigm to the Bayesian one for comparison of means, we now report on experiments that compare Bayesian results against classi cal test results using actual IR data. More speci cally, we compare the probability that System X is be er than System Y with p-values; credible intervals with classical con dence intervals, as well as e ect sizes computed based on both approaches. We show that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect"",null,null",null,null
221,"220,""11 h p://www.f.waseda.jp/tetsuya/tools.html 12 h ps://cran.r-project.org/ 13 h ps://cran.r-project.org/bin/windows/Rtools/ 14By typing the command without arguments, suggested sets of arguments are displayed."",null,null",null,null
222,"221,29,null,null",null,null
223,"222,Session 1A: Evaluation 1,null,null",null,null
224,"223,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
225,"224,Table 1: IR data sets and evaluation measures used in this study,null,null",null,null
226,"225,Data set name NTCIR7IR4QA NTCIR9INTENT NTCIR12STC TREC03robust TREC11webD TREC15TS,null,null",null,null
227,"226,year track/task,null,null",null,null
228,"227,language measure,null,null",null,null
229,"228,tool,null,null",null,null
230,"229,#teams #runs #topics,null,null",null,null
231,"230,2008 IR for question answering [25],null,null",null,null
232,"231,Chinese Q-measure,null,null",null,null
233,"232,NTCIREVAL,null,null",null,null
234,"233,9 40 (20),null,null",null,null
235,"234,97,null,null",null,null
236,"235,2011 INTENT [28] (web diversity task),null,null",null,null
237,"236,Chinese D -nDCG@10 NTCIREVAL,null,null",null,null
238,"237,7 24 (20),null,null",null,null
239,"238,100,null,null",null,null
240,"239,2016 short text conversation [26] (tweet retrieval) Chinese nERR@10,null,null",null,null
241,"240,NTCIREVAL,null,null",null,null
242,"241,16 44 (20),null,null",null,null
243,"242,100,null,null",null,null
244,"243,2003 robust track [32],null,null",null,null
245,"244,English nDCG@1000 NTCIREVAL,null,null",null,null
246,"245,16 78 (20),null,null",null,null
247,"246,50,null,null",null,null
248,"247,2011 web track diversity task [7],null,null",null,null
249,"248,English  -nDCG@10 ndeval,null,null",null,null
250,"249,9 25 (20),null,null",null,null
251,"250,50,null,null",null,null
252,"251,""2015 temporal summarisation track, task 2 [1]"",null,null",null,null
253,"252,English H,null,null",null,null
254,"253,-,null,null",null,null
255,"254,9 22 (20),null,null",null,null
256,"255,21,null,null",null,null
257,"256,Figure 1: A sample R script for comparing paired data.,null,null",null,null
258,"257,Figure 3: A sample R script for comparing unpaired data.,null,null",null,null
259,"258,""Figure 2: A shell script for obtaining the EAP, credible intervals, and the probability that the hypothesis is correct (paired data) for the absolute di erence, Glass's , and correlation coe cient (paired data)."",null,null",null,null
260,"259,""sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes."",null,null",null,null
261,"260,""Table 1 provides a brief summary of the six data sets we used for our experiments. To strengthen the generalisability of our experimental results, we tried to cover diverse IR tasks from both TREC and NTCIR. For each data set (i.e., test collection with its submi ed runs), we chose one particular commonly-used evaluation measure: with the exception of TREC03robust15, we chose from one of the"",null,null",null,null
262,"261,15 We chose nDCG rather than Average Precision (AP) for TREC03robust as AP cannot handle graded relevance even though the data set comes with graded relevance assessments.,null,null",null,null
263,"262,""Figure 4: A shell script for obtaining the EAP, credible intervals, and the probability that the hypothesis is correct (paired data) for the absolute di erence, and Glass's  (unpaired data)."",null,null",null,null
264,"263,""o cial measures of that track/task. Also, for each data set, we considered only the top 20 runs for pairwise comparisons as measured by that particular evaluation measure, which gives us 190 run pairs. For TREC11webD, -nDCG was computed using their o cial evaluation script ndeval16; For TREC15TS, the values of H (which is basically like a nugget-based F-measure de ned over a timeline [1]) were obtained from the o cial results of the track; other evaluation measures were computed using NTCIREVAL17, with the exponential gain value se ing (See, for example, [26])."",null,null",null,null
265,"264,""For each data set, we conducted Bayesian and classical tests for every system pair (where System 1 outperforms System 2 for the sample data), using both paired and unpaired tests. For classical paired and unpaired tests, common sample e ect sizes were obtained by substituting sample means and System 2's sample standard deviations into Eq. 9. For Bayesian paired and unpaired tests, the EAP values of µ1, µ2, 2 were used with Eq. 9, under the two models described in Section 3.5, respectively."",null,null",null,null
266,"265,16 h p://trec.nist.gov/data/web/11/ndeval.c 17 h p://research.nii.ac.jp/ntcir/tools/ntcireval-en.html,null,null",null,null
267,"266,30,null,null",null,null
268,"267,Session 1A: Evaluation 1,null,null",null,null
269,"268,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
270,"269,Figure 5: Paired Bayesian vs classical tests: comparisons with NTCIR data.,null,null",null,null
271,"270,4.1 Paired Test Results,null,null",null,null
272,"271,""Here we compare the paired Bayesian test (based on NUTS) with the classical paired t-test. We compare: (I) the paired Bayesian P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) with the classical one-sided paired p-value (See Section 3.4); (II) the paired 95% credible interval with the classical paired 95% con dence interval; (III) the paired Bayesian EAP Glass2 with the classical Glass2 based on sample statistics. e margin of error for the classical paired 95% con dence interval is given by t(n - 1; 0.05) V /n, where n is the sample size, V is the sample variance of the score di erences, and t(; ) is the two-sided critical t value18."",null,null",null,null
273,"272,""Figure 5 visualises the results of comparing the Bayesian and classical paradigms for paired data with NTCIR7IR4QA (graphs (A)(D)), NTCIR9INTENT (graphs (E)-(H)), and NTCIR12STC (graphs (I)(L)). Graphs (A), (E) and (I) (i.e., the le most column) compare the Bayesian P(S1 < S2|D) with the p-value; graphs (B), (F), and (J) compare the Bayesian EAP Glass2 with the sample Glass2; graphs (C), (G) and (K) compare the Bayesian credible interval lower limit with the con dence interval lower limit; and graphs (D), (H) and"",null,null",null,null
274,"273,""18 T.INV.2T(P,  ) with Microso Excel."",null,null",null,null
275,"274,""(L) (i.e., the rightmost column) compare the Bayesian credible interval upper limit with the con dence interval upper limit. Figure 6 provides similar information for TREC03robust, TREC11webD, and TREC15TS."",null,null",null,null
276,"275,""With the exception of Figure 6(J), i.e., the e ect size results for TREC15TS which we shall discuss in Section 4.3, the results in Figures 5 and 6 are highly consistent across the diverse NTCIR and TREC data sets and the messages are clear:"",null,null",null,null
277,"276,""(1) Graphs (A), (E), and (I) in Figures 5 and 6 show that the Bayesian P(S1 < S2|D) and the classical p-values are very highly correlated, echoing an earlier observation by Cartere e [5] (See Section 2.3). us, while P(S1 < S2|D) is what we usually want, it appears that the one-sided pvalue, which represents P(D+|S1 ,"""" S2), can be considered as a reasonable approximation of P(S1 < S2|D)."""""",null,null",null,null
278,"277,""(2) Graphs (C), (D), (G), (H), (K), (L) in Figures 5 and 6 show that the Bayesian 95% credible intervals and the classical 95% con dence intervals are also very similar, despite the fundamental di erences in what they represent. us, the con dence interval can be considered as an approximation to the credible interval, which is what we really want."",null,null",null,null
279,"278,31,null,null",null,null
280,"279,Session 1A: Evaluation 1,null,null",null,null
281,"280,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
282,"281,Figure 6: Paired Bayesian vs classical tests: comparisons with TREC data.,null,null",null,null
283,"282,""(3) Graphs (B) and (F) in Figures 5 and 6 suggest that, while the Bayesian EAP e ect sizes generally align with the sample e ect sizes (Glass2), if the sample e ect size is small (e.g., less than 0.2), that may be an underestimation of the population e ect size. For example, Figure 6(B) indicates an instance (with a baloon) where the sample e ect size is 0.070 even though the Bayesian EAP e ect size, which we believe to be more accurate, is 0.113."",null,null",null,null
284,"283,""Observations (1) and (2) suggest that, even though the IR community may have relied on p-values and con dence intervals for decades, sometimes with incorrect interpretations, switching to Bayesian approaches would not turn all the experimental results in the literature upside down. As for Observation 3, even though we lack the ground truth for population e ect sizes, we would like to repeat Kruschke's argument [14]: """"the relevant question is asking which method provides the richest, most informative, and meaningful results for any set of data [. . .]"""" (See Section 2.1)."",null,null",null,null
285,"284,4.2 Unpaired Test Results,null,null",null,null
286,"285,Here we compare the unpaired Bayesian test (based on NUTS) with the classical Welch's t-test. We compare: (I) the unpaired Bayesian,null,null",null,null
287,"286,""P(S1 < S2|D) (i.e., the probability of the less likely hypothesis)"",null,null",null,null
288,"287,with the classical one-sided unpaired p-value (See Section 3.4);,null,null",null,null
289,"288,(II) the unpaired 95% credible interval with the classical unpaired,null,null",null,null
290,"289,95% con dence interval; (III) the unpaired Bayesian EAP Glass2,null,null",null,null
291,"290,with the classical Glass2 based on sample statistics. e margin of,null,null",null,null
292,"291,""error for the classical unpaired 95% con dence interval is given by t(; 0.05) V1/n1 + V2/n2, where n1, n2 are the sample sizes, V1, V2 are the sample variances, and the approximated degrees of freedom  is given by [24]:"",null,null",null,null
293,"292,"","",null,null",null,null
294,"293,( V1 n1,null,null",null,null
295,"294,+,null,null",null,null
296,"295,V2 )2/{ (V1/n1)2,null,null",null,null
297,"296,n2,null,null",null,null
298,"297,n1 - 1,null,null",null,null
299,"298,+,null,null",null,null
300,"299,(V2/n2)2 } n2 - 1,null,null",null,null
301,"300,.,null,null",null,null
302,"301,(10),null,null",null,null
303,"302,""In fact, since our unpaired test experiments merely regard the paired data from NTCIR and TREC (i.e., two systems evaluated with a common topic set) as unpaired data, n1 , n2 holds in our case."",null,null",null,null
304,"303,""Figure 7 visualises the results of comparing the Bayesian and classical paradigms for unpaired TREC data, similarly to Figure 6."",null,null",null,null
305,"304,""e unpaired results with the NTCIR data, which look very much like the corresponding paired test results with the NTCIR data shown in Figure 5, are omi ed in this paper due to lack of space."",null,null",null,null
306,"305,32,null,null",null,null
307,"306,Session 1A: Evaluation 1,null,null",null,null
308,"307,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
309,"308,Figure 7: Unpaired Bayesian vs classical tests: comparisons with TREC data.,null,null",null,null
310,"309,""Note that the classical sample e ect sizes used in Graphs (B), (F), and (J) are the same as the ones used in Figure 6. For example, we have observed from Figure 6(B) that while the sample e ect size for a system pair was 0.070, the Bayesian paired model gives us an EAP Glass2 of 0.113; in contrast, Figure 7(B) indicates that the Bayesian unpaired model gives us an EAP Glass2 of 0.161 for the same system pair."",null,null",null,null
311,"310,""It is clear that Observations 1-3 listed up in Section 4.1 also hold for the unpaired tests as well, which further strengthens our"",null,null",null,null
312,"311,""ndings. However, just like Figure 6(J), Figure 7(J) shows and anomalous result for TREC15TS: we therefore discuss these results separately in the next section."",null,null",null,null
313,"312,4.3 On the Anomalous Behaviour of H,null,null",null,null
314,"313,""e nugget-based H measure, the primary measure from the TREC 2015 Temporal Summarisation track, demonstrates a strange behaviour in Figure 6(J) and Figure 7(J), where the Bayesian EAP e ect sizes and sample e ect sizes are compared. e graphs look quite di erent from Graphs (B) and (F) of Figures 5-7. More specifically, for a small set of system pairs, EAP values are larger than sample e ect sizes; for a few others, sample e ect sizes are larger"",null,null",null,null
315,"314,""than EAPs. For example, for a system pair whose sample e ect size is 11.39, the paired Bayesian EAP is 12.10 (Figure 6(J)), while the unpaired Bayesian EAP is 12.37 (Figure 7(J)), as indicated by baloons. Similarly, for a system pair whose sample e ect size is 16.19, the paired Bayesian EAP is 12.55, while the unpaired Bayesian EAP is 12.76. is is in contrast to the aforementioned Obsevation 3 (Section 4.1) for the other data sets."",null,null",null,null
316,"315,""While the other evaluation measures used in our experiments have been studied quite extensively (e.g., [6, 20, 21]), we are not aware of any work in the literature that validated H in a similar way, and we believe that an investigation is in order. For example, while the actual nDCG scores from our TREC03robust data range between 0 and 0.9816 (i.e., almost fully covering the theoretical range of [0, 1]), the actual H scores from TREC15TS range between 0 and 0.4021: that is, the actual range width is about 0.4 rather than 1. Moreover, the standard deviations of H for each system are very low compared to the other measures, causing very large e ect sizes (See Eq. 9): hence, note that the axis scales of Figure 6(J) and 7(J) are very di erent from the other e ect size graphs. While studying the properties of a new measure is not the focus of this"",null,null",null,null
317,"316,33,null,null",null,null
318,"317,Session 1A: Evaluation 1,null,null",null,null
319,"318,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
320,"319,""study, these anomalous results with H may deserve a ention from other researchers such as the TREC track coordinators."",null,null",null,null
321,"320,5 CONCLUSIONS AND FUTURE WORK,null,null",null,null
322,"321,""Using diverse data sets from TREC and NTCIR, we compared, under both paired and unpaired data se ings, (I) the Bayesian P(S1 < S2|D) (i.e., the probability of the less likely hypothesis) with the classical one-sided p-value; (II) the 95% credible interval with the classical 95% con dence interval; (III) the Bayesian EAP Glass2 with the classical Glass2 based on sample statistics. Our results showed that (a) p-values and con dence intervals can respectively be regarded as approximations of what we really want, namely, P(H |D) and credible intervals; and (b) sample e ect sizes from classical signi cance tests can di er considerably from the Bayesian EAP e ect sizes, which suggests that the former can be poor estimates of population e ect sizes. Fortunately, our results suggest that Bayesian statistics will not turn all experimental results in the IR literature upside down; however, we hope that these results, as well as our tools, will help IR researchers to take up Bayesian hypothesis testing approaches. For both paired and unpaired tests, we propose that the IR community report the EAP, the credible interval, and the probability of hypothesis being true, not only for the raw di erence in means but also for Glass's ."",null,null",null,null
323,"322,""e present study focussed on the problem of comparing two systems, and did not address the multiple comparison and familywise error rate problems [11]. If a researcher is interested in the p-value of every system pair, one e ective way to obtain them would be to employ the randomised Tukey HSD test [4, 22], which is completely distribution-free. In future work, we would like to explore Bayesian alternatives to this test and validate them."",null,null",null,null
324,"323,ACKNOWLEDGEMENTS,null,null",null,null
325,"324,""We thank Professor Hideki Toyoda (Waseda University) for le ing us modify his R code and distribute it, and Dr. Ma hew EkstrandAbueg (Google) for providing the TREC temporal summarisation track results."",null,null",null,null
326,"325,REFERENCES,null,null",null,null
327,"326,""[1] Javed Aslam, Fernando Diaz, Ma hew Ekstrand-Abueg, Richard McCreadie, Virgil Pavlu, and Tetsuya Sakai. 2016. TREC 2015 Temporal Summarization Track. In Proceedings of TREC 2015."",null,null",null,null
328,"327,""[2] omas Bayes. 1763. An Essay towards Solving a Problem in the Doctrine of Chances. Philosophical Transactions of the Royal Society of London 53 (1763), 370­418."",null,null",null,null
329,"328,[3] Ben Cartere e. 2011. Model-Based Inference About IR Systems. In Proceedings of ICTIR 2011 (LNCS 6931). 101­112.,null,null",null,null
330,"329,""[4] Ben Cartere e. 2012. Multiple testing in statistical analysis of systems-based information retrieval experiments. ACM TOIS 30, 1 (2012)."",null,null",null,null
331,"330,[5] Ben Cartere e. 2015. Bayesian Inference for Information Retrieval Evaluation. In Proceedings of ACM ICTIR 2015. 31­40.,null,null",null,null
332,"331,""[6] Charles L.A. Clarke, Nick Craswell, Ian Soboro , and Azin Ashkan. 2011. A Comparative Analysis of Cascade Measures for Novelty and Diversity. In Proceedings"",null,null",null,null
333,"332,""of ACM WSDM 2011. 75­84. [7] Clarles L. A. Clarke, Nick Craswell, Ian Soboro , and Ellen M. Voorhees. 2012."",null,null",null,null
334,"333,""Overview of the TREC 2011 Web Track. In Proceedings of TREC 2011. [8] Bradley Efron. 2005. Bayesians, Frequentists, and Scientists. J. Amer. Statist."",null,null",null,null
335,"334,""Assoc. 100, 469 (2005), 1­5. [9] Ronald A. Fisher. 1970. Statistical Methods for Research Workers (14th Edition)."",null,null",null,null
336,"335,Oliver & Boyd. [10] Andrew Gelman. 1996. Inference and Monitoring Convergence. In Markov Chan,null,null",null,null
337,"336,""Monte Carlo in Practice, W. R. Gilks, S. Richardson, and D. J. Spiegelhalter (Eds.). Chapman & Hall/CRC, Chapter 8. [11] Andrew Gelman, Jennifer Hill, and Masanao Yajima. 2008. Why We (Usually) Don't Have to Worry about Multiple Comparisons. Technical Report. [12] Lisa L. Harlow, Stanley A. Mulaik, and James H. Steiger (Eds.). 2016. What If"",null,null",null,null
338,"337,ere Were No Signi cance Tests (Classic Edition). Routledge. [13] Ma hew D. Ho man and Andrew Gelman. 2014. e No-U-Turn Sampler:,null,null",null,null
339,"338,""Adaptively Se ing Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research 15 (2014), 1351­1381. [14] John K. Kruschke. 2013. Bayesian Estimation Supersedes the t test. Journal of Experimental Psychology: General 142, 2 (2013), 573­603. [15] John K. Kruschke. 2015. Doing Bayesian Data Analysis (Second Edition). Elsevier. [16] Yasushi Nagata. 1996. How to Understand Statistical Methods (in Japanese). Nikkagiren. [17] Radford M. Neal. 2011. MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo, Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng (Eds.). 113­162. [18] Yurii Nesterov. 2009. Primal-Dual Subgradient Methods for Convex Problems. Mathematical Programming 120 (2009), 221­259. [19] Matia Okubo and Kensuke Okada. 2012. Psychological Statistics to Tell Your Story: E ect Size, Con dence Interval, and Power. Keiso Shobo. [20] Tetsuya Sakai. 2006. Evaluating Evaluation Metrics based on the Bootstrap. In Proceedings of ACM SIGIR 2006. 525­532. [21] Tetsuya Sakai. 2011. Evaluating Diversi ed Search Results Using Per-Intent Graded Relevance. In Proceedings of ACM SIGIR 2011. 1043­1052. [22] Tetsuya Sakai. 2014. Statistical Reform in Information Retrieval? SIGIR Forum 48, 1 (2014), 3­12. [23] Tetsuya Sakai. 2016. Statistical Signi cance, Power, and Sample Sizes: A Systematic Review of SIGIR and TOIS, 2006-2015. Proceedings of ACM SIGIR 2016 (2016), 5­14. [24] Tetsuya Sakai. 2016. Two Sample T-tests for IR Evaluation: Student or Welch?. In Proceedings of ACM SIGIR 2016. 1045­1048. [25] Tetsuya Sakai, Noriko Kando, Chuan-Jie Lin, Teruko Mitamura, Hideki Shima, Donghong Ji, Kuang-Hua Chen, and Eric Nyberg. 2008. Overview of the NTCIR-7 ACLIA IR4QA Task. In Proceedings of NTCIR-7. 77­114. [26] Lifeng Shang, Tetsuya Sakai, Zhengdong Lu, Hang Li, Ryuichiro Higashinaka, and Yusuke Miyao. 2016. Overview of the NTCIR-12 Short Text Conversation Task. In Proceedings of NTCIR-12. 473­484. [27] Mark D. Smucker, James Allan, and Ben Cartere e. 2007. A Comparison of Statistical Signi cance Tests for Information Retrieval Evaluation. In Proceedings of ACM CIKM 2007. 623­632. [28] Ruihua Song, Min Zhang, Tetsuya Sakai, Makoto P. Kato, Yiqun Liu, Miho Sugimoto, Qinglei Wang, and Naoki Orii. 2011. Overview of the NTCIR-9 INTENT Task. In Proceedings of NTCIR-9. 82­105. [29] Student. 1908. e Probable Error of a Mean. Biometrika 6, 1 (1908), 1­25. [30] Hideki Toyoda (Ed.). 2015. Fundamentals of Bayesian statistics: Practical Ge ing Started by Hamiltonian Monte Carlo Method (in Japanese). Asakura Shoten. [31] Hideki Toyoda. 2016. An Introduction to Statistical Data Analysis: Bayesian Statistics for `post p-value era' (in Japanese). Asakuha Shoten. [32] Ellen M. Voorhees. 2004. Overview of the TREC 2003 Robust Retrieval Track. In Proceedings of TREC 2003. [33] Ronald L. Wasserstein and Nicole A. Lazar. 2016. e ASA's Statement on P-values: Context, Process, and Purpose. e American Statistician (2016). [34] Dell Zhang, Jun Wang, Emine Yilmaz, Xiaoling Wang, and Yuxin Zhou. 2016. Bayesian Performance Comparison of Text Classi ers. In Proceedings of ACM SIGIR 2016. 15­24. [35] Stephen T. Ziliak and Deirdre N. McCloskey. 2008. e Cult of Statistical Signi cance: How the Standard Error Costs Us Jobs, Justice, and Lives. e University of Michigan Press."",null,null",null,null
340,"339,34,null,null",null,null
341,"340,,null,null",null,null
