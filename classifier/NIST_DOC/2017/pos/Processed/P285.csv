,sentence,label,data
0,",sentence,label,data",null,null
1,"0,Session 3A: Search Interaction 2,null,null",null,null
2,"1,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
3,"2,Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach,null,null",null,null
4,"3,Rishabh Mehrotra and Emine Yilmaz,null,null",null,null
5,"4,""University College London, London, United Kingdom  e Alan Turing Institute, British Library, London, United Kingdom"",null,null",null,null
6,"5,""{r.mehrotra,e.yilmaz}@cs.ucl.ac.uk"",null,null",null,null
7,"6,ABSTRACT,null,null",null,null
8,"7,""A signi cant amount of search queries originate from some real world information need or tasks [13]. In order to improve the search experience of the end users, it is important to have accurate representations of tasks. As a result, signi cant amount of research has been devoted to extracting proper representations of tasks in order to enable search systems to help users complete their tasks, as well as providing the end user with be er query suggestions [9], for be er recommendations [41], for satisfaction prediction [36] and for improved personalization in terms of tasks [24, 38]. Most existing task extraction methodologies focus on representing tasks as at structures. However, tasks o en tend to have multiple subtasks associated with them and a more naturalistic representation of tasks would be in terms of a hierarchy, where each task can be composed of multiple (sub)tasks. To this end, we propose an e cient Bayesian nonparametric model for extracting hierarchies of such tasks & subtasks. We evaluate our method based on real world query log data both through quantitative and crowdsourced experiments and highlight the importance of considering task/subtask hierarchies."",null,null",null,null
9,"8,KEYWORDS,null,null",null,null
10,"9,search tasks; bayesian non-parametrics; hierarchical model,null,null",null,null
11,"10,""ACM Reference format: Rishabh Mehrotra and Emine Yilmaz. 2017. Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach. In Proceedings of SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan, , 10 pages. DOI: h p://dx.doi.org/10.1145/3077136.3080823"",null,null",null,null
12,"11,1 INTRODUCTION,null,null",null,null
13,"12,""e need for search o en arises from a person's need to achieve a goal, or a task such as booking travels, buying a house, etc., which would lead to search processes that are o en lengthy, iterative, and are characterized by distinct stages and shi ing goals. [13]."",null,null",null,null
14,"13,""us, identifying and representing these tasks properly is highly important for devising search systems that can help end users complete their tasks. It has previously been shown that these task representations can be used to provide users with be er query"",null,null",null,null
15,"14,""Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR'17, August 7­11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. ISBN 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080823"",null,null",null,null
16,"15,""suggestions [9], o er improved personalization [24, 38], provide be er recommendations [41], help in satisfaction prediction [36] and search result re-ranking. Moreover, accurate representations of tasks could also be highly useful in aptly placing the user in the task-subtask space to contextually target the user in terms of be er recommendations and advertisements, developing task speci c ranking of documents, and developing task based evaluation metrics to model user satisfaction. Given the wide range of applications these tasks representations can be used for, signi cant amount of research has been devoted to task extraction and representation [12, 13, 15, 17, 21]."",null,null",null,null
17,"16,""Task extraction is quite a challenging problem as search engines can be used to achieve very di erent tasks, and each task can be de ned at di erent levels of granularity. A major limitation in existing task-extraction methods lies in their treatment of search tasks as at structure-less clusters which inherently lack insights about the presence or demarcation of subtasks associated with individual search tasks. In reality, o en search tasks tend to be hierarchical in nature. For example, a search task like planning a wedding involves subtasks like searching for dresses, browsing di erent hairstyles, looking for invitation card templates, nding planners, among others. Each of these subtasks (1) could themselves be composed of multiple subtasks, and (2) would warrant issuing di erent queries by users to accomplish them. Hence, in order to obtain more accurate representations of tasks, new methodologies for constructing hierarchies of tasks are needed."",null,null",null,null
18,"17,""As part of the proposed research, we consider the challenge of extracting hierarchies of search tasks and their associated subtasks from a search log given just the log data without the need of any manual annotation of any sort. In a recent poster we showed that Bayesian nonparametrics have the potential to extract a hierarchical representation of tasks [25]; we extend this model further to form more accurate representations of tasks."",null,null",null,null
19,"18,""We present an e cient Bayesian nonparametric model for discovering hierarchies and propose a tree based nonparametric model to discover this rich hierarchical structure of tasks/subtasks embedded in search logs. Most existing hierarchical clustering techniques result in binary tree structures with each node decomposed into two child nodes. Given that a complex task could be composed of an arbitrary number of subtasks, these techniques cannot directly be used to construct accurate representations of tasks. In contrast, our model is capable of identifying task structures that can be composed of an arbitrary number of children. We make use of a number of evaluation methodologies to evaluate the e cacy of the proposed task extraction methodology, including quantitative and qualitative analyses along with crowdsourced judgment studies"",null,null",null,null
20,"19,285,null,null",null,null
21,"20,Session 3A: Search Interaction 2,null,null",null,null
22,"21,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
23,"22,speci cally catered to evaluating the quality of the extracted task hierarchies. We contend that the techniques presented expand the scope for be er recommendations and search personalization and opens up new avenues for recommendations speci cally targeting users based on the tasks they involve in.,null,null",null,null
24,"23,2 RELATED WORK,null,null",null,null
25,"24,Web search logs provide explicit clues about the information seeking behavior of users and have been extensively studied to improve search experiences of users. We cover several areas of related work and discuss how our work relates to and extends prior work.,null,null",null,null
26,"25,2.1 Task Extraction,null,null",null,null
27,"26,""ere has been a large body of work focused on the problem of segmenting and organizing query logs into semantically coherent structures. Many such methods use the idea of a timeout cuto between queries, where two consecutive queries are considered as two di erent sessions or tasks if the time interval between them exceeds a certain threshold [6, 10, 33]. O en a 30-minute timeout is used to segment sessions. However, experimental results of these methods indicate that the timeouts are of limited utility in predicting whether two queries belong to the same task, and unsuitable for identifying session boundaries."",null,null",null,null
28,"27,""More recent studies suggest that users o en seek to complete multiple search tasks within a single search session [20, 23] with over 50% of search sessions having more than 2 tasks [23]. At the same time, certain tasks require signi cantly more e ort, time and sessions to complete with almost 60% of complex information gathering tasks continued across sessions [1, 22]. ere have been a empts to extract in-session tasks [13, 20, 35], and cross-session tasks [15, 37] from query sequences based on classi cation and clustering methods, as well as supporting users in accomplishing these tasks [9]. Prior work on identifying search-tasks focuses on task extraction from search sessions with the objective of segmenting a search session into disjoint sets of queries where each set represents a di erent task [12, 21]."",null,null",null,null
29,"28,""Kotov et al. [15] and Agichtein et al. [1] studied the problem of cross-session task extraction via binary same-task classi cation, and found di erent types of tasks demonstrate di erent life spans. While such task extraction methods are good at linking a new query to an on-going task, o en these query links form long chains which result in a task cluster containing queries from many potentially di erent tasks. With the realization that sessions are not enough to represent tasks, recent work has started exploring cross-section task extraction, which o en results in complex non-homogeneous clusters of queries solving a number of related yet di erent tasks. Unfortunately, pairwise predictions alone cannot generate the partition of tasks e ciently and even with post-processing, the nal task partitions obtained are not expressive enough to demarcate subtasks [18]. Finally, authors in [17] model query temporal pa erns using a special class of point process called Hawkes processes, and combine topic model with Hawkes processes for simultaneously identifying and labeling search tasks."",null,null",null,null
30,"29,Jones et al. [13] was the rst work to consider the fact that there may be multiple subtasks associated with a user's information need and that these subtasks could be interleaved across di erent,null,null",null,null
31,"30,""sessions. However, their method only focuses on the queries submi ed by a single user and a empts to segment them based on whether they fall under the same information need. Hence, they only consider solving the task boundary identi cation and same task identi cation problem and cannot be used directly for task extraction. Our work alleviates the same user assumption and considers queries across di erent users for task extraction. Finally, in a recent poster [25], we proposed the idea of extracting task hierarchies and presented a basic tree extraction algorithm. Our current work extends the preliminary model in a number of dimensions including novel model of query a nities and task coherence based pruning strategy, which we observe gives substantial improvement in results. Unlike past work, we also present detailed derivation and evaluation of the extracted hierarchy and application on task extraction."",null,null",null,null
32,"31,2.2 Supporting Complex Search Tasks,null,null",null,null
33,"32,""ere has been a signi cant amount of work on task continuation assistance [1, 28], building task tours and trails [30, 34], query suggestions [2, 14, 27], predicting next search action [5] and notes taking when accomplishing complex tasks [8]. e quality of most of these methods depends on forming accurate representations of tasks, which is the problem we are addressing in this paper."",null,null",null,null
34,"33,2.3 Hierarchical Models,null,null",null,null
35,"34,""Rich hierarchies are common in data across many domains, hence quite a few hierarchical clustering techniques have been proposed."",null,null",null,null
36,"35,""e traditional methods for hierarchically clustering data are bo omup agglomerative algorithms. Probabilistic methods of learning hierarchies have also been proposed [3, 19] along with hierarchical clustering based methods [7, 11]. Most algorithms for hierarchical clustering construct binary tree representations of data, where leaf nodes correspond to data points and internal nodes correspond to clusters. ere are several limitations to existing hierarchy construction algorithms. e algorithms provide no guide to choosing the correct number of clusters or the level at which to prune the tree. It is o en di cult to know which distance metric to choose. Additionally and more importantly, restriction of the hypothesis space to binary trees alone is undesirable in many situations - indeed, a task can have any number of subtasks, not necessarily two. Past work has also considered constructing task-speci c taxonomies from document collections [39], browsing hierarchy construction [40], generating hierarchical summaries [16]. While most of these techniques work in supervised se ings on document collections, our work instead focused on short text queries and o ers an unsupervised method of constructing task hierarchies."",null,null",null,null
37,"36,""Finally, Bayesian Rose Trees and their extensions have been proposed [3, 4, 32] to model arbitrary branching trees. ese algorithms naively cast relationships between objects as binary (0-1) associations while the query-query relationships in general are much richer in content and structure."",null,null",null,null
38,"37,""We consider a number of such existing methods as baselines and the various advantages of the proposed approach is highlighted in the evaluation section wherein the proposed approach in addition to being more expressive, performs be er than state-of-the-art task extraction and hierarchical methods."",null,null",null,null
39,"38,286,null,null",null,null
40,"39,Session 3A: Search Interaction 2,null,null",null,null
41,"40,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
42,"41,Symbol,null,null",null,null
43,"42,nT ab |c,null,null",null,null
44,"43,ch(T),null,null",null,null
45,"44,(T ),null,null",null,null
46,"45,p(Dm |Tm ) Tm f (Dm ) H(T ),null,null",null,null
47,"46,""f (Q) rqki , q j"",null,null",null,null
48,"47,""Description number of children of tree T partition of set {a, b, c} into disjoint sets {a, b},{c} children of T partition of tree T likelihood of data Dm given the tree Tm mixing proportions of partition of tree T marginal probability of the data Dm set of all partitions of queries Q , lea es(T ) task a nity function for set of queries Q"",null,null",null,null
49,"48,the k-th inter-query a nity between qi & qj,null,null",null,null
50,"49,Table 1: Table of symbols,null,null",null,null
51,"50,3 DEFINING SEARCH TASKS,null,null",null,null
52,"51,""Jones et al. [13] was one of the rst papers to point out the importance of task representations, where they de ned a search task as:"",null,null",null,null
53,"52,De nition 3.1. A search task is an atomic information need resulting in one or more queries.,null,null",null,null
54,"53,""Ahmed et al. [9] later extended this de nition to a more generic one, which can also capture task structures that could possibly consist of related subtasks, each of which could be complex tasks themselves or may nally split down into simpler tasks or atomic informational needs. Following Ahmed et al. [9], a complex search task can then be de ned as:"",null,null",null,null
55,"54,""De nition 3.2. A complex search task is a multi-aspect or a multistep information need consisting of a set of related subtasks, each of which might recursively be complex."",null,null",null,null
56,"55,""e de nition of complex tasks is much more generic, and captures all possible search tasks, that can be either complex or atomic (non-complex). roughout this paper we adopt the de nition provided in De nition 3.2 as the de nition for a search task."",null,null",null,null
57,"56,""Hence, by de nition a search task has a hierarchical nature, where each task can consist of an arbitrary number of, possibly complex subtasks. An e ective task extraction system should be capable of accurately identifying and representing such hierarchical structures."",null,null",null,null
58,"57,4 CONSTRUCTING TASK HIERARCHIES,null,null",null,null
59,"58,""While hierarchical clustering are widely used for clustering, they construct binary trees which may not be the best model to describe data's intrinsic structure in many applications, for example, the task-subtask structure in our case. To remedy this, multi-branch trees are developed. Currently there are few algorithms which generate multi-branch hierarchies. Blundel et al. [3, 4] adopt a simple, deterministic, agglomerative approach called BRTs (Bayesian Rose Trees) for constructing multi-branch hierarchies. In this work, we adapt BRT as a basic algorithm and extend it for constructing task hierarchies. We next describe the major steps of BRT approach."",null,null",null,null
60,"59,4.1 Bayesian Rose Trees,null,null",null,null
61,"60,""BRTs [3, 4] are based on a greedy probabilistic agglomerative approach to construct multi-branch hierarchies. In the beginning,"",null,null",null,null
62,"61,Figure 1: e di erent ways of merging trees which allows us to obtain tree structures which best explain the tasksubtask structure.,null,null",null,null
63,"62,""each data point is regarded as a tree on its own: Ti ,"""" {xi } where xi is the feature vector of i-th data. For each step, the algorithm selects two trees Ti and Tj and merges them into a new tree Tm . Unlike binary hierarchical clustering, BRT uses three possible merging operations, as shown in Figure 1:"""""",null,null",null,null
64,"63,""· Join: Tm ,"""" Ti ,Tj , such that the tree Tm has two children now"""""",null,null",null,null
65,"64,""· Absorb: Tm ,"""" children(Ti )  Tj , i.e., the children of one tree gets absorbed into the other tree forming an absorbed tree with >2 children"""""",null,null",null,null
66,"65,""· Collapse: Tm ,"""" children(Ti )  children(Tj ), all the children of both the subtrees get combined together at the same level."""""",null,null",null,null
67,"66,""Speci cally, in each step, the algorithm greedily nds two trees Ti and Tj to merge which maximize the ratio of probability:"",null,null",null,null
68,"67,p(Dm |Tm ) p(Di |Ti )p(Dj |Tj ),null,null",null,null
69,"68,(1),null,null",null,null
70,"69,""where p(Dm |Tm ) is the likelihood of data Dm given the tree Tm , Dm is all the leaf data of Tm , and Dm , Di  Dj . e probability p(Dm |Tm ) is recursively de ned on the children of Tm :"",null,null",null,null
71,"70,""p(Dm |Tm ) , Tm f (Dm ) + (1 - Tm )"",null,null",null,null
72,"71,p(Di |Ti ) (2),null,null",null,null
73,"72,Ti ch(Tm ),null,null",null,null
74,"73,""where f (Dm ) is the marginal probability of the data Dm and Tm is the """"mixing proportion"""". Intuitively, Tm is the prior probability that all the data in Tm is kept in one cluster instead of partitioned"",null,null",null,null
75,"74,""into sub-trees. In BRT[4], Tm is de ned as:"",null,null",null,null
76,"75,""Tm , 1 - (1 -  )nTm -1"",null,null",null,null
77,"76,(3),null,null",null,null
78,"77,""where nTm is the number of children of Tm , and 0    1 is the hyperparameter to control the model. A larger  leads to coarser"",null,null",null,null
79,"78,287,null,null",null,null
80,"79,Session 3A: Search Interaction 2,null,null",null,null
81,"80,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
82,"81,cosine edit Jac Term,null,null",null,null
83,"82,Min-edit-U Avg-edit-U Jac-U-min Jac-U-avg,null,null",null,null
84,"83,Same-U Same-S,null,null",null,null
85,"84,Embedding,null,null",null,null
86,"85,ery-Term Based A nity (r 1) cosine similarity between the term sets of the queries,null,null",null,null
87,"86,norm edit distance between query strings Jaccard coe between the term sets of the queries proportion of common terms between the queries,null,null",null,null
88,"87,URL Based A nity (r 2) Minimum edit distance between all URL pairs from the queries Average edit distance between all URL pairs from the queries Minimum Jaccard coe cient between all URL pairs from the queries Average Jaccard coe cient between all URL pairs from the queries,null,null",null,null
89,"88,Session/User Based A nity (r 3) if the two queries belong to the same user,null,null",null,null
90,"89,if the two queries belong to the same session Embedding Based A nity (r 4) cosine distance between embedding vectors of the two queries,null,null",null,null
91,"90,Table 2: ery- ery A nities.,null,null",null,null
92,"91,partitions and a smaller  leads to ner partitions. Table 1 provides an overview of notations & symbols used throughout the paper.,null,null",null,null
93,"92,4.2 Building Task Hierarchies,null,null",null,null
94,"93,""We next describe our task hierarchy construction approach built on top of Bayesian Rose Trees. A tree node in our se ing is comprised of a group of queries which potentially compose a search task, i.e. these are the set of queries that people tend to issue in order to achieve the task represented in the tree node."",null,null",null,null
95,"94,""We de ne the task-subtask hierarchy recursively: T is a task if either T contains all the queries at its node (an atomic search task) or if T splits into children trees as T ,"""" {T1,T2, ...,TnT } where each of the children trees (Ti ) are disjoint set of queries corresponding to the nT subtasks associated with task T . is allows us to consider trees as a nested collection of sets of queries de ning our tasksubtask hierarchical relation."""""",null,null",null,null
96,"95,""To form nested hierarchies, we rst need to model the query data. is corresponds to de ning the marginal distribution of the data f (Dm ) as de ned in Equation 2. e marginal distribution of the query data (f (Dm )) helps us encapsulate insights about task level interdependencies among queries, which aid in constructing be er task representations. e original BRT approach [4] assumes that the data can be modeled by a set of binary features that follow the Bernoulli distribution. In other words, features (that represent the relationship/similarities between data points) are not weighted and can only be binary. Binary (0/1) relationships are too simplistic to model inter-query relationships; as a result, this major assumption fails to capture the semantic relationships between queries and is not suited for modeling query-task relations. To this end, we propose a novel query a nity model and to alleviate the binary feature assumption imposed by BRT, we propose a conjugate model of query a nities, which we describe next."",null,null",null,null
97,"96,4.3 Conjugate Model of ery A nities,null,null",null,null
98,"97,A tree node in our se ing is comprised of a group of queries which potentially belong to the same search task. e likelihood of a tree should encapsulate information about the di erent relationships,null,null",null,null
99,"98,""which exists between queries. Our goal here is to make use of the rich information associated with queries and their result set available to compute the likelihood of a set of queries to belong to the same task. In order to do so, we propose a query a nity model which makes use of a number of di erent inter-query a nities to determine the tree likelihood function."",null,null",null,null
100,"99,We next describe the technique used to compute four broad categories of inter-query a nity and later describe the Gamma-Poisson conjugate model which makes use of these a nities to compute the marginal distribution of the data.,null,null",null,null
101,"100,""ery-term based A nity (r 1): Search queries catering to the same or similar informational needs tend to have similar query terms. We make use of this insight and capture query level a nities between a pair of queries. We make use of cosine similarity between the query term sets, the normalized edit distances between queries and the Jaccard Coe cient between query term sets."",null,null",null,null
102,"101,""URL-based A nity (r 2): Users tackling similar tasks tend to issue queries (possibly di erent) which return similar URLs, thus encoding the URL level similarity between pairs of queries into the query a nity model helps in capturing another task-speci c similarity between queries. Any query pair having high URL level similarity increase the possibility of the query pair originating from similar informational needs. We capture a number of URL-based signals including minimum and average edit distances between URL domains and jaccard coe cient between URLs."",null,null",null,null
103,"102,User/Session based A nity (r 3): It is o en the case that users issue related queries within a session so as to satisfy their informational need. We leverage this insight by making use of session level information (as a 0/1 binary feature) and user-level information (as a 0/1 binary feature) in our a nity model to identify queries issued in the same session and by the same user accordingly.,null,null",null,null
104,"103,288,null,null",null,null
105,"104,Session 3A: Search Interaction 2,null,null",null,null
106,"105,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
107,"106,""ery Embedding based A nity (r 4): Word embeddings capture lexico-semantic regularities in language, such that words with similar syntactic and semantic properties are found to be close to each other in the embedding space. We leverage this insight and propose a query-query a nity metric based on such embeddings. We train a skip-gram word embeddings model where a query term is used as an input to a log-linear classi er with continuous projection layer and words within a certain window before and a er the words are predicted. To obtain a query's vector representation, we average the vector representations of each of its query terms and compute the cosine similarity between two queries' vector representations to quantify the embedding based a nity (r 4)."",null,null",null,null
108,"107,""Table 2 summarizes all features considered to compute these a nities. Our goal is to capture information from all four a nities when de ning the likelihood of the tree. We assume that the global a nity among a group of queries can be decomposed into a product of independent terms, each of which represent one of the four a nities from the query-group. For each query group Q, we take the normalized sum of the a nities from all pairs of queries in the group Q to form each of the a nity component (rk , k,""""1,2,3,4)."""""",null,null",null,null
109,"108,""Poisson models have been shown as e ective query generation models for information retrieval tasks [26]. While these a nities could be used with a lot of distributions, in the interest of computational e ciency and to avoid approximate solutions, our model will use a hierarchical Gamma-Poisson distribution to encode the query-query a nities. We incorporate the gamma-Poisson conjugate distribution in our model under the assumptions that the query a nities are discretized and for a group of queries Q, the a nities can be decomposed to a product of independent terms, each of which represents contributions from the four di erent a nity types. Finally, for a tree (Tm ) consisting of the data (Dm ), i.e. the set of queries Q, we de ne the marginal likelihood as:"",null,null",null,null
110,"109,""k ,4"",null,null",null,null
111,"110,""f (Dm ) , f (Q) , p"",null,null",null,null
112,"111,""rqki,qj |k , k (4)"",null,null",null,null
113,"112,""k ,1 i 1··· |Q | j 1··· |Q |"",null,null",null,null
114,"113,where k & k are respectively the shape parameter & the rate parameter of the four di erent a nities. Making use of the Poisson-,null,null",null,null
115,"114,""Gamma conjugacy, the probability term in the above product can"",null,null",null,null
116,"115,be wri en as:,null,null",null,null
117,"116,""p(r |, ) ,"""" p(r |)p(|, )d"""""",null,null",null,null
118,"117,(5),null,null",null,null
119,"118,r,null,null",null,null
120,"119,"","",null,null",null,null
121,"120,( + r )  r ! ()  + 1,null,null",null,null
122,"121,1  +1,null,null",null,null
123,"122,(6),null,null",null,null
124,"123,""where  is the Poisson mean rate parameter which gets eliminated from computations because of the Gamma-Poisson conjugacy and where r ,  &  get replaced by a nity class speci c values."",null,null",null,null
125,"124,4.4 Task Coherence based Pruning,null,null",null,null
126,"125,""e search task extraction algorithm described above provides us a way of constructing a task hierarchy wherein as we go down the tree, nodes comprising of complex multi-aspect tasks split up to provide ner tasks which ideally should model user's ne grained information needs. One key problem with the hierarchy construction algorithm is the continuous spli ing of nodes which results"",null,null",null,null
127,"126,""in singleton queries occupying the leave nodes. While spli ing of nodes which represent complex tasks is important, the nodes representing simple search task queries corresponding to atomic informational needs should not be further split into children nodes. Our goal in this section is to provide a way of quantifying the task complexity of a particular node so as to prevent spli ing up nodes representing atomic search task into further subsets of query nodes."",null,null",null,null
128,"127,""4.4.1 Identifying Atomic Tasks. We wish to identify nodes capturing search subtasks which represent atomic informational need. In order to do so, we introduce the notion of Task Coherence:"",null,null",null,null
129,"128,De nition 4.1. Task Coherence is a measure indicating the atomicity of the information need associated with the task. It is captured by the semantic closeness of the queries associated with the task.,null,null",null,null
130,"129,""By measuring Task Coherence, we intend to capture the semantic variability of queries within this task in an a empt to identify how complex or atomic a task is. For example, a tree node corresponding to a complex task like planning a vacation would involve queries from varied informational needs including ights, hotels, getaways, etc; while a tree node corresponding to a ner task representing an atomic informational need like nding discount coupons would involve less varied queries - all of which would be about discount coupons. Traditional research in topic modelling has looked into automatic evaluation of topic coherence [29] via Pointwise Mutual Information. We leverage the same insights to capture task coherence."",null,null",null,null
131,"130,""4.4.2 Pointwise Mutual Information. PMI has been studied variously in the context of collocation extraction [31] and is one measure of the statistical independence of observing two words in close proximity. We wish to compute PMI scores for each node of the tree. A tree node in our discussion so far has been represented by a collection of search queries. We split queries into terms and obtain a set of terms corresponding to each node, and calculate a node's PMI scores using the node's set of query terms."",null,null",null,null
132,"131,""More speci cally, the PMI of a given pair of query terms (w1 & w2) is given by:"",null,null",null,null
133,"132,""PMI (w1, w2) , lo"",null,null",null,null
134,"133,""p(w1, w2) p(w1)p(w2)"",null,null",null,null
135,"134,(7),null,null",null,null
136,"135,where the probabilities are determined from the empirical statistics of some full standard collection. We employ the AOL log query set for this and treat two query terms as co-occurring if both terms,null,null",null,null
137,"136,""occur in the same session. For a given task node (Q), we measure task coherence as the average of PMI scores for all pairs of the search terms associated with the task node:"",null,null",null,null
138,"137,PMI,null,null",null,null
139,"138,- Score(Q),null,null",null,null
140,"139,"","",null,null",null,null
141,"140,1 |w |,null,null",null,null
142,"141,""|w | i ,1"",null,null",null,null
143,"142,|w |,null,null",null,null
144,"143,""PMI (wi , wj )"",null,null",null,null
145,"144,""j ,1"",null,null",null,null
146,"145,(8),null,null",null,null
147,"146,where |w | represents the total number of unique search terms associated with task node Q. e node's PMI-Score is used as the,null,null",null,null
148,"147,nal measure of task coherence for the task represented via the corresponding node.,null,null",null,null
149,"148,""4.4.3 Tree Pruning. We use the task coherence score associated with each node of the task hierarchy constructed, and prune lower level nodes of the tree to avoid aggressive node spli ing. e"",null,null",null,null
150,"149,289,null,null",null,null
151,"150,Session 3A: Search Interaction 2,null,null",null,null
152,"151,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
153,"152,""overall motivation here is to avoid spli ing nodes which represent simple search tasks associated with atomic informational needs. We scan through all levels of the search task hierarchy obtained by the algorithm described above and for each node compute its task coherence score. If the task coherence score exceeds a speci c threshold, it implies that all the queries in this particular node are aimed at solving the same or very similar informational need and hence, we prune o the sub-tree rooted at this particular node and ignore all further splits of this node."",null,null",null,null
154,"153,4.5 Algorithmic Overview,null,null",null,null
155,"154,""We summarize the overall algorithm to construct the hierarchy by outlining the steps. e problem is treated as one of greedy model selection: each tree T is a di erent model, and we wish to nd the model that best explains the search log data in terms of task-subtask structure."",null,null",null,null
156,"155,""Step 1: Forrest Initialization: e tree is built in a bo om-up greedy agglomerative fashion, start-"",null,null",null,null
157,"156,""ing from a forest consisting of n (,""""|Q |) trivial trees, each corresponding to exactly one vertex. e algorithm maintains a forest F of trees, the likelihood p(i) """","""" p(Di |Ti ) of each tree Ti  F and the di erent query a nities. Each iteration then merges two of the trees in the forest. At each iteration, each vertex in the network is a leaf of exactly one tree in the forest. At each iteration a pair of trees in the forest F is chosen to be merged, resulting in forest F ."""""",null,null",null,null
158,"157,""Step 2: Merging Trees: At each iteration, the best potential merge, say of trees X and Y resulting in tree I, is picked o the heap. Binary trees do not t into representing search tasks since a task is likely to be composed of more than two subtasks. As a result, following [3] we consider three possible mergers of two trees Ti and Tj into Tm . Tm may be formed by joining Ti and Tj together using a new node, giving Tm ,"""" {Ti ,Tj }. Alternatively Tm may be formed by absorbing Ti as a child of Tj , yielding Tm """","""" {Tj } ch(Ti ), or vice-versa, Tm """", {Ti } ch(Tj ). We explain the di erent possible merge operations in Figure 1. We obtain arbitrary shaped sub-trees (without restricting to binary tress) which are be er at representing the varied task-subtask structures as observed in search logs with the structures themselves learnt from log data. Such expressive nature of our approach di erentiates it from traditional agglomerative clustering approaches which necessarily result in binary trees."",null,null",null,null
159,"158,""Step 3: Model Selection: Which pair of trees to merge, and how to merge these trees, is determined by considering which pair and type of merger yields the largest Bayes factor improvement over the current model. If the trees Ti and Tj are merged to form the tree M, then the Bayes factor score is:"",null,null",null,null
160,"159,""SCORE(M; I,"",null,null",null,null
161,"160,),null,null",null,null
162,"161,"","",null,null",null,null
163,"162,p(DM |F ) p(DM |F ),null,null",null,null
164,"163,(9),null,null",null,null
165,"164,"","",null,null",null,null
166,"165,p(DM |M) p(Di |Ti )p(Dj |Tj ),null,null",null,null
167,"166,(10),null,null",null,null
168,"167,""where p(Di |Ti ) and p(Dj |Tj ) are given by the dynamic programming equation mentioned above. A er a successful merge, the"",null,null",null,null
169,"168,""statistics associated with the new tree are updated. Finally, potential mergers of the new tree with other trees in the forest are considered and added onto the heap."",null,null",null,null
170,"169,""e algorithm nishes when no further merging results in improvement in the Bayes Factor score. Note that the Bayes factor score is based on data local to the merge - i.e., by considering the probability of the connectivity data only among the leaves of the newly merged tree. is permits e cient local computations and makes the assumption that local community structure should depend only on the local connectivity structure."",null,null",null,null
171,"170,""Step 4: Tree Pruning: A er constructing the entire hierarchy, we perform the post-hoc tree pruning procedure described in Section 4.4 wherein we identify atomic task nodes via their task coherence estimates and prune all child nodes of the identi ed atomic nodes."",null,null",null,null
172,"171,5 EXPERIMENTAL EVALUATION,null,null",null,null
173,"172,""We perform a number of experiments to evaluate the proposed task-subtask extraction method. First, we compare its performance with existing state-of-the-art task extraction systems on a manually labelled ground-truth dataset and report superior performance (5.1). Second, we perform a detailed crowd-sourced evaluation of extracted tasks and additionally validate the hierarchy using human labeled judgments (5.2). ird, we show a direct application of the extracted tasks by using the task hierarchy constructed for term prediction (5.3)."",null,null",null,null
174,"173,""Parameter Setting: Unless stated otherwise, we made use of the best performing hyperparameters for the baselines as reported by the authors. e query a nities in the proposed approach were computed from the speci c query collection used in the dataset used for each of the three experiments reported below. While hyperparmeter optimization is beyond the scope of this work, we experimented with a range of the shape and inverse scale hyperparameters (, ) used for the Poison Gamma conjugate model and used the ones which performed best on the validation set for the search task identi cation results reported in the next section. Additionally, for the tree pruning threshold, we empirically found that a threshold of 0.8 gave the best performance on our toy hierarchies, and was used for all future experiments."",null,null",null,null
175,"174,5.1 Search Task Identi cation,null,null",null,null
176,"175,""To justify the e ectiveness of the proposed model in identifying search tasks in query logs, we employ a commonly used AOL data subset with search tasks annotated which is a standard test dataset for evaluating task extraction systems. We used the task extraction dataset as provided by Lucchese et al.[20]. e dataset comprises of a sample of 1000 user sessions for which human assessors were asked to manually identify the optimal task-based query sessions, thus producing a ground-truth that can be used for evaluating automatic task-based session discovery methods. For further details on the dataset and the dataset access links, readers are directed to Lucchese et al.[20]."",null,null",null,null
177,"176,290,null,null",null,null
178,"177,Session 3A: Search Interaction 2,null,null",null,null
179,"178,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
180,"179,We compare our performance with a number of search task identi cation approaches:,null,null",null,null
181,"180,· Bestlink-SVM [37]: is method identi ed search task using a semi-supervised clustering model based on the latent structural SVM framework.,null,null",null,null
182,"181,""· QC-HTC/QC-WCC [20]: is series of methods viewed search task identi cation as the problem of best approximating the manually annotated tasks, and proposed both clustering and heuristic algorithms to solve the problem."",null,null",null,null
183,"182,""· LDA-Hawkes [17]: a probabilistic method for identifying and labeling search tasks that model query temporal patterns using a special class of point process called Hawkes processes, and combine topic model with Hawkes processes for simultaneously identifying and labeling search tasks."",null,null",null,null
184,"183,""· LDA Time-Window(TW): is model assumes queries belong to the same search task only if they lie in a xed or exible time window, and uses LDA to cluster queries into topics based on the query co-occurrences within the same time window. We tested time windows of various sizes and report results on the best performing window size."",null,null",null,null
185,"184,""5.1.1 Metrics. A commonly used evaluation metric for search task extraction is the pairwise F-measure computed based on pairwise precision/recall [13, 15] de ned as,"",null,null",null,null
186,"185,ppair,null,null",null,null
187,"186,"","",null,null",null,null
188,"187,i j (,null,null",null,null
189,"188,""(qi ), (qj )) ( ^(qi ),  ( ^(qi ), ^(qj ))"",null,null",null,null
190,"189,^(qj )),null,null",null,null
191,"190,(11),null,null",null,null
192,"191,rpair,null,null",null,null
193,"192,"","",null,null",null,null
194,"193,i j (,null,null",null,null
195,"194,""(qi ), (qj )) ( ^(qi ), ^(qj ))  ( (qi ), (qj ))"",null,null",null,null
196,"195,(12),null,null",null,null
197,"196,where ppair evaluates how many pairs of queries predicted in the,null,null",null,null
198,"197,""same task, i.e.,  ( ^(qi ), ^(qj ) ,"""" 1, are actually annotated as in the"""""",null,null",null,null
199,"198,""same task, i.e.,  ( (qi ), (qj )) , 1 and rpair evaluates how many"",null,null",null,null
200,"199,pairs annotated as in the same task are recovered by the algorithm.,null,null",null,null
201,"200,""us, globally F-measure evaluates the extent to which a task con-"",null,null",null,null
202,"201,tains only queries of a particular annotated task and all queries,null,null",null,null
203,"202,""of that task. Given ppair and rpair , the F-measure is computed"",null,null",null,null
204,"203,as:F1,null,null",null,null
205,"204,"","",null,null",null,null
206,"205,2×ppair ×rpair ppair +rpair,null,null",null,null
207,"206,.,null,null",null,null
208,"207,""5.1.2 Results & Discussion. Figure 2 compares the proposed model with alternative probabilistic models and state-of-the-art task identi cation approaches by F1 score. To make fair comparisons, we consider the last level of the pruned tree constructed as task clusters when computing pairwise precision/recall values. It is important to note that the labelled dataset has only at tasks extracted on a per user basis; as a result, this dataset is not ideal for making fair comparisons of the proposed hierarchy extraction method with baselines. Nevertheless, the proposed approach manages to outperform existing task extraction baselines while having much greater expressive powers and providing the subdivision of tasks into subtasks. LDA-TW performs the worst since its assumptions on query relationship within the same search task are too strong. e advantage over QC-HTC and QC-WCC demonstrates that appropriate usage of query a nity information can even better re ect the semantic relationship between queries, rather than exploiting it in some collaborative knowledge."",null,null",null,null
209,"208,F Score,null,null",null,null
210,"209,0.85 0.84 0.83 0.82 0.81,null,null",null,null
211,"210,0.8 0.79 0.78 0.77 0.76 0.75,null,null",null,null
212,"211,Proposed,null,null",null,null
213,"212,LDA-TW,null,null",null,null
214,"213,Bestlink-SVM,null,null",null,null
215,"214,LDA-Hawkes,null,null",null,null
216,"215,QC-HTC,null,null",null,null
217,"216,QC-WCC,null,null",null,null
218,"217,Figure 2: F1 score results on AOL tagged dataset,null,null",null,null
219,"218,5.2 Evaluating the Hierarchy,null,null",null,null
220,"219,""While there are no gold standard datasets for evaluating hierarchies of tasks, we performed crowd-sourced assessments to assess the performance of our hierarchy extraction method. We separately evaluated the coherence and quality of the extracted hierarchies via two di erent set of judgements obtained via crowdsourcing."",null,null",null,null
221,"220,""Evaluation Setup For the judgment study, we make use of the AOL search logs and randomly sampled entire query history of frequent users who had more than 1000 search queries. e AOL log is a very large and long-term collection consisting of about 20 million of Web queries issued by more than 657000 users over 3 months. We run the task extraction algorithms on the entire set of queries of the sampled users and collect judgments to assess the quality of the tasks extracted. Judgments were provided by over 40 judges who were recruited from the Amazon Mechanical Turk crowdsourcing service. We restricted annotators to those based in the US because the logs came from searchers based in the US. We also used hidden quality control questions to lter out poor-quality judges. e judges were provided with detailed guidelines describing the notion of search tasks and subtasks and were provided with several examples to help them be er understand the judgement task."",null,null",null,null
222,"221,""Evaluating Task Coherence In the rst study, we evaluated the quality of the tasks extracted by the task extraction algorithms. In an ideal task extraction system, all the queries belonging to the same task cluster should ideally belong to the same task and hence have be er task coherence. To this end, we evaluate the task coherence property of the tasks extracted by the di erent algorithms. For each of the baselines and the proposed algorithm, we select a task at random from the set of tasks extracted and randomly pick up two queries from the selected task. We then ask the human judges the following question:"",null,null",null,null
223,"222,291,null,null",null,null
224,"223,Session 3A: Search Interaction 2,null,null",null,null
225,"224,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
226,"225,Task Relatedness,null,null",null,null
227,"226,Proposed LDA-TW QC-WCC LDA-Hawkes QC-HTC,null,null",null,null
228,"227,Task Related,null,null",null,null
229,"228,72%*,null,null",null,null
230,"229,47%,null,null",null,null
231,"230,60%,null,null",null,null
232,"231,67%,null,null",null,null
233,"232,61%,null,null",null,null
234,"233,Somewhat Related 20%,null,null",null,null
235,"234,14%,null,null",null,null
236,"235,15%,null,null",null,null
237,"236,13%,null,null",null,null
238,"237,5%,null,null",null,null
239,"238,Unrelated,null,null",null,null
240,"239,10%,null,null",null,null
241,"240,23%,null,null",null,null
242,"241,25%,null,null",null,null
243,"242,20%,null,null",null,null
244,"243,34%,null,null",null,null
245,"244,Table 3: Performance on Task Relatedness. e results highlighted with * signify statistically signi cant di erence between the proposed approach and best performing baseline using  2 test with p  0.05.,null,null",null,null
246,"245,Subtask Validity,null,null",null,null
247,"246,Valid,null,null",null,null
248,"247,Proposed Jones BHCD BAC,null,null",null,null
249,"248,81%*,null,null",null,null
250,"249,69% 51% 49%,null,null",null,null
251,"250,Somewhat Valid,null,null",null,null
252,"251,8%,null,null",null,null
253,"252,19% 17% 21%,null,null",null,null
254,"253,Not Valid,null,null",null,null
255,"254,11%,null,null",null,null
256,"255,12% 32% 30%,null,null",null,null
257,"256,Subtask Usefulness,null,null",null,null
258,"257,Useful,null,null",null,null
259,"258,67%*,null,null",null,null
260,"259,52% 41% 43%,null,null",null,null
261,"260,Somewhat Useful,null,null",null,null
262,"261,8%,null,null",null,null
263,"262,17% 19% 20%,null,null",null,null
264,"263,Not Useful,null,null",null,null
265,"264,25%,null,null",null,null
266,"265,31% 40% 37%,null,null",null,null
267,"266,Table 4: Performance on Subtask Validity and Subtask Use-,null,null",null,null
268,"267,fulness. Results highlighted with * signify statistically sig-,null,null",null,null
269,"268,ni cant di erence between the proposed framework and best performing baseline using  2 test with p  0.05.,null,null",null,null
270,"269,""RQ1: Task Relatedness: Are the given pairs of queries related to the same task? e possible options include (i) Task Related, (ii) Somewhat Task Related and (iii) Unrelated."",null,null",null,null
271,"270,""e task relatedness score provides an estimate of how coherent tasks are. Indeed, a task cluster containing queries from di erent tasks would score less in Task Relatedness score since if the task cluster is impure, there is a greater chance that the 2 randomly picked queries belong to di erent tasks and hence get judged Unrelated."",null,null",null,null
272,"271,""Evaluating the hierarchy While there are no gold standard dataset to evaluate hierarchies, in our second crowd-sourced judgment study, we evaluate the quality of the hierarchy extracted. A valid task-subtask hierarchy would have the parent task representing a higher level task with its children tasks representing more focused subtasks, each of which help the user achieve the overall task identi ed by the parent task."",null,null",null,null
273,"272,""We evaluate the correctness of the hierarchy by validating parentchild task-subtask relationships. More speci cally, we randomly select a parent node from the hierarchy and then randomly select a child node from the set of its immediate child nodes. Given such parent-child node pairs, we randomly pick 5 queries from the parent node and randomly pick 2 queries from the child node. We then show the human judges these parent and child queries and ask the following questions:"",null,null",null,null
274,"273,RQ2: Subtask Validity: Consider the set of queries representing the search task and the pair of queries representing the subtask.,null,null",null,null
275,"274,How valid is this subtask given the overall task?,null,null",null,null
276,"275,""e possible judge options include (i) Valid Subtask, (ii) Somewhat valid and (iii) Invalid. Answering this question helps us in analyzing the correctness of the parent-child task-subtask pairs."",null,null",null,null
277,"276,RQ3: Subtask Usefulness: Consider the set of queries representing the search task and the pair of queries representing the subtask. Is the subtask useful in completing the overall search task?,null,null",null,null
278,"277,""e possible judge options include (i) Useful, (ii) Somewhat Useful and (iii) Not Useful. is helps us in evaluating the usefulness of task-subtask pairs by nding the proportion of subtasks which help users in completing the overall task described by the parent node. Overall, the RQ2 and RQ3 help in evaluating the correctness and usefulness of the hierarchy extracted."",null,null",null,null
279,"278,""Baselines Since RQ1 evaluates task coherence without any notion of tasksubtask structure, we compare against the top performing baselines from the task extraction setup described in section 5.1. On the other hand, RQ2 & RQ3 help in answering questions about the quality of hierarchy constructed. To make fair comparisons while evaluating the hierarchies, we introduce additional hierarchy extraction baselines:"",null,null",null,null
280,"279,· Jones Hierarchies [13]: A supervised learning approach for task boundary detection and same task identi cation. We train the classi er using the supervised Lucchese AOL task dataset and use it to extract tasks on the current dataset used in the judgment study.,null,null",null,null
281,"280,· BHCD [3]: A state-of-the-art bayesian hierarchical community detection algorithm based on stochastic blockmodels and makes use of Beta-Bernoulli conjugate priors to de ne a network. We build a network of queries and apply BHCD algorithm to extract hierarchies of query communities.,null,null",null,null
282,"281,· Bayesian Agglomerative Clustering (BAC) [11]: A standard agglomerative hierarchical clustering model based on Dirichlet process mixtures.,null,null",null,null
283,"282,""Results & Discussion For the rst judgment study, each HIT is composed of 20 query pairs per approach being judged for task relatedness. We had three judges work on every HIT. Overall, per method we obtained judgments for 60 query pairs to evaluate the performance on task-relatedness. From among the three judges judging each query-pair, we followed majority voting mechanism to nalize the label for the instance."",null,null",null,null
284,"283,292,null,null",null,null
285,"284,Session 3A: Search Interaction 2,null,null",null,null
286,"285,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
287,"286,avg no of query terms predicted per session,null,null",null,null
288,"287,1.2,null,null",null,null
289,"288,QC-WCC Proposed BHCD LDA-TW LDA-Hawkes,null,null",null,null
290,"289,1.1,null,null",null,null
291,"290,1,null,null",null,null
292,"291,0.9,null,null",null,null
293,"292,0.8,null,null",null,null
294,"293,0.7,null,null",null,null
295,"294,0.6,null,null",null,null
296,"295,0.5,null,null",null,null
297,"296,0.4,null,null",null,null
298,"297,0.3 50,null,null",null,null
299,"298,66,null,null",null,null
300,"299,75,null,null",null,null
301,"300,80,null,null",null,null
302,"301,90,null,null",null,null
303,"302,% age of user session data tested on,null,null",null,null
304,"303,Figure 3: Term Prediction performance,null,null",null,null
305,"304,""Table 3 presents the proportions of query pairs judged as related. About 72% of query pairs were judged task-related for the proposed approach with LDA-Hawkes performing second best with 67%. Task relatedness measures how pure the task clusters obtained are, a higher score indicates that the queries belonging to the same task are indeed used for solving the same search task. e overall results indicate that the tasks extracted by the proposed task-subtask extraction algorithm are indeed be er than those extracted by the baselines."",null,null",null,null
306,"305,""For the second judgment study used for evaluating the quality of the hierarchy, we show 10 pairs of parent-child questions in each HIT and ask the human annotators to judge the subtask validity and usefulness. Overall, per method we evaluate 300 such judgments resulting in over 1200 judgments and used maximum voting criterion from among the 3 judges to decide the nal label for each instance. Table 4 compares the performance of the proposed hierarchy extraction method against other hierarchical baselines."",null,null",null,null
307,"306,""e identi ed subtask was found useful in 67% cases with the best performing baseline being useful in 52% of judged instances. is highlights that the extracted hierarchy is indeed composed of be er subtasks which are found to be useful in completing the overall task depicted by the parent task. It is interesting to note that for BHCD and BAC baselines, most o en the subtasks were found to be invalid and not useful."",null,null",null,null
308,"307,""Since the same parent-child task-subtask was judged for validity and usefulness, it is expected that the proportion of task-subtasks judged useful would be less than the ones judged valid. Indeed, as can be seen from the Table 4, the relative proportions of taskssubtasks found useful is much less than those found valid."",null,null",null,null
309,"308,5.3 Term Prediction,null,null",null,null
310,"309,""In addition to task extraction and user study based evaluation, we chose to follow an indirect evaluation approach based on ery Term Prediction wherein given an initial set of queries, we predict future query terms the user may issue later in the session. is is in line with our goal of supporting users tackling complex search tasks since a task identi cation system which is capable of identifying"",null,null",null,null
311,"310,good search tasks will indeed perform be er in predicting the set of future query terms.,null,null",null,null
312,"311,""To evaluate the performance of the proposed task extraction method, we primarily work with the TREC Session Track 2014 [? ] and AOL log data and constructed a new dataset consisting of user sessions from AOL logs concerned with Session Track queries."",null,null",null,null
313,"312,e session track data consists of over 1200 sessions while AOL logs consists of 20M search queries issued by over 657K users. We,null,null",null,null
314,"313,""nd the intersection of queries between the Session Track data and AOL logs to identify user sessions in AOL data trying to achieve similar task objectives. e Session Track dataset consists of 60 di erent topics. For each of these 60 topics, we separately nd user sessions from the entire AOL logs which contain query overlaps with these topics. For each topic, we iterate through the entire AOL logs and select any user session which contains query overlap with the current topic. As a result, we obtain a total of 14030 user sessions which contain around 6.4M queries."",null,null",null,null
315,"314,""Given the initial queries from a user session and a set of tasks extracted from Session Track data, we leverage queries from the identi ed task to predict future query terms. For each Session Track topic, we construct a task hierarchy and use the constructed task hierarchy to predict future query terms in the associated user sessions. More speci cally, for each topic, we split each user session into two parts: (i) task matching and (ii) held-out evaluation part. We use queries from the task matching part of user sessions to obtain the right node in the task hierarchy from which we then recommend query terms. We pick the tree node which has the highest cosine similarity score based on all the query terms under consideration. We evaluate based on the absolute recall scores - the average number of recommended query terms which match with the query terms in the held-out evaluation part of user sessions."",null,null",null,null
316,"315,""We baseline against the top performing task extraction baselines from Section 5.1 as well as the top performing hierarchical algorithms from Section 5.2. To make fair comparisons, we consider nodes at the bo om most level of the pruned tree for task matching and term recommendation."",null,null",null,null
317,"316,Figure 3 compares the performance on term prediction against the considered baselines. We plot the average number of query terms predicted against the proportion of user session data used.,null,null",null,null
318,"317,e proposed method is able to be er predict future query terms than a standard task extraction baseline as well as a very recent hierarchy construction algorithm.,null,null",null,null
319,"318,6 CONCLUSION,null,null",null,null
320,"319,""Search task hierarchies provide us with a more naturalistic view of considering complex tasks and representing the embedded tasksubtask relationships. In this paper we rst motivated the need for considering hierarchies of search tasks & subtasks and presented a novel bayesian nonparametric approach which extracts such hierarchies. We introduced a conjugate query a nity model to capture query a nities to help in task extraction. Finally, we propose the idea of Task Coherence and use it to identify atomic tasks. Our experiments demonstrated the bene ts of considering search task hierarchies. Importantly, we were able to demonstrate competitive performance while at the same time outpu ing a richer and more"",null,null",null,null
321,"320,293,null,null",null,null
322,"321,Session 3A: Search Interaction 2,null,null",null,null
323,"322,""SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan"",null,null",null,null
324,"323,expressive model of search tasks. is expands the scope for bet-,null,null",null,null
325,"324,""ter task recommendation, be er search personalization and opens"",null,null",null,null
326,"325,up new avenues for recommendations speci cally targeting users,null,null",null,null
327,"326,based on the tasks they are involved in.,null,null",null,null
328,"327,REFERENCES,null,null",null,null
329,"328,""[1] Eugene Agichtein, Ryen W White, Susan T Dumais, and Paul N Bennet. 2012. Search, interrupted: understanding and predicting search task continuation. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval. ACM, 315­324."",null,null",null,null
330,"329,""[2] Ricardo Baeza-Yates, Carlos Hurtado, and Marcelo Mendoza. 2004. ery recommendation using query logs in search engines. In International Conference on Extending Database Technology. Springer, 588­596."",null,null",null,null
331,"330,[3] Charles Blundell and Yee Whye Teh. 2013. Bayesian hierarchical community discovery. In Advances in Neural Information Processing Systems. 1601­1609.,null,null",null,null
332,"331,""[4] Charles Blundell, Yee Whye Teh, and Katherine A Heller. 2012. Bayesian rose trees. arXiv preprint arXiv:1203.3468 (2012)."",null,null",null,null
333,"332,""[5] Huanhuan Cao, Daxin Jiang, Jian Pei, Enhong Chen, and Hang Li. 2009. Towards context-aware search by learning a very large variable length hidden markov model from search logs. In Proceedings of the 18th international conference on World wide web. ACM, 191­200."",null,null",null,null
334,"333,""[6] Lara D Catledge and James E Pitkow. 1995. Characterizing browsing strategies in the World-Wide Web. Computer Networks and ISDN systems 27, 6 (1995), 1065­1073."",null,null",null,null
335,"334,""[7] Shui-Lung Chuang and Lee-Feng Chien. 2002. Towards automatic generation of query taxonomy: A hierarchical query clustering approach. In Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on. IEEE, 75­82."",null,null",null,null
336,"335,""[8] Debora Donato, Francesco Bonchi, Tom Chi, and Yoelle Maarek. 2010. Do you want to take notes?: identifying research missions in Yahoo! search pad. In Proceedings of the 19th international conference on World wide web. ACM, 321­ 330."",null,null",null,null
337,"336,""[9] Ahmed Hassan Awadallah, Ryen W White, Patrick Pantel, Susan T Dumais, and Yi-Min Wang. 2014. Supporting complex search tasks. In Proceedings of the"",null,null",null,null
338,"337,""23rd ACM International Conference on Conference on Information and Knowledge Management. ACM, 829­838. [10] Daqing He, Ay¸se Go¨ker, and David J Harper. 2002. Combining evidence for automatic web session identi cation. Information Processing & Management 38, 5 (2002), 727­742. [11] Katherine A Heller and Zoubin Ghahramani. 2005. Bayesian hierarchical clustering. In Proceedings of the 22nd international conference on Machine learning. ACM, 297­304. [12] Wen Hua, Yangqiu Song, Haixun Wang, and Xiaofang Zhou. 2013. Identifying users' topical tasks in web search. In Proceedings of the sixth ACM international conference on Web search and data mining. ACM, 93­102. [13] Rosie Jones and Kristina Lisa Klinkner. 2008. Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs. In Proceedings of the 17th ACM conference on Information and knowledge management. ACM, 699­708. [14] Rosie Jones, Benjamin Rey, Omid Madani, and Wiley Greiner. 2006. Generating query substitutions. In Proceedings of the 15th international conference on World Wide Web. ACM, 387­396. [15] Alexander Kotov, Paul N Benne , Ryen W White, Susan T Dumais, and Jaime Teevan. 2011. Modeling and analysis of cross-session search tasks. In Proceedings"",null,null",null,null
339,"338,""of the 34th international ACM SIGIR conference on Research and development in Information Retrieval. ACM, 5­14. [16] Dawn J Lawrie and W Bruce Cro . 2003. Generating hierarchical summaries for web searches. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 457­458. [17] Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, and Hongyuan Zha. 2014. Identifying and labeling search tasks via query-based hawkes processes. In"",null,null",null,null
340,"339,""Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 731­740. [18] Zhen Liao, Yang Song, Li-wei He, and Yalou Huang. 2012. Evaluating the e ectiveness of search task trails. In Proceedings of the 21st international conference on World Wide Web. ACM, 489­498. [19] Xueqing Liu, Yangqiu Song, Shixia Liu, and Haixun Wang. 2012. Automatic taxonomy construction from keywords. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1433­ 1441. [20] Claudio Lucchese, Salvatore Orlando, Ra aele Perego, Fabrizio Silvestri, and Gabriele Tolomei. 2011. Identifying task-based sessions in search engine query logs. In Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 277­286. [21] Claudio Lucchese, Salvatore Orlando, Ra aele Perego, Fabrizio Silvestri, and Gabriele Tolomei. 2013. Discovering tasks from search engine query logs. ACM Transactions on Information Systems (TOIS) 31, 3 (2013), 14."",null,null",null,null
341,"340,""[22] Bonnie Ma Kay and Carolyn Wa ers. 2008. Exploring multi-session web tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1187­1196."",null,null",null,null
342,"341,""[23] Rishabh Mehrotra, Prasanta Bha acharya, and Emine Yilmaz. 2016. Characterizing users' multi-tasking behavior in web search. In Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval. ACM, 297­300."",null,null",null,null
343,"342,""[24] Rishabh Mehrotra and Emine Yilmaz. 2015. Terms, topics & tasks: Enhanced user modelling for be er personalization. In Proceedings of the 2015 International Conference on e eory of Information Retrieval. ACM, 131­140."",null,null",null,null
344,"343,""[25] Rishabh Mehrotra and Emine Yilmaz. 2015. Towards hierarchies of search tasks & subtasks. In Proceedings of the 24th International Conference on World Wide Web. ACM, 73­74."",null,null",null,null
345,"344,""[26] Qiaozhu Mei, Hui Fang, and ChengXiang Zhai. 2007. A study of Poisson query generation model for information retrieval. In Proceedings of the 30th annual"",null,null",null,null
346,"345,""international ACM SIGIR conference on Research and development in information retrieval. ACM, 319­326. [27] Qiaozhu Mei, Dengyong Zhou, and Kenneth Church. 2008. ery suggestion using hi ing time. In Proceedings of the 17th ACM conference on Information and knowledge management. ACM, 469­478. [28] Dan Morris, Meredith Ringel Morris, and Gina Venolia. 2008. SearchBar: a search-centric web history for task resumption and information re- nding. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1207­1216. [29] David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: e"",null,null",null,null
347,"346,""2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 100­108. [30] Brendan O'Connor, Michel Krieger, and David Ahn. 2010. TweetMotif: Exploratory Search and Topic Summarization for Twi er.. In ICWSM. 384­385. [31] Pavel Pecina. 2010. Lexical association measures and collocation extraction. Language resources and evaluation 44, 1-2 (2010), 137­158. [32] Eran Segal and Daphne Koller. 2002. Probabilistic hierarchical clustering for biological data. In Proceedings of the sixth annual international conference on Computational biology. ACM, 273­280. [33] Craig Silverstein, Hannes Marais, Monika Henzinger, and Michael Moricz. 1999. Analysis of a very large web search engine query log. In ACm SIGIR Forum, Vol. 33. ACM, 6­12. [34] Adish Singla, Ryen White, and Je Huang. 2010. Studying trail nding algorithms for enhanced web search. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval. ACM, 443­450. [35] Amanda Spink, Sherry Koshman, Minsoo Park, Chris Field, and Bernard J Jansen. 2005. Multitasking web search on vivisimo. com. In Information Technology: Coding and Computing, 2005. ITCC 2005. International Conference on, Vol. 2. IEEE, 486­490. [36] Hongning Wang, Yang Song, Ming-Wei Chang, Xiaodong He, Ahmed Hassan, and Ryen W White. 2014. Modeling action-level satisfaction for search task satisfaction prediction. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval. ACM, 123­132. [37] Hongning Wang, Yang Song, Ming-Wei Chang, Xiaodong He, Ryen W White, and Wei Chu. 2013. Learning to extract cross-session search tasks. In Proceedings of the 22nd international conference on World Wide Web. ACM, 1353­1364. [38] Ryen W White, Wei Chu, Ahmed Hassan, Xiaodong He, Yang Song, and Hongning Wang. 2013. Enhancing personalized search by mining and modeling task behavior. In Proceedings of the 22nd international conference on World Wide Web. ACM, 1411­1420. [39] Hui Yang. 2012. Constructing task-speci c taxonomies for document collection browsing. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics, 1278­1289. [40] Hui Yang. 2015. Browsing hierarchy construction by minimum evolution. ACM Transactions on Information Systems (TOIS) 33, 3 (2015), 13. [41] Yongfeng Zhang, Min Zhang, Yiqun Liu, Chua Tat-Seng, Yi Zhang, and Shaoping Ma. 2015. Task-based recommendation on a web-scale. In Big Data (Big Data), 2015 IEEE International Conference on. IEEE, 827­836."",null,null",null,null
348,"347,294,null,null",null,null
349,"348,,null,null",null,null
