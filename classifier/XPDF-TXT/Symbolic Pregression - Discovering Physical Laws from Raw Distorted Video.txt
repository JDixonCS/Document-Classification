arXiv:2005.11212v1 [cs.CV] 19 May 2020

Symbolic Pregression: Discovering Physical Laws from Raw Distorted Video

Silviu-Marian Udrescu & Max Tegmark MIT Dept. of Physics & Center for Brains, Minds & Machines, Cambridge, MA 02139
Theiss Research, La Jolla, CA 92037, USA sudrescu@mit.edu
Abstract
We present a method for unsupervised learning of equations of motion for objects in raw and optionally distorted unlabeled video. We first train an autoencoder that maps each video frame into a low-dimensional latent space where the laws of motion are as simple as possible, by minimizing a combination of non-linearity, acceleration and prediction error. Differential equations describing the motion are then discovered using Pareto-optimal symbolic regression. We find that our pre-regression ("pregression") step is able to rediscover Cartesian coordinates of unlabeled moving objects even when the video is distorted by a generalized lens. Using intuition from multidimensional knot-theory, we find that the pregression step is facilitated by first adding extra latent space dimensions to avoid topological problems during training and then removing these extra dimensions via principal component analysis.
1 Introduction
A central goal of physics and science more broadly is to discover mathematical patterns in data. For example, after four years of analyzing data tables on planetary orbits, Johannes Kepler started a scientific revolution in 1605 by discovering that Mars' orbit was an ellipse [1]. There has been great recent progress in automating such tasks with symbolic regression: discovery of a symbolic expression that accurately matches a given data set [2­22]. Open-source software now exists that can discover quite complex physics equations by combining neural networks with techniques inspired by physics and information theory [21].

Pregression

Symbolic regression

Figure 1: Our pregression algorithm seeks to autoencode a sequence of video frames (left) into a low-dimensional latent space (middle) where the laws of motion (right) are as simple as possible, in this example those of a quartic oscillator.
Preprint. Under review.

However, there is an important underlying problem that symbolic regression does not solve: how to decide which parameters of the observed data we should try to describe with equations. In Kepler's case, for example, the raw data corresponded to two-dimensional telescope images observed by Tycho Brahe: how could a computer algorithm presented with these images automatically learn that it was supposed to extract the two position coordinates of the small white dot corresponding to Mars? In Figure 1, how can an unsupervised algorithm learn that to predict the next video frame, it should focus on the x- and y-coordinates of the rocket, not on its color or on the objects in the background? The goal of this paper is to offer an answer to such questions. We will refer to this pre-regression problem as "pregression" for brevity. Automated pregression enables laws of motion to be discovered starting with raw observational data such as videos. This can be viewed as a step toward unsupervised learning of physics, whereby an algorithm learns from raw observational data without any human supervision or prior knowledge [23­25].
There has been impressive recent progress on using neural networks for video prediction [26­40] and more general physics problems [25, 41­46]. However, these machine-learned models tend to be inscrutable black boxes that provide their human users with limited understanding. In contrast, the machine learning approach in this paper aspires to intelligible intelligence, i.e., learning a model of the system that is simple enough for a human user to understand. Such intelligibility (pursued in, e.g., [24, 25, 47­50]) is a central goal of physics research, and has two advantages:
1. Understanding how a model works enables us to trust it more, which is particularly valuable when AI systems make decisions affecting peoples lives [51­54].
2. Simple intelligible models such as the laws of physics tend to yield more accurate and generalizable predictions than black-box over-parametrized fits, especially over long timescales. This is why spacecraft navigation systems use Newton's law of gravitation rather than a neural-network-based approximation thereof.
The video prediction papers most closely related to the present work take one of two approaches. Some improve accuracy and intelligibility by hardcoding physics elements by hand to help learn e.g. rigid-body motion [55], physical object properties or partial differential equations [56, 57]. The alternative tabula rasa approach assumes no physics whatsoever and attempts to learn physical object properties [58], object positions [59, 60], object relations [61] and time evolution [62­64] by learning a low-dimensional representation or latent space which is unfortunately too complex or inscrutable to allow discovery of exact equations of motion. The present paper builds on this tabula rasa approach; our key contribution is to automatically simplify the latent space, using ideas inspired by general relativity and knot theory, to make the dynamics simple enough for symbolic regression to discover equations of motions.
The rest of this paper is organized as follows. In Section 2, we present our algorithm. In Section 3, we test it on simulated videos (such as the flying rocket example in Figure 1) for motion in a force-free environment, a gravitational field, a magnetic field, a harmonic potential and a quartic potential. We also test the effects of adding noise and geometric image distortion. We summarize our conclusions and discuss future challenges in Section 4.
2 Method
The goal of our method is to start with raw video sequences of an object moving in front of some static background, and, in a fully unsupervised manner (with no input besides the raw video), to discover the differential equation governing the object's motion. Our algorithm consists of two parts:
1. a neural-network-based pregression step that learns to map images into a low-dimensional latent space representing the physically relevant parameters (degrees of freedom), and
2. a symbolic regression step that discovers the law of motion, i.e., the differential equation governing the time-evolution of these parameters.
2.1 Learning the latent space
Abstractly, we can consider each video frame as a single point in an N -dimensional space, where N is the number of color channels (3 in our case) times the number of pixels in each image. If the motion involves only n N degrees of freedom (for example, n = 2 for a rigid object moving
2

Input images:
Latent space:
Reconstructed images:
Figure 2: Our pregression algorithm jointly trains three neural networks: an encoder E that maps images xi into latent space vectors zi, a decoder D that maps latent space vectors zi back into images xi, and an evolution operator U that predicts the next latent space vector from the two previous ones.

without rotating in a two dimensions), then all observed points in the N -dimensional space lie on some n-dimensional submanifold that we wish to discover, parametrized by an n-dimensional parameter vector that we can consider as a point in an n-dimensional latent space. Our neural network architecture for learning the latent space is shown in Figure 2, and consists of three separate feedforward neural networks:
1. An encoder E that maps images xi  RN into latent space vectors zi  Rn, 2. a decoder D that maps latent space vectors zi into images xi, and 3. an evolution operator U that predicts the next latent space vector zi from the two previous
ones (two are needed to infer velocities).1
The encoder-decoder pair forms an autoencoder [65­73] that tries to discover the n most dynamically relevant parameters from each movie frame, from which it can be reconstructed as accurately as possible.
2.2 Quantifying simplicity

Original

Warping

Noise

Figure 3: Our method can discover simple laws of motion even if the images are severely warped or mixed with distracting noise.
It is tempting to view the results of our pregression algorithm as rather trivial, merely learning to extract x- and y- coordinates of objects. This would be incorrect, however, since we will see that the pregression discovers simple physical laws even from video images that are severely warped, as illustrated in Figure 3, where the learned latent space is a complicated non-linear function of the Cartesian coordinates. The basic reason for this is that Figure 2 makes no mention of any preferred
1The two last images are needed because the laws of physics are second order differential equations that can be transformed into second order difference equations; our method trivially generalizes to using the last T inputs for any choice T = 1, 2, 3, ...
3

latent-space coordinate system. This reparametrization invariance (a core feature of general relativity) is a double-edged sword, however: a core challenge that we must overcome is that even if the system can be described by a simple time-evolution U , the basic architecture in Figure 2 may discover something much more complicated. To see this, suppose that there is an autoencoder (E, D) and evolution operator U providing perfect image reconstruction and prediction, i.e., satisfying

D(E(xi)) = xi, U (zi-2, zi-1) = zi,

(1)

and that U is a fairly simple function. If we now deform the latent space by replacing z by z  f (z) for some invertible but horribly complicated function f , then it is easy to see that the new mappings defined by

E (x)  f (E(x)), D (z )  D(f -1(z )), U (z )  f (U (f -1(z )))

(2)

will still provide perfect autoencoding and evolution

D (E (xi)) = xi, U (zi-2, zi-1)) = zi,

(3)

even though the new evolution operator U is now a very complicated.
Not only can our architecture discover unnecessarily complicated solutions, but it by default will. We jocularly termed this the Alexander principle in honor of a child of one of the authors whose sense of humor dictated that he comply with requests in the most complicated way consistent with the instructions. We will face multiple challenges of this type throughout this paper, where our neural networks appeared humorously spiteful simply because they statistically find the most generic solution in a vast class of equally accurate ones.
To tackle this problem, we wish to add a term to the loss function that somehow rewards simplicity and penalizes complexity, ideally in a way that involves as few assumptions as possible about the type of dynamics occurring in the video. Defining the 2n-dimensional vector

wi 

zi-2 zi-1

 R2n,

(4)

we can view the evolution function U (w) as a mapping from R2n to Rn that we wish to be as simple as possible. One natural complexity measure for U is its curvature

Lcurv  Rµ Rµ ,

(5)

defined as the squared Riemann tensor that is ubiquitous in differential geometry and general relativity, defined as

Rµ  ,µ - µ, + µ  -  µ ,

(6)

µ



1 g 2

(gµ,

+

g,µ

-

gµ,) ,

(7)

g  JJt,

(8)

where J is the Jacobian of U , the matrix g is the induced metric on the latent space Rn, indices are raised by multiplying by g-1, commas denote derivatives as in standard tensor notation, and the Einstein summation convention is used. Natural alternatives are the squared Ricci curvature RµRµ or the scalar curvature R  gµ Rµ , where Rµ  Rµ .
Unfortunately, these curvature measures are numerically cumbersome, since they require taking 3rd derivatives of the neural-network-defined function U and the Riemann tensor has n4 components. Fortunately, we find that a simpler measure of complexity performs quite well in practice, as reflected by the following loss function:

L  Lrecon + Lpred + Lnl + Lacc,

(9)

4

where

Lrecon



1 m |xi - D(E(xi))| ,

m
i=1

|xi|

(10)

Lpred



1 m |zi - U (zi-2, zi-1))| ,

m
i=1

|zi-1 - zi-2|

(11)

1m

Lnl  4n3m |zi-1 - zi-2| ||J(wi))||1,

(12)

i=1

1m

Lacc  2mn2 ||U (wi) - Mwi||,

(13)

i=1

and , ,  are tunable hyperparameters. Here Lrecon is the mse reconstruction error, Lpred is the mse prediction error, and both Lnl and Lacc are measures of the complexity of U . Lnl is a measure of the nonlinearity of the mapping U , since its Jacobian J will be constant if the mapping is linear. Note that Lnl = 0 implies that Lcurv = 0, since if J is constant, then µ = 0 and the curvature vanishes. Physically, Lnl = 0 implies that the dynamics is described by coupled linear difference equations, which can be modeled by coupled linear differential equations and encompass behavior
such as helical motion in magnetic fields, sinusoidal motion in harmonic oscillator potentials and
parabolic motion under gravity. Lacc is a measure of the predicted acceleration, since there is no acceleration if the mapping is U (w) = Mw, where

M  ( -I 2I ) ,

(14)

and I is the n × n identity matrix. For example, xi = 2xi-1 - xi-2 gives uniform 1D

motion. An alternative implementation not requiring Jacobian gradient evaluation would be

Lnl



1 4n3 m

m i=1

||J(wi+1)

-

J(wi)||22,

and

an

alternative

acceleration

penalty

would

be

Lacc



1 n

|U

(0))|2

+

1 2mn2

m i=1

||M

-

J(wi))||22.

3 Results

3.1 Latent space learning
We first tested our algorithm for four physical systems obeying linear differential equations, corresponding to motion with no forces, in a gravitational field, in a magnetic field and in a 2D harmonic oscillator potential (see Figure 4).

No force

Gravity

Magnetic field

2D harmonic oscillator

Quartic oscillator

Figure 4: Original (top) and discovered (bottom) latent spaces For each type of motion, we generated between 100 and 150 trajectories, with around 30 video frames each, giving a total of 3000-5000 images per data set, as can be seen in Figure 4 (top). After
5

simulating the trajectories and generating 1000 × 1000 pixel image of each video frame (Figure 1 for an example), we downsampled resolution of the images to 64 × 64 pixels before passing them to our neural network. The encoder networks consist of five convolutional ReLU layers with kernel-size 4 and padding 1, four with stride 1 followed by one with stride 1, followed by a fully connected linear layer. The number of channels goes from 3 for the input image to 32, 32, 64, 64 and 256 for the convolutional layers. The decoder network is a mirror image of the encoder, but with the convolution layers replaced with a deconvolution layers. The evolution operator has three fully connected 32-neuron hidden layers with softplus activation function and a linear n-neuron output layer. We implemented these networks using PyTorch using a batch size of 256 and the Adam optimizer. We set  = 0 and  =  = 10-3 and trained for 4,000 epochs with a a learning rate of 10-3, multiplying  and  by 10 after every 1000 epochs. We then trained for 3, 000 additional epochs while dividing the learning rate by 10 every 1,000 epochs.
Although our algorithm successfully learned useful 2D latent spaces (Figure 4, bottom) and predicted images with 2% r.m.s. relative error that were visually nearly indistinguishable from the truth, this required overcoming two separate obstacles. We initially lacked the factor |zi-1 - zi-2| in equation (11), so by the Alexander principle, the neural network learned to drive the prediction loss Lpred toward zero by collapsing the latent space to minuscule size. The |zi-1 - zi-2|-factor solves this problem by making the prediction loss invariant under latent space rescaling.

Quartic oscillator

Magnetic field Gravitatio2naDl fihealdrmonic oscillator

Eigenvalue

No forces

1

2

3

4

5

Principal component

Figure 5: The topological problems (middle) that prevented directly learning a 2-dimensional latent space (left) can be understood via knot theory and eliminated by instead discovering the two main principal components (right) in a learned 5-dimensional latent space.

3.2 Knot theory to the rescue

The second obstacle is topological. If you drop a crumpled-up towel (a 2D surface in 3D space) on the floor, it will not land perfectly flat, but with various folds. Analogously, the space of all possible rocket images forms a highly curved surface in the N -dimensional space of images, so when a randomly initialized neural network first learns to map it into a 2D latent space, there will be numerous folds as seen in Figure 5: some pairs of trajectories which in this example are straight lines (left panel) are seen to cross in a cat-like pattern in the latent space (middle panel) even though they should not cross. During training, the network tries to reduce prediction and complexity loss by gradually distorting this learned latent space to give trajectories with the simplest possible shapes (straight lines in this case), but gets stuck and fails to unfold the latent space. This is because the reconstruction loss Lrecon effectively causes distinct images to repel each other in the latent space: if two quite different rocket images get mapped to essentially the same latent-space point, then the decoder will epically fail for at least one. Unfolding would require temporarily moving one trajectory across another, thus greatly increasing the loss. This is analogous to topological defects in physics that cannot be removed because of an insurmountable energy barrier.

Fortunately, knot theory comes to the rescue: a famous theorem states that there are no d-dimensional

knots

in

an

n-dimensional

space

if

n

>

3 2

(1

+

d)

[74].

For

example,

you

cannot

tie

your

shoelaces

(d = 1) if you live in n = 4 dimensions. Our topological pregression problem corresponds to

the inability of the neural network to untie a d-dimensional knot in n dimensions, where d is the

dimensionality of the image submanifold of RN (d = 2 for our examples). We therefore implemented

the following solution, which worked well for all our examples: First run the pregression algorithm

with a latent space of dimension n

>

3 2

(1

+

d)

and

then

extract

an

n-dimensional

latent

space

6

using principal component analysis. This corresponds to incentivizing the above-mentioned towel to flatten out while still in the air and then rotating it to be parallel to the floor before landing. Figure 5 (right) shows two principal components much larger than the rest, revealing that all rocket images get mapped roughly into a 2D plane (Figure 4) in a 5D latent space.
3.3 Nonlinear dynamics and the accuracy-simplicity tradeoff
Increasing the two parameters  and  in equation (9) penalizes complexity (Lnl and Lacc) more relative to inaccuracy (Lrecon and Lpred). For our quartic oscillator example (Figure 1), achieving Lnl = 0 is impossible and undesirable, since the correct dynamics is nonlinear with J = 0, so we wish to find the optimal tradeoff between simplicity and accuracy. We did this by training as above for 7,000 epochs but setting  = 0, then keeping  =  and further training 14 networks in parallel for a roughly geometric series of -values from 0.01 to 200. These 14 networks were trained for 3,000 epochs with learning rate starting at 10-3 and dropping tenfold every 1,000 epochs.
Since, as mentioned above, there is a broad class of equally accurate solutions related by a latent space reparametrization z  f (z), we expect that increasing  from zero to small values should discover the simplest solution in this class without decreasing prediction or reconstruction accuracy. This is the solution we want, in the spirit of Einstein's famous dictum "everything should be made as simple as possible, but not simpler". Further increasing  should simplify the solution even more, but now at the cost of leaving this equivalence class, reducing accuracy. Our numerical experiment confirmed this expectation: we could increase regularization to  = 50 (the choice shown in Figure 1) without significant accuracy loss, after which the inacuraccy started rising abruptly.
3.4 Image warping and noise
As mentioned in Section 2.2, the fact that our algorithm rewards simplicity in the evolution operator U rather than the encoder/decoder pair should enable it to to discover the simplest possible latent space even if the space of image (x, y)-coordinates is severely distorted. To test this, we replaced each image with color c[x, y] (defined over the unit square) by a warped image
c [x, y]  c[g(x) + x(1 - x)y, g(y) + y(1 - y)x], where g(u)  u(11 - 18u + 12u2)/5 (15)
as illustrated in Figure 3 (middle panel), and analyzed the 10,000 warped video frames of the rocket moving in a magnetic field. As expected, the pregression algorithm recovered an non-warped latent space just as in Figure 4, so this extra complexity was entirely absorbed by the decoder/encoder, which successfully learned the warping function of equation (15) and its inverse.
We also tested the robustness of our pregression algorithm to noise in the form of smaller rockets added randomly to each video frame. We used 3 different types of distractor rockets as noise, and added between zero and 10 to each image as illustrated in Figure 3 (right panel). The result was that the pregression algorithm learned to reconstruct the latent space just as before, focusing only on the large rocket, and reconstructing images with the distractor rockets removed. When there was only one distractor rocket present and it too moved in a predictable way, the pregression network learned to predict it too, encoding its position in the 3rd and 4th principal component.
3.5 Automatically discovering equations and inertial frames

Latent y Vertical shift Complexity [bits] Shear angle

1

0

-1

-2

0

2

Latent x

10

0

-10

-10

0

10

Horizontal shift

103
Quartic

Harmonic

Magnetic

102

Gravitational

Gravitational

­180°

0

180°

Rotation

180°
0°
­180° ­0.1

Sh0ear

0.1

Figure 6: Affine transformations to simplify equations of motion

Let us now turn to the task of discovering physical laws that are both accurate and simple. Although the five rocket-motion examples took place in the same image space, there is no reason for the five

7

latent spaces (bottom panels in Figure 4) to coincide. However, as seen in the Figure 6 example
(left panel), they are all related by affine transformations. Here we have mapped all latent space coordinates ri, i = 1, ..., 5, into a single unified latent space r = Airi + ai by introducing five 2 × 2 matrices Ai and 2D translation vectors ai to match up corresponding rocket positions. Specifically, we without loss of generality take the first (harmonic oscillator) latent space to the be unified one, so r1 = r, A1 = I, a1 = 0, and solve for the other Ai and ai by minimizing the total mismatch

5

M

(|Airi + ai - r1|) + (|A-i 1(r1 - ai) - ri|) ,

(16)

i=2

where the average is over all our rocket images mapped through the the five encoders. If the

loss function penalizing mismatch distance were (r) = r2, equation (16) would simply be a

2-minimization determining Ai and ai via linear regression, except that we have also penalized

inaccuracy in the inverse mapping (second term) to avoid biasing Ai low. To increase robustness

toward outliers, we instead followed the prescription of [24] by choosing

(r)



1 2

log2

1 + (r/ )2

and minimizing M with gradient descent, using an annealing schedule = 101, 100, ..., 10-10.

Next, we estimated the velocity r and acceleration ¨r at each data point by cubic spline fitting to each trajectory r(t) in the unified latent space, and discovered candidate differential equations of the form ¨r = f (r, r) using the publicly available AI Feynman symbolic regression package [21, 75]. To eliminate dependence on the cubic spline approximation, we then recomputed the accuracy of each candidate formula f by using it to predict each data point from its two predecessors using the boundary-value ODE solver scipy.integrate.solve_bvp [76], selecting the most accurate formula for each of our five examples.

Applying an affine transformation r  Ar + a to both the data and these equations of course leaves
the prediction accuracy unchanged, so we now exploit this to further reduce the total information-
theoretic complexity of our equations, defined as in [24]. Figure 6 (2nd panel) shows a clear optimum for the shift vector a, corresponding to eliminating additive constants in the harmonic and quartic oscillator equations; for example, x¨ = -x is simpler than x¨ = 1.7724 - x. Figure 6 (3rd panel) shows multiple minima when A is a rotation matrix, corresponding to parameters vanishing: the gravitational example likes 45 rotation because this makes the new horizontal acceleration vanish, but the other examples outvote it in favor of 0 to avoid xy cross-terms.

Only three degrees of freedom now remain in our matrix A: shear (expanding along some axis and shrinking by the inverse factor along the perpedicular axis) and an overall scaling. We apply the vectorSnap algorithm of [21, 75] to discover rational ratios between parameters and then select the shear that maximizes total accuracy (Figure 6, right panel). Finally, we apply the scaling that minimizes total complexity, resulting in these discovered laws of motion:

x¨

0

11

=

,-

,

y

1 ,-

4x

, -7.3 × 10-6(x2 + y2)

x

,

(17)

y¨

0

1 3 -x

9y

y

for the force-free, gravitational, magnetic, 2D oscillator and quartic oscillator examples, respectively.

These are in fact exactly the laws of motion we put into our simulation (up to some noise in the quartic term prefactor), but reexpressed in a five times smaller latent space than the one we used to further simplify our formulas (giving a gravitation acceleration of 1 instead of the 5).

4 Summary
We have presented a method for unsupervised learning of equations of motion for objects in raw and optionally distorted unlabeled video. This automatic un-distortion may be helpful for modeling realworld video afflicted by stereoscopic projection, lens artifacts, varying lighting conditions, etc., and also for learning degrees of freedom such as 3D coordinates and rotation angles. The above-mentioned intuition provided by knot theory may also help improve autoencoders more generally.
We deal with latent space reparametrization invariance by quantifying and minimizing the geometric and symbolic complexity of the dynamics. Although different systems were simplest in different coordinate systems, minimizing total complexity for all of them recovered a standard isotropic inertial frame. An interesting topic for future work would be to explore whether our brains' representations of physical systems are similarly optimized to make prediction as simple as possible.

8

Acknowledgments and Disclosure of Funding
The authors with to thank Zhiyu Dong, Jiahai Feng, Bhairav Mehta, Andrew Tan and Tailin Wu for helpful comments, and the Center for Brains, Minds, and Machines (CBMM) for hospitality.
Funding: This work was supported by The Casey and Family Foundation, the Ethics and Governance of AI Fund, the Foundational Questions Institute, the Rothberg Family Fund for Cognitive Science and the Templeton World Charity Foundation, Inc.
Competing interests: The authors declare that they have no competing interests.
Data and materials availability: Data and code will be publicly released when this paper is accepted for publication.
References
[1] Alexandre Koyré. The Astronomical Revolution: Copernicus-Kepler-Borelli. Routledge, 2013.
[2] James P Crutchfield and Bruce S McNamara. Equation of motion from a data series. Complex systems, 1(417-452):121, 1987.
[3] Saso Dzeroski and Ljupco Todorovski. Discovering dynamics: from inductive logic programming to machine discovery. Journal of Intelligent Information Systems, 4(1):89­108, 1995.
[4] Elizabeth Bradley, Matthew Easley, and Reinhard Stolle. Reasoning about nonlinear system identification. Artificial Intelligence, 133(1-2):139­188, 2001.
[5] Pat Langley, Dileep George, Stephen D Bay, and Kazumi Saito. Robust induction of process models from time-series data. In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pages 432­439, 2003.
[6] Michael Schmidt and Hod Lipson. Distilling free-form natural laws from experimental data. science, 324(5923):81­85, 2009.
[7] Randall K McRee. Symbolic regression using nearest neighbor indexing. In Proceedings of the 12th annual conference companion on Genetic and evolutionary computation, pages 1983­1990. ACM, 2010.
[8] Dominic P Searson, David E Leahy, and Mark J Willis. Gptips: an open source genetic programming toolbox for multigene symbolic regression. In Proceedings of the International multiconference of engineers and computer scientists, volume 1, pages 77­80. IMECS Hong Kong, 2010.
[9] Renáta Dubcáková. Eureqa: software review. Genetic programming and evolvable machines, 12(2):173­178, 2011.
[10] Sean Stijven, Wouter Minnebo, and Katya Vladislavleva. Separating the wheat from the chaff: on feature selection and feature importance in regression random forests and symbolic regression. In Proceedings of the 13th annual conference companion on Genetic and evolutionary computation, pages 623­630. ACM, 2011.
[11] Michael D Schmidt, Ravishankar R Vallabhajosyula, Jerry W Jenkins, Jonathan E Hood, Abhishek S Soni, John P Wikswo, and Hod Lipson. Automated refinement and inference of analytical models for metabolic networks. Physical biology, 8(5):055011, 2011.
[12] Christopher Hillar and Friedrich Sommer. Comment on the article" distilling free-form natural laws from experimental data". arXiv preprint arXiv:1210.7273, 2012.
[13] Bryan C Daniels and Ilya Nemenman. Automated adaptive inference of phenomenological dynamical models. Nature communications, 6:8133, 2015.
[14] Pat Langley and Adam Arvay. Heuristic induction of rate-based process models. In Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.
[15] Ignacio Arnaldo, Una-May O'Reilly, and Kalyan Veeramachaneni. Building predictive models via feature synthesis. In Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation, pages 983­990, 2015.
9

[16] Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the National Academy of Sciences, 113(15):3932­3937, 2016.
[17] Matthew Guzdial, Boyang Li, and Mark O Riedl. Game engine learning from video. In IJCAI, pages 3707­3713, 2017.
[18] Markus Quade, Markus Abel, J Nathan Kutz, and Steven L Brunton. Sparse identification of nonlinear dynamics for rapid model recovery. Chaos: An Interdisciplinary Journal of Nonlinear Science, 28(6):063116, 2018.
[19] Maciej Koch-Janusz and Zohar Ringel. Mutual information, neural networks and the renormalization group. Nature Physics, 14(6):578, 2018.
[20] Weiwei Kong, Christopher Liaw, Aranyak Mehta, and D Sivakumar. A new dog learns old tricks: Rl finds classic optimization algorithms. ICLR, 2018.
[21] Silviu-Marian Udrescu and Max Tegmark. Ai feynman: A physics-inspired method for symbolic regression. Science Advances, 6(16):eaay2631, 2020.
[22] Jiechun Liang and Xi Zhu. Phillips-inspired machine learning for band gap and exciton binding energy prediction. The journal of physical chemistry letters, 10(18):5640­5646, 2019.
[23] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436­444, 2015.
[24] Tailin Wu and Max Tegmark. Toward an artificial intelligence physicist for unsupervised learning. Physical Review E, 100(3):033311, 2019.
[25] Raban Iten, Tony Metger, Henrik Wilming, Lídia Del Rio, and Renato Renner. Discovering physical concepts with neural networks. arXiv preprint arXiv:1807.10300, 2018.
[26] MarcAurelio Ranzato, Arthur Szlam, Joan Bruna, Michael Mathieu, Ronan Collobert, and Sumit Chopra. Video (language) modeling: a baseline for generative models of natural videos. arXiv preprint arXiv:1412.6604, 2014.
[27] Vincent Michalski, Roland Memisevic, and Kishore Konda. Modeling deep temporal dependencies with recurrent grammar cells"". In Advances in neural information processing systems, pages 1925­1933, 2014.
[28] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. Unsupervised learning of video representations using lstms. In International conference on machine learning, pages 843­852, 2015.
[29] Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard L Lewis, and Satinder Singh. Actionconditional video prediction using deep networks in atari games. In Advances in neural information processing systems, pages 2863­2871, 2015.
[30] Chelsea Finn, Ian Goodfellow, and Sergey Levine. Unsupervised learning for physical interaction through video prediction. In Advances in neural information processing systems, pages 64­72, 2016.
[31] William Lotter, Gabriel Kreiman, and David Cox. Deep predictive coding networks for video prediction and unsupervised learning. arXiv preprint arXiv:1605.08104, 2016.
[32] Francesco Cricri, Xingyang Ni, Mikko Honkala, Emre Aksu, and Moncef Gabbouj. Video ladder networks. arXiv preprint arXiv:1612.01756, 2016.
[33] Nal Kalchbrenner, Aäron van den Oord, Karen Simonyan, Ivo Danihelka, Oriol Vinyals, Alex Graves, and Koray Kavukcuoglu. Video pixel networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1771­1779. JMLR. org, 2017.
[34] Xiaodan Liang, Lisa Lee, Wei Dai, and Eric P Xing. Dual motion gan for future-flow embedded video prediction. In Proceedings of the IEEE International Conference on Computer Vision, pages 1744­1752, 2017.
[35] Emily L Denton et al. Unsupervised learning of disentangled representations from video. In Advances in neural information processing systems, pages 4414­4423, 2017.
[36] Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. Decomposing motion and content for natural video sequence prediction. arXiv preprint arXiv:1706.08033, 2017.
10

[37] Vedran Vukotic´, Silvia-Laura Pintea, Christian Raymond, Guillaume Gravier, and Jan C Van Gemert. One-step time-dependent future video frame prediction with a convolutional encoder-decoder neural network. In International Conference on Image Analysis and Processing, pages 140­151. Springer, 2017.
[38] Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H Campbell, and Sergey Levine. Stochastic variational video prediction. arXiv preprint arXiv:1710.11252, 2017.
[39] Marc Oliu, Javier Selva, and Sergio Escalera. Folded recurrent neural networks for future video prediction. In Proceedings of the European Conference on Computer Vision (ECCV), pages 716­731, 2018.
[40] Zhipeng Liu, Xiujuan Chai, and Xilin Chen. Deep memory and prediction neural network for video prediction. Neurocomputing, 331:235­241, 2019.
[41] Juan Carrasquilla and Roger G Melko. Machine learning phases of matter. Nature Physics, 13(5):431, 2017.
[42] Evert PL Van Nieuwenburg, Ye-Hua Liu, and Sebastian D Huber. Learning phase transitions by confusion. Nature Physics, 13(5):435, 2017.
[43] Evert van Nieuwenburg, Eyal Bairey, and Gil Refael. Learning phase transitions from dynamics. Physical Review B, 98(6):060301, 2018.
[44] Giacomo Torlai and Roger G Melko. Learning thermodynamics with boltzmann machines. Physical Review B, 94(16):165134, 2016.
[45] Tomi Ohtsuki and Tomoki Ohtsuki. Deep learning the quantum phase transitions in random electron systems: Applications to three dimensions. Journal of the Physical Society of Japan, 86(4):044708, 2017.
[46] Vedran Dunjko and Hans J Briegel. Machine learning & artificial intelligence in the quantum domain: a review of recent progress. Reports on Progress in Physics, 81(7):074001, 2018.
[47] Ilker Yildirim, Kevin A Smith, Mario Belledonne, Jiajun Wu, and Joshua B Tenenbaum. Neurocomputational modeling of human physical scene understanding. In 2nd Conference on Cognitive Computational Neuroscience, 2018.
[48] David Zheng, Vinson Luo, Jiajun Wu, and Joshua B Tenenbaum. Unsupervised learning of latent physical properties using perception-prediction networks. arXiv preprint arXiv:1807.09244, 2018.
[49] Michael B Chang, Tomer Ullman, Antonio Torralba, and Joshua B Tenenbaum. A compositional object-based approach to learning physical dynamics. arXiv preprint arXiv:1612.00341, 2016.
[50] Zhang Zhang, Yi Zhao, Jing Liu, Shuo Wang, Ruyi Tao, Ruyue Xin, and Jiang Zhang. A general deep learning framework for network reconstruction and dynamics learning. Applied Network Science, 4(1):1­17, 2019.
[51] Stuart Russell, Daniel Dewey, and Max Tegmark. Research priorities for robust and beneficial artificial intelligence. Ai Magazine, 36(4):105­114, 2015.
[52] Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.
[53] Margaret Boden, Joanna Bryson, Darwin Caldwell, Kerstin Dautenhahn, Lilian Edwards, Sarah Kember, Paul Newman, Vivienne Parry, Geoff Pegman, Tom Rodden, et al. Principles of robotics: regulating robots in the real world. Connection Science, 29(2):124­129, 2017.
[54] Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.
[55] Kiran S Bhat, Steven M Seitz, Jovan Popovic´, and Pradeep K Khosla. Computing the physical parameters of rigid-body motion from video. In European Conference on Computer Vision, pages 551­565. Springer, 2002.
[56] Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, and Ken Perlin. Accelerating eulerian fluid simulation with convolutional networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 3424­3433. JMLR. org, 2017.
11

[57] Peter Y Lu, Samuel Kim, and Marin Soljacic´. Extracting interpretable physical parameters from spatiotemporal systems using unsupervised learning. arXiv preprint arXiv:1907.06011, 2019.
[58] Jiajun Wu, Joseph J Lim, Hongyi Zhang, Joshua B Tenenbaum, and William T Freeman. Physics 101: Learning physical object properties from unlabeled videos. In BMVC, volume 2, page 7, 2016.
[59] Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. In Advances in neural information processing systems, pages 4967­4976, 2017.
[60] Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex Sergeev, and Jason Yosinski. An intriguing failing of convolutional neural networks and the coordconv solution. In Advances in Neural Information Processing Systems, pages 9605­9616, 2018.
[61] Jessica B Hamrick, Kelsey R Allen, Victor Bapst, Tina Zhu, Kevin R McKee, Joshua B Tenenbaum, and Peter W Battaglia. Relational inductive bias for physical construction in humans and machines. arXiv preprint arXiv:1806.01203, 2018.
[62] Nicholas Watters, Daniel Zoran, Theophane Weber, Peter Battaglia, Razvan Pascanu, and Andrea Tacchetti. Visual interaction networks: Learning a physics simulator from video. In Advances in neural information processing systems, pages 4539­4547, 2017.
[63] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.
[64] Samuel Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian neural networks. In Advances in Neural Information Processing Systems, pages 15353­15363, 2019.
[65] Hervé Bourlard and Yves Kamp. Auto-association by multilayer perceptrons and singular value decomposition. Biological cybernetics, 59(4-5):291­294, 1988.
[66] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541­551, 1989.
[67] Geoffrey E Hinton and Richard S Zemel. Autoencoders, minimum description length and helmholtz free energy. In Advances in neural information processing systems, pages 3­10, 1994.
[68] Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks. science, 313(5786):504­507, 2006.
[69] Yoshua Bengio, Aaron C Courville, and Pascal Vincent. Unsupervised feature learning and deep learning: A review and new perspectives. CoRR, abs/1206.5538, 1:2012, 2012.
[70] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
[71] Yoshua Bengio. Deep learning of representations: Looking forward. In International Conference on Statistical Language and Speech Processing, pages 1­37. Springer, 2013.
[72] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. ICLR, 2(5):6, 2017.
[73] Alessandro Achille and Stefano Soatto. Information dropout: Learning optimal representations through noisy computation. IEEE transactions on pattern analysis and machine intelligence, 40(12):2897­2905, 2018.
[74] EC Zeeman. Unknotting spheres. Annals of Mathematics, pages 350­361, 1960.
[75] Silviu-Marian et al. Udrescu. Ai feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. In Preparation, 2020.
[76] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, Ilhan Polat, Yu Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul
12

van Mulbregt, and SciPy 1. 0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261­272, 2020.
13

