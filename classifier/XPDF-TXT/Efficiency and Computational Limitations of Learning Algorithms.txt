Efficiency and Computational Limitations of Learning Algorithms
A thesis presented by
Vitaly Feldman
to The Division of Engineering and Applied Sciences
in partial fulfillment of the requirements for the degree of
Doctor of Philosophy in the subject of Computer Science
Harvard University Cambridge, Massachusetts
January 2007

c 2007 - Vitaly Feldman All rights reserved.

Thesis advisor
Leslie G. Valiant

Author
Vitaly Feldman

Efficiency and Computational Limitations of Learning Algorithms
Abstract
This thesis presents new positive and negative results concerning the learnability of several well-studied function classes in the Probably Approximately Correct (PAC) model of learning.
Learning Disjunctive Normal Form (DNF) expressions in the PAC model is widely considered to be the main open problem in Computational Learning Theory. We prove that PAC learning of DNF expressions by an algorithm that produces DNF expressions as its hypotheses is NP-hard. We show that the learning problem remains NP-hard even if the learning algorithm can ask membership queries. We also prove that with an additional restriction on the size of hypotheses the learning remains NP-hard even with respect to the uniform distribution. These last two negative results are the first for learning in the PAC model with membership queries that are not based on cryptographic assumptions.
We complement the hardness results above by presenting a new algorithm for learning DNF expressions with respect to the uniform distribution using membership queries. Our algorithm is attribute-efficient, noise-tolerant, and uses membership queries in a nonadaptive way. In terms of running time, it substantially improves on the best previously known algorithm of Bshouty et al.
Learning of parities with random noise with respect to the uniform distribution is a famous open problem in learning theory and is also equivalent to a major open problem in coding theory. We show that an efficient algorithm for this problem would imply efficient algorithms for several other key learning problems with respect to the uniform distribution. In particular, we show that agnostic learning of parities (also referred to as learning with adversarial noise) reduces to learning parities with random classification noise. Together with the parity learning algorithm of Blum et al., this gives the first non-trivial algorithm for agnostic learning of parities. This reduction also implies that learning of DNF expressions reduces to learning noisy parities of just logarithmic number of variables.
A monomial is a conjunction of (possibly negated) Boolean variables and is one of the simplest and most fundamental concepts. We show that even weak agnostic learning of monomials by an algorithm that outputs a monomial is NP-hard, resolving a basic open problem in the model.
The proposed solutions rely heavily on tools from computational complexity and yield solutions to a number of problems outside of learning theory. Our hardness results are based on developing novel reductions from interactive proof systems for NP and known NP-hard approximation problems. Reductions and learning algorithms with respect to the uniform distribution are based on new techniques for manipulating the Fourier Transform of a Boolean function.
iii

Bibliographic Note
Most of the research that appears in this thesis was published elsewhere in some form. Chapter 3 is based on parts of the papers "Learnability and Automizability" and
"Hardness of Approximate Two-level Logic Minimization and PAC Learning with Membership Queries". The paper "Learnability and Automizability" is a joint work with Misha Alekhnovich, Mark Braverman, Adam Klivans, and Toni Pitassi. It appeared in the Proceedings of 45th IEEE Symposium on Foundations of Computer Science, 2004 [ABF+04].
The paper "Hardness of Approximate Two-level Logic Minimization and PAC Learning with Membership Queries" is also the basis of Chapter 4 and appeared in the Proceedings of 38th ACM Symposium on Theory of Computing, 2006 [Fel06a].
Chapter 5 is based on the paper "On Attribute Efficient and Non-adaptive Learning of Parities and DNF Expressions" which appeared in the Proceedings of 18th Annual Conference on Computational Learning Theory, 2005 [Fel05].
Chapter 6 is based on a part of the paper "New Results for Learning Noisy Parities and Halfspaces" which is a joint work with Parikshit Gopalan, Subhash Khot, and Ashok Ponnuswami and appeared in the Proceedings of 47th IEEE Symposium on Foundations of Computer Science, 2006 [FGKP06].
Chapter 7 is based on the paper "Optimal Hardness Results for Maximizing Agreements with Monomials" which appeared in the Proceedings of 21st Annual IEEE Computational Complexity Conference, 2006 [Fel06b].
iv

Contents

1 Introduction

1

1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.1.1 Computational Learning Theory . . . . . . . . . . . . . . . . . . . . 1

1.1.2 The PAC Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.1.3 Learning DNF Expressions . . . . . . . . . . . . . . . . . . . . . . . 4

1.2 Summary of Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . 6

2 Preliminaries

10

2.1 Concepts and Their Representations . . . . . . . . . . . . . . . . . . . . . . 10

2.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

2.2.1 The Basic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

2.2.2 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

2.2.3 Noise Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

2.2.4 Agnostic Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

2.3 Estimating Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . 17

3 Hardness of Proper PAC Learning of DNF Expressions

18

3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

3.1.1 Previous Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.1.2 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

3.1.3 Our Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

3.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

3.3 Hardness of Learning DNF and Intersections of Halfspaces . . . . . . . . . . 22

3.3.1 The Reduction of Pitt and Valiant . . . . . . . . . . . . . . . . . . . 22

3.3.2 The Target Function and Distribution . . . . . . . . . . . . . . . . . 24

3.3.3 The Case of Small Chromatic Number . . . . . . . . . . . . . . . . . 24

3.3.4 The Case of Large Chromatic Number . . . . . . . . . . . . . . . . . 25

3.4 Intersections of Two Halfspaces . . . . . . . . . . . . . . . . . . . . . . . . . 29

v

CONTENTS

4 Hardness of Approximate DNF Minimization and Learning

33

4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

4.1.1 Relation to Other Work . . . . . . . . . . . . . . . . . . . . . . . . . 35

4.1.2 Outline and Organization . . . . . . . . . . . . . . . . . . . . . . . . 36

4.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

4.3 Hypercube Reductions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

4.3.1 From PHC-COVER to PTT-MinDNF . . . . . . . . . . . . . . . . . 38

4.3.2 From PTT-MinDNF to TT-MinDNF . . . . . . . . . . . . . . . . . . 39

4.3.3 From TT-MinDNF to HC-COVER . . . . . . . . . . . . . . . . . . . 41

4.4 Hardness of Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.4.1 Reduction from Hypergraph Vertex Cover to PHC-COVER . . . . . 43

4.4.2 Reducing from Multi-prover Proof Systems . . . . . . . . . . . . . . 45

4.5 Hardness of Proper PAC+MQ Learning over the Uniform Distribution . . . 51

5 Attribute-Efficient and Non-adaptive Learning of DNF Expressions and

Parities

53

5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

5.1.1 Previous Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

5.1.2 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

5.1.3 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.2.1 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.2.2 Learning by Non-adaptive Membership Queries . . . . . . . . . . . . 59

5.2.3 Learning by Non-adaptive Membership Queries . . . . . . . . . . . . 60

5.3 Learning of Parities and Binary Linear Codes . . . . . . . . . . . . . . . . . 61

5.3.1 Background on Linear Codes . . . . . . . . . . . . . . . . . . . . . . 61

5.3.2 The Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

5.4 A Fast Randomized Algorithm for ae.naMQ Learning of Parities . . . . . . 66

5.5 Finding Fourier Coefficients and Weak DNF Learning . . . . . . . . . . . . 68

5.6 Learning DNF Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . 72

5.6.1 Weak DNF Learning with Respect to Any Distribution . . . . . . . 72

5.6.2 Background on Boosting a Weak DNF Learner . . . . . . . . . . . . 74

5.6.3 Optimized Boosting . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

5.7 Handling Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

5.7.1 Boosting Weak Parity Learning Algorithm in the Presence of Noise . 82

vi

CONTENTS

6 Learning Parities with Noise

86

6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86

6.1.1 Overview and Previous Work . . . . . . . . . . . . . . . . . . . . . . 87

6.1.2 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

6.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

6.2.1 Learning Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

6.2.2 Fourier Transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

6.3 Reduction To Learning Parities with Random Noise . . . . . . . . . . . . . 92

6.3.1 Finding Heavy Fourier Coefficients . . . . . . . . . . . . . . . . . . . 92

6.4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96

6.4.1 Learning of Parities with Adversarial Noise . . . . . . . . . . . . . . 96

6.4.2 Learning DNF Expressions . . . . . . . . . . . . . . . . . . . . . . . 97

6.4.3 Learning Juntas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98

6.4.4 Learning in the Presence of Random Noise . . . . . . . . . . . . . . 98

7 Hardness of Proper Agnostic Learning of Monomials

100

7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

7.1.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102

7.2 Preliminaries and Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

7.2.1 The Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104

7.2.2 Agreement with Monomials and Set Covers . . . . . . . . . . . . . . 106

7.3 Hardness of Approximating Mon-MA and Mon-MD . . . . . . . . . . . . . . 108

7.3.1 Feige's Multi-Prover Proof System . . . . . . . . . . . . . . . . . . . 108

7.3.2 Balanced Set Partitions . . . . . . . . . . . . . . . . . . . . . . . . . 109

7.3.3 Creating Balanced Set Partitions . . . . . . . . . . . . . . . . . . . . 111

7.3.4 Main Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

7.4 Results and Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

8 Conclusions and Further Directions

122

vii

Acknowledgements
I am deeply grateful to Leslie Valiant, my advisor, for his endless support and encouragement of my work. I was extremely fortunate to have both his trust in my independent work and his advice whenever I needed it. Les' suggestions and insights are the basis of some of the most important fruits of my research and his own work is always a great source of inspiration.
I thank Nader Bshouty, my advisor during my graduate studies at the Technion. Nader introduced me to research in computational learning theory and was very supportive during my first steps as a researcher. He has also provided me with a concise formula for success in research: "Read papers, write papers! Do nothing else!". I often recall it when failing to implement it.
I thank my collaborators Misha Alekhnovich1, Mark Braverman, Parikshit Gopalan, Subhash Khot, Adam Klivans, Toni Pitassi, and Ashok Ponnuswami. Their brilliant ideas have greatly contributed to results presented in Chapters 3 and 6. I would also like to thank many colleagues for illuminating discussions and valuable comments on my work. I have especially benefited from the friendship and advice of Rocco Servedio.
Harvard's Division of Engineering and Applied Sciences has been a stimulating and enjoyable place to engage in graduate studies. I am grateful to the wonderful teachers I had during these years: Silvio Micali, Michael Mitzenmacher, Avi Pfeffer, Michael Rabin, Peter Shor, Madhu Sudan, and especially Salil Vadhan for sharing their outstanding knowledge and enthusiasm for science. I would like to thank Avi Pfeffer, Michael Rabin, and Salil Vadhan for also serving on my thesis committee. I thank fellow graduate students Adi Akavia, Yan-Cheng Chang, Kai-Min Chung, Eleni Drinea, Kobi Gal, Alex Healy, Shaili Jain, Minh Huyen-Nguyen, Adam Kirsch, Loizos Michael, Shien Jin Ong, and Emanuele Viola for their friendship and numerous interesting discussions. My special thanks to Alex and Shaili for the careful proofreading and insightful comments on my manuscripts.
I would like to thank my friends both local and distant (and, fortunately, too numerous to list here). Their friendship, unique personalities, and diverse talents have made these years an extraordinary and memorable experience. In particular, my time here would not have been the same without the friendship of my long-time roommates Matthias R¨oder and Sasha Tokovinine with whom I shared lots of great times and countless conversations on the "meaning of it all".
Finally, my biggest thanks are reserved for my close family ­ my mother Tatiana, my father Georgiy, my sister Polina, my brother Vladik, and my beloved girlfriend Polinka for their boundless love, care, and understanding. I owe them much more than I could possibly describe. I also feel greatly indebted to Marian Tkach, my high school math teacher, for igniting and nourishing my interest in mathematics as well as for being a close friend and in many ways a personal example for the last 15 years.
1Sorrowfully, my thanks are posthumous. Misha died in a tragic accident on August 5, 2006.
viii

This thesis is dedicated to my parents and to Marian Tkach ix

Chapter 1
Introduction
1.1 Background
1.1.1 Computational Learning Theory
Learning, or the ability to derive useful functionality through experience, is a fundamental computational phenomenon. It is widely believed to be the basis of most human cognitive abilities and is exhibited by a variety of other living organisms. The study of natural learning phenomena and the realization of learning behavior by machines in a wide range of real-life problems are among the most important modern scientific pursuits.
Computational learning theory is the study of learning from the viewpoint of the theory of computation. Its goal is to understand the capabilities and inherent limitations of learning algorithms that can be performed by computers as well as to shed light on natural learning phenomena. The basis of this study and one of its important products are formal mathematical models of learning. The great diversity and complexity of real-life learning phenomena make defining realistic and general learning models a very challenging task.
A major step toward more realistic learning models was made by Leslie Valiant who introduced the Probably Approximately Correct (PAC) learning model [Val84]. Unlike previous models, such as identification in the limit [Gol78] and statistical learning theory, the PAC model was defined to study efficient (and hence more realistic) learning algorithms. Valiant's elegant and general paradigm of learning from examples was quickly embraced by numerous researchers within both the theory of computer science and machine learning. Their research has lead to a rich theory with connections to many other areas of computer science such as computational complexity theory, statistical pattern recognition, cryptography, and information theory. This theory provides a sound basis for applied machine learning research and has yielded important algorithmic techniques used in practical learning systems.
1

1.1 Background
1.1.2 The PAC Model
In the PAC model the functionality that is being learned is modeled as a binary classifier function (or a concept) over some domain, referred to as the target concept. For example, this concept could be "Is it going to rain tomorrow?" defined on the domain of all the possible measurements of temperature, humidity, wind speed, etc. , taken today. A learning algorithm is then given access to points in the domain randomly chosen from some unknown distribution together with values of the target concept on these points, i.e. examples. In the above scenario this would correspond to having historical information on both the measurements and the rain. The goal of the learning algorithm is to predict with "high" accuracy the target concept on points it has not previously seen (the accuracy is measured with respect to the same unknown distribution). Note that if we do not make any assumptions on the target concept then its values on the unseen points are not restricted in any way and therefore any non-trivial prediction would be impossible. A general way to model such assumptions suggested by Valiant is to restrict the target concept to belong to a certain concept class which is simply a set of functions over the domain. A concept class is considered learnable if there exists an algorithm that can successfully learn every concept from the concept class. In our example one might assume that the points corresponding to positive predictions about the rain form a (multidimensional) ball in the space of all measurements. A learning algorithm for the concept class of all the possible balls could then be used to automatically find the unknown ball with high accuracy.
A major emphasis in Valiant's model is placed on the computational efficiency of the learning algorithms. Specifically, it asks which concept classes can be learned in time polynomial in the description of the problem and the inverse of the desired accuracy (see Section 2.2 for a formal description of the model). Such restrictions are necessary from both practical and theoretical perspectives. From the practical perspective, dealing with large domains and a huge number of candidate functions is only possible by efficient learning algorithms. From the theoretical viewpoint, this restricts the discussion to algorithms that "reveal" the structure of the problem instead of exhaustively searching through all candidate concepts.
The basic PAC model should not be thought of as the universal learning model that applies to any learning scenario (and it was not intended as such [Val84]). Indeed, in most practical settings some of the generality of the model is not required and/or some of the assumptions do not hold [Hau90]. Instead, it provides a general framework for thinking about learning problems that emphasizes the computational problem of finding a "suitable" hypothesis in a large (often exponentially large in the learning parameters) space of candidate hypotheses given examples of the target function. Based on this paradigm,
2

1.1 Background
researchers in learning theory have introduced several variants of the basic PAC model a as well as number of other learning models that reflect a wide variety of practical considerations. For example presence of noise is studied by considering various ways to corrupt the examples available to the learning algorithm [AL88, Hau92, Kea98, KL93, KSS94, Val85]; learning in the online setting (in which the learning algorithm updates its hypothesis after each inconsistency is discovered) is studied in the online mistake-bound model of Angluin [Ang88] and Littlestone [Lit88]; exact identification of the target function via different types of queries is studied in models introduced by Angluin [Ang87, Ang88] (Sections 2.2.2, 2.2.3, and 2.2.4 describe the models relevant to this thesis; we recommend the textbook by Kearns and Vazirani [KV94b] for a detailed treatment of these models). It is important to note that an array of results is known for automatically transforming between learning algorithms in different models and numerous algorithmic ideas and techniques reappear in several of these seemingly unrelated settings (cf. [DHW91, KV94b]). This unusually favorable situation corroborates the universality of the basic insights of Valiant's model and motivates further research into the foundations of computational learning theory.
Besides "passive" learning in which the learner has no influence over the choice of examples, learning theory also studies models that allows the learner to ask questions about the unknown function or perform tests on it. This ability is formalized by allowing the learning algorithm to access a membership query oracle [Val84]. Upon request of the learner, this oracle returns the value of the target concept on any desired element of the domain. A fundamental question in learning theory is when and how can asking questions help to learn. We address this questions in Chapters 3, 4 and 5.
For a specific learning model and an input domain, the main question addressed in learning theory is which "interesting" concept classes over the domain are efficiently learnable. The domain most widely studied is the set of all objects that can be described using a fixed set of binary features (also referred to as variables and attributes), or simply {0, 1}n, where n is the number of features. Many other domains can be naturally reduced to this relatively simple setting. Among the most natural and well-studied concept classes for this domain are (see Section 2.1 for formal definitions of these concept classes):
· monomials, or conjunctions of (possibly negated) variables; · disjunctive normal form, or DNF, expressions (which are ORs of monomials); · linear threshold functions (also called halfspaces); · neural networks, or threshold circuits; · decision trees; · k-juntas, or functions that depend on only k variables; · parities, or XORs of subsets of the variables.
3

1.1 Background
1.1.3 Learning DNF Expressions
While in this research we address learnability of several of the above concept classes, the primary focus will be on the learnability of DNF expressions. Therefore, we now briefly and informally survey some of the results relevant to this problem. A more thorough treatment of the relevant previous work is postponed until after the models are defined formally and appears in the introductory section of each chapter.
DNF expressions are a succinct way to represent a variety of concepts and are relatively easily understood by humans [Jac95, Hel01]. They are also commonly used to represent Boolean functions in computer hardware where they are referred to as two-level logic [UVSV06]. The significance of learning these expressions given random examples of the function was already recognized in Valiant's first paper on the PAC model [Val84] and has since been one of the most well-studied problems in learning theory. Despite numerous attempts to find efficient algorithms for learning DNF in the basic PAC model, only DNF expressions with a constant number of monomials (referred to as the terms of a DNF expression) are known to be learnable in polynomial time [Val85]. In fact, even a seemingly much simpler question: "Are (1)-juntas efficiently learnable when the distribution of examples is uniform over {0, 1}n?" is still unresolved (note that -juntas are a subclass of DNF with 2 terms).
The lack of progress on the original question has lead to efforts to resolve its restricted or related versions. The variants of the problem that are often considered involve one or more of the following modifications:
1. bound the number terms; 2. bound the number of variables in each term; 3. bound the number of times a variable can appear in the expression; 4. allow only monotone DNF (i.e. without negations); 5. assume that the distribution of examples is uniform (or product); 6. allow membership queries; 7. allow only proper learning algorithms, or algorithms that output hypotheses in DNF
representation; 8. consider algorithms that run in superpolynomial time (but are more efficient than
the straightforward exhaustive search).
Some of the most important and interesting results obtained for these restrictions are as follows.
4

1.1 Background
(1,2) Both DNF expressions with at most k terms and DNF expressions with at most k variables in each term are efficiently learnable for constant k [Val84].
(4+6) Valiant has showed that monotone DNF expressions are learnable using membership queries [Val84].
(4) Kearns et al. showed a simple reduction implying that in the basic PAC model learning of monotone DNF expressions is equivalent to learning unrestricted DNF expressions [KLPV87b].
(1+7) Pitt and Valiant showed that learning k-term DNF expressions by an algorithm that outputs a k-term DNF expression as its hypothesis is NP-hard for every k  2 [PV88].
(3+5) Hancock proved that DNF formulas in which each variable appears at most k times for a constant k are learnable with respect to the uniform distribution [Han92].
(5+8) Verbeurgt gave an algorithm that learns s-term DNF expressions with respect to the uniform distribution in time nO(log s).
(6) Angluin and Kharitonov have proved that under certain cryptographic assumptions membership queries do not help to learn unrestricted DNF expressions [AK95b].
(5+6) Jackson has showed that unrestricted DNF expressions are efficiently learnable if the underlying distribution of examples is uniform and membership queries are allowed [Jac97]. The running time of his algorithm was significantly improved by Bshouty et al. [BJT04] and Klivans and Servedio [KS03]. Bshouty et al. showed that a similar approach can be used to learn from examples on points given by a random walk on {0, 1}n (instead of membership queries) [BMOS03].
(1+6) Blum and Rudich proved that O(log n)-term DNF expressions are learnable with membership queries [BR95].
(1+4+5) Sakai and Maruoka gave an algorithm that learns O(log n)-term monotone DNF expressions with respect to the uniform distribution (and is also proper) [SM00]. This was improved by Bshouty and Tamon to O(log2 n/ log3 log n)-term DNF and product distributions [BT96] and by Servedio to O(2log1/2 n)-term DNF and product distributions [Ser01].
(8) Bshouty gave an algorithm that learns s-term DNF in time 2O~(n log s) [Bsh96]. This was later improved by Klivans and Servedio to 2O~(n1/3 log s). Alekhnovich et al. gave a proper learning algorithm for s-term DNF running in time 2O~(n log s) [ABF+04].
An overview of DNF learning results in the related exact learning model of Angluin [Ang87, Ang88] can be found in a survey by Hellerstein [Hel01].
5

1.2 Summary of Our Contributions
1.2 Summary of Our Contributions
The results presented in this thesis provide answers to several long-standing open questions regarding the limits of learnability by algorithms that use specific representation (e.g. DNF) for their hypotheses. In particular, algorithms that produce hypotheses in the same representation as the most natural representation of the concept class they learn are called proper. Many theoretical and applied techniques are based on a specific representation of the hypothesis, such as decision trees, linear thresholds, or neural networks. Thus, representation-based hardness results elucidate the limitations of such techniques.
A significant part of this thesis is devoted to learning of DNF expressions and parities when the distribution of examples is uniform over {0, 1}n. We show new algorithms and connections between open problems for learning in this setting. We believe that these results advance the understanding of learnability in this well-studied model.
Some of the results presented in this thesis are for the agnostic learning model of Haussler [Hau92] and Kearns et al. [KSS94]. This model is an extension of the PAC learning model that deals with the situation in which one cannot assume anything on the target function. Learning in this model is notoriously hard, even though few hardness results are actually known. We give a strong hardness result for proper learning of a basic concept class (monomials) in this model and also the first non-trivial algorithm for agnostic learning another basic class (parities).
Below we summarize the main contributions of this thesis (formal definitions and discussion of the relevant concept classes and learning models can be found in Chapter 2).
Hardness of Proper PAC Learning of DNF Expressions (Chapter 3)
Valiant showed that monotone DNF expressions are learnable properly by a PAC algorithm with access to a membership query oracle and asked whether the same is true for unrestricted DNF expressions [Val84]. We answer his question by proving that, unless NP = RP, there is no polynomial-time PAC learning algorithm for DNF expressions where the hypothesis is an OR-of-thresholds. As special cases, we show that neither DNF nor OR-of-thresholds are properly learnable unless NP = RP. Moreover, we show that these results hold even when the learner can make membership queries. While a few hardness results for proper learning are known, all previous results placed significant restrictions on the size of hypotheses and did not allow membership queries.
The proof of this result is based on the inapproximability of the chromatic number of a graph and a delicate reduction from coloring power graphs to learning of DNF formulae by OR-of-thresholds using membership queries.
In addition we prove that it is NP-hard to learn the intersection of  2 halfspaces
6

1.2 Summary of Our Contributions
by the intersection of k halfspaces for any constant k. This improves on the fundamental result of Blum and Rivest who proved that intersections of k halfspaces are not learnable by intersections of k halfspaces for every k  2 [BR92]. This result is based on a generalization of the reduction of Blum and Rivest, and a strong inapproximability result for coloring 2-colorable hypergraphs of Dinur et al. [DRS02].
Hardness of Approximate DNF Minimization and Learning (Chapter 4)
We show that learning of DNF expressions by DNF expressions of a certain, somewhat larger, size is NP-hard even when learning with respect to the uniform distribution and using membership queries. The result is incomparable to that of Chapter 3 since learning often becomes easier when the distribution is uniform but we only rule out a restricted form of proper learning. No hardness results for learning DNF in this model were previously known.
The result is obtained via a new connection to the problem of two-level logic minimization or finding a minimal DNF formula consistent with a given complete truth table (TT-MinDNF). This problem was formulated by Quine in 1952 and has been since one of the key problems in logic design. We prove that TT-MinDNF for a function of n variables is NP-hard to approximate within n for some constant  > 0, establishing the first inapproximability result for the problem.
The proof of the hardness result for TT-MinDNF is based on a specialized reduction from a multi-prover proof system with certain properties. A powerful low-error PCP by Raz and Safra [RS97] is used to obtain a multi-prover proof system with the desired properties, yielding the desired inapproximability result.
Attribute-Efficient and Non-adaptive Learning of DNF Expressions and Parities (Chapter 5)
Some of the most important considerations in the design of practical learning algorithms are attribute efficiency and noise tolerance. Attribute-efficient algorithms are algorithms that can learn from a small number of examples even in the presence of numerous irrelevant features in the data. They are of great importance in a common scenario where the data is scarce or expensive to get while each example has a lot of information that is irrelevant to the learned function. Noise-tolerant algorithms are algorithms that are robust to errors in the labels of examples ­ another common situation in practice.
To contrast the results in Chapter 4, we design the most efficient algorithm for learning DNF expressions with respect to the uniform distribution that uses membership queries. Our algorithm runs in time O~(ns4/ ) and uses O~(s4 · log2 n/ ) MQs, where s is the number
7

1.2 Summary of Our Contributions
of terms in the shortest DNF representation of the target concept. The best previously known algorithm for learning DNF runs in time O~(ns6/ 2) and requires O~(ns4/ 2) examples [BJT04, KS03]. In addition, our algorithm is attribute-efficient, noise-tolerant, and its membership queries (MQs) are non-adaptive, that is, the points at which the algorithm asks MQs do not depend on the target concept. Each of the previously known algorithms had at most one of these properties.
In this chapter we also study attribute-efficient learnability of parity functions with respect to the uniform distribution. We show that attribute-efficient learning of parity functions with respect to the uniform distribution is equivalent to decoding high-rate random linear codes from a low number of errors, a long-standing open problem in coding theory.
Learning Parities with Noise (Chapter 6)
Parity functions are one of most fundamental concept classes in learning theory. In particular, the powerful Fourier transform learning technique is based on representing functions as linear combinations of parities. We address a well-studied problem of learning parities under the uniform distribution with random classification noise, also called the noisy parity problem. We reduce a number of basic problems regarding learning under the uniform distribution to learning of noisy parities, thus establishing the central role of this problem in learning under the uniform distribution.
We show that (under the uniform distribution) agnostic learning of parities reduces to learning parities with random classification noise. Together with the parity learning algorithm of Blum et al. [BKW03], this gives the first non-trivial algorithm for agnostic learning of parities. We also show that (under the uniform distribution) PAC learning of DNF expressions reduces to learning noisy parities of just logarithmic number of variables and PAC learning of k-juntas reduces to learning noisy parities of k variables. These reductions work even in the presence of random classification noise in the original DNF or junta.
Our main reduction can also be stated in terms of coding theory. Specifically, it implies that if there exists an algorithm that can efficiently decode random linear codes from random errors of rate , then there exists an algorithm that can efficiently (list)decode random linear codes from adversarial errors of rate .
Hardness of Proper Agnostic Learning of Monomials (Chapter 7)
A monomial or a conjunction of Boolean variables is one of the simplest and most fundamental concepts. The concept class of monomials is long-known to be learnable when
8

1.2 Summary of Our Contributions

examples given to the learning algorithm are guaranteed to be consistent with a monomial

(as in the PAC model) [Val84, Lit88]. Real data is rarely completely consistent with a sim-

ple concept and therefore this assumption is a limitation of learning algorithms in Valiant's

PAC learning model [Val84]. A general way to address this limitation was suggested by

Haussler [Hau92] and Kearns et al. [KSS94] who introduced the agnostic learning model.

In this model, informally, nothing is known about the process that generated the examples

and the learning algorithm is required to do nearly as well as is possible using hypotheses

from a given class. This corresponds to a common empirical approach when few or no

assumptions are made on the data and a fixed space of hypotheses is searched to find the

"best" approximation of the unknown function.

We show that for any constant finding a monomial that agrees with an unknown

function on 1/2 + fraction of examples is NP-hard even when there exists a monomial

that agrees with the unknown function on 1 - fraction of examples. This implies that

even weak agnostic learning of monomials by an algorithm that outputs a monomial is

NP-hard, resolving one of the basic open problems in the model [Blu98].

The result is obtained by showing that the maximum agreement rate of a monomial

with a given set of examples is NP-hard to approximate within 2- for any constant > 0.

Factor 2 approximation is trivial and therefore this result is optimal. It substantially

improves on previously known results of Ben-David et al. [BDEL03], and Bshouty and

Burroughs

[BB06]

(who

prove

hardness

for

factors

770 767

and

59 58

,

respectively).

Under the assumption that NP  RTIME(npoly log(n)), we also obtain an inapprox-

imability factor of 2log1- n for the symmetric problem of approximating the minimum

disagreement rate. This improves on the log n hardness of approximation factor due to

Kearns et al. [KSS94] and Hoffgen et al. [HvHS95].

To prove these results we design a new probabilistically checkable proof system that

is of independent interest. Previous approaches to this and similar problems used known

inapproximability results and in this sense this is the first direct application of powerful

PCP techniques to learning theory. This approach was recently used by Feldman et al.

[FGKP06] and Guruswami and Raghavendra [GR06] to prove equally strong hardness

results for agnostic learning of halfspaces.

9

Chapter 2
Preliminaries
In this chapter we define the learning models and the classes of functions that are discussed in this thesis. For detailed introduction of the models and great examples of learning algorithms we refer the reader to the textbook by Kearns and Vazirani [KV94b].
We assume the reader is familiar with the basic notions of computational complexity theory. For the background and definitions related to such topics as circuits, randomized computation, NP-completeness and interactive proofs we refer the reader to [Pap94].
2.1 Concepts and Their Representations
Let X be a set which is the domain or the input space of the unknown function to be learned. The domain of the learning problems that we study is {0, 1}n, or the ndimensional Boolean hypercube. In this domain a point is described using n Boolean variables (or, attributes) denoted x1, x2, . . . , xn. The dimension of the domain n is a parameter of our learning problems used for asymptotic analysis of the efficiency of learning. A concept over X is a Boolean function over the domain and a concept class C is a set of concepts over X. The unknown function c  C that a learning algorithm is trying to learn is referred to as the target concept.
In order to discuss algorithms that learn and output functions we need to define how these functions are represented. A representation for a concept class C is a way to describe functions from C that defines a procedure to evaluate a function in C on any input in the domain. For example, we can represent a concept class of all the conjunctions of input variables by the listing the variables in a conjunction. More formally, we define
Definition 2.1.1 A representation class F over X is a pair (L, R) where
· L is a language over some fixed finite alphabet (e.g. {0, 1});
10

2.1 Concepts and Their Representations

· R is an algorithm that for   L, on input (, 1n) returns a Boolean circuit over {0, 1}n.

For the purposes of this work we only consider efficient representations, in other words,

representations for which R is a polynomial-time algorithm. The concept class represented

by F is set of functions over {0, 1}n defined by the circuits in {R(, 1n) |   L} and is

denoted by CF . For a Boolean function f we say that f  F if f  CF and is given by its representation   L. For most of the representations we use, it is straightforward

to construct a language L and the translating function R, and we do not specify them

explicitly.

Associated with each representation is the complexity of describing a Boolean func-

tion using this representation. More formally for a Boolean function c  CF we define F-size(c) to be the length the shortest way to represent c using F, or min{|| |  

L, R(, 1n) = c}.

The representation class that we study most frequently is Disjunctive Normal Form

(DNF) expressions (or formulae). A DNF formula is defined as an OR of ANDs of literals,

where a literal is a possibly negated input variable. We refer to the ANDs of a DNF

formula as its terms. For example, (x1  x¯2  x5)  (x3  x5) is a DNF expression with two terms. The representation class of s-term DNF includes all the DNF expressions with at

most s terms. Note that every Boolean function can be represented as a DNF expression

(possibly of exponential in n size).

A linear threshold function(LTF) or a halfspace is a function f = (

n i=1

ixi



),

where i (for all i) and  are integers (and it is represented by these integers). An AND-

of-thresholds, or intersection of halfspaces is a function g = ki=1hi, for some k, where each

hi is a halfspace. Similarly, an OR-of-thresholds (or a union of halfspaces) is a function

equal to ki=1hi.

In the context of DNF we use the number of terms to measure DNF-size(f ) instead of

the length of description as in the general definition. Similarly, for unions and intersections

of halfspaces we use the number of halfspaces.

Some other simple concept and representation classes that we study are parities, mono-

mials, and juntas. A monomial is a function equal to a conjunction of any subset of literals.

We denote the representation class of monomials by Mon.

A parity function is a function equal to the XOR of some subset of variables, where

XOR is the exclusive OR operation denoted by . For a Boolean vector a  {0, 1}n we

define the parity function a(x) as a(x) = a·x = inaixi. We denote the representation class of parity functions {a | a  {0, 1}n} by PAR and the class of all the parities on at

most k literals by PAR(k).

A k-junta is a function that depends only on k variables. We represent a parity function

11

2.2 PAC Learning
or a monomial by listing the indices of the variables on which it depends. For a junta we also fully describe the function of the k variables (that is, we give its truth table).
A decision tree is a binary tree with labels chosen from x1, . . . , xn on the internal nodes, and labels from {0, 1} on the leaves. Each internal node's left branch is viewed as the 0-branch; the right branch is the 1-branch. For a decision tree T , a vector a  {0, 1}n defines a path in the tree from the root to a specific leaf by choosing ai-branch at each node xi; the value of T at a is defined to be the label of the leaf.
2.2 PAC Learning
In this section we review the basic PAC learning model and a number of related models.
2.2.1 The Basic Model
The Probably Approximately Correct (PAC) model of learning was introduced by Valiant in 1984 and has since become one of the most widely studied learning models [Val84]. In this model the learning algorithm is given access to random examples of the target concept drawn from some distribution D over X, and is supposed to produce, with high probability, a hypothesis h that approximates c (hence the name of the model). More formally, when learning the target concept c with respect to an unknown distribution D the learning algorithm has access to an example oracle EX(c, D). On request of the learning algorithm, the oracle EX(c, D) returns an example x, c(x) where x is chosen randomly with respect to D independently of any previous examples.
Learning in the PAC model in its general form is described by a number of parameters. The first parameter is the representation class F that is learned. This representation class expresses the prior belief of the learning algorithm about the nature of the unknown function. This parameter has two aspects. First, it means that the target concept belongs to CF (the concept class represented by F). Note that in the case of learning DNF expressions (or other universal representation), CF is the set of all the Boolean functions and therefore this is not a meaningful restriction. The second aspect is that the representation is used to define the complexity of the target concept. Specifically, it defines the size of the unknown function in representation F or F-size(c), usually denoted by s. In the PAC model the learning algorithm is allowed to use more resources (such as running time or examples) when it is learning a more complicated hypothesis in terms of F-size. Therefore, when learning DNF expressions the learning algorithm is allowed to use more resources on functions whose minimal DNF representation has more terms.
The second parameter is the representation class of hypotheses H. The learning algorithm is said to learn by H if it outputs a hypothesis h  H. The significance of this
12

2.2 PAC Learning
parameter was identified by Pitt and Valiant who showed that the choice of H can have dramatic impact on the computational complexity of the learning problem [PV88] (Section 3.1.1 has a more detailed description of their result). Algorithms for which H = F are called proper.
The desired accuracy of learning, denoted by , is another parameter given to the learning algorithm. One cannot expect a polynomial time algorithm to predict the target concept exactly since, intuitively, a portion of the input space may have a very low weight under D and therefore the learning algorithm will not see any examples of the target function's behavior on that portion of the space. This implies that the hypothesis will not be correct on some of the points. The accuracy parameter specifies the maximum permissible error of the learning algorithm (relative the same distribution D) and allows the learning algorithm to use more resources to achieve higher accuracy. For  0, we say that function g -approximates function f with respect to distribution D if PrD[f (x) = g(x)]  1 - . Alternatively, one can say that the error of h on f with respect to D is at most .
Finally, the learning algorithm depends on randomly chosen examples and therefore will likely fail altogether if the examples happen to be not representative (such as always being equal to the same point). The confidence parameter  specifies the probability with which the learning algorithm is allowed to fail.
We are now ready to define the model formally.
Definition 2.2.1 We say that an algorithm A learns representation class F by representation class H if for every > 0,  > 0, n, c  CF , and distribution D over X, A(n, , ), given access to EX(c, D), outputs, with probability at least 1 - , a hypothesis h  H that -approximates c. Furthermore, the learning algorithm is efficient if it runs in time polynomial in n, s = F-size(c), 1/ and 1/.
We are primarily interested in efficient algorithms and will often use "learn" to mean "learn efficiently". When we do not specify H explicitly it is meant to be unrestricted. Such learning is referred to as representation-independent (or PAC prediction in some other works). Effectively this means that A can output any Boolean circuit.
Throughout this work we will usually fix  = 1/2. In order to obtain an algorithm with success probability 1 - , one can always use a standard confidence boosting procedure (cf. [KV94b]). The boosting procedure consists of repeating the original algorithm k = log (1/) + 1 times with slightly increased accuracy (e.g. /2), each time on new examples and independent coin flips. The hypotheses obtained from these runs are then tested on an independent sample of size O( -1 log (1/)) and the best one is chosen. This procedure increases the running time and the number of examples used by the algorithm by a factor
13

2.2 PAC Learning
O(log (1/)).
2.2.2 Extensions
A number of variants of the PAC learning model have been defined to reflect a variety of considerations. Here we briefly review the ones that are relevant to this work.
In distribution-specific PAC learning we assume that the distribution is fixed and known to the learning algorithm. One of the most common distributions that we will consider is the uniform distribution U over the whole hypercube. We will denote the model of learning with respect to a specific distribution D by PACD. To emphasize the difference between these two settings, the usual PAC learning model is often referred to as distributionindependent or distribution-free.
Valiant has also introduced an augmented version of his model in which a learning algorithm has access to a membership query oracle for the target concept [Val84]. A membership query(MQ) oracle MEM(c) is the oracle that, given any point x  {0, 1}n, returns the value c(x). Examples of real-world learning tasks that are modeled by MQs include learning a certain skill from a human expert and learning the influence of genes on a certain condition by conducting biological tests on synthesized DNA sequences.
Achieving any desired accuracy is a strong requirement on a learning algorithm, sometimes referred to as strong learning. A relaxation of this requirement is the notion of weak learning introduced by Kearns and Valiant [KV94a]. A weak learning algorithm is a learning algorithm that can produce a hypothesis whose error on the target concept is noticeably less than 1/2 (either 0 or 1 constant hypothesis predicts the target on 1/2 of the points). More precisely, a weak learning algorithm produces a hypothesis h such that PrD[c(x) = h(x)]  1/2 - 1/p(n, s) for some fixed polynomial p (the rest of Definition 2.2.1 is unchanged).
In a celebrated result Schapire showed that weak PAC learning in a distributionindependent setting implies strong PAC learning [Sch90]. His proof is based on using the weak learning algorithm on different distributions to construct a strong learning algorithm. This general technique, referred to as boosting, has become a subject of intensive theoretical and practical research. We use a boosting algorithm of Freund in Chapter 5 [Fre92].
In numerous real-life situations examples are an "expensive" resource. It is therefore important to consider the number of examples used by an algorithm to learn, referred to as its sample complexity. An algorithm A is said to be attribute-efficient if the number of examples (both random and received from a MQ oracle) it uses is polynomial in the size of the representation of the target concept and 1/ . Attribute-efficient learning is important when the number of variables on which the target concept depends is small in comparison with the total number of variables n. We say that a variable xi is relevant
14

2.2 PAC Learning

for a function f if there exists y  {0, 1}n such that f (y) = f (yi), where yi is y with the bit in i-th position flipped. The number of relevant variables of the target concept is denoted by r. Attribute-efficiency does not allow the number of examples to depend polynomially on n. Instead the number of examples used can depend polynomially on r and log n since for most representations (including the ones considered in this work) the size of the representation of f is lower bounded by both log n and r.
Note that these extensions are generally independent of each other and various combinations are often considered in the learning literature. For example, in Section 5.5 we will present an attribute-efficient weak PACU learning algorithm that uses membership queries.

2.2.3 Noise Models

Learning in the basic PAC model and its extensions defined in the previous section relies

on the assumption that the examples that are given to the learning algorithm are always

labeled by the correct value of the target concept c(x). Several ways of dealing with the

situation when the labels are noisy have been suggested and widely-studied. The first one

that we consider is the simplest type of noise called random classification noise. It was

introduced by Angluin and Laird [AL88]. In this model for any   1/2, called the noise

rate, the regular example oracle EX(c, D) is replaced with the noisy oracle EX(c, D). On

each call, EX(c, D), draws x according to D, and returns x, c(x) with probability 

and x, ¬c(x) with probability 1 - . When  approaches 1/2, the label of the corrupted

example approaches the result of a random coin flip, and therefore the running time of

algorithms

in

this

model

is

allowed

to

polynomially

depend

on

1 1-2

.

This model of noise is not suitable for corrupting labels returned by MEM(c) since a

learning algorithm can, with high probability, find the correct label at point x by asking

for

the

label

of

x

polynomial

(in

1 1-2

)

number

of

times

and

then

returning

the

label

which

appeared in the majority of answers (the Chernoff bound given in Lemma 2.3.1 implies

that the result will, with high probability, be equal to the correct label). An appropriate

modification of the noise model is the introduction of persistent classification noise by

Goldman, Kearns and Shapire [GKS93]. In this model, as before, the answer to a query

at each point x is flipped with probability 1 - . However, if the membership oracle

was already queried about the value of f at some specific point x, or if x was already

generated as a random example, the returned label has the same value as in the first

occurrence (i.e., in such a case the noise persists and is not purely random). If the learner

does not ask for the label of a point more than once then this noise can be treated as

the usual independent random classification noise. There is another subtle but important

feature of this model. We cannot require learning algorithms in this model to work for an

15

2.2 PAC Learning
arbitrarily small confidence parameter  because with some (though negligible) probability the target function can be persistently totally corrupted (for example negated), making learning absolutely infeasible. So we must impose a positive lower bound on the confidence  that can be required from the learning algorithm in the persistent noise model, although this bound will be negligible.
2.2.4 Agnostic Learning
Another way of relaxing the assumption that examples are labeled by a concept from a specific concept class is the introduction of the agnostic PAC learning model by Haussler [Hau92] and Kearns et al. [KSS94]. In this model no assumptions are made on the function that labels the examples, in other words, the learning algorithm has no prior beliefs about the target concept (and hence the name of the model). The goal of the agnostic learning algorithm for a concept class C is to produce a hypothesis h whose error on the target concept is close to the best possible by a concept from C. This model reflects a common empirical approach to learning, where few or no assumptions are made on the unknown function and a limited space of candidate hypothesis functions is searched in an attempt to find the best approximation to the target function.
Formally, for two Boolean functions f and h and a distribution D over the domain, we define D(f, h) = PrD[f = h]. Similarly, for a concept class C and a function f define D(f, C) = minhC{D(f, h)}.
Definition 2.2.2 We say that an algorithm A agnostically learns representation class F by representation class H if for every > 0,  > 0, n, Boolean function f and distribution D over X, A(n, , ), given access to EX(f, D), outputs, with probability at least 1 - , a hypothesis h  H such that D(f, h)  D(f, CF ) + . As before, the learning algorithm is efficient if it runs in time polynomial in n, s = F-size(f ), 1/ and 1/.
It is easy to see that if we restrict the target function to be in CF then D(f, CF ) = 0 and we obtain the usual PAC learning model. In this sense the agnostic PAC model generalizes the basic model. Furthermore, all the extensions of the PAC model discussed in Section 2.2.2 can also be applied to the agnostic setting.
The agnostic learning model can also be thought of as a model of adversarial noise. By definition, a Boolean function f differs from some function in c  CF on D(f, CF ) fraction of the domain. Therefore f can be thought of as c corrupted by adversarial classification noise of rate D(f, CF ). Note that an agnostic learning algorithm will not necessarily find a hypothesis that approximates c ­ any other function that differs from f on at most D(f, CF ) + fraction of the domain is acceptable.
16

2.3 Estimating Random Variables

A minor difference arises from the fact that the noise rate is not explicitly mentioned

in the agnostic setting and, in particular, agnostic algorithms are not allowed polynomial

time

dependence

on

1 1-2

.

But

we

note

that

if

> 1/2 -  then a constant function (either

0 or 1) will be a good agnostic hypothesis. Therefore we can assume that  1/2 -  and

any

algorithm

that

is

polynomial

in

1 1-2

will

also

be

polynomial

in

1/

.

2.3 Estimating Random Variables

As can be seen from the definitions above, the PAC model is intrinsically probabilistic. Therefore, the analysis of learning algorithms often involves evaluation of the accuracy and confidence of estimates produced by random sampling. We do this by using the standard inequalities of Chernoff and Bienaym´e-Chebyshev.

Lemma 2.3.1 (Chernoff [Che52](see also [MR95])) Let X1, . . . , Xm be a sequence

of m independent Bernoulli trials, each with probability of success E[Xi] = p and let

S=

m i=1

Xi

.

Then

for

0







1,

Pr[S > (1 + )pm]  e-mp2/3

and Pr[S < (1 - )pm]  e-mp2/2 .

Lemma 2.3.2 (Bienaym´e-Chebyshev (c.f. [MR95])) Let X1, . . . , Xm be pairwise independent random variables all with mean µ and variance 2. Then for any   0,

Pr

1 m

m

Xi - µ





2 m2

.

i=1

17

Chapter 3
Hardness of Proper PAC Learning of DNF Expressions
In this chapter we prove that unless NP = RP, there is no polynomial-time PAC learning algorithm for DNF formulae where the hypothesis is an OR-of-thresholds. As special cases, we show that neither DNF nor OR-of-thresholds are properly learnable unless NP = RP. Moreover, we show that these results hold even when the learner can make membership queries. We also prove that it is NP-hard to learn the intersection of  2 halfspaces by the intersection of k halfspaces for any constant k  0.
3.1 Introduction
A fundamental goal of computational learning theory is to establish hardness results for PAC learning concept classes. Seminal work by Kearns and Valiant [KV94a] has shown that, under the assumption that certain cryptographic primitives are computationally intractable (e.g. inverting one-way functions), there are no polynomial-time learning algorithms for concept classes which are expressive enough to compute pseudorandomfunctions. Subsequent work [Kha93, NR97, JKS02] has shown that even constant depth, polynomial size circuits (often referred to as AC0) are capable of computing pseudo-random objects and are unlikely to be learnable in polynomial time.
Still, several well-studied concept classes seem too weak to compute cryptographic primitives, such as polynomial-size DNF formulae, intersections of halfspaces, and decision trees. For all of these concept classes the existence of a polynomial-time PAC learning algorithm remains a challenging open problem. The primary contribution of this chapter is new negative results for learning DNF formulae and intersections of halfspaces. Our hardness results apply to representation dependent learning algorithms, algorithms where
18

3.1 Introduction
the output hypothesis is represented in a certain specific way.
3.1.1 Previous Work
Previous representation dependent hardness results for learning concept classes applied to proper learning algorithms and required strong restrictions on the size of the hypothesis output by the learning algorithm [BR92, Gol78, KLPV87a, PV88, NJS98]. In each case, the hardness assumption required is not cryptographic, but a worst-case assumption on the complexity of NP (e.g. NP = RP).
Initial hardness results for properly learning DNF formulae due to Pitt and Valiant [PV88] show that coloring a k-colorable graph on n vertices using colors can be reduced to learning k-term DNF formulae over n variables by -term DNF formulae. In particular, combined with the hardness results on chromatic number due to Feige and Kilian [FK96], their result implies that unless NP = RP it is hard to learn n-term DNF by n1-term DNF. Pitt and Valiant also show a similar reduction from k-NM-Colorability [GJ79] (also called hypergraph coloring) to learning of DNF formulae by DNF formulae. They used this reduction to show that 2-term DNF formulae are not learnable properly (unless NP = RP). Combined with recent results on the hardness of approximate hypergraph coloring [DRS02], their reduction implies that 2-term DNFs are NP-hard to learn by kterm DNFs for any constant k (we include this reduction for completeness in Section 3.3.1).
The best result along these lines is due to Nock et al. [NJS98] who have used reductions from generalized coloring problems to show that it is hard to output a DNF formula whose size is at most O(kanb) times the size of the unknown k-term DNF formula for a  2, b  0 and k = (n) for any  > 0.
The best hardness result for learning intersections of halfspaces is due to Blum and Rivest [BR92]. They prove that unless NP = RP, it is hard to learn intersections of k halfspaces by intersections of k halfspaces for any k  2.
We note here that the above hardness results hold for proper Occam algorithms, learning algorithms which work by receiving a suitably large set of training examples and outputting a small hypothesis consistent with the examples. It is not known, in general, if the existence of a proper PAC learning algorithm for a concept class implies the existence of a proper Occam algorithm for the class [PB90]. In particular, it is not known for the classes of DNF formulae and intersections of halfspaces. Our hardness results for DNF formulae and intersections of halfspaces hold for any proper PAC learning algorithm and overcome this limitation.
Angluin and Kharitonov prove that if non-uniform one-way functions exist then MQs do not help predicting DNF formulae [AK95b]. However, their reduction does not preserve
19

3.1 Introduction

the representation of a hypothesis and therefore cannot be used to obtain hardness of

proper learning with MQs.

Hardness results for learning of DNF expressions with MQs are only known for the

exact model of learning (which is weaker than PAC learning) and only for strong proper

learning (or slight relaxations similar to the one we prove for PAC learning with respect

to the uniform distribution). The strongest results in this model are due to Hellerstein

and Raghavan [HR02] and are based on information-theoretic hardness.

Our hardness results for learning DNF expressions are contrasted by the fact that

monotone DNF expressions are known to be strongly properly PAC learnable with MQs

[Val84]. In addition to that, DNF expressions with k terms are known to be learnable by

DNF expressions with 2k terms when MQs are available [BR95]. It is also interesting to

note that known non-trivial algorithms for learning unrestricted DNF formulae (running

in

time

2O~(n

1 3

)

[KS04a]

and

in

time

2O~(n)

with

DNF

hypotheses

[ABF+04])

use

only

random examples and it is unknown whether they could be sped-up by using MQs.

3.1.2 Our Results
Learning DNF formulae is one of the central challenges in computational learning theory. We give strong evidence that there are no polynomial-time learning algorithms for DNF formulae which output DNF formulae or unions of halfspaces as output hypotheses:
Theorem 3.1.1 If there exists an algorithm A such that for every Boolean function c, distribution D and error parameter , A, given access to the example and the membership query oracles for c, runs in time poly(n, DNF-size(c), 1/ ) and with probability 3/4 outputs an OR-of-thresholds formula h such that PrxD[h(x) = c(x)]  1 - , then NP = RP.
Access to membership queries plays an instrumental role in numerous learning algorithms (many of which are proper), but hardness results for learning with MQs are still very scarce. This is the first result showing that PAC learning can be NP-hard even when MQs are available.

Hardness Results for Learning Intersections of Halfspaces

Let h = sign(

n i=1

wixi

-

)

where

each

wi

and



are

integers;

h

naturally

induces

two

halfspaces: the set of points in {0, 1}n which make h positive and the set of points which

make h negative (h is often referred to as a linear threshold function). Although several

polynomial-time algorithms for learning halfspaces are known (e.g. [BEHW87]), a long-

standing open problem in learning theory is to develop polynomial-time algorithms for

20

3.1 Introduction
learning intersections of halfspaces (i.e. functions of the form h = ki=1hi where each hi is a linear threshold function).
The above theorem proves as a special case that intersections of halfspaces are not properly learnable unless NP = RP. If we wish to restrict the concept class to intersections of just two halfspaces (even for this case no polynomial-time learning algorithms are known), we can prove the following hardness result:
Theorem 3.1.2 Let C be the concept class of intersections of two halfspaces. If there exists an algorithm A such that for every c  C, distribution D and error parameter , A runs in time poly(n, 1/ ) and with probability 3/4 outputs h, an intersection of k halfspaces for any constant  0 such that PrxD[h(x) = c(x)]  1 - , then NP = RP.
The result of Blum and Rivest [BR92] only implies hardness of learning the intersection of two halfspaces by the intersection of two halfspaces.
3.1.3 Our Approach
Our results are based on the intractability of approximate graph and hypergraph coloring.
Amplifying Hardness Results for Approximate Graph Coloring
For proving hardness results for properly learning DNF and intersections of halfspaces we amplify known hardness results for the problem of distinguishing between graphs with small and large chromatic number. Feige and Kilian [FK96] have proved that for any  > 0 it is NP-hard (under randomized reductions) to distinguish between graphs with chromatic number O(n) and graphs with chromatic number (n1-). This result combined with known reductions from graph coloring to properly learning DNF formulae (i.e. [PV88]) implies that it is NP-hard to distinguish between distributions induced by n-term DNF formulae and n1--term DNF formula.
We wish to amplify this n1- bound and prove hardness results for na-term DNF formulae (and intersections of na halfspaces) for any a  0. To do this we apply specialized graph products (along the lines of Linial and Vazirani [LV89]) to create distributions which amplify the size of the underlying chromatic number. In addition, we provide an accompanying transformation of DNF formulae and intersections of halfspaces into "normal forms" which satisfy only examples derived from subsets of independent sets from the product. Many terms or halfspaces are required for a good approximation to these distributions if and only if the original graph had large chromatic number.
For proving hardness results for learning the intersection of two halfspaces, we make critical use of recent hardness results due to Dinur et al. [DRS02] on the hardness of color-
21

3.2 Preliminaries

ing 2-colorable, 3-uniform hypergraphs. We give a reduction from -coloring k-colorable, 3-uniform hypergraphs to properly learning intersections of k halfspaces by halfspaces.

3.2 Preliminaries

Our learning model is Valiant's well known Probably Approximately Correct (PAC) learn-

ing model [Val84] defined in Section 2.2. Recall that a DNF formula is a logical formula

equal to the OR of a number of ANDs. A halfspace is a function f = sign(

n i=1

ixi

-

)

where i (for all i) and  are integers. An intersection of k halfspaces is a function

g = ki=1hi where each hi is a halfspace. A neural network with k hidden nodes is a func-

tion g = f (h1(x), . . . , hk(x)) where each hi is a halfspace and f is an arbitrary Boolean

function. Each hi is called a hidden node. The halfspace hi is origin-centered if the

corresponding  = 0.

3.3 Hardness of Learning DNF and Intersections of Halfspaces
In this section we prove our main hardness result for DNF formulae, namely that an algorithm for learning DNF in polynomial-time by ORs of threshold functions can be used to approximate the chromatic number of a graph. We will actually prove the equivalent hardness result for CNF formulae and ANDs of thresholds (intersections of halfspaces). It is easy to see that this will imply the intractability of properly learning both DNF formulae and intersections of halfspaces. We begin by reviewing the reduction of Pitt and Valiant that gives a simple way to reduce a coloring problem to proper learning of DNF [PV88].
3.3.1 The Reduction of Pitt and Valiant
Pitt and Valiant [PV88] gave a reduction from coloring k-colorable hypergraphs to learning k-term DNF formulae (in their work this problem is referred to as k-NM-Colorability). We include this reduction for completeness and also observe that, combined with a recent hardness result for coloring hypergraphs due to Dinur et al. [DRS02], the reduction implies that 2-term DNF in not learnable by k-term DNF for any constant k.
Recall that k-coloring a hypergraph means finding a mapping from the vertices to {1, . . . , k} such that no edge has all of its vertices assigned the same integer.
Theorem 3.3.1 ([PV88]) Coloring a k-colorable hypergraph H = (V, E) using colors reduces to learning k-term DNF formulae by outputting an -term DNF formulae.
22

3.3 Hardness of Learning DNF and Intersections of Halfspaces

Proof: Let A be an algorithm for learning k-term DNF formulae by -term DNF formulae
and let H = (V, E) be any k-colorable hypergraph on n vertices. For a vertex vi  V let a(vi) be the a vector of length n which is equal to 0 in position i and 1 elsewhere. For an edge e  E let a(e) = ve a(v) (conjunction is applied bitwise).
We construct a set of examples S as follows:

· Vertex examples: for each v  V , (a(v), +).

· Edge examples: for each e  E, (a(e), -).

We now claim that any k-coloring of H can be efficiently translated into a k-term DNF

formula consistent with the given examples and vice versa. Let  be a k-coloring of H.

For every color c  k we define

tc =

xi ,

(vi)=c

that is, tc is the conjunction of all the variables whose corresponding vertices are not colored in color c. We set h = t1  t2  . . .  tk. Clearly h is a k-term DNF formula and the translation is efficient. For every vertex example a(vi), t(vi)(a(vi)) = 1 and hence h(a(vi)) = 1. For any edge example a(e), vertices in e are colored in at least two different colors and hence every term tc will contain at least one variable xi such that vi  e. This means that h will not satisfy a(e).

Now let h = t1  t2  . . .  t be a DNF expression consistent with the given examples. For every vertex v, we define (v) = c if a(v) is satisfied by tc (if there are several terms that satisfy a(v) we choose the one with the smallest c). Clearly this defines a mapping

of vertices into colors. Take e  E and assume that all the vertices in it are colored in

color c. That is, for each v  e, tc(a(v)) = 1. This implies that

tc(a(e)) = tc( a(v)) = tc(a(v)) = 1

ve

ve

contradicting the consistency with example (a(e), -). This reduction can be used with the following hardness result due to Dinur et al.
[DRS02]:

Theorem 3.3.2 ([DRS02]) It is NP-hard to k-color a 2-colorable 3-uniform hypergraph for any constant k  0.

We therefore obtain the following hardness result.
Theorem 3.3.3 Assuming NP = RP there is no polynomial-time algorithm for learning 2-term DNF formulae by k-term DNF formulae for any constant k.

23

3.3 Hardness of Learning DNF and Intersections of Halfspaces

To contrast this with known results for learning k-term DNF, note that a k-term DNF is learnable in time O(nk) where the hypothesis is a CNF of size O(nk) [Val85].

3.3.2 The Target Function and Distribution
We now present our reduction from coloring a graph to learning of CNF. Given a graph G = (V, E), construct a target function f and a distribution D as follows.
Fix some positive integer parameter r. The examples are from {0, 1}V r = {0, 1}|V |·r.
Definition 3.3.4 Let G(V, E) be a graph with n vertices and m edges. For a vertex v  V , let z(v) denote the vector with a 1 in the v-th position and 0 everywhere else. For an edge e = (u, v) of G, let z(e) be the vector with a 1 in positions u and v.
With each vector (v1, v2, . . . , vr)  V r, we associate a negative example z(v1), . . . , z(vr), 0 . For each choice of k1, k2, such that 1  k1  r, 1  k2  r, k1 = k2, e = (u, w)  E and vi  V for each i = 1, 2, . . . , r, i = k1, k2, we associate a positive example

z(v1), . . . , z(vk1-1), z(e), z(vk1+1), . . . , z(vk2-1), 0, z(vk2+1), . . . , z(vr), 1 .

Let S+ denote the positive examples and S- denote the negative examples. Set S =

S+  S-.

There are r ways to choose k1, r - 1 ways to choose k2, |E| ways to choose e, and |V |r-2 ways to choose the rest of vi's. Hence there is a total of r · (r - 1) · |E| · nr-2 positive examples.

Distribution D is uniform over the above set of examples S, so the probability of each

negative

example

is

1 2·nr

and

the

probability

of

each

positive

example

is

1 2·r·(r-1)·|E

|·nr-2

.

These examples define the values of f on points in S. In order to answer membership

query we also need to define f on the rest of the hypercube. Let x = (x1, . . . , xr) be a point not in S+  S-. If for all i, xi  {¯0}  {z(v) | v  V } then f (x) = 0. We refer

to this set of points as 0-vertex points. If for some i  [r], there exists (u, v)  E such

that xiu = xiv = 1, then f (x) = 0. We call this set of points non-edge points. Otherwise, let f (x) = 1. We first note that the example oracle for f with respect to the distribution

D and the membership query oracle for f can be simulated efficiently by a randomized

algorithm with input G.

3.3.3 The Case of Small Chromatic Number
We now prove that if the chromatic number (G) is small, then there exists a small CNF formula equal to f . Set r = g(n)/ = g/, for some function g such that g(n)  n and constant  < 1. Hence  = g/r. Then we have
24

3.3 Hardness of Learning DNF and Intersections of Halfspaces

Lemma 3.3.5 If (G)  n = ng/r, then there is a CNF formula of size at most ng +r|E| equal to f .

Proof: Suppose V =

 i=1

Vi,

where

Vi

are

independent

sets.

Such

sets

must

exist

by

the

definition of . Define the CNF formula



g(x1, x2, . . . , xn) =

xv .

i=1 v/Vi

This formula rejects all points in {¯0}  {z(v) | v  V } and accepts all points in {z(e) | e  E}.
We then define an expression F that rejects all the points in S- and 0-vertex points

r

r

F (x1, . . . , xr) = g(xk1, . . . , xkn) =

xkv ,

k=1

k=1 i=1 v/Vi

and a CNF formula H on r · n variables that is negative on all the non-edge points and

positive elsewhere

H(x1, . . . , xr) =

(xku  xkv ) .

k[r]; (u,v)E

We claim that in addition to S- and 0-vertex points F rejects only non-edge points. By the definition of F , if F rejects a point x1, . . . , xr then for all k  [r], there exists i  [] such that for all v  Vi, xv = 0. Therefore if for some k  [r] and u, v  V , xku = xkv = 1 then u, v  Vi for some i. In particular, (u, v)  E since Vi is an independent set. We therefore obtain that F  H rejects exactly points in S-, 0-vertex points and the non-edge points, in other words, is identical to f . We remark that in order to answer membership queries to F we would need to know which non-edge points it accepts and which rejects. This would not be possible without knowing the "small" coloring. Therefore f is defined as F  H in order to hide all the coloring-dependent information in F by using H that rejects all the non-edge points.
Note that F above is not written as a CNF formula. It is, however, a disjunction of r CNF formulas, each having at most (G) clauses. Hence expanding the expression for F yields a CNF formula with at most (G)r  ng clauses. So F  H can be written as a CNF formula satisfying the conditions of the lemma.

3.3.4 The Case of Large Chromatic Number
In this section we assume that (G)  n1-, and we prove that no small AND-of-thresholds formula gives a good approximation to the learning problem.
25

3.3 Hardness of Learning DNF and Intersections of Halfspaces

Theorem 3.3.6 Let

1 2r

-1 log n

r
. Then F

G be a graph such that (G)  n1-. Let

has

error

at

least

1 n2g+4

with

respect

to

D.

F

=

i=1hi

where

<

We will need the following covering lemma which was first proved by Linial and Vazirani [LV89] and is a special case of a result due to Feige on randomized graph products (Corollary 2.9 of [Fei95]):

Lemma 3.3.7 [LV89] One needs at least

-1 ln n

r
products of the form I1 × I2 × . . . × Ir,

where the Ii's are independent sets, to cover V r = V × V × . . . × V .

Let a product in the above form be called a product of independent sets. At a high

level, we will argue that any hk  F correctly classifies very few negative examples that lie outside a particular product of independent sets. Then using the above lemma, it will

follow that we need many hk's to cover (correctly classify) all negative examples. We now

proceed to the details.

Fix a particular hk  F . Let hk =

r i=1

n j=1

ji

xij



.

For each i  r, the i-

coefficients in h are the coefficients of the form ji , j  n. For each i  r, let Ii be the set

of all j  n such that there is no edge (k, j)  E such that ki is less than ji . (That is,

we order all i-coefficients in nondecreasing order, and take the coefficients in order that

are independent). Note that Ii is an independent set of G. Let S1k = V × I2 × . . . × Ir, S2k = I1 × V × I3 × . . . × Ir, and so forth. Let Sk = ri=1Sik. The following lemma shows that hk either misclassifies many positive examples, or misclassifies almost all negative examples outside of Sk.

Lemma 3.3.8 Let {hk}k=1 be a family of halfspaces, and Sk as above. Let N denote the number of negative examples outside of k=1Sk that hk classifies correctly. Then the
number of positive examples that hk misclassifies is at least N/2n.

Proof: Fix hk and I1, I2, . . . , Ir as above. Let  = z(j1), . . . , z(jr) be a negative example such that  is not in Sk, and hk() = 0. Thus hk() = j11 + j22 + . . . + jrr < . Since  is not in Sk, there exist two ji's, say j1 and j2 such that j1  I1 and j2  I2. Since j1 is not in I1, there is some vertex k1 in I1 such that the edge (j1, k1) is present in E1 and similarly there is a vertex k2 in I2 such that the edge (j2, k2) is in E2. By the way we chose I1 and I2, it follows that k11  j11 and k22  j22. Either (a) j11  j22 , or (b) j22 < j11 . If (a) holds, then k11 + j11 + j33 + . . . + jrr < . But this corresponds to the positive example  = (z(j1, k1), 0, z(j3), . . . , z(jr)) and thus hk (and hk) misclassifies  . Similarly if (b) holds, then hk (and hk) misclassifies the positive example  = (0, z(j2, k2), z(j3), . . . , z(jr)). Thus we have a mapping from the set of all correctly classified negative examples outside of k=1Sk to incorrectly classified positive
26

3.3 Hardness of Learning DNF and Intersections of Halfspaces

examples. Since each positive example is mapped onto by at most 2n negative examples (each misclassified positive example can be obtained from starting with a negative example that falls into either cae (a) or case(b)), it follows that the number of positive examples misclassified by hk is at least N/2n.

Recall that F is the conjunction of threshold formulas, h1, . . . , h . For each hk, let Sk be the associated set of cross products. Let the negative examples that hk correctly

classifies be denoted by Ink  Outk, where Ink are those correctly classified negative examples in Sk, and Outk are the remaining correctly classified negative examples.

Lemma 3.3.9 Let Sk, k 

be defined as above. If



1 2r

·

-1 ln n

r
then

nr

- | k=1

Sk|



1 2

·

-1 ln n

r
.

Proof: If this were not the case, we would have a collection of

··r



1 2

·

-1 r ln n

products

of

independent

sets

which

cover

all

but

m

<

1 2

·

-1 ln n

r points of V r.

(To see

this, replace the cross product I1 × . . . Ii-1 × V × . . . × Ii+1 × . . . × Ir by  cross products

I1 × . . . Ii-1 × Jk × Ii+1 × . . . × . . . × Ir, where k  , and J1, J2, . . . J is a partition of the

vertices in G into  independent sets.) Then by adding m singletons (which are trivially

products of independent sets) we obtain a cover of V r by r + m <

-1 ln n

r
products of

independent sets, which contradicts the above covering lemma (Lemma 3.3.7).

hk

We is a

can now analyze the overall error with respect

threshold formula, and

<

1 2r

-1 r ln n

to

D.

Let

F

=

k=1 hk ,

where

each

Let

R

=

1 4

·

-1 ln n

r
.

There are two cases to consider.

The first case is when | k=1

Outk|  R. Then by Lemma 3.3.8, the number of positive examples that F misclassifies

is

at

least

R 2n

.

Thus

the

probability

of

error

with

respect

to

D

is

at

least

R 4n·r·(r-1)·|E|·nr-2

which, for sufficiently large n, is at least:

R/nr+4 = >

1 4

·

-1 ln n

nr+4

r



1 4

·

n1-g/r -1 r ln n
nr+4

n1-2g/r nr+4

r

= n-2g-4 =

1 n2g+4

.

In the second negative examples

case, | k=1 Outk| misclassified is at

< R.

least

1 2

But then by

·

-1 ln n

r
-R

Lemma which is

3.3.9, equal

the number of to R. Thus the

probability

of

an

error

with

respect

to

D

is

at

least

R 2nr

,

which

again

is

at

least

1 n2g+4

for

sufficiently large n.

27

3.3 Hardness of Learning DNF and Intersections of Halfspaces

Finally, we have reduced the problem of approximating (G) to learning CNF:

Theorem 3.3.10 Suppose that CNF is efficiently learnable with membership queries by ANDs-of-thresholds in time O(nkg(n)/2 · sk · ( 1 )k), where k  2, and 2  g(n)  n (recall s
is the size of the CNF). Then there exists a randomized algorithm for approximating the chromatic number of a graph within a factor of n1-1/8k in time O(n7kg(n)). Moreover, the algorithm will always give a valid answer for   n1-1/8k.

Proof: Set

=

1 n2g+4

and r = 8kg.

Let G be a graph and let f

and D be the target

function and the distribution induced from G as described previously. Run the learning

algorithm with respect to distribution D using f to answer membership queries. If it does

not terminate after n7kg steps output "  n1-1/8k". Otherwise, let h be the hypothesis

the algorithm outputs. Calculate the error h of h with respect to the distribution D.

If

h<

1 n2g+4

output "  n1/8k", otherwise output "  n1-1/8k".

We claim that this

algorithm works with probability at least 3/4 for sufficiently large n in approximating

  n1/8k and works perfectly for   n1-1/8k.

If   n1/8k, by Lemma 3.3.5, s  ng + r|E|  ng + n3  2ng+1. The number

of variables in the underlying learning problem is r · n  n2. Hence the running time

with probability  3/4 is at most O(n2·kg/2n(g+1)·kn(2g+4)k)  O(n4kg+5k) < n7kg for

sufficiently large n, and the output is supposed to have an error <

=

. 1
n2g+4

Hence

the

algorithm outputs "  n1/8k" with probability at least 3/4 in this case.

If   n1-1/8k, by Lemma 3.3.6 the output of the algorithm must contain at least

1 2r

-1 ln n

r
terms in order to have an error <

=

. 1
n2g+4

In

this

case

the

running

time

of

the algorithm (for n sufficiently large) is at least:

1 2r

-1 ln n

r



1 16kn2

n1-1/8k - 1 ln n

r



1

n8kg-g

16kn2 (2 ln n)8kg

> n7kg

.

Hence if the algorithm terminates in n7kg steps, its error will be bigger than , and the algorithm outputs "  n1-1/8k" with probability 1 in this case.

Remark 3.3.11 By negating the CNFs and the ANDs-of-thresholds in Theorem 3.3.10,
we obtain the following: Suppose that DNFs are learnable with MQs by ORs-of-thresholds in time O(nkg(n)/2 ·
sk · ( 1 )k), where k > 1, and 2  g(n)  n. Then there exists a randomized algorithm for approximating the chromatic number of a graph within a factor of n1-1/8k in time O(n7kg(n)). Moreover, the algorithm will always give a valid answer for   n1-1/8k.

We will require the following hardness result due to Feige and Kilian [FK96]:

28

3.4 Intersections of Two Halfspaces
Theorem 3.3.12 [FK96] For any constant  > 0, there exists a polynomial-time randomized reduction mapping instances f of SAT of length n to graphs G with N = poly(n) vertices with the property that if f is satisfiable then (G)  O(N ) and if f is unsatisfiable then (G)  (N 1-). The reduction has zero-sided error.
An immediate corollary is that approximating the chromatic number is hard:
Corollary 3.3.13 [FK96] Let  > 0 be a constant. Assume there exists an algorithm which approximates the chromatic number of a graph with n vertices within a factor of n1- in RTIME(t(n)) (with zero error if   n1-). Then NP  RTIME(t(na)) for some constant a  1.
Now we can combine Theorem 3.3.10 and Corollary 3.3.13 to prove Theorem 3.1.1. Proof:(of Theorem 3.1.1) If DNF formulae are efficiently learnable with MQs by ORs-ofthresholds, we show how to approximate the chromatic number of a graph in polynomialtime to within a factor of n for some small constant  > 0. Let G be a graph on n vertices. From Remark 3.3.11 setting g = 2, we can approximate (G) within a factor of n1-1/8k in time O(n14k) where k is a constant, with zero error for   n1-1/8k. Hence, by Corollary 3.3.13, NP  RTIME(nO(1)) = RP.
From the proof of Theorem 3.3.10 we can see that it is hard to learn even n-term DNF by nb-term OR-of-thresholds in time nb for any constant b  0. We can, under a stronger hardness assumption, prove stronger hardness results for learning superpolynomial size DNF formulae (i.e., if we do not restrict our concept class to be polynomial-size DNF formulae):
Corollary 3.3.14 Suppose that SAT / RTIME(O(nn )) for some . Then for any k > 0 there is  > 0 such that DNF formulas are not properly learnable with MQs in time O(nn · sk · ( 1 )k).
Notice that if we assume SAT / RTIME(2n ) for some  and substitute k = 2 in Corollary 3.3.14 then we can conclude that DNF formulae are not properly learnable in time O(nn ·( s )2) for some  < 1. Alekhnovich et al. prove that DNF formula are properly learnable in time 2O((n log s)1/2 log n)/ , so our lower bound is fairly tight [ABF+04].
3.4 Intersections of Two Halfspaces
In this section we show that it is hard to learn the intersection of two halfspaces by the intersection of any constant number of halfspaces. This result may be especially interesting
29

3.4 Intersections of Two Halfspaces
in light of the fact that it is not known how to learn (even non-properly) the intersection of two n-dimensional halfspaces in time less than 2O(n).
The main idea is to apply recent hardness results on the hardness of hypergraph coloring. Recently, several researchers [GHS00, Kho02, DRS02] have shown that it is hard to color uniform hypergraphs, i.e., hypergraphs where each hyperedge is of equal size.
We start by reducing the problem of coloring a 3-uniform hypergraph to a consistency problem for intersections of halfspaces:
Theorem 3.4.1 The problem of -coloring a k-colorable hypergraph on n vertices reduces to finding an intersection of halfspaces over n variables consistent with examples labelled by an intersection of k halfspaces.
Proof: Let H = (V, E) be a k-colorable hypergraph with n vertices. We construct a set of examples S classified by the intersection of k halfspaces such that any intersection of
halfspaces consistent with S can be used to -color H (the reduction is an extension of the reduction by Blum and Rivest [BR92]).
Denote the vertices of H by v1, v2, . . . , vn. For a vertex vi  V , let a(vi) denote the vector of length n with a 1 in the ith position and 0 everywhere else. For an edge e  V of G let a(e) be the vector equal to ve a(v) (that is, the characteristic vector for set e). Let 0n denote the all zeroes vector of length n. Create the following set S of examples
· The example (0n, +).
· For every vertex v  V , the example (a(v), -).
· For every edge e  E, the example (a(e), +).
Assume H is colorable by k colors according to the function . We construct an intersection of k halfspaces consistent with S. Let hi = sign(wi · x - i) where i = -1/2 and wi = (wi,1, . . . , wi,n) such that wi,j equals -1 if (vj) = i and n otherwise. Set h = ki=1hi.
Checking that h1  h2, . . . , hk is consistent with S is straightforward; the example (0n, +) is satisfied and each (a(v), -) example is consistent with the intersection. Finally given an edge e each (a(e), +) is satisfied by each hi since there exist two vertices in e which are colored in different colors and hence at least one of two vertices will contribute n to the weighted sum making the total positive.
For the other direction, assume there exists an intersection of halfspaces h = h1 · · · h consistent with the examples in S. Construct a coloring for H as follows. Let (v) = t where t is the first halfspace ht such that ht(a(v)) is negative. This assigns a color to each
30

3.4 Intersections of Two Halfspaces
vertex. Now let e  E. If there exists a color c and edge e such that v  e, (v) = c then for all v  e, hc(a(v)) = 0. Since h(0n) is positive, it implies that hc(0n) is positive, and hence its threshold c is negative. But for all i such that vi  e, hc(a(vi)) = 0 and thus wc,i < c. This implies vie wc,i < c and therefore hc(a(e)) = 0 contradicting the consistency with S.
Applying Theorem 3.4.1 and Theorem 3.3.2 we obtain Theorem 3.1.2, our main hardness result for this section. Proof:(of Theorem 3.1.2) Assume there exists a polynomial time algorithm for learning the intersection of two halfspaces which outputs a hypothesis equal to an intersection of k halfspaces. Given a hypergraph H construct a set of examples S as above. Consider a distribution D which is uniform over this set of examples. Setting the error parameter
= 1/(|S| + 1), run the algorithm to obtain with probability 3/4 a hypothesis h equal to the intersection of k halfspaces. The algorithm will run in time polynomial in n and 1/ = |V | + |E| + 2, that is, will be polynomial in the size of H. Since < 1/|S|, h must be consistent with S. Hence from Theorem 3.4.1 we can reconstruct a coloring for H.
Dinur et al. [DRS02] also give the following hardness result under a slightly stronger assumption:
Theorem 3.4.2 ([DRS02]) If NP  DTIME(2logO(1) n) then there is no polynomial time algorithm for coloring a 2-colorable 3-uniform hypergraph using O((log log n)1/3) colors.
We obtain a corresponding hardness result:
Corollary 3.4.3 There is no efficient algorithm for learning intersections of two halfspaces by intersections of O((log log n)1/3) halfspaces unless NP  RTIME(2logO(1) n).
We can also prove a hardness result for learning two-node neural networks by neural networks with a constant number of origin-centered hidden nodes:
Theorem 3.4.4 Coloring a k-colorable hypergraph with 2 colors reduces to the problem of finding any function of origin-centered halfspaces consistent with a data set labelled by the intersection of k origin-centered halfspaces.
Proof: Let H = (V, E) and use the same reduction as in the proof of Theorem 3.4.1 to obtain a set of examples S without the 0n example. We first note that if we define h = i=1hi where hi's are defined as before but with thresholds i = 0 we will get an intersection of k origin-centered halfspaces consistent with S.
For the other direction let f be a Boolean function of origin-centered halfspaces h1, . . . , h consistent with S. Put 2 colors in correspondence with every subset of
31

3.4 Intersections of Two Halfspaces halfspaces. Color v the color corresponding to which subset of the halfspaces are negative on input a(v). Assume e is a monochromatic edge. Then each v  e is set negative by the same subset of halfspaces. That is for every j  and vi1, vi2  e, hj(a(vi1)) = hj(a(vi2)). hj is zero centered and hence sign(wj,i1) = sign(wj,i2). This implies that for every v  e,
hj(a(e)) = sign( wj,i) = hj(a(v))
vie
and thus f (a(e)) = f (a(v)) which contradicts the consistency with S. Now we can apply the hardness result due to Dinur et al. [DRS02]. For any learning
algorithm outputting some representation of a function of halfspaces in polynomial time we have the following: Corollary 3.4.5 It is NP-hard to learn three-node neural networks by outputting a neural network with a constant number of hidden, origin-centered nodes.
32

Chapter 4
Hardness of Approximate DNF Minimization and Learning
In this chapter we prove that learning of DNF expressions by DNF expressions of somewhat larger size is NP-hard even when learning with respect to the uniform distribution and using membership queries. The result and techniques are incomparable to those of Chapter 3 since learning often becomes easier when the distribution is uniform but we only rule out a restricted form of proper learning.
The result is obtained via a new connection to the problem of two-level logic minimization or finding a minimal DNF formula consistent with a given complete truth table (TT-MinDNF). This problem was formulated by Quine in 1952 and has been since one of the key problems in logic design. We prove that TT-MinDNF for a function of d variables is NP-hard to approximate within d for some constant  > 0, establishing the first inapproximability result for the problem. This result is of independent interest and will be the main focus of this chapter.
4.1 Introduction
The problem of finding a minimal-size disjunctive normal form expression consistent with a given truth table (TT-MinDNF) is one of the oldest problems in computer science. It was formulated by the famous logician and philosopher Willard Van Quine in his work on mathematical logic [Qui52, Qui56]. His algorithm for simplifying logical steps was also discovered in 1956 by Edward McCluskey in the context of circuit design [McC56]. Besides its important role in circuit design (in particular, two-level and multi-level logic synthesis for VLSI design of ASICs and Programmable Gate Arrays [CS01]) the problem has more recently appeared in reliability analysis [CM94], IP routing table compaction
33

4.1 Introduction
[Liu02], and high-dimensional data representation [AGGR05]. This array of applications has led to an ongoing effort by many researchers to seek efficient heuristic and exact minimization procedures. We direct the interested reader to [CS01] for an overview of a large number of publications and some software tools. In the original Quine-McCluskey algorithm and in most of the later approaches, after a number of simplification steps the problem is reduced to an instance of the classical SET-COVER problem. Then, either an exact solution is found via the brute-force search, or an approximate solution is found using a certain heuristic. In the former case the size of the search space is not theoretically analyzed and in the latter no guarantees on the quality (i.e. size) of the output are given (both are usually measured empirically).
Far less work has been done on the theoretical side of this problem. Gimpel [Gim65] and Paul [Pau74] showed that Quine-McCluskey method can produce instances of SETCOVER that are NP-hard to solve. Then, in 1979, the full truth table version was proven NP-complete by Masek [Mas79] (his manuscript was not published but the proof can be found in surveys by Czort [Czo99] and Umans et al. [UVSV06]). Inapproximability results are only known for a generalization of TT-MinDNF that allows "don't care" values in the truth table (i.e., the truth table is partial). Allender et al. prove that this problem (we denote it by PTT-MinDNF) is NP-hard to approximate within any constant factor and cannot be approximated within log d factor unless NP  RTIME(npolylog(n)), where d is the number of variables [AHPM04]. Using Gimpel's reduction from PTT-MinDNF to TT-MinDNF they also produced a simpler proof (than Masek's) for NP-hardness of TT-MinDNF.
On the approximation side the only known efficient approximating algorithm is the one resulting from using the greedy algorithm to solve the SET-COVER instance obtained in Quine-McCluskey algorithm [Chv79]. It gives ln 2d = O(d) approximation factor.
In this paper we present the first result on hardness of approximating TT-MinDNF. More specifically, we prove the following theorem.
Theorem 4.1.1 There exists a constant  > 0 such that it is NP-hard to approximate TT-MinDNF to within a factor d, where d is the number of variables of the TT-MinDNF instance.
This result implies that the approximation factor achieved by the greedy algorithm is at most polynomially larger than the best possible. In addition we prove the first hardness of approximation result for a natural restriction of SET-COVER problem, in which the ground set is {0, 1}d and all subsets are subcubes (see Section 4.2 for a formal definition).
The unpublished results of Allender et al. were recently substantially strengthened by the same authors and Paul McCabe [AHM+06]. They prove NP-hardness of approximating
34

4.1 Introduction
TT-MinDNF within any constant factor and also show how to get the d factor under the assumption that NP  DTIME(npolylog(n)). Their independent work is based on a similar approach.
Learning is another context where finding a small DNF formula consistent (or almost) with the given data is a fundamental problem. The problem was formulated by Leslie Valiant in his seminal paper introducing the PAC model of learning [Val84] and has been the subject of numerous subsequent works. A number of questions related to PAC learning of DNF expressions originated in his work. In particular, he asked whether DNF expressions are learnable from random examples with or without the use of the membership query (MQ) oracle [Val84, Val85]. Valiant's original definition required that the learning algorithm output a DNF expression but this restriction was later relaxed to any efficiently-computable hypothesis with the stricter version being referred to as proper learning. Hardness of proper learning DNF from random examples only in the distribution independent PAC learning was recently established by Alekhnovich et al. [ABF+04]. Feldman has extended their proof to learning with MQs [Fel06a] (both results are presented in Chapter 3).
We observe that hardness of TT-MinDNF implies hardness of strongly proper learning of DNF expressions with MQs even with respect to the uniform distribution, where strongly proper means that the size (number of terms) of a hypothesis has to be upperbounded by the DNF-size of the target function. Our inapproximability result then translates to hardness even when the size of a hypothesis is O(log (s/ )) times larger than the size of the target. We note that, as proved by Jackson, unrestricted DNF expressions are learnable non-properly in this strong model [Jac97] (see also Chapter 5), and hence our result highlights the importance of knowledge representation in this model.
4.1.1 Relation to Other Work
Besides the results that we have already mentioned, one of the most significant results in DNF minimization is Umans' proof that finding a minimum DNF formula for a function given by a DNF formula (also called finding a minimum equivalent DNF and denoted MinEquDNF) is p2-hard to approximate within N  for some constant  > 0, where N is the size of the given DNF formula [Uma99]. Despite the same goal in both problems the difference in input makes the nature of the problem (and, eventually, the proof techniques) very different. In particular, the gaps differ exponentially in terms of the size of hard instances. Hardness results for some other variants of DNF minimization can be found in a survey by Umans et al. [UVSV06].
Hardness results for learning of DNF expressions with MQs are also known for the exact model of learning (which is weaker than PAC learning). The strongest results in
35

4.1 Introduction
this model are due to Hellerstein and Raghavan [HR02] and are based on informationtheoretic hardness. For proper PAC learning without MQs a number of hardness results are known for several other representations [BR92, Gol78, KLPV87a, ABF+04].
When learning with respect to the uniform distribution DNF expressions are known to be PAC learnable (non-properly) with MQs [Jac97] and PAC learnable properly in time nO(log (s/ )) [Ver90].
4.1.2 Outline and Organization
The proof of the TT-MinDNF hardness result has two key components. The first one is a reduction from a more general problem of covering a subset of the Boolean hypercube with a given set of subcubes (we denote it by PHC-COVER) to TT-MinDNF. PHC-COVER can be seen as a geometric version of the general SET-COVER problem. The second component of the proof is a reduction from a multi-prover proof system with certain simple properties to PHC-COVER. This reduction follows the key ideas of the inapproximability result for SET-COVER by Lund and Yannakakis [LY94] and its generalization by Bellare et al. [BGLR93]. Finally, a low-error PCP by Raz and Safra [RS97] is used to obtain a multi-prover proof system with the desired properties, yielding the inapproximability result for TT-MinDNF. The low-error PCP of Raz and Safra was used in a similar way to obtain hardness of approximating within (log n) for SET-COVER under the assumption that P = NP [RS97].
Besides the main reduction in Section 4.4.1, we show a reduction from hypergraph vertex cover problem to PHC-COVER. The reduction is based on families of sets in which none of the sets is covered by k others. This reduction together with a recent result by Dinur et al. [DGKR05] implies the same inapproximability result for TT-MinDNF under a stronger assumption NP  DTIME(nlog(n)). This reduction is more direct and simple than both the reduction given in Section 4.4.1 and the reduction of Allender et al. [AHM+06] (which gives the same result).
The rest of the chapter is organized as follows. In Section 4.3 we show that TTMinDNF and two other covering problems on the hypercube can be reduced (in an approximation-preserving way) to PHC-COVER. Then, in Section 4.4, PHC-COVER is reduced to the hypergraph vertex cover and the low-error PCP by Raz and Safra [RS97] giving the desired hardness of approximation results. In Section 4.5 we prove the abovementioned hardness result for proper learning with MQs.
36

4.2 Preliminaries
4.2 Preliminaries
A Boolean partial function is a function f : {0, 1}d  {0, 1, }. We say that a Boolean function g is consistent with a partial function f , if for every a  {0, 1}d such that f (a) = , g(a) = f (a). A subcube of a Boolean hypercube is a set I1 × I2 × · · · × Id where for each j, Ij  {0, 1}. We identify each subcube with a term whose satisfying assignments are exactly the elements of the subcube.
The size of a DNF formula is the number of terms in it. The DNF-size of a function is the size of a minimum DNF formula equal to the function. Given the truth table of a function f the problem of finding the DNF-size of f is denoted TT-MinDNF. When f is a partial function the problem of finding the size of a minimum DNF consistent with f is referred to as PTT-MinDNF.
The problem of finding the size of a minimum cover of the d-dimensional Boolean hypercube with subcubes represented by the terms in T = {Ti}mi=1 is referred to as HCCOVER. We also consider the following generalization of HC-COVER. Given a set of terms as above and a set of points S  {0, 1}d find the size of a minimum cover of S by terms in T . We refer to this generalized version as PHC-COVER. We say that PTTMinDNF(f ) = C (HC-COVER(T ) = C, or PHC-COVER(S, T ) = C) if the size of a minimum DNF formula consistent with f (or, respectively, a cover for an instance T or (S, T )) equals C.
In all the above problems, we assume that the input is of size poly(2d) (it cannot be larger as there are 3d different terms). For PHC-COVER and HC-COVER the input can, in certain situations, be represented more concisely. However, for consistency with the definition of the usual set cover problem, we assume that all the 2d points of the cube are given explicitly as part of the input. Hardness results for this setting imply hardness results for more concise representations of the same problem.
We use a dot `·' to denote concatenation of bits and bit vectors. Unless defined otherwise we use a subscript to refer to an individual coordinate of a vector and use [n] to denote the set {1, 2, . . . , n}. Let par() denote the parity function defined for any bit vector. For any Boolean variable v and b  {0, 1}, let v(b) = v, if b = 1 and v(b) = v¯, if b = 0. Similarly, for a vector of variables w  V r and a vector a  {0, 1}r, we define eq(w, a) = ir wi(ai), or simply the term that checks if variables of w are set to a.
Our learning model is Valiant's well-known Probably Approximately Correct (PAC) learning model [Val84] defined in Section 2.2. A proper learning algorithm for a representation class F is referred to as strongly proper if, it outputs a hypothesis h  F such that F-size(h)  F-size(c), where c is the target concept.
37

4.3 Hypercube Reductions

4.3 Hypercube Reductions
Below we show that the covering problems defined in the previous section have similar approximation complexity by describing efficient reductions from PHC-COVER to PTTMinDNF, from PTT-MinDNF to TT-MinDNF, and from TT-MinDNF to HC-COVER. Our reductions preserve the approximation ratio and increase the number of variables by a small constant factor.

4.3.1 From PHC-COVER to PTT-MinDNF

It can be easily seen that PTT-MinDNF is an instance of PHC-COVER. For the other direction our reduction converts an instance of PHC-COVER given by a set S  {0, 1}d and a set of terms T , to an instance of PTT-MinDNF given by a function f where each element of T corresponds to a prime implicant of f . A prime implicant of a function f is a term T such that T is consistent with f (that is it does not accept points where f equals 0) and is not covered properly by another term consistent with f . Any DNF formula consistent with f can always be easily converted to a DNF formula of the same size that includes only prime implicants of f . Therefore, any DNF formula for f produced by our reduction corresponds to a cover of S by terms from T . We now provide the details of this mapping.

Theorem 4.3.1 There exists a polynomial-time algorithm that given an instance (S, T ) of PHC-COVER over d variables produces the truth table of partial function f over 2d variables such that (S, T ) has a cover of size C if and only if there exists a C-term DNF formula consistent with f .

Proof: For a point x  {0, 1}d, let p[x] denote a point in {0, 1}2d equal to x · x¯ (that is, x

on first d coordinates and the bit complement of x on coordinates from d + 1 to 2d). For a

term T over d variables, let p[T ] denote a term over 2d variables in which all the positive

literals are the same as in T while each negative literal x¯i is replaced by literal xd+i. Let

g(y) = T T p[T ](y). Then we map (S, T ) to the instance of PTT-MinDNF given by the

following function:

  0 if g(y) = 0

f (y) = 

1 

if y = p[x] and x  S otherwise

Let S  T be a set of C terms such that S  T S T . We claim that h(y) = T S p[T ](y) is consistent with f . Let y be a point in {0, 1}2d. If f (y) = 0, then g(y) = 0 and so
h(y) = 0. If f (y) = 1 then there exists x such that y = p[x] and x  S. Therefore, there

38

4.3 Hypercube Reductions
exists T  S such that T (x) = 1, which is equivalent to p[T ](p[x]) = 1. In particular, h(y) = 1, which completes the proof of the claim.
For the other direction, let h = ZZ Z be a C-term DNF formula consistent with f . For a term Z  Z, let y be the point with the minimum number of 1's accepted by Z. By the consistency with f , we get that f (y) = 0 and hence g(y) = 1. Therefore let m(Z) be a term of g that covers y and let TZ  T be some term for which m(Z) = p[TZ]. We claim that Z  m(Z). If for a point z, Z(z) = 1 then for every i  2d, if zi = 0 then yi = 0. This is true since if zi = 0 then Z does not include literal xi and, therefore, by the minimality of y, yi = 0. The term m(Z) = p[TZ] is monotone and, therefore, if it covers y then it covers z. This implies the claim that Z  m(Z).
Define T = {TZ | Z  Z}. If x  S, then f (p[x]) = 1 and therefore, there exists Z  Z such that Z(p[x]) = 1. This, in turn, implies that TZ(x) = 1, that is, T is a set of C subsets from T that covers S.
4.3.2 From PTT-MinDNF to TT-MinDNF
The next step is an approximation preserving reduction from a partially-specified truth table to a fully-specified one. A part of this reduction is based on Gimpel's reduction from partially to fully specified truth-table [Gim65].
Theorem 4.3.2 There exists an algorithm that given the truth table of a partial function f on d variables and an integer r  1 produces the truth table of partial function g over d + r + 2 variables such that there exists a C-term DNF consistent with f if and only if there exists (2r-1C + |f -1()|)-term DNF formula equal to g. The algorithm runs in time 2O(r+d).
Proof: The reduction has two components. The first component is Gimpel's reduction [Gim65]. It converts f to a fully-specified function that has a distinct prime implicant for each point x where f equals  thereby forcing any consistent DNF to include a term for every  of the original function. The addition of new terms does not preserve approximation factors and therefore the second component replicates f 2r-1 times to ensure that the size of the cover is still dominated by the original problem (for large enough r). For a vector in {0, 1}d+r+2, we refer to its first d coordinates as x1, . . . , xd; its next r variables as y1, . . . , yr; and its last two variables as z1, z2. We define Boolean function g over {0, 1}d+r+2 as follows:
39

4.3 Hypercube Reductions



 g(xyz) = 

par(y) 1
0

if f (x) = 1 and z = 11 if f (x) =  and (z = par(x) · ¬par(x) or z = 11) otherwise

Let S = f -1(). We claim that there exists a C-term DNF consistent with f if and only if there exists a (2r-1C + |S|)-term DNF equal to g. For the simpler direction, let S be a
set of C terms such that h(x) = T S T (x) is consistent with f . For b  {0, 1} we define sw-z(b) = z2-b (that is, sw-z switches between z1 and z2 according to b). We claim that

g(xyz)  (h(x)  par(y)  z1  z2) ((f (x) = )  sw-z(par(x))) .

By definition, the expression R(xyz)  (f (x) = )  sw-z(par(x)) equals to g(xyz) on all

points with z = 11. In addition, for z = 11, R(xy · 11)  (f (x) = ). The expression

L(xyz) = h(x)  par(y)  z1  z2 only covers points for which z = 11 and L(xy · 11) =

h(x)  par(y). Therefore, by the consistency of h with f , L(xy · 11) equals to par(y)

when f (x) = 1 and does not cover any points for which f (x) = 0. Altogether, g(xyz) 

L(xyz)  R(xyz).

Expressions L(xyz) and R(xyz) are not in DNF. To convert them to DNF we note

that

par(y) 

eq(y, a)

a{0,1}r ,par(a)=1

and (f (x) = )  eq(x, a) .
aS

Therefore





g(xyz)  

T  eq(y, a)  z1  z2

T S,a{0,1}r,par(a)=1

eq(x, a)  sw-z(par(a)) ,
aS
that is, g has a DNF expression with C2r-1 + |S| terms. For the other direction, let T be a set of C2r-1 + |S| terms such that g(xyz) =
T T T (xyz). For each a  S, let a  T be a term that accepts point
p(a) = a · 0r · par(a) · ¬par(a) .

40

4.3 Hypercube Reductions
We first prove that a contains all the literals of eq(x, a). If a does not contain literal xi(ai), then let ai be the point a with the i-th bit negated. Clearly a will also accept the point ai · 0r · par(a) · ¬par(a). But this contradicts the consistency with g, since par(a) = ¬par(ai). It follows that for each a  S, there is a distinct term in S that can only accept points with x part in S. We denote this set of terms by T .
Now let D = {p | p  {0, 1}r, par(p) = 1}, p be any point in D and a be any point such that f (a) = 1. Then, by definition of g, there exists a term p,a that accepts the point a·p·11. We claim that p,a contains all the literals of eq(y, p). If p,a does not contain literal yi(pi), then let pi be the point p with the i-th bit negated. Clearly p,a will also accept the point a·pi ·11. But this contradicts the consistency with g, since g(a·pi ·11) = par(pi) = 0. Now let Tp = {p,a | f (a) = 1} and let hp(x) = T Tp T (x · p · 11). We claim that hp(x) is consistent with f . This is true since if f (a) = 1 then p,a  Tp and p,a(a · p · 11) = 1. If f (a) = 0 then g(a · p · 11) = 0 and since Tp  T then no term in Tp can accept point a · p · 11. As we have shown, all the Tp's for p  D are disjoint and they are clearly disjoint from T  (since 0r  D). Therefore |T |  |S| + pD |Tp|. As |D| = 2r-1 we get that there exists p such that |Tp|  C and hence hp is a C-term DNF formula consistent with f .
By a suitable choice of r in Theorem 4.3.1 one easily obtains the following corollary (the proof is omitted for brevity):
Corollary 4.3.3 If TT-MinDNF can be approximated within h(d) in time t(d) then PTTMinDNF can be approximated within h(2d + log d) + 1 in time t(2d + log d) + 2O(d).
4.3.3 From TT-MinDNF to HC-COVER
We now give a simple reduction proving that finding a minimum cover of the whole hypercube by terms from a restricted set T is not substantially easier than finding a minimum cover of a subset of the hypercube. Note that this reduction is not required as a step in our main result and is provided to extend our hardness of approximation results to HC-COVER.
Theorem 4.3.4 There exists an algorithm that, given the truth table of a function f on d variables and an integer r  1, produces a set of terms T over d + r variables such that there exists a C-term DNF expression equal to f , if and only if, {0, 1}d+r can be covered by 2rC + |f -1(0)| terms from T . The algorithm runs in time 2O(r+d).
Proof: The idea of the proof is to create T that contains all the terms consistent with f and terms that cover ¬f . As in the proof of Theorem 4.3.2, we will replicate f many times to preserve the approximation ratio .
41

4.4 Hardness of Approximation

Our instance of the HC-COVER problem is over d + r variables where we refer to the first d variables as x1, . . . xd and to the next r variables as y1, . . . , yr. Let T f be the set of all the terms consistent with f (we can assume that it includes only the prime implicants of f but this is not essential). For p  {0, 1}r let Tpf = {T  eq(y, p) | T  T f }, let S = f -1(0) and T ¬f = {eq(x, a) | a  S}. Then we define





T = T ¬f



Tpf  .

p{0,1}r

We claim that there exists a C-term DNF equal to f , if and only if, there exists a set S  T of size C2r + |S| that is a cover of {0, 1}r+d. Let Sf be a set of C terms such that
T Sf T = f . Then it is clear that

S = T ¬f T  eq(y, p) | p  {0, 1}r, T  Sf

is a cover of {0, 1}r+d, has size C2r + |S|, and includes only terms from T . For the other direction, let S  T be a cover of {0, 1}d+r. We observe that the only
way to cover S × {0, 1}r is by including all the terms of T ¬f in S. For each p  {0, 1}r, let Sp = S  Tpf . Only terms in Sp cover the subset f -1(1) × {p} and therefore hp(x) =
T Sp T (x · p) equals exactly f (x). All the Sp's are mutually disjoint and are disjoint from T ¬f . Therefore if |S|  C2r + |S|, then DNF-size(f )  C.
As with Theorem 4.3.2, we obtain the following corollary.
Corollary 4.3.5 If HC-COVER can be approximated within h(d) = o(d) in time t(d), then TT-MinDNF can be approximated within h(2d+log d)+1 in time t(2d+log d)+2O(d).

We summarize the reductions in this section by the following equivalence theorem: Theorem 4.3.6 If there exists a constant 0 <   1 such that there is no polynomial-time algorithm approximating PHC-COVER, to within a factor d then there is no polynomialtime algorithm approximating TT-MinDNF, PTT-MinDNF and HC-COVER to within a factor (d).
4.4 Hardness of Approximation
Below we prove hardness of approximating TT-MinDNF by presenting two reductions to PHC-COVER both showing hardness of approximating within a factor of d for a constant  > 0. The first one is a reduction from the problem of finding a vertex cover of a kuniform hypergraph. It is simple (relative to the other reduction and the reduction by
42

4.4 Hardness of Approximation
Allender et al. [AHM+06]) but relies on a stronger assumption NP  DTIME(nlog(n)). The second one is a general reduction from one-round multi-prover proof systems. When used with a low-error PCP it gives NP-hardness of approximating within a factor of d. In addition, it makes an explicit connection between  and standard parameters of a proof system that might be useful in obtaining inapproximability factors with specific or optimal exponent .
4.4.1 Reduction from Hypergraph Vertex Cover to PHC-COVER
A k-uniform hypergraph H = (V, E) consists of a set of vertices V and a collection E of k-element subsets of V called hyperedges. A vertex cover of H is a subset S  V such that every hyperedge in E intersects S. The Ek-Vertex-Cover problem is the problem of finding a minimum size vertex cover on a k-uniform hypergraph. The problem is alternatively called the minimum hitting set problem with sets of size k and is equivalent to the set cover problem where each element of the universe occurs in exactly k sets.
The first explicit hardness result shown for Ek-Vertex-Cover was due to Trevisan who showed an inapproximability factor of k1/19 [Tre01] (and a comparable result is implicit in Feige's proof of inapproximability of SET-COVER [Fei98]). As we aim at obtaining a large inapproximability factor for covering the hypercube, we are interested in results that hold for large values of k. The first result stating the range of k explicitly is due to Dinur et al. [DGKR05] who give the following theorem.
Theorem 4.4.1 There exists some c > 0 such that unless NP  DTIME(nlog log(n)), there is no polynomial-time algorithm for approximating Ek-Vertex-Cover for k  (log M )1/c to within a factor of k/2 - 0.01, where M is the number of hyperedges in the k-uniform hypergraph.
Remark 4.4.2 It can be easily seen from the proof of this theorem, that the number of vertices N is smaller than M and therefore the result can be stated with the number of vertices N in place of M .
Union-free Families
A family of sets F is called k-union-free if A0  A1  A2  · · ·  Ak for all distinct A0, A1, . . . , Ak  F . They were introduced by Kautz and Singleton [KS64] (and then rediscovered by Erd¨os et al. [EFF85]). A family of sets F is a (s, )-combinatorial design if each set in F has size s and the intersection of any two sets in F has size at most . If < s/k then (s, )-combinatorial design is k-union-free. The first efficient construction of combinatorial designs was given by Nisan and Widgerson [NW94]. For our purposes,
43

4.4 Hardness of Approximation
k-union-free families can be obtained by derandomizing a straightforward randomized construction using the method of conditional probabilities (cf. [Vad04, Lecture 21]).
Theorem 4.4.3 There exists a k-union-free family of sets over [d] of size m for d = O(k2 log m). Moreover, such F can be constructed in time poly(m, d).
Simple Reduction to PHC-COVER
Below we present a reduction from SET-COVER with each point occurring in k sets to PHC-COVER.
Theorem 4.4.4 There exists a polynomial-time algorithm that, given a k-uniform hypergraph H = (V, E) with |V | = N , produces an instance (S, T ) of PHC-COVER over d = O(k2 log N ) variables such that H has a vertex cover of size C, if and only if, (S, T ) has a cover of size C. The algorithm runs in time O(N 2d).
Proof: We first transform the k-uniform hypergraph vertex cover problem to its dual set cover problem with each point occurring in k sets. That is, for v  V , let Sv = {e | e  E, v  e} and S = {Sv | v  V }. Then (E, S) is the equivalent instance of SET-COVER. Let F = {Pv}vV be a k-union-free family (with N elements indexed by nodes in V ). By Theorem 4.4.3, such F exists and can be efficiently constructed for d = O(k2 log N ). For any set P  [d], let (P ) be a characteristic vector of P , that is vector with (P )i = 1 when i  P and (P )i = 0, otherwise. For each e  E, let xe = (vePv). We define T = {eq(x, (Pv)) | v  V }, and define S = {xe | e  E}.
To prove the correctness of this reduction all we need to show is that for each e  E and v  V , eq(x, (Pv)) covers xe, if and only if, e  Sv or, in other words, v  e. If v  e then Pv  uePu and, therefore xei = 1 for all i  Pv. This implies that eq(x, (Pv)) = iPv xi accepts xe. On the other hand, if v  e then for each u  e, by the properties of F , Pv  uePu. This implies that eq(x, (Pv)) will not accept xe.
Corollary 4.4.5 There exists a constant  > 0 such that, unless NP  DTIME(nlog(n)), there is no polynomial-time algorithm approximating PHC-COVER to within a factor d, where d is the number of variables in the PHC-COVER instance.
Proof: Given an instance of SAT on n variables, the reduction of Theorem 4.4.1 produces an instance of Ek-Vertex-Cover on N = nO(log log n) vertices for k = (log N )1/b, where b = max{3, c}. The gap in vertex cover sizes between positive and negative instances is k (  1/2). Then reduction in Theorem 4.4.4 will produce an instance of PHC-COVER over d = O(k2 log N ) = O((log N )1+2/b) with the same gap of k, that in terms of d, is
44

4.4 Hardness of Approximation

(d1/(b+2))

>

d

for

any

constant



<

1 2+b

(and

large

enough

d).

The

running

time

of

the

reduction and the produced instance are both bounded by

2O(d) = 2O((log N )1+2/b) = nO((log n)2/b(log log n)1+2/b) = O(nlog n)

(since b  3).

4.4.2 Reducing from Multi-prover Proof Systems
Below we prove hardness of approximating PHC-COVER by presenting a direct reduction from one-round multi-prover proof systems with certain properties to PHC-COVER. We then obtain the claimed result by coupling our reduction with the low-error PCP for NP due to Raz and Safra [RS97]. The reduction simulates the reduction from SET-COVER given by Bellare et al. [BGLR93] (which is a simple generalization of the reduction by Lund and Yannakakis [LY94]) on the Boolean hypercube. That is, the instance of PHCCOVER we create is the same as the instance of SET-COVER created in the reduction of Bellare et al. [BGLR93]. Therefore the analysis we give follows directly from the analysis of Lund and Yannakakis [LY94].
Following the definition by Bellare et al. [BGLR93] we distinguish five important parameters of one-round multi-prover proof systems and define the class MIP1( r, p, a, q, ) as follows:
Definition 4.4.6 L  MIP1( r(n), p(n), a(n), q(n), (n)) if there exists a probabilistic polynomial-time verifier V , communicating with p(n) provers such that for every x  {0, 1}n the verifier:
· tosses r(n) random coins obtaining r  {0, 1} r ,
· computes p(n) questions q(r)1, . . . , q(r)p(n) each of length at most q(n),
· for each i, asks the i-th prover question q(r)i and gets p(n) answers a1, . . . , ap(n) each of length at most a(n),
· computes a predicate V (x, r, a1, . . . , ap(n)) and accepts if and only if it is 1,
· has perfect completeness: if x  L then P¯ = P1, . . . , Pp(n) such that Prr[V accepts when interacting with P¯] = 1 ;
· has soundness error at most (n): if x  L then P¯ = P1, . . . , Pp(n), Prr[V accepts when interacting with P¯]  (n).

45

4.4 Hardness of Approximation

Our reduction will rely on three simple properties of V . The functionality property requires that for each x  {0, 1}n and each a1  {0, 1} a there is at most one vector (a2, a3, . . . , ap) such that V (x, r, a1, a2, . . . , ap) = 1 for some r  {0, 1} r . The second property, uniformity, requires that for each i  [p], queries of V to prover i are uniformly distributed over the set Qi of all the possible queries to prover i. The last, equality of question space sizes, requires that |Q1| = |Q2| = · · · = |Qp|. Following Bellare et al. [BGLR93] we call V canonical if it has these three properties.
Similarly, we distinguish analogous parameters for a PCP system. We denote the class PCP( r(n), p(n), a(n), q(n), (n)) to be the class of languages decidable by a PCP verifier V that uses r(n) random bits, generates p(n) questions of length r(n), gets answers of length a(n), has perfect completeness and soundness error (n).

Packing a Proof System into the Boolean Hypercube The main tool for creating an approximation gap is a set system

Bm,l = (B; C1, C2, . . . , Cm)

where m, l are positive integers and for each i  [m], Ci  B. This set system has the
property that if I  [m] and |I|  l, then no union iI Di covers B, where Di equals Ci or its complement.

Lemma 4.4.7 ([LY94]) There exists Bm,l = (B; C1, C2, . . . , Cm) for |B| = O(22lm2) and it can be constructed in time polynomial in |B|.

The main construction of this section is given in the following lemma.

Lemma 4.4.8 If L  MIP1( r, p, a, q, ) with a canonical verifier V , then there exists an algorithm A that given x, produces an instance of PHC-COVER (Sx, Tx) over d  r + p( q + 2 a) variables such that
· if x  L then PHC-COVER(Sx, Tx) = p|Q1|, where Q1 is the question space of the first prover.

·

if

xL

then

PHC-COVER(Sx, Tx) 

1 2

(2

)-1/p|Q1|.

Moreover, A runs in time polynomial in n and 2d.

Proof: We start by describing a way to map an answer from a prover to a subset. In this mapping the first prover is treated differently from the rest because of the functionality property of V . As before, let Qi  {0, 1} q denote the set of questions that V asks prover i and let Ai be the answer space of prover i. Set sa = |A2| + |A3| + . . . + |Ap| (note that |A1|

46

4.4 Hardness of Approximation

is not included) and let Bsa,l = (B; C1, C2, . . . , Csa) be a set system given by Lemma 4.4.7 for l to be specified later. We index the sets C1, C2, . . . , Csa by pairs (i, ai) for 2  i  p and ai  Ai. Let A = {(i, ai) | i  [p], ai  Ai} be the set of all possible answers (answers

from different provers correspond to different elements).

Now for each setting of a random string r  R = {0, 1} r and (i, ai)  A, we define a

subset C(r, i, ai)  B as follows.



C(r, i, ai) =

 

Ci,ai B \ (C2,a2


 · · ·  Cp,ap )

if i  2 if i = 1 and a2, . . . , ap, V (x, r, a1, a2, . . . , ap) = 1 otherwise

For a1  A1, C(r, 1, a1) is well-defined since V has the functionality property. The definition of C(r, i, ai) implies that if V (x, r, a1, a2, . . . , ap) = 1 then i[p]C(r, i, ai) = B, that is, answers from provers that cause the verifier to accept correspond to "small" covers. Bellare et al. [BGLR93] define the following instance of SET-COVER. The ground set equals to R × B and for every i  [p], qi  Qi, ai  Ai the set system includes a subset

Z(i, qi, ai) = {(r, b) | qi = q(r)i and b  C(r, i, ai)} ,

where qi = q(r)i means that V generates query qi to prover i on input x and random string r. In other words, the set system is Zx = {Z(i, qi, ai) | i  [p], qi  Qi, ai  Ai}.
We now show that exactly the same set system can be created on a hypercube of dimension d = r + p q + |A|. We refer to the first r variables of the Boolean cube {0, 1}d as yr,1, . . . , yr, r , the next p q variables as zi,j for i  [p] and j  [ q], and the last |A| variables as z(i,ai) for (i, ai)  A.
For every r  R and b  B, let z(r, b)  {0, 1}A be a Boolean vector of length |A| such that z(r, b)(i,ai) = 1 whenever b  C(r, i, ai). Furthermore, let [r, b] = r · q(r)1 · · · q(r)p · z(r, b). Let Sx = {[r, b] | r  R, b  B}. We now proceed to define the terms. For i  [p], qi  Qi, and ai  Ai, let T (i, qi, ai) be the term that checks that variables of i-th question equal to qi and that the variable corresponding to answer ai from prover i is set to 1, or formally
T (i, qi, ai) = eq(zi,1 · · · zi, q , qi)  z(i,ai) .
Let Tx = {T (i, qi, ai) | i  [p], qi  Qi, ai  Ai}. It is easy to verify that the term T (i, qi, ai) covers a point [r, b] if and only if qi = q(r)i and b  C(r, i, ai). Therefore the set system (Sx, Tx) corresponds exactly to the SET-COVER instance of Bellare et al. [BGLR93], where [r, b] corresponds to (r, b) and T (i, qi, ai) corresponds to Z(i, qi, ai).

47

4.4 Hardness of Approximation

The analysis of Lund and Yannakakis [LY94] can now be used to prove that for x  L,
PHC-COVER(Sx, Tx)  iP |Qi| = p|Q1| and for x  L, PHC-COVER(Sx, Tx)  (1 - lp)l · |Q1|. Therefore by setting l = (2 )-1/p we will get the stated inapproximability gap of (2 )-1/p/(2p). For completeness we provide the details of this analysis using the
notation of the above SET-COVER instance. First, let x  L and let P¯ be an honest deterministic prover. For qi  Qi denote by
Pi(qi) the answer given by Pi to query qi and set S = {Z(i, qi, Pi(qi)) | i  [p], qi  Qi}. For every point (r, b) and i  [p], let ai = Pi(q(r)i). By perfect completeness of V , V (x, r, a¯ ) = 1 and therefore C(r, 1, a1) = B \ (C2,a2  · · ·  Cp,ap), i.e, i[p]C(r, i, ai) = B. This means that for some j, b  C(r, j, aj) and therefore (r, b)  Z(j, q(r)j, aj). This means that S  Z is a collection of size i[p] |Qi| that covers R × B. By equality of question space sizes, |S| = i[p] |Qi| = p|Q1|.
Let x  L and S  Zx be a cover for R × B. For a random string r and a set C  B, denote by (r, C) the set {(r, b) | b  C} and let Sr = {Z(i, q(r)i, ai) | i  [p], Z(i, q(r)i, ai)  S}, in other words Sr includes the terms from S that cover (r, B). We say that r is good if |Sr|  l and bad otherwise. Let  be the fraction of good r's.
Claim 4.4.9 There exists a prover P¯ such that V will accept with probability /lp.
Proof: We define P¯ with the following strategy: prover Pi on query qi chooses ai from the set Aiqi = {a | Z(i, qi, a)  S} randomly and uniformly (this set cannot be empty). Note that for every r, i |Aiq(r)i| = |Sr|. If r is good, then |Sr|  l and hence there should exist a1, . . . , ap such that for every i  p, ai  Aiq(r)i and V (x, r, a1, . . . , ap) = 1. To prove this, assume that for every a1  A1q(r)1, there exists j(a1) such that V (x, r, a1, . . . , ap) = 1 but aj(a1)  Ajq((ar)1j)(a1) . Then

Z(1, q(r)1, a1)  (r, B) = (r, C(1,  (1, a1)) = (r, B \ Ci,ai )  (r, Cj(a1),aj(a1) ) .
i2

This implies that







Cj(a1),aj(a1) 

a1 A1q(r)1







Ci,ai  = B .

i2, aiAiqi

We obtained a union of at most l sets from Bsa,l that does not include a set and its

complement, and covers B. This contradicts the definition of Bsa,l, proving the existence

of a1, . . . , ap as above. For good r's and each i, |Aiq(r)i|  l and therefore, the probability that each Pi will answer with ai is at least l-p. Hence this strategy has success probability

at least /lp.

(Claim 4.4.9)

48

4.4 Hardness of Approximation

Claim 4.4.10 |S|  (1 - )l|Q1|.

Proof: For each bad r, |Sr|  l and therefore r |Sr| = (1 - )2 r l. On the other hand, each subset Z(i, qi, ai)  S appears once in all the sets for which qi = q(r)i. The uniformity property of V implies that each query qi is asked for exactly 2 r /|Qi| = 2 r /|Q1| different r's (the last equality follows from the equality of question space sizes property). This

implies that

|S |

=

|Qi| 2r

r

|Sr |



|Qi| 2r

(1

-

)2

rl

=

(1

-

)l|Q1|

.

(Claim 4.4.10)

By Claim 4.4.9 and soundness of V , we get that   ·lp. By Claim 4.4.10, this implies

that |S|  (1 - lp)l|Q1|.

(Lemma 4.4.8)

Obtaining Proof Systems with Canonical Verifiers
In this section, we show how to derive canonical multi-prover proofs systems from general PCPs for NP. The first step is obtaining a multi-prover system from a PCP. As shown by Bellare, Goldreich, and Safra, (their proof appears in Ta-Shma's paper [TS96]) the identity transformation of a PCP to an MIP (that is, just distributing p queries to p different provers) increases the soundness error of the proof system by a factor of at most pp. That is,
Lemma 4.4.11 ([TS96])

PCP( r(n), p(n), a(n), q(n), (n))  MIP1( r(n), p(n), a(n), q(n), pp (n)) .

The next step in our transformation is obtaining the functionality property. Lemma 4.4.12 If L  MIP1( r, p, a, q, ) with a verifier V , then

L  MIP1( r, p + 1, p a, p q, )

with a verifier V that has the functionality property.
Proof: To get a verifier V with the desired property, we add one more prover (which we place first in the enumeration). Given r, V uses V to generate questions q1, . . . , qp, asks all the "old" provers their respective questions, and asks the new prover question (q1, q2, . . . , qp). Given answers a1, . . . , ap from the "old" provers and an answer (a1, . . . , ap) from the new prover, V accepts if ai = ai for all i  [p], and V (x, r, a1, . . . , ap) = 1. We first observe that, by definition, V has the functionality property. Next, we observe that V interacts with the original p provers exactly as V does and accepts only when V does.

49

4.4 Hardness of Approximation
Therefore the soundness error of the new multi-prover system does not increase and, in particular, is at most . Perfect completeness is preserved since if the first prover answers his questions in the same way as the other p honest deterministic provers, then V will accept whenever V accepts. Finally, the bounds on the length of queries and answers grow by a factor of at most p.
Next we describe how to obtain the last two properties required to get a canonical verifier.
Lemma 4.4.13 If L  MIP1( r, p, a, q, ) with a verifier V , then
L  MIP1((p + 1) r, p, a, r + q, )
with a verifier V that has uniformity and "equality of answer space sizes" properties. Furthermore, if V has the functionality property then V is canonical.
Proof: For each qi  Qi, let Ri,qi denote the set of random strings for which V generates question qi for prover i. New verifier V uses V to generate questions q1, q2, . . . , qp and then asks questions ((q1, j1), (q2, j2), . . . , (qp, jp)) where ji is an element of [|Ri,qi|] chosen randomly, uniformly, and independently of other choices. It is easy to see that after this modification the sets of possible questions are all of the same size 2 r and the questions are distributed uniformly. These random bits can be disregarded by honest provers and therefore completeness is not changed. Clearly, randomly and independently chosen bits cannot help dishonest provers and therefore soundness error is still bounded by . Finally, the bound on questions size is at most r + q and the number of random bits required is at most (p + 1) r. The accepting predicate of V was not changed and thus functionality property is preserved in this transformation.
We can now combine these transformations with the following theorem due to Raz and Safra [RS97],
Theorem 4.4.14 For any   1/4, q(n)  log n there exist fixed positive constants br, bp, bq, b such that SAT  P CP (br log n, bp, a(n), bq log n, 2-b a(n)).
obtaining the following result:
Lemma 4.4.15 There exist fixed positive constants cr, cp, cq, c for which
SAT  MIP1(cr log n, cp, log log n, cq log n, log-c n)
with a canonical verifier.
50

4.5 Hardness of Proper PAC+MQ Learning over the Uniform Distribution
Proof: We start with the PCP from Theorem 4.4.14 and then apply Lemmas 4.4.11, 4.4.12, and 4.4.13 to get
SAT  MIP1((bp + 2)br log n, bp + 1, bp a(n), (bpbq + br) log n, bbpp 2-b q(n)) .
We now choose a(n) = (log log n)/bp and obtain the desired result for cr = (bp + 2)br, cp = bp + 1, cq = (bpbq + br), and any c > b /bp ("strictly greater" is to offset the constant factor bbpp).
We can now use the results from Sections 4.3 and 4.4.2 to summarize our inapproximabilily results for covering problems on the Boolean hypercube.
Theorem 4.4.16 (subsumes Th. 4.1.1) There exists a constant  > 0 such that, unless P = NP, there is no polynomial-time algorithm approximating TT-MinDNF, PTTMinDNF, HC-COVER, and PHC-COVER, to within a factor d = (log(N )), where d is the number of variables and N is the size of an instance.
By using our reduction from MIP to PHC-COVER(Lemma 4.4.8) with the canonicalverifier MIP obtained from the PCP of Raz and Safra [RS97] (Lemma 4.4.15), we get an inapproximability gap of (2 log n)c /cp/(2cp) for d  (cr + cpcq + cp) log n. This implies the claim for PHC-COVER. We use Theorem 4.3.6 to extend the result to TT-MinDNF, PTT-MinDNF and HC-COVER.
4.5 Hardness of Proper PAC+MQ Learning over the Uniform Distribution
We now show a simple application of the hardness of TT-MinDNF to the hardness of proper PAC learning of DNF expressions restricted to the uniform distribution over {0, 1}n. It is a very strong model in which, as proved by Jackson [Jac97], DNF expressions are learnable non-properly.
It has been observed by Allender et al. that TT-MinDNF naturally reduces to exact learning of DNF with MQs [AHPM04]. We further this observation by reducing TTMinDNF to PAC+MQ learning of DNF over the uniform distribution. We denote the uniform distribution over {0, 1}n by U .
Theorem 4.5.1 There exists a constant  > 0 such that, if there exists an algorithm A that for every Boolean function c and > 0, A, given access to EX(c, U ) and MEM(c), runs in time poly(n, s = DNF-size(c), 1/ ) and, with probability at least 3/4, outputs a DNF formula h of size at most log (s/ ) · s that -approximates c with respect to U , then NP = RP.
51

4.5 Hardness of Proper PAC+MQ Learning over the Uniform Distribution

Proof: We reduce from TT-MinDNF and let  be the constant from Theorem 4.1.1.

Given the truth table of a function f over d = log n variables, we let the target concept

be c(x) = f (x1 · · · xd). Clearly, s = DNF-size(c)  2log n = n. The definition of c(x) implies that EX(c, U ) and MEM(c) can be efficiently simulated given the truth table of

f . We then set = 1/(2n) and  = 1/2. A strongly proper algorithm on this input will

(with probability at least 1/2) produce in time polynomial in n = 2d a DNF formula h of

size

t  log (s/

)·s

that

1 2n

-approximates

c.

Now

we

choose

a

vector

y

of

length

n-d

randomly and uniformly and let hy be the projection of h to first d variables with the last

n - d variables set to y. We claim that with probability at least 1/2, f  hy. To see this,

note that

1 2n



Prx{0,1}n [c(x)

=

h(x)]

=

Ey{0,1}n-d

Prz{0,1}d [f (z) = hy(z)]

,

and

thus

for

at

least

1 2

of

y's,

Prz{0,1}d [f (z)

=

hy (z )]

=

0,

that

is,

f (z)

=

hy (z )

for

all z. For each y, the number of terms in hy is at most t and therefore with probability at

least 1/4, t approximates DNF-size(f ) within log (s/ ) = O(d).

52

Chapter 5
Attribute-Efficient and Non-adaptive Learning of DNF Expressions and Parities
In this chapter we study the problems of attribute-efficient PAC learning of parity functions and DNF expressions over {0, 1}n. We show that attribute-efficient learning of parities with respect to the uniform distribution is equivalent to decoding high-rate random linear codes from a low number of errors, a long-standing open problem in coding theory.
An algorithm is said to use membership queries (MQs) non-adaptively if the points at which the algorithm asks MQs do not depend on the target concept. We give the first non-adaptive and attribute-efficient algorithm for learning DNF with respect to the uniform distribution. Our algorithm runs in time O~(ns4/ ) and uses O~(s4 · log2 n/ ) nonadaptive MQs where s is the number of terms in the shortest DNF representation of the target concept. The algorithm improves on the best previous algorithm for learning DNF (of Bshouty et al. [BJT04]) and can also be easily modified to tolerate random persistent classification noise in MQs.
5.1 Introduction
The problems of PAC learning parity functions and DNF expressions are among the most fundamental and well-studied problems in machine learning theory. Along with running time efficiency, an important consideration in the design of learning algorithms is their attribute-efficiency. A class C of Boolean functions is said to be attribute-efficiently learnable if there is an efficient algorithm which can learn any function f  C using a number of examples which is polynomial in the "size" (description length) of the function f to be
53

5.1 Introduction
learned, rather than in n, the number of attributes in the domain over which learning takes place. Attribute-efficiency arises naturally from a ubiquitous practical scenario in which the total number of potentially influential attributes is much larger than the number of relevant attributes (i.e., the attributes on which the concept actually depends), whereas examples are either scarce or expensive to get.
Learning of DNF expressions and attribute-efficient learning of parities from random examples with respect to the uniform distribution are both long-standing challenges in learning theory. The lack of substantial progress on these questions has resulted in attempts to solve them in stronger learning models. The most well-studied such model is one in which a membership query oracle is given to the learner in addition to the example oracle. The learning algorithm may query this oracle for a value of the target function at any point of its choice. Jackson gave the first algorithm that learns DNF from membership queries (MQs) under the uniform distribution [Jac97] and later Bshouty, Jackson and Tamon gave a more efficient and attribute-efficient algorithm for learning DNF in the same setting [BJT99]. The first algorithm for attribute-efficient learning of parities using MQs is due to Blum, Hellerstein and Littlestone [BHL95], and their result was later refined by Uehara et al. [UTW97].
A restricted model of membership queries, which addresses some of the disadvantages of the MQ model, is the model in which MQs are asked non-adaptively. An algorithm is said to use MQs non-adaptively if the queries of the algorithm do not depend on the target concept (in our context we will often call it non-adaptive for brevity). In other words, the learning algorithm can be split into two stages. In the first stage, given the learning parameters, the algorithm generates a set S of queries for the membership oracle. In the second stage, given the answers to the queries in S, the algorithm produces a hypothesis (without further access to the oracle). An immediate advantage of this model (over the usual MQ model) is the fact that the queries to the membership oracle can be parallelized. This, for example, is crucial in DNA sequencing and other biological applications where tests are very time-consuming but can be parallelized (cf. [FKKM97, Dam98] and references therein). Another advantage of a non-adaptive learner is that the same set of points can be used to learn numerous concepts. This is conjectured to happen in the human brain where a single example can be used to learn several different concepts and hence systems that aim to reproduce the learning abilities of the human brain need to possess this property [Val94, Val00, Val06].
As it is detailed later, attribute-efficiency is easy to achieve using a simple technique that relies on adaptive MQs but there is no known general method to convert a learning algorithm to an attribute-efficient one using MQs non-adaptively. It is important to note that in the two practical applications mentioned above, attribute-efficiency is also a major
54

5.1 Introduction

concern. It is therefore natural to ask: which classes can be PAC learned attributeefficiently by non-adaptive MQs? We refer to this model of learning as ae.naMQ learning. This question was first explicitly addressed by Damaschke [Dam98] who proved that any function of r variables is ae.naMQ learnable when it is represented by the truth table of the function (requiring r log n + 2r bits). Later Hofmeister gave the first ae.naMQ algorithm for learning parities [Hof99] and Guijarro et al. gave an algorithm for learning functions of at most log n variables in the decision tree representation [GLR99]. But the question remains open for numerous other representations used in learning theory.

5.1.1 Previous Results

Attribute-efficient Learning of Parities. Blum et al. were the first to ask whether

parities are learnable attribute-efficiently (in the related on-line mistake-bound model)

[BHL95]. They also presented the first algorithm to learn parity functions attribute-

efficiently using MQs. Their algorithm is based on the following approach: first all the

relevant attributes are identified and then a simple (not attribute-efficient) algorithm

restricted to the relevant variables is used to learn the concept. Since then other algorithms

were proposed for attribute-efficient identification of relevant variables [BH98, GTT99].

All the algorithms are based on a binary search for a relevant variable given a positive and

a negative example. Binary search and the fact that queries in the second stage depend

on the variables identified in the first stage only allows for the construction of adaptive

algorithms via this approach. Uehara et al. gave several algorithms for attribute-efficient

learning of parities that again used adaptiveness in an essential way [UTW97].

Hofmeister gave the first ae.naMQ algorithm for learning parities based on BCH error-

correcting codes. When learning the class of parities on at most k variables his algorithm

has running time of O(kn) and uses O(k log n) non-adaptive MQs. While the complexity of

this algorithm is asymptotically optimal it is based on the relatively complex Berlekamp-

Massey algorithm for creating and decoding BCH codes [Mas69].

Little previous work has been published on attribute-efficient learning of parities from

random examples only. Indeed, the first non-trivial result in this direction has only recently

been given by Klivans and Servedio [KS04b]. They prove that parity functions on at most

k

variables

are

learnable

in

polynomial

time

using

O(n1-

1 k

log

n)

examples.

Learning DNF. Efficient learning of unrestricted DNF formulae under the uniform distri-

bution begins with a famous result by Jackson [Jac97]. The algorithm, while polynomialtime, is somewhat impractical due to the O~(ns10/ 12) bound on running time (where s is

the number of terms in the target DNF). By substantially improving the key components

of Jackson's algorithm, the works of Freund [Fre92], Bshouty et al. [BJT99], and Klivans and Servedio [KS03] resulted in an algorithm that learns DNF in time O~(ns6/ 2) and uses

55

5.1 Introduction
O~(ns4/ 2) MQs1. This algorithm is non-adaptive, but is also not attribute-efficient. Using the algorithm for identification of relevant variables by Bshouty and Hellerstein mentioned above, Bshouty et al. gave an attribute-efficient version of their algorithm running in time O~(rs6/ 2 +n/ ) and using O~(rs4 log n/ 2) adaptive MQs, where r is the number of relevant variables [BJT99].
Bshouty et al. give an algorithm for learning DNF expressions from examples generated by a random walk on the Boolean hypercube [BMOS03]. This model is more passive than non-adaptive MQs but the algorithm of Bshouty et al. is not attribute-efficient as it is an adaptation of the non-attribute-efficient algorithm Bshouty and Feldman [BF02]. In fact, it is information-theoretically impossible to learn anything non-trivial attribute-efficiently in this model.
5.1.2 Our Results
We give a simple and fast randomized algorithm for ae.naMQ learning of parities (Theorem 5.4.1) and provide a transformation that converts a non-adaptive parity learning algorithm into an algorithm for finding significant Fourier coefficients of a function while preserving attribute-efficiency and non-adaptiveness (Theorem 5.5.4). Using these components we give the first ae.naMQ algorithm for learning DNF expressions with respect to the uniform distribution (Theorem 5.6.8). It runs in time O~(ns4/ ) and uses O~(s4 log2 n/ ) MQs. The algorithm improves on the O~(ns6/ 2)-time and O~(ns4/ 2)-query algorithm of Bshouty et al. [BJT99]. In Theorem 5.7.3 we also show a simple and general modification that allows the above algorithm to efficiently handle random persistent classification noise in MQs (see Section 2.2.3 for the formal definition of the noise model). Earlier algorithms for learning DNFs that handled persistent classification noise were based on Jackson's DNF learning algorithm and therefore are substantially less efficient [JSS97, BF02].
Alongside our ae.naMQ algorithm for learning of parities we establish the equivalence between attribute-efficient learning of parities from random uniform examples and decoding high-rate random linear codes from a low number of errors, a long-standing open problem in coding theory widely believed to be intractable (Theorems 5.3.4 and 5.3.6). Thus we may consider this equivalence as evidence of the hardness of attribute-efficient learning of parities from random examples only. Previously hardness of attribute-efficient learning results were only known for specially designed concept classes [DGR99, Ser00].
The connection between attribute-efficient learning of parities by membership queries and linear codes was earlier observed by Hofmeister [Hof99]. His result allows to derive attribute-efficient parity learning algorithms from efficiently decodable linear codes with
1Bshouty et al. claimed sample complexity O~(ns2/ 2) but this was in error as explained in Remark 5.6.3.
56

5.2 Preliminaries
appropriate parameters. Our result can be seen as an adaptation of this connection to random and uniform examples. The restriction to the uniform distribution allows us to prove the connection in the other direction, giving the above-mentioned negative result for attribute-efficient learning of parities from random examples only.
5.1.3 Organization
In the next section we describe the models and tools that will be used in this work. In Section 5.3, we give the required background on binary linear codes and prove the equivalence between attribute-efficient learning of parities from random uniform examples and decoding high-rate random linear codes from a low number of errors. In Section 5.4, we show a simple algorithm for ae.naMQ learning of parities. Section 5.5 gives a way to convert a non-adaptive parity learning algorithm into an algorithm for finding significant Fourier coefficients of a function while preserving attribute-efficiency and nonadaptiveness, yielding an ae.naMQ algorithm for weakly learning DNF expressions. Then in Section 5.6 we describe our ae.naMQ algorithm for learning DNF expressions and in Section 5.7 we show how this algorithm can be modified to handle random persistent classification noise.
5.2 Preliminaries
For vectors x, y  {0, 1}n we denote by x  y the vector obtained by bitwise XOR of x and y; by [k] the set {1, 2, . . . , k}; by ei a vector with 1 in i-th position and zeros in the rest; by xi the i-th element of vector x. Dot product x · y of vectors x, y  {0, 1}n denotes i xiyi (mod 2) or simply vector product xyT over GF(2) (with vectors being row vectors by default). By weight(x) we denote the Hamming weight of x and we define dist(x, y) = weight(x  y).
5.2.1 PAC Learning
We study learning of Boolean functions on the Boolean hypercube {0, 1}n. Our Boolean functions take values +1 (true) and -1 (false). Our main interest are the classes of parity functions and DNF expressions. Recall that a parity function a(x) for a vector a  {0, 1}n is defined as a(x) = (-1)a·x. We refer to the vector associated with a parity function as its index and the Hamming weight of the vector as the length of the parity function. We denote the concept class of parity functions {a | a  {0, 1}n} by PAR and the class of all the parities of length at most k by PAR(k). We represent a parity function by listing
57

5.2 Preliminaries

all the variables on which it depends. This representation for a parity of length k requires

(k log n) bits.

For the standard DNF representation and any Boolean function f we denote by DNF-

size(f ) the number of terms in a DNF representation of f with the minimal number of

terms. In context of learning DNF this parameter is always denoted s. Our learning model

is Valiant's well-known PAC model [Val84] defined in Section 2.2. We are mostly interested

in learning with respect to the uniform distribution, denoted by U. When learning with

respect to U, EX(c, U) can be trivially simulated using MEM(c) and therefore EX(c, U) is

not used at all. We also briefly review the concepts of weak learning, attribute efficiency

and classification noise defined in Sections 2.2.2 and 2.2.3. We say that an algorithm

weakly

learns

F

if

it

produces

a

hypothesis

h

that

(

1 2

-

1 p(n,s)

)-approximates

(or

weakly

approximates) c for some polynomial p. An algorithm A is said to be attribute-efficient

if the number of examples (both random and received from the MQ oracle) it uses is

polynomial in the size of the representation of the target concept and 1/ . We say that a

variable xi is relevant for a function f if there exists y  {0, 1}n such that f (y) = f (y  ei).

The number of relevant variables of the target concept is denoted by parameter r.

We consider two standard models of noise in learning. The first one is the well-studied

random classification noise model introduced by Angluin and Laird [AL88]. In this model

for any   1/2 called the noise rate the regular example oracle EX(c, D) is replaced with

the faulty oracle EX(c, D). On each call, EX(c, D), draws x according to D, and returns

x, c(x) with probability  and x, ¬c(x) with probability 1 - . When  approaches

1/2 the result of the corrupted query approaches the result of the random coin flip, and

therefore the running time of algorithms in this model is allowed to polynomially depend

on

1 1-2

.

This model of noise is not suitable for corrupting labels returned by MEM(c) since a

learning algorithm can, with high probability, find the correct label at point x by asking

the

label

of

x

polynomial

(in

1 1-2

)

number

of

times

and

then

returning

the

label

that

appeared in the majority of answers. An appropriate modification of the noise model is

the introduction of random persistent classification noise by Goldman, Kearns and Shapire

[GKS93]. In this model, as before, the answer to a query at each point x is flipped with

probability 1 - . However, if the membership oracle was already queried about the value

of f at some specific point x or x was already generated as a random example, the returned

label has the same value as in the first occurrence (i.e., in such a case the noise persists

and is not purely random). If the learner does not ask for the label of a point more than

once then this noise can be treated as the usual independent random classification noise.

Fourier transform. The Fourier transform is a technique for learning with respect to

the uniform distribution (primarily) based on the fact that the set of all parity functions

58

5.2 Preliminaries
{a(x)}a{0,1}n forms an orthonormal basis of the linear space of real-valued function over {0, 1}n. This fact implies that any real-valued function f over {0, 1}n can be uniquely represented as a linear combination of parities, that is f (x) = a{0,1}n f^(a)a(x). The coefficient f^(a) is called Fourier coefficient of f on a and equals EU [f (x)a(x)]; a is called the index and weight(a) the degree of f^(a). Given the values of f on all the points of the hypercube {0, 1}n one can compute the values of all the Fourier coefficients {f^(a)}a{0,1}n using the Fast Fourier Transform (FFT) algorithm in time O(n2n) [CT65] (cf. [AHU74]). The same algorithm FFT also converts the set of all Fourier coefficients {f^(a)}a{0,1}n into the values of the function f on all the points of the hypercube. This transformation is called inverse Fourier transform. For further details on the technique we refer the reader to the survey by Mansour [Man94]. Randomized functions. Besides deterministic functions on {0, 1}n we will also deal with functions whose value on a point x is a real-valued random variable (x) independent of (y) for any y = x and of any previous evaluations of (x). To extend learning and Fourier definitions to this case we include the probability over the random variable  in estimations of probability, expectation and variance. For example, we say that a randomized function  -approximates f with respect to D if PrD,[f (x) = (x)]  1 - . Similarly, (a) = EU,[(x)a(x)].
5.2.2 Learning by Non-adaptive Membership Queries
We say that an algorithm A uses MQs non-adaptively if it can be split into two stages. The first stage, given all the parameters of learning, (n, and a bound on the size of the target concept), generates a set of points S  {0, 1}n. The second stage, given the answers from MEM(c) on points in S, i.e. the set {(x, c(x)) | x  S}, computes a hypothesis (or, in general, performs some computation). Neither of the stages has any other access to MEM(c). We note that in the general definition of PAC learning we did not assume that size of the target concept (or a bound on it) is given to the learning algorithm. When learning with adaptive queries a good bound can be found via the "guess-and-double" technique, but for non-adaptive algorithms we will assume that this bound is always given. To emphasize this we specify the parameters that have to be given to a nonadaptive algorithm in the name of the algorithm. Clearly the same "guess-and-double" technique can be used to produce a sequence of independent and non-adaptive executions of the learning algorithm.
The immediate consequence of non-adaptiveness is that in order to parallelize a nonadaptive learning algorithm only the usual computation has to be parallelized since all the MQs can be made in parallel. Non-adaptiveness is also useful when learning concepts from the same concept class in parallel. The fact that queries are independent of the
59

5.2 Preliminaries
target concept implies that same set of points can be used for learning different concepts. To achieve probability of success 1/2 in learning of all concepts we will have to learn with each concept with probability of success 1 - 1/(2 ). This implies that the number of points needed for learning might grow by a factor of log whereas in the general case times more examples might be required.
Results of Goldreich et al. imply that if one-way functions exist then the concept class of all polynomial circuits is not learnable even with respect to U and with access to a MQ oracle [GGM86, KV94a]. By modifying the values of each circuit to encode the circuit itself in a polynomial number of fixed points one can make this class learnable by non-adaptive MQs but not learnable from random and uniform examples only (the modification is very unlikely to be detected by random examples yet MQs to the fixed points will reveal the circuit). Similarly, by placing the encoding of the circuit in some location that is encoded in a fixed location, one can create a function class learnable by adaptive membership queries but not learnable by the non-adaptive ones (if one-way functions exist).
5.2.3 Learning by Non-adaptive Membership Queries
We say that an algorithm A uses MQs non-adaptively if it can be split into two stages. The first stage, given all the parameters of learning, (n, and a bound on the size of the target concept), generates a set of points S  {0, 1}n. The second stage, given the answers from MEM(c) on points in S, i.e. the set {(x, c(x)) | x  S}, computes a hypothesis (or, in general, performs some computation). Neither of the stages has any other access to MEM(c). We note that in the general definition of PAC learning we did not assume that size of the target concept (or a bound on it) is given to the learning algorithm. When learning with adaptive queries a good bound can be found via the "guess-and-double" technique, but for non-adaptive algorithms we will assume that this bound is always given. To emphasize this we specify the parameters that have to be given to a nonadaptive algorithm in the name of the algorithm. Clearly the same "guess-and-double" technique can be used to produce a sequence of independent and non-adaptive executions of the learning algorithm.
The immediate consequence of non-adaptiveness is that in order to parallelize a nonadaptive learning algorithm only the usual computation has to be parallelized since all the MQs can be made in parallel. Non-adaptiveness is also useful when learning concepts from the same concept class in parallel. The fact that queries are independent of the target concept implies that same set of points can be used for learning different concepts. To achieve probability of success 1/2 in learning of all concepts we will have to learn with each concept with probability of success 1 - 1/(2 ). This implies that the number of points needed for learning might grow by a factor of log whereas in the general case
60

5.3 Learning of Parities and Binary Linear Codes
times more examples might be required. Results of Goldreich et al. imply that if one-way functions exist then the concept class
of all polynomial circuits is not learnable even with respect to U and with access to a MQ oracle [GGM86, KV94a]. By modifying the values of each circuit to encode the circuit itself in a polynomial number of fixed points one can make this class learnable by non-adaptive MQs but not learnable from random and uniform examples only (the modification is very unlikely to be detected by random examples yet MQs to the fixed points will reveal the circuit). Similarly, by placing the encoding of the circuit in some location that is encoded in a fixed location, one can create a function class learnable by adaptive membership queries but not learnable by the non-adaptive ones (if one-way functions exist). Further details of these simple separations are left to the reader.
5.3 Learning of Parities and Binary Linear Codes
In this section we show that attribute-efficient learning of parities with respect to the uniform distribution from random examples only is likely to be hard by proving that it is equivalent to an open problem in coding theory. Unlike in the rest of the paper in this section and the following section parity functions will be functions to {0, 1}. To emphasize this we use  instead of .
5.3.1 Background on Linear Codes
We say that a code C is an [m, n] code if C is a binary linear code of block length m and message length n. Any such code can be described by its n × m generator matrix G as follows: C = {xG | x  {0, 1}n}. Equivalently, a code can be described by its parity-check matrix H of size m × (m - n) by C = {y | yH = 0m-n}. It is well-known that G·H = 0n×(m-n) and decoding given a corrupted message y is equivalent to decoding given the syndrome of the corrupted message. The syndrome equals to yH and the decoding consists of finding a vector e of Hamming weight at most w such that y  e = xG, where w = (d - 1)/2 and d is the distance of the code (cf. [vL98]). For a linear code C the distance equals to the Hamming weight of a non-zero vector with the smallest Hamming weight.
By saying that C is a random [m, n] code we mean that C is defined by choosing randomly, uniformly, and independently n vectors in {0, 1}m that form the basis of C. Alternatively, we can say that the generator matrix G of C was chosen randomly with each entry equal to 1 with probability 1/2 independently of others. We denote this distribution by Un×m. Some authors restrict the random choice of G's to matrices of full rank n. As we will see, this definitions would only make our proofs simpler.
61

5.3 Learning of Parities and Binary Linear Codes

Binary linear codes generated randomly meet the Gilbert-Varshamov bound with high

probability, that is, they achieve the best known rate (or n/m) versus distance trade-off

(cf. [Sud02]). However decoding a random linear code or even determining its distance

is a notorious open problem in coding theory. For example the McEliece cryptosystem

is based, among other assumptions, on the hardness of this problem [McE78]. Besides

that, while the average-case hardness of this problem is unknown, a number of worst-case

problems related to decoding linear codes are NP-hard (cf. [Bar97, Var97, Sud02]).

A potentially simpler version of this problem in which the errors are assumed to be

random and independent with some rate  (and not adversarial as in the usual definition)

is equivalent to learning of parities with random classification noise of rate , a long-

standing open problem in learning theory. In fact, in Section 6.4.1 we prove that when

learning parities from random and uniform examples, random classification noise of rate

 is as hard as adversarial noise of rate  (up to a polynomial blowup in the running

time). The only known non-trivial algorithm for learning parities with noise is a slightly

subexponential algorithm by Blum et al. [BKW00]. In our discussion  is very low (e.g.

log n

n

),

yet

even

for

this

case

no

efficient

noise-tolerant

algorithms

are

known.

Correcting a random linear [m, n] from up to w errors is defined as follows.

Definition 5.3.1 Input: An n×m binary generator matrix G randomly chosen according to Un×m and y  {0, 1}m. Output: x  {0, 1}n such that dist(xG, y)  w if there exists one.

A successful algorithm for this problem is an algorithm that would allow to correct up to w errors in a "good" fraction of randomly created linear codes. That is, with non-negligible probability over the choice of G, and for every y, the algorithm should produce the desired output. Note that the algorithm can only be successful when the code generated by G has distance at least 2w + 1.
For simplicity, we will usually assume a constant probability of success but all the results can be translated to algorithms having the success probability lower-bounded by a polynomial (in m) fraction.

5.3.2 The Reduction
The equivalence of attribute-efficient learning of parities with respect to the uniform distribution and decoding of random linear codes relies on two simple lemmas. The first one, due to Hofmeister [Hof99], is that the syndrome decoding of a linear code implies attribute-efficient learning of parities. We include it with a proof for completeness.
Lemma 5.3.2 (Hofmeister) Let H be a parity-check matrix of some [m, n] w-error correcting code C. Let A be an algorithm that for any y  {0, 1}m such that y = c  e where
62

5.3 Learning of Parities and Binary Linear Codes

c  C and weight(e)  w, given the syndrome yH, finds e. Then A learns PAR(w) over {0, 1}m given the values of an unknown parity on the columns of H.

Proof: The condition y = c  e for c  C implies that yH = eH. Therefore the syndrome

yH is equal to the vector eH =  e(H1),  e(H2), . . . ,  e(Hm-n) where Hi is the i-th column

of H. Therefore finding an error vector e of weight at most w using the syndrome yH is

the same as finding a parity of length at most w given the values of the unknown parity

on the columns of H.

This observation has lead Hofmeister to a simple

ae.naMQ algorithm for learning parities that uses the columns of the parity check matrix

of BCH code as MQs. We note that the converse of this lemma is only true if the learning

algorithm is proper, that is, produces a parity function in PAR(w) as a hypothesis.

To obtain the claimed equivalence for the uniform distribution we first need to prove

that generating a linear code by choosing a random and uniform parity check matrix (that

is, from Un×m-n) is equivalent to (or indistinguishable from) generating a linear code by

choosing a random and uniform generator matrix (that is, from Un×m). Let p(i, j) denote the probability that i vectors chosen randomly and uniformly from

{0, 1}j are linearly independent. Each i  1 linearly independent vectors span subspace

of size 2i and therefore there are 2j - 2i vectors that are linearly independent of them.

This implies that, p(i + 1, j) = p(i, j)(1 - 2-j+i). All vectors except for 0j form a linearly

independent set of size 1. Therefore p(1, j) = (1 - 2-j). Hence

p(i, j) = (1 - 2-j) · (1 - 2-j+1) · · · (1 - 2-j+i-1) .

Note that

p(i, j)  1 - 2-j - 2-j+1 - · · · - 2-j+i-1 > 1 - 2-j+i

(5.1)

and

for

i

=

j,

p(j, j)

=

1 2

p(j,

j

- 1)

>

1 2

(1

-

1 2

)

=

1 4

.

This means that for any i  j,

p(i, j) > 1/4.

Let Vn×m denote the distribution on matrices of size n×m resulting from the following process. Choose randomly and uniformly a m × (m - n) matrix H of rank m - n and

then choose randomly and uniformly a matrix G of size n × m of rank n such that GH =

0n×(m-n). To generate G's like this we find a basis b1, . . . , bn for the subspace of {0, 1}m

that is "orthogonal" to H in the standard (and efficient) way. Let G0 denote the matrix whose rows are the vectors b1, . . . , bn. It is easy to see that any matrix G of rank n such that GH = 0n×(m-n), can be represented uniquely as F · G0 where F is a matrix of size n × n and full rank (). Therefore we can generate G's as above by choosing randomly and

uniformly a matrix F of rank n. If we choose a random matrix F according Un×n, with probability at least p(n, n) > 1/4, it will have the full rank. We can repeatedly sample

63

5.3 Learning of Parities and Binary Linear Codes

from Un×n to get a full-rank F with any desired probability. This implies that we can generate a matrix according to Vn×m with probability 1 -  in time O(m3 log (1/)) (or

less if a non-trivial matrix multiplication algorithm is used).

All we need to prove now is that Vn×m is "close" to Un×m. More specifically, the sta-

tistical distance between two distributions D1 and D2 over X is defined to be (D1, D2) =

1 2

xX |D1(x) - D2(x)|. It is well known and easy to see that for any event E  X,

|PrD1[x  E] - PrD2[x  E]|  (D1, D2).

Lemma 5.3.3 The distribution Vn×m is uniform over matrices of size n × m and rank n. In particular, (Vn×m, Un×m)  2-m+n.

Proof: Let G be any matrix of size n × m with linearly independent rows. Its probability

under Un×m is Un×m(G) = 2-mn. When sampling with respect to Vn×m, G can be

obtained only if all the columns of H are "orthogonal" to rows of G, that is belong to a

linear subspace of {0, 1}m of dimension m - n. The total number of H's like these of rank

m - n is 2(m-n)2p(m - n, m - n) (as follows from ()) and the total number of matrices size

m×(m-n) of rank m-n is 2m(m-n)p(m-n, m). Therefore the probability of getting each

H

like

this

is

2-n(m-n)

p(m-n,m-n) p(m-n,m)

.

Given

H

the

total

number

of

matrices

of

size

n×m

and

rank n that are "orthogonal" to H is p(n, n)2n2 (as follows from ()) and therefore G will

be generated with probability 2-n2/p(n, n). Hence the total probability of G under Vn×m

is

Vn×m(G)

=

2-mn

p(m-n,m-n) p(m-n,m)p(n,n)

.

For

every i < j, p(j - i, j)p(i, i) = p(j, j).

Therefore

Vn×m(G) = 2-mn/p(n, m). This implies that Vn×m is uniform over matrices of size n × m

and rank n. The statistical distance between Vn×m and Un×m equals to

1 2

|Vn×m(G) - Un×m(G)| =



G{0,1}n×m



1 2

2-mn +

2-mn

1 p(n, m)

-

1



=

1 - p(n, m)

rank(G)<n

rank(G)=n

According to equation (5.1), 1 - p(n, m) < 1 - (1 - 2-m+n) = 2-m+n.

We can now

prove that decoding of random linear codes implies attribute-efficient learning of parities

from random examples only.

Theorem 5.3.4 Assume that there exists an algorithm RandDec that corrects a random linear [m, n] code from up to w errors with probability at least 1/2 +  for any constant . Then PAR(w) over {0, 1}m is efficiently learnable from m - n random examples.

Proof: Let  e  PAR(w) be the unknown parity function and z1, z2, . . . , zm-n be random and uniform examples given by the example oracle. Let H be the m × (m - n) matrix

64

5.3 Learning of Parities and Binary Linear Codes

whose column i is equal to zi for each i  m - n. If H does not have rank m - n we return 0m. Otherwise let G be a random matrix such that GH = 0n×(m-n) generated as
in the description of Vn×m for  = /2. The values of  e on zi's give us the vector eH. Let y be any solution to the linear equation yH = eH. Clearly (y  e)H = 0m-n and

therefore y  e equals to xG for some x  {0, 1}n. This means that RandDec (if successful)

will output x on input G and y. By the definition of x, e = xG  y, giving us the desired

parity function.

To analyze the success probability of the algorithm we observe that the procedure above

generates G according to Vn×m with probability at least p(m - n, m)(1 - /2)  1 - 2-n - /2. According to Lemma 5.3.3, the statistical distance between the G generated as above

and Un×m is at most 2-m+n. RandDec is successful with probability 1/2 +  and therefore our algorithm will succeed with probability at least 1/2 +  - (/2 + 2-n + 2-m+n)  1/2.

The transformation above produces an attribute-efficient algorithm only if m - n is

polynomial in w and log m. According to the Gilbert-Varshamov bound, a random linear

code

will, with high probability,

have

distance

d

=

(

m-n log m

).

Therefore if the number of

errors that RandDec can correct is at least w = d errors for some constant  > 0 then the

sample complexity of learning a parity of length at most w over m variables would equal

O(w1/ log m). Therefore such an algorithm could be used to obtain an attribute-efficient

algorithm for learning parities.

We have noted previously that using a parity learning algorithm to obtain a syndrome

decoding algorithm requires the parity learning algorithm to be proper. When a distribu-

tion over examples is not restricted it is unknown whether proper learning of parities is

harder than non-proper. Fortunately, when learning with respect to the uniform distribu-

tion any learning algorithm for parities can be converted to a proper and exact one (that

is, with a hypothesis equal to the target function). We include a proof of this folklore fact

for completeness.

Fact 5.3.5 Let A be an algorithm that learns PAR(k) in time t(n, k, ) and with sample
complexity s(n, k, ). Then there exists a probabilistic algorithm A that learns PAR(k) properly and exactly in time t(n, k, 1/5) + O~(nk) and using s(n, k, 1/5) samples.

Proof: We assume for simplicity that if A is probabilistic then it succeeds with probability at least 3/4. Let h be the output of A when running on an unknown parity  e  PAR(k) with = 1/5. Given h that is correct on 4/5 of all the points we can use it simulate membership queries to  e(x) as follows. Let y  {0, 1}n be any point and let x be a randomly and uniformly chosen point. Then h(x) =  e(x) with probability at least 4/5 and h(x  y) =  e(x  y) with probability at least 4/5. Therefore with probability at least 3/5, h(x)  h(x  y) =  e(x)   e(x  y) =  e(y). We can increase the confidence in the

65

5.4 A Fast Randomized Algorithm for ae.naMQ Learning of Parities

label to 1 -  by repeating this procedure for O(log (1/)) independent x's. Given these

membership queries we can use a proper and exact MQ algorithm for learning PAR(k). A number of such algorithms are known running in time O~(nk) and using O(k log n) MQs

(including AEParityStat(k) given in Theorem 5.4.1). In order to get correct answers to

all the membership queries with probability at least 3/4 we need each of the MQs to be

correct

with

probability

1-

for



=

(

k

1 log

n

).

This

means

that

making

O(k log n)

MQs

will take O(nk log n log (k log n)) = O~(nk) steps. Altogether we get algorithm A that

succeeds with probability at least 1/2 and has the claimed complexity bounds. We can

now assume that algorithms for learning parity with respect to the uniform distribution

are proper and exact (and in particular do not require parameter ) and use this to obtain

the other direction of the equivalence.

Theorem 5.3.6 Assume that there exists an algorithm AELearnParU (k) that efficiently learns PAR(k) over {0, 1}m using at most q(m, k) random examples. Then there exists an algorithm RandDec that corrects a random linear [m, m - q(m, k)] code from up to k errors with probability at least 1/2 -  for any constant  > 0.

Proof: Let G and y be the input of RandDec, n = m - q(m, k), x be the vector for which y = xG  e where weight(e)  k. If G is not of rank n we just return the vector 0n. Otherwise let H be a random matrix such that GH = 0n×(m-n) generated as rank m - n we return 0m. Otherwise let G be a random matrix such that GH = 0n×(m-n) generated as in the description of Vn×m for  = /2 (with the roles of G and H reversed).
The syndrome yH is equal to eH and gives the values of  e on q(m, k) columns of H. We feed these columns as random examples to AELearnParU (k) and obtain  e from it (if AELearnParU (k) is successful). Given e we obtain x by solving the system of linear equations xG = y  e. To analyze the success probability of the algorithm we observe
that the procedure above generates H according to Vm×(m-n) with probability at least p(n, m)(1 - /2)  1 - 2-q(m,k) - /2. According to Lemma 5.3.3, the statistical distance between H's generated as above and Um×(m-n) is at most 2-m+(m-n) = 2-n. Therefore AELearnParU (k) will succeed with probability at least 1/2-2-n. This implies that RandDec will return the correct x with probability at least 1/2 - (2-m+q(m,k) + 2-q(m,k) + /2) 
1/2 - .

5.4 A Fast Randomized Algorithm for ae.naMQ Learning of Parities
We next present a simple randomized algorithm for ae.naMQ learning of parities. The only previously known ae.naMQ algorithm for learning parities is due to Hofmeister and is
66

5.4 A Fast Randomized Algorithm for ae.naMQ Learning of Parities

a deterministic algorithm based on constructing and decoding of BCH binary linear codes (see also Section 5.3.2)[Hof99]. The algorithm we present is substantially simpler and has essentially the same asymptotic complexity as Hofmeister's.
The basic idea of our algorithm is to use a distribution over {0, 1}n for which each attribute is correlated with the parity function if and only if it is present in the parity.

Theorem 5.4.1 For each k  n there exists an algorithm AEParityStat(k) that ae.naMQ learns the class PAR(k) in time O(nk log n) and asks O(k log n) MQs.

Proof: Let  c be the target concept (such that weight(c)  k). We define D 1 to be the

product

distribution

such

that

for

each

i,

Pr[xi

=

1]

=

1 t

.

Let

us

draw

a

point

t
x

randomly

according to distribution D 1 . Then for each i  n 4k

PrD 1 [xi = 1 and  c(x) = 1] = PrD 1 [ c(x) = 1 | xi = 1] PrD 1 [xi = 1]

4k

4k

4k

=

1 4k

PrD

1 4k

[ c(x)

=

1

|

xi

=

1]

.

Our second observation is that for any set of indices B  [n] and the corresponding parity function  b,

PrD 1 [ b(x) = 1]  1 - PrD 1 [i  B,

4k

4k

xi

= 0] = 1 - (1 -

1 4k

)|B|



|B| 4k

.

First examine the case that ci = 1 and therefore does not influence  c. Then by the second observation,

PrD 1 [ c(x) 4k

=

1

|

xi

=

1]

=

PrD 1 [ c(x) 4k

=

1]



k 4k



1/4

.

Now assume that ci = 1 and let c = cei. Then  c (x) is independent of xi and  c(x) = 1 if and only if  c (x) = 0. Therefore

PrD 1 [ c(x) = 1 | xi = 1] = PrD 1 [ c (x) = 0 | xi = 1]

4k

4k

=

1 - PrD 1 [ c 4k

(x)

=

1]



1-

k-1 4k

>

3/4

.

Hence estimation of PrD 1 [xi = 1 and  c(x) = 1] within the half of the expectation can be used to find out whether c4ki = 1. Lemma 2.3.1 for  = 1/2 implies that by taking O(k log n) independent samples with respect to D 1 we will get that each estimate is correct with
4k
probability at least 1 - 1/(2n) and therefore we will discover c with probability at least 1 - n/(2n) = 1/2. The running time of AEParityStat(k) is clearly O(nk log n).

67

5.5 Finding Fourier Coefficients and Weak DNF Learning
5.5 Finding Fourier Coefficients and Weak DNF Learning
The original Jackson's algorithm for learning DNF expressions with respect to the uniform distribution is based on a procedure that weakly learns DNF with respect to the uniform distribution [Jac97]. The procedure for weak learning is essentially an algorithm that, given a Boolean function f finds a significant Fourier coefficient of f , if one exist. Jackson's algorithm is based on a technique by Goldreich and Levin for finding a significant Fourier coefficient [GL89] (also called the KM algorithm [KM93]). Bshouty, Jackson, and Tamon used a later algorithm by Levin [Lev93] to give a significantly faster weak learning algorithm [BJT99]. In this section we will briefly describe Levin's algorithm with improvements by Bshouty et al. Building on their ideas we then present an attribute-efficient and non-adaptive version of the improved Levin's algorithm. This algorithm will give us an ae.naMQ algorithm for weak learning of DNF expressions that will serve as the basis of our ae.naMQ algorithm for DNF learning.
A Fourier coefficient ^(a) of a real-valued function  over {0, 1}n is said to be -heavy if |^(a)|  . For a Boolean f , E[f a]   if and only if Pr[f = a]  1/2 + /2. This means that |f^(a)|   is equivalent to either a or -a being a (1/2-/2)-approximator of f . Therefore finding a significant Fourier coefficient of f is sometimes called weak parity learning [Jac97]. It can also be interpreted as a learning algorithm for parities in the agnostic learning framework of Haussler [Hau92] and Kearns et al. [KSS94] (cf. [FGKP06] for details).
Definition 5.5.1 Let f be a Boolean function with at least one -heavy Fourier coefficient. Given  > 0 and access to MEM(f ), the weak parity learning problem consists of finding a vector z such that f^(z) is /2-heavy.
We will only consider algorithms for weak parity learning that are efficient, that is, produce the result in time polynomial in n, and -1. In addition we are interested in weak parity learning algorithms that are attribute-efficient.
Definition 5.5.2 Attribute-efficient weak parity algorithm is an algorithm that given k, , and MEM(f ) for f that has a -heavy Fourier coefficient of degree at most k efficiently solves weak parity learning problem and asks polynomial in k, log n, and -1 number of MQs.
We follow the presentation of Levin's weak parity algorithm given by Bshouty et al. and refer the reader to their paper for detailed proofs of all the statements and smaller remarks (we use the same definitions and notation to simplify the reference). Levin's
68

5.5 Finding Fourier Coefficients and Weak DNF Learning

algorithm is based on estimating a Fourier coefficient f^(a) by sampling f on randomlychosen pairwise independent points. More specifically, the following pairwise independent distribution is generated. For a fixed m, a random m-by-n 0-1 matrix R is chosen and the set Y = {pR | p  {0, 1}m \ {0m}} is formed. For different vectors p1 and p2 in {0, 1}m \ {0m}, p1R and p2R are pairwise independent. The variance 2 of a Boolean function is upper-bounded by 1 and thus Bienaym´e-Chebyshev's inequality (Lemma 2.3.2) implies that

PrR |

xY f (x)a(x) 2m - 1

-

f^(a)|







(2m

1 -

1)2

(5.2)

Therefore using a sample for m = log (16-1-2 + 1), xY f (x)a(x) will, with probability at least 1 - , approximate f^(a) within /4.

On the other hand, xY f (x)a(x) is a summation over all (but one2) elements of a linear subspace of {0, 1}n and therefore can be seen as a Fourier coefficient of f restricted to

subspace Y . That is, if we define fR(p) = f (pR) then, by definition of Fourier transform, for every z  {0, 1}m

fR(z) = 2-m

fR(p)z(p) .

p{0,1}m

This together with equality a(pR) = aRT (p) implies that f^(a) is approximated by fR(aRT ) (with probability at least 1 - ).
All the coefficients fR(z) can be computed exactly in time O(m2m) via the FFT algorithm giving estimations to all the Fourier coefficients of f .
Another key element of the weak parity algorithm is the following equation.

Lemma 5.5.3 ([BJT99]) For c  {0, 1}n let fc(x) = f (x  c). Then fc(a) = f^(a)a(c).

Proof:

fc(a) = 2-n

f (x  c)a(x) = 2-n

f (x)a(x  c) = f^(a)a(c) .

x{0,1}n

x{0,1}n

(5.3)

Assuming that f^(a)   estimation of f^(a) within /4 (when successful) has the same sign as f^(a). Similarly we can obtain the sign of fc(a). By Lemma 5.5.3, the sign of the product f^(a)fc(a) is equal to a(c). This gives a way to make MQs for a using the values fc,R(aRT ) for a random R. Levin and Bshouty et al. implicitly used this technique
2The value at 0m does not influence the estimation substantially and therefore can be offset by slightly increasing the size of sample space Y [BJT99].
69

5.5 Finding Fourier Coefficients and Weak DNF Learning

with a basic membership query algorithm for learning parities. The speed-up in Levin's algorithm is achieved by making each MQ to many a's in parallel. Therefore only a non-adaptive membership query algorithm for learning parities can be used. In our next theorem we give an interpretation of improved Levin's algorithm that makes the use of a non-adaptive membership query algorithm explicit.

Theorem 5.5.4 Let B(k) be an ae.naMQ algorithm for learning parities that runs in time
t(n, k) and uses q(n, k) MQs. There exists an attribute-efficient and non-adaptive algo-
rithm AEBoundedSieve-B(, k) that, with probability at least 1 - , solves the weak parity learning problem. AEBoundedSieve-B(, k) runs in time O~ -2t(n, k) · q(n, k) log (1/) and asks O~ -2q2(n, k) log (1/) MQs.

Proof: We assume for simplicity that B(k) succeeds with probability at least 3/4. Besides

that according to Fact 5.3.5, we can assume that B(k) is a proper algorithm.

Let S be the set of MQs for an execution of B(k). Choose randomly an m-by-n

matrix R for m = log (16-2 · 4 · (q(n, k) + 1) + 1) and compute the Fourier transforms of

fR = f0n,R and fy,R for each y  S via the FFT algorithm. Then, for each z  {0, 1}m,

we run B(k) with the answer to MQ y  S equal to sign(fR(z)fy,R(z)). If the output of

B(k) is a parity function a of length at most k then we test that (i) : |fR(z)|  3/4 and (ii) : aRT = z. If both conditions are satisfied we add a to the set of hypotheses H.
By equation (5.2), for a such that |f^(a)|   and weight(a)  k, with probability at

least

1

-

1 4(q(n,k)+1)

,

each

of

the

estimations

fy,R(aRT

)

for

y



S



{0n}

will

be

within

/4

of fy(a). In particular, with probability at least 3/4, for all y  S  {0n}, sign(fy(a)) =

sign(fy,R(aRT )) . If all the signs are correct then by Lemma 5.5.3, sign(fR(z)fy,R(z)) =

a(y) and as a result B(k) will succeed with probability at least 3/4. Therefore a will satisfy both conditions (i) and (ii) and will be added as a possible hypothesis with probability

at least 1/2. Note that B(k) is executed on up to 2m possible hypotheses while using the

same set of queries S. This is only possible for a non-adaptive algorithm B(k).

On the other hand, for any fixed b such that |f^(b)| < /2, if bRT = z (condition (ii))

then

with

probability

at

least

1

-

1 4(q(n,k)+1)



7/8,

fR(z)

approximates

f^(b)

within

/4.

This implies that |fR(z)| < 3/4 and therefore condition (i) will be failed with probability

at least 7/8. This implies that b can be added to the set of hypotheses with probability

at most 1/8.

Now we use a simple method of Bshouty et al. to remove all "bad" (not /2-heavy) hy-

potheses from the set of hypotheses without removing the "good" ones (-heavy) [BJT99].

We repeat the described algorithm times for independent choices of R and S generat-

ing sets of hypotheses (each of size at most 2m). This procedure generates at most

2m hypotheses. According to Chernoff's bound (Lemma 2.3.1) each "good" hypothesis

70

5.5 Finding Fourier Coefficients and Weak DNF Learning
appears in at least 1/3 of all the sets with probability at least 1 - 2- and each fixed "bad" hypothesis appears in at least 1/3 of all the sets with probability at most 2- , for a fixed constant  (since 1/8 < 1/3 < 1/2). Note that we need to fix a "bad" hypothesis to apply this argument. A hypothesis can be fixed as soon as it has appeared in a set of hypotheses. We then exclude the first set in which a hypothesis has appeared when counting the fraction of sets in which the hypothesis has appeared (Chernoff bound is now on - 1 trials but this is insubstantial). By setting = (m + log m + 2 log (1/) + 3)/ we will get that 2m2- -1  /2. Therefore the probability that a "bad" hypothesis will appear in 1/3 of the sets is at most /2. Similarly all "good" hypotheses will appear in 1/3 of the sets with probability at least 1 - /2. Thus by picking any a that appears in at least 1/3 of all the sets we will find a /2-heavy coefficient with probability at least 1 - .
Computing each of the Fourier transforms takes O(m2m) = O~(-2 ·q(n, k)) time. They are performed for each of q(n, k) MQs of B and this is repeated = O(m + log (1/)) times giving the total bound of O~(-2q2(n, k) log (1/)). For each of the 2m values of z we run B(k) and tests (i) and (ii). This takes O(2m(t(n, k) + mn)) = O~(-2t(n, k) · q(n, k)) time and is repeated = O(m + log (1/)) times. Therefore the total running time is O~(-2 · t(n, k) · q(n, k) log (1/)). Similarly we observe that each of the estimations via FFT uses 2m examples and · (q(n, k) + 1) such estimations are done. This implies that the sample complexity of the algorithm is O~ -2q2(n, k) log (1/) . It can also be easily seen that all MQs are non-adaptive.
Another way to see Theorem 5.5.4 is as a way to convert an ae.naMQ algorithm for learning of parities to an ae.naMQ algorithm for agnostic learning of parities.
By plugging AEParityStat(k) algorithm (Theorem 5.4.1) into Theorem 5.5.4 we obtain our weak parity learning algorithm.
Corollary 5.5.5 There exists an attribute-efficient and non-adaptive weak parity learning algorithm AEBoundedSieve(, k) that succeeds with probability at least 1 - , runs in time O~ nk2-2 log (1/) , and asks O~ k2 log2 n · -2 log (1/) MQs.
Jackson has proved that for every distribution D, every DNF formula f has a parity function that weakly approximates f with respect to D [Jac97]. A refined version of this claim by Bshouty and Feldman shows that f has a short parity that weakly approximates f if the distribution is not too far from the uniform [BF02]. More formally, for a realvalued function  we define L() = maxx{|(x)|} and we view a distribution D as a function over {0, 1}n that for a point x gives its probability weight under D.
Lemma 5.5.6 ([BF02]) For any Boolean function f of DNF-size s and a distribution D
71

5.6 Learning DNF Expressions

over {0, 1}n there exists a parity function a such that

|ED[f a]|



1 2s + 1

and

weight(a)



log ((2s + 1)L(2nD))

.

By combining this fact with Corollary 5.5.5 we get an algorithm for weakly learning DNF.

Theorem 5.5.7 There exist an algorithm WeakDNFU (s) that for a Boolean function f

of DNF-size s given n, s, and access to MEM(f ), with probability at least 1/2, finds a

(

1 2

-

(

1 s

))-approximator

to

f

with

respect

to

U.

Furthermore,

WeakDNFU (s)

runs

in

time

O~ ns2 and asks O~ s2 log2 n non-adaptive MQs.

Proof: Lemma 5.5.6 implies that there exists a parity a on at most log (2s + 1) vari-

ables

such

that

|EU [f a]| = |f^(a)| 

1 2s+1

.

This

means

that

f

has

a

1 2s+1

-heavy

Fourier

coefficient of degree at most log (2s + 1). Using Corollary 5.5.5 for  = 1/2, we can find a

1 2(2s+1)

-heavy

Fourier

coefficient

f^(a

)

in

time

O~

ns2

and using O~

s2 log2 n

non-adaptive

MQs.

The parity a

or

its

negation

(

1 2

-

1 4(2s+1)

)-approximates

f.

The algorithm for weakly learning DNFs by Bshouty et al. requires O~ ns2 MQs and

runs in time3 O~ ns2 [BJT99].

5.6 Learning DNF Expressions
In this section we show an ae.naMQ algorithm for learning DNF expressions. Following Jackson's approach we first show how to generalize our weak DNF learning algorithm to other distributions [Jac97]. We then use Freund's boosting algorithm to obtain a strong DNF learning algorithm [Fre92]. Besides achieving attribute-efficiency and nonadaptiveness we show a way to speed up the boosting process by exploiting several properties of our WeakDNF algorithm.
5.6.1 Weak DNF Learning with Respect to Any Distribution
The first step in Jackson's approach is to generalize a weak parity algorithm to work for any real-valued function. We follow this approach and give a generalization of our AEBoundedSieve(, k) algorithm (Corollary 5.5.5) to any real-valued and also randomized functions.
Lemma 5.6.1 There exists an algorithm AEBoundedSieveRV(, k, V) that for any realvalued randomized function  with a -heavy Fourier coefficient of degree at most k, given
3The running time bound is based on use of a membership query oracle, that given any two vectors x, y  {0, 1}n, passed to it "by reference", returns f (x  y) in O(1) time.
72

5.6 Learning DNF Expressions

k, , V  VarU,((x)), and an oracle access to , finds, with probability at least 1 - ,
a /2-heavy Fourier coefficient of  of degree at most k. The algorithm runs in time O~ nk2-2V log (1/) and asks O~ k2 log2 n · -2V log (1/) non-adaptive MQs.

Proof: By revisiting the proof of Theorem 5.5.4, we can see that the only place where we used the fact that f is Boolean and deterministic is when relying on equation (5.2) in which the variance of the random variable f (x)  {-1, +1} was upper-bounded by 1. In this bound f (x) is already treated as a random variable on pairwise independent x's. For any point x, (x) is independent of any other evaluations of  and therefore evaluations of  on pairwise independent points are pairwise independent. This implies that in order to estimate (a) within /4 we only need to account for the fact that the variance of (x) is not necessarily bounded by 1. This can be done by using Var()  V times more samples, that is, we set m = log (16V -2 · 4 · (q(n, k) + 1) + 1). It is now straightforward to verify that the rest of the proof of Theorem 5.5.4 is unchanged. The increase in the required sample size increases the running time and the sample complexity of the algorithm by a factor O~(V ) giving us the claimed bounds.
As in Jackson's work we use the generalized weak parity algorithm to obtain an algorithm that weakly learns DNF expressions with respect to any distribution. The algorithm is efficient only when the distribution function is "close" to the uniform and requires access to the value of the distribution function at any point x.

Theorem 5.6.2 There exist an algorithm WeakDNF(s, B) that for a Boolean function f of

DNF-size s and any distribution D, given n, s, B  L(2nD(x)), access to MEM(f ), and

an

oracle

access

to

D,

with

probability

at

least

1

-

,

finds

a

(

1 2

-

(

1 s

))-approximator

to

f with respect to D. Furthermore, WeakDNF(s, B)

· runs in time O~(ns2B log (1/));

· asks O~(s2 log2 n · B log (1/)) non-adaptive MQs;

· returns a parity function of length at most O(log (sB)) or its negation.

Proof: Lemma 5.5.6 states that there exists a vector a of Hamming weight bounded by O (log (sL(2nD))) such that |ED[f (x)a(x)]| = (1/s). But

ED[f (x)a(x)] = [f (x)D(x)a(x)] = E[f (x)2nD(x)a(x)] = (a) ,
x

(5.4)

where (x) = f (x)2nD(x). This means that (x) has a (1/s)-heavy Fourier coefficient of

degree bounded by O (log (sL(2nD))) = O(log (sB)). We can apply AEBoundedSieveRV

73

5.6 Learning DNF Expressions

on (x) to find its (1/s)-heavy Fourier coefficient of degree O(log (sB)). All we need to do this is to provide a bound V on the variance of f (x)2nD(x).

Var(f (x)2nD(x)) = E[(f (x)2nD(x))2] - E2[f (x)2nD(x)]

 L(2nD(x))E[2nD(x)] - E2[f (x)2nD(x)]  L(2nD(x))E[2nD(x)]

= L(2nD(x))  B

(5.5)

This bound on variance relies essentially on the fact that D(x) is a distribution function 4

and therefore E[2nD(x)] = ED[1] = 1. This improves on L2(2nD(x)) bound for an unrestricted function D(x) that was used in analysis of previous weak DNF learning algorithms

[Jac97, BJT99].

We can now run AEBoundedSieveRV(, k, V) for  = (1/s), k = O(log (sB)), V = B,

and a simulated oracle access to  = f 2nD to obtain a such that |(a )| = (1/s) and

weight(a ) = O(log (sB)). By equation (5.4), we get that |ED[f (x)a (x)]| = (1/s) and

therefore

a

(x)

or

its

negation

(

1 2

-

(

1 s

))-approximates

f

with

respect

to

D.

The

claimed

complexity bounds can be obtained by using Lemma 5.6.1 for , k and V as above.

5.6.2 Background on Boosting a Weak DNF Learner
Jackson's DNF learning algorithm was obtained by converting his weak learning algorithm to a strong one via a boosting algorithm [Jac97]. Boosting is a general technique for improving the accuracy of a learning algorithm. It was introduced by Schapire who gave the first efficient boosting algorithm [Sch90]. Let C be a concept class and let WL be a weak learning algorithm for C that for any distribution D, produces a (1/2 - )-approximating hypothesis. Known boosting algorithms have the following structure.
· At stage zero WL is run on D0 = D to obtain h0.
· At stage i a distribution Di is constructed using D and previous weak hypotheses h0, . . . , hi-1. The distribution Di usually favors the points on which the previous weak hypotheses do poorly. Then random examples from Di are simulated to run WL with respect to Di and obtain hi.
· After repeating this for a number of times an -approximating hypothesis h is created using all the generated weak hypotheses.
Jackson's use of Freund's boosting algorithm slightly deviates from this scheme as it provides the weak learner with the oracle that returns the density of the distribution
4Actual D(x) given to a weak learner will be equal to cD (x) where D (x) is a distribution and c is a constant in [2/3, 4/3] [BJT99]. This modifies the bound above by a small constant factor.
74

5.6 Learning DNF Expressions

function Di at any desired point instead of simulating random examples with respect to Di. The WeakDNF algorithm also requires oracle access to Di(x) and therefore we will use a boosting algorithm in the same way. The running time of Jackson's (and our) algorithm for weak learning of DNF expression depends polynomially on L(2nD) [Jac97] and therefore it can only be boosted by a boosting algorithm that produces distributions that are polynomially-close to the uniform distribution; that is, the distribution function is bounded by p2-n where p is a polynomial in learning parameters (such boosting algorithms are called p-smooth). In Jackson's result Freund's boost-by-majority algorithm [Fre95] is used to produce distribution functions bounded by O( -2). More recently, Klivans and Servedio have observed [KS03] that a later Freund's B-Comb boosting algorithm [Fre92] produces distribution functions bounded by O~(1/ ), thereby improving the dependence of running time and sample complexity on . This improvement together with improved weak DNF learning algorithm due to Bshouty et al. [BJT99] gives DNF learning algorithm that runs in O~(ns6/ 2) time and has sample complexity of O~(ns4/ 2).
Remark 5.6.3 Bshouty et al. claimed sample complexity of O~(ns2/ 2) based on erroneous assumption that sample points for weak DNF learning can be reused across boosting stages. A distribution function Di in i-th stage depends on hypotheses produced in previous stages. The hypotheses depend on random sample points and therefore in i-th stage the same set of sample points cannot be considered as chosen randomly and independently of Di [Jac04]. This implies that new and independent points have to be sampled for each boosting stage and increases the sample complexity of the algorithm by Bshouty et al. by a factor of O(s2).
As in the work of Klivans and Servedio [KS03], we use Freund's B-Comb boosting algorithm [Fre92] to boost the accuracy of our weak DNF learning algorithm. We will now briefly describe the B-Comb boosting algorithm (see also the work of Klivans and Servedio for a detailed discussion on application of B-Comb to learning DNF expressions [KS03]).

Freund's B-Comb Boosting Algorithm

B-Comb boosting algorithm is based on a combination of two other boosting algorithms.

The first one in an earlier F1 algorithm due to Freund and is used to boost from accuracy

1 2

-

to

accuracy

1/4

[Fre95].

Its

output

is

the

function

equal

to

the

majority

vote

of

the

weak hypotheses that it received. This algorithm is used as a weak learner by the second

boosting algorithm B-Filt. At stage k B-Filt sets h to be either the output of a weak

learner or a random coin flip (that is a randomized function equal to either 1 or -1, each

with probability 1/2). Accordingly the distribution function generated at stage i depends

on random coin flips and the final hypothesis is a majority vote over hypotheses from the

75

5.6 Learning DNF Expressions

weak learner and random coin flips. As it is done by Freund, we analyze the algorithm for a fixed setting of these coin flip hypotheses [Fre92]. Freund's analysis shows that with overwhelming probability over the coin flips the randomized hypothesis produced by the boosting algorithm -approximates the target function.
Each of the executions of F1 has O(-2) stages and B-Filt has O(log (1/ )) stages. We denote the distribution function generated at stage i of F1 during stage of B-Filt as DC,oimb. In both boosting algorithms Di(x) = (i, N (x))D/, where N (x) is the number of previous hypotheses that are correct on x,  is a fixed function from a pair of integers to the interval [0, 1] computable in polynomial (in the length of its input) time, and  is the normalization factor equal to ED[(i, N (x))]. We can therefore say that

DC,oimb(x) = ( , NFilt(x)) · (i, NF1(x))D(x)/(  ,i) ,

(5.6)

where NFilt(x) and NF1(x) count the correct hypotheses so far for B-Filt and F1 respectively. The normalization factor  equals ED[( , NFilt(x))] and

 ,i = ED[( , NFilt(x)) · (i, NF1(x))D(x)/ ] .

The analysis by Freund implies that for every and i,

L(2nDC,oimb)  1/(  ,i) = O~(1/ ) .

(5.7)

In Figure 5.6.2 we include the pseudocode of B-Comb algorithm simplified and adapted to our setting.

5.6.3 Optimized Boosting
We now use Freund's B-Comb boosting algorithm [Fre92] to boost the accuracy of our weak DNF learning algorithm. Unlike in the previous work, we will exploit several properties of WeakDNF to achieve faster execution of each boosting stage. Specifically, we note that evaluation of the distribution function Di(x) at boosting stage i involves evaluation of i - 1 previous hypotheses on x and therefore, in a general case, for a sample of size q will require (i · q) steps, making the last stages of boosting noticeably slower. Our goal is to show that for our WeakDNF algorithm and the B-Comb boosting algorithm the evaluation of Di(x) for the whole sample needed by WeakDNF can be made more efficiently.
The idea of the speed-up is to use equation (5.6) together with the facts that weak hypotheses are parities and MQs of WeakDNF come from a "small" number of low-dimension linear subspaces. Let g be a function that is equal to a linear combination of short parity functions. We start by showing a very efficient way to compute the values of g on a

76

5.6 Learning DNF Expressions

B-Comb( , , D, WL)

1. k  c0 log (1/ ) 2.   c1 / log (1/ )

3. h0  F1(1/4, /(2k + 1), D, WL) 4. for  1 to k

5. N (x)  |{hj | 0  j  - 1 and hj(x) = f (x)}| 6.   EstExpRel(( , N (x)), D, 1/3, /(2k + 1))

7. if    then

8.

D  ( , N (x))/

9.

h  F1(1/4, /(2k + 1), D , WL)

10. else

11.

h  Random(1/2)

12. end for

13. return Majority(h0, h1, . . . , hk)

F1( , , D, WL)

1. k  c2/2 2.   c3 2

3. h0  WL(D, /(2k + 1)) 4. for i  1 to k

5. N (x)  |{hj | 0  j  i - 1 and hj(x) = f (x)}|

6. i  EstExpRel((i, N (x)), D, 1/3, /(2k + 1))

7. if i   then

8.

Di  (i, N (x))/i

9.

hi  WL(Di, /(2k + 1))

10. else

11.

k  i-1

12.

break for

13. end for

14. return Majority(h0, h1, . . . , hk)

Figure 5.1: Pseudocode of B-Comb boosting algorithm. The first part is B-Filt with F1

used as a weak learner.

WL

is a weak learning algorithm that has accuracy

1 2

-



and

takes an oracle for a distribution D and confidence  as parameters. EstExpRel(R, D, , )

produces estimates of the expectation of a random variable R with respect to a distribution

D within relative accuracy  and confidence  (that is the estimate v  [(1-)v, (1+)v],

where v is the true expectation). Various unspecified constants are denoted by c0, c1, . . .

The membership query oracle for the target function f is available to all procedures.

77

5.6 Learning DNF Expressions

linear subspace of {0, 1}n. We will assume that vectors of Hamming weight at most w are represented by the list of indices where the vector is equal to 1 (as we did for parities). One can easily see that adding such vectors or multiplying them by any vector takes O(w log n) time.

Lemma 5.6.4 Let {c1, c2, . . . , ci} be a set of vectors in {0, 1}n of Hamming weight at most w; ¯  Ri be a real-valued vector, and R be a m-by-n 0-1 matrix. Then the set of

pairs

S = { p, jcj (pR) | p  {0, 1}m}
ji

can be computed in time O~(i · w log n + 2m).

Proof: We define g(x) = ji jcj (x) and for p  {0, 1}m we define gR(p) = g(pR) (as in Sect. 5.5). Our goal is to find the values of function gR on all the points of {0, 1}m. The

function g is given as a linear combination of parities, or in other words, we are given its

Fourier transform. Given the Fourier transform of g we can derive the Fourier transform

of gR from the following equation:





gR(p) = jcj (pR) = jcjRT (p) =

(

j)z(p) .

ji

ji

z{0,1}m ji; cj RT =z

Hence gR(z) = ji; cjRT =z j. Given the Fourier transform of gR we can use the FFT algorithm to perform the inverse Fourier transform of gR giving us the desired values of gR(p) on all the points of {0, 1}m. This task can be performed in O(m2m) steps. To compute the Fourier transform of gR we need to compute cjRT for each j  i and sum
the ones that correspond to the same z. Given that each cj is of Hamming weight w, cjRT can be computed in O(wm log n) steps (note that we do not read the entire matrix

R). Therefore the computation of the Fourier transform and the inversion using the FFT

algorithm will take O(m(iw log n + 2m)) = O~(i · w log n + 2m) steps.

Note that a

straightforward computation would take (iw2m log n) steps. We apply Lemma 5.6.4 to

speed up the evaluation of DC,oimb(x) on points at which WeakDNF asks non-adaptive MQs (here again we will rely on the non-adaptiveness of the weak learning algorithm). The

speed-up is based on the following observations.

1. WeakDNF is based on estimating Fourier coefficients on a "small" number of linear subspaces of {0, 1}n (as in equation (5.2)).

2. WeakDNF produces a short parity function (or its negation) as the hypothesis.

78

5.6 Learning DNF Expressions

3. In computation of DC,oimb(x) the only information that is needed about the previous hypotheses is NFilt(x) and NF1(x), that is the number of hypotheses so far that are correct on the given point. The number of correct hypotheses is determined by f (x) and the sum (in particular, a linear combination) of the values of the hypotheses on x.
Now we prove these observations formally and show a more efficient way to compute DC,oimb(x) given oracle access to NFilt(x), in other words, we show a more efficient way to compute NF1(x).
Lemma 5.6.5 Let {b1c1, b2c2, . . . , bici} be the hypotheses returned by WeakDNF(s, B) in i first stages of F1 boosting algorithm during stage of B-Filt, where bj  {-1, +1} is the sign of cj (indicating whether or not it is negated). Let W be the set of queries for the (i + 1)-th execution of WeakDNF(s, B) with confidence parameter  and B  L(2nDC,oimb). Then, given MEM(f ) and an oracle access to NFilt(x), the set of pairs
S = { x, DC,oimb(x) | x  W }
for some constant   [2/3, 4/3], can be computed, with probability at least 1 - , in time O~((i + s2B) log2 n log (1/)).
Proof: We start by proving our first observation. By revisiting the proof of Theorem 5.5.4 we can see that our weak parity algorithm asks queries on Y = {pR | p  {0, 1}m} for a randomly chosen R and then for each query z of a ae.naMQ parity algorithm it asks queries on points of the set Yz = {z  y | y  Y }. The set Yz is a subset of the linear subspace of dimension m + 1 spanned by the rows of R and vector y. These queries are then repeated O(m + log (1/)) times to single out "good" Fourier coefficients. Therefore by substituting the parameters of WeakDNF(s, B) into the proofs of Lemma 5.6.1 and Theorem 5.5.4, we can see that W can be decomposed into O~(log2 (sB) log n log (1/)) linear subspaces of dimension m = log T for T = O~(s2B log n).
Our second observation is given by Theorem 5.6.2 and states that for each j  i, cj is a parity on at most log sB variables.
Our next observation is that the number of hypotheses from {b1c1, b2c2, . . . , bici} that agree with f on x equals to

f (x) NF1(x) =

ji bj cj (x) 2

+

i 2

,

that is, given ji bjcj (x) and f (x), NF1(x) can be computed in O(1) steps. According to Lemma 5.6.4, we can compute ji bjcj (x) on a linear subspace of dimension m in

79

5.6 Learning DNF Expressions

time O~(iw log n + 2m). Together with the first observation this implies that computing NF1(x) for all points in W can be done in time
O~(log2 (sB) log n log (1/))O~(i · log (sB) log n + s2B log n) = O~((i + s2B) log2 n log (1/)) .

Equation (5.6) implies that for every point x, given NF1(x), oracle access to NFilt(x)

and   ,i we obtain DC,oimb(x). The normalization factor  ,i is estimated with relative accuracy 1/3 and therefore instead of the true DC,oimb(x) we will obtain DC,oimb(x) for some

constant   [2/3, 4/3].

Lemma 5.6.5 assumes oracle access to NFilt(x). In the next

lemma we show that this oracle can be simulated efficiently.

Lemma 5.6.6 Let {h0, h1, . . . , h -1} be the set of hypotheses obtained by B-Comb in first
stages of boosting. Let W be the set of queries for the (i + 1)-th execution of WeakDNF(s, B)
with confidence parameter  and B  L(2nDC,oimb). Then, given MEM(f ), the set of pairs S = { x, NFilt(x) | x  W } can be computed, with probability at least 1 - , in time O~( s2B · log2 n log (1/)).

Proof: For each j  - 1, hj is an output of F1 or a random coin flip hypothesis.

WeakDNF(s,

B)

returns

(

1 2

-

(

1 s

))-approximate

hypotheses

and

therefore

each

hypothesis

generated by F1 is a majority vote of O(-2) = O(s2) short parities (or their negations).

A majority vote of these parities and their negations is simply the sign of their sum,

and in particular is determined by a linear combination of parity functions. Hence, as in Lemma 5.6.5, hj(x) for all points in W can be computed O~((s2 + s2B) log2 n log (1/))
time. Therefore for any stage , h0, h1, . . . , h -1 can be computed on points in W in O~( s2B log2 n log (1/)) steps giving the required oracle NFilt(x).

Remark 5.6.7 In this simulation of B-Comb we ignored the running time and sample
complexity of procedure EstExpRel that is used to evaluate the normalization factors. The
factor  = E[( , NFilt(x))] needs to be estimated within relative accuracy 1/3 and its value is only used when the estimate    = c1 / log (1/ ) for some constant c1 since otherwise B-Comb uses a random coin flip hypothesis (see line 7 of the pseudocode). This
implies that the estimate is only used when   3/4. The Chernoff bound (Lemma 2.3.1) implies that if   3/4 then using M = O( log(1/ ) log (1/) ) random uniform
samples will be sufficient to estimate  within relative accuracy 1/3 with confidence 1 - .
If  < 3/4 then with probability 1 -  the obtained estimate  will be less than  and therefore will not be used. Evaluating NFilt(x) on each of these points will take O( ns2) steps and therefore each of these estimation will run in time O~( ns2 log (1/)/ ).

80

5.6 Learning DNF Expressions
At each stage of the F1 boosting algorithm we need to estimate
 ,i = E[( , NFilt(x)) · (i, NF1(x))/ ]
to within relative accuracy 1/3 and its value is only used when the estimate  ,i  c for some constant c. Therefore it is sufficient to estimate  ,i to within constant additive accuracy. With probability at least 1 -  this can be achieved by using a sample of O(log (1/)) random uniform points. Estimating both NFilt(x) and NF1(x) on each point takes O( ns2) steps and therefore each of these estimations runs in time O( ns2 log (1/)).
We are now ready to describe the resulting ae.naMQ algorithm for learning DNF expressions.
Theorem 5.6.8 There exists an algorithm AENALearnDNF(s) that for any Boolean function f of DNF-size s, given n, s, , and access to MEM(f ), with probability at least 1/2, finds an -approximator to f with respect to U. Furthermore, AENALearnDNF(s) runs in time O~ ns4/ and asks O~ s4 log2 n/ non-adaptive MQs.
Proof: As we know from the description of B-Filt, it has O(log (1/ )) stages and for each and i, L(2nDC,oimb) = O~(1/ ). Therefore the running time of each execution of WeakDNF(s, B) is O~(ns2/ ). In particular, for every boosting stage of F1, it dominates the running time of computing the distribution function DC,oimb (Lemmas 5.6.5 and 5.6.6) and estimations of  and  ,i (Remark 5.6.7). There are total O(s2 log (1/ )) executions of WeakDNF and therefore the total running time of AENALearnDNF(s) is O~ ns4/ and the total number of non-adaptive MQs used is O~ s4 log2 n/ .
The improvements to the algorithm by Bshouty et al. are summarized below [BJT99].
· The use of attribute-efficient weak learning improves the total sample complexity from O~ ns4/ 2 to O~ s4 log2 n/ 2 and the same running time is achieved without assumptions on the MQ oracle (see Theorem 5.5.7).
· Faster computation of distribution functions used in boosting improves the total running time from O~ ns6/ 2 to O~ ns4/ 2 (see Lemmas 5.6.4, 5.6.5 and 5.6.6).
· Tighter estimation of variance improves the dependence of running time and sample complexity on from 1/ 2 to 1/ (equation (5.5)).
Remark 5.6.9 While the analysis of the speedup was done for Freund's B-Comb booster the same idea works for any other booster in which estimation of new weight function is based on a linear combination of previous hypotheses. In particular, for the other known boosting algorithms that produce smooth distributions: SmoothBoost by Servedio [Ser03] and AdaFlat by Gavinsky [Gav03].
81

5.7 Handling Noise

5.7 Handling Noise

Now we would like to show that our DNF learning algorithm can be modified to tolerate random persistent classification noise in MQs. To simplify the proof we first show that we can assume that we are dealing with random and independent classification noise.

Lemma 5.7.1 The probability that AENALearnDNF(s) asks an MQ for the same point more than once is upper bounded by P · 2-n/ log Q where P and Q are polynomial in n, s and 1/ .

Proof: We start by observing that in the algorithm AENALearnDNF(s) all the points that

are given to the MQ oracle are chosen uniformly and the points that are used in different

executions of WeakDNF are independent. As can be seen from the proof of Theorem 5.5.4,

the generated points are of the form pR  y, where R is a randomly and uniformly chosen

matrix, y is chosen randomly according to D 1 (defined in Theorem 5.4.1) or equal to 0n,

and

p  {0, 1}m.

Points generated

4k
for two randomly

chosen R1

and R2

are independent

of each other and uniformly distributed. Let y0 = 0n, q be the number of samples taken

from D 1 , and y1, y2, . . . , yq denote the samples. 4k For some randomly chosen R, let x1 = p1R  yi and x2 = p2R  yj be two different

sample points. For two different sample points either i = j or p1 = p2. If i = j then either

i = 0 or j = 0. Without loss of generality we assume that i = 0. Then

PryiD 1 4k

[p1R

 yi

=

p2R

 yj]

=

PryiD 1 4k

[yi

=

p1R

 p2R

 yj]



(1 -

1 4k

)n



e-n/(4k)

.

If p1 = p2 then PrRUm×n[(p1  p2)R = yi  yj] = 2-n. This implies that for any two MQs made by AENALearnDNF(s), probability that they are equal is at most e-n/(4k). As it can be seen from the analysis of AENALearnDNF(s), k = O(log (s/ )) and the total number of MQs used is polynomial in n, s and 1/ .
If an algorithm does not ask a MQ for the same point again then persistent classification noise can be treated as random and independent.

5.7.1 Boosting Weak Parity Learning Algorithm in the Presence of Noise
The main part of the modification is to show an algorithm that can locate heavy Fourier coefficients of any randomized function can be used to learn DNFs in the presence of noise. Our method can be applied in more general setting. In particular, it could be used to prove that Jackson's original algorithm is resistant to persistent noise in MQs and was recently used to produce a noise tolerant DNF learning algorithm by Feldman et al. [FGKP06]. Previous methods to produce noise-tolerant DNF learning algorithms gave
82

5.7 Handling Noise

statistical query analogues of Jackson's algorithm and then simulated statistical queries5 in the presence of noise [JSS97, BF02]. Our approach is more direct and the resulting algorithm is substantially more efficient than the previous ones.
The goal of a weak DNF learning algorithm at stage i of boosting is to find a parity correlated with the function 2nDi(x)f (x) given an oracle access to values of Di(x) and the oracle for f with noise of rate  < 1/2 instead of MEM(f ). Handling the noisy case is further complicated by the fact that the computation of Di(x) by the boosting algorithm uses the value f (x) (in particular, B-Comb and B-Filt need the value of f (x) to compute N (x)) which is not available in the noisy case. To make this dependence explicit we define Di(x, b) (for b  {-1, +1}) to be the value of Di on x when the boosting algorithm is supplied with the value b in place of f (x) to compute Di(x) (in particular, Di(x) = Di(x, f (x))). We will now show a general method to compute a Fourier coefficient of a function that depends on f (x) given a noisy oracle for f .

Lemma 5.7.2 Let g(x, b) be any real-valued function over {0, 1}n × {-1, +1} and let  denote a randomized function such that for every x, (x) = f (x) with probability 1- and (x) = -f (x) with probability . Then for each a  {0, 1}n, [g(x, f (x))](a) = g,(a), where g, is a randomized function defined as

g, (x)

=

1 2

1

1 -

2

(g(x,

1)

-

g(x,

-1))

·



(x)

+

g(x,

1)

+

g(x,

-1)

.

Proof: We use the following observation due to Bshouty and Feldman [BF02]. For any real-valued function (x, b)

(x, f (x))

=

(x,

-1)

1

-f 2

(x)

+

(x,

1)

1

+

f 2

(x)

=

Then

1 2

(((x,

1)

-

(x,

-1))f (x)

+

(x, 1)

+

(x, -1))

.

Ex,

(x)

[

1 2

((x,

1)

-

(x,

-1))

·

 (x)]

=

(1

-

2)Ex[

1 2

((x,

1)

-

(x,

-1))f (x)]

,

5They used stronger versions of statistical queries than those introduced by Kearns [Kea98].

83

5.7 Handling Noise

and therefore we can offset the effect of noise in g(x, f (x)) as follows.

[g(x, f (x))](a) = E[g(x, f (x))a(x)]

=

1 2

(Ex[(g(x, 1)

-

g(x, -1))a(x)f (x)]

+

Ex[(g(x, 1)

+

g(x, -1))a(x)])

=

1 2

1

1 -

2

Ex,

(x)[(g(x,

1)

-

g(x,

-1))a(x)

·



(x)]

+

Ex

[(g(x,

1)

+

g(x,

-1))a

(x)]

= Ex,(x)

1 2

1

1 -

2

(g(x,

1)

-

g(x,

-1))

·



(x)

+

g(x,

1)

+

g(x,

-1)

a(x)

= (a)

An oracle for (x) is exactly the membership query oracle for f (x) with noise of rate  that is given to us (by Lemma 5.7.1 we can ignore the persistency of noise). Therefore Lemma 5.7.2 gives a way to find heavy Fourier coefficients using an oracle for (x) instead of the membership query oracle for f (x). We apply it to WeakDNF and obtain our noise-tolerant ae.naMQ DNF learning algorithm.

Theorem 5.7.3 There exists an algorithm AENALearnDNF(s, ) that for any Boolean func-
tion f of DNF-size s, given n, s, , , and access to MEM(f ) corrupted by random persistent
classification noise of rate , with probability at least 1/2, finds an -approximator to f with respect to U . Furthermore, AENALearnDNF(s, ) runs in time O~ ns4/( (1 - 2)2) and asks O~ s4 log2 n/( (1 - 2)2) non-adaptive MQs.

Proof: Section 5.6.3 gives a way to efficiently compute DC,oimb(x) given the label f (x). This computation defines the oracle for DC,oimb(x, b) where b is the supposed label of f (x). Let g(x, b) = b · 2nDC,oimb(x, b) and let g,(x) be defined as in Lemma 5.7.2. Given the oracle for DC,oimb(x, b) and oracle access to (x) we use AEBoundedSieveRV(, k, V) on g,(x) in the same way it was used on (x) by WeakDNF(s, B) (see the proof of Theorem 5.6.2). By
Lemma 5.7.2, g,(x) has the same Fourier coefficients as f (x)2nDC,oimb(x, f (x)). Therefore this modified weak learning algorithm will produce an equivalent hypothesis. We can deal
with the noise while estimating the normalization factor  ,i in exactly the same way.
Furthermore, the definition of g, and equation (5.5) imply that

L (g, )



1

2 -

2

L(2nDC,oimb)

and

Var(g, )



(1

4 - 2)2

L(2nDC,oimb)

.

By substituting these bounds into Theorem 5.6.2 we obtain that the running time and the sample complexity of each execution of the modified weak learner will grow by (1 - 2)2. They also imply that WeakDNF(s, B) will produce parities on log (s2/( (1 - 2))) variables

84

5.7 Handling Noise (this change is absorbed by O~ notation).
85

Chapter 6
Learning Parities with Noise

In this chapter we study learning of parities under the uniform distribution with random classification noise, also called the noisy parity problem. We reduce a number of basic problems regarding learning under the uniform distribution to learning of noisy parities, thus establishing the central role of this problem in learning under the uniform distribution. In particular, we show that under the uniform distribution, agnostic learning of parities, PAC learning of DNF expressions, and learning of k-juntas all reduce to learning parities with random classification noise. The first reduction also yields the first nontrivial algorithm for agnostic learning of parities under the uniform distribution.

6.1 Introduction

A parity function is the XOR of some set of variables T  [n], where [n] denotes the

set {1, 2, . . . , n}. This is one of most fundamental concept classes in learning theory. In

particular, the powerful Fourier transform learning technique is based on representing

functions as linear combination of parities. In the absence of noise, one can identify the

set T by running Gaussian elimination on the given examples. The presence of noise in

the labels, however, leads to a number of challenging and important problems. We address

learning of parities in the presence of two types of noise.

Random classification noise is a relatively benign model of noise in which the label of

each point is flipped randomly independently with probability  for some  < 1/2 and

then given to the learner. As  approaches 1/2 the labels approach an unbiased coin flip

and hence the running time of the learning algorithm is allowed to depend polynomially

on

1 1-2

(see

Section

2.2.3

for

the

details

on

the

model).

The other model we consider is the agnostic learning model of Haussler [Hau92] and

Kearns et al. [KSS94]. In this model, informally, nothing is known about the process that

86

6.1 Introduction

generated the examples and the learning algorithm is required to do nearly as well as is possible using hypotheses from a given class. This corresponds to a common empirical approach when few or no assumptions are made on the data and a fixed space of hypotheses is searched to find the "best" approximation of the unknown function (see Section 2.2.4 for more details on the model). Designing algorithms that learn in this model is notoriously hard and very few positive results are known [KSS94, LBW95, GKS01, KKMS05].
The agnostic model can also be thought of as a model of adversarial classification noise by viewing the data as coming from f   C but with labels corrupted on an  fraction of examples (f  is the function in C that has the minimum error ). Note however, that unlike in most other models of noise the learning algorithm is not required to recover the corrupted labels but only to classify correctly "almost" (in the PAC sense) 1 -  fraction of examples.

6.1.1 Overview and Previous Work

We start by summarizing the main known results about the problems of learning parities with random classification noise and learning parities in the agnostic model.

· Adversarial Noise: Without any restrictions on the distribution of examples the problem of (proper) agnostic learning parities is known to be NP-hard. This follows easily from NP-hardness of maximum-likelihood decoding of linear codes proved by Berlekamp et al. [BMvT78] (a significantly stronger version of this result follows from a celebrated result of H°astad [Has01]). We are unaware of non-trivial algorithms for this problem under any fixed distribution, prior to our work. The problem of learning parities with adversarial noise under the uniform distribution is equivalent to finding a significant Fourier coefficient of a Boolean function and related to the problem of decoding Hadamard codes. If the learner can ask membership queries (or queries that allow the learner to get the value of function f at any point), a celebrated result of Goldreich and Levin gives a polynomial time algorithm for this problem [GL89]. Later algorithms were given by Kushilevitz and Mansour [KM93], Levin [Lev93], Bshouty et al. [BJT04], and Feldman (see Section 5.5).

· Random Noise: The problem of learning parities in the presence of random noise,

or the noisy parity problem is a notorious open problem in computational learning

theory. Blum, Kalai and Wasserman give an algorithm for learning parity functions

on

n

variables

in

the

presence

of

random

noise

in

time

2O(

n log

n

)

for

any

constant



[BKW03]. Their algorithm works for any distribution of examples. We will also

consider a natural restriction of this problem in which the set T is of size at most

k.

A

brute-force

algorithm

for

this

problem

is

to

take

O(

1 1-2

k

log

n)

samples

and

87

6.1 Introduction

then find the parity on k variables that best fits the data through exhaustive search in time O(nk). This is essentially the best known algorithm.
In this work, we focus on learning parities under the uniform distribution. We reduce a number of fundamental open problems on learning under the uniform distribution to learning noisy parities, establishing the central role of noisy parities in this model of learning.

Learning Parities with Adversarial Noise

We show that under the uniform distribution, learning parities with adversarial noise reduces to learning parities with random noise. In particular, our reduction and the result of Blum et al. imply the first non-trivial algorithm for learning parities with adversarial noise under the uniform distribution [BKW03].

Theorem 6.1.1 For any constant  < 1/2, parities are learnable under the uniform

distribution

with

adversarial

noise

of

rate



in

time

O(2

n log

n

).

Equivalently, this gives the first non-trivial algorithm for agnostically learning parities. The restriction on the noise rate in the algorithm of Blum et al. translates into a restriction on the optimal agreement rate of the unknown function with a parity (namely it has to be a constant greater than 1/2). Hence in this case the adversarial noise formulation is cleaner.
Our main technical contribution is to show that an algorithm for learning noisy parities gives an algorithm that finds significant Fourier coefficients (i.e. correlated parities) of a function from random samples. Thus an algorithm for learning noisy parities gives an analogue of the Goldreich-Levin/Kushilevitz-Mansour algorithm for the uniform distribution, but without membership queries. This result is proved using Fourier analysis.

Learning DNF formulae
Learning of DNF expressions from random examples is a famous open problem originating from Valiant's seminal paper on PAC learning [Val84]. In this problem we are given access to examples of a Boolean function f on points randomly chosen with respect to distribution D, and > 0. The goal is to find a hypothesis that -approximates f with respect to D in time polynomial in n, s = DNF-size(f ) and 1/ , where DNF-size(f ) is the number of terms in the DNF formula for f with the minimum number of terms. The best known algorithm for learning DNF in this model was given by Klivans and Servedio [KS04a] and runs in time 2O~(n1/3).

88

6.1 Introduction

For learning DNF under the uniform distribution a simple quasi-polynomial algorithm was given by Verbeurgt [Ver90]. His algorithm essentially collects all the terms of size log (s/ ) + O(1) that are consistent with the target function, i.e. do not accept negative points and runs in time O(nlog (s/ )). We are unaware of an algorithm improving on this approach. Jackson [Jac97] proved that DNFs are learnable under the uniform distribution if the learning algorithm is allowed to ask membership queries. This breakthrough and influential result gives essentially the only known approach to learning of unrestricted DNFs in polynomial time.
We show that learning of DNF expressions reduces to learning parities of O(log (s/ )) variables with noise rate  = 1/2 - O~( /s) under the uniform distribution.

Theorem 6.1.2 Let A be an algorithm that learns parities of k variables over {0, 1}n for

every

noise

rate



< 1/2

in

time

T

(n,

k,

1 1-2

)

using

at

most

S(n,

k,

1 1-2

)

examples.

Then

there

exists

an

algorithm

that

learns

DNF

expressions

of

size

s

in

time

O~(

s4
2

·T

(n,

log

B,

B)·

S(n, log B, B)2), where B = O~(s/ ).

Learning k-juntas

A Boolean function is a k-junta if it depends only on k variables out of n. Learning of k-juntas was proposed by Blum and Langley [BL97, Blu94], as a clean formulation of the problem of efficient learning in the presence of irrelevant features. Moreover, for k = O(log n), a k-junta is a special case of a polynomial-size decision tree or a DNF expression. Thus, learning juntas is a first step toward learning polynomial-size decision trees and DNFs under the uniform distribution. A brute force approach to this problem would be to take O(k log n) samples, and then run through all nk subsets of possible relevant variables. The first non-trivial algorithm was given only recently by Mossel et al. [MOS04], and runs in time roughly O(n0.7k). Their algorithm relies on new analysis of the Fourier transform of juntas. However, even the question of whether one can learn k-juntas in polynomial time for k = (1) still remains open (cf. [Blu03a]).
We give a stronger and simpler reduction from the problem of learning k-juntas to learning noisy parities of size k.

Theorem 6.1.3 Let A be an algorithm that learns parities of k variables on {0, 1}n for

every

noise

rate



<

1/2

in

time

T (n, k,

1 1-2

).

Then

there

exists

an

algorithm

that

learns

k-juntas in time O(22kk · T (n, k, 2k-1)).

This reduction also applies to learning k-juntas with random noise. A parity of k variables is a special case of a k-junta. Thus we can reduce the noisy junta problem to a

89

6.2 Preliminaries

special case, at the cost of an increase in the noise level. By suitable modifications, the reduction from DNF can also be made resilient to random noise.
Even though at this stage our reductions for DNFs and juntas do not yield new algorithms they establish connections between well-studied open problems. Our reductions allow one to focus on functions with known and simple structure viz parities, in exchange for having to deal with random noise. They show that a non-trivial algorithm for learning noisy parities of O(log n) variables will help make progress on a number of important questions regarding learning under the uniform distribution.
6.1.2 Organization
The rest of this chapter is organized as follows: we present our main technical Lemma regarding finding significant Fourier coefficients in Section 6.3. We derive the consequences of this Lemma in Sections 6.4.

6.2 Preliminaries
We start by briefly reviewing the relevant learning models. See Sections 2.2 for more details on the models.

6.2.1 Learning Models

The learning models discussed in this work are based on Valiant's well-known PAC model

[Val84]. In this model, for a concept c and distribution D over X, an example oracle

EX(c, D) is an oracle that upon request returns an example x, c(x) where x is chosen

randomly with respect to D. For  0 we say that function g -approximates a function

f with respect to distribution D if PrD[f (x) = g(x)]  1 - . For a concept class C, we say that an algorithm A PAC learns C, if for every > 0, c  C, and distribution D

over X, A given access to EX(c, D) outputs, with probability at least 1/2, a hypothesis

h that -approximates c. The learning algorithm is efficient if it runs in time polynomial

in 1/ , and the size s of the learning problem where the size of the learning problem is

equal to the length of an input to c plus the description length of c in the representation

associated with C. An algorithm is said to weakly learn C if it produces a hypothesis h

that

(

1 2

-

1 p(s)

)-approximates

(or

weakly

approximates)

c

for

some

polynomial

p.

The random classification noise model introduced by Angluin and Laird formalizes

the simplest type of white label noise [AL88]. In this model for any   1/2 called the

noise rate the regular example oracle EX(c, D) is replaced with the noisy oracle EX(c, D).

On each call, EX(c, D), draws x according to D, and returns x, c(x) with probability

90

6.2 Preliminaries

1 -  and x, ¬c(x) with probability . When  approaches 1/2 the label of the corrupted

example approaches the result of a random coin flip, and therefore the running time of

algorithms

in

this

model

is

allowed

to

polynomially

depend

on

1 1-2

.

The agnostic PAC learning model was introduced by Haussler [Hau92] and Kearns et

al. [KSS94] in order to relax the assumption that examples are labeled by a concept from a

specific concept class. In this model no assumptions are made on the function that labels

the examples. In other words, the learning algorithm has no prior beliefs about the target

concept (and hence the name of the model). The goal of the agnostic learning algorithm

for a concept class C is to produce a hypothesis h  C whose error on the target concept

is close to the best possible by a concept from C.

Formally, for two Boolean functions f and h and a distribution D over the domain, we

define D(f, h) = PrD[f = h]. Similarly, for a concept class C and a function f , define D(f, C) = infhC{D(f, h)}. Kearns et al. define the agnostic PAC learning model as follows [KSS94].

Definition 6.2.1 An algorithm A agnostically (PAC) learns a concept class C if for every > 0, a Boolean function f and distribution D over X, A, given access to EX(f, D),
outputs, with probability at least 1/2, a hypothesis h  C such that D(f, h)  D(f, C)+ . As before, the learning algorithm is efficient if it runs in time polynomial in s and 1/ .

One can also consider a more general agnostic learning in which the examples are drawn from an arbitrary distribution over X × {0, 1} (and not necessarily consistent with a function). It is easy to verify that our positive result applies to this setting as well (to see this, note that oracles defined in Definition 6.3.1 can simulate this generalized scenario).
The agnostic learning model can also be thought of as a model of adversarial noise. By definition, a Boolean function f differs from some function in c  C on D(f, C) fraction of the domain (the fraction is measured relative to distribution D). Therefore f can be thought of as c corrupted by noise of rate D(f, C). Unlike in the random classification noise model the points on which a concept can be corrupted are unrestricted and therefore we refer to it as adversarial classification noise. Note that an agnostic learning algorithm will not necessarily find a hypothesis that approximates c ­ any other function in C that differs from f on at most D(f, C) + fraction of the domain is acceptable. This way to view the agnostic learning is convenient when the performance of a learning algorithm depends on the rate of disagreement (that is the noise rate).

6.2.2 Fourier Transform
Our main reduction uses Fourier-analytic techniques which were first introduced to computational learning theory by Linial et al. [LMN93]. In this context we view Boolean
91

6.3 Reduction To Learning Parities with Random Noise
functions as functions f : {0, 1}n  {-1, 1}. All probabilities and expectations are taken with respect to the uniform distribution unless specifically stated otherwise. For a Boolean vector a  {0, 1}n let a(x) = (-1)a·x, where `·' denotes an inner product modulo 2, and let weight(a) denote the Hamming weight of a.
We define an inner product of two real-valued functions over {0, 1}n to be f, g = Ex[f (x)g(x)]. The technique is based on the fact that the set of all parity functions {a(x)}a{0,1}n forms an orthonormal basis of the linear space of real-valued functions over {0, 1}n with the above inner product. This fact implies that any real-valued function f over {0, 1}n can be uniquely represented as a linear combination of parities, that is f (x) = a{0,1}n f^(a)a(x). The coefficient f^(a) is called Fourier coefficient of f on a and equals Ex[f (x)a(x)]; a is called the index and weight(a) the degree of f^(a). We say that a Fourier coefficient f^(a) is -heavy if |f^(a)|  . Let L2(f ) = Ex[(f (x))2]1/2. Parseval's identity states that
(L2(f ))2 = Ex[(f (x))2] = f^2(a)
a
6.3 Reduction To Learning Parities with Random Noise
In this section, we describe our reductions from learning of parities with adversarial noise to learning of parities with random noise. We will also show applications of this reduction to learning of DNF and juntas. We start by describing the main technical component of our reductions: an algorithm that using an algorithm for learning noisy parities, finds a heavy Fourier coefficient of a Boolean function if one exists. Following Jackson [Jac97], we call such an algorithm a weak parity algorithm.
The high-level idea of the reduction is to modify the Fourier spectrum of a function f so that it is "almost" concentrated at a single point. For this, we introduce the notion of a probabilistic oracle for real-valued functions f : {0, 1}n  [-1, 1]. We then present a transformation on oracles that allows us to clear the Fourier coefficients of f not belonging to a particular subspace of {0, 1}n. Using this operation we show that one can simulate an oracle which is close (in statistical distance) to a noisy parity.
6.3.1 Finding Heavy Fourier Coefficients
Given the example oracle for a Boolean function f the main idea of the reduction is to transform this oracle into an oracle for a noisy parity a such that f^(a) is a heavy Fourier coefficient of f . First we define probabilistic oracles for real-valued functions in the range [-1, 1].
92

6.3 Reduction To Learning Parities with Random Noise

Definition 6.3.1 For any function f : {0, 1}n  [-1, 1] a probabilistic oracle O(f ) is the oracle that produces samples x, b , where x is chosen randomly and uniformly from {0, 1}n and b  {-1, +1} is a random variable with expectation f (x).
For a Boolean f this defines exactly EX(f, U ). Random classification noise can also be easily described in this formalism. For   [-1, 1], and f : {0, 1}n  {-1, 1}, define f : {0, 1}n  [-1, 1] as f (x) =  · f (x). A simple calculation shows that O(f ) is just an oracle for f (x) with random noise of rate  = 1/2 - /2. Our next observation is that if the Fourier spectra of f and g are close to each other, then their oracles are close in statistical distance.
Claim 6.3.2 The statistical distance between the outputs of O(f ) and O(g) is upperbounded by L2(f - g).
Proof: For a given x, the probability that O(f ) outputs x, 1 is (1 + f (x))/2 and the probability that it outputs x, -1 is (1 - f (x))/2. Therefore the statistical distance between O(f ) and O(g) equals Ex [|f (x) - g(x)|]. By Cauchy-Schwartz inequality,

(Ex [|f (x) - g(x)|])2  Ex (f (x) - g(x))2
and therefore the statistical distance is upper bounded by L2(f - g). We now describe the main transformation on a probabilistic oracle that will be used
in our reductions. For a function f : {0, 1}n  [-1, 1] and a matrix A  {0, 1}m×n define an A-projection of f to be

fA(x) =

f^(a)a(x),

a{0,1}n,Aa=1m

where the product Aa is performed mod 2.

Lemma 6.3.3 For the function fA defined above: 1. fA(x) = Ep{0,1}m [f (x  AT p)1m (p)]. 2. Given access to the oracle O(f ) one can simulate the oracle O(fA).
Proof: Note that for every a  {0, 1}n and p  {0, 1}m,

a(AT p) = (-1)aT ·(AT p) = (-1)(Aa)T ·p = Aa(p)

Thus if Aa = 1m then Ep[a(AT p)1m(p)] = Ep[Aa1m(p)] = 1 otherwise it is 0. Now let gA(x) = Ep{0,1}m [f (x  AT p)1m (p)]. 93

6.3 Reduction To Learning Parities with Random Noise

We show that gA is the same as the function fA by computing its Fourier coefficients.

gA(a) = Ex[Ep[f (x  AT p)1m(p)a(x)]] = Ep[Ex[f (x  AT p)a(x)]1m(p)] = Ep[f^(a)a(AT p)1m(p)] = f^(a)Ep[a(AT p)1m(p)]
Therefore gA(a) = f^(a) if Aa = 1m and gA(a) = 0 otherwise. This is exactly the definition of fA(x).
For Part 2, we sample x, b , choose random p  {0, 1}m and return xAT p, b·1m(p) . The correctness follows from Part 1 of the Lemma.
We will use Lemma 6.3.3 to project f in a way that separates one of its significant Fourier coefficients from the rest. We will do this by choosing A to be a random m × n matrix for appropriate choice of m.

Lemma 6.3.4 Let f : {0, 1}n  [-1, 1] be any function, and let s = 0n be any vector. Choose A randomly and uniformly from {0, 1}m×n. With probability at least 2-(m+1), the following conditions hold:

fA(s) = f^(s) fA2(a)  L22(f )2-m+1
a{0,1}n\{s}

(6.1) (6.2)

Proof: Event (6.1) holds if As = 1m, which happens with probability 2-m. For every a  {0, 1}n \ {s, 0n} and a randomly uniformly chosen vector v  {0, 1}n,

Prv[v · a = 1 | v · s = 1] = 1/2 Therefore, PrA[Aa = 1m | As = 1m] = 2-m

Whereas for a = 0n, PrA[Aa = 1m] = 0. Hence





EA 

fA2(a) As = 1m

a{0,1}n\{s}



2-mf^2(a)  2-mL22(f ).

a{0,1}n\{s}

94

6.3 Reduction To Learning Parities with Random Noise

By Markov's inequality,





PrA 

fA2(a)  2-m+1L22(f ) As = 1m

a{0,1}n\{s}

 1/2.

Thus conditioned on event (6.1), event (6.2) happens with probability at least 1/2. So both events happen with probability at least 2-(m+1).
Finally, we show that using this transformation, one can use an algorithm for learning noisy parities to get a weak parity algorithm.

Theorem 6.3.5 Let A be an algorithm that learns parities of k variables over {0, 1}n for

every

noise

rate



< 1/2

in

time

T

(n,

k,

1 1-2

)

using

at

most

S(n,

k,

1 1-2

)

examples.

Then

there exists an algorithm WP-R that for every function f : {0, 1}n  [-1, 1] that has a

-heavy Fourier coefficient s of degree at most k, given access to O(f ), with probability at

least 1/2, finds s. Furthermore, WP-R runs in time O(T (n, k, 1/) · S2(n, k, 1/)) and uses

O(S3(n, k, 1/)) random examples.

Proof: Let S = S(n, k, 1/). The algorithm WP-R proceeds in two steps:
1. Let m = 2 log S + 3. Let A  {0, 1}m×n be a randomly chosen matrix and O(fA) be the oracle for A-projection of f . Run the algorithm A on O(fA).
2. If A stops in T (n, k, 1/) steps and outputs r with weight(r)  k, check that r is at least /2-heavy and if so, output it.
Let s be a -heavy Fourier coefficient of degree at most k. Our goal is to simulate an oracle for a function that is close to a noisy version of s(x).
By Lemma 6.3.4, in Step 1, with probability at least 2-m-1 , we create a function fA such that |fA(s)|   and

fA2(a)



2-m+1L22(f )



L22(f ) 4S2



1 4S2

.

a=s

By Claim 6.3.2, the statistical distance between the oracle O(fA) and oracle O(fA(s)s(x))

is bounded by



1/2

L2(fA - fA(s)s(x)) =  (fA2(a))
a=s



1 2S

,

hence this distance is small. Since A uses at most S samples, with probability at least

1 2

,

it

will

not

notice

the

difference

between

the

two

oracles.

But

O(fA(s)s(x))

is

exactly

95

6.4 Applications

the noisy parity s with noise rate 1/2 - fA/2 . If fA   we will get a parity with   1/2 - /2 < 1/2 and otherwise we will get a negation of s with   1/2 - /2. Hence we get (1 - 2)-1  1/, so the algorithm A will learn the parity s when executed either with the oracle O(fA) or its negation. We can check that the coefficient produced by A is indeed heavy using Chernoff bounds (see Lemma 2.3.1), and repeat until we succeed. Using O(2m) = O(S2) repetitions, we will get a /2-heavy Fourier coefficient of degree k with probability at least 1/2. A-projection always clears the coefficient f^(0n) and therefore we need to check whether this coefficient is -heavy separately.
Remark 6.3.6 A function f can have at most L22(f )/2 -heavy Fourier coefficients. Therefore by repeating WP-R O((L22(f )/2) · log (L2(f )/)) = O~(L22(f )/2) times we can, with high probability, obtain all the -heavy Fourier coefficients of f as it is required in some applications of this algorithm.

6.4 Applications
In this section we will demonstrate a number of applications of Theorem 6.3.5.

6.4.1 Learning of Parities with Adversarial Noise

A weak parity algorithm is in its essence an algorithm for learning of parities with adversarial noise. In particular, Theorem 6.3.5 gives the following reduction from adversarial to random noise.

Theorem 6.4.1

The

problem

of

learning

parities

with

adversarial

noise

of

rate



<

1 2

reduces to learning parities with random noise of rate .

Proof: Let f be a parity s corrupted by noise of rate . Then f^(s) = E[f s]  (1 - ) + (-1) = 1 - 2. Now apply the reduction from Theorem 6.3.5 setting k = n. We get an oracle for the function f^(s)s(x), which is s(x) with random noise of level .
Blum et al. give a sub-exponential algorithm for learning noisy parities.

Lemma 6.4.2 ([BKW03]) Parity functions on {0, 1}n can be learned in time and sam-

ple

complexity

2O(

n log

n

)

in

the

presence

of

random

noise

of

rate



for

any

constant



<

1 2

.

This algorithm together with Theorem 6.4.1 gives Theorem 6.1.1. One can also interpret Theorem 6.4.1 in terms of coding theory problems. Learning a
parity function with noise is equivalent to decoding a random linear code from the same type of noise (see Section 5.3 for more details on this equivalence). More formally, we say that a code C is an [m, n] code if C is a binary linear code of block length m and

96

6.4 Applications

message length n. Any such code can be described by its n × m generator matrix G as follows: C = {xG | x  {0, 1}n}. A random linear [m, n] code C is produced by choosing randomly and uniformly a generator matrix G for C (that is, each element of G equals to the outcome of an unbiased coin flip). It is now easy to verify that Theorem 6.3.5 implies the following result.
Theorem 6.4.3 Assume that there exists an algorithm RandCodeRandError that corrects a random linear [m, n] code from random errors of rate  with probability at least 1/2 (over the choice of the code, errors, and the random bits of the algorithm) in time T (m, n). Then there exists an algorithm RandCodeAdvError that corrects a random linear [M, n] code from up to  · M errors with probability at least 1/2 (over the choice of the code and the random bits of the algorithm) in time O(m2 · T (m, n)) for M = O(m3).
The sample bounds in Theorem 6.3.5 correspond to the block length of linear codes. Note that for   1/4, there might be more than one codeword within the relative distance . In this case, by repetitively using RandCodeAdvError as in Remark 6.3.6, we can list-decode the random code.

6.4.2 Learning DNF Expressions
Jackson's celebrated result gives a way to use a weak parity algorithm and Freund's boosting algorithm [Fre95] to build an algorithm for learning DNF expressions with respect to the uniform distribution [Jac97]. His approach can be adapted to our setting. We give an outline of the algorithm and omit the now-standard analysis.
We view a probability distribution D as a density function and define its L norm. Jackson's algorithm is based on the following Lemma (we use a refinement from [BF02]).

Lemma 6.4.4 ([BF02]) For any Boolean function f of DNF-size s and any distribution

D,

over

{0, 1}n

there

exists

a

parity

function

a

such

that

|ED[f a]|



1 2s+1

and

weight(a)  log ((2s + 1)L(2nD)).

This lemma implies that DNFs can be weakly learned by finding a parity correlated with f under distribution D(x) which is the same as finding a parity correlated with the function 2nD(x)f (x) under the uniform distribution. The range of 2nD(x)f (x) is not necessarily [-1, 1], whereas our WP-R algorithm was defined for functions with this range. So in order to apply Theorem 6.3.5, we first scale 2nD(x)f (x) to the range [-1, 1] and obtain the function D (x)f (x), where D (x) = D(x)/L(2nD) (L(D) is known to the boosting algorithm). We then get the probabilistic oracle O(D (x)f (x)) by flipping a ±1 coin

97

6.4 Applications

with expectation D (x)f (x). Therefore a -heavy Fourier coefficient of 2nD(x)f (x) can be found by finding a /L(2nD)-heavy Fourier coefficient of D (x)f (x) and multiplying it by L(2nD). We summarize this generalization in the following lemma.

Lemma 6.4.5 Let A be an algorithm that learns parities of k variables over {0, 1}n for

every

noise

rate



< 1/2

in

time

T

(n,

k,

1 1-2

)

using

at

most

S(n,

k,

1 1-2

)

examples.

Then

there exists an algorithm WP-R' that for every real-valued function  that has a -heavy

Fourier coefficient s of degree at most k, given access to random uniform examples of ,

finds s in time O(T (n, k, L()/) · S(n, k, L()/)2) with probability at least 1/2.

The running time of WP-R' depends on L(2nD) (polynomially if T is a polynomial) and therefore gives us an analogue of Jackson's algorithm for weakly learning DNFs. Hence it can be used with a boosting algorithm that produces distributions that are polynomiallyclose to the uniform distribution; that is, the distribution function is bounded by p2-n where p is a polynomial in learning parameters (such boosting algorithms are called psmooth). In Jackson's result [Jac97], Freund's boost-by-majority algorithm [Fre95] is used to produce distribution functions bounded by O( -(2+)) (for arbitrarily small constant ). More recently, Klivans and Servedio have observed [KS03] that a later algorithm by Freund [Fre92] produces distribution functions bounded by O~( ). By using WP-R' with this boosting algorithm in the same way as in Jackson's DNF learning algorithm, we obtain Theorem 6.1.2.

6.4.3 Learning Juntas
For the class of k-juntas, we can get a simpler reduction with better parameters for noise. Since there are at most 2k non-zero coefficients and each of them is at least 2-k+1-heavy, for a suitable choice of m, the projection step is likely to isolate just one of them. This leaves us with an oracle O(f^(s)s). Since |f^(s)|  2-k+1, the noise parameter is bounded by  < 1/2 - 2-k. Using Remark 6.3.6, we will obtain the complete Fourier spectrum of f by repeating the algorithm O(k22k) times. The proof of Theorem 6.1.3 follows from these observations. Instead of repeating WP-R one can also use a simple recursive procedure of Mossel et al. [MOS04, Sec 3.1] that requires only k invocations of WP-R.

6.4.4 Learning in the Presence of Random Noise
Our reductions from DNFs and k-juntas can be made tolerant to random noise in the original function.
This is easy to see in the case of k-juntas. An oracle for f with classification noise  is the same as an oracle for the function (1 - 2 )f . By repeating the reduction used for

98

6.4 Applications

k-juntas, we get an oracle for the function O((1 - 2 )f^ss). Hence we have the following theorem:

Theorem 6.4.6 Let A be an algorithm that learns parities of k variables on {0, 1}n for

every

noise

rate



<

1/2

in

randomized

time

T (n, k,

1 1-2

).

Then

there

exists

an

algorithm

that learns k-juntas with random noise of rate 

in

time

O(k22k

·

T (n, k,

2k-1 1-2

)).

A noisy parity of k variables is a special case of a k-junta. Thus we have reduced the

noisy junta problem to a special case viz. noisy parity, at the cost of an increase in the

noise level.

Handling noise in the DNF reduction is more subtle since Freund's boosting algorithms

do not necessarily work in the presence of noise. In particular, Jackson's original algorithm

does not handle noisy DNFs (learnability of DNF from noisy membership queries was

established by Jackson et al. [JSS97]). Nevertheless, as we have shown in Section 5.7.1,

the effect of noise can be offset if the weak parity algorithm can handle a "noisy" version of

2nD(x)f (x). More specifically, we need a generalization of the WP-R algorithm that for any

real-valued function (x), finds a heavy Fourier coefficient of (x) given access to (x),

where (x) is an independent random variable with expectation (x) and L((x)) 

2L() 1-2

.

It

is

easy

to

see

that

WP-R'

can

handle

this

case.

Scaling

by

L((x))

will

give

us

a

random variable  (x) in the range [-1, 1] with expectation (x)/L((x)). By flipping

a ±1 coin with expectation  (x) we will get a ±1 random variable with expectation

(x)/L((x)). Therefore WP-R algorithm will find a heavy Fourier coefficient of (x)

(scaled

by

L((x))



2L() 1-2

).

Altogether

we

obtain

the

following

theorem

for

learning

noisy DNFs.

Theorem 6.4.7 Let A be an algorithm that learns parities of k variables on {0, 1}n for

every

noise

rate



< 1/2

in

time

T

(n,

k,

1 1-2

)

using

at

most

S(n,

k,

1 1-2

)

examples.

Then

there exists an algorithm that learns DNF expressions of size s with random noise of rate



in

time

O~(

s4
2

· T (n, log B,

B 1-2

) · S(n, log B,

B 1-2

)2)

where

B

=

O~(s/

).

99

Chapter 7
Hardness of Proper Agnostic Learning of Monomials
In this chapter we study the learnability of monomials (or conjunctions) in the agnostic learning framework of Haussler [Hau92] and Kearns et al. [KSS94]. We show that for any constant , finding a monomial that agrees with an unknown function on 1/2 + fraction of examples is NP-hard even when there exists a monomial that agrees with the unknown function on 1 - fraction of examples. This implies that even weak agnostic learning of monomials is NP-hard, resolving an open question of Blum [Blu98]. This hardness result is optimal and significantly improves on a number of previous results for this problem.
7.1 Introduction
We study the computational complexity of approximation problems arising in agnostic learning of monomials. The agnostic framework [Hau92, KSS94] is a useful variant of Valiant's PAC learning model in which, informally, nothing is known about the target function and a learning algorithm is required to do nearly as well as is possible using hypotheses from a given class. Haussler's work [Hau92] implies that learnability in this model is, in a sense, equivalent to the ability to come up with a member of the hypothesis class that has close-to-the-optimal agreement rate with the given examples.
For a number of concept classes it is known that finding a hypothesis with the best agreement rate is NP-hard [AL88, HvHS95, KL93]. However, for most practical purposes a hypothesis with agreement rate close to the maximum would be sufficient. This reduces agnostic learning of a function class to a natural combinatorial approximation problem or, more precisely, to the following two problems: approximating the maximum agreement rate and the minimum disagreement rate. We address the approximation complexity of
100

7.1 Introduction

these problems for the class of monomials (also referred to as terms). The class of mono-

mials is one of the simplest and most well-studied function classes easily learnable in a

variety of settings. Angluin and Laird proved that finding a monotone monomial with the

maximum agreement rate (this problem is denoted MMon-MA) is NP-hard [AL88]. This

was extended to general monomials by Kearns and Li [KL93] (the problem is denoted

Mon-MA). Ben-David et al. gave the first inapproximability result for this problem, prov-

ing

that

the

maximum

agreement

rate

is

NP-hard

to

approximate

within

a

factor

of

770 767

-

for any constant > 0 [BDEL03]. This result was more recently improved by Bshouty

and

Burroughs

to

the

inapproximability

factor

of

59 58

-

[BB06].

The problem of approximating the minimum disagreement with a monomial (denoted

Mon-MD) was first considered by Kearns et al. who give an approximation preserving

reduction from the SET-COVER problem to Mon-MD (similar result was also obtained

by Hoffgen et al. [HvHS95]). This reduction together with the hardness of approximation

results for SET-COVER due to Lund and Yannakakis [LY94] (see also [RS97]) implies

that Mon-MD is NP-hard to approximate within a factor of c log n for some constant c.

On the positive side, the only non-trivial approximation algorithm is due to Bshouty

and

Burroughs

and

achieves

2-

log n

n

-approximation

for

the

agreement

rate

[BB06].

Note

that factor 2 can always be achieved by either constant 0 or constant 1 function.

In this work, we give the following inapproximability results for Mon-MA.

Theorem 7.1.1 For every constant > 0, Mon-MA is NP-hard to approximate within a factor of 2 - .

Then, under a slightly stronger assumption, we show that the second order term is small.

Theorem 7.1.2 For any constant  > 0, there is no polynomial-time algorithm that approximates Mon-MA within a factor of 2 - 2- log1- n, unless NP  RTIME(npoly log(n)).

Theorem 7.1.2 also implies strong hardness results for Mon-MD.

Corollary 7.1.3 For any constant  > 0, there is no polynomial time algorithm that approximates Mon-MD within a factor of 2log1- n, unless NP  RTIME(npoly log(n)).

In practical terms, these results imply that even very low (sub-constant) amounts of adversarial noise in the examples make finding a term with agreement rate larger (even by very small amount) than 1/2, NP-hard, in other words even weak agnostic learning of monomials is NP-hard. This resolves an open problem due to Blum [Blu98, Blu03b].
All of our results hold for the MMon-MA problem as well. A natural equivalent formulation of the MMon-MA problem is maximizing the number of satisfied monotone disjunction constraints, that is, equations of the form t(x) = b, where t(x) is a disjunction of

101

7.1 Introduction

(unnegated) variables and b  {0, 1}. We denote this problem by MAX-B-MSAT where B is the bound on the number of variables in each disjunction (see Definition 7.2.5 for more details). A corollary of our hardness result for MMon-MA is the following theorem
Theorem 7.1.4 For any constant , there exists a constant B such that MAX-B-MSAT is NP-hard to approximate within 2 - .
This result gives a form of the PCP theorem with imperfect completeness. Finally, we show that Theorems 7.1.1 and 7.1.2 can be easily used to obtain hardness of
agnostic learning results for classes richer than monomials, thereby improving on several known results and establishing hardness of agreement max/minimization for new function classes.
It is important to note that our results do not rule out agnostic learning of monomials when the disagreement rate is very low (i.e. 2- log1-o(1) n), weak agnostic learning with agreement lower than 1/2 + 2- log1-o(1) n, or non-proper agnostic learning of monomials.
Our proof technique is based on using Feige's multi-prover proof system for 3SAT5 (3SAT with each variable occurring in exactly 5 clauses) together with set systems possessing a number of specially-designed properties. The set systems are then constructed by a simple probabilistic algorithm. As in previous approaches, our inapproximability results are eventually based on the PCP theorem. However, previous results reduced the problem to an intermediate problem (such as MAX-CUT, MAX-E2-SAT, or SETCOVER) thereby substantially losing the generality of the constraints. We believe that key ideas of our technique might be useful in dealing with other constraint satisfaction problems involving constraints that are conjunctions or disjunctions of Boolean variables.

7.1.1 Related Work

Besides the results for monomials mentioned earlier, hardness of agnostic learning results

are known for a number of other classes. Optimal hardness results are known for the class

of parities. H°astad proved that approximating agreements with parities within a factor of

2- is NP-hard for any constant . Amaldi and Kann [AK95a], Ben-David et al. [BDEL03],

and Bshouty and Burroughs [BB06] prove hardness of approximating agreements with

halfspaces (factors

262 261

,

418 415

,

and

85 84

,

respectively).

Similar inapproximability results are

also known for 2-term DNF, decision lists and balls [BDEL03, BB06]. Following this work,

Feldman et al. proved that approximating agreements with halfspaces over Rn within a

factor of 2 - is NP-hard for any constant [FGKP06], and, independently, Guruswami

and Raghavendra established the same result for halfspaces over the Boolean hypercube

[GR06].

102

7.2 Preliminaries and Notation
Arora et al. give strong inapproximability results for minimizing disagreements with halfspaces (factor 2log0.5- n) and with parities1 (factor 2log1- n) under the assumption that NP  DTIME(npoly log n). Bshouty and Burroughs prove inapproximability of minimizing disagreements with k-term multivariate polynomials (factor ln n) and a number of other classes [BB02].
For an extension of the agnostic framework where a learner can output a hypothesis from a richer class of functions (see also Section 7.2.1) the first non-trivial algorithm for learning monomials was recently given by Kalai et al. [KKMS05]. Their algorithm learns monomials agnostically in time 2O~(n). They also gave a breakthrough result for agnostic learning of halfspaces by showing a simple algorithm that for any constant > 0 agnostically learns halfspaces with respect to the uniform distribution up to accuracy (both their algorithms output thresholds of parities as hypotheses).
We also note that minimum disagreement cannot be approximated for classes that are known to be not properly learnable, i.e., when a hypothesis has to use the same representation as the class being learned (since in the usual PAC model it is assumed that there exists a hypothesis with zero disagreement rate). In particular, the minimum disagreement with various classes of DNF formulae, intersections of halfspaces, decision trees, and juntas cannot be approximated [PV88, ABF+04].
7.2 Preliminaries and Notation
For a vector v, we denote its ith element by vi (unless explicitly defined otherwise). For a positive integer m we denote [m] = {1, 2, . . . , m}.
The domain of all discussed Boolean functions is the Boolean hypercube {0, 1}n. The ith literal is a function over {0, 1}n equal to the i-th coordinate of a point and denoted xi, or its negation, denoted x¯i. A monomial is a conjunction of literals and/or constants (0 and 1). It is also commonly referred to as a conjunction. A monotone monomial is a monomial that includes only positive literals and constants. We denote the concept class of all monomials by Mon and the class of all monotone monomials by MMon. A DNF formula is a disjunction of terms and a k-term DNF formula is a disjunction of k terms. A halfspace or a threshold function is a function equal to i[n] wixi   (as a Boolean expression), where w1, . . . , wk,  are integers.
1This problem is more commonly known as "finding the nearest codeword".
103

7.2 Preliminaries and Notation
7.2.1 The Problem
Our model of learning is the agnostic PAC learning model [Hau92, KSS94] described in Section 2.2.4. Here we briefly review some of the relevant definitions.
For two Boolean functions f and h and a distribution D over {0, 1}n we define D(f, h) = PrD[f = h]. Similarly, for a class of Boolean functions C and a function f define D(f, C) = minhC{D(f, h)}.
Definition 7.2.1 An algorithm A agnostically (PAC) learns a concept class C if for every > 0, a Boolean function f and distribution D over X, A, given access to EX(f, D),
outputs, with probability at least 1/2, a hypothesis h  C such that D(f, h)  D(f, C)+ . As usual, the learning algorithm is efficient if it runs in time polynomial in n and 1/ .
One can also consider a more general agnostic learning in which the examples are drawn from an arbitrary distribution over X × {0, 1} (and not necessarily consistent with a function). In Remark 7.2.4 we prove that learning in this more general setting is not harder than in the agnostic model defined above.
In this work we will deal with samples of fixed size instead of random examples generated with respect to some distribution. One can easily see that these settings are essentially equivalent. In one direction, given an agnostic learning algorithm and a sample S we can just run the algorithm on examples chosen randomly and uniformly from S, thereby obtaining a hypothesis with the disagreement rate on S equal to the error guaranteed by the agnostic learning algorithm. For the other direction, one can use uniform convergence results for agnostic learning given by Haussler [Hau92] (based on the earlier work in statistical learning theory). They state that for every c  C and sample S of size poly(VC-dim(C), ) randomly drawn with respect to a distribution D, with high probability the true error of c will be within of the disagreement rate of c on S. Monomials over {0, 1}n have VC dimension n and therefore we can, without loss of generality, restrict our attention to algorithms that operate on samples of fixed size.
Besides algorithms with this strong agnostic guarantee it is natural and potentially useful to consider algorithms that output hypotheses with weaker yet non-trivial guarantees (e.g. having error of at most twice the optimum or within an additive constant of the optimum). According to the uniform convergence results, these weaker forms of agnostic learning are equivalent to approximating the maximum agreement rate or the minimum disagreement rate of a function in C with a given sample. We now proceed to define the problems more formally.
For a set of examples S  X × {0, 1}, we denote S+ = {x | x, 1  S} and similarly S- = {x | x, 0  S}. For any function f and a set of examples S, the agreement rate
104

7.2 Preliminaries and Notation

of

f

with

S

is

AgreeR(f, S) =

|Tf

S

+

|+|S |S|

- \Tf

|

,

where

Tf

= {x

|

f (x) = 1}.

For

a

class

of

functions C, let AgreeR(C, S) = maxfC{AgreeR(f, S)}.

Definition 7.2.2 For a class of functions C and domain X, we define the Maximum Agreement problem C-MA as follows: The input is a set of examples S  X × {0, 1}. The problem is to find a function h  C such that AgreeR(h, S) = AgreeR(C, S).

For   1, an -approximation algorithm for C-MA is an algorithm that returns a hypothesis h such that  · AgreeR(h, S)  AgreeR(C, S). Similarly, an -approximation algorithm for the Minimum Disagreement problem C-MD is an algorithm that returns a hypothesis h  C such that 1 - AgreeR(h, S)  (1 - AgreeR(C, S)).
An extension of the original agnostic learning framework is the model in which a hypothesis may come from a richer class H. The corresponding combinatorial problems were introduced by Bshouty and Burroughs and are denoted C/H-MA and C/H-MD [BB06]. Note that an approximation algorithm for these problems can return a value larger than AgreeR(C, S) and therefore cannot be used to approximate the value AgreeR(C, S).
Remark 7.2.3 An -approximation algorithm for C -MA(MD) where C  C  H is an -approximation algorithm for C/H-MA(MD).

Remark 7.2.4 A more general agnostic learning in which random examples are not necessarily consistent with a function corresponds to agreement maximization and disagreement minimization over samples that might contain contradicting examples (i.e. x, 0 and x, 1 ). We remark that such contradicting examples do not make the problems of agreement maximization and disagreement minimization harder. To see this, let S be a sample and let S be S with all contradicting pairs of examples removed (that is for each example x, 0 we remove it together with one example x, 1 ). Every function has the same agreement rate of 1/2 with examples in S \ S . Therefore for any concept class C, AgreeR(C, S) =  ·AgreeR(C, S )+(1-)/2, where  = |S |/|S|. Therefore agreement maximization (or disagreement minimization) over S is equivalent to agreement maximization (or disagreement minimization) over S . The same also holds for approximate agreement maximization and disagreement minimization. This is true since for every function h and   1, if  · AgreeR(h, S )  AgreeR(C, S ) then

·AgreeR(h, S) = ·(·AgreeR(h, S )+(1-)/2)  ·AgreeR(C, S )+(1-)/2 = AgreeR(C, S)
(and similarly for approximate disagreement minimization). Therefore if an agreement maximization or disagreement minimization problem is hard for samples with contradictions then its hard for samples without contradictions and hence the corresponding version of agnostic learning is hard.
105

7.2 Preliminaries and Notation
7.2.2 Agreement with Monomials and Set Covers
For simplicity we first consider the MMon-MA problem. The standard reduction of the general to the monotone case [KLPV87a] implies that this problem is at least as hard to approximate as Mon-MA. We will later observe that our proof will hold for the unrestricted case as well. We start by giving two equivalent ways to formulate MMon-MA.
Definition 7.2.5 The Maximum Monotone Disjunction Constraints problem MAX-MSAT is defined as follows: The input is a set C of monotone disjunction constraints, that is, equations of the form d(x) = b where, d(x) is a monotone disjunction and b  {0, 1}. The output is a point z  {0, 1}n that maximizes the number of satisfied equations in C. For an integer function B, MAX-B-MSAT is the same problem with each disjunction containing at most B variables.
Lemma 7.2.6 MMon-MA is equivalent to MAX-MSAT.
Proof: For a vector v  {0, 1}n, let dv denote the monotone disjunction equal to vi=1xi. Furthermore for a Boolean vector v  {0, 1}n, we denote by v¯ the bitwise negation of v. We claim that a monotone disjunction constraint dv = b is equivalent to example v¯, ¯b in an instance of MMon-MA. To show this, we prove that a point z  {0, 1}n satisfies dv = b if and only if monomial cz = zi=1xi is consistent with example v¯, ¯b . This is true since z satisfies dv = 0 if and only if for all i  [n], zi = 1 implies vi = 0. This is equivalent to saying that zi=1v¯i = 1 or cz is consistent with example v¯, 1 . Similarly, z satisfies dv = 1 if and only if cz is consistent with example v¯, 0 .
Another equivalent way to formulate MMon-MA is the following.
Definition 7.2.7 We define the Balanced Set Cover problem or BAL-SET-COVER as follows. Input: S = (S+, S-, {Si+}i[n], {Si-}i[n]) where S1+, . . . , Sn+  S+ and S1-, . . . , Sn-  S-. Output: A set of indices I that maximizes the sum of two values, Agr-(S, I) = | iI Si-| and Agr+(S, I) = |S+| - | iI Si+|. We denote this sum by Agr(S, I) = Agr-(S, I) + Agr+(S, I) and denote the maximum value of agreement by MMaxAgr(S).
Lemma 7.2.8 MMon-MA is equivalent to BAL-SET-COVER.
Proof: Let S be a set of examples. We define an instance S = (S+, S-, {Si+}i[n], {Si-}i[n]) of BAL-SET-COVER as follows. Let S- = {x | x, 0  S} and S+ = {x | x, 1)  S} (note that this definition is consistent with notation in Section 7.2.1). Now let Si- = {x | x  S- and xi = 0} and Si+ = {x | x  S+ and xi = 0}.
106

7.2 Preliminaries and Notation

Then for any set of indices I  [n], the monotone monomial tI = iI xi is consistent with all the examples in S- that have a zero in at least one of the coordinates with indices
in I, that is, with examples in iI Si-. It is also consistent with all the examples in S+ that do not have zeros in coordinates with indices in I, that is, S+ \ iI Si+. Therefore the number of examples with which tI agrees is exactly Agr(S, I).
For the other direction, let S = (S+, S-, {Si+}i[n], {Si-}i[n]) be an instance of BALSET-COVER. For a point s  S+, let y+(s)  {0, 1}n the point such that for all i  [n],
y+(s)i = 0 if and only if s  Si+. For a point s  S-, we define a point y-(s)  {0, 1}n analogously. Now let

YS = { y+(s), 1 | s  S+}  { y-(s), 0 | s  S-} .

It is easy to see that this mapping is exactly the inverse of the mapping given in the first direction. This implies that for any monotone monomial tI = iI xi, |YS | · AgreeR(tI , YS ) = Agr(S, I).

Remark 7.2.9 Lemmas 7.2.6 and 7.2.8 imply that BAL-SET-COVER is equivalent to MAX-MSAT. In addition, we claim that if in a given instance S of BAL-SET-COVER, every point s  S+  S- belongs to almost t subsets, then every clause of the corresponding instance of MAX-MSAT has at most t variables (i.e. is an instance of MAX-t-MSAT).

Proof: Every point s  S- corresponds to example y-(s), 0 in the equivalent instance of MMon-MA. Recall that for all i  [n], y-(s)i = 0 if and only if s  Si-. Now, according to the transformation given in the proof of Lemma 7.2.6, example v¯, ¯b is equivalent to clause constraint dv = b. This implies that point s corresponds to constraint y-(s)i=0xi = 1. By the definition of y-(s), this is equivalent to sSi-xi = 1. Therefore the clause that corresponds to point s has at most t variables. By the same argument, this also holds for points in S+.
In the rest of the discussion it will be more convenient to work with instances of the Balanced Set Cover problem instead of instances of MMon-MA. It is also possible to formulate Mon-MA in a similar fashion. We need to specify an additional bit for each variable that tells whether this variable is negated in the monomial or not (when it is present). Therefore the formulation uses the same input and the following output. Output(Mon-MA): A set of indices I and a vector v  {0, 1}n that maximizes the value

Agr(S, I, v) = | Zi-| + |S+| - | Zi+|,

iI

iI

107

7.3 Hardness of Approximating Mon-MA and Mon-MD
where Zi+/- = Si+/- if vi = 0 and Zi+/- = S+/- \Si+/- if vi = 1. We denote the maximum value of agreement with a general monomial by MaxAgr(S).
7.3 Hardness of Approximating Mon-MA and Mon-MD
It is easy to see that BAL-SET-COVER is similar to the SET-COVER problem. Indeed, our hardness of approximation result will employ some of the ideas from Feige's hardness of approximation result for SET-COVER [Fei98].
7.3.1 Feige's Multi-Prover Proof System
Feige's reduction to the SET-COVER problem is based on a multi-prover proof system for MAX-3SAT-5 [Fei98]. MAX-3SAT-5 is the problem of maximizing the number of satisfied clauses in a given 3CNF-5 formula, that is a CNF formula with each clause containing exactly 3 variables and each variable appearing in exactly 5 clauses. Using the PCP theorem [ALM+98, AS98], Feige shows that MAX-3SAT-5 is NP-hard to approximate. Namely,
Lemma 7.3.1 ([ALM+98, AS98, Fei98]) There exists a constant  > 0 for which it is NP-hard to distinguish between satisfiable 3CNF-5 formulas and those in which at most (1 -  ) fraction of the clauses can be satisfied simultaneously.
The basis of Feige's proof system is a two-prover protocol for MAX-3SAT-5 in which the verifier chooses a random clause and a random variable in that clause. It then asks for the values of all the variables in the clause from the first prover and for the value of the chosen variable from the second prover. The verifier accepts if the values given by the first prover satisfy the clause and the values of the chosen variable returned by both provers are consistent. It is easy to see, that if the input formula  is satisfiable then there exist provers that will cause the verifier to accept. On the other hand, if at most 1 -  fraction of 's clauses are (simultaneously) satisfiable, then for every prover, the verifier will accept with probability at most 1 -  /3. The soundness of this proof system can be amplified by performing the test times and using Raz' parallel repetition theorem [Raz98]. In Feige's proof system the challenges are distributed to k provers with each prover getting /2 clause questions and /2 variable questions. This is done using an asymptotically-good code with k codewords of length and Hamming weight /2. Specifically, let C = {z(1), z(2), . . . , z(k)} be an asymptotically-good code of length and Hamming weight /2. The prover i gets the j-th clause query for every j such that zj(i) = 1 and gets the j-th variable query for every j such that zj(i) = 0. The verifier accepts if all provers gave answers that satisfy all the clause questions and at least two provers
108

7.3 Hardness of Approximating Mon-MA and Mon-MD

gave consistent answers. Here the fact that C is an asymptotically good code implies that for any i1 = i2, the set (i1, i2) = {j | zj(i1) = zj(i2)} has size at least  · for some constant . This implies that in order to produce consistent answers, provers i1 and i2

have to answer consistently in at least |(i1, i2)|   · challenges. Simple analysis given

by Feige shows that if at most 1 -  clauses of  can be satisfied then this cannot happen

with probability larger than 2-c (for some fixed constant c ). In addition, when  is

satisfiable there exist provers that always answer consistently.

In this protocol choosing 3SAT-5 challenges requires log (5n) random bits. There

are

5 3

n

different

clauses

and

an

answer

to

a

clause

question

consists

of

3

bits.

The

answer

to a variable question is just a single bit. Therefore the query to each prover has length

2

(log

n

+

log

(

5 3

n))

=

log (

5 3

n)

and

a

response

to

such

a

query

is

of

length

2 (3 + 1)

=

2

.

We now summarize the relevant properties of Feige's proof system. For integer k

and such that  c log k for some fixed constant c , Feige's k-prover proof system for

MAX-3SAT-5 has the following properties:

1. Given a 3CNF-5 formula  over n variables, verifier V tosses a random string r of

length

log (5n) and generates k queries q1(r), . . . qk(r) of length

log (

5 3

n).

2. Given answers a1, . . . ak of length 2 from the provers, V computes V1(r, a1), . . . , Vk(r, ak)  [2 ] for fixed functions V1, . . . , Vk. These are the functions that choose a single bit from an answer to each clause question. The bit that is chosen depends only on r.

3. V accepts if there exist i = j such that Vi(r, ai) = Vj(r, aj) and for all i, ai satisfies the clause questions in query qi(r).
4. Completeness: if  is satisfiable, then there exist a k-prover P¯ for which, with probability 1, V1(r, a1) = V2(r, a2) = · · · = Vk(r, ak) and for all i, ai satisfies the clause questions in query qi(r) (note that this is stronger than the acceptance predicate above).

5. Soundness: if at most 1 -  clauses of  can be satisfied simultaneously, then for any P¯, V accepts with probability at most k22-c · for some fixed constant c .

7.3.2 Balanced Set Partitions
As in Feige's proof, the second part of our reduction is a set system with certain properties tailored to be used with the equality predicate in Feige's proof system. Our set system consists of two main parts. The first part is sets grouped by partitions in a way that sets in the same partition are disjoint (and hence correlated) and sets from different partitions

109

7.3 Hardness of Approximating Mon-MA and Mon-MD

are uncorrelated. The second part of our set system is a collection of uncorrelated smaller sets. Formally, a balanced set partition B(m, L, M, k, ) has the following properties:

1. There is a ground set B of m points.

2. There is a collection of L distinct partitions p1, . . . , pL.

3. For i  [L], partition pi is a collection of k disjoint sets Bi,1, . . . , Bi,k  B whose union is B.

4. There is a collection of M sets C1, . . . , CM  B.

5.

Let s,t

=

1

-

(1

-

1 k2

)s(1

-

1 k

)t.

For any I

 [M ] and J

 [L] × [k] with all elements

having different first coordinate (corresponding to partition number), it holds

iI Ci

(i,j)J Bi,j m

- |I|,|J|   .

Property 5 of a balanced set partition implies that each set Bi,j has size approximately m/k and each set Ci has size approximately m/k2. In addition, this property implies that any union of s different Ci's and t Bi,j's from distinct partitions has size approximately equal to s,tm. Here s,tm is the expected size of this union if all elements of Ci's and Bi,j's were chosen randomly and independently.
To see why balanced set partitions are useful in proving hardness of approximating
BAL-SET-COVER, consider an instance S of BAL-SET-COVER defined as follows. For B(m, L, M, k, ) as above, let S+ = S- = B, Sj-,i = Bj,i, and Sj+,i = Bj,1 (note that for all i, Sj+,i = Sj+,1). Now for any j  [L], let Ij = {(j, i) | i  [k]} be index set of all sets in partition j. Then

Agr(S, Ij) =

Bj,i + |B| - |Bj,1| .

i[k]

According to property 3 of S, i[k] Bj,i = B while according to property 5, |Bj,1| 

(

1 k

+ )m.

This

implies

that

Agr(S, Ij)



(2 -

1 k

- )m.

On

the

other

hand,

for

any

index

set I that does not include sets from the same partition, we have that

Agr(S, I) =

Bj,i + |B| -

Bj,1 .

(j,i)I

(j,i)I

By property 5 of balanced set partitions, |( (j,i)I Bj,i)|  (0,|I| + )m, and similarly, |( (j,i)I Bj,1)|  (0,|I| - )m. Therefore Agr(S, I)  (1 + 2)m. For sufficiently large k

110

7.3 Hardness of Approximating Mon-MA and Mon-MD

and sufficiently small , this creates a multiplicative gap of 2 - between the two cases. To relate this to Feige's proof system we design a reduction in which consistent answers from provers corresponds to choosing sets from the same partition, while inconsistent answers correspond to choosing sets from distinct partitions. Then properties 3,4 and 5 of Feige's proof system would imply a multiplicative gap of 2 - for the instances of BAL-SET-COVER that will be created by the reduction.
In our reduction to each set Sj+,i and Sj-,i we add a single set Ck for some k  [M ]. Adding these smaller sets does not substantially influence the agreement rate if the size of I is relatively small. But if the size of I is large then these small sets will cover both S+ and S- resulting in Agr(S, I)  (1 + 2)m. This property of index sets will be required to convert an index set with high agreement rate to a good provers' strategy. In this sense, the addition of smaller sets is analogous to the use of the random skew in H°astad's long code test [Has01].

7.3.3 Creating Balanced Set Partitions

In this section, we show a straightforward randomized algorithm that produces balanced set partitions.

Theorem 7.3.2 There exists a randomized algorithm that on input k, L, M,  produces a balanced set partition B(m, L, M, k, ) for m = O~(k2-2 log (M + L)) in time O((M +
L)m).

Proof: First we create the sets Bj,i. To create each partition j  [L], we roll m k-sided

dice and denote the outcomes by d1, . . . , dm. Set Bj,i = {r | dr = i}. This clearly defines

a collection of disjoint sets whose union is [m]. To create M sets C1, . . . , CM , for each

i



[M ]

and

each

r



[m],

we

include

r

in

Ci

with

probability

1 k2

.

Now let I  [M ] and J  [L] × [k] be a set of indices with different first coordinate

(corresponding to sets from different partitions) and let U = iI Ci

(i,j)J Bi,j .

Elements of these sets are chosen independently and therefore for each r  [m],

Pr[r



U]

=

1

-

(1

-

1 k2

)|I

|(1

-

1 k

)|J

|

=

|I |,|J |

independently of other elements of [m]. Using Chernoff bounds, we get that for any  > 0,

Pr

|U | m

-

|I |,|J |

>

 2e-2m2 ,

which is exactly the property 5 of balanced set partitions (for  = ). Our next step is to ensure that property 5 holds for all possible index sets I and J. This can be done by first

111

7.3 Hardness of Approximating Mon-MA and Mon-MD

observing

that

it

is

enough

to

ensure

that

this

condition

holds

for



=

/2,

|I |



k2

ln

1 

and

|J |



k

ln

1 

.

This

is

true

since

for

|I |



k2

ln

1 

and

every

t,

|I |,t

 1 - .

Therefore

|U |/m - |I|,t  1 - |I|,t   < . For the other side of the bound on the size of the union,

let I

be

a

subset

of

I

of

size

k2 ln

1 

and

U

be the union of sets with indices in I

and J.

It then follows that

|I |,t

-

|U | m



1-

|U | m



1 - (k2 ln

1 

,t

- )



1 - (1 - ) + 

=



.

The

second

condition,

|J |



k

ln

1 

,

is

obtained

analogously.

There are at most M s different index sets I  [M ] of size at most s and at most (kL)t

different index sets J of size at most t. Therefore, the probability that property 5 does

not hold is at most

((kL)k

ln

1 

+

M

k2

ln

1 

)

·

2e-2m2

.

For

m



2k2-2

·

ln

(kL

+

M)

·

ln

2 

+

2,

this probability is less than 1/2. We can now proceed to the reduction itself.

7.3.4 Main Reduction
Below we describe our main transformation from Feige's proof system to BAL-SETCOVER. To avoid confusion we denote the number of variables in a given 3CNF-5 formula by d and use n to denote the number of sets in the produced BAL-SET-COVER instance (that corresponds to the number of variables in the equivalent instance of MMon-MA).
Theorem 7.3.3 For every > 0 (not necessarily constant), there exists an algorithm A that given a 3CNF-5 formula  over d variables, produces an instance S() of BAL-SETCOVER on base sets S+ and S- of size T such that
1. A runs in time dO( ) plus the time to create a balanced set partition B(m, 2 , 4 , 4 , 8 ), where = c1 log 1 for some constant c1, and m = O~( -4) is the size of the ground set of the balanced set partition.
2. |S+| = |S-| = T = (5d) m.
3. n  4 (6d) .
4. If  is satisfiable, then MMaxAgr(S())  (2 - )T .

112

7.3 Hardness of Approximating Mon-MA and Mon-MD

5. If at most 1 -  clauses of  can be satisfied simultaneously, then |MMaxAgr(S()) - T|  ·T.

Proof: Let k = 4 ,  = /8, and V be Feige's verifier for MAX-3SAT-5. Given , we construct an instance S() of BAL-SET-COVER as follows. Let R denote the set of all possible random strings used by V , let Qi denote the set of all possible queries to prover i and let Ai(, q)  {0, 1}2 denote the set of answers of prover i to query q in which all clause questions are satisfied. Let L = 2 , M = 22 , and B(m, L, M, k, ) be a balanced set partition. We set S+ = S- = R × B, and for every r  R and B  B, let (r, B ) denote the set {(r, b) | b  B }. We now proceed to define the sets in S(). Let I = {(q, a, i) | i  [k], q  Qi, a  Ai(, q)}. For (q, a, i)  I, we define

S(-q,a,i) =

(r, BVi(r,a),i  Ca) and

qi(r)=q

S(+q,a,i) =

(r, BVi(r,a),1  Ca) .

qi(r)=q

For r  R, let S()r denote the instance of BAL-SET-COVER obtained by restricting S() to points with the first coordinate equal to r. We also denote the restrictions of S-
and S+ to points with the first coordinate equal to r by Sr- and Sr+. It is easy to see that
for every I  I, Agr(S(), I) = rR Agr(S()r, I). Intuitively, sets S(-q,a,i) (or S(+q,a,i)) correspond to prover i responding a when presented
with query q. We can also immediately observe that answers from different provers that

are mapped to the same value (and hence cause the verifier to accept) correspond to sets in S- that are almost disjoint and strongly overlapping sets in S+ (following the idea

outlined in Section 7.3.2). To formalize this intuition, we prove the following claim.

Claim 7.3.4 If  is satisfiable, then MMaxAgr(S())  (2 - )T for T = m|R|.
Proof: Let P¯ be the k-prover that always answers correctly and consistently and let Pi(q) denote the answer of the ith prover to question q. By the correctness of P¯, Pi(q)  Ai(, q), and therefore we can define

I = {(q, Pi(q), i) | i  [k], q  Qi} . For each r  R, the prover P¯ satisfies

V1(r, P1(q1(r))) = V2(r, P2(q2(r))) = · · · = Vk(r, Pk(qk(r))) = c(r) .

113

7.3 Hardness of Approximating Mon-MA and Mon-MD

Therefore,

Sr- 

S(-qi(r),Pi(qi(r)),i) 

(r, Bc(r),i) = (r, B) = Sr- .

i[k]

i[k]

This means that sets with indices in I cover all the points in S- = R×B, or Agr-(S(), I) = m|R| = T . On the other hand for each r  R,

Sr+ 

S(+qi(r),Pi(qi(r)),i) =

(r, Bc(r),1  CPi(qi(r)))

i[k]

i[k]

=(r, Bc(r),1)  (r,

CPi(qi(r))) .

i[k]

This implies that for each r, only (r, Bc(r),1  i[k] CPi(qi(r))) is covered in Sr+ = (r, B). By property 5 of balanced set partitions, the size of this set is at most

(1

-

(1

-

1 k

)(1

-

1 k2

)k

+

)m



(1

-

(1

-

1 k

)2

+

)m



(

2 k

+

)m

<

m.

This means that Agr+(S(), I)  m|R| = T . Altogether,

Agr(S(), I)  (1 + 1 - )m|R| = (2 - )T .

(Claim 7.3.4) We now deal with the case when at most 1 -  clauses of  can be satisfied simultaneously. Our goal is to show that, for every I  I, if Agr(S(), I) is "significantly" larger than (1 + )T (or smaller than (1 - )T ) then I can be used to design k provers that violate the soundness guarantee of the verifier V . We now briefly outline the idea of the proof. If I has agreement larger than (1 + )|B| with S()r then it must include sets from the same partition (see Section 7.3.2 for an outline of the proof of this). Sets in the same partition correspond to consistent answers and therefore can be used by provers to "fool" V . In order to enable the provers to find consistent answers, we need to make sure that the set of all answers corresponding to a certain query to a prover is not "too" large. This is ensured by the inclusion of Ca's in S(+q/,a-,i)'s (and this is exactly the reason why these sets are needed). If "too" many different answers correspond to a certain query then the included Ca's will cover almost all of (r, B). In this situation the agreement of I with S()r cannot be larger than (1 + )|B| (or smaller than (1 - )|B|) and hence the number of possible answers is not "too" large. We now give the formal analysis of this case.

114

7.3 Hardness of Approximating Mon-MA and Mon-MD

We say that r is good if |Agr(S()r, I) - m| > 2 m, and let I denote the fraction of good r's. Then

Agr(S(), I)  I · 2T + (1 - I )(1 + /2)T  (1 + /2 + 2I )T , and

Hence,

Agr(S(), I)  (1 - I )(1 - /2)T  (1 - /2 - I )T .

|Agr(S(), I) - T |  ( /2 + 2I )T.

(7.1)

Claim 7.3.5 If at most 1 -  clauses of  can be satisfied simultaneously then for any set of indices I  I, there exists a prover P¯ that will make the verifier V accept with probability at least I (k2 ln 8 )-2.

Proof: We define P¯ with the following randomized strategy. Let q be a question to

prover i. Let Pi be the prover that presented with q, answers with a random element from Aqi = {a | (q, a, i)  I}. We will show that properties of B imply that, for any good r, there exist i , j , ai  Aqii (r) and aj  Aqjj (r) such that Vi (r, ai ) = Vj (r, aj ). That
is, for a random string r, V accepts given answers ai and aj from provers i and j . In addition, we will show that for a good r  R and all i  [k], |Aqii(r)|  k2 ln 8 . This would imply that, with probability at least (k2 ln 8 )-2, Pi will choose ai and Pj will choose aj causing V to accept. As this happens for all good r's, the success probability of P¯ is at

least I (k2 ln 8 )-2 (as claimed by the lemma).
We now prove that both properties hold for any good random string r. First denote Vir = {Vi(r, a) | a  Aqii(r)}. This is the set of all values computed by V when used with our prover Pi on a random string r (see property 2 of Feige's proof system). By the definition of S(), this is also the set of all partition indices of sets in I that cover Sr-/+.

Therefore,





Agr-(S()r, I) = Sr-  

S(-q,a,i)



 (q,a,i)I



=

Bj,i

i[k], jVir



Ca .

i[k], aAqi i(r)

(7.2)

Now, if for all i = j, Vir  Vjr = , then all elements in sets V1r, . . . , Vkr are distinct and therefore, by property 5 of balanced set partitions,

115

7.3 Hardness of Approximating Mon-MA and Mon-MD

Agr-(S()r, I) m

-

1

+

(1

-

1 k2

)s(1

-

1 k

)t

 ,

(7.3)

where s =

i[k] Aqii(r) and t = i[k] |Vir|. Similarly,





Agr+(S()r, I) = m - Sr+  

S(+q,a,i)



 (q,a,i)I



=m- 

Bj,1

i[k], jVir



Ca .

i[k], aAqi i(r)

(7.4)

Again, if for all i = j, Vir  Vjr = , then by property 5 of balanced set partitions,







1 m

Bj,1

i[k], jVir



Ca

-

1

+

(1

-

1 k2

)s(1

-

1 k

)t

 .

i[k], aAqi i(r)

Hence

Agr+ (S ()r , m

I)

-

(1

-

1 k2

)s(1

-

1 k

)t

 .

(7.5)

This implies (by combining equations (7.3) and (7.5)) that |Agr(S()r, I) - m|  2m <

2 m, and therefore r is not good. In particular, for any good r, there exist i and j such that Vir  Vjr = . By the definition of Vir, this implies that there exist ai  Aqii (r) and

aj  Aqjj (r) such that Vi (r, ai ) = Vj (r, aj ). This gives the first property of good r's.

Now assume that for a good r and some i  [k], |Aqii (r)|  k2 ln 8 . Then s =

i[k] Aqi i(r)



k2 ln

8

and

in

particular,

(1 -

1 k2

)s

<

8.

This

means

that

Ca  (1 - 8 - )m .
i[k], aAqi i(r)

Equations (7.2) and (7.4) imply that Agr-(S()r, I)  (1 - 8 - )m and Agr+(S()r, I)  ( 8 + )m. Altogether, this would again imply that |Agr(S()r, I) - m|  ( 4 + 2)m = 2 m, contradicting the assumption that r is good. This gives the second property of good r's

and hence finishes the proof of the claim.

(Claim 7.3.5)

116

7.3 Hardness of Approximating Mon-MA and Mon-MD

Using the bound on the soundness of V , Claim 7.3.5 implies that I (k2 ln 8 )-2  k22-c · , or I  (k3 ln 8 )22-c · . Thus for

=

1 c

log ( 4 (k3

ln

8 )2)



c1

log

1

we get I  4 . We set c1 to be at least as large as c (constant defined in Section 7.3.1). For I  4 equation (7.1) gives |Agr(S(), I) - T |  T . The total number of sets used in the reduction n = |I| = k · |Q| · |A|, where |Q| is the number of different queries that

a prover can get and |A| is the total number of answers that a prover can return (both

|A| and |Q| are equal for all the provers). Therefore, by the properties 1 and 2 of Feige's

proof system,

n = 4 · 22 · 2 log (

5 3

·d)

=

4

·

(4

5 3

·

d)

< 4 · (6d)

.

Finally, according to Theorem 7.3.2, m = O~( -4). Construction of S() takes time poly-

nomial (in fact even linear) in its size. There are 2n subsets in S(), each of size at most m · |Q|. Therefore, given the balanced set partition B, the reduction takes dO( ) time.

(Theorem 7.3.3)

BAL-SET-COVER is equivalent to MMon-MA and therefore this reduction is sufficient

for obtaining hardness of approximation for MMon-MA. However, it does not immediately

imply hardness of approximation for Mon-MA. Mon-MA corresponds to a generalized

version of BAL-SET-COVER described in Section 7.2.2. There, in addition to a set of

indices I, a candidate solution includes a vector v  {0, 1}n. The agreement of an instance

S() with (I, v) is defined to be

Agr(S(), I, v) = | Zi-| + |S+| - | Zi+|,

iI

iI

where Zi+/- = Si+/- if vi = 0 and Zi+/- = S+/- \ Si+/- if vi = 1. Note that if  is satisfiable then MaxAgr(S())  MMaxAgr(S())  (2 - )T . Therefore to extend our
reduction to Mon-MA, it is sufficient to show the following claim.

Claim 7.3.6 In the conditions of Theorem 7.3.3 and for an unsatisfiable , |MaxAgr(S())- T|  ·T.

Proof: Assume that the claim does not hold and let I and v be such that |Agr(S(), I, v)- T | > · T . Clearly, v = 0n (since 0n is exactly the case handled by Theorem 7.3.3). Let (q, a, i)  I be the index for which v(q,a,i) = 1. The set Z(-q,a,i) = S- \ S(-q,a,i) has size

117

7.4 Results and Applications T - |S(-q,a,i)|. But

|S(-q,a,i)| =

(r, BVi(r,a),i  Ca) < |R||BVi(r,a),i  Ca)|  |R|(1,1 + )

qi(r)=q



|R|(

1 k

+

1 k2

+

)



|R|

/2

and therefore |Z(-q,a,i)| > (1 - /2)T . Similarly, |Z(+q,a,i)| > (1 - /2)T . This implies that (1 - )T  Agr(S(), I, v)  (1 + )T . Hence we have arrived at a contradiction.
In order to use this reduction to prove hardness of MAX-B-MSAT we need to show
an additional property of the main reduction.

Lemma 7.3.7 For every instance S() of BAL-SET-COVER generated by algorithm A, each point (r, b)  R × B appears in at most poly(1/ ) subsets in S().

Proof: According to the definition of S(-q,a,i), a point (r, b)  S(-q,a,i) only if q = qi(r). Therefore, there are at most k · |Ai(, q)|  k · 22 = O( -2c1-1) sets containing (r, b). The
same applies to any (r, b)  S+.

7.4 Results and Applications

We are now ready to use the reduction from Section 7.3.4 with balanced set partitions from Section 7.3.3 to prove our main theorems.

Theorem 7.4.1 (same as 7.1.1) For every constant > 0, MMon/Mon-MA is NPhard to approximate within a factor of 2 - .

Proof: We use Theorem 7.3.3 for = /3. For a satisfiable formula , the reduction

produces an instance S() of BAL-SET-COVER such that MMaxAgr(S())  (2 - ) ·

T = (2 - /3) · T . If at most 1 -  clauses of  can be satisfied simultaneously, then

MMaxAgr(S())  (1 + ) · T = (1 + /3) · T . The multiplicative gap between these two

cases is

2- 1+

/3 /3

> 2-

and therefore a (2 - )-approximating algorithm for Mon-MA or

MMon-MA can distinguish between them. By Lemma 7.3.1, this is NP-hard. To finish the

proof we also need to verify that our reduction is efficient. In this reduction k = 4 ,  = 8 , and = c1 log (1/ ) are constants and therefore B(m, 2 , 4 , 4 , 8 ) can be constructed in
constant randomized time. The reduction creates an instance of BAL-SET-COVER of

size polynomial in d and runs in time dO( ) = poly(d). By derandomizing the construction

of B in the trivial way, we get a deterministic polynomial-time reduction.

118

7.4 Results and Applications

Furthermore, Remark 7.2.9 and Lemma 7.3.7 imply that for any constant , there exists a constant B such that MAX-B-MSAT is NP-hard to approximate within 2 - , proving Theorem 7.1.4.
Theorem 7.1.1 can be easily extended to sub-constant .

Theorem 7.4.2 (same as 7.1.2) For any constant  > 0, there is no polynomial-time algorithm that approximates MMon/Mon-MA within a factor of 2 - 2- log1- n, unless NP  RTIME(npoly log(n)).

Proof: We repeat the proof of Theorem 7.4.1 with = 2- logr d for some r to be specified

later. Then k = 12 · 2logr d,  = 2- logr d/24 and = c1 · logr d. Therefore, according to Theorem 7.3.2, B(m, 2 , 4 , 12 , 24 ) can be constructed in polynomial in 2logr d randomized time and m = 2c2 logr d. The rest of the reduction takes time dO( ) = 2O(logr+1 d) and creates

an instance of BAL-SET-COVER over n = dc3 logr d = 2c3 logr+1 d variables. Therefore, for

r

=

1 

,

log1-

n



c4

log(r+1)

r-1 r

d

<

logr

d

for large enough d. Therefore the reduction implies hardness of approximating MMon/MonMA within a factor 2 - = 2 - 2- logr d > 2 - 2- log1- n.

It is easy to see that the gap in the agreement rate between 1 - and 1/2 + implies

a gap in the disagreement rate of 1/2-

>

1 3

(for small enough

). That is, Theorem 7.4.2

gives the following multiplicative gap for approximating Mon-MD.

Corollary 7.4.3 (same as 7.1.3) For any constant  > 0, there is no polynomial time algorithm that approximates MMon/Mon-MD within a factor of 2log1- n, unless NP  RTIME(npoly log(n)).

A simple application of these results is hardness of approximate agreement maximiza-

tion with function classes richer than monomials. More specifically, let C be a class that

includes monotone monomials. Assume that for every f  C such that f has high agree-

ment with the sample, one can extract a monomial with "relatively" high agreement. Then

we could approximate the agreement or the disagreement rate with monomials, contra-

dicting Theorems 7.1.1 and 7.1.2. A simple and, in fact, the most general class with this

property, is the class of thresholds of monomials with low integer weights. Let THW (C)

denote

the

class

of

all

functions

equal

to

1 2

+

1 2

sign(

ik wi(2fi - 1)), where k, w1, . . . , wk

are integer, ik |wi|  W , and f1, . . . , fk  C (this definition of a threshold function is

simply sign( ik wifi) when fi and the resulting function are in the range {-1, +1}).

The following lemma is a straightforward generalization of a simple lemma due to Hajnal

et al. [HMP+93] (the original version is for  = 0).

119

7.4 Results and Applications

Lemma 7.4.4 Let C be a class of functions and let f = i[k] hi  THW (C). If for some

function g and distribution D, PrD[f = g]  1 - , then there exists j  [k] such that

|PrD [hj

=

g] - 1/2|



1-(W 2W

+1)

.

Proof: Let D be the distribution D conditioned on f (x) = g(x). By the definition of D ,

PrD [f = g] = 1. We can therefore apply the original lemma ( = 0) and get that there

exists hj

C

such that |PrD [hj

= g] - 1/2| 

1 2W

.

If PrD [hj

=

g]



1/2

+

1 2W

then

PrD [hj

=

g] 

(1

-

)(

1 2

+

1 2W

)

=

1 2

+

1 - (W 2W

+ 1)

.

Similarly, if PrD [hj

=

g]



1/2

-

1 2W

then PrD[hj

= g] 

1 2

-

1-(W 2W

+1)

.

Combining these

inequalities gives the claim.

Lemma 7.4.4 implies the following results.

Corollary 7.4.5 For any constant  > 0 and t = 2log1- n, there is no polynomial-
time algorithm that approximates MMon/THt(Mon)-MD within a factor of t, unless NP  RTIME(npoly log(n)).

Proof: We use Theorem 7.3.3 for

=

1 t2

.

Let

S

be

the

set

of

examples

in

the

instance

of

MMon-MA equivalent to the instance S() of BAL-SET-COVER. If there exists a mono-

mial with the disagreement rate with S of at most

/2

=

1 2t2

then

a

t-approximation

algorithm for MMon/THt(Mon)-MD will produce a function f  THt(Mon) with the dis-

agreement

rate

of

at

most

1 2t

with

S.

By

Lemma

7.4.4,

there

exist

a

monomial

h

of

f

such

that

|AgreeR(h, S) -

1 2

|



1-

1 2t

(t

+

1)

2t

=

1 4t

-

1 4t2

>

1 2t2

.

To apply the lemma we take D to be uniform over S. Therefore the approximation

algorithm can distinguish between this case and the case when no monomial has agreement

rate within

/2

=

1 2t2

of

1/2.

The parameters of the reduction are analogous to those in the proof of Theorem 7.4.2

and hence the resulting assumption is the same.

Corollary 7.4.6 For every integer constant W  1 and constant > 0, MMon/THW (Mon)-

MA

is

NP-hard

to

approximate

within

a

factor

of

1+

1 W

-

.

Proof: The reduction in Theorem 7.1.1 proves hardness of distinguishing instances of

MMon-MA with the maximum agreement rate  being  1- 2 and instances for which |-

1/2|  2 . If there exists an algorithm that, given sample S such that AgreeR(MMon, S) 

1-

2,

can

produce

a

function

f



THW (Mon)

such

that

f

agrees

with

at

least

W W +1

+

120

7.4 Results and Applications

fraction of examples then, by Lemma 7.4.4 (for D being the uniform distribution over S

and



=

1

-

(

W W +1

+

)), one of the monomials of f

has agreement rate  that satisfies

|

-

1 2

|



1

-

(W 2W

+

1)



1

-

(

1 W +1

-

2W

)(W

+

1)

=

(W + 1) 2W

>

2

.

Producing

f

that

agrees

with

at

least

W W +1

+

fraction of examples can be done by a

1- /2

W W +1

+

-

approximation algorithm for MMon/THW (Mon)-MA. Therefore, MMon/THW (Mon)-MA

cannot be approximated within

1 - /2

W W +1

+

=

1

+

1

-

3 2

W+

(W (W

+ 1) + 1)



1

+

1 W

-

for = 3(W +1) .

A

k-term

DNF

t1  t2  · · ·  tk

can

be

expressed

as

1 2

+

1 2

sign(

i[k](-1)ti + (k - 1)),

where ti = 2ti -1 (here sign(0) is defined to be 1). Therefore k-term DNF TH2k-1(Mon).

This implies that Corollary 7.4.6 improves the best known inapproximability factor for (2-

term

DNF)-MA

from

59 58

-

[BB06] to 4/3 -

and gives the first result on hardness of

agreement maximization with thresholds of any constant number of terms.

121

Chapter 8
Conclusions and Further Directions
In this thesis we presented positive and negative results on a number of central problems in learning theory, most notably the problem of learning DNF expressions. We saw some powerful applications of the recent advanced techniques for proving inapproximability results and new techniques for manipulating the Fourier transform of real-valued functions. We believe that our contribution as well as many other recent developments in learning theory provide grounds for optimism about the prospects for resolving of many other fundamental questions.
In this chapter we highlight some of the major open questions related to this research and a number of directions in which our work might be extended.
Proper learning
In Chapter 3 we have conclusively answered the questions of proper learning of DNF expressions and intersections (or unions) of thresholds in the PAC+MQ model. In Chapter 4 we also made some progress toward proving hardness of proper PAC+MQ learning of DNF when the distribution is uniform. It is easy to see that, in the uniform case finding a DNF hypothesis log (s/ ) times larger than the target can be achieved in time nlog (s/ ), and therefore, is unlikely to be NP-hard. This means that substantial improvements of the result will have to be based on different (probably stronger) assumptions. In fact, we believe that it is likely that DNF are learnable properly in this model. In this situation our hardness result would be close to optimal. A small improvement of our result could be achieved by closing the gap between O(d) and d for approximating TT-MinDNF, a problem of independent interest.
122

An important way in which this line of research might be extended is to consider algorithms that use richer representations for their hypotheses. The closest natural candidates are Boolean circuits of depth 3 (or any constant depth) and polynomial threshold functions (or linear thresholds of monomials). Among the algorithms that use these representations as their hypotheses are Bshouty's algorithm for learning decision trees using membership queries [Bsh95] and Jackson's algorithm for learning DNF [Jac97] (the original version outputs a majority of parities but the algorithm can be modified easily to produce a majority of monomials). Clearly, the ultimate goal would be to prove hardness results without any restrictions on the representation of hypotheses (other than it being a circuit of polynomial size).
Learning with respect to the uniform distribution
In Chapter 5 we gave an algorithm for learning DNF that is relatively fast and has several other useful properties (attribute-efficiency, non-adaptiveness, and noise-tolerance). Quite surprisingly, our algorithm and all other known efficient algorithms for learning unrestricted DNF with respect to the uniform distribution [Jac97, JSS97, BJT04, BF02, BMOS03] use the same approach (due to Jackson): learn weakly by finding a correlated parity and then boost the accuracy. It seems that this approach has a significant overhead in terms of the running time complexity, and the running time of our algorithm appears to be close to the limits of this technique. Therefore it would be interesting to explore other approaches to learning DNF in this setting.
An important open question is whether DNF expressions are learnable without membership queries. As we noted in the introduction, even the potentially simpler question: "Are (1)-juntas efficiently learnable with respect to the uniform distribution?" is still unresolved1. The results of Chapter 6 imply that progress on this question could be achieved by showing an algorithm for learning parities of (1) variables with noise of rate 1/2-o(1). Indeed it is plausible that there exists a better algorithm than exhaustive search for this variant of the problem, as in the case of (unrestricted) noisy parities [BKW03].
Agnostic Learning
The results of Chapter 7 have essentially ruled out any interesting form of proper agnostic learning of monomials, adding to the present strong evidence of the hardness of this problem. Similar negative results were recently shown for halfspaces [FGKP06, GR06]. While the reduction in Chapter 6 does show that agnostic learning of parities is not
1Avrim Blum has declared a reward of $1000 for the "head" of this problem [Blu03a].
123

harder than learning parities with random noise, the problem is still apparently very hard. Many fundamental problems in this model remain open; including the representationindependent learnability of monomials, parities, and thresholds. From a more theoretical perspective, it is very interesting to understand the limits of learnability in this natural model. Besides that, as demonstrated by this thesis, the study of this model has strong connections to significant problems in other areas of the theory of computation.
The agnostic learning model, when seen as a noise model, allows the labels of examples to be corrupted by an adversary with unlimited computational power, which is overly pessimistic for most real-life learning scenarios. The only other well-studied model of noise is the random classification noise model, which is often too benign. Therefore, from a more practical perspective, it is important to define and investigate models that place more realistic assumptions on the nature of noise. The difficulty of this task lies primarily in finding models that are both natural and general enough to be applicable to a variety of contexts.
124

Bibliography

[ABF+04] M. Alekhnovich, M. Braverman, V. Feldman, A. Klivans, and T. Pitassi. Learnability and automizability. In Proceeding of FOCS, pages 621­630, 2004.

[AGGR05] R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data. Data Mining and Knowledge Discovery, 11(1):5­33, July 2005.

[AHM+06] E. Allender, L. Hellerstein, P. McCabe, T. Pitassi, and M.Saks. Minimizing DNF formulas and AC0 circuits given a truth table. In Proceedings of IEEE
Conference on Computational Complexity, pages 237­251, 2006.

[AHPM04] E. Allender, L. Hellerstein, T. Pitassi, and M.Saks. On the complexity of finding minimal representations of boolean functions. 2004. Unpublished.

[AHU74]

A. Aho, J. Hopcroft, and J. Ullman. The Design and Analysis of Computer Algorithms. Addison-Wesley Series in Computer Science and Information Processing. Addison-Wesley, 1974.

[AK95a]

E. Amaldi and V. Kann. The complexity and approximability of finding maximum feasible subsystems of linear relations. Theoretical Computer Science, 147(1&2):181­210, 1995.

[AK95b] D. Angluin and M. Kharitonov. When won't membership queries help? Journal of Computer and System Sciences, 50(2):336­355, 1995.

[AL88]

D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 2:343­370, 1988.

[ALM+98] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof verification and the hardness of approximation problems. Journal of the ACM, 45(3):501­ 555, 1998.

[Ang87]

D. Angluin. Learning Regular Sets from Queries and Counterexamples. Information and Computation, 75(2):87­106, 1987.

[Ang88]

D. Angluin. Queries and concept learning. Machine Learning, 2:319­342, 1988.

125

BIBLIOGRAPHY

[AS98]

S. Arora and S. Safra. Probabilistic checking of proofs : A new characterization of NP. Journal of the ACM, 45(1):70­122, 1998.

[Bar97]

A. Barg. Complexity issues in coding theory. Electronic Colloquium on Computational Complexity (ECCC), 4(046), 1997.

[BB02]

N. Bshouty and L. Burroughs. Bounds for the minimum disagreement problem with applications to learning theory. In Proceedings of COLT, pages 271­286, 2002.

[BB06]

N. Bshouty and L. Burroughs. Maximizing agreements and coagnostic learning. Theoretical Computer Science, 350(1):24­39, 2006.

[BDEL03] S. Ben-David, N. Eiron, and P. M. Long. On the difficulty of approximately maximizing agreements. Journal of Computer and System Sciences, 66(3):496­514, 2003.

[BEHW87] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. Occam's razor. Information Processing Letters, 24:377­380, 1987.

[BF02]

N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership queries. Journal of Machine Learning Research, 2:359­395, 2002.

[BGLR93] M. Bellare, S. Goldwasser, C. Lund, and A. Russell. Efficient probabilistically checkable proofs and applications to approximations. In Proceedings of STOC, pages 294­304, 1993.

[BH98]

N. Bshouty and L. Hellerstein. Attribute efficient learning with queries. Journal of Computer and System Sciences, 56:310­319, 1998.

[BHL95]

A. Blum, L. Hellerstein, and N. Littlestone. Learning in the presence of finitely or infinitely many irrelevant attributes. Journal of Computer and System Sciences, 50:32­40, 1995.

[BJT99]

N. Bshouty, J. Jackson, and C. Tamon. More efficient PAC learning of DNF with membership queries under the uniform distribution. In Proceedings of COLT, pages 286­295, 1999.

[BJT04]

N. Bshouty, J. Jackson, and C. Tamon. More efficient PAC-learning of DNF with membership queries under the uniform distribution. Journal of Computer and System Sciences, 68(1):205­234, 2004.

[BKW00]

A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. In Proceedings of STOC, pages 435­440. ACM Press, 2000.

[BKW03]

A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. Journal of the ACM, 50(4):506­519, 2003.

126

BIBLIOGRAPHY

[BL97]

A. Blum and P. Langley. Selection of relevant features and examples in machine learning. Artificial Intelligence, 97(1-2):245­271, 1997.

[Blu94]

A. Blum. Relevant examples and relevant features: Thoughts from computational learning theory, 1994. In AAAI Fall Symposium on `Relevance'.

[Blu98]

A. Blum. Lecture notes for 15-854 machine learning theory. Available at http://www.cs.cmu.edu/~avrim/ML98/index.html, 1998.

[Blu03a] A. Blum. Open problem: Learning a function of r relevant variables. In Proceeding of COLT, pages 731­733, 2003.

[Blu03b]

A. Blum. Tutorial on Machine Learning Theory given at FOCS '03, 2003. Available at http://www.cs.cmu.edu/~avrim/Talks/FOCS03/.

[BMOS03] N. Bshouty, E. Mossel, R. O'Donnell, and R. Servedio. Learning DNF from random walks. In Proceedings of FOCS, pages 189­199, 2003.

[BMvT78] E. Berlekamp, R. McEliece, and H. van Tilborg. On the inherent intractability of certain coding problems. IEEE Transactions on Information Theory, 24, 1978.

[BR92]

A. L. Blum and R. L. Rivest. Training a 3-node neural network is NPcomplete. Neural Networks, 5(1):117­127, 1992.

[BR95]

A. Blum and S. Rudich. Fast learning of k-term DNF formulas with queries. Journal of Computer and System Sciences, 51(3):367­373, 1995.

[Bsh95]

N. Bshouty. Exact learning via the monotone theory. Information and Computation, 123(1):146­153, 1995.

[Bsh96]

N. Bshouty. A subexponential exact learning algorithm for DNF using equivalence queries. Information Processing Letters, 59:37­39, 1996.

[BT96]

N. Bshouty and C. Tamon. On the Fourier spectrum of monotone functions. Journal of the ACM, 43(4):747­770, 1996.

[Che52]

H. Chernoff. A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. Ann. Math. Statist., 23:493­507, 1952.

[Chv79]

V. Chv`atal. A greedy heuristic for the set-covering problem. Mathematics of Operations Research, 4:233­235, 1979.

[CM94]

O. Coudert and J. Madre. METAPRIME, an Interactive Fault-Tree Analyser. IEEE Transactions on Reliability, 43(1):121­127, 1994.

[CS01]

O. Coudert and T. Sasao. Two-level logic minimization. In R. Brayton, S. Hassoun, and T. Sasao, editors, Logic Synthesis and Verification, pages 1­29. Kluwer, 2001.

127

BIBLIOGRAPHY

[CT65]

J. Cooley and J. Tukey. An Algorithm for the Machine Calculation of Complex Fourier Series. Math. Computat., 19:297­301, 1965.

[Czo99]

S. Czort. The complexity of minimizing disjunctive normal form formulas. Master's thesis, University of Aarhus, 1999.

[Dam98] P. Damaschke. Adaptive versus nonadaptive attribute-efficient learning. In Proceedings of STOC, pages 590­596, 1998.

[DGKR05] I. Dinur, V. Guruswami, S. Khot, and O. Regev. A new multilayered pcp and the hardness of hypergraph vertex cover. SIAM Journal of Computing, 34(5):1129­1146, 2005.

[DGR99] S. Decatur, O. Goldreich, and D. Ron. Computational sample complexity. SIAM Journal on Computing, 29(3):854­879, 1999.

[DHW91]

N. Littlestone D. Haussler, M.Kearns and M. Warmuth. Equivalence of models for polynomial learnability. Information and Computation, 95(2):129­161, 1991.

[DRS02] I. Dinur, O. Regev, and C. Smyth. The hardness of 3-uniform hypergraph coloring. In Proceedings of FOCS, pages 33­42, 2002.

[EFF85]

P. Erd¨os, P. Frankl, and Z. Furedi. Families of finite sets in which no set is covered by the union of r others. Israel Journal of Mathematics, 51:79­89, 1985.

[Fei95]

U. Feige. Randomized graph products, chromatic numbers, and the Lov´asz -function. In STOC, pages 635­640, 1995.

[Fei98]

U. Feige. A threshold of ln n for approximating set cover. Journal of the ACM, 45(4):634­652, 1998.

[Fel05]

V. Feldman. On attribute efficient and non-adaptive learning of parities and DNF expressions. In Proceedings of COLT, pages 576­590, 2005.

[Fel06a]

V. Feldman. Hardness of approximate two-level logic minimization and PAC learning with membership queries. In Proceedings of STOC, pages 363­372, 2006.

[Fel06b]

V. Feldman. Optimal hardness results for maximizing agreements with monomials. In Proceedings of Conference on Computational Complexity (CCC), pages 226­236, 2006.

[FGKP06] V. Feldman, P. Gopalan, S. Khot, and A. Ponuswami. New Results for Learning Noisy Parities and Halfspaces. In Proceedings of FOCS, pages 563­574, 2006.

[FK96]

U. Feige and J. Kilian. Zero knowledge and the chromatic number. In Proceedings of Conference on Computational Complexity (CCC-96), pages 278­289, May 24­27 1996.

128

BIBLIOGRAPHY

[FKKM97] M. Farach, S. Kannan, E. Knill, and S. Muthukrishnan. Group testing problems in experimental molecular biology. In Proceedings of Sequences '97, 1997.

[Fre92]

Y. Freund. An improved boosting algorithm and its implications on learning complexity. In Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pages 391­398, 1992.

[Fre95]

Y. Freund. Boosting a weak learning algorithm by majority. Information and Computation, 121(2):256­285, 1995.

[Gav03]

D. Gavinsky. Optimally-smooth adaptive boosting and application to agnostic learning. Journal of Machine Learning Research, 4:101­117, 2003.

[GGM86] O. Goldreich, S. Goldwasser, and S. Micali. How to construct random functions. Journal of the ACM, 33(4):792­807, 1986.

[GHS00] V. Guruswami, J. Hastad, and M. Sudan. Hardness of approximate hypergraph coloring. In Proceedings of FOCS, pages 149­158, 2000.

[Gim65]

J.F. Gimpel. A method for producing a boolean function having an arbitrary prescribed prime implicant table. IEEE Transactions on Computers, 14:485­ 488, 1965.

[GJ79]

M. Garey and D. S. Johnson. Computers and Intractability. W. H. Freeman, San Francisco, 1979.

[GKS93]

S. Goldman, M. Kearns, and R. Schapire. Exact identification of read-once formulas using fixed points of amplification functions. SIAM Journal on Computing, 22(4):705­726, 1993.

[GKS01] S. A. Goldman, S. Kwek, and S. D. Scott. Agnostic learning of geometric patterns. Journal of Computer and System Sciences, 62(1):123­151, 2001.

[GL89]

O. Goldreich and L. Levin. A hard-core predicate for all one-way functions. In Proceedings of STOC, pages 25­32, 1989.

[GLR99] D. Guijarro, V. Lavin, and V. Raghavan. Exact learning when irrelevant variables abound. In Proceedings of EuroCOLT '99, pages 91­100, 1999.

[Gol78]

E. A. Gold. Complexity of automaton identification from given data. Information and Control, 37:302­320, 1978.

[GR06]

V. Guruswami and P. Raghavendra. Hardness of Learning Halfspaces with Noise. In Proceedings of FOCS, pages 543­552, 2006.

[GTT99]

D. Guijarro, J. Tarui, and T. Tsukiji. Finding relevant variables in PAC model with membership queries. Lecture Notes in Artificial Intelligence, 1720:313 ­ 322, 1999.

[Han92]

T. Hancock. The complexity of learning formulas and decision trees that have restricted reads. PhD thesis, Harvard University, 1992.

129

BIBLIOGRAPHY

[Has01]

J. Hastad. Some optimal inapproximability results. Journal of the ACM, 48(4):798­859, 2001.

[Hau90]

D. Haussler. Probably approximately correct learning. In Proceedings of the National Conference on Artificial Intelligence, pages 1101­1108, 1990.

[Hau92]

D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning applications. Information and Computation, 100(1):78­ 150, 1992.

[Hel01]

L. Hellerstein. Learning DNF formulas: a selected survey, 2001. Avalilable at http://cis.poly.edu/~hstein/lics.ps.

[HMP+93] A. Hajnal, W. Maass, P. Pudlak, M. Szegedy, and G. Turan. Threshold circuits of bounded depth. Journal of Computer and System Sciences, 46:129­ 154, 1993.

[Hof99]

T. Hofmeister. An application of codes to attribute-efficient learning. In Proceedings of EuroCOLT, pages 101­110, 1999.

[HR02]

L. Hellerstein and V. Raghavan. Exact learning of DNF formulas using DNF hypotheses. In Proceedings of STOC, pages 465­473, 2002.

[HvHS95] K. Hoffgen, K. van Horn, and H. U. Simon. Robust trainability of single neurons. Journal of Computer and System Sciences, 50(1):114­125, 1995.

[Jac95]

J. Jackson. The Harmonic sieve: a novel application of Fourier analysis to machine learning theory and practice. PhD thesis, Carnegie Mellon University, August 1995.

[Jac97]

J. Jackson. An efficient membership-query algorithm for learning DNF with respect to the uniform distribution. Journal of Computer and System Sciences, 55:414­440, 1997.

[Jac04] J. Jackson. Personal communication, 2004.

[JKS02]

J. Jackson, A. Klivans, and R. Servedio. Learnability beyond AC0. In Proceedings of STOC, pages 776­784, 2002.

[JSS97]

J. Jackson, E. Shamir, and C. Shwartzman. Learning with queries corrupted by classification noise. In Proceedings of the Fifth Israel Symposium on the Theory of Computing Systems, pages 45­53, 1997.

[Kea98]

M. Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 45(6):983­1006, 1998.

[Kha93]

M. Kharitonov. Cryptographic hardness of distribution-specific learning. In Proceedings of STOC, pages 372­381, 1993.

[Kho02]

S. Khot. Hardness results for coloring 3-Colorable 3-Uniform hypergraphs. In Proceedings of FOCS, pages 23­32, 2002.

130

BIBLIOGRAPHY

[KKMS05] A. Tauman Kalai, A. Klivans, Y. Mansour, and R. Servedio. Agnostically learning halfspaces. In Proceedings of FOCS, pages 11­20, 2005.

[KL93]

M. Kearns and M. Li. Learning in the presence of malicious errors. SIAM Journal on Computing, 22(4):807­837, 1993.

[KLPV87a] M. Kearns, M. Li, L. Pitt, and L. Valiant. On the learnability of Boolean formulae. In Proceedings of STOC, pages 285­295, 1987.

[KLPV87b] M. Kearns, M. Li, L. Pitt, and L. Valiant. Recent results on boolean concept learning. In Proceedings of the Fourth International Workshop on Machine Learning, pages 337­352, 1987.

[KM93]

E. Kushilevitz and Y. Mansour. Learning decision trees using the Fourier spectrum. SIAM Journal on Computing, 22(6):1331­1348, 1993.

[KS64]

W. Kautz and R. Singleton. Nonrandom binary superimposed codes. IEEE Trans. Inform. Theory, 10:363­377, 1964.

[KS03]

A. Klivans and R. Servedio. Boosting and hard-core set construction. Machine Learning, 51(3):217­238, 2003.

[KS04a]

A. Klivans and R. Servedio. Learning DNF in time 2O~ (n1/3). Journal of Computer and System Sciences, 68(2):303­318, 2004.

[KS04b]

A. Klivans and R. Servedio. Toward attribute efficient learning of decision lists and parities. In Proceedings of COLT, pages 234­248, 2004.

[KSS94]

M. Kearns, R. Schapire, and L. Sellie. Toward efficient agnostic learning. Machine Learning, 17(2-3):115­141, 1994.

[KV94a] M. Kearns and L. Valiant. Cryptographic limitations on learning boolean formulae and finite automata. Journal of the ACM, 41(1):67­95, 1994.

[KV94b] M. Kearns and U. Vazirani. An introduction to computational learning theory. MIT Press, Cambridge, MA, 1994.

[LBW95]

W. S. Lee, P. L. Bartlett, and R. C. Williamson. On efficient agnostic learning of linear combinations of basis functions. In Proceedings of COLT, pages 369­ 376, 1995.

[Lev93]

L. Levin. Randomness and non-determinism. Journal of Symbolic Logic, 58(3):1102­1103, 1993.

[Lit88]

N. Littlestone. Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm. Machine Learning, 2:285­318, 1988.

[Liu02]

H. Liu. Routing table compaction in ternary cam. IEEE Micro, 22(1):58­64, 2002.

131

BIBLIOGRAPHY

[LMN93] [LV89] [LY94] [Man94]
[Mas69] [Mas79] [McC56] [McE78] [MOS04] [MR95] [NJS98]
[NR97] [NW94] [Pap94] [Pau74] [PB90] [PV88]

N. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform and learnability. Journal of the ACM, 40(3):607­620, 1993.
N. Linial and U. Vazirani. Graph products and chromatic numbers. In Proceeding of FOCS, pages 124­128, 1989.
C. Lund and M. Yannakakis. On the hardness of approximating minimization problems. Journal of the ACM, 41(5):960­981, 1994.
Y. Mansour. Learning boolean functions via the fourier transform. In V. P. Roychodhury, K. Y. Siu, and A. Orlitsky, editors, Theoretical Advances in Neural Computation and Learning, pages 391­424. Kluwer, 1994.
J. Massey. Shift-register synthesis and BCH decoding. IEEE Trans. Inform. Theory, 15:122­127, 1969.
W. Masek. Some NP-complete set covering problems. unpublished, 1979.
E. L. Jr. McCluskey. Minimization of Boolean Functions. Bell Sys. Tech. Jour., 35:1417­1444, 1956.
R. J. McEliece. A public-key cryptosystem based on algebraic coding theory. DSN progress report, 42-44, 1978.
E. Mossel, R. O'Donnell, and R. Servedio. Learning functions of k relevant variables. Journal of Computer and System Sciences, 69(3):421­434, 2004.
R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge University Press, 1995.
R. Nock, P. Jappy, and J. Sallantin. Generalized graph colorability and compressibility of boolean formulae. In Proceedings of the 9th International Symposium on Algorithms and Computation (ISAAC), 1998.
M. Naor and O. Reingold. Number-theoretic constructions of efficient pseudorandom functions. In Proceedings of FOCS, pages 458­467, 1997.
N. Nisan and A. Wigderson. Hardness versus randomness. Journal of Computer and System Sciences, 49:149­167, 1994.
C. H. Papadimitriou. Computational Complexity. Addison Wesley Pub. Co., 1994.
W. J. Paul. Boolesche minimalpolynome und u¨berdeckungsprobleme. Acta Informatica, 4:321­336, 1974.
L. Pitt and R. Board. On the necessity of Occam algorithms. In Proceddings of STOC, pages 54­63, 1990.
L. Pitt and L. Valiant. Computational limitations on learning from examples. Journal of the ACM, 35(4):965­984, 1988.

132

BIBLIOGRAPHY

[Qui52]

W.V. Quine. The problem of simplifying truth functions. Americal Mathematical Monthly, 59:521­531, 1952.

[Qui56]

W.V. Quine. A way to simplify truth functions. Americal Mathematical Monthly, 62:627­631, 1956.

[Raz98]

Ran Raz. A parallel repetition theorem. SIAM Journal on Computing, 27(3):763­803, 1998.

[RS97]

R. Raz and S. Safra. A sub-constant error-probability low-degree test, and a sub-constant error-probability PCP characterization of NP. In Proceedings of STOC, pages 475­484, 1997.

[Sch90]

R. Schapire. The strength of weak learnability. Machine Learning, 5(2):197­ 227, 1990.

[Ser00]

R. Servedio. Computational sample complexity and attribute-efficient learning. Journal of Computer and System Sciences, 60(1):161­178, 2000.

[Ser01]

R. Servedio. On learning monotone DNF under product distributions. In Proceedings of COLT, pages 473­489, 2001.

[Ser03]

R. Servedio. Smooth boosting and learning with malicious noise. Journal of Machine Learning Research, 4:633­648, 2003.

[SM00]

Y. Sakai and A. Maruoka. Learning monotone log-term DNF formulas under the uniform distribution. Theory of Computing Systems, 33:17­33, 2000.

[Sud02]

M. Sudan. Essential coding theory (lecture notes). Available at http://theory.lcs.mit.edu/~madhu/FT02/, 2002.

[Tre01]

L. Trevisan. Non-approximability results for optimization problems on bounded degree instances. In Proceedings of STOC, pages 453­461, 2001.

[TS96] [Uma99]

A. Ta-Shma. A Note on PCP vs. MIP. Information Processing Letters, 58(3):135­140, 1996.
C. Umans. Hardness of approximating 2p minimization problems. In Proceedings of FOCS, pages 465­474, 1999.

[UTW97]

R. Uehara, K. Tsuchida, and I. Wegener. Optimal attribute-efficient learning of disjunction, parity, and threshold functions. In Proceedings of EuroCOLT '97, pages 171­184, 1997.

[UVSV06] C. Umans, T. Villa, and A. L. Sangiovanni-Vincentelli. Complexity of twolevel logic minimization. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 25(7):1230­1246, 2006.

[Vad04]

S. Vadhan. Lecture notes on pseudorandomness. http://www.courses.fas.harvard.edu/~cs225/, 2004.

Available at

133

BIBLIOGRAPHY

[Val84] [Val85]
[Val94] [Val00] [Val06] [Var97] [Ver90]
[vL98]

L. G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134­1142, 1984.
L. G. Valiant. Learning disjunctions of conjunctions. In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, pages 560­ 566, 1985.
L. G. Valiant. Circuits of the Mind. Oxford University Press, 1994.
L. G. Valiant. A neuroidal architecture for cognitive computation. Journal of the ACM, 47(5):854­882, 2000.
L. G. Valiant. Knowledge infusion. In Proceedings of AAAI, 2006.
A. Vardy. Algorithmic complexity in coding theory and the minimum distance problem. In Proceedings of STOC, pages 92­109, 1997.
K. Verbeurgt. Learning DNF under the uniform distribution in quasipolynomial time. In Proceedings of the Third Annual Workshop on Computational Learning Theory, pages 314­326, 1990.
J.H. van Lint. Introduction to Coding Theory. Springer, Berlin, 1998.

134

