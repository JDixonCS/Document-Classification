1
Deep Learning in Industrial Internet of Things: Potentials, Challenges, and Emerging Applications
Ruhul Amin Khalil Student Member, IEEE, Nasir Saeed Senior Member, IEEE, Yasaman Moradi Fard, Tareq Y. Al-Naffouri, Senior Member, IEEE, Mohamed-Slim Alouini, Fellow, IEEE

arXiv:2008.06701v1 [eess.SP] 15 Aug 2020

Abstract--The recent advancements in the Internet of Things (IoT) are giving rise to the proliferation of interconnected devices, enabling various smart applications. These enormous number of IoT devices generates a large capacity of data that further require intelligent data analysis and processing methods, such as Deep Learning (DL). Notably, the DL algorithms, when applied in the Industrial Internet of Things (IIoT), can enable various applications such as smart assembling, smart manufacturing, efficient networking, and accident detection-andprevention. Therefore, motivated by these numerous applications; in this paper, we present the key potentials of DL in IIoT. First, we review various DL techniques, including convolutional neural networks, auto-encoders, and recurrent neural networks and there use in different industries. Then, we outline numerous use cases of DL for IIoT systems, including smart manufacturing, smart metering, smart agriculture, etc. Moreover, we categorize several research challenges regarding the effective design and appropriate implementation of DL-IIoT. Finally, we present several future research directions to inspire and motivate further research in this area.
Index Terms--Industrial Internet of Things, deep Learning, smart industries, optimization, convolutional neural networks, auto-encoders, recurrent neural networks

digital transformation in many industries is accelerating [12]­ [18]. With strong alliances between leading IIoT stakeholders and proven IIoT applications, inspire companies worldwide to invest in the IIoT market, which is expected to grow up to $123.89 billion by 2021 (see Fig. 1). Throughout the literature, various terms are used to describe IoT for the industry, such IIoT, smart manufacturing, and Industry 4.0 [19]­[22]. The step towards this smart production technology or IIoT is way different from past technologies; therefore, it is also called the Industrial Revolution. The newly IIoT technology will explicitly change the overall working conditions and day to day lifestyles of people [23]­[25]. The revolution in smart industry from Industry 1.0 to 4.0 is illustrated in Fig. 2. Generally, IIoT networks consist of interconnected intelligent industrial components to accomplish high production with low cost. This is possible by real-time monitoring, precise execution of tasks, and efficient controlling of the overall industrial procedures [26]­[29].

I. INTRODUCTION

The recent technological advancements in hardware, software, and wireless communication have facilitated the emergence of a new concept termed as the Internet of Things (IoT), simplifying the human lifestyle by saving time, energy, and money [1]­[6]. In IoT, the term "Things" represents smart devices, such as sensors, machines, and vehicles, with intelligent processing capabilities. Many interesting IoT applications include smart cities, smart homes, healthcare monitoring, intelligent transportation, smart power generation, and agriculture [7]­[11]. Nevertheless, the IoT technology also plays a vital role in modern industries by introducing automation and reducing expenses. Adding IoT sensors to the industrial systems helps operators to monitor equipment in near real-time with high reliability. The Industrial IoT (IIoT) market (without the consumer IoT) is growing fast as
Ruhul Amin Khalil is with the Department of Electrical Engineering, University of Engineering and Technology, Peshawar 25120, Pakistan. email:ruhulamin@uetpeshawar.edu.pk
Nasir Saeed, Tareq Y. Al-Naffouri, and Mohamed-Slim Alouini are with Computer, Electrical, and Mathematical Sciences & Engineering (CEMSE) Division, King Abdullah University of Science and Technology, Thuwal 23955, Makkah, Kingdom of Saudi Arabia. email: mr.nasir.saeed@ieee.org,
Yasaman Moradi Fard is with the Department of Biomedical Engineering, Faculty of Engineering, University of Isfahan, Isfahan, Iran. email: yasman.moradifard@gmail.com

Fig. 1. Size and market impact of IIoT .
As the number of internet-connected devices grows exponentially, a significant amount of data is generated. In the case of IIoT, both volume of the data and its characteristics needs proper consideration because the performance of IIoT applications is strictly related to the intelligent processing of the big data, which comes from different real-time resources [30]­ [37]. Therefore, big data analysis in IIoT networks requires intelligent modeling that can be achieved using deep learning techniques.

2

Fig. 2. Revolution of smart industries.
As we discussed above, the most critical factor in automation and intelligence for IIoT is data modeling, analyzing, and support real-time processing. Among data analysis schemes, Deep Learning (DL) used in regression, classification, and forecasting has shown the most potential for IIoT systems [37]­[39]. DL approaches have benefits to learn from the given data automatically, identify the patterns, and make some precise decisions. With the advancements provided by DL methods, IIoT will transform into highly optimized facilities [40]. The advantages of using DL include lower operation costs, no change with variations in consumer demands, enhancing productivity, downtime reduction, obtaining a better perspective of the market, and extracting valuables from the operations [41], [42].
With all these advantages of DL in IIoT, this paper aims to present a state-of-the-art review for DL techniques, such as Convolutional Neural Networks (CNNs), Auto Encoder (AE), Recurrent Neural Network (RNN), Restricted Boltzmann Machine (RBM) and its variants, and their usage in IIoT. Notably, the DL-enabled advanced analytics framework can realize the opportunistic need for smart manufacturing. First, we review the basic DL techniques and their applications in IIoT. Then, we introduce various use cases of IIoT, where DL can significantly improve the performance of predictive maintenance, assets tracking, smart metering, remote healthcare, power-andsmart grid industry, telecommunications, and human resource management. Finally, we provide different research challenges and future trends for DL-based IIoT.
The rest of the paper is organized as follows. Key DL concepts in the context of smart industries are illustrated in Section II. In Section III, we present numerous use cases of DL in different smart industries. Section IV provides various challenges faced by DL-based IIoT, followed by future research directions in Section V. Finally, conclusions are drawn in Section VI.
II. DEEP LEARNING FOR IIOT
It is crucial to use smart manufacturing, making both manufacturing and production intelligent, which can have

several advantages in IIoT [43], [44]. Recently, IIoT solutions are growing significantly, especially for sensor-based data consisting of various structures, formats, and semantics [45], [46]. Data released from IIoT technologies is derivative from various resources across manufacturing that includes product line, equipment-and-processes, labor operation, and environmental conditions. Therefore, data modeling, labeling, and analysis play an important role in making manufacturing much smarter [47], [48]. They are essential parts of handling high-volume data and supporting real-time data processing.
Deep Learning (DL) is one of the powerful methods of machine learning (ML) which can upgrade manufacturing into highly optimized smart facilities by processing a bunch of data with its multi-layered structure. The DL approaches can provide computing intelligence from unclear sensory data, resulting in smart manufacturing [49]. DL techniques are useful due to their automatic data learning behavior, identifying the underlying patterns, and making smart decisions. One of the advantages of DL over traditional machine learning methods is that feature learning is done automatically, and there is no need to design a separate algorithm to do this part [50], [51]. The comparison of DL with traditional techniques in IIoT can be analyzed in Fig. 3.
Fig. 3. Comparison of DL with traditional algorithms for IIoT .
Different data analysis methods can be utilized to interpret the IIoT data, such as predictive analytics, descriptive analytics, diagnostic analytics, and prescriptive analytics [52]­ [56]. After capturing and analyzing the product's condition, environment, and operational parameters, we can arrive at a summary of what happens; this is called descriptive analytics. Predictive analytics utilizes statistical models and provides the prospect of making future equipment fabrication or degradation based on the provided historical data. We use diagnostic analytics to figure out the foundation cause and report the reason for failure or reducing product performance. In contrast, prescriptive analytics recommends one or more courses of action and whatever lies beyond it. Measures out of data analysis techniques are classified for developing the production outcomes or improve the problems, depicting probable result of each assessment. Fig.4 shows the DL-based architecture and its impact on IIoT. In the following, we discuss various DL techniques for IIoT networks.

3

Fig. 4. Deep learning in future Industrial Internet of Things.

A. Convolutional Neural Network
Convolutional neural network (CNN) consists of artificial neural network layers that was first introduced for twodimensional natural language processing (NLP), image/signal processing and speech processing [57], [58]. CNNs are a type of DL method that convolve different neural layer for a high dimensional input data, arriving at a particular lower dimensional output. The CNNs follows a multi-layer feed-forward architecture where the whole procedure of data analysis-andmanaging includes filtering and dimension reduction by using convolutional and pooling layers. Considering the generic layer-wise architecture of CNN with its convolutional, pooling and fully-connected layers are depicted in Fig.5.

layers and pooling processes. These layers (convolutional layers) convolve with the given input data in raw form utilizing local procreative invariant features and multiple local kernel filters. On the other hand, the pooling layers extricate the signified features with fixed-length sliding windows of the raw form input data. This is carried out using various pooling techniques such as average-pooling and max-pooling [61]­ [63]. The average-pooling basically measures the mean value of the specified section and considered it as the pooling value of that section. In contrast, the max-pooling chooses the maximum value for a stipulated section of the featured map being the utmost substantial feature. It should be noted that average-pooling is not optimal in all feature extraction scenarios, however, the max-pooling is reasonably well-matched for sparse feature extraction.

Fig. 5. Generic layer-wise architecture of CNN.
Moreover, recently, CNN is explored and utilized for 1D consequent data analysis, incorporating various IIoT applications [59], [60]. The feature learning in CNN is usually obtained by interchanging and assembling the convolutional

After successful multi feature-learning, the fully connected layers transform the 2D feature mapping into a 1D vector and feed it into activation functional layer for better model representation. In CNN, the most commonly used activation functional layer is softmax, which usually transforms the output of the previous layer into the most suitable and essential output probabilistic distribution. This layer-wise architecture is quite helpful in IIoT applications such as the detection of surface defects that occurs in the manufacturing process [64]­[66]. The CNN is mainly trained by using Gradientbased backpropagation that minimizes the overall minimummean-squared-error (MMSE) and cross-entropy (CE) function for loss occurrence. The CNN has numerous advantages as compared to its counter parts' neural networks, including parameter distribution with fewer numbers, local connectivity

4

with sparse interfaces, and equid-variant illustration, which is mostly invariant to object localities.
The CNN is advantageous in IIoT, as it provides extensive knowledge (in terms of feature extraction) using various datasets with minimal human supervision [37]. This not only enables the industrial process to be precise but can also effectively identify the underlying defects using its visual defect detection capability [67], [68]. Furthermore, the requirement of hand-crafted features, lengthy trials of various procedures, and error occurrence are reduced due to the accurate feature measuring capability of CNNs towards industrial processes.
B. Auto-Encoders
Auto Encoder (AE) is an unsupervised learning neural network which extricates various features from the provided input data without any labeled information requirement [69]. The AE is primarily comprised of an encoder f, a decoder g, and a hidden layer in between, as shown in Fig. 6. The encoder f is capable of performing data compression by mapping the given input to a defined hidden layer in cases where high dimensionality is desired, and the decoder can reconstruct the approximation of the input information [70]. Further, it can effectively reconstruct the approximate relative to the input information. The AE can perform comparably to principal component analysis (PCA) if the activation function is linear with few defined hidden layers. It is observed that if the input data is non-linear, then more hidden layers need to be defined to create a deeper AE [71]. Usually, Stochastic gradient descent (SGD) is utilized to measures various factors and construct an AE with minimal loss in the objective function. This loss is minimized in terms of cross-entropy loss or least square loss [72]. The most important feature that has

C. Recurrent Neural Network
Recurrent Neural Network (RNN) has an exclusive capability of hierarchical links among the neurons for modeling sequential data [77], [78]. Fig. 7 provides the basic architecture of RNN with inputs, outputs, and underlying deep hidden layers. The input variables are expressed as xt-1, xt and xt+1 (depending upon the number of input variables), st provides the information of underlying hidden states, whereas ot-1, ot and ot+1 gives the respective outputs at time instant t. The terms U , V , and W are the respective hidden matrices whose values vary for each timestamp where , the hidden states can be measured as St = f (Ux(t) + W ) S(t-1) [57]. Thus, RNNs are appropriate to acquire precise measurements from the sequential data, allowing it to persist the information in hidden layers and capture the preceding conditions of the data. Nowadays, a reorganized form of RNN is used in a layerwise architecture that can effectively calculate the variance between various time steps [79], [80]. The RNNs take the data as a sequential input in the form of a vector where the existing hidden state is computed by using an activation function, such as tanh or sigmoid. The initial portion of the data is calculated with the provided input; however, the next section is acquired form the underlying hidden state at the earlier step time t [81]. The targeted output ot is then measured with the help of these hidden layer states through softmax or any other available method. Once the whole order of data is processed, the hidden states represent the learning illustration of the whole consecutive input data. Further, a traditional multilayer-perception (MLP) is added on the topmost layer to map the target representations.

Fig. 7. Generic layer-wise architecture of RNN.

Fig. 6. Generic layer-wise architecture of AE.
made the AE useful for the IIoT application is its ability to reduce the input data dimensions and learn the features of non-label data [73]. AE can also help in the security of IIoT networks as it is capable of providing information regarding any intrusion detection in the IIoT environment [74]­[76]. Hence some precautionary measures can be taken to avoid any mishap in the industrial process such as safety, production, and warehousing.

Unlike traditional neural networks, RNNs use backpropagation-through-time (BPTT) for model training. The RNN is usually unrolled in time at the initial stage, and later on, which is then used as an extra layer to the whole architecture. Subsequently, the back-propagation is used to measure the gradients decent [82], [83]; however, the BPTT undergoes the shattering problem when applied during model training. The reason for this is that RNN is not durable enough and has complications to capture the long-term dependencies effectively. In literature, a diverse set of improvements are proposed to tackle these issues, amongst which is the long short-term memory (LSTM) solution [84]. The fundamental knowledge of LSTM is the cell state, which is responsible for allowing the data to be fluttered down with a linear interface. In comparison with single state RNN, in LSTM, different gates

5

such as input, forget, and output gates are utilized to regulate the cell state. This facilitates each recurrent unit to apprehend the long-term dependences for every time scales adaptively.
Initially, RNNs were applied effectively in NLP and textual analytics, using their temporal behavior to rely on time series. However, the same knowledge can be applied to various industrial applications such as optimization of smart manufacturing, where the computational load can be reduced with the help of RNN [85]. This will improve the manufacturing process without any sacrifice of predictive power usage. In comparison to NLP, the RNN can effectively be used in IIoT to predict potential issues that arise with different machine health parameters. It can be helpful in smart factories where future predictions can minimize the overall manufacturing cost and enhance downtime of the product.
D. Restricted Boltzmann Machine
Restricted Boltzmann Machine (RBM) is an artificial neural network mainly with two-layer networking architecture that includes a hidden layer and a visible layer, respectively. In RBM, only the hidden and visible layers are connected; however, there is no correlation between the neurons of the identical layer [86]. It is a kind of energy-based technique, where the visible layer is responsible for input data, while the hidden layer is utilized for different feature extraction. Additionally, it is assumed that all the hidden nodes are conditionally selfdetermining and have no interdependency [87]. The offsets and weights of the visible and hidden layer are revolved throughout iterations to sort the visible layer an estimate to that of input data [88]. Conclusively, the hidden layers deemed as an alternate depiction of the corresponding visible layer. A generalized layer-wise architecture of RBM is given in Fig. 8. The factors

naive Bayes, support vector machine (SVM), linear regression, and belief propagation (BP) can be used for data regression and categorization. RBM usually retrieve the essential features from the training datasets adaptively and take advantage of avoiding the local minima problem. According to [89], RBM is vastly used as a principal learning mechanism on whose basis other variants are modeled.
1) Deep Belief Network: Deep Belief Network (DBN) is a variant of RBM and is fabricated by mounding various RBMs. In DBN, there are input layer units, hidden layer units, and the output layer units. The underlying architecture of DBN is depicted in Fig. 9. A fast-greedy algorithm is used to train the DBN, and a wake-sleep algorithm is utilized to fin-tuned the different parameters in its deep architecture [90], [91]. The area closed to the visible layer is tackled by Bayesian Belief Network (BBN), and far away region is investigated by the RBMs [92]. It can be observed that the lowermost layers in DBN are directed while the uppermost layers are undirected.
According to [93], the DBNs are quite beneficial in pretraining due to their unsupervised nature, especially for unlabeled and massive datasets. Moreover, the DBNs is also advantageous due to their low computational capability. Nevertheless, the DBNs approximation method follows bottom-up fashion, where the greedy layer is responsible for learning only single layer features and is unable to fine-tune with the residual layers [94], [95].

Fig. 9. Generalized layer-wise architecture of DBN.

Fig. 8. Generic layer-wise architecture of RBM.
in hidden layers are utilized to characterize the input data in the realization of dimensionality reduction and various data coding mechanisms. Supervised learning methods comprises

2) Deep Boltzmann Machine: Deep Boltzmann Machine (DBM) is another variant of RBM and is also known as deep-layer structured RBMs. In DBM, the hidden layer units are clustered into a deeper hierarchical layer structure. There is full-fledged connectivity between the adjacent two layers; however, there is no connectivity between the nodes within a specific layer or amongst the neighboring layers, as shown in 10. Due to the assembling of multi RBMs in DBM, it is capable of ascertaining complicated edifices and paradigm high-level illustration of the provided input data [96]. DBM is a complete undirected model as compared to DBN, which is both undirected/directed in nature. Also, the DBM model is typically trained simultaneously and is having a high compu-

6
tation cost. In contrast, the DBN can be adequately trained in a layer-wise manner and is computationally less expensive.

Fig. 11. Layer-wise architecture of RvNN.

Fig. 10. Generalized layer-wise architecture of DBM.

controls [105]­[107]. It can also be used in controlling industrial pollution by providing an earlier forecast with greater precision [108].

The RBM techniques can be quite useful for IIoT by improving their efficiency, accuracy in production, safety in operations, and reliability in the overall system. For instance, recently in [97], a hybrid model on the basis of GaussianBernoulli deep Boltzmann machine (GDBM) was used for optimal detection processes such as manufacturing or production in a smart industrial setup. The RBM and its variants can be utilized in IIoT for other tasks that include material handling, optimized designing, an inspection of the product quality, and forecasting.
E. Recursive Neural Network
Recursive Neural Network (RvNN) is also a well-known DL method that does not require any tree-structure sequence as an input [98]­[100]. It can understand the parse-tree sequences for the given input data and categorize it. RvNN is created with a set of similar weights applied recursively to the input data [101]. The weights are defined almost for each node and are not restricted to a specific node. Furthermore, the RvNN is categorized as a classical architecture used to operate on inputs in a structured form, predominantly, on guided acyclic graphs. A simplified layer-wise architecture of RvNN is illustrated in Fig. 11, where p1,2 = tanh(W [C2 : C2]) is the parent matrix, the terms C1 and C2 are the respective n-dimensional vectors defined for nodes, and W is the weighted matrix of order n × 2n. RvNN determines the overall score for any potential pair that can be fused to design a syntactic tree structure and then merged with compositional vectors [102]. After these possible pairs get merged, the RvNN creates various components that include the bounded territory characterizing vectors and the classification labels.
RvNN-based DL methods can efficiently perform the tasks of natural language processing, image processing, and speech processing [103], [104]. Nevertheless, it can also effectively handle IIoT applications, including smart manufacturing, smart object detection during assembling, packaging, and machine

F. Comparison of DL models
From the above discussions, it is clear that CNN and RNN are complex algorithms for learning representations and modeling. On the other hand, RBM and AE are used in a layer-by-layer fashion for the pre-training of a neural network to illustrate the given input data. The top layer in all of these DL techniques represents the targets. The Softmax layer is used when these targets are discrete; however, linear regression is utilized for continuous targets. Some of these DL techniques are dependent on data labeling that includes RBM, AE, and their variants, which are called unsupervised or semi-supervised learning. In contrast, the other methods, including CNN, RNN, and RvNN, are supervised due to their non-dependency on labeling input data. The advantages and limitations of these DNN techniques, along with their applications, are presented in Table I.
III. KEY USE CASES OF DL-BASED IIOT
In this section, we describe potential opportunities for DL-based IIoT, which can handle the communication and resources of underlying smart nodes. One of the necessary parts of modern smart manufacturing is computational intelligence, which enables accurate insights from data for efficient and better future decision-making. As we have mentioned earlier, DL is one of the top fields in the investigation of different manufacturing lifecycle stages covering concepts, design [109], evaluation, production, operation, and sustainment [110]. These various data mining applications in manufacturing are discussed and reviewed in [111], which covers different production processes like operation, maintenance, fault detection, effective decision making, and quality improvement of the product. Similarly, the authors in [112], [113] review the evolution of future manufacturing, where they emphasize the importance of data modeling and manufacturing intelligence analysis. In the following, we discuss various use cases of DL in IIoT networks.

7

TABLE I COMPARISON OF DEEP LEARNING MODELS IN CONTEXT OF IIOT

DL model Applications

Advantages

Limitations

References

CNN AE RNN RBM RvNN

Feature learning by stacked convolutional and pooling layers Encoding do the unsupervised learning and dimensionality reduction in data
Temporal outline in recurrent links while distributed states are in timeseries data Connectivity between input and output is elaborated by hidden layer variables Able to understand the parse-tree sequences in the provided data

minimizes the shifting, scalability and alteration
preserve only meaningful input data while the irrelevant data is filtered
temporal correlation is apprehended in progressive data with short-term info retention robust to input ambiguity, and pre-training stage do not require label training
Has the capability to capture long-distance dependencies

higher

hierarchical

models requires complex

computations

Sparse illustration and

layer-by-layer

error

procreation are not

assured

Model training is difficult

to keep long-term depen-

dencies

take much time to execute optimization of parameters

The parsing is slower and usually have domain dependency

[37], [57]­[68] [69]­[76] [57], [77]­[85] [86]­[97] [98]­[108]

A. DL for Predictive Maintenance
Maintenance problems can be quite challenging and diverse in nature. Therefore, the predictive data fed to the Predictive Maintenance (PdM) unit has to be tailored for a particular problem [114], [115]. Hence, the literature on various approaches to input information for the PdM is quite rich [116], where DL techniques seem to be among the most popular [117]. Fig. 12 provides the effectiveness of DL-based industrial infrastructure for PdM.
DL-based PdM solutions can be categorized as follows:
(a) Supervised, where the modeling dataset has the information of failures occurrence.
(b) Unsupervised, where the modeling dataset has only logistics and processes information without having any maintenance data.
The accessibility to maintenance data depends mostly on maintenance management policies. For example, in case of Run-to-Failure(R2F) policies [118], the interventions of maintenance are only performed when a failure occurs. The information for a maintenance cycle, i.e., the activity between two successive failures, exists, and therefore supervised learning methods can be used. On the contrary, in the presence of PvM policies, the maintenance is performed before any potential failure, and therefore full maintenance cycle may not exist [119]­[121]. In such a case, only unsupervised learning methods are reasonable. In general, supervised learning methods are preferable in industries because of the extensive use of R2F policies.
Additionally, in PdM, regression techniques are utilized when predicting the lifetime of an industrial process or equipment either directly [122] or indirectly [123]. In contrast, classification-based techniques are used for PdM when discriminating between the health conditions of industrial

equipment [124]. Moreover, classification techniques can also distinguish defective and flawless processes on the basis of observed data.
B. DL for Assets Tracking
The data analysis feature and deciding on historical data of AI are being in the exploration phase by assets and wealth management firms [125]­[127]. According to the AI Opportunity Landscape, approximately 13.5% of AI vendors in banking offer assets and wealth management solutions. Digital asset management (investment portfolio, etc.) or distributed industrial assets (like transportation machinery, i.e., truck, factory machinery) are the applications DL in assets management. It takes the data to DL-techniques and makes automatic decision-making, whether what to be best for the future.
Most of the time, the data related to financial, news, and industrial sensors are unlabeled, and unsupervised learning works best in making investment decisions on exciting new ways. The report published in the Financial Stability Board in 2017 states that AI and ML firms were able to increase their assets over $10 billion till 2017, and this number is expected to grow rapidly in the next five years [128]­[130]. The main applications of asset management through DL are digital assets management like investment portfolio and advisory consumers and investment management like physical asset management, including industrial predictive asset management.
C. DL for Smart Metering
Smart meters are essentially called smart because they are intelligent and enable two-way communication with the distribution service operator (DSO) and smart appliances [131]­ [133]. Smart meters can measure both consumed energy the

8

Fig. 12. DL-based industrial infrastructure for predictive maintenance.

amount of energy that is injected into the network. The data is sent at regular intervals to distribution network operators who, among others, use it to map consumption peaks and gain insights, while passing it on to the energy supplier for invoicing purposes [134]. One of the smart meters' promises is a more precise measurement and invoicing method in combination with dynamic pricing. With ongoing electrification, digitalization, decentralization, and rising demand for power, along with the addition of new energy sources, smart meters are deemed critical for the electricity sector [135], [136].
Smart meters dispose of embedded communication possibilities where several solutions are used, including power line communications (PLC), wireless low-power wide-area network (LPWAN) standards, and other wireless options, including RF Mesh (Radio Frequency mesh-based systems [137]­[140]. According to recent research, smart meters will be the second most significant vertical IoT application in 2023 as deployed by energy and water utilities and have the potential to contribute over one-third of the global LPWA device connections (see Fig. 13).
Mainly LoRa, Sigfox, and NB-IoT seem to be promising wireless technologies to enable smart metering. Following are some of the common examples of smart metering:
· In Sweden, Telia was able to show that the TCO of NBIoT was less than that of PLC and RF Mesh for last-mile connectivity. Along with its system integration partners, Telia is converting and managing more than 2 million of the 5.4 million electric meters across the country with cellular IoT.
· In France, LoRa is being used by Nova Veolia and its subsidiary Birdz, in collaboration with Orange Business Services, to connect over 3 million water meters to the

LoRa network of Orange. Their goal is also to read more than 70% of their meters remotely by 2027. · In Japan, 850,000 NICIGAS (Nippon Gas) gas meters across the country will get a smart makeover by the end of 2020, thanks to a retrofitted gas meter reader developed by UnaBiz and SORACOM. The gas consumption data are transmitted to NICIGAS' IoT data platform, via Sigfox's Japan-wide 0G wireless network.
The rapid development of new wireless technologies for IIoT is impacting the Europe's smart metering market [141]­ [144]. For instance, Berg Insight states, adding that DSOs are looking for new projects on smart grid and roll-outs in 2020 with a wide range of various wireless technologies with many advantages compared to PLC technologies [145], [146].
In the future smart cities, the smart grid will be the primary energy provider that involves energy-efficient resources (like renewable energy), smart meters, and other intelligent applications [147]­[149]. One of the differences between smart energy grids and traditional grids is that in the traditional electric grid system, consumers are billed once a month on provided electrical resources [150]­[152]. However, due to the dynamic requirements of energy resources, we need a smart device that uses both way communication of customers and suppliers, which is the basic concept of the smart grid.
In smart grids, the electricity is provided from the microgrid (a distributed energy provider company located at the local level) to the users [153]­[155]. The telecom companies are making contracts with local authorities to provide an advanced metering infrastructure (AMI) between the smart meters and service providers, as we know that the concept of the smart grid is not only restricted to electric suppliers [156], [157]. In AMI, the service provider tracks electricity consumption in

9

Fig. 13. Smart Meter Market 2019: Global penetration.

real-time and provides suggestions and feedback to the users on electricity consumption and requirement.
Due to the massive amount of data generated by smart grids and smart meters, data management, and processing for controlling smart pricing is an issue [158], [159]. Hence, it is critical to have well-defined communication infrastructures and requirements for service providers with the customers through which power outage will be predictable and minimized (see Fig. 14). This will help industries in a way that they

change their operation timing to avoid unscheduled power outage.
The data and communication will differ in frequency and type based on the users. For instance, a smart home will be less communicative as compared to a smart factory (which will be high communicative due to shifting in there power requirements between day and night and seasons [160], [161].) Therefore, the smart grid team needs sophisticated data communication and flow management technologies. In the case

Fig. 14. DL-based power transmission from Smart grid towards customers.

10

of an industrial environment, different topological configurations and settings would be required for different flows, also illustrated in Fig. 14. For example, one flow will be from the service provider to smart meters, and the other will be inside the factory from the smart meter to the different types of machinery and utilities. In such dynamic scenarios, a smart datacenter (having DL) with SDN and NFV functionalities would be needed for data management [162].
D. DL in Remote Healthcare Monitoring
Healthcare is one of the most important and necessary industries, which offers millions of people value-based healthcare services around the world [163], [164]. Therefore, it is the world's top revenue generated business with a revenue of almost $1.668 trillion in the United States alone. The value proposition of this industry is quality, value, and outcome. Therefore, it requires innovation in this industry, in which even stakeholders and specialists are investing highly in delivering the value prepositions of healthcare [165], [166]. Smart healthcare by technology is no longer a flight of fancy but is a requirement of health care due to the increasing global population.
The digital technologies are playing a critical role in various aspects of smart healthcare systems, such as patient care, billing, and handling medical records, and developing alternate staffing models. The research on DL in healthcare is seeking a gradual acceptance [167]­[169]. For example, Google recently introduced a DL technique that can detect cancerous tumors. Moreover, researchers at Stanford University are investigation DL for the detection of skin cancer. In this context, DL is lending a hand in diverse healthcare situations, analyzing massive data, suggesting outcomes, and providing timely risk scores (see Fig. 15). In the following, we provide some of the top utilization of DL in the healthcare industry:

· Diagnosis: One of the most significant uses in healthcare for DL is the diagnosis of a certain disease, including genetic disease and cancers at initial stages (which is hard to identify) [168], [170]. The most common approach would be using DL models of identifying disease using classification or detection models trained on using supervisor learning.
· Drug discovery and manufacturing: AI and DL based algorithms help in the early-stage drug discovery process as a primary clinical application [171]­[173]. Drug discovery also lies in the R&D section working nextgeneration precision and sequencing of medicines. And this is useful in finding the new and alternate ways of therapy for the multifactorial disease. The DL technique currently uses unsupervised learning for prediction; it only identifies patterns. For example, many researchers are using GAN network for finding vaccines or drugs for Corona disease by using GNOME [174]­[176].
· Medical Imaging Diagnosis: The recent breakthroughs in DL algorithms lead to the advancement of computer vision tools in the medical sector [177]­[179]. One such example is the diagnosis using medical imagery. For instance, the project by Microsoft named InnerEye, that utilizes image analysis as a diagnostic tool. Medical imagery analysis has may variables that arise at any moment and are discrete in nature [180], [181]. Therefore, the modeling of such variables using a complex mathematical analysis is quite difficult. With the use of DL algorithms, a ceratin model is easy to learn using data samples. Accordingly, the diagnosis approach based on DL will result in the classification of images into different categories like normal, abnormal, etc. [182]­[184].
· Smart Health Records: DL and data analytic can also be useful in facilitating smart health care records [185],

Fig. 15. DL-based remote healthcare monitoring.

11

[186] as the maintaining of health care records is exhausting process. Even by using technology like data entry, it takes a lot of time to do so [187], [188]. · Clinical Trial and Research: Generally, clinical trials and research takes quite long time and sometimes can even take years to complete. DL can enable prospective applications in clinical trials by reducing both cost and time for the Pharma industry [189]­[191]. Applying DLbased data analytics help researchers to find potential clinical trials among wide variety of data points, such as social media use, previous doctor visits, etc. [97], [192], [193]. This way, both time and resources for the clinical trials are minimized. · Outbreak Prediction: Today, the data scientists can predict outbreaks (malaria or severe chronic infection) using a large amount of data fed to Neural Networks. The data is collected from different open data platforms (Kaggle, etc.) or by themselves from real-time social media posts and updates, satellites, and websites information [194]­[198]. Thanks to the breakthrough of AI and DL in predictions and the availability of high amounts of data in today's life, it is easy to predict and monitor epidemics around the globe [199]­[201]. The prediction of these outbreaks helps prepare for the counter activities, especially in low-income countries, where there is a lack of crucial medical infrastructure. ProMED-mail is an example of monitoring evolving diseases and provide information regarding new emerging outbreaks in realtime with an internet-based reporting platform.
E. DL in Enhancing Human Resources
DL can bring loTs of facilities for the human resource (HR) management in any industry [202]­[205]. The managers in any company prefer value beyond the numbers in understanding what is happening, i.e., whether their leaders and executive staff need extra information or help in a particular area to point them in the right direction [206]­[208]. Thanks to the DL based algorithms, which can predict employee attrition and enable DL to work in the HR department.
DL can react faster in finding insights and inferences as in the changing and evolving key performance indicators (KPIs) than people who take time and a ream of the workforce [209], [210]. For instance, in the job application process, most of the companies use application tracking and assessment algorithms and platforms (like LinkedIn), which help in automation and making the process faster when there is a high volume of applicants for a specific role [211]­[214]. There is a dire need of DL based platform which is capable of giving calibrated guidance without humans, help in allowing more people to grow their skills, career, and stay engaged.
On such example of DL in HR is Google's People Analytics, which is a pioneer in building engineers for performancemanagement at the enterprise level. People Analytics helped solve the fundamental problem of employee-related to business, focused on improving the lifestyle of "Googlers", their productivity, and overall wellness. This project posed some interesting questions (like the ideal size for a team or department) but focused on finding new ways of using data to find

answers to such questions. In Short, DL in HR helps pave the new way for more valuable programs in less time by illuminating the development of a more people-centric approach [215], [216]. It also reduces personal biases in programs, and the need for administration, by increasing individual development.
F. DL in Mining Industry
The IBM states that in a lifetime, each person needs around 3.11 million pounds of mineral, fuels, and metal [217]. Therefore data analysis is a critical requirement for efficient use of the minerals [218]­[220]. Nevertheless, mining is a risky and expensive task to perform [221]. Therefore, the use of IIoT will help improve production, avoid unnecessary waste, improve safety, and reduce costs for the mining industry. For example, data collection and analytic before the digging process can help save both time and the corresponding cost.
Similarly, IIoT can improve the mining industry's safety by overcoming the risks of suffocation, rock sliding, and other similar scenarios [222]. On top of IIoT, DL models can enable autonomous drilling and digging systems that can reduce the risks and improve efficiency [223]­[226].
G. DL in Agriculture Industry
DL-based IoT can play a fundamental role in the agriculture industry by making it smart and effective [227]­[232]. Recently, DL with IoT has become an essential technology for smart farming [233]­[236]. For instance, drone technology DL assistance can enable effective ways of seeding, monitoring, and spraying crops. Moreover, DL-based IoT can also offer large scale irrigation systems. For example, a DL-based irrigation system with a single pump can offer an optimal solution, where the pump will operate only when there is a demand for more water. To find the specific area that needs more water, high-speed drones with wireless technology or moisture-based sensors deployed in the soil can provide the sensing information [237]­[240]. Once the area is identified, the pump will start operation, and the system will drive the water only when there is a need for water. Fig. 16 illustrates drone-based imagery to get the moisture-related information of specific agricultural land. Moreover, a trained model on specific datasets can be used to develop a water stress map, which can help find the location where water is needed.
H. DL in Telecom Industry
There is a variety of research studies regarding the use of DL in telecom industry [241]­[243]. DL techniques are used as tools for improving telecom networks' performance and helping in various compelling wireless technologies like massive MIMO, D2D, highly dense small cell networks, etc. [244]­[246]. For example, in [247], a reinforcement learning method is investigated to optimize the scheduling of packet transmission in the cognitive-IoT networks. The main idea was to maximize the throughput's in a multi-channel environment of cognitive nodes in selecting appropriate values of network parameters (transmission power, scheduling, and spectrum action). Furthermore, in [248], the authors proposed a DLbased model for classification and controlling of traffic in

12

Fig. 16. DL-based agriculture monitoring.

IoT networks. This model used a hybrid Recurrent Neural Networks with Convolution Neural Networks in predicting the class of packets by using features classification from packet headers. Another example is given in [249], where the author studied different DL algorithms to analyze the challenges in wireless networks and their design optimization.
I. DL in Transportation Industry
The transportation industry is the backbone of any country where ITS (intelligence transportation services) are becoming popular [250]­[256]. In ITS, the roadside units can be equipped with a DL model to enable the internet of vehicle applications such as vehicle automation, supporting in-car entertainment, and providing location and context-aware services. Other applications pf DL in the transportation industry include smart parking and smart traffic light that control the traffic according to the situation rather than having some fixed rules [257]­[262]. For example, in [263], the author used the D2D features of the LTE-A network for roadside units with a graphical neural network to enable smart transportation.
J. DL in Waste Management Industry
Making the process of waste management smart is one of the goals of the current waste management industry [264]­ [267]. There must be some flaws and inefficiencies in manual management, which is the cause of different diseases. The use of DL in waste management will not only improve the overall process, but it will also help us in speeding up the recycling process and utilizing the wastage effectively by linking the waste-collecting at the disposal to the recycling industry [268]­[271]. The DL will properly allocate different resources following the quantity and type of specific waste like glass, paper, organic, etc. The DL will not only establish the connection between various industries like waste-to-energy

and waste management authorities but will effectively manage the transfer and collection of waste material.
K. DL in Advertisement Industry
The advertisement industry in the world is moving toward smart advertisement by using DL algorithms. For example, YouTube, Facebook and other social media apps uses recommendation algorithms for their advertisements [272]­[275]. In the same way, advertisements can be made smarter on large billboards screens updated by the trends in that location found by using the DL algorithms [276]­[278]. Consequently, at hyper-marts or shopping malls, advertisements on a small screen located on a specific location can be customized and changed from user-to-user by applying DL on the user's previous data [279]­[281].
IV. KEY CHALLENGES IN DL-IIOT
We have discussed the importance of DL in various industries; however, its successful implementation in the industrial environment and obtaining trustful and useful results are not easy. It requires domain understanding with a problem-solving mindset and people with statistical analysis background who are good at finding valuable insights into the data. In the following, we discuss some of the key challenges of DLassisted IIoT.
A. Complexity
Complexity is one of the major issues of DL models, which requires an extra effort to solve [282], [283]. One of the problems regarding DL performance is the time-consumption of the training phase and computation requirement due to the complexity of the model and large industrial dataset. The second issue is the lack of a large number of training samples in industrial scenarios, which reduces the accuracy

13

and efficiency of models by overfitting. The problem of complexity can be tackled by using a tensor-train deep compression (TTDC) model for learning different features efficiently from the industrial data [284]. This technique compresses a large number of factors in the DL model, which further improves the model's speed.
B. Selection of Algorithm
There are several widely available popular DL algorithms to be used in IIoT applications [285]. These algorithms can work in any generic scenario, but selecting an algorithm for specific industrial applications should be based on particular guidelines available. For each algorithm, it is essential to know which DL algorithm will give its best in which scenario [286]. The improper selection of a DL algorithm can cause many issues like the production of garbage outputs, which leads to a waste of time, effort, and money.
C. Selection of Data
A DL algorithm's success is directly correlated with the training data, which is well described by a famous saying, "Garbage in, Garbage out." The correct type and amount of data are very critical for any DL algorithm [287]. It is vital to avoid such data that causes selective bias and make or select the data representative of the case in an industrial process.
D. Data Preprocessing
After selecting the data, the next crucial step would be to convert the messy data containing missing values, outliers, and valueless entries to the form of data that could be understood by statistics and DL algorithms [288]­[290]. This step includes parsing, cleaning, and preprocessing data like converting the other form of data into numbers, scaling of features (for preventing their dominance over others), and removing or replacing missing entries.
E. Data Labelling
As we know, supervised DL algorithms are the easiest and most appropriate algorithm these days in terms of implementation, training, and deployment in various IIoT applications. On the other hand, unsupervised DL algorithms are harder to implement, sometimes requiring several unsuccessful iterations and a very lengthy training process [291]. Nevertheless, data labeling for supervised DL algorithms is challenging and can't be outsourced for advanced and intensive tasks. For example, labeling of medical imaging on which a classification model could be trained for diagnosis process needs domain experts such as doctors. However, the issue is that specialized medical experts view this activity as a time-consuming process [292]. Besides these critical challenges, many other challenges exist in the field of DL in a smart industrial environment, including managing model versions, data version, reproducing the models, etc. DL is continuously evolving, and its feature's learning capabilities are constantly changing [293]. But incorporating the newer versions and features in the DL setup can sometimes be a nightmare if the team finds that the earlier dataset, models, and features are not appropriately documented.

V. FUTURE RESEARCH DIRECTIONS IN DL-IIOT
For better expressing the overall requirements of DL-based IIoT, there are various aspects of DL that shall be rectified in the future to implicate the DL in smart industries conclusively. The different aspects of DL that need enhancement include intelligent algorithms with improved efficiency and supporting better platforms. Therefore, in the following, we provide a few essential research directions for DL-based IIoT.
A. Low-latency and Ultra-Reliability
As discussed earlier, that smart industrial setup requires several synchronized processes that require low latency and improved reliability to achieve the necessary performance [294]­[296]. Moreover, the DL methods applied in IIoT should be able to handle these issues along with other parameters such as network deployment and resource management [297]. Nonetheless, the competency and usefulness of DL-based IIoT scenarios are still in the evolving stage, exclusively demanding the strict low latency and ultra-reliability requirements in IIoT. Hence, research efforts are required in this direction to establish a theoretical and practical background for DL-IIoT to guarantee low-latency and ultra-reliable communication.
B. DL-enabled Cloud/Edge Computing
Fast and efficient computing is another main feature that can affect not only the latency and reliability but many other performance parameters in smart industries [298]. As discussed, the IIoT requires powerful and useful tools to compute the big data obtained from various processes and analyze it at specific platforms, including servers, transmission mediums, and storage devices [299]­[301]. Presently, hybrid cloud-edge computing is used to perform fast and effective computations and offers comprehensible computing infrastructure for IIoT. Nevertheless, to deal with an adequate complex-learning issue, the training-in-device processing is not considered as a feasible option [302]­[304]. The reason behind this is the limited storage and low processing power of the devices, and the overall complexity of the problem. Therefore, it is considered suitable to use the edge-based infrastructure of computing due to its capability to reduce latency and improve the learning process in the network. Nevertheless, the integration of DL and edge-based computing infrastructure for IIoT is still an open research problem [305]. Specifically, the combined realization of distributed and parallel learning for edge-based designs requires additional optimization to achieve higher productivity, self-organization, and lower runtime.
C. Intelligent Sensing and Decision Making
The controlling issues in DL-based IIoT consist of both sensing and evaluation procedures with the massive number of actuators and sensors [306], [307]. This will enable smart sensing capabilities in IIoT, such as prediction, categorization, and decision, directly controlling the overall system. For instance, in a smart manufacturing environment, intelligent sensing and useful decision-making aptitudes are strict enough with no allowed chances of economic loss and safety problems caused

14

by failure [308]. Therefore, the successful implementation of DL-IIoT has strict requirements of effective prediction, categorization, and decision that can only be achieved with intelligent sensing-and-decision.
D. E-Learning and Re-learning
IIoT is capable enough to enable smart and highly scalable connected industrial systems, where the handling of computation and networking are performed in a fully dynamic environment [309]. It is a matter of the fact that DL models necessitate for pre-training to provide precise outputs from the learning processes [310], [311]. Moreover, with the dynamic and evolving nature of the IIoT systems, DL techniques should adapt to the complexities of the industrial environment [312]. One way is to enable adaptive DL techniques is to combine elearning and re-training for updating DL models continuously; however, this requires further investigation.

this paper, we presented the prospects of DL in IIoT. First, we discussed potential DL algorithms for IIoT networks, including Convolutional Neural Networks (CNNs), Auto Encoder (AE), Recurrent Neural Network (RNN), Restricted Boltzmann Machine (RBM) and its variants. We then extend the discussion towards different use cases of DL-based IIoT, including predictive maintenance, asset tracking, smart meter, and smart grid, remote-healthcare monitoring, mining industry, transportation, telecom, and agriculture. We also discussed some of the remarkable challenges faced by the proper implementation of DL-based IIoT that include the complexity and selection of specific DL algorithms, preprocessing, and data labeling. Finally, we listed various future research directions for DLbased IIoT, such as low-latency, ultra-reliability, cloud/edge computing, intelligent sensing-and-decision. We believe that this survey can help both the academics and practitioners in the field of DL and IIoT to get an insight into various DL algorithms and their potentials in a specific smart industry.

E. Distributed Deep Learning
For large-scale DL processes with massive training datasets and long training times, distributed DL is a dedicated technique that allocates various computation resources to work collaboratively on a single task [313]. Distributed DL can perform multiple tasks such as data collection, data mining, and testing phases into the various number of distributed nodes that simultaneously work on it, and hence, solve the problem in a time-efficient manner. Therefore, distributed DL is considered one of the fundamental techniques to be implemented in the IIoT environment [314]. However, the implementation of distributed DL in smart industries is not an easy task. The main challenge is identifying the way to manage the overall distributed computation resources.
F. Light-weight Learning Platform
IIoT consists of various connected, intelligent devices to make a smart industrial setup [315]. These devices include controllers, actuators, sensors that use different DL algorithms for learning and provide future predictions. In general, the computational capacity of such devices is limited, thus requiring light-weight learning platforms [316], [317]. This way, the learning process for various industrial devices will improve, resulting in an intelligent IIoT network with low computational complexity and improved network lifetime. One such example is the use of hardware-in-the-loop (HIL) platform of simulation [318]­[325]. The HIL integrates the computations carried out for various process with the internal hardware of the sensors and actuators. The HIL platform's critical potential is the utilization of real-time data produced by deployed hardware testbeds.
VI. CONCLUSION
Recent advancements in the Industrial Internet of Things (IIoT) and Deep learning (DL) have made the industrial setup smarter for various applications. According to Industry 4.0 standardization, there is a huge potential for DL in IIoT. Nevertheless, smart industries are still facing many challenges. In

REFERENCES
[1] A. Gilchrist, Industry 4.0: The Industrial Internet of Things. Springer, 2016.
[2] E. Sisinni, A. Saifullah, S. Han, U. Jennehag, and M. Gidlund, "Industrial Internet of Things: Challenges, Opportunities, and Directions," IEEE Trans. Ind. Informat., vol. 14, no. 11, pp. 4724­4734, 2018.
[3] S. Greengard, The Internet of Things. MIT press, 2015. [4] N. Saeed, M. Alouini, and T. Y. Al-Naffouri, "Toward the internet of
underground things: A systematic survey," IEEE Commun. Surv. Tuts., vol. 21, no. 4, pp. 3443­3466, 2019. [5] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, "Internet of Things (IoT): A Vision, Architectural Elements, and Future Directions," Future Gen. Comp. Syst., vol. 29, no. 7, pp. 1645­1660, 2013. [6] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari, and M. Ayyash, "Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications," IEEE Commun. Surv. Tuts., vol. 17, no. 4, pp. 2347­2376, 2015. [7] H. Boyes, B. Hallaq, J. Cunningham, and T. Watson, "The Industrial Internet of Things (IIoT): An Analysis framework," Comput. Ind., vol. 101, pp. 1­12, 2018. [8] F. Liang, W. Yu, X. Liu, D. Griffith, and N. Golmie, "Toward EdgeBased Deep Learning in Industrial Internet of Things," IEEE Internet Things J., vol. 7, no. 5, pp. 4329­4341, 2020. [9] M. Zarei, A. Mohammadian, and R. Ghasemi, "Internet of Things in Industries: A Survey for Sustainable Development," Int. J. Innov. Sustain. Dev., vol. 10, no. 4, pp. 419­442, 2016. [10] L. Atzori, A. Iera, and G. Morabito, "The Internet of Things: A Survey," Comp. Netw., vol. 54, no. 15, pp. 2787­2805, 2010. [11] J. Branger and Z. Pang, "From Automated Home to sustainable, Healthy and Manufacturing home: A New story enabled by the Internetof-Things and Industry 4.0," J. Manage. Anal., vol. 2, no. 4, pp. 314­ 332, 2015. [12] A.-R. Sadeghi, C. Wachsmann, and M. Waidner, "Security and Privacy Challenges in Industrial Internet of Things," in 2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC). IEEE, 2015, pp. 1­6. [13] C. Perera, C. H. Liu, and S. Jayawardena, "The Emerging Internet of Things Marketplace from an Industrial Perspective: A Survey," IEEE Trans. Emerg. Topics Comput., vol. 3, no. 4, pp. 585­598, 2015. [14] J. Wan, S. Tang, Z. Shu, D. Li, S. Wang, M. Imran, and A. V. Vasilakos, "Software-Defined Industrial Internet of Things in the Context of Industry 4.0," IEEE Sensors J., vol. 16, no. 20, pp. 7373­7380, 2016. [15] L. Da Xu, W. He, and S. Li, "Internet of Things in Industries: A Survey," IEEE Trans. Ind. Informat., vol. 10, no. 4, pp. 2233­2243, 2014. [16] P. P. Ray, "A Survey on Internet of Things Architectures," J. King Saud Uni.-Comp. Informat. Sci., vol. 30, no. 3, pp. 291­319, 2018. [17] S. Li, L. Da Xu, and S. Zhao, "The Internet of Things: A Survey," Inf Syst Front, vol. 17, no. 2, pp. 243­259, 2015.

15

[18] I. Lee and K. Lee, "The Internet of Things (IoT): Applications, investments, and challenges for enterprises," Business Horizons, vol. 58, no. 4, pp. 431­440, 2015.
[19] P. Zheng, Z. Sang, R. Y. Zhong, Y. Liu, C. Liu, K. Mubarok, S. Yu, X. Xu et al., "Smart Manufacturing Systems for Industry 4.0: Conceptual Framework, Scenarios, and Future Perspectives," Front. Mech. Eng., vol. 13, no. 2, pp. 137­150, 2018.
[20] C. Qiu, F. R. Yu, H. Yao, C. Jiang, F. Xu, and C. Zhao, "Blockchainbased Software-Defined Industrial Internet of Things: A Dueling deep Q-learning approach," IEEE Internet Things J., vol. 6, no. 3, pp. 4627­ 4639, 2018.
[21] M. Liu, F. R. Yu, Y. Teng, V. C. Leung, and M. Song, "Performance Optimization for Blockchain-enabled Industrial Internet of Things (IIoT) systems: A Deep Reinforcement Learning Approach," IEEE Trans. Ind. Informat., vol. 15, no. 6, pp. 3559­3570, 2019.
[22] S. Jeschke, C. Brecher, T. Meisen, D. O¨ zdemir, and T. Eschert, "Industrial Internet of Things and Cyber Manufacturing Systems," in Industrial Internet of Things. Springer, 2017, pp. 3­19.
[23] R. A. Khalil and N. Saeed, "Network Optimization for Industrial Internet of Things (IIoT)," IEEE Sensors Lett., vol. 4, no. 7, pp. 1­4, 2020.
[24] C.-H. Chen, M.-Y. Lin, and C.-C. Liu, "Edge Computing Gateway of the Industrial Internet of Things using Multiple Collaborative Microcontrollers," IEEE Netw., vol. 32, no. 1, pp. 24­32, 2018.
[25] C. Perera, C. H. Liu, S. Jayawardena, and M. Chen, "A Survey on Internet of Things from Industrial market perspective," IEEE Access, vol. 2, pp. 1660­1679, 2014.
[26] W. Khan, M. Rehman, H. Zangoti, M. Afzal, N. Armi, and K. Salah, "Industrial Internet of Things: Recent Advances, Enabling Technologies and Open Challenges," Comp. Elect. Eng, vol. 81, p. 106522, 2020.
[27] A. Karmakar, N. Dey, T. Baral, M. Chowdhury, and M. Rehan, "Industrial Internet of Things: A Review," in Int. Conf. on Opto-Electr. and App. Optics (Optronix), 2019, pp. 1­6.
[28] R. Y. Zhong, X. Xu, E. Klotz, and S. T. Newman, "Intelligent Manufacturing in the Context of Industry 4.0: A Review," Engineering, vol. 3, no. 5, pp. 616­630, 2017.
[29] B.-h. Li, B.-c. Hou, W.-t. Yu, X.-b. Lu, and C.-w. Yang, "Applications of Artificial Intelligence in Intelligent Manufacturing: A Review," Front. Inf. Technol. Electron. Eng., vol. 18, no. 1, pp. 86­96, 2017.
[30] M. S. Mahdavinejad, M. Rezvan, M. Barekatain, P. Adibi, P. Barnaghi, and A. P. Sheth, "Machine Learning for Internet of Things Data Analysis: A Survey," Digit. Commun. Netw., vol. 4, no. 3, pp. 161­ 175, 2018.
[31] T. Wuest, D. Weimer, C. Irgens, and K.-D. Thoben, "Machine Learning in Manufacturing: Advantages, Challenges, and Applications," Prod. Manuf. Res., vol. 4, no. 1, pp. 23­45, 2016.
[32] P. C. M. Arachchige, P. Bertok, I. Khalil, D. Liu, S. Camtepe, and M. Atiquzzaman, "A Trustworthy Privacy Preserving Framework for Machine Learning in Industrial IoT Systems," IEEE Trans. Ind. Informat., vol. 16, no. 9, pp. 6092­6102, 2020.
[33] K. Wang, Y. Wang, Y. Sun, S. Guo, and J. Wu, "Green Industrial Internet of Things Architecture: An Energy-Efficient Perspective," IEEE Comm. Mag., vol. 54, no. 12, pp. 48­54, 2016.
[34] H. Wang, O. L. Osen, G. Li, W. Li, H.-N. Dai, and W. Zeng, "Big Data and Industrial Internet of Things for the Maritime Industry in Northwestern Norway," in TENCON 2015-IEEE Region 10 Conference. IEEE, 2015, pp. 1­5.
[35] P. Hu, "A System Architecture for Software-Defined Industrial Internet of Things," in IEEE Int. Conf. on Ubiquitous Wireless Broadband (ICUWB). IEEE, 2015, pp. 1­5.
[36] M. M. Najafabadi, F. Villanustre, T. M. Khoshgoftaar, N. Seliya, R. Wald, and E. Muharemagic, "Deep Learning Applications and Challenges in Big Data Analytics," J. Big Data, vol. 2, no. 1, p. 1, 2015.
[37] F. Liang, W. Yu, X. Liu, D. Griffith, and N. Golmie, "Towards Edgebased Deep Learning in Industrial Internet of Things," IEEE Internet Things J., 2020.
[38] H. Ahuett-Garza and T. Kurfess, "A Brief Discussion on the Trends of Habilitating Technologies for Industry 4.0 and Smart Manufacturing," Manuf. Lett., vol. 15, pp. 60­63, 2018.
[39] F. Ullah, H. Naeem, S. Jabbar, S. Khalid, M. A. Latif, F. Al-Turjman, and L. Mostarda, "Cyber Security Threats Detection in Internet of Things using Deep Learning Approach," IEEE Access, vol. 7, pp. 124 379­124 389, 2019.

[40] H. Yan, J. Wan, C. Zhang, S. Tang, Q. Hua, and Z. Wang, "Industrial Big Data Analytics for Prediction of Remaining useful Life based on Deep Learning," IEEE Access, vol. 6, pp. 17 190­17 197, 2018.
[41] J. Wang, Y. Ma, L. Zhang, R. X. Gao, and D. Wu, "Deep Learning for Smart Manufacturing: Methods and Applications," J. Manuf. Syst., vol. 48, pp. 144­156, 2018.
[42] Q. Zhang, L. T. Yang, Z. Chen, P. Li, and F. Bu, "An Adaptive Dropout Deep Computation Model for Industrial IoT Big Data Learning with Crowdsourcing to Cloud Computing," IEEE Trans. Ind Informat., vol. 15, no. 4, pp. 2330­2337, 2018.
[43] L. Zeng, E. Li, Z. Zhou, and X. Chen, "Boomerang: On-demand Cooperative Deep Neural Network Inference for Edge Intelligence on the Industrial Internet of Things," IEEE Netw., vol. 33, no. 5, pp. 96­ 103, 2019.
[44] Y. Chen, "Integrated and Intelligent Manufacturing: Perspectives and Enablers," Engineering, vol. 3, no. 5, pp. 588­595, 2017.
[45] X. Yao, J. Zhou, J. Zhang, and C. R. Boe¨r, "From Intelligent Manufacturing to Smart Manufacturing for Industry 4.0 Driven by Next Generation Artificial Intelligence and Further On," in 5th Int. Conf. on Enterp. Syst. (ES). IEEE, 2017, pp. 311­318.
[46] C.-H. Lee, J.-W. Lin, P.-H. Chen, and Y.-C. Chang, "Deep LearningConstructed Joint Transmission-Recognition for Internet of Things," IEEE Access, vol. 7, pp. 76 547­76 561, 2019.
[47] M. A. Al-Garadi, A. Mohamed, A. Al-Ali, X. Du, I. Ali, and M. Guizani, "A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security," IEEE Commun. Surv. Tutor., 2020.
[48] Y. LeCun, Y. Bengio, and G. Hinton, "Deep Learning," Nature, vol. 521, no. 7553, pp. 436­444, 2015.
[49] F. A. Espitia and L. R. Soto, "Novel Methods Based on Deep Learning Applied to Condition Monitoring in Smart Manufacturing Processes," in New Trends in the Use of Artificial Intelligence for the Industry 4.0. IntechOpen, 2020.
[50] B. Chen and J. Wan, "Emerging trends of ml-based intelligent services for industrial internet of things (iiot)," in Comput., Comm. and IoT Appl. (ComComAp). IEEE, 2019, pp. 135­139.
[51] F. Zantalis, G. Koulouras, S. Karabetsos, and D. Kandris, "A Review of Machine Learning and IoT in Smart Transportation," Future Internet, vol. 11, no. 4, p. 94, 2019.
[52] P. Lade, R. Ghosh, and S. Srinivasan, "Manufacturing Analytics and Industrial Internet of Things," IEEE Intell. Syst., vol. 32, no. 3, pp. 74­79, 2017.
[53] N. Saeed, H. Nam, M. I. U. Haq, and D. B. Muhammad Saqib, "A survey on multidimensional scaling," ACM Comput. Surv., vol. 51, no. 3, May 2018.
[54] F. Al-Turjman and S. Alturjman, "Context-sensitive Access in Industrial Internet of Ihings (IIoT) Healthcare Applications," IEEE Trans. Ind. Informat., vol. 14, no. 6, pp. 2736­2744, 2018.
[55] C. H. Liu, Q. Lin, and S. Wen, "Blockchain-Enabled Data Collection and Sharing for Industrial IoT with Deep Reinforcement Learning," IEEE Trans. Ind. Informat., vol. 15, no. 6, pp. 3516­3526, 2018.
[56] M. Weyrich and C. Ebert, "Reference Architectures for the Internet of Things," IEEE Software, vol. 33, no. 1, pp. 112­116, 2015.
[57] R. A. Khalil, E. Jones, M. I. Babar, T. Jan, M. H. Zafar, and T. Alhussain, "Speech Emotion Recognition Using Deep Learning Techniques: A Review," IEEE Access, vol. 7, pp. 117 327­117 345, 2019.
[58] P. Li, Z. Chen, L. T. Yang, Q. Zhang, and M. J. Deen, "Deep Convolutional Computation Model for Feature Learning on Big Data in Internet of Things," IEEE Trans. Ind. Informat., vol. 14, no. 2, pp. 790­798, 2017.
[59] D. Weimer, A. Y. Benggolo, and M. Freitag, "Context-aware Deep Convolutional Neural Networks for Industrial Inspection," in Proc. of the Australian Conf. on Artificial Intelligence, Canberra, Australia, vol. 30, 2015.
[60] P. Li, Z. Chen, L. T. Yang, J. Gao, Q. Zhang, and M. J. Deen, "An Incremental Deep Convolutional Computation Model for Feature Learning on Industrial Big Data," IEEE Trans. Ind. Informat., vol. 15, no. 3, pp. 1341­1349, 2018.
[61] L. Wen, X. Li, L. Gao, and Y. Zhang, "A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method," IEEE Trans. Ind. Electr., vol. 65, no. 7, pp. 5990­5998, 2018.
[62] M. He and D. He, "Deep Learning based Approach for Bearing Fault Diagnosis," IEEE Trans. Ind. App., vol. 53, no. 3, pp. 3057­3065, 2017.
[63] H. Subakti and J.-R. Jiang, "Indoor Augmented Reality using Deep Learning for Industry 4.0 Smart Factories," in 42nd Annual Comp. Soft. and Appl. Conf. (COMPSAC), vol. 2. IEEE, 2018, pp. 63­68.

16

[64] N. Neogi, D. K. Mohanta, and P. K. Dutta, "Review of Vision-based Steel Surface Inspection Systems," EURASIP J. Image Video Process., vol. 2014, no. 1, p. 50, 2014.
[65] C. Monsone and A. B. CsapA, "Charting the State-of-the-Art in the Application of Convolutional Neural Networks to Quality Control in Industry 4.0 and Smart Manufacturing," in IEEE Int. Conf. on Cognit. Infocomm. (CogInfoCom), 2019, pp. 463­468.
[66] J. Wang, P. Fu, and R. X. Gao, "Machine Vision Intelligence for Product Defect Inspection based on Deep Learning and Hough Transform," J. Manuf. Syst., vol. 51, pp. 52­60, 2019.
[67] J. Lee, M. Azamfar, J. Singh, and S. Siahpour, "Integration of Digital Twin and Deep Learning in Cyber-Physical Systems: Towards Smart Manufacturing," IET Collab. Intell. Manuf., vol. 2, no. 1, pp. 34­36, 2020.
[68] J. Posada, C. Toro, I. Barandiaran, D. Oyarzun, D. Stricker, R. de Amicis, E. B. Pinto, P. Eisert, J. Do¨llner, and I. Vallarino, "Visual computing as a key enabling technology for Industrie 4.0 and Industrial Internet," IEEE Comp. Graph. Appl., vol. 35, no. 2, pp. 26­40, 2015.
[69] T. Wong and Z. Luo, "Recurrent Auto-Encoder Model for Large-Scale Industrial Sensor Signal Analysis," in Int. Conf. on Engg. App. of Neural Netw. Springer, 2018, pp. 203­216.
[70] A.-H. Muna, N. Moustafa, and E. Sitnikova, "Identification of Malicious Activities in Industrial Internet of Things Based on Deep Learning Models," J. Inf. Secur. Appl., vol. 41, pp. 1­11, 2018.
[71] L. Ren, Y. Sun, J. Cui, and L. Zhang, "Bearing Remaining Useful Life Prediction Based on Deep Autoencoder and Deep Neural Networks," J. Manuf. Syst., vol. 48, pp. 71­77, 2018.
[72] A. Essien and C. Giannetti, "A deep learning model for smart manufacturing using convolutional lstm neural network autoencoders," IEEE Trans. Ind. Informat., vol. 16, no. 9, pp. 6069­6078, 2020.
[73] L. Wen, L. Gao, and X. Li, "A New Deep Transfer Learning based on Sparse Auto-Encoder for Fault Diagnosis," IEEE Trans. Syst. Man Cybern. Syst., vol. 49, no. 1, pp. 136­144, 2017.
[74] J. Huang, L. Kong, G. Chen, M.-Y. Wu, X. Liu, and P. Zeng, "Towards Secure Industrial IoT: Blockchain System with Credit-based Consensus Mechanism," IEEE Trans. Ind. Informat., vol. 15, no. 6, pp. 3680­3689, 2019.
[75] A. Hassanzadeh, S. Modi, and S. Mulchandani, "Towards Effective Security Control Assignment in the Industrial Internet of Things," in 2nd World Forum on Internet of Things (WF-IoT). IEEE, 2015, pp. 795­800.
[76] J. Pescatore and G. Shpantzer, "Securing the Internet of Things Survey," SANS Institute, pp. 1­22, 2014.
[77] A. Sherstinsky, "Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network," Physica D, vol. 404, p. 132306, 2020.
[78] M. K. Putchala, "Deep Learning Approach for Intrusion Detection System (IDS) in the Internet of Things (IoT) Network using Gated Recurrent Neural Networks (GRN)," 2017.
[79] K. Lepenioti, M. Pertselakis, A. Bousdekis, A. Louca, F. Lampathaki, D. Apostolou, G. Mentzas, and S. Anastasiou, "Machine Learning for Predictive and Prescriptive Analytics of Operational Data in Smart Manufacturing," in Int. Conf. on Adv. Informat. Syst. Engg. Springer, 2020, pp. 5­16.
[80] B. Roy and H. Cheung, "A Deep Learning Approach for Intrusion Detection in Internet of Things using Bi-directional Long Short-Term Memory Recurrent Neural Network," in 28th Int. Telecomm. Netw. and Appl. Conf. (ITNAC). IEEE, 2018, pp. 1­6.
[81] K. O. Temeng, P. D. Schnelle, and T. J. McAvoy, "Model Predictive Control of An Industrial Packed Bed Reactor Using Neural Networks," J. Process Control, vol. 5, no. 1, pp. 19­27, 1995.
[82] Q. Wu, K. Ding, and B. Huang, "Approach for Fault Prognosis Using Recurrent Neural Network," J. Intell. Manuf., pp. 1­13, 2018.
[83] C.-W. Chang, H.-W. Lee, and C.-H. Liu, "A Review of Artificial Intelligence Algorithms used for Smart Machine Tools," Inventions, vol. 3, no. 3, p. 41, 2018.
[84] C.-H. Lu and C.-C. Tsai, "Adaptive Predictive Control with Recurrent Neural Network for Industrial Processes: An Application to Temperature Control of a Variable-Frequency Oil-Cooling machine," IEEE Trans. Ind. Electr., vol. 55, no. 3, pp. 1366­1375, 2008.
[85] M. Pacella and Q. Semeraro, "Using Recurrent Neural Networks to Detect Changes in Autocorrelated Processes for Quality Monitoring," Comp. Ind. Engg., vol. 52, no. 4, pp. 502­520, 2007.
[86] N. Zhang, S. Ding, J. Zhang, and Y. Xue, "An Overview on Restricted Boltzmann Machines," Neurocomputing, vol. 275, pp. 1186­1199, 2018.

[87] Y. Bai, Z. Sun, J. Deng, L. Li, J. Long, and C. Li, "Manufacturing Quality Prediction using Intelligent Learning Approaches: A Comparative Study," Sustainability, vol. 10, no. 1, p. 85, 2018.
[88] T. J. Saleem and M. A. Chishti, "Deep Learning for Internet of Things Data Analytics," Proc. Comp. Sci., vol. 163, pp. 381­390, 2019.
[89] X. Ma, T. Yao, M. Hu, Y. Dong, W. Liu, F. Wang, and J. Liu, "A Survey on Deep Learning Empowered IoT Applications," IEEE Access, vol. 7, pp. 181 721­181 732, 2019.
[90] L. Banjanovic´-Mehmedovic´ and F. Mehmedovic´, "Intelligent Manufacturing Systems Driven by Artificial Intelligence in Industry 4.0," in Handbook of Research on Integrating Industry 4.0 in Business and Manufacturing. IGI Global, 2020, pp. 31­52.
[91] K. Alrawashdeh and C. Purdy, "Toward an Online Anomaly Intrusion Detection System based on Deep Learning," in 15th IEEE Int. Conf. on Machine Learning and Appl. (ICMLA). IEEE, 2016, pp. 195­200.
[92] M. Ranzato, Y.-L. Boureau, and Y. L. Cun, "Sparse Feature Learning for Deep Belief Networks," in Adv. Neural Info. Process. Syst., 2008, pp. 1185­1192.
[93] Y. Xu, S. Li, D. Zhang, Y. Jin, F. Zhang, N. Li, and H. Li, "Identification Framework for Cracks on a Steel Structure Surface by a Restricted Boltzmann Machines Algorithm based on Consumer-grade Camera Images," Struct. Control Health Monit., vol. 25, no. 2, p. e2075, 2018.
[94] L. Xu, Y. Li, Y. Wang, and E. Chen, "Temporally Adaptive Restricted Boltzmann Machine for Background Modeling," in Twenty-Ninth AAAI Conf. on Artificial Intelligence, 2015.
[95] S. Huda, S. Miah, J. Yearwood, S. Alyahya, H. Al-Dossari, and R. Doss, "A Malicious Threat Detection Model for Cloud Assisted Internet of Things (CoT) based Industrial Control System (ICS) Networks using Deep Belief Network," J. Parallel Distrib. Comput., vol. 120, pp. 23­31, 2018.
[96] R. Salakhutdinov and G. Hinton, "Deep Boltzmann Machines," in Artificial Intelligence and Statistics, 2009, pp. 448­455.
[97] J. Wang, K. Wang, Y. Wang, Z. Huang, and R. Xue, "Deep Boltzmann Machine Based Condition Prediction for Smart Manufacturing," J. Ambient Intell. Humaniz. Comput., vol. 10, no. 3, pp. 851­861, 2019.
[98] R. Socher, C. C. Lin, C. Manning, and A. Y. Ng, "Parsing Natural Scenes and Natural Language with Recursive Neural Networks," in Proc. of the 28th Int. Conf. on Machine Learning (ICML-11), 2011, pp. 129­136.
[99] L. Dong, F. Wei, C. Tan, D. Tang, M. Zhou, and K. Xu, "Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification," in Proc. of the 52nd Annual Meeting of the Assoc. for Comput. Linguistics (Volume 2: Short papers), 2014, pp. 49­54.
[100] D. Wu and M. Chi, "Long Short-Term Memory with Quadratic Connections in Recursive Neural Networks for Representing Compositional Semantics," IEEE Access, vol. 5, pp. 16 077­16 083, 2017.
[101] O. Irsoy and C. Cardie, "Deep Recursive Neural Networks for Compositionality in Language," in Advances in Neural Information Processing Systems, 2014, pp. 2096­2104.
[102] A. Mishra and V. Desai, "Drought Forecasting using Feed-forward Recursive Neural Network," Ecol. Modell., vol. 198, no. 1-2, pp. 127­ 138, 2006.
[103] Y. Kamp and M. Hasler, Recursive Neural Networks for Associative Memory. John Wiley & Sons, Inc., 1990.
[104] A. Chinea, "Understanding The Principles of Recursive Neural Networks: A Generative Approach to Tackle Model Complexity," in Int. Conf. on Artificial Neural Netw. Springer, 2009, pp. 952­963.
[105] Y. Han, C.-J. Zhang, L. Wang, and Y.-C. Zhang, "Industrial IoT for Intelligent Steelmaking With Converter Mouth Flame Spectrum Information Processed by Deep Learning," IEEE Trans. Ind. Informat., vol. 16, no. 4, pp. 2640­2650, 2019.
[106] Q. P. He and J. Wang, "Statistical Process Monitoring as a Big Data Analytics Tool for Smart Manufacturing," J. Process Control, vol. 67, pp. 35­43, 2018.
[107] K. Nowopolski, B. Wicher, D. Luczak, and P. Siwek, "Recursive Neural Network as Speed Controller for Two-sided Electrical Drive with Complex Mechanical Structure," in 22nd Int. Conf. on Methods and Models in Automation and Robotics (MMAR). IEEE, 2017, pp. 576­581.
[108] F. Biancofiore, M. Busilacchio, M. Verdecchia, B. Tomassetti, E. Aruffo, S. Bianco, S. Di Tommaso, C. Colangeli, G. Rosatelli, and P. Di Carlo, "Recursive Neural Network Model for Analysis and Forecast of PM10 and PM2. 5," Atmospheric Pollut. Res., vol. 8, no. 4, pp. 652­659, 2017.
[109] W. Zhang, M.-P. Jia, L. Zhu, and X.-A. Yan, "Comprehensive Overview on Computational Intelligence Techniques for Machinery Condition

17

Monitoring and Fault Diagnosis," Chinese Journal of Mechanical Engineering, vol. 30, no. 4, pp. 782­795, 2017. [110] J. Lee, E. Lapira, B. Bagheri, and H.-a. Kao, "Recent Advances and Trends in Predictive Manufacturing Systems in Big Data Environment," Manuf. Lett., vol. 1, no. 1, pp. 38­41, 2013. [111] J. A. Harding, M. Shahbaz, and A. Kusiak, "Data Mining in Manufacturing: A Review," J. Manuf. Sci. Engg., vol. 128, 2006. [112] B. Esmaeilian, S. Behdad, and B. Wang, "The Evolution and Future of Manufacturing: A Review," J. Manuf. Syst., vol. 39, pp. 79­100, 2016. [113] H. S. Kang, J. Y. Lee, S. Choi, H. Kim, J. H. Park, J. Y. Son, B. H. Kim, and S. Do Noh, "Smart Manufacturing: Past Research, Present Findings, and Future Directions," Int. J. Precision Engg. Manuf.-Green Tech., vol. 3, no. 1, pp. 111­128, 2016. [114] L. Krishnamurthy, R. Adler, P. Buonadonna, J. Chhabra, M. Flanigan, N. Kushalnagar, L. Nachman, and M. Yarvis, "Design and Deployment of Industrial Sensor Networks: Experiences from a Semiconductor Plant and The North Sea," in Proc. of the 3rd Int. Conf. on Embedded Netw. Sensor Syst., 2005, pp. 64­75. [115] B. Lenz and B. Barak, "Data Mining and Support Vector Regression Machine Learning in Semiconductor Manufacturing to Improve Virtual Metrology," in 46th Hawaii Int. Conf. on Syst. Sci. IEEE, 2013, pp. 3447­3456. [116] M. Luo, Z. Xu, H. L. Chan, and M. Alavi, "Online predictive maintenance approach for semiconductor equipment," in 39th Annual Conf. of the IEEE Ind. Electr. Society (IECON). IEEE, 2013, pp. 3662­3667. [117] Y.-C. Su, F.-T. Cheng, M.-H. Hung, and H.-C. Huang, "Intelligent Prognostics System Design and Implementation," IEEE Trans. Semicond. Manuf., vol. 19, no. 2, pp. 195­207, 2006. [118] G. A. Susto, A. Beghi, and C. De Luca, "A Predictive Maintenance System for Epitaxy Processes based on Filtering and Prediction Techniques," IEEE Trans. Semicond. Manuf., vol. 25, no. 4, pp. 638­649, 2012. [119] D. Mourtzis, E. Vlachou, and N. Milas, "Industrial Big Data as a Result of IoT Adoption in Manufacturing," Procedia cirp, vol. 55, pp. 290­ 295, 2016. [120] F. Civerchia, S. Bocchino, C. Salvadori, E. Rossi, L. Maggiani, and M. Petracca, "Industrial Internet of Things Monitoring Solution for Advanced Predictive Maintenance Applications," J. Ind Inform. Integr., vol. 7, pp. 4­12, 2017. [121] G. A. Susto, A. Schirru, S. Pampuri, S. McLoone, and A. Beghi, "Machine Learning for Predictive Maintenance: A Multiple Classifier Approach," IEEE Trans. Ind. Informat., vol. 11, no. 3, pp. 812­820, 2014. [122] S. Butler and J. Ringwood, "Particle Filters for Remaining useful Life Estimation of Abatement Equipment used in Semiconductor Manufacturing," in Conf. on Control and Fault-Tolerant Syst. (SysTol). IEEE, 2010, pp. 436­441. [123] A. Heng, A. C. Tan, J. Mathew, N. Montgomery, D. Banjevic, and A. K. Jardine, "Intelligent Condition-based Prediction of Machinery Reliability," Mech. Syst. Signal Process., vol. 23, no. 5, pp. 1600­1614, 2009. [124] R. Baly and H. Hajj, "Wafer Classification Using Support Vector Machines," IEEE Trans. Semicond. Manuf., vol. 25, no. 3, pp. 373­ 383, 2012. [125] J. R. Kala, D. M. Kre, A. N. Gnassou, J. R. K. Kala, Y. M. A. Akpablin, and T. Coulibaly, "Assets Management on Electrical Grid using FasterRCNN," Ann. Oper. Res., pp. 1­14, 2020. [126] P. Lu¨thi, T. Gagnaux, and M. Gygli, "Distributed Ledger for Provenance Tracking of Artificial Intelligence Assets," in IFIP International Summer School on Privacy and Identity Management. Springer, 2019, pp. 411­426. [127] L. Verma and M. Lalwani, "Digital Transformation: Impact of 5G Technology in Supply Chain Industry," in Technology Optimization and Change Management for Successful Digital Supply Chains. IGI Global, 2019, pp. 256­274. [128] S. Rohit, A. G. Jamkhandi, A. Rao, V. Krishna, A. Naik, and M. Parathodiyil, "Iot based identification and assessment of industrial assets," in 2018 International Conference on Computing, Power and Communication Technologies (GUCON). IEEE, 2018, pp. 378­383. [129] C. J. Turner, J. Oyekan, L. Stergioulas, and D. Griffin, "Utilizing Industry 4.0 on the Construction Site Challenges and Opportunities," IEEE Trans. Ind. Informat., 2020. [130] D. Seneviratne, L. Ciani, M. Catelani, D. Galar et al., "Smart Maintenance and Inspection of Linear Assets: An Industry 4.0 Approach," Acta Imeko, 2018.

[131] S. Marvin, H. Chappells, and S. Guy, "Pathways of Smart Metering Development: Shaping Environmental Innovation," Comput. Environ. Urban Syst., vol. 23, no. 2, pp. 109­126, 1999.
[132] H. Shi, M. Xu, and R. Li, "Deep Learning for Household Load Forecasting: A Novel Pooling Deep RNN," IEEE Trans. Smart Grid, vol. 9, no. 5, pp. 5271­5280, 2017.
[133] Y. Wang, Q. Chen, D. Gan, J. Yang, D. S. Kirschen, and C. Kang, "Deep Learning-based Socio-Demographic Information Identification from Smart Meter Data," IEEE Trans. Smart Grid, vol. 10, no. 3, pp. 2593­2602, 2018.
[134] B. Yang, S. Liu, M. Gaterell, and Y. Wang, "Smart Metering and Systems for Low-Energy Households: Challenges, Issues and Benefits," Adv. Build. Energy Res., vol. 13, no. 1, pp. 80­100, 2019.
[135] E. F. Livgard, "Smart Metering-Opportunity or Threat to the Power Industry?" in Int. Conf. on Power Syst. Tech. IEEE, 2010, pp. 1­4.
[136] I. Khatri, X. Dong, J. Attia, and L. Qian, "Short-Term Load Forecasting on Smart Meter via Deep Learning," in North American Power Symposium (NAPS). IEEE, 2019, pp. 1­6.
[137] A. K. Chakraborty and N. Sharma, "Advanced Metering Infrastructure: Technology and Challenges," in IEEE/PES Transm. and Distrib. Conf. and Exposition (T&D). IEEE, 2016, pp. 1­5.
[138] N. Andreadou, M. O. Guardiola, and G. Fulli, "Telecommunication Technologies for Smart Grid Projects with Focus on Smart Metering Applications," Energies, vol. 9, no. 5, p. 375, 2016.
[139] N. Varsier and J. Schwoerer, "Capacity Limits of LoRaWAN Technology for Smart Metering Applications," in IEEE Int. Conf. on Comm. (ICC). IEEE, 2017, pp. 1­6.
[140] Y. Li, X. Yan, L. Zeng, and H. Wu, "Research on Water Meter Reading System based on LoRa Communication," in IEEE Int. Conf. on Smart Grid and Smart Cities (ICSGSC). IEEE, 2017, pp. 248­251.
[141] A. Nilsson, M. Wester, D. Lazarevic, and N. Brandt, "Smart Homes, Home Energy Management Systems and Real-Time Feedback: Lessons for Influencing Household Energy Consumption from a Swedish Field Study," Energy and Buildings, vol. 179, pp. 15­25, 2018.
[142] P. Van Aubel and E. Poll, "Smart Metering in the Netherlands: What, How, and Why," Int. J. Electr. Power Energy Syst., vol. 109, pp. 719­ 725, 2019.
[143] L. Draetta, A. Lorenzet, F. Neresini, and B. Tavner, "When an Emerging Technology goes Public. A Comparative Analysis of the Smart Meters Debate in France and Italy," 2020.
[144] N. Uribe-Pe´rez, L. Herna´ndez, D. De la Vega, and I. Angulo, "Stateof-the-Art and Trends Review of Smart Metering in Electricity Grids," Applied Sciences, vol. 6, no. 3, p. 68, 2016.
[145] A. K. M. Masum, S. Manzur, M. K. A. Chy, S. I. Khan, M. G. R. Alam, and S. T. Reza, "An IoT based Smart Energy Meter for the Idle Use of Electricity: An Industry Perspective," in 1st Int. Conf. on Adv. in Sci, Engg. and Robotics Tech. (ICASERT). IEEE, 2019, pp. 1­6.
[146] P. Weiß, B. Ko¨lmel, and R. Bulander, "Digital Service Innovation and Smart Technologies: Developing Digital Strategies based on Industry 4.0 and Product Service Systems for the Renewal Energy Sector," Tiziana Russo-Spenaand Cristina Mele, p. 274, 2016.
[147] Y. Kabalci, "A Survey on Smart Metering and Smart Grid Communication," Renew. Sust. Energ. Rev., vol. 57, pp. 302­318, 2016.
[148] H. Xu, W. Yu, D. Griffith, and N. Golmie, "A Survey on Industrial Internet of Things: A Cyber-Physical Systems Perspective," IEEE Access, vol. 6, pp. 78 238­78 259, 2018.
[149] V. C. Gungor, D. Sahin, T. Kocak, S. Ergut, C. Buccella, C. Cecati, and G. P. Hancke, "Smart Grid Technologies: Communication Technologies and Standards," IEEE Trans. Ind. Informat., vol. 7, no. 4, pp. 529­539, 2011.
[150] L. Li, K. Ota, and M. Dong, "Deep Learning for Smart Industry: Efficient Manufacture Inspection System with Fog Computing," IEEE Trans. Ind. Informat., vol. 14, no. 10, pp. 4665­4673, 2018.
[151] Y. He, G. J. Mendis, and J. Wei, "Real-Time Detection of False Data Injection Attacks in Smart Grid: A Deep Learning-based Intelligent mechanism," IEEE Trans. Smart Grid, vol. 8, no. 5, pp. 2505­2516, 2017.
[152] Y. Wang, P. Zeng, H. Yu, Y. Zhang, and X. Wang, "Energy Tree dynamics of Smart Grid based on Industrial Internet of Things," Int. J. Distr. Sensor Netw., vol. 9, no. 8, p. 583846, 2013.
[153] P. Kukuca and I. Chrapciak, "From Smart Metering to Smart Grid," Meas. Sci. Rev., vol. 16, no. 3, pp. 142­148, 2016.
[154] M. Faheem, S. B. H. Shah, R. A. Butt, B. Raza, M. Anwar, M. W. Ashraf, M. A. Ngadi, and V. C. Gungor, "Smart Grid Communication and Information Technologies in the Perspective of Industry 4.0: Opportunities and Challenges," Comp. Sci. Rev., vol. 30, pp. 1­30, 2018.

18

[155] P. Palensky and D. Dietrich, "Demand Side Management: Demand Response, Intelligent Energy Systems, and Smart Loads," IEEE Trans. Ind. Informat., vol. 7, no. 3, pp. 381­388, 2011.
[156] D. Zhang, X. Han, and C. Deng, "Review on the Research and Practice of Deep Learning and Reinforcement Learning in Smart Grids," CSEE J. Power Energy Syst., vol. 4, no. 3, pp. 362­370, 2018.
[157] O. Vermesan and P. Friess, Internet of Things: Converging Technologies for Smart environments and Integrated ecosystems. River publishers, 2013.
[158] X. Li, J. Wan, H.-N. Dai, M. Imran, M. Xia, and A. Celesti, "A Hybrid Computing Solution and Resource Scheduling Strategy for Edge Computing in Smart Manufacturing," IEEE Trans. Ind. Informat., vol. 15, no. 7, pp. 4225­4234, 2019.
[159] G. D. L. T. Parra, P. Rad, and K.-K. R. Choo, "Implementation of Deep Packet Inspection in Smart Grids and Industrial Internet of Things: Challenges and Opportunities," J. Netw. Comp. Appl., vol. 135, pp. 32­46, 2019.
[160] H. Wang, J. Ruan, G. Wang, B. Zhou, Y. Liu, X. Fu, and J. Peng, "Deep Learning-based Interval State Estimation of AC Smart Grids against Sparse Cyber Attacks," IEEE Trans. Ind. Informat., vol. 14, no. 11, pp. 4766­4778, 2018.
[161] M. Esmalifalak, L. Liu, N. Nguyen, R. Zheng, and Z. Han, "Detecting Stealthy False Data Injection using Machine Learning in Smart Grid," IEEE Syst. J., vol. 11, no. 3, pp. 1644­1652, 2014.
[162] K. Yan, X. Wang, Y. Du, N. Jin, H. Huang, and H. Zhou, "Multistep Short-term Power Consumption Forecasting with a Hybrid Deep Learning Strategy," Energies, vol. 11, no. 11, p. 3089, 2018.
[163] Z. Liang, G. Zhang, J. X. Huang, and Q. V. Hu, "Deep Learning for Healthcare Decision Making with EMRs," in IEEE Int. Conf. on Bioinformatics and Biomedicine (BIBM). IEEE, 2014, pp. 556­559.
[164] S. Min, B. Lee, and S. Yoon, "Deep Learning in Bioinformatics," Briefings in Bioinformatics, vol. 18, no. 5, pp. 851­869, 2017.
[165] S. R. Islam, D. Kwak, M. H. Kabir, M. Hossain, and K.-S. Kwak, "The Internet of Things for Health care: A Comprehensive Survey," IEEE Access, vol. 3, pp. 678­708, 2015.
[166] C. A. Tokognon, B. Gao, G. Y. Tian, and Y. Yan, "Structural Health Monitoring Framework based on Internet of Things: A Survey," IEEE Internet Things J., vol. 4, no. 3, pp. 619­635, 2017.
[167] R. Zhao, R. Yan, Z. Chen, K. Mao, P. Wang, and R. X. Gao, "Deep Learning and its Applications to Machine Health Monitoring: A Survey," arXiv preprint arXiv:1612.07640, 2016.
[168] S. Tuli, N. Basumatary, S. S. Gill, M. Kahani, R. C. Arya, G. S. Wander, and R. Buyya, "Healthfog: An Esemble Deep Learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in Integrated IoT and Fog Computing Environments," Future Gen. Comp. Syst., vol. 104, pp. 187­200, 2020.
[169] L. Saba, M. Biswas, V. Kuppili, E. C. Godia, H. S. Suri, D. R. Edla, T. Omerzu, J. R. Laird, N. N. Khanna, S. Mavrogeni et al., "The Present and Future of Deep Learning in Radiology," European J. Radiology, vol. 114, pp. 14­24, 2019.
[170] P. Tamilselvan and P. Wang, "Failure Diagnosis using Deep Belief Learning based Health State Classification," Reliab. Eng. Syst. Saf., vol. 115, pp. 124­135, 2013.
[171] A. Lavecchia, "Deep Learning in Drug Discovery: Opportunities, Challenges and Future Prospects," Drug Discovery Today, vol. 24, no. 10, pp. 2017­2032, 2019.
[172] K. Preuer, G. Klambauer, F. Rippmann, S. Hochreiter, and T. Unterthiner, "Interpretable Deep Learning in Drug Discovery," in Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Springer, 2019, pp. 331­345.
[173] G. Klambauer, S. Hochreiter, and M. Rarey, "Machine Learning in Drug Discovery," 2019.
[174] E. Lindelo¨f, "Deep Learning for Drug Discovery, Property Prediction with Neural Networks on Raw Molecular Graphs," Master's thesis, 2019.
[175] A. S. Rifaioglu, H. Atas, M. J. Martin, R. Cetin-Atalay, V. Atalay, and T. Dogan, "Recent Applications of Deep Learning and Machine Intelligence on in Silico Drug Discovery: Methods, Tools and Databases," Briefings in Bioinformatics, vol. 20, no. 5, pp. 1878­1912, 2019.
[176] P. Maragakis, H. Nisonoff, B. Cole, and D. E. Shaw, "A Deep-Learning View of Chemical Space Designed to Facilitate Drug Discovery," arXiv preprint arXiv:2002.02948, 2020.
[177] A. S. Lundervold and A. Lundervold, "An Overview of Deep Learning in Medical Imaging Focusing on MRI," Zeitschrift fu¨r Medizinische Physik, vol. 29, no. 2, pp. 102­127, 2019.

[178] M. Biswas, V. Kuppili, L. Saba, D. R. Edla, H. S. Suri, E. CuadradoGodia, J. R. Laird, R. T. Marinhoe, J. M. Sanches, A. Nicolaides et al., "State-of-the-Art Review on Deep Learning in Medical Imaging." Frontiers in Bioscience (Landmark Edition), vol. 24, pp. 392­426, 2019.
[179] G.-S. Fu, Y. Levin-Schwartz, Q.-H. Lin, and D. Zhang, "Machine Learning for Medical Imaging," 2019.
[180] B. Sahiner, A. Pezeshk, L. M. Hadjiiski, X. Wang, K. Drukker, K. H. Cha, R. M. Summers, and M. L. Giger, "Deep Learning in Medical Imaging and Radiation Therapy," Medical Physics, vol. 46, no. 1, pp. e1­e36, 2019.
[181] Z. Guo, X. Li, H. Huang, N. Guo, and Q. Li, "Deep Learning-based Image Segmentation on Multimodal Medical Imaging," IEEE Trans. Radiation Plasma Med. Sci., vol. 3, no. 2, pp. 162­169, 2019.
[182] G. Currie, K. E. Hawk, E. Rohren, A. Vial, and R. Klein, "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging," J. Med. Imaging Radiat. Sci., vol. 50, no. 4, pp. 477­487, 2019.
[183] G. Haskins, U. Kruger, and P. Yan, "Deep Learning in Medical Image Registration: A Survey," Mach. Vis. Appl., vol. 31, no. 1, p. 8, 2020.
[184] H.-P. Chan, R. K. Samala, L. M. Hadjiiski, and C. Zhou, "Deep Learning in Medical Image Analysis," in Deep Learning in Medical Image Analysis. Springer, 2020, pp. 3­21.
[185] M. Simsek, A. A. Obinikpo, and B. Kantarci, "Deep Learning in Smart Health: Methodologies, Applications, Challenges," in Connected Health in Smart Cities. Springer, 2020, pp. 23­46.
[186] Q. Xue and M. C. Chuah, "Explainable Deep Learning based Medical Diagnostic System," Smart Health, vol. 13, p. 100068, 2019.
[187] G. Harerimana, J. W. Kim, H. Yoo, and B. Jang, "Deep Learning for Electronic Health Records Analytics," IEEE Access, vol. 7, pp. 101 245­101 259, 2019.
[188] S. U. Amin, M. S. Hossain, G. Muhammad, M. Alhussein, and M. A. Rahman, "Cognitive Smart Healthcare for Pathology Detection and Monitoring," IEEE Access, vol. 7, pp. 10 745­10 753, 2019.
[189] W. W. Stead, "Clinical Implications and Challenges of Artificial Intelligence and Deep Learning," Jama, vol. 320, no. 11, pp. 1107­ 1108, 2018.
[190] G. Wang, "A Perspective on Deep Imaging," IEEE Access, vol. 4, pp. 8914­8924, 2016.
[191] Z. Shen and M. Spruit, "A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare," Applied Sciences, vol. 9, no. 1, p. 150, 2019.
[192] Y. Liang, D. Wu, D. Ledesma, C. Davis, R. Slaughter, and Z. Guo, "Virtual Tai-Chi System: A Smart-Connected Modality for Rehabilitation," Smart Health, vol. 9, pp. 232­249, 2018.
[193] Y. K. Dwivedi, L. Hughes, E. Ismagilova, G. Aarts, C. Coombs, T. Crick, Y. Duan, R. Dwivedi, J. Edwards, A. Eirug et al., "Artificial Intelligence (AI): Multidisciplinary Perspectives on Emerging Challenges, Opportunities, and Agenda for Research, Practice and Policy," Int. J. Inf. Manage., p. 101994, 2019.
[194] S. F. Ardabili, A. Mosavi, P. Ghamisi, F. Ferdinand, A. R. VarkonyiKoczy, U. Reuter, T. Rabczuk, and P. M. Atkinson, "Covid-19 Outbreak Prediction with Machine Learning," Available at SSRN 3580188, 2020.
[195] S. M. Ayyoubzadeh, S. M. Ayyoubzadeh, H. Zahedi, M. Ahmadi, and S. R. N. Kalhori, "Predicting COVID-19 Incidence Through Analysis of Google Trends Data in Iran: Data Mining and Deep Learning Pilot Study," JMIR Public Health and Surveillance, vol. 6, no. 2, p. e18828, 2020.
[196] V. Sharma, A. Kumar, D. Lakshmi Panat, G. Karajkhede et al., "Malaria Outbreak Prediction Model using Machine Learning," Int. J. Adv. Res. Comp. Eng. Techn. (IJARCET), vol. 4, no. 12, 2015.
[197] J. Zhang and K. Nawata, "A Comparative Study on Predicting Influenza Outbreaks," Bioscience Trends, 2017.
[198] A. Alessa and M. Faezipour, "Preliminary Flu Outbreak Prediction using Twitter posts Classification and Linear Regression with Historical Centers for Disease Control and Prevention Reports: Prediction Framework Study," JMIR Public Health and Surveillance, vol. 5, no. 2, p. e12383, 2019.
[199] M. Chen, Y. Hao, K. Hwang, L. Wang, and L. Wang, "Disease Prediction by Machine Learning Over Big Data from Healthcare Communities," IEEE Access, vol. 5, pp. 8869­8879, 2017.
[200] H. Lu, Y. Li, S. Mu, D. Wang, H. Kim, and S. Serikawa, "Motor Anomaly Detection for Unmanned Aerial Vehicles using Reinforcement Learning," IEEE Internet Things J., vol. 5, no. 4, pp. 2315­2322, 2017.
[201] W. Jia, X. Li, K. Tan, and G. Xie, "Predicting the Outbreak of the Hand-Foot-Mouth Diseases in China using Recurrent Neural Network,"

19

in IEEE Int. Conf. on Healthcare Informat. (ICHI). IEEE, 2019, pp. 1­4. [202] P. Tambe, P. Cappelli, and V. Yakubovich, "Artificial Intelligence in Human Resources Management: Challenges and a Path Forward," California Manage. Rev., vol. 61, no. 4, pp. 15­42, 2019. [203] V. N. Lu, J. Wirtz, W. H. Kunz, S. Paluch, T. Gruber, A. Martins, and P. G. Patterson, "Service Robots, Customers and Service Employees: What Can We Learn from the Academic Literature and Where are the gaps?" J. Serv. Theory Pract., 2020. [204] A. V. Bogoviz, "Perspective Directions of State Regulation of Competition between Human and Artificial Intellectual Capital in Industry 4.0," J. Intellectual Capital, 2020. [205] C. Arnold, D. Kiel, and K.-I. Voigt, "How the Industrial Internet of Things Changes Business Models in Different Manufacturing Industries," Int. J. Innov. Manage., vol. 20, no. 08, p. 1640015, 2016. [206] E. Tsui, B. J. Garner, and S. Staab, "The Role of Artificial Intelligence in Knowledge management," Knowledge Based Systems, vol. 13, no. 5, pp. 235­239, 2000. [207] A. Pera et al., "Towards Effective Workforce Management: Hiring Algorithms, Big Data-Driven Accountability Systems, and Organizational Performance," Psychosociological Issues in Human Resource Management, vol. 7, no. 2, pp. 19­24, 2019. [208] P. Dahlbom, N. Siikanen, P. Sajasalo, and M. Jarvenpa¨a¨, "Big data and hr analytics in the digital era," Baltic Journal of Management, 2019. [209] R. Buettner, "Cognitive Workload of Humans using Artificial Intelligence Systems: Towards Objective Measurement Applying EyeTracking Technology," in Annual Conf. on Artificial Intelligence. Springer, 2013, pp. 37­48. [210] D. Kiel, C. Arnold, and K.-I. Voigt, "The Influence of the Industrial Internet of Things on Business Models of Established Manufacturing Companies?A Business Level Perspective," Technovation, vol. 68, pp. 4­19, 2017. [211] J. Liebowitz, "Knowledge Management and its Link to Artificial intelligence," Expert Syst. Appl., vol. 20, no. 1, pp. 1­6, 2001. [212] B. Hmoud, V. Laszlo et al., "Will Artificial Intelligence Take Over Human Resources Recruitment and Selection," Netw. Intell. Stud., vol. 7, no. 13, pp. 21­30, 2019. [213] C. Dirican, "The Impacts of Robotics, Artificial Intelligence on Business and Economics," Procedia-Social and Behavioral Sciences, vol. 195, pp. 564­573, 2015. [214] H. P. Breivold and K. Sandstro¨m, "Internet of Things for Industrial Automation?Challenges and Technical Solutions," in Int. Conf. on Data Sci. and Data Intensive Syst. IEEE, 2015, pp. 532­539. [215] D. Paschek, A. Mocan, C.-M. Dufour, and A. Draghici, "Organizational Knowledge Management with Big Data. The Foundation of using Artificial Intelligence," in Balkan Region Conf. on Eng. and Busin. Edu., vol. 3, no. 1. Sciendo, 2017, pp. 301­308. [216] M. H. Jarrahi, "Artificial Intelligence and the Future of work: HumanAI Symbiosis in Organizational Decision Making," Business Horizons, vol. 61, no. 4, pp. 577­586, 2018. [217] "5 Benefits IoT is having on the Mining Industry - Internet of Things Blog," Feb 2019. [Online]. Available: https://www.ibm.com/ blogs/internet-of-things/mining-industry-benefits/ [218] C. Lee, S.-M. Kim, and Y. Choi, "Case Analysis for Introduction of Machine Learning Technology to the Mining industry," Tunnel and Underground Space, vol. 29, no. 1, pp. 1­11, 2019. [219] L. Ri-Xian, Y. Ming-Hai, and W. Xian-Bao, "Defects detection based on deep learning and transfer learning." Metallurgical & Mining Industry, no. 7, 2015. [220] A. J. Trappey, C. V. Trappey, U. H. Govindarajan, and J. J. Sun, "Patent Value Analysis Using Deep Learning Models? The Case of IoT Technology Mining for the Manufacturing Industry," IEEE Trans. Eng. Manage., 2019. [221] D. Ali and S. Frimpong, "Artificial Intelligence, Machine learning and Process Automation: Existing Knowledge Frontier and Way Forward for Mining Sector," Artificial Intelligence Rev., pp. 1­18, 2020. [222] F. P. Carvalho, "Mining Industry and Sustainable Development: Time for Change," Food and Energy Security, vol. 6, no. 2, pp. 61­77, 2017. [223] Z. Hyder, K. Siau, and F. Nah, "Artificial Intelligence, Machine Learning, and Autonomous Technologies in Mining Industry," J. Database Management (JDM), vol. 30, no. 2, pp. 67­79, 2019. [224] E. Van Wyk and R. De Villiers, "Virtual Reality Training Applications for the Mining Industry," in 6th Int. Conf. on Comp. Graph., Virtual Reality, Visualisation and Interaction in Africa, 2009, pp. 53­63. [225] S. T. Phakathi, Introduction', Production, Safety and Teamwork in a Deep-Level Mining Workplace. Emerald Publishing Limited, 2017.

[226] R. Chiong, Z. Hu, Z. Fan, Y. Lin, S. Chalup, and A. Desmet, "A Bio-inspired Clustering Model for Anomaly Detection in the Mining Industry," Bio-inspired Computing Models And Algorithms, p. 133, 2019.
[227] A. Kamilaris and F. X. Prenafeta-Boldu´, "Deep Learning in Agriculture: A Survey," Comp. Electr. Agri, vol. 147, pp. 70­90, 2018.
[228] S. Prathibha, A. Hongal, and M. Jyothi, "IoT Based Monitoring System in Smart Agriculture," in Int. Conf. on Recent Adv. in Electr. & Comm. Techn. (ICRAECT). IEEE, 2017, pp. 81­84.
[229] N. Suma, S. R. Samson, S. Saranya, G. Shanmugapriya, and R. Subhashri, "Iot based smart agriculture monitoring system," Int. J. on Recent Innov. Trends in Comput. Comm., vol. 5, no. 2, pp. 177­181, 2017.
[230] M. Taylor, "Climate-Smart Agriculture: What is it good for?" The J. Peasant Stud., vol. 45, no. 1, pp. 89­107, 2018.
[231] "A Survey: Smart Agriculture IoT with Cloud Computing, author=Mekala, Mahammad Shareef and Viswanathan, P, booktitle=Int. Conf. on Microelectr. Devi., Circ. and Syst. (ICMDCS), pages=1­7, year=2017, organization=IEEE."
[232] A. X. Wang, C. Tran, N. Desai, D. Lobell, and S. Ermon, "Deep Transfer Learning for crop yield prediction with Remote Sensing Data," in 1st ACM SIGCAS Conf. on Comput. and Sustain. Societies, 2018, pp. 1­5.
[233] N. Zhu, X. Liu, Z. Liu, K. Hu, Y. Wang, J. Tan, M. Huang, Q. Zhu, X. Ji, Y. Jiang et al., "Deep Learning for Smart Agriculture: Concepts, Tools, Applications, and Opportunities," Int. J. of Agri. and Bio. Eng., vol. 11, no. 4, pp. 32­44, 2018.
[234] X.-B. Jin, N.-X. Yang, X.-Y. Wang, Y.-T. Bai, T.-L. Su, and J.-L. Kong, "Hybrid Deep Learning Predictor for Smart Agriculture sensing based on Empirical Mode Decomposition and Gated Recurrent Unit Group Model," Sensors, vol. 20, no. 5, p. 1334, 2020.
[235] H. Park, E. JeeSook, and S.-H. Kim, "Crops Disease Diagnosing using Image-based Deep Learning Mechanism," in Int. Conf. on Comput. and Netw. Commun. (CoCoNet). IEEE, 2018, pp. 23­26.
[236] K. Kuwata and R. Shibasaki, "Estimating Crop yields with Deep Learning and Remotely sensed data," in Int. Geosci. and Remote Sens. Symp. (IGARSS). IEEE, 2015, pp. 858­861.
[237] B. Veeramani, J. W. Raymond, and P. Chanda, "DeepSort: Deep Convolutional Networks for sorting haploid maize seeds," BMC Bioinformatics, vol. 19, no. 9, p. 289, 2018.
[238] S. Coulibaly, B. Kamsu-Foguem, D. Kamissoko, and D. Traore, "Deep Neural Networks with Transfer Learning in Millet Crop Images," Comp. In Industry, vol. 108, pp. 115­120, 2019.
[239] B. A. Ashqar and S. S. Abu-Naser, "Identifying Images of Invasive Hydrangea Using Pre-Trained Deep Convolutional Neural Networks," Int. J. of Acad. Eng. Res. (IJAER), vol. 3, no. 3, pp. 28­36, 2019.
[240] C.-H. Lin, W.-C. Wang, C.-Y. Liu, P.-N. Pan, and H.-R. Pan, "Research into the E-learning model of Agriculture Technology Companies: Analysis by Deep Learning," Agronomy, vol. 9, no. 2, p. 83, 2019.
[241] R. Prashanth, K. Deepak, and A. K. Meher, "High Accuracy Predictive Modelling for Customer Churn Prediction in Telecom Industry," in Int. Conf. on Machine Learning and Data Mining in Pattern Recognition. Springer, 2017, pp. 391­402.
[242] U. Ahmed, A. Khan, S. H. Khan, A. Basit, I. U. Haq, and Y. S. Lee, "Transfer Learning and Meta classification based Deep Churn Prediction system for Telecom industry," arXiv preprint arXiv:1901.06091, 2019.
[243] Y. Khan, S. Shafiq, A. Naeem, S. Hussain, S. Ahmed, and N. Safwan, "Customers Churn Prediction using Artificial Neural Networks (ANN) in Telecom Industry," Editorial Preface From the Desk of Managing Editor, vol. 10, no. 9, 2019.
[244] K. Alshathri, H. Xia, V. Lawrence, and Y.-D. Yao, "Cellular System Identification using Deep Learning: GSM, UMTS and LTE," in 28th Wireless and Optical Comm. Conf. (WOCC). IEEE, 2019, pp. 1­4.
[245] A. Mishra and U. S. Reddy, "A Comparative Study of Customer Churn Prediction in Telecom Industry using Ensemble based classifiers," in Int. Conf. on Inventive Comp. and Informat. (ICICI). IEEE, 2017, pp. 721­725.
[246] R. Hebbalaguppe, G. Garg, E. Hassan, H. Ghosh, and A. Verma, "Telecom Inventory Management via Object Recognition and Localisation on Google Street View Images," in IEEE Winter Conf. on Appl. of Comp. Vision (WACV). IEEE, 2017, pp. 725­733.
[247] C.-W. Huang, C.-T. Chiang, and Q. Li, "A Study of Deep Learning Networks on Mobile Traffic Forecasting," in 28th Annual Int. Symp. on Personal, Indoor, and Mobile Radio Comm. (PIMRC). IEEE, 2017, pp. 1­6.

20

[248] A. Thantharate, R. Paropkari, V. Walunj, and C. Beard, "Deepslice: A Deep Learning Approach Towards an Efficient and Reliable Network slicing in 5G Networks," in 10th Annual Ubiquitous Comput., Electr. & Mobile Comm. Conf. (UEMCON). IEEE, 2019, pp. 0762­0767.
[249] H. Zahid, T. Mahmood, A. Morshed, and T. Sellis, "Big Data Analytics in Telecommunications: Literature Review and Architecture Recommendations," IEEE/CAA J. Aut. Sinica, vol. 7, no. 1, pp. 18­38, 2019.
[250] J. Zhang, F.-Y. Wang, K. Wang, W.-H. Lin, X. Xu, and C. Chen, "Datadriven Intelligent Transportation Systems: A Survey," IEEE Trans. Intell. Transp. Syst., vol. 12, no. 4, pp. 1624­1639, 2011.
[251] G. Dimitrakopoulos and P. Demestichas, "Intelligent Transportation Systems," IEEE Veh. Tech. Mag., vol. 5, no. 1, pp. 77­84, 2010.
[252] K. Ozbay and P. Kachroo, "Incident Management in Intelligent Transportation Systems," 1999.
[253] C. Hu, X. Bai, L. Qi, P. Chen, G. Xue, and L. Mei, "Vehicle Color Recognition with Spatial Pyramid Deep Learning," IEEE Trans. Intell. Transp. Syst., vol. 16, no. 5, pp. 2925­2934, 2015.
[254] Y. Lv, Y. Duan, W. Kang, Z. Li, and F.-Y. Wang, "Traffic Flow Prediction with Big Data: A Deep Learning Approach," IEEE Trans. Intell. Transp. Syst., vol. 16, no. 2, pp. 865­873, 2014.
[255] V. John, K. Yoneda, B. Qi, Z. Liu, and S. Mita, "Traffic Light Recognition in varying illumination using Deep Learning and Saliency Map," in 17th Int. Conf. on Intell. Transp. Syst. (ITSC). IEEE, 2014, pp. 2286­2291.
[256] L. Wang and D. Sng, "Deep Learning Algorithms with Applications to Video Analytics for a Smart City: A Survey," arXiv preprint arXiv:1512.03131, 2015.
[257] C. Hodges, S. An, H. Rahmani, and M. Bennamoun, "Deep Learning for Driverless Vehicles," in Handbook of Deep Learning Appl. Springer, 2019, pp. 83­99.
[258] K.-H. N. Bui, H. Yi, H. Jung, and J. Seo, "Big Data Analytics-based Urban Traffic Prediction using Deep Learning in its," in Int. Conf. on Artificial Intelligence (ICAI). The Steering Committee of The World Congress in Computer Science, Computer ?, 2019, pp. 270­273.
[259] Y. Wang, D. Zhang, Y. Liu, B. Dai, and L. H. Lee, "Enhancing Transportation Systems via Deep Learning: A Survey," Transp. Res. Part C: Emerging Tech., vol. 99, pp. 144­163, 2019.
[260] Y. Duan, Y. Lv, W. Kang, and Y. Zhao, "A Deep Learning based approach for Traffic Data Imputation," in 17th Int. Conf. on Intell. Transp. Syst. (ITSC). IEEE, 2014, pp. 912­917.
[261] B. Huval, T. Wang, S. Tandon, J. Kiske, W. Song, J. Pazhayampallil, M. Andriluka, P. Rajpurkar, T. Migimatsu, R. Cheng-Yue et al., "An Empirical Evaluation of Deep Learning on Highway Driving," arXiv preprint arXiv:1504.01716, 2015.
[262] T. Chen, Z. Chen, Q. Shi, and X. Huang, "Road Marking Detection and Classification using Machine Learning Algorithms," in IEEE Intell. Veh. Symp. (IV). IEEE, 2015, pp. 617­621.
[263] R. Atallah, C. Assi, and M. Khabbaz, "Deep Reinforcement Learningbased Scheduling for Roadside Communication Networks," in 15th Int. Symp. on Modeling and Optim. in Mobile, Ad Hoc, and Wireless Netw. (WiOpt). IEEE, 2017, pp. 1­8.
[264] H. Crooks, Giants of Garbage: The Rise of the Global Waste Industry and the Politics of Pollution. James Lorimer & Company, 1993.
[265] J. C. Kabugo, S.-L. Ja¨msa¨-Jounela, R. Schiemann, and C. Binder, "Industry 4.0 based process Data Analytics platform: A Waste-toEnergy plant Case Study," Int. J. Elect. Power & Energy Syst., vol. 115, p. 105508, 2020.
[266] S. Sudha, M. Vidhyalakshmi, K. Pavithra, K. Sangeetha, and V. Swaathi, "An Automatic Classification method for Environment: Friendly Waste Segregation using Deep Learning," in IEEE Technological Innovations in ICT for Agriculture and Rural Development (TIAR). IEEE, 2016, pp. 65­70.
[267] C. Bircanoglu, M. Atay, F. Bes¸er, O¨ . Genc¸, and M. A. Kizrak, "Recyclenet: Intelligent waste sorting using Deep Neural Networks," in Innov. in Intell.t Syst. and App. (INISTA), 2018, pp. 1­7.
[268] J. Sousa, A. Rebelo, and J. S. Cardoso, "Automation of Waste Sorting with Deep Learning," in XV Workshop de Visa~o Computacional (WVC). IEEE, 2019, pp. 43­48.
[269] T. Vafeiadis, A. Nizamis, V. Pavlopoulos, L. Giugliano, V. Rousopoulou, D. Ioannidis, and D. Tzovaras, "Data Analytics Platform for the Optimization of Waste Management Procedures," in 15th Int. Conf. on Distrib. Comput. in Sensor Syst. (DCOSS). IEEE, 2019, pp. 333­338.
[270] S. O. Ajayi, L. O. Oyedele, O. O. Akinade, M. Bilal, H. A. Owolabi, H. A. Alaka, and K. O. Kadiri, "Reducing Waste to Landfill: A need for Cultural change in the UK Construction Industry," J. Build. Eng., vol. 5, pp. 185­193, 2016.

[271] M. A. Lapre´, A. S. Mukherjee, and L. N. Van Wassenhove, "Behind the Learning Curve: Linking Learning activities to Waste Reduction," Manage. Sci., vol. 46, no. 5, pp. 597­611, 2000.
[272] A. J. McStay, Digital Advertising. Macmillan International Higher Education, 2016.
[273] M. Lombard and J. Snyder-Duch, "Interactive Advertising and Presence: A Framework," J. Interactive Advert., vol. 1, no. 2, pp. 56­65, 2001.
[274] A. E. Carter and C. T. Ragsdale, "Scheduling Pre-printed Newspaper Advertising Inserts using Genetic Algorithms," Omega, vol. 30, no. 6, pp. 415­421, 2002.
[275] H. Li, "Special Section Introduction: Artificial Intelligence and Advertising," J. Advert., vol. 48, no. 4, pp. 333­337, 2019.
[276] W. Li, X. Wang, R. Zhang, Y. Cui, J. Mao, and R. Jin, "Exploitation and Exploration in a Performance based Contextual Advertising System," in 16th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, 2010, pp. 27­36.
[277] J. Kietzmann, J. Paschen, and E. Treen, "Artificial Intelligence in Advertising: How Marketers can Leverage Artificial Intelligence along the Consumer Journey," J. Advert. Res., vol. 58, no. 3, pp. 263­267, 2018.
[278] Y. R. Cha, "Artificial Intelligence Strategy for Advertising and Media Industries: Focused on In-depth Interviews," The Journal of the Korea Contents Association, vol. 18, no. 9, pp. 102­115, 2018.
[279] D. S. Evans, "The Online Advertising Industry: Economics, Evolution, and Privacy," J. Econ. Persp., vol. 23, no. 3, pp. 37­60, 2009.
[280] S. Deng, C.-W. Tan, W. Wang, and Y. Pan, "Smart Generation System of Personalized Advertising copy and its Application to Advertising Practice and Research," J. Advert., vol. 48, no. 4, pp. 356­365, 2019.
[281] H. Lee and C.-H. Cho, "Digital Advertising: Present and Future Prospects," International Journal of Advertising, vol. 39, no. 3, pp. 332­341, 2020.
[282] H. Li, K. Ota, and M. Dong, "Learning IoT in Edge: Deep Learning for the Internet of Things with Edge Computing," IEEE Netw., vol. 32, no. 1, pp. 96­101, 2018.
[283] Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, A. Shabtai, D. Breitenbacher, and Y. Elovici, "N-baiot? Network-based detection of IoT botnet attacks using Deep Autoencoders," IEEE Perv. Comput., vol. 17, no. 3, pp. 12­22, 2018.
[284] M. Roopaei, P. Rad, and M. Jamshidi, "Deep Learning Control for Complex and Large Scale Cloud Systems," Intell. Autom. & Soft Comput., vol. 23, no. 3, pp. 389­391, 2017.
[285] S. Zhang, S. Zhang, B. Wang, and T. G. Habetler, "Machine Learning and Deep Learning Algorithms for Bearing Fault Diagnostics?A Comprehensive Review," arXiv preprint arXiv:1901.08247, 2019.
[286] T. Rymarczyk, G. Klosowski, E. Kozlowski, and P. Tcho´rzewski, "Comparison of Selected Machine Learning Algorithms for Industrial Electrical Tomography," Sensors, vol. 19, no. 7, p. 1521, 2019.
[287] Y. Wang, Z. Pan, X. Yuan, C. Yang, and W. Gui, "A novel deep learning based fault diagnosis approach for chemical process with extended deep belief network," ISA Transactions, vol. 96, pp. 457­467, 2020.
[288] J. Deutsch and D. He, "Using Deep learning-based approach to predict remaining useful life of rotating components," IEEE Trans. Syst. Man Cybern. Syst., vol. 48, no. 1, pp. 11­20, 2017.
[289] F. Jiang, Y. Fu, B. B. Gupta, F. Lou, S. Rho, F. Meng, and Z. Tian, "Deep learning based multi-channel intelligent attack detection for data security," IEEE Trans. Sust. Comput., 2018.
[290] S. Zhang, L. Yao, A. Sun, and Y. Tay, "Deep learning based recommender system: A survey and new perspectives," ACM Comput. Surv. (CSUR), vol. 52, no. 1, pp. 1­38, 2019.
[291] Z. Bi and L. Wang, "Advances in 3D Data acquisition and processing for Industrial applications," Robotics and Computer-Integrated Manuf., vol. 26, no. 5, pp. 403­413, 2010.
[292] L. Zhou, D. Wu, J. Chen, and Z. Dong, "When computation hugs intelligence: Content-aware data processing for industrial IoT," IEEE Internet Things J., vol. 5, no. 3, pp. 1657­1666, 2017.
[293] N. Mehdiyev, J. Lahann, A. Emrich, D. Enke, P. Fettke, and P. Loos, "Time series classification using Deep Learning for process planning: A case from the process industry," Procedia Comp. Sci., vol. 114, pp. 242­249, 2017.
[294] Y. J. Heo, S. J. Kim, D. Kim, K. Lee, and W. K. Chung, "Superhigh-purity seed sorter using low-latency image-recognition based on deep learning," IEEE Robot. Autom. Lett., vol. 3, no. 4, pp. 3035­3042, 2018.
[295] H. Yang, A. Alphones, W.-D. Zhong, C. Chen, and X. Xie, "Learningbased Energy-Efficient Resource Management by Heterogeneous

21

RF/VLC for Ultra-Reliable Low-latency Industrial IoT Networks," IEEE Trans. Ind. Informat., vol. 16, no. 8, pp. 5565­5576, 2019. [296] X. Zuo, Y. Cui, M. Wang, T. Xiao, and X. Wang, "Low-latency networking: Architecture, techniques, and opportunities," IEEE Internet Comput., vol. 22, no. 5, pp. 56­63, 2018. [297] M. Bennis, M. Debbah, and H. V. Poor, "Ultrareliable and Low-latency Wireless Communication: Tail, risk, and scale," Proceedings of the IEEE, vol. 106, no. 10, pp. 1834­1853, 2018. [298] Y. Ai, M. Peng, and K. Zhang, "Edge Computing Technologies for Internet of Things: A Primer," Digital Commun. Netw., vol. 4, no. 2, pp. 77­86, 2018. [299] M. S. Hossain and G. Muhammad, "Cloud-Assisted Industrial Internet of Things (IIoT)?Enabled Framework for Health Monitoring," Comp. Netw., vol. 101, pp. 192­202, 2016. [300] W. G. Hatcher and W. Yu, "A survey of Deep Learning: Platforms, applications and emerging research trends," IEEE Access, vol. 6, pp. 24 411­24 432, 2018. [301] J. Chen, K. Li, Q. Deng, K. Li, and S. Y. Philip, "Distributed Deep Learning model for Intelligent Video Surveillance Systems with Edge Computing," IEEE Trans. Ind. Informat., 2019. [302] X.-W. Chen and X. Lin, "Big Data Deep Learning: Challenges and Perspectives," IEEE Access, vol. 2, pp. 514­525, 2014. [303] J. Pan and J. McElhannon, "Future Edge Cloud and Edge Computing for Internet of Things applications," IEEE Internet Things J., vol. 5, no. 1, pp. 439­449, 2017. [304] P. Corcoran and S. K. Datta, "Mobile-Edge Computing and the Internet of Things for Consumers: Extending Cloud computing and services to the Edge of the network," IEEE Consum. Electr. Mag., vol. 5, no. 4, pp. 73­74, 2016. [305] Z. Li, J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, "Consortium Blockchain for Secure Energy trading in Industrial Internet of Things," IEEE Trans. Ind. Informat., vol. 14, no. 8, pp. 3690­3700, 2017. [306] V. C. Gungor and G. P. Hancke, "Industrial Wireless Sensor Networks: Challenges, Design principles, and Technical Approaches," IEEE Trans. Ind. Electr., vol. 56, no. 10, pp. 4258­4265, 2009. [307] L. Wang and R. X. Gao, Condition Monitoring and Control for Intelligent Manufacturing. Springer Science & Business Media, 2006. [308] G. H. Popescu et al., "The Economic Value of the Industrial Internet of Things," J. Self-Gover. Manage. Econ., vol. 3, no. 2, pp. 86­91, 2015. [309] C. Zander, J. Boustedt, A. Eckerdal, R. McCartney, K. Sanders, J. E. Mostro¨m, and L. Thomas, "Self-Directed Learning: Stories from Industry," in 12th Koli Calling Int. Conf. on Comput. Educ. Res., 2012, pp. 111­117. [310] J. Willems, E. Hostens, B. Depraetere, A. Steinhauser, and J. Swevers, "Learning control in practice: Novel paradigms for Industrial applications," in IEEE Conf. on Contr. Techn. and Appl. (CCTA). IEEE, 2018, pp. 1270­1276. [311] F. Moreno, J. Alarco´n, R. Salvador, and T. Riesgo, "Reconfigurable Hardware Architecture of a Shape Recognition System based on specialized Tiny Neural Networks with Online Training," IEEE Trans. Ind. Electr., vol. 56, no. 8, pp. 3253­3263, 2009. [312] Y. Lu, "Artificial Intelligence: A Survey on Evolution, Models, Appli-

cations and Future Trends," J. Manage. Analy., vol. 6, no. 1, pp. 1­29, 2019.
[313] A. Luckow, M. Cook, N. Ashcraft, E. Weill, E. Djerekarov, and B. Vorster, "Deep Learning in the Automotive Industry: Applications and Tools," in IEEE Int. Conf. on Big Data (Big Data). IEEE, 2016, pp. 3759­3768.
[314] E. Oyekanlu, "Distributed Osmotic Computing approach to Implementation of explainable predictive Deep Learning at Industrial IoT network edges with real-time adaptive wavelet graphs," in IEEE First Int. Conf. on Artificial Intelligence and Knowledge Engineering (AIKE). IEEE, 2018, pp. 179­188.
[315] A° . Kastensson, "Developing Lightweight Concepts in the Automotive Industry: Taking on the environmental challenge with the sa°na¨tt project," J. Cleaner Production, vol. 66, pp. 337­346, 2014.
[316] B. Cantor, P. Grant, and C. Johnston, Automotive engineering: lightweight, functional, and novel materials. CRC press, 2008.
[317] D.-p. Tan, S.-t. Chen, G.-j. Bao, and L.-b. Zhang, "An embedded lightweight GUI component library and ergonomics optimization method for industry process monitoring," Front. Inform. Techn. Electr. Eng., vol. 19, no. 5, pp. 604­625, 2018.
[318] F. Lehfuss, G. Lauss, P. Kotsampopoulos, N. Hatziargyriou, P. Crolla, and A. Roscoe, "Comparison of multiple power amplification types for power hardware-in-the-loop applications," in Proc. of Complexity in Engg. (COMPENG). IEEE, 2012, pp. 1­6.
[319] H. K. Fathy, Z. S. Filipi, J. Hagena, and J. L. Stein, "Review of Hardware-in-the-Loop simulation and its prospects in the automotive area," in Modeling and Simulation for Military Applications, vol. 6228. International Society for Optics and Photonics, 2006, p. 62280E.
[320] C. D. Tran, R. Ibrahim, V. S. Asirvadam, N. Saad, and H. S. Miya, "Internal model control for industrial wireless plant using WirelessHART hardware-in-the-loop simulator," ISA Transactions, vol. 75, pp. 236­ 246, 2018.
[321] F. Alvarez-Gonzalez, A. Griffo, B. Sen, and J. Wang, "Real-time hardware-in-the-loop simulation of permanent-magnet synchronous motor drives under stator faults," IEEE Trans. Ind. Electr., vol. 64, no. 9, pp. 6960­6969, 2017.
[322] Y. Huo and G. Gruosso, "Hardware-in-the-loop framework for validation of ancillary service in microgrids: Feasibility, problems and improvement," IEEE Access, vol. 7, pp. 58 104­58 112, 2019.
[323] F. Huerta, J. K. Gruber, M. Prodanovic, and P. Matatagui, "Powerhardware-in-the-loop test beds: evaluation tools for grid integration of distributed energy resources," IEEE Ind. Appl. Mag., vol. 22, no. 2, pp. 18­26, 2016.
[324] X. H. Mai, S.-K. Kwak, J.-H. Jung, and K. A. Kim, "Comprehensive electric-thermal photovoltaic modeling for power-hardware-in-the-loop simulation (phils) applications," IEEE Trans. Ind. Electr., vol. 64, no. 8, pp. 6255­6264, 2017.
[325] J. Lima, P. Costa, T. Brito, and L. Piardi, "Hardware-in-the-loop simulation approach for the Robot at Factory Lite competition proposal," in Int. Conf. on Autonomous Robot Systems and Competitions (ICARSC).
IEEE, 2019, pp. 1­6.

