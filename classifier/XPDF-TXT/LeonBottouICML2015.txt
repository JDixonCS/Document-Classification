Two  big  challenges   in  machine  learning

LÉ ON  B OT TOU FAC E B OOK  AI   R E SE AR C H

IC M L  2015   -- LILLE

Machine  Learning  in  2015

§An  established  academic  discipline
o that  attracts  bright  students.
§Pervasive  applications
o all  over  the  Internet o and  sometimes i  n  the  real  world.
§Massive  investments. §Massive  returns.

more  logos   in  your   ICML b  ooklet...

Machine  Learning  in  2015

§An  established  academic  discipline
o that  attracts  bright  students.
§Pervasive  applications
o all  over  the  Internet o and  sometimes i  n  the  real  world.
§Massive  investments. §Massive  returns.

more  logos   in  your   ICML b  ooklet...

Machine  Learning  in  2015

§An  established  academic  discipline
o that  attracts  bright  students.
§Pervasive  applications
o all  over  the  Internet o and  sometimes i  n  the  real  world.
§Massive  investments. §Massive  returns.

more  logos   in  your   ICML b  ooklet...

Challenges  of  a  new  kind
1. Machine  learning  disrupts  software  engineering.
àChallenging  our  impact  on  real  world  applications.
2. Our  experimental p  aradigm  is  reaching  its  limits.
àChallenging  the  speed  of  our  scientific p  rogress.
3. Elements  of  a  solution

Machine  Learning   disrupts  software  
engineering

Engineering  complex  artifacts
Counting  parts  down  to  the  smallest  screw
§ Automobile:  ~  30,000  parts     § Airplane:   ~  3,000,000  parts
Specifications  and  replication
§The  engineer  does  not d  esign  the  alloy a  nd  the  threads  of  each  screw.   Standard  screws  come  with k  nown s  pecifications  (size,  strength,  weight, ...  ) §Many p  arts  and  many  assemblies  are  identical.  

Abstraction  in  engineering
Thinking  with  the  specifications  instead  of  the  details.
§ part  specifications i  nstead  of  part  details. § assembly  specifications i  nstead  of  assembly  details.
Abstractions  leak!
Sometimes  one  needs  to l  ook m  ore  closely. § Example:  engine c  ooling a  ssembly  can  have c  omplicated h  eat  inertia. § Example:  global r  esource  allocation (  cost,  weight, e  tc.) Abstraction l  eaks  limits t  he  complexity o  f  what  we  can  build.

Abstraction  in  mathematics  and  logic
Pure  abstraction  belongs  to  mathematics  and  logic
· When  we  use  a  theorem,  we  do  not n  eed  to  revisit i  ts  proof. · Mathematical  abstractions  do  not l  eak.
Computer  programs  are  similar  to  mathematical  proofs (  in  theory)
· Design  with  contracts ­ knowing t  he  specification o  f  a  module i  s  enough. · In  practice,  there  are  abstraction l  eaks  (  but  less.  )

Computer  programs

The  closer  to  logic,  the  more  complex  the  artifacts

§ Automobile:   § Airplane:   § Processor:  

~  30,000  parts     ~  3,000,000  parts ~  3,000,000,000  transistors

(note  :  counts  include m  any  identical p  arts  and  assemblies.)

§ MS  Office:   § Facebook: § Debian :  

~  40,000,000  LOCS ~  60,000,000  LOCS ~  400,000,000  LOCS

(note:  different  metric:  lines o  f  codes  are  rarely  identical.)

Programming  versus  learning
Two  conceptions o  f  computing
Frank   Rosenblatt
Digital  computers (  that  one  programs) a  re e  verywhere. Programming m  akes  it  easy  to  leverage  the  work  of  others.

Programming  versus  learning
Programming  has  real  advantages
Minsky  and  Papert,  Perceptrons,   1968.
Remark
This  book  is  not  just  about  Rosenblatt's p  erceptron!   What  Minsky  and P  apert call  an  "order--k p  erceptron" c  overs   most  machine l  earning  models,  including t  he  convolutional   neural n  etworks t  hat  are  changing  computer v  ision.

Connectedness
Is  a  shape  made  of  a  single  connected c  omponent?
M&P  prove t  hat  a small--order  perceptron c  annot s  ay, but  a  simple  algorithm  can.
Such  an  algorithm  fulfils  a  clear  contract:  verifying  connectedness.

Is  connectedness   easy  for  us?

What  is  easy  for  us?

This  shape   represents  a  
mouse

This  shape   represents  a   piece  of  cheese

Why  is  learning  gaining  momentum?

§ Since  "connectedness"   has  a  clear  mathematical  specification, we  can  envision p  rovable a  lgorithms.
§ Since  "mousiness"  and  "cheesiness"   do n  ot  have  such  a  specification, we  cannot  envision p  rovable a  lgorithms.
We  must  rely  on -- heuristic s  pecifications -- or  learning  techniques.

"Connectedness?" "Mousiness?" "Cheesiness?"

Why  is  learning  gaining  momentum?
§ We  must  rely  on -- heuristic s  pecifications    (e.g.  rules) -- or  learning  techniques.
Big  data  and  big  computing  power
When  the  volume o  f  data  increases -- defining h  euristic s  pecifications b  ecomes  harder. -- training l  earning  systems  becomes  more  effective.

Programming  versus  learning
Two  conceptions o  f  computing
Frank   Rosenblatt

Integrating  machine  learning   in  large  software  systems
Machine  learning  systems  must*  work  with  digital  software because  digital  computers  are  everywhere. § Use  trained  models  as  software  modules. § Use  learning  algorithms  as  software  modules.
*  at l  east u  ntil w  e  solve  AI...

Trained  models  as  software  modules
"DeepVisotronTM,,®  detects   1000  object  categories  with  
less  than  1%  errors."
What  is  the  nature  of  the  contract?
§ This  does  not  mean  that  one r  olls  a  dice  for  each  picture. § This  statement  refers  to  a  specific  testing s  et.
The  error  guarantee  is  lost i  f  the  image  distribution c  hanges.

Weak  contracts
§ A  smart  programmer  makes  an   inventive u  se  of  a  sorting  routine.
§ The  sorting  routine f  ulfils the   contract  by  sorting  the  data   (however  strange.)
§ The  code  of  the  smart   programmer  does  what  was   intended.

§ A  smart  programmer  makes  an   inventive u  se  of  a  trained o  bject   recognizer.
§ The  object  recognizer  receives  data   that  does  not  resemble  the  testing   data  and  outputs n  onsense.
§ The  code  of  the  smart  programmer   does  not  work.

Weak  contracts
§ A  smart  programmer  makes  an   inventive u  se  of  a  sorting  routine.
§ The  sorting  routine f  ulfils the   contract  by  sorting  the  data   (however  strange.)
§ The  code  of  the  smart   programmer  does  what  was   intended.

§ A  smart  programmer  makes  an   inventive u  se  of  a  trained o  bject   recognizer.
§ The  object  recognizer  receives  data   that  does  not  resemble  the  testing   data  and  outputs n  onsense.
§ The  code  of  the  smart  programmer   does  not  work.
Collecting n  ew  data  and   retraining m  ay  help ...    or  may  not!  

Learning  algorithms  as  software  modules

Example   1
Click  curves
Many w  eb  sites  offer l  ists  of  items (  search r  esults, r  ecommendations, a  ds ...  ) and s  elect  them  by  modeling c  lick  probabilities.

A  common  click  model
  , ,  =     ×  (, )

Position e  ffect "click  curve"

Item  effect "clickability"

Why  separating  position  effect  and  item  effect?
§ Click  probabilities o  f  this f  orm  allow a    greedy  placement a  lgorithm:
1. Sort  items  by  clickability  (, ).
2. Allocate  them  greedily  to  the  best  positions.

A  common  click  model
Why  separating  position  effect  and  item  effect?
§ Click  probabilities o  f  this f  orm  work  well i  n  auction t  heory  results. § There  are  easy  ways  to  estimate  () and  (, ).
How  incorrect  is  this  model?
§ All  ML  models a  re  incorrect. § Model  misspecification s  hould o  nly d  egrade t  he  performance g  racefully. § How  bad  can  things  go?

How  bad  things  can  go?

§Assume  there  are  only t  wo  contexts C  1  and  C2  and  two  positions P  1,P2
§Assume  the  true  click  probability i  s   P  , ,  =  ,    ×  (, )



P1

P2

C1

0.8

0.2

C2

0.6

0.4



R1

R2

R3

R4

C1

0.12 0.10

0

0

C2

0

0

0.12 0.10

§Our  model  estimates  some  intermediate c  lick  curve   

How  bad  can  things  go  in  context  C1  ?
True  position e  ffect  steeper  than  estimated.
§ P1 <  C1, P1     overestimate c  lickability  of  items  shown i  n  P1 § P2 >  C1, P2     underestimate c  lickability o  f  items  shown i  n  P2
Combined w  ith  the  greedy  placement  algorithm.
§After  retraining,  whatever w  e  placed  in  position  P1  looks  better  than  it  really  is. Therefore w  e k  eep  placing  it  in  position P  1. §After  retraining,  whatever w  e  placed  in  position  P2  looks  worse t  han  it  really  is. Therefore w  e k  eep  placing  it  in  position P  2  (or  stop s  howing  it.)

How  bad  can  things  go  in  context  C1  ?
True  position e  ffect  steeper  than  estimated.
§ P1 <  C1, P1     overestimate c  lickability  of  items  shown i  n  P1 § P2 >  C1, P2     underestimate c  lickability o  f  items  shown i  n  P2
Combined w  ith  the  greedy  placement  algorithm.
§After  retraining,  whatever w  e  placed  in  position  P1  looks  better  than  it  really  is. Therefore w  e k  eep  placing  it  in  position P  1. §After  retraining,  whatever w  e  placed  in  position  P2  looks  worse t  han  it  really  is. Therefore w  e k  eep  placing  it  in  position P  2  (or  stop s  howing  it.)

How  bad  can  things  go  in  context  C2  ?
True  position e  ffect  less  steep  than  estimated.
§ P1 >  C1, P1     underestimate c  lickability o  f  items  shown i  n  P1 § P2 <  C1, P2     overestimate c  lickability  of  items  shown i  n  P2
Combined w  ith  the  greedy  placement  algorithm.
§After  retraining,  whatever w  e  placed  in  position  P1  looks  worse t  han  it  really  is. Therefore w  e m  ight  move  it  down t  o  position  P2. §After  retraining,  whatever w  e  placed  in  position  P2  looks  better  than  it  really  is. Therefore w  e m  ight  move  it  up  position P  1.

How  bad  can  things  go  in  context  C2  ?
True  position e  ffect  less  steep  than  estimated.
§ P1 >  C1, P1     underestimate c  lickability o  f  items  shown i  n  P1 § P2 <  C1, P2     overestimate c  lickability  of  items  shown i  n  P2
Combined w  ith  the  greedy  placement  algorithm.
§After  retraining,  whatever w  e  placed  in  position  P1  looks  worse t  han  it  really  is. Therefore w  e m  ight  move  it  down t  o  position  P2. §After  retraining,  whatever w  e  placed  in  position  P2  looks  better  than  it  really  is. Therefore w  e m  ight  move  it  up  position P  1.

Feedback  loops  in  machine  learning
Norbert  Wiener,   Cybernetics,  1948
§"Information (  signal)  feedback  loops  are  everywhere." "They  are  central  to a  daptation  and  learning..." §See  (Bottou et  al.,  JMLR  2013)  for  a  possible t  reatment  of  causal  loops.

Example   2
Team  work

Red  Team
Owns  the  code  that s  elects content t  o r  ecommend.

Blue  Team
Owns  the  code  that s  elects  fonts a  nd   colors f  or  all p  age  components.

Red  team
The  red  team  knows  the  bandit  literature
§There  are  lots  of  potential r  ecommendations t  o  select  from.
§One  can  only m  odel  the  click p  robabilities o  f  the  recommendations   that  have b  een  shown  often  enough i  n e  ach  context.
§Therefore t  he  red  team  code  performs  --greedy  exploration,   showing  a  small  proportion o  f  random  recommendations.
§Although e  xploration h  as  a  cost,  such  the  system  cannot   discover  the  most  relevant r  ecommendations w  ithout i  t.

Blue  team
The  blue  team  also  knows  machine  learning.
§ The  job  of  the  blue t  eam  is  to  emphasize  things  that  the  user  will l  ike. § The  blue t  eam  code  runs  a  click p  robability m  odel t  o  spot  what  users  like. § The  click  probability m  odel e  asily  discovers t  hat  some  of  the  
recommendations g  enerated b  y  the  red  team  are  not v  ery  good. § Therefore  these  recommendations w  ill b  e  shown  with a    smaller  font.

Blue  team
The  blue  team  also  knows  machine  learning.
§ The  job  of  the  blue t  eam  is  to  emphasize  things  that  the  user  will l  ike. § The  blue t  eam  code  runs  a  click p  robability m  odel t  o  spot  what  users  like. § The  click  probability m  odel e  asily  discovers t  hat  some  of  the  
recommendations g  enerated b  y  the  red  team  are  not v  ery  good. § Therefore  these  recommendations w  ill b  e  shown  with a    smaller  font.

Red  team
The  red  team  is  very  content!
§Analysis  of  the  exploration t  raffic  shows  that  there  isn't  much t  o  improve. à they  can  safely  reduce  the  exploration l  evel!
§Whenever  they  try  new  features  in t  he  click  model,   randomized  testing  shows  a  reduction i  n p  erformance
à it  is  amazing,  but i  t  seems  they  got  their  model r  ight  the  first  time!

Red  team
The  red  team  is  very  content!
§Analysis  of  the  exploration t  raffic  shows  that  there  isn't  much t  o  improve. à they  can  safely  reduce  the  exploration l  evel!
§Whenever  they  try  new  features  in t  he  click  model,   randomized  testing  shows  a  reduction i  n p  erformance
à it  is  amazing,  but i  t  seems  they  got  their  model r  ight  the  first  time!

Paying  attention
"A  manager   of  the  two  teams  should  have  paid  more  attention." "The  software   architect  should  have  paid  more  attention."
Micro--management  does  not w  ork  because  it  does  not  scale...

beyond  two  teams

Conclusion   of  part  1 Machine  learning   in  large  software   systems
§ Use  trained  models  as  software  modules. à problematic  because  trained  models  offer  weak  contracts.
§ Use  learning  algorithms  as  software  modules. à problematic  because  the  output  of  the  learning  algorithm   depends  on  the  training  data  which  itself  depends   on  every  other  module.
Working  around  these  difficulties  could  save  billions...

Our  experimental   paradigm  is reaching  
its  limits

Minsky  and  Papert 1968,  F.A.Q.
Are  we  dealing w  ith   an  exact  science  (like  mathematics)  or  
an  empirical s  cience  (like  physics)?

Essential  epistemology

Deals  with Truth is Examples

Exact   sciences
Axioms  & Theorems
Forever
Mathematics C.S. theory

Experimental sciences
Facts  & Theories

Engineering
Artifacts

Temporary

It  works.

Physics Biology

Lots...

Essential  epistemology ­ Exact  sciences

Deals&with Truth is Examples

Exact& sciences
Axioms&& Theorems
Forever
Mathematics C.S. theory

Experimental sciences
Facts&& Theories

Engineering
Artifacts

Temporary

It&works.

Physics Biology

C.S.

Exact  sciences
§ Deal  with  axioms and t  heorems.  
§ Axioms a  re  neither  true  or  false. Theorems a  re t  rue  once  proven. They  remain t  rue  forever.
§ Examples o Mathematics o Theoretical C  .S.  (e.g.,  algorithms, t  ype  theory,  ...) o Theoretical P  hysics  (e.g.,  string  theory)

Essential  epistemology ­ Experimental  sciences

Deals&with Truth is Examples

Exact& sciences
Axioms&& Theorems
Forever
Mathematics C.S. theory

Experimental sciences
Facts&& Theories

Engineering
Artifacts

Temporary

It&works.

Physics Biology

C.S.

The  word  "true" has  a  different  
meaning.

Experimental s  ciences
§ Deal  with  facts and t  heories.
§ Facts  are  true  when t  hey  can  be  replicated.   Theories a  re  true  when  they  predict  the  facts.   New  facts  can  invalidate t  heories   that  were p  reviously c  onsidered t  rue  (K.  Popper)
§ Examples o Physics,  Biology,... o Social  sciences,  Experimental p  sychology,...  

Essential  epistemology ­ Engineering

Deals&with Truth is Examples

Exact& sciences
Axioms&& Theorems
Forever
Mathematics C.S. theory

Experimental sciences
Facts&& Theories

Engineering
Artifacts

Temporary

It&works.

Physics Biology

C.S.

Engineering
§ Deals  with a  rtifacts. § A  claim  is  true  when  the  artifact  works,
(the  artifact  fulfils a    contract.)
§ Examples o Mechanical e  ngineering,  ... o Nuclear  engineering, ...  o Computer s  cience.

Machine  learning?

What  is  machine  learning?
§ An  engineering d  iscipline? § An  exact  science? § An  experimental s  cience?

Yes:  applications a  bound. Yes:  statistical/algorithmic l  earning t  heory. Yes:  papers  often r  eport  on  experiments.

This  is  all  good

Machine  learning?

What  is  machine  learning?
§ An  engineering d  iscipline? § An  exact  science? § An  experimental s  cience?

Yes:  applications a  bound. Yes:  statistical/algorithmic l  earning t  heory. Yes:  most  papers  include e  xperiments.

This  is  all  good  ...  as  long  as  we  don't  mix  the  genres. § "My  software   works  really  well,  therefore   my  theory  is  true."
§ "This  is  NP--complete,  therefore   this  experiment  is  wrong."

ML  as  an  experimental  science
§Some  problems  of  interest  do  not  have  a  clear  specification. They  are  not  amenable  to  provable  algorithms.
§Machine  learning  replaces  the  missing  specification  by  lots  of  data. §Important  aspects  of  the  data  cannot  be  described  by  a  compact   mathematical   statement  (otherwise  we  have  a  specification!) §Therefore e  xperimentation  is  necessary!

ML  as  an  experimental  science
Progress  during  the   last  few  decades   has  been  driven b  y
a  single  experimental   paradigm!

ML  as  an  experimental  science

Progress  during  the   last  few  decades   has  been  driven b  y
a  single  experimental   paradigm!

This  is  unusual  for  an   experimental  science!
Physicists,  biologists, e  xperimental   psychologists, .  ..,  must  work  a  lot h  arder   to  design  experiments a  nd  interpret   their  results.  

Where  does  the  data  come  from?

How  to  improve  the  performance  of  a  ML  application?

§ Get  better  algorithm?  

+

§ Get  better  features?

+++

§ Get  better  data?

++++++

Data  collection  is  hard  work
§ The  data  distribution m  ust  match  the  operational c  onditions. § Rely o  n  manual  data  curation to  avoid d  ataset  bias.

The  impact  of  dataset  bias
Training/testing  on  biased  datasets  gives  unrealistic  results.
§E.g.  :  Torralba and  Efros,  Unbiased   look  at  dataset  bias,  CVPR  2011.

Increased  ambitions:  Big  Data
Too  much  data  for  manual  curation
§ Big  data  exists  because  data  collection i  s  automated. § Nobody c  hecks  that  the  data  distribution m  atches  
the  operational c  onditions o  f  the  system.
à All l  arge  scale  datasets  are  biased.
Training/testing  on  a  big  dataset  can  give  unrealistic  results.

Increased  ambitions:  A.I.
Statistical  machine  learning
§Building a    classifier  that  works  well  under a    certain  distribution.
Machine  learning  for  artificial  intelligence
§Building a    classifier  that  recognizes  a  "concept". §Concepts e  xist  independently o  f  the  pattern d  istribution. §Training d  ata  will n  ever  cover  the  whole r  ange  of  possible i  nputs.
In  fact,  a  system  that  recognizes   a  "concept"  fulfils  a  stronger   contract than  a  classifier  that  works  well  under  a  certain  distribution.

Concepts    Statistics
Example:  detection  of  action  "giving  a  phone  call"
(Oquab et  al.,  CVPR  2014)

Concepts    Statistics
Computer  vision  is  not  a  statistical  problem

Car  examples  in  ImageNet

Is  this  less  of  a  car because  the  context  is  wrong?

Concepts    Statistics
Convolutional   networks   can  be   fooled.
(Nguyen  et  al,  CVPR  2015)

Concepts    Statistics

From  a  talk  of  (  Zitnick 14  )

Caption  generation
§ Eight i  ndependent p  apers i  n 2  014. According t  o  the  BLEU  score, some  of  these  systems p  erform   better t  han h  umans...
§ They m  et  in  Berkeley  in  January 2  015.
§ Evaluation i  s v  ery  difficult.
§ Example o  f d  ifficulty :     caption g  eneration v  s r  etrieval

Conclusion  of  part  2 Training/testing   only  goes  so  far...
Training/testing  is  an  unusually  convenient e  xperimental  paradigm... à it  makes  experimentation  easier  than  in  other  sciences à it  has  played  a  role  in  the  fast  progress o  f  ML.
...but  may  not  fulfil  our  increased  ambition  (big  data,  AI.) à the  end  of  an  anomaly?
Working  around  this  could  save  decades.

Elements   of  a  solution

1.  Process  challenges
Challenges  of  a  new  kind
§We  are  used  to  face  technical  challenges. §These  are  "process  challenges."

1.  Process  challenges
Engineering  process
§There  is  a  rich  literature  about  the  software  engineering  process. §What  should  be  the  machine  learning  engineering  process?

1.  Process  challenges
Scientific p  rocess
§We  cannot  solely rely  on  training/testing  experiments. §We  can  understand m  ore t  hings  with  ad  hoc  experiments.
Example i  n  question a  nswering :     the  "BABI"  tasks    (Bordes et  al.,  2015) o questions t  hat  require c  ombining o  ne/two/more f  actoids. o questions t  hat  require s  patial/temporal r  easoning. o etc.
§ What  are  the  best  practices  in  other  experimental s  ciences?

1.  Process  challenges
A  constructive  proposition
§ Machine  learning p  apers  rarely  show  the  limits o  f  their  approach. -- For  fear  that  reviewers  will u  se  them  against  their  work.
§ Reviewers  should i  nstead d  emand  that  authors  discuss  these  limits. -- Additional c  redits  if  they  illustrate t  hese  limits  with e  xperiments. -- This w  ould m  ake  the  papers  more  informative... -- and  would t  herefore f  acilitate s  cientific p  rogress.

2.  ML  with  stronger  contracts
How  to  better  resist  distribution  shifts?
§ Optimize  measure  of  coverage instead o  f  average  accuracy.
-- Selective c  lassification  (El Y  aniv's,  ...) -- KWIK  (Li  &  Littman) -- Conformal l  earning  (Vovk, ...  ) §Very  interesting p  roperties w  hen  the  data  is  Zipf distributed...

2.  ML  with  stronger  contracts
Zipf distributed  patterns
way  enough d  ata  to  train not  enough d  ata  to  train
Queries  sorted  in f  requency  order

2.  ML  with  stronger  contracts
Doubling  the  size  of  a  Zipf distributed  dataset.
Diminishing r  eturns for  average  accuracy   improvements.

2x

No  diminishing   returns

on  number o  f  

queries  for  which  we  

can  learn  correct  

answers.

3  How  to  package  the  work  of  others
§Digital  computers  :  "software"
§Learning  machines :    
 Trained  module  as  a  software  component? Trained  components o  nly o  ffer  "weak  contracts".
 Training  software? If  you  can  get  the  training  data  and  replicate t  he  rig. Recent e  xample  :  AlexNet.
 Task  specific  trained  features Nearly  as  good.

Example:  face  recognition
Interesting  task:    "Recognizing  the  faces  of  106 persons."
§How  many  labeled i  mages  per  person c  an  we  obtain?
Auxiliary  task:    "Do  these  faces  belong  to  the  same  person?"
§Two  faces  in t  he  same  picture u  sually  are  different  persons. §Two  faces  in s  uccessive  frames  are  often t  he  same  person.
(Matt  Miller,   NEC,  2006)

Example:  NLP  tagging
(Collobert,   Weston,  et  al.,  2008--2011)

Example:  object  recognition
Dogs  in I  mageNet (~106 dogs)
Dogs  in P  ascal  VOC (only ~  104 imgages)

Example:  object  recognition
Several  CVPR  2014  papers  ­ figure   from   (Oquab et  al.,  2014)

Conclusion

Two  process  challenges
§ Machine  learning  disrupts  software  engineering.
à Challenging  our  impact  on  real  world  applications.
§ Our  experimental p  aradigm  is  reaching  its  limits.
à Challenging  the  speed  of  our  scientific  progress.

