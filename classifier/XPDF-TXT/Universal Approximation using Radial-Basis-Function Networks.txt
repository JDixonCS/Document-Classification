Communicatedby Halbert White
Universal Approximation using Radial-Basis-Function Networks
J. Park
I. W. Sandberg Departmenot t'Electricaal nd ComputerEngineering, Uniaersityof Texaast Austin,Austin,Texa7sg712IISA

There have been several recent studies concerning feedforward net-

fTinoiltker

and the problem of approximating arbitra[, functionals of a number of real variables. some of tf,ese studies deal with cases

in which the hidden-layer nonlinearity is not a sigmoid. This was

motivated by successful applications of feeclforwairt networks with

nonsigmoidal hidden-layer units.

This paper reports on a related study of radial_basis_function(RBF)

networks,-and it is proved that RBF networks having one hidden rayer

are capable of universal approximation. Here the e-mphasisis on the

"o1f t!R_BoFI

typical RBF networks, and the results show t networks with the same smoothing factor in

hit ea

a ch

certain kerner

crass node

is broad enough for universal approximation.

1 Introduction

There have been several recent studies concerning the capabilities of

multilayered feedforward neural networks. particufirly pertinent to this

Paper are results that show that certain classes of neural networks are

capable oj pr_oviding arbitrarily good approximations to prescribed func-

tionals of a finite number of reil variibles. From the theoretical point

of view, these studies are important, because they address the question

of whether a satisfactory solution_is yierded by sorne member of'a given

class of networks. More specifically, iuppose we have a problem that we

want to.solve using a certain type of neural network. suppose also that

there exists a decision function network plays a central role in

,f : the

sSo"lu-tioSn"'ofwthhoesperoimbpielemm. eInmtaaetioinne

as a that

we have a family G of functions mapping n' to n- characteriied by a

certain strucfure and having certain etem".,ts (e.g., one might consider a

set of multilayered perceptrons), and that we hJpe to solvE the problem

NeuraCl omputatio3n,246-2Sj(7991) @ 1991MassachusetItnsstituteof Technology

Radial-Basis-FunctionNetworks

ata

by implementing some satisfactorymember of G. The first question we need to consider might be: Is this family G broad enough to contain ./ or a good approximation of .l'?Obviously, attempts to solve the problem without considering this question might be very time-consuming and
might even be fruitless. Severalpapers addressthis question for the caseof multilayered per-
ceptron models with sigmoidal nonlinearities, and affirmative answers have been obtained by showing that in a satisfactorysensethe family Ci considered can actually approximate any decision function drawn from a certain large class (Cybenko 1989;Hornik et al. 1989).
At the present time, with the advantages and limitations of multilayered perceptron networks more transparent and with results containing comparative studies becoming available (e.g.,Lippman 1989),researchconcerning different types of feedforward networks is very active. Among the various kinds of promising networks are the so-calledradialbasis-function (RBF) networks (Lippman 1989). The block diagram of a version of an RBF classifierwith one hidden layer is shown in Figure 1. Each unit in the hidden layer of this RBF network has its own centroid, and for eachinput 1 : (:r'r.t:2.. . . ..r;".)i,t computes the distancebetween rtr and its centroid. Its output (the output signal at one of the kernel nodes) is somenonlinear function of that distance.Thus, eachkernel node in the RBF network computes an output that depends on a radially symmetric function, and usually the strongestoutput is obtained when the input is
near the centroid of the node. Assuming that thereare r input nodesand nr output nodes,the overall

Figure 1: A radial-basis-function network

248

J. Park and I. W. Sandberg

responsefunction without considering nonlinearity in an output node has the following form:

(1.1)

where 11 e rV the set of natural numbers is the number of kernel nodes in the hidden layer, I,t', fR"'is the vector of weights from the ith kernel node to the output nodes, ,r' is an input vector (an element of llt'), l( is a radially symmetric kernel function of a unit in the hidden layer, zi dnd a1are ihe centroid and smoothing factor (or width) of the ith kernel node, respectivelya, nd 17:10.x) - R is a function called the activation function, which characterizesthe kernel shape.
A gaussian function is often used as an activation function, and the smoothing factors of kernel nodes may be the same or may vary across nodes.
In this paper, RBF networks having the representation 1.1 are studied. Strong results are obtained to the effect that, under certain mild conditions on tl'rekernel function li' (or the activation function (), RBF networks representedby 1.1 with the sameo; in each kernel node have the capability of universal approximation. Cybenko (1989)also considers feedforward networks with a single hidden laver of kernel functions. H o w e v e r,o n l y L l a p p ro x i mati oni s 6nsi dered i n the correspondi ngparr of Cybenko (1989),and only the case in which the smoothing factors can vary acrossnodes is addressed. A detailed comparison is givcn in S e c t i o n3 .
This paper is organized as follows: In Section2 our main results are presented,and in Section3 a discussionof our results is given.

2 Main Results
In this section, we consider the approximation of a function by some element of a specific family of RBF networks.
Throughout the paper, we use the following notation and definitions, in which "A/,!t and I?' denote the set of natural numbers, the set of real numbers,and the set of real r'-vectorsr,espectively.Let Tl'(R'), /.-(!P'), C(Jt'), and C, (|)t'), respectively,denote the usual spacesof $l-valued maps I defined on S' such that ./ is 1.ithpower integrable, essentially bounded, continuous, and continuous with compact support. The usual Lp and 1-- norms are denoted by ]1 ]1,and ll . ]l-, respectively.The integral of J'e Ll()R")overa Lebesguemeasurableset I in It' is written as !.a.fQ:)dr or, if .f is a function of several variables and, say, .l(u..) e It(n') we write l^J@".r:)d.rt;o denotethe integral of .fQ..) over l. The convolution operation is denoted by " *:'and the characteristicfunction of a LebesguemeasurablesubsetI of )t' is written as 1.1.

Radial-Basis-FunctionNetworks

249

The family of RBF networks considered here consists of functions r7: lt' - It representedby

(2.1)

w h e re -1 1e .\' r,o > 0 , r/,; !1,and z;  l t, for I :7.....,.| 1. W e cal l thi s family 56.
Note that 2.1is the sameas 1.1,with the exceptionthat the smoothing factors in all kernel nodes are same,and the output spaceis E instead of R"'. It will becomeclear that the extensionof our results to multidimensional output spacesis trivial, and so we consider only a one-dimensional output space.
We will use the following result, which is a slight modification of a theorem in (Bochner and Chandrasekharan 1949,p, 707).

Lemma1,. Let .f  r1'()R'),p  11:.r), grableftmction such that .l'* ct(r)dt - 1 (l l e ' )o (,rl e )fo r r > 0 . Thenl l ,p,* l - .f

and let o I
. Define6r,: 1,,-0 ase*

l)t' !?' 0.

-

W be nn inte'R by o.(.r') :

Proof. Note that o.  I1(n'). By a direct extension from !? to l)?,of a standard theorem in analysis(Bochnerand Chandrasekharan7949, p. 99), one has e,* .f  Lp(n'), which is used below.
By a change of variable,

(r2*. ./)(rr): .1.,.tt^ - ti)ct,(t:)rtt:I:,o ,fkt et:)c,t(ti)rtt Thus,

I (o.*./)(o)- l(,i)

l. l/(ri - er)-.l(o)lcr(.r:)dI r

With ,t definedby 1 1, t 7',j - 1,

11,,,*J-.fll,,

lr(rr)l- ) ll,,- ,,) .l'(nI)

sup
t..t,tti.t,,=tJt

1..

(

)

(

.

t)
'J

l P[

. J(.,, r.r) - ./(o) rlod,t:

/,(,r)

./ l?'
by Fubini's theorem and Holder's inequality.

J. Park and I. W. Sandberg

Since ll f (. - et:) - /O ]"< 2ll f llo and translation is continuous in ,r($?') (seeBochnerand Chandrasekharan1949,p.98, and considerits direct extension to IIl') we have

ll O.x/-./

n+0

as

e -0

by Lebesgue'sdominated convergencetheorem. This proves,the lemma. Our Theorem 1 (below) establishesthat, under certain mild conditions
on the kernel function K, RBF networks representedby 2.1' are capable of approximating arbitrarily well any function ln lp(S').

Tishceoonretimnuo1u,,sLaelmt Kos:te$a?e' -rywYhle.breeaanndi.n1t,epKg,r(ar)bdlxebolu0n' deTdfhuenncttihoenfsaumcihlyth5a6t

K is

densein r'(n") for eueryp e [1,oo).

Proof. Let p  11,

e lr($t'), and e > 0.

Since C.(U?') is-),d.e/ nse ln trp($t") (Rudin 1986' p.69), there exists an

.1.e C"(!}t'-)such that ll f.- f llr,< r13. We will assumebelow that /" is

nonzero. Notice that this involves no loss of generality.

Le Then

t r!: $?" Jt be qj satisf-ies the

defined by conditions

(tQ): on O

in

(

1 / l u r . r . r . to ) ' Lemma 1.

K(."), for .r  D'. Thus, by defining

do Th

: ft' eref

o-r e ,tWh earse ii ns

Lemma 1, we obtain a positive o such that

ll

6"', d" *

f,,f .-

f. llr- 0 as o f"llr<'13.

*

0.

Since ./" has compact support, there exists a positive 7 such that

supp./" c [-",?]'. Note that /'(rr -')/"O is Riemann integrableon

l-T,Tl',
l ld " l l -

becauseit
. il/" ll*

is

continuous

almost

everywhere

and

is

bounded

by

Defineu,,:$l'-nby

r',(r)r -- Lr"h
t I

/tr\'

-

o;)/,(rr;)

[
\/

r- '

l

]

wheretheset{a; e $t' :i:I,2,...,rt'') consistosf all pointsin [-7."]'

of theform l-T Note that u,(a)

+ (2i[ln),..., -T + is a Riemannsum

(2i,Tln)1,'ir,i,z,...,i,:1,2,...,n. for [y'r,ryd"@ - r)f,'(r)dr, and

Ir ,. a.,y

rt, d,(a - t:)f.(r)dr: ln, d" rr e S",r,(t,v)-: (.$o*/.)(o)

(a as

n

r) +

f

: (6" c"o( t.:S) di nrc e@ "*

* /")(") Thus,for f.  Le(!ll'),there

is a positivefi suchthat

I

l1o"x /";1n)lPdo < \rl9\P

Jtt"\t,71 ."11,

Since@"is bounded and $"  -L1(n'). we have d"  Le(ft'). Thus, there exists 12 > 0 such that

t
J R, 11- r ,

rr1.

le,\o)

pao.(

\

e 1fl. l l *

( z r Y) '

Radial-Basis-FunctionNetworks

251

ine

Note that I r',,(o) <ll ./, quality (Rudin 7986,p.

( 62- ),

.

2

7

)

'

(

1 l

n

'

)

l

'

i

-

,

t1nlr rr;) . By Jensen's

[r
I

'

rt'
f

Itr'". L

r-r

r' , , . r , '

]1'
r, r |
I I

Therefore,

1 ,i
-t
tt'-. / I

,"trr -rr t !'

i ' , , ( r ir)' <| . / , . , ( 2 7 )f'l'''=+ i r . . , n ( or r , )'

Definenr-max(Tr.72+'l'). Using lrr;1 1l forall 7 \1-2.....t1,

.|/:R,\J lr .l,l,

4tn(rt

(\i ) It' d(\ < ,[/It,\[ tz tz) r;to(rt) t' dtt

and so

l,t, ,',r',,'I r"'(rr)" rlrr<' ('l9)t'

Also,

(2.2)

/[P \[ I.Il

,"' - . 1. )r'r ) 1"11v {r e l i '

b e c a u s e' l ,t > T r. Si n c erl o * .1,.6 7-r' (rR 'a)nd ?' ,,l -( (2I)'. one has

r? ?) o. ]]- .f, -

I
'/[ l,' Il

t ," + l,)(o) - i',,(o)l" rkr - 0 as rr- :c

by the dominated convergencetheorem. Thus, there is an N e ,V for which

I
, J|

't'r. t'\)1,

t,n ,* .f,)(u) -

1,-u(o)t' rl rt < -(rf 9)t'

Therefore,using 2.2 and 2.3,

/rN rito* .l', ,, I l'N . 1:R,\lL."rl, ,, * ll (irr r:t,'*.1.) ' 1;-'ri,.'r;1,,, I (r2"* f , ) ' 1:it.\l rt,.?,1,t,

252

J. Park and L W Sandberg

From the above, ll t,r - .l' lln< e. Since

i 'v(')- t

()n \-' tri ).1' ,f(+.,)'',

A'

/ _ tr.\

-tt,';h.('-"i)eS,. u,\a/"

Vn ./

with

tt'i - 7. iJ'(,',)(

27. J t'r*,

1

^,*1

the proof is complete.

By K radially symmetric/ we mean that ll t: )lr:ll y llt implies K(.r') : K(y), In this case,the activation function 17:l0.oc) --- llt is obtained by d e fi n i n g g (rl ): K(r). w h e re z i s any el ementof $t' such that l l .l l z:,1. Therefore,in the caseof radial symmetrv 2.1 can be written as

ilI
tt(r.) I,,,, ^(+)

:itt, !t('l' ',ilr)

Note,nu,1",.,", :" l-r",.";1:, or)a'u,,r-J",ry orthekerner

function K in the above theorem. Thus, the theorem is stronger than

necessaryfor RBF networks, and might be useful for other purposes.

Similarly, in the following theorem and corollaries,radial symmetry of

the kernel function K is not assumed, even though we are interested

primarily in radial-basis-functionnetworks.

If we interpret the term "radially symmetric" more generally than

literally, then we may say that K is radially symmetric with respectto

ll . on

l$l ti'f'.lWl " itlhl:

ll y this

llimpliesK(r;) : generalizationin

K('y). whe mind, we

re ll ll ir someno sometimesuse ll

r r

m -

defined z; ll for

the distance between :r:and z1instead of ll :r - z.illz.

A slight modification of Theorem 1 given below addressesthe casein

which the function / we wish to approximate with an RBF network is

not an elementof tp(S''), but an elementof lf..(ffi') for somep e [1.oo). Here the locally-Lp spacelj'".(tr''),7 < p < oo is defined as the set of all measurableI : $l' --- ft such that / . 11,r,r.,r,1,rn($t") for every N e,A/.

One way to define a metric on tl".(W'') is by

r,. tf ,,\ I'loc\J.:Jl-

co

\-r /

L

rt:7

tt

ll ( / _ g ) . 7 7 _ , t . , t 1 ,t n 1 + l l (/ - g) .1;-,r,,21l t,a

The following is direct corollary of Theorem 1.
Corollary 1. Let K : ffi'. -- ffi be an integrable bounded function such that K is continuous almost everywhere and .l*, K(r)dr f 0. Then the family ,Sr<is dense in I{'..($t.) for every p e i1.oo).
Proof. Let p e l1,oo),J e Ll",($t'').and e ) 0. Chooserrt.,V such that D7.,*t2-" < ef2.

Radial-Basis-Function Networks
Since/ .7;*,^1,  Le(W'),by Theorem1 thereis a a  S7rsuchthat ll f '77,.,*1,- o llp<ef2. Thus,
@m
prc,(f,u)

which establishes the corollary.
Theorem 1 and Corollary 1 concern approximation with respect to the Lp metric or a metric induced by trr mehic. We next give a theorem concerning the approximation of continuous functions with respect to a metric induced by the uniform metric.

Theorem 2. Let K : is continuousand !s,

ffi' K(r)-dr

f

r. bda 10.

n integrableboundedfunction such that K Thenthefamily 56 is densein C(Yi,) with

respectto the metric d definedby

-r\trtr \ rn/ t :

S r-' ?r-

' (f - g)'71,,1'' * 1 + ]] (/ - 9) . 11_,,,1l,l _

Proof. /: ft'+

Let S

f by

: ffi' n o r m-

$l aliz

be ing

any continuous function, and K, and defineQo:ft'* S for

e > o >

0. Define 0 as in the

proof of Theorem 1.

Pick a natural number m such that 2-* < 13,and then choose a

positive 7 such thatT > m.

Since / is continuous on the compact set [-rn, tn],, we can obtain a
nonzero continuous function / : S' * W with the property that /(c) : f(r) for r  [-m.ml", and |trl :0 for r  n'\ lT.Tl'. Note that f is bounded and uniformly continuous.

Using /  ,1(m'), pick a positive 76 such that

.f,t, r,.r,,'. alrt I rlr <

(2.4)

Since/ is uniformly continuous,there is a 6 > 0 for which r-a)lz<5 implies

t
I

I \n-,

,

t,

) -

J;. t a ) |l <

(
6lk

il,

(2.5)

Chooseo> 0suchthatll or ]]2<6forallr  l-To,To],L. eta e l-^,^1,. Thenusing2.4 and2.5,

1a",,i11o)-ftorr < s

J[.lr. i r . - o r ) - / r o ) . I o ( r ) d r

f-
l , - w L_a0ta0l - , . 1 f ( a -

or)- f(a)1. I g(r)ldt

+Jlgt--t'\[-." _o,To]". 2 / l l - |g ( r ) ld r < e1 3 ( 2 . 6 )

]. Park and I. W. Sandberg

Notethat(4t"*,f1@:1.ly rrl o"(! - r|.i(r1d:rD. efine,',:,Jt' - Rby

r',,(rr)- I,,.t,'
,l\tt/

-

,

r

;

)

.

l

,
1

r

r

,

)

l2
|-

T

\'
I

w h e re th e s e t { o ;  } t' : l :7.2.....rt' I consi stsof al l poi nts i n I I.T]' o f th e fo rm l -T + (2 i 1 rl l r)..... T + (2_i ,Tl i )1,i r.....i , :\.....rt.
Since the map (.s.r:) + p"(.5-.r')l(L:) is uniformly continuous on
f-rrt.rrtl ' x l T .T )' , th e re i sa6e> 0suchthat,se I rrt.rrr,)r'' .y l -T.Tl ' w i th l l .t -l t 2 ' fu i m p l i e sl ,,^r- .r).i t.,t ,,^rs-t1ti tt1t1 ,3127)' .l t easilyfollows that for r, 2rfiT t,,,

r,,,(o )-

I
r|l

tt"(.a T.T),

t:1fQ)1dt' l <el 3

(2.7)

Choose I e I such that X > 2\/FTl[e. Then using 2.6 and2.7,

i ,,y (rr) l Ql l < 2 el 3

i n w h i c h o  [ ;rrr.rn ]i's a rbi trary.S i nce.f l t):./t ,1for., e | ,,,.,rt)' ,

,tt,,^ /r

i, o-,_

"

t

*

l

l

( ,

'l', ,t

i

'

v

)11 ,'1-

)

""1' 1 ;, , .

,

,

1l

l'

-

/r-rrr+r
which finishesthe proof. The statementin Theorem 2 is equivalent to the statementthat 5'n is
uniformly denseon compactain C.'()i'')under the indicated conditions on K. That is, under the conditions on 1{ of Theorem 2, for any continuous function f' : lJ?'+ J?,for any r > 0, and for any compact subset C c $t', thereexistsa q e 56 such that ll (q l)'lcr ll-< c. Thus,by a useful relationship between uniform convergenceon compacta and convergencein measure (Hornik et al. 1.98,9lemma 2.2), we have the following corollary:
Corollary 2. Let y.be a finite measureon W'. Then under the conditions on K of Theorem 2, the family Sr<is densein C()?') with respectto the m e tri c p ,, d e fi n e db y p ,,Q .g) : i nf{ e > 0:trr{.r: e )t' : /' (r) rr(.r:1) ;'
.) <,1.

3 Conclusions and Discussion
The results in Section 2 establish that under certain mild conditions on the kernel function, radial-basis-function networks having one hidden layer and the samesmoothing factor in eachkernel are broad enough for universal approximation. This provides an analyticalbasisfor the design of neural networks usine radial basis functions.

Radial-Basis-Function Networks

255

To the extent that the results of this paper bear on the approximation
of a function in 11(S') with a finite sum DYtwr.K(.- zif o) of kernel functions, there is some overlap of a part of Cybenko (1989) and this study. Using a theorem due to Wiener (Rudin 1,973,p. 210) and the pertinent argument used in Cybenko (1989),it can be shown that the
s e t { ![, rL t;.K(- z .rloi ): M e Jtl , rf;  U ?,zi  ft' , oi I 0] i s dense in l1(W'), under the condition that K  ,1(W') and /y1,K(r)dr I 0. This certainly shows the capability of certain RBF networks with respect
to approximating an arbitrary tr1 function. However, note that here the
smoothing factor o; in each kernel node has a full degree of freedom, that is, the d?scan have different values acrossthe kernel nodes. Thus, the
major differencesbetween this LI approximation and the results given
in Section2 concern the classof RBF networks consideredas well as the
metrics used.l From the theoretical point of view, this condition concerning the same
smoothing factor is often very important, becausemany studies are concerned with approximation using the functions lfr'wi' lt( - zi ) (Broomhead and Lowe 1988; Powell 1985;Sun 1989),and radial basis
functions with the same smoothing factor in each kernel node are often used in real applications (Broomhead and Lowe 1988). In connection
with studies of approximation using radial basis functions, the recent results concerning the solvability of radial-function interpolation (Powell
1985;Sun 1989)are interesting, becausethey are directly applicable to
the training of neural networks of the type we have focused attention on. These studies (Powell 1985;Sun 1989)are concerned with the interpolation of data by the rl functions h( . - zr l), i : 7,....m,, when the data (zi,l/r)with zi Vl'',9i  $?,i:7,...inl aregiven. More precisely, the existenceof a unique interpolant lit'uti.h( .- zi ) for distinct data (2.;,y1w) ith z;  S', gi  W,'i : 7,.. . . rn hasbeenshown for a certainclass of pairs of h and ' ll. This existenceleads us to an interesting observation: Supposethat training data (z,,ai).i -- 1,...,ffi, are given, where z i  Y i " .l /r.:1 i f z i  A.' !1" : -7 i f z,t B , and A , B c n' w i th A ) B : A F ro m th e g i v e n d a ta ,c onstructa new data set zi eW ^.i :\,...,' m,by
defining

z'^. :

t

,

t

|
f

/
\

1

1

.

,-
o

.

,

-

1\,
)

.

.

.

.

u

t

- "

\

(

,,-.,,1\r
o ' lll)

Note that zi e ft'^. while zr  $1".Then by the above existence property,

1In this connection, Wiener's theorem referred to above can also be used to give a direct proof that -Ll approximations can be achieved with linear combinations of translates of any element of Z1(|Ii') whose Fourier transform never vanishes. The gaussrans
exp(-o l. ll) are examples of such functions.

256

J.Parkand I. W. Sandberg

for certainclassesof 17and for eachI e {1.2.....rn|.

,,,/\

!t, r,l,:tlJl

;'

\

o

, there exist  !?..7: 7..... rrts. uch that ^/
)

Thus,with A - (),.

z1t\ > 0i f ;:; e -'1.and zi.\ < 0 if zi e l).

In o th e r w o rd s , { (t^i .2y.i.l ...:),i,,-1r,1..2.....rrr} i s linearly separable in this

case. Therefore, the perceptron learning rule sufficesfor the training of

this network.

Additional related papers are (Hartman et al. 1990;Sandberg1991).

The work of Hartman et aI. (7990),which appeared after this work was

completed, considers gaussian functions and approximations on com-

pact subsetsof lR' that are convex. It is shown there that networks with

a single layer of gaussian units are universal approximators. In Sand-

berg (1991)more general results for gaussian functions are given as a

special case of propositions concerning the uniform approximation of

functionals defined on compact subsetsof spacesthat need not be finite dimensional. Also, it is observed in Sandberg (1991)that (what might

be called) "function-space feedforward neural networks" with an input

layer of bounded linear functionals and just one hidden nonlinear liyer

are universal approximators of real continuous functionals on compact

subsetsof a normed linear space.

Acknowledgments
This work was supported in part bv the National ScienceFoundation under Grant MIP-8915335.

References
Bochner, S., and Chandrasekharan, K. 1949. Fourier Transform.Princeton University Press,Princeton, NJ.
Broomhead, D. S., and Lowe, D. 1988. Multi-variable functional interpolation and adaptive networks. ComplexSyst. 2,327 355.
Cybenko, G. 1989. Approximation by superpositions of a sigmoidal function. Math. Control,Signals,Syst.2,303-314.
Hartman, E. J.,Keeler,J. D., and Kowalski, J. M. 1990.Layered neural networks with gaussianhidden units as universal approximations. NeuralComp. 2, 210-215.
Hornik, K. M., Stinchcombe, M., and White, H. 1989. Multilayer feedforward networks are universal approximators. Neural Networks2,359 366.
Lippman, R. P. 1989. Pattern classification using neural networks. IEEE Commun. Mag. 27,47 64.

Radial-Basis-FunctionNetworks

zJ/

Powell, M. J. D. 1985. Radial basis functions for multi-variable interpolation: A review. IMA Conference on Algorithms for the Approximation of Functions
and Data, RMCS Shrivenham, UK. Rudin, W.1973. FunctionalAnalysis. McGraw-Hill, New York. Rudin, W. 1986. Realand Abstract Analysis,3rd ed. McGraw-Hill, New York. Sandberg,I. W. 1991.Gaussian basis functions and approximations for nonlin-
ear systems. Proceedingsof the Ninth Kobe Internntional Symposium on Elec-
tronics and Int'ormation SciencesK, obe, Japan. Sun, X. 1989. On the solvability of radial function interpolation. Approximation
Theory VI 2,643-446.

Received 17 September 1990; accepted 25 Januaty 7991'.

