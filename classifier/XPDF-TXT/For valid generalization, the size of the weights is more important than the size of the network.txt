For valid generalization, the size of the weights is more important than the size
of the network
Peter L. Bartlett Department of Systems Engineering Research School of Information Sciences and Engineering
Australian National University Canberra, 0200 Australia Peter .BartlettClanu .edu.au
Abstract
This paper shows that if a large neural network is used for a pattern classification problem, and the learning algorithm finds a network with small weights that has small squared error on the training patterns, then the generalization performance depends on the size of the weights rather than the number of weights. More specifically, consider an i-layer feed-forward network of sigmoid units, in which the sum of the magnitudes of the weights associated with each unit is bounded by A. The misclassification probability converges to an error estimate (that is closely related to squared error on the training set) at rate O((cA)l(l+1)/2J(log n)jm) ignoring log factors, where m is the number of training patterns, n is the input dimension, and c is a constant. This may explain the generalization performance of neural networks, particularly when the number of training examples is considerably smaller than the number of weights. It also supports heuristics (such as weight decay and early stopping) that attempt to keep the weights small during training.
1 Introduction
Results from statistical learning theory give bounds on the number of training examples that are necessary for satisfactory generalization performance in classification problems, in terms of the Vapnik-Chervonenkis dimension of the class of functions used by the learning system (see, for example, [13, 5]). Baum and Haussler [4] used these results to give sample size bounds for multi-layer threshold networks

Generalization and the Size ofthe Weights in Neural Networks

135

that grow at least as quickly as the number of weights (see also [7]). However, for pattern classification applications the VC-bounds seem loose; neural networks often perform successfully with training sets that are considerably smaller than the number of weights. This paper shows that for classification problems on which neural networks perform well, if the weights are not too big, the size of the weights determines the generalization performance.
In contrast with the function classes and algorithms considered in the VC-theory, neural networks used for binary classification problems have real-valued outputs, and learning algorithms typically attempt to minimize the squared error of the network output over a training set. As well as encouraging the correct classification, this tends to push the output away from zero and towards the target values of {-1, I}. It is easy to see that if the total squared error of a hypothesis on m examples is no more than mf, then on no more than mf/(I- o? of these examples can the hypothesis have either the incorrect sign or magnitude less than a.
The next section gives misclassification probability bounds for hypotheses that are "distinctly correct" in this way on most examples. These bounds are in terms of a scale-sensitive version of the VC-dimension, called the fat-shattering dimension. Section 3 gives bounds on this dimension for feedforward sigmoid networks, which imply the main results. The proofs are sketched in Section 4. Full proofs can be
found in the full version [2].

2 Notation and bounds on misclassification probability
Denote the space of input patterns by X. The space of labels is {-I, I}. We assume that there is a probability distribution P on the product space X x { -1, I}, that reflects both the relative frequency of different input patterns and the relative frequency of an expert's classification of those patterns. The learning algorithm uses a class of real-valued functions, called the hypothesis class H. An hypothesis h is correct on an example (x, y) if sgn(h(x)) = y, where sgn(a) : 1R -+ {-I, I} takes
value 1 iff a 2: 0, so the misclassification probability (or error) of h is defined as
erp(h) = P {(x, y) E X x {-I, I} : sgn(h(x)) "# y} .
The crucial quantity determining misclassification probability is the fat-shattering dimension of the hypothesis class H. We say that a sequence Xl, ... , X d of d points from X is shattered by H iffunctions in H can give all classifications of the sequence.
= That is, for all b (bl , ... , bm ) E {-I, l}m there is an h in H satisfying sgn(h(xi)) =
bi . The VC-dimension of H is defined as the size of the largest shattered sequence. l
For a given scale parameter, > 0, we say that a sequence Xl, ... , Xd of d points
from X is ,-shattered by H if there is a sequence rl, ... , rd of real values such that
= for all b (bl , ... , bm ) E {-I, l}m there is an h in H satisfying (h(xd - rdbi 2: ,.
The fat-shattering dimension of H at " denoted fatH(!), is the size of the largest ,-shattered sequence. This dimension reflects the complexity of the functions in the class H, when examined at scale ,. Notice that fatH(!) is a nonincreasing function of ,. The following theorem gives generalization error bounds in terms of fatH(!). A related result, that applies to the case of no errors on the training set, will appear in [12].
  Theorem 1 Define the input space X, hypothesis class H, and probability distri-
bution P on X x {-I, I} as above. Let < 0 < 1/2, and < , < 1. Then,
with probability 1- 0 over the training sequence (Xl, YI), ... , (xm, Ym) of m labelled
1In fact, according to the usual definition, this is the VO-dimension of the class of thresholded versions of functions in H.

136

P. L. Bartlett

examples, every hypothesis h in H satisfies

erp(h)

<

~
m

I{i

:

Ih(xdl

<

,

or sgn(h(xt))

I- Yi}1 + fb, m, 6),

where

f2b, m, 6)

=

2 m

(d In(50em/d) log2(1250m)

+ In(4/6))

,

(1)

and d = fatHb/16).

2.1 Comments
It is informative to compare this result with the standard VC-bound. In that case, the bound on misclassification probability is
erp(h) < m1 I{i : sgn(h(xi)) I- ydl + ( mC (dlog(m/d) + log(I/6))) 1/2 ,
where d = VCdim(H) and c is a constant. We shall see in the next section that there are function classes H for which VCdim(H) is infinite but fatHb) is finite
for all, > 0; an example is the class of functions computed by any two-layer neu-
ral network with an arbitrary number of parameters but constraints on the size of the parameters. It is known that if the learning algorithm and error estimates are constrained to make use of the sample only by considering the proportion of training examples that hypotheses misclassify, there are distributions P for which the second term in the VC-bound above cannot be improved by more than log factors. Theorem 1 shows that it can be improved if the learning algorithm makes use of the sample by considering the proportion of training examples that are correctly
classified and have Ih(xdl < ,. It is possible to give a lower bound (see the full
paper [2]) which, for the function classes considered here, shows that Theorem 1 also cannot be improved by more than log factors.
The idea of using the magnitudes of the values of h(xd to give a more precise estimate of the generalization performance was first proposed by Vapnik in [13] (and was further developed by Vapnik and co-workers). There it was used only for the case of linear hypothesis classes. Results in [13] give bounds on misclassification probability for a test sample, in terms of values of h on the training and test data. This result is extended in [11], to give bounds on misclassification probability (that is, for unseen data) in terms of the values of h on the training examples. This is further extended in [12] to more general function classes, to give error bounds that are applicable when there is a hypothesis with no errors on the training examples. Lugosi and Pinter [9] have also obtained bounds on misclassification probability in terms of similar properties of the class of functions containing the true regression function (conditional expectation of Y given x). However, their results do not extend to the case when the true regression function is not in the class of real-valued functions used by the estimator.
It seems unnatural that the quantity, is specified in advance in Theorem 1, since it depends on the examples. The full paper [2] gives a similar result in which the statement is made uniform over all values of this quantity.

3 The fat-shattering dimension of neural networks
Bounds on the VC-dimensionofvarious neural network classes have been established (see [10] for a review), but these are all at least linear in the number of parameters. In this section, we give bounds on the fat-shattering dimension for several neural network classes.

Generalization and the Size ofthe Weights in Neural Networks

137

We assume that the input space X is some subset of ]Rn. Define a sigmoid unit as a function from ]R k to ]R, parametrized by a vector of weights w E ]R k  The unit computes x t-7 0'( X  w), where 0' is a fixed bounded function satisfying a Lipchitz condition. (For simplicity, we ignore the offset parameter. It is equivalent
to including an extra input with a constant value.) A multi-layer feed-forward sigmoid network of depth  is a network of sigmoid units with a single output unit, which can be arranged in a layered structure with  layers, so that the output of a unit passes only to the inputs of units in later layers. We will consider networks in which the weights are bounded. The relevant norm is the 1 norm: for a vector
w E ]Rk, define IIwl11 = 2:7=1 IWil. The following result gives a bound on the fat-
shattering dimension of a (bounded) linear combination of real-valued functions, in terms of the fat-shattering dimension of the basis function class. We can apply this result in a recursive fashion to give bounds for single output feed-forward networks.

Theorem 2 Let F be a class of functions that map from X to [-M/2, M/2], such
that 0 E F and, for all f in F, - f E F. For A > 0, define the class H of

weight-bounded linear combinations of functions from F as

{t H =

~ Wdi : k E W, fi E F, "will A} .

,=1

= Suppose , > 0 is such that d

fatFb/(32A)) 2: 1. Then fatHb) ~

(cM2 A 2d/,2) log2(MAd/,), for some constant c.

Gurvits and Koiran [6] have shown that the fat-shattering dimension of the class of two-layer networks with bounded output weights and linear threshold hidden units
a = is ((A 2n 2h 2) log(n/,y)), when X lRn. As a special case, Theorem 2 improves
this result.
Notice that the fat-shattering dimension of a function class is not changed by more than a constant factor if we compose the functions with a fixed function satisfying a Lipschitz condition (like the standard sigmoid function) . Also, for X = ]Rn and
H = {x t-7 xd we have fatHb) ~ logn for all 'Y. Finally, for H = {x t-7 W x: w E
]Rn} we have fatHb) ~ n for all 'Y. These observations, together with Theorem 2,
give the following corollary. The 0() notation suppresses log factors. (Formally,
= = f O(g) if f o(g1+O:) for all 0' > 0.)

Corollary 3 If X C lR n and H is the class of two-layer sigmoid networks with the
= weights in the outp;;i unit satisfying IIwlh ~ A, then fatHb) 6 (A2n/'Y2).
If X = {x E lRn: Ilxlioo ~ B} and the hidden unit weights are also bounded, then fatHb) = 0 (B2 A6 (log n)h4).

Applying Theorem 2 to this result gives the following result for deeper networks. Notice that there is no constraint on the number of hidden units in any layer, only on the total magnitude of the weights associated with a processing unit.

Corollary 4 For some constant c, if X C ]Rn and H is the class of depth  sigmoid networks in which the weight vector w associated with each unit beyond the first
layer satisfies IIwlll ~ A, then fatHb) = () (n(cA)l(l-1)h 2(l-1)) . If X = {x E lRn : IIxlioo ~ B} and the weights in the first layer units also satisfy
IIwll1 ~ A, then fatHb) = () (B2(cA)l(l+1) /'Y2llog n).

In the first part of this corollary, the network has fat-shattering dimension similar to the VC-dimension of a linear network. This formalizes the intuition that when the weights are small, the network operates in the "linear part" of the sigmoid, and so behaves like a linear network.

138

P. L. Bartlett

3.1 Comments
Consider a depth '- sigmoid network with bounded weights. The last corollary and Theorem 1 imply that if the training sample size grows roughly as B2 Al2 /f2, then the misclassification probability of a network is within f of the proportion of training examples that the network classifies as "distinctly correct."
These results give a plausible explanation for the generalization performance of neural networks. If, in applications, networks with many units have small weights and small squared error on the training examples, then the VC-dimension (and hence number of parameters) is not as important as the magnitude of the weights for generalization performance.
It is possible to give a version of Theorem 1 in which the probability bound is uniform over all values of a complexity parameter indexing the function classes (using the same technique mentioned at the end of Section 2.1). For the case of sigmoid network classes, indexed by a weight bound, minimizing the resulting bound on misclassification probability is equivalent to minimizing the sum of a sample error term and a penalty term involving the weight bound. This supports the use of two popular heuristic techniques, weight decay and early stopping (see, for example, [8]), which aim to minimize squared error while maintaining small weights.
These techniques give bounds on the fat-shattering dimension and hence generalization performance for any function class that can be expressed as a bounded number of compositions of either bounded-weight linear combinations or scalar Lipschitz functions with functions in a class that has finite fat-shattering dimension. This includes, for example, radial basis function networks.

4 Proofs

4.1 Proof sketch of Theorem 1
For A f S, ' where (S, p) is a pseudometric space, a set T <; S is an f-cover of A if for all a in A there is a tin T with p(t, a) < f.. We define N(A, f, p) as the size of the
= smallest f-cover of A . For x (Xl, . . . , Xm) E X m , define the pseudometric dloo(x)
on the set S of functions defined on X by dloo(x)(f,g) = max; If(xd - g(x;)I. For a set A of functions, denote maxxEx",N(A,f,dloo(x)) by Noo(A,f,m). Alon et al. [1] have obtained the following bound on Noo in terms of the fat-shattering dimension.

Lemma 5 For a class F of functions that map from {I, .. . , n} to {I, ... , b} with

(L:1=o fatF(l) ~ d, log2Noo(F,2,n) < 1 + log2(nb2)log2

(7)bi ), provided that n ~

1 + log2 (L:1=o (7)bi ).

For, > 0 define 7r"'( : lR -+ [-",] as the piecewise-linear squashing function satis-
fying 7r"'((a) = , if a ~ " 7r"'((a) = -, if a ~ -" = and 7r"'((a) a otherwise. For a
class H of real-valued functions, define 7r"'((H) as the set of compositions of 7r"'( with
functions in H.

Lemma 6 For X, H, P, 6, and, as in Theorem 1,

(! 2m)) ) pm { z : 3h E H, erp(h) 2: In CNoo(",(H), '1/2,

+ 1/2

~ I{i: Ih(z.)1 < 'I orsgn(h(z.)) # !Ii}I} < 6.

Generalization and the Size o/the Weights in Neural Networks

139

The proof of the lemma relies on the observation that
{z : ! <, pm 3h E H, erp(h) 2: f + I{i : Ih(xi)1 or sgn(h(xd) =f. ydl}

{z : f+! < pm 3h E H, P(11I""((h(x)) -,yl2: ,) 2:

I{i : 1I""((h(xd) =f. ,ydl}.

We then use a standard symmetrization argument and the permutation argument introduced by Vapnik and Chervonenkis to bound this probability by the probability under a random permutation of a double-length sample that a related property holds. For any fixed sample , we can then use Pollard's approach of approximating the hypothesis class using a {J/2)-cover, except that in this case the appropriate cover is with respect to the /00 pseudometric. Applying Hoeffding's inequality gives the lemma.
To prove Theorem 1, we need to bound the covering numbers in terms of the fatshattering dimension. It is easy to apply Lemma 5 to a quantized version of the function class to get such a bound, taking advantage of the range constraint imposed by the squashing function 11""( .

4.2 Proof sketch of Theorem 2

For x = (Xl"'" Xm) E X m , define the pseudometric dl1(x) on the class of func-
tions defined on X by dl1(x)(f,g) = ~ L:;:l I/(xi) - g(Xi)/. Similarly, define
dl2 (x)(f, g) = (~ L:;:I(f(Xi) - g(xd)2)1/2 . If A is a set of functions defined on
X, denote maxxEXm N(A", dl1(x)) by Nt{A", m), and similarly for N 2(A , " m) .
The idea of the proof of Theorem 2 is to first derive a general upper bound on an /1 covering number of the class H, and then apply the following result (which is implicit in the proof of Theorem 2 in [3]) to give a bound on the fat-shattering dimension.
Lemma 7 For a class F 01 [0 , I]-valued functions on X satisfying fatF(4,) 2: d, we have log2 Nt{F" , d) 2: d/32.
To derive an upper bound on N1{J, H, m) , we start with the bound that Lemma 5
implies on the /00 covering number Noo(F", m) for the class F of hidden unit functions. Since dl.A/, g) :::; dl oo (f, g) , this implies the following bound on the /2 covering number for F (provided m satisfies the condition required by Lemma 5, and it turns out that the theorem is trivial otherwise).

log2 N2 (F", m) < 1 + dlog2 ( 4edm, M) log2 (9m,2M2) .

(2)

Next, we use the following result on approximation in /2 , which A. Barron attributes to Maurey.

Lemma 8 (Maurey) Suppose G is a Hilbert space and F ~ G has 11/11:::; b for all

III - lil1 I in F. Let I be an element from the convex closure of F. Then for all k 2: 1 and all

c> b2_1//I/ 2, there are functions {It ,   . Jd ~ F such that

~ L:7=1

~ . 2 :::;

This implies that any element of H can be approximated to a particular accuracy (with respect to /2) using a fixed linear combination of a small number of elements of F . It follows that we can construct an /2 cover of H from the /2 cover of F; using Lemma 8 and Inequality 2 shows that
log2 N2 (H", m) < 2M,22A2 ( 1 + dlog2 (8emdM, A) log2 (36m,M2 2A2)) .

140

P. L. Bartlett

Now, Jensen's inequality implies that dI1(x)(f,g) ~ dI2 (x)(f,g), which gives a bound
on Nt (H, 1, m). Comparing with the lower bound given by Lemma 7 and solving
for m gives the result. A more refined analysis for the neural network case involves
bounding N2 for successive layers, and solving to give a bound on the fat-shattering
dimension of the network.
Acknowledgements
Thanks to Andrew Barron, Jonathan Baxter, Mike Jordan, Adam Kowalczyk, Wee Sun Lee, Phil Long, John Shawe-Taylor, and Robert Slaviero for helpful discussions and comments.

References
[1] N. Alon, S. Ben-David, N. Cesa-Bianchi, and D. Haussler. Scale-sensitive di-
mensions, uniform convergence, and learnability. In Proceedings of the 1993 IEEE Symposium on Foundations of Computer Science. IEEE Press, 1993.
[2] P. L. Bartlett. The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network. Technical report, Department of Systems Engineering, Australian National University, 1996. (available by anonymous ftp from syseng.anu.edu.au:pub/peter/TR96d.ps).
[3] P. L. Bartlett, S. R. Kulkarni, and S. E. Posner. Covering numbers for realvalued function classes. Technical report, Australian National University and Princeton University, 1996.
[4] E. Baum and D. Haussler. What size net gives valid generalization? Neural Computation, 1(1):151-160,1989.
[5] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Learnability and the Vapnik-Chervorienkis dimension. J . ACM, 36(4):929-965, 1989.
[6] L. Gurvits and P. Koiran. Approximation and learning of convex superpositions. In Computational Learning Theory: EUROCOLT'95, 1995.
[7] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning applications. Inform. Comput., 100(1):78-150,1992.
[8] J. Hertz, A. Krogh, and R. G. Palmer. Introduction to the Theory of Neural Computation. Addison-Wesley, 1991.
[9] G. Lugosi and M. Pinter. A data-dependent skeleton estimate for learning. In Proc. 9th Annu. Conference on Comput. Learning Theory. ACM Press, New York, NY, 1996.
[10] W. Maass. Vapnik-Chervonenkis dimension of neural nets. In M. A. Arbib, editor, The Handbook of Brain Theory and Neural Networks, pages 1000-1003. MIT Press, Cambridge, 1995.
[11] J. Shawe-Taylor, P. 1. Bartlett, R. C . Williamson, and M. Anthony. A framework for structural risk minimisation. In Proc. 9th Annu. Conference on Comput. Learning Theory. ACM Press, New York, NY, 1996.
[12] J. Shawe-Taylor, P. 1. Bartlett, R. C. Williamson, and M. Anthony. Structural risk minimization over data-dependent hierarchies. Technical report, 1996.
[13] V. N. Vapnik. Estimation of Dependences Based on Empirical Data. SpringerVerlag, New York, 1982.

