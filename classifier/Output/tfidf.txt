#### 1st Training Size

#Declaring and applying TFIDF functions to train and test data

tfidf_vect = TfidfVectorizer(ngram_range=(1,2))
tfidf_train = tfidf_vect.fit_transform(x1.values)
tfidf_test=tfidf_vect.transform(x2.values)
print(tfidf_train.shape)
print(tfidf_test.shape)
#tfidf_train.toarray()

x_tfidf = tfidf_vect.fit_transform(df1["lemmatized"])

train_values= np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values = 1 - train_values
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i, j in zip(train_values, test_values):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf,df1["label"], train_size=i, test_size=j)

#### 2nd training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect1 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train1 = tfidf_vect1.fit_transform(x3.values)
tfidf_test1=tfidf_vect.transform(x4.values)
print(tfidf_train1.shape)
print(tfidf_test1.shape)
#tfidf_train1.toarray()

x_tfidf1 = tfidf_vect1.fit_transform(df2["lemmatized"])

train_values1 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values1 = 1 - train_values1
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i1, j1 in zip(train_values1, test_values1):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf1,df2["label"], train_size=i1, test_size=j1)

#### 3rd training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect2= TfidfVectorizer(ngram_range=(1,2))
tfidf_train2 = tfidf_vect1.fit_transform(x5.values)
tfidf_test2=tfidf_vect.transform(x6.values)
print(tfidf_train2.shape)
print(tfidf_test2.shape)
#tfidf_train2.toarray()

x_tfidf2 = tfidf_vect2.fit_transform(df3["lemmatized"])

train_values2 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values2 = 1 - train_values2
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i2, j2 in zip(train_values2, test_values2):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf2,df3["label"], train_size=i2, test_size=j2)


#### 4th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect3 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train3 = tfidf_vect1.fit_transform(x7.values)
tfidf_test3=tfidf_vect.transform(x8.values)
print(tfidf_train3.shape)
print(tfidf_test3.shape)
#tfidf_train3.toarray()

x_tfidf3 = tfidf_vect3.fit_transform(df4["lemmatized"])

train_values3 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values3 = 1 - train_values3
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i3, j3 in zip(train_values3, test_values3):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf3,df4["label"], train_size=i3, test_size=j3)

#### 5th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect4 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train4 = tfidf_vect1.fit_transform(x9.values)
tfidf_test4=tfidf_vect.transform(x10.values)
print(tfidf_train4.shape)
print(tfidf_test4.shape)
#tfidf_train4.toarray()

x_tfidf4 = tfidf_vect4.fit_transform(df5["lemmatized"])

train_values4 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values4 = 1 - train_values4
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i4, j4 in zip(train_values4, test_values4):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf4,df5["label"], train_size=i4, test_size=j4)

#### 6th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect5 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train5 = tfidf_vect1.fit_transform(x11.values)
tfidf_test5=tfidf_vect5.transform(x12.values)
print(tfidf_train5.shape)
print(tfidf_test5.shape)
#tfidf_train5.toarray()

x_tfidf5 = tfidf_vect5.fit_transform(df6["lemmatized"])

train_values5 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values5 = 1 - train_values5
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i5, j5 in zip(train_values5, test_values5):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf5,df6["label"], train_size=i5, test_size=j5)


#### 7th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect6 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train6 = tfidf_vect1.fit_transform(x13.values)
tfidf_test6=tfidf_vect5.transform(x14.values)
print(tfidf_train6.shape)
print(tfidf_test6.shape)
#tfidf_train6.toarray()

x_tfidf6 = tfidf_vect6.fit_transform(df7["lemmatized"])

train_values6 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values6 = 1 - train_values6
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i6, j6 in zip(train_values6, test_values6):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf6,df7["label"], train_size=i6, test_size=j6)

#### 8th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect7 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train7 = tfidf_vect1.fit_transform(x15.values)
tfidf_test7=tfidf_vect5.transform(x16.values)
print(tfidf_train6.shape)
print(tfidf_test6.shape)
#tfidf_train7.toarray()

x_tfidf7 = tfidf_vect7.fit_transform(df8["lemmatized"])

train_values7 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values7 = 1 - train_values7
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i7, j7 in zip(train_values7, test_values7):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf7,df8["label"], train_size=i7, test_size=j7)

#### 9th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect8 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train8 = tfidf_vect1.fit_transform(x17.values)
tfidf_test8=tfidf_vect5.transform(x18.values)
print(tfidf_train8.shape)
print(tfidf_test8.shape)
#tfidf_train8.toarray()

x_tfidf8 = tfidf_vect8.fit_transform(df9["lemmatized"])

train_values8 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values8 = 1 - train_values8
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i8, j8 in zip(train_values8, test_values8):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf8,df9["label"], train_size=i8, test_size=j8)

#### 10th training size ####
#Declaring and applying TFIDF functions to train and test data

tfidf_vect9 = TfidfVectorizer(ngram_range=(1,2))
tfidf_train9 = tfidf_vect1.fit_transform(x19.values)
tfidf_test9=tfidf_vect5.transform(x20.values)
print(tfidf_train9.shape)
print(tfidf_test9.shape)
#tfidf_train9.toarray()

x_tfidf9 = tfidf_vect9.fit_transform(df10["lemmatized"])

train_values9 = np.array([0.16, 0.33, 0.50, 0.67, 0.83])
test_values9 = 1 - train_values9
# Other train values: , 0.60, 0.70, 0.80, 0.85, 0.90
# , 0.146, 0.219, 0.229, 0.300, 0.335, 0.380, 0.415, 0.465
#test_sizes = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])
#train_sizes = round(train_list, 3)
for i9, j9 in zip(train_values9, test_values9):

x_train, x_test, y_train, y_test = train_test_split(x_tfidf9,df10["label"], train_size=i9, test_size=j9)
