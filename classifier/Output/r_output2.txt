
R version 4.1.3 (2022-03-10) -- "One Push-Up"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Workspace loaded from ~/.RData]

> # Stuck On
Warning message:
R graphics engine version 14 is not supported by this version of RStudio. The Plots tab will be disabled until a newer version of RStudio is installed. 
>   foo2 <- foo %>% 
+     add_residuals(mod)
Error in foo %>% add_residuals(mod) : could not find function "%>%"
> # Stuck On
>   # foo2 <- foo %>% 
>   #   add_residuals(mod_foo)
>  foo2 %>%
+    filter(abs(l_x) > 1) %>%
+    add_predictions(mod_foo2) %>%
+    mutate(pred = pred) %>%
+    select(l_x, pred, l_y:foo, x:y) %>%
+    arrange(x)
Error in foo2 %>% filter(abs(l_x) > 1) %>% add_predictions(mod_foo2) %>%  : 
  could not find function "%>%"
> # Chapter 25
> foo3 %>% 
+    ggplot(aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
Error in foo3 %>% ggplot(aes(x, y, group = classifier)) : 
  could not find function "%>%"
> # Chapter 25
> foo %>% 
+    ggplot(aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
Error in foo %>% ggplot(aes(x, y, group = classifier)) : 
  could not find function "%>%"
> # Chapter 25
> foo %>% 
+    ggplot(aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
Error in foo %>% ggplot(aes(x, y, group = classifier)) : 
  could not find function "%>%"
> ggplot(aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
Error in ggplot(aes(x, y, group = classifier)) : 
  could not find function "ggplot"
> library(ggplot2)
> library(tidyverse)
-- Attaching packages ----------------- tidyverse 1.3.1 --
âˆš tibble  3.1.6     âˆš dplyr   1.0.8
âˆš tidyr   1.2.0     âˆš stringr 1.4.0
âˆš readr   2.1.2     âˆš forcats 0.5.1
âˆš purrr   0.3.4     
-- Conflicts -------------------- tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
> library(reshape)

Attaching package: ‘reshape’

The following object is masked from ‘package:dplyr’:

    rename

The following objects are masked from ‘package:tidyr’:

    expand, smiths

> ggplot(aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
Error in `fortify()`:
! `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class uneval.
Did you accidentally pass `aes()` to the `data` argument?
Run `rlang::last_error()` to see where the error occurred.
> ggplot(foo, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, lclassifier, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo2, aes(x, lclassifier, group = classifier)) +
+    geom_line(alpha = 1/3)
> ggplot(foo, aes(x, y, group = classifier)) +
+    geom_line(alpha = 1/3)
> foo2 %>%
+ filter(abs(l_x) > 1) %>%
+  add_predictions(mod_foo2) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:foo, x:y) %>%
+  arrange(x)
Error in add_predictions(., mod_foo2) : 
  could not find function "add_predictions"
> library(tidyverse)
> library(reshape)
> library(ggplot2)
> library(modelr)
> options(na.action = na.warn)
> foo2 %>%
+ filter(abs(l_x) > 1) %>%
+  add_predictions(mod_foo2) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:foo, x:y) %>%
+  arrange(x)
Note: Using an external vector in selections is ambiguous.
i Use `all_of(foo)` instead of `foo` to silence this message.
i See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.
This message is displayed once per session.
Error in `select()`:
! Must subset columns with a valid subscript vector.
x Subscript has the wrong type `tbl_df<
  model     : character
  x         : double
  y         : double
  classifier: character
  resid     : double
>`.
i It must be numeric or character.
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>%
+ filter(abs(l_x) > 1) %>%
+  add_predictions(mod_foo2) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `select()`:
! Must subset columns with a valid subscript vector.
x Subscript has the wrong type `tbl_df<
  model     : character
  x         : double
  y         : double
  classifier: character
  resid     : double
>`.
i It must be numeric or character.
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>%
+ filter(abs(lclassifier) > 1) %>%
+  add_predictions(mod_foo2) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `select()`:
! Must subset columns with a valid subscript vector.
x Subscript has the wrong type `tbl_df<
  model     : character
  x         : double
  y         : double
  classifier: character
  resid     : double
>`.
i It must be numeric or character.
Run `rlang::last_error()` to see where the error occurred.
> foo2 <- foo %>% 
+   add_residuals(mod_foo2)
Error in eval(response_var(model), as.data.frame(data)) : 
  object 'l_y' not found
> foo2 <- foo %>% 
+   add_residuals(mod_foo)
> foo2 %>%
+ filter(abs(lclassifier) > 1) %>%
+  add_predictions(mod_foo) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `filter()`:
! Problem while computing `..1 =
  abs(lclassifier) > 1`.
Caused by error:
! object 'lclassifier' not found
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>%
+ filter(abs(l_x) > 1) %>%
+  add_predictions(mod_foo) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `filter()`:
! Problem while computing `..1 =
  abs(l_x) > 1`.
Caused by error:
! object 'l_x' not found
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>%
+ filter(abs(x) > 1) %>%
+  add_predictions(mod_foo) %>%
+  mutate(pred = pred) %>%
+  select(l_x, pred, l_y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `select()`:
! Can't subset columns that don't exist.
x Column `l_x` doesn't exist.
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>%
+ filter(abs(x) > 1) %>%
+  add_predictions(mod_foo) %>%
+  mutate(pred = pred) %>%
+  select(x, pred, y:all_of(foo), x:y) %>%
+  arrange(x)
Error in `select()`:
! Must subset columns with a valid subscript vector.
x Subscript has the wrong type `tbl_df<
  model     : character
  x         : double
  y         : double
  classifier: character
  resid     : double
>`.
i It must be numeric or character.
Run `rlang::last_error()` to see where the error occurred.
> foo2 <- foo2  %>% 
+   mutate(classifier) %>% 
+   group_by() %>% 
+     summarise(n = n())
> # Alternative code
> m1 <- lm(x ~ classifier, data = foo2)
> grid <- data.frame(x = seq(0, 1, length = 10))
> grid %>% add_predictions(m1)
Error in `[[<-.data.frame`(`*tmp*`, var, value = c(`1` = 67.500909090909,  : 
  replacement has 225 rows, data has 10
In addition: Warning message:
'newdata' had 10 rows but variables found have 225 rows 
> # Alternative code
> m1 <- lm(x ~ classifier, data = foo2)
> grid <- data.frame(x = seq(0, 1, length = 255))
> grid %>% add_predictions(m1)
Error in `[[<-.data.frame`(`*tmp*`, var, value = c(`1` = 67.500909090909,  : 
  replacement has 225 rows, data has 255
In addition: Warning message:
'newdata' had 255 rows but variables found have 225 rows 
> grid <- data.frame(x = seq(0, 1, length = 225))
> grid %>% add_predictions(m1)
              x     pred
1   0.000000000 67.50091
2   0.004464286 74.03709
3   0.008928571 34.35907
4   0.013392857 69.89873
5   0.017857143 46.23833
6   0.022321429 67.50091
7   0.026785714 74.03709
8   0.031250000 34.35907
9   0.035714286 69.89873
10  0.040178571 46.23833
11  0.044642857 67.50091
12  0.049107143 74.03709
13  0.053571429 34.35907
14  0.058035714 69.89873
15  0.062500000 46.23833
16  0.066964286 67.50091
17  0.071428571 74.03709
18  0.075892857 34.35907
19  0.080357143 69.89873
20  0.084821429 46.23833
21  0.089285714 67.50091
22  0.093750000 74.03709
23  0.098214286 34.35907
24  0.102678571 69.89873
25  0.107142857 46.23833
26  0.111607143 67.50091
27  0.116071429 74.03709
28  0.120535714 34.35907
29  0.125000000 69.89873
30  0.129464286 46.23833
31  0.133928571 67.50091
32  0.138392857 74.03709
33  0.142857143 34.35907
34  0.147321429 69.89873
35  0.151785714 67.50091
36  0.156250000 74.03709
37  0.160714286 34.35907
38  0.165178571 69.89873
39  0.169642857 67.50091
40  0.174107143 74.03709
41  0.178571429 34.35907
42  0.183035714 69.89873
43  0.187500000 67.50091
44  0.191964286 74.03709
45  0.196428571 34.35907
46  0.200892857 69.89873
47  0.205357143 67.50091
48  0.209821429 74.03709
49  0.214285714 34.35907
50  0.218750000 69.89873
51  0.223214286 67.50091
52  0.227678571 74.03709
53  0.232142857 34.35907
54  0.236607143 69.89873
55  0.241071429 67.50091
56  0.245535714 74.03709
57  0.250000000 34.35907
58  0.254464286 69.89873
59  0.258928571 67.50091
60  0.263392857 74.03709
61  0.267857143 34.35907
62  0.272321429 69.89873
63  0.276785714 67.50091
64  0.281250000 74.03709
65  0.285714286 34.35907
66  0.290178571 69.89873
67  0.294642857 67.50091
68  0.299107143 74.03709
69  0.303571429 34.35907
70  0.308035714 69.89873
71  0.312500000 67.50091
72  0.316964286 74.03709
73  0.321428571 34.35907
74  0.325892857 69.89873
75  0.330357143 67.50091
76  0.334821429 74.03709
77  0.339285714 34.35907
78  0.343750000 69.89873
79  0.348214286 67.50091
80  0.352678571 74.03709
81  0.357142857 34.35907
82  0.361607143 69.89873
83  0.366071429 67.50091
84  0.370535714 74.03709
85  0.375000000 34.35907
86  0.379464286 69.89873
87  0.383928571 67.50091
88  0.388392857 74.03709
89  0.392857143 34.35907
90  0.397321429 69.89873
91  0.401785714 67.50091
92  0.406250000 74.03709
93  0.410714286 34.35907
94  0.415178571 69.89873
95  0.419642857 67.50091
96  0.424107143 74.03709
97  0.428571429 34.35907
98  0.433035714 69.89873
99  0.437500000 67.50091
100 0.441964286 74.03709
101 0.446428571 34.35907
102 0.450892857 69.89873
103 0.455357143 69.89873
104 0.459821429 67.50091
105 0.464285714 74.03709
106 0.468750000 67.50091
107 0.473214286 74.03709
108 0.477678571 34.35907
109 0.482142857 69.89873
110 0.486607143 67.50091
111 0.491071429 74.03709
112 0.495535714 34.35907
113 0.500000000 69.89873
114 0.504464286 67.50091
115 0.508928571 74.03709
116 0.513392857 34.35907
117 0.517857143 69.89873
118 0.522321429 67.50091
119 0.526785714 74.03709
120 0.531250000 34.35907
121 0.535714286 69.89873
122 0.540178571 67.50091
123 0.544642857 74.03709
124 0.549107143 34.35907
125 0.553571429 69.89873
126 0.558035714 67.50091
127 0.562500000 74.03709
128 0.566964286 34.35907
129 0.571428571 69.89873
130 0.575892857 67.50091
131 0.580357143 74.03709
132 0.584821429 34.35907
133 0.589285714 69.89873
134 0.593750000 67.50091
135 0.598214286 74.03709
136 0.602678571 34.35907
137 0.607142857 69.89873
138 0.611607143 67.50091
139 0.616071429 74.03709
140 0.620535714 34.35907
141 0.625000000 69.89873
142 0.629464286 67.50091
143 0.633928571 74.03709
144 0.638392857 34.35907
145 0.642857143 69.89873
146 0.647321429 67.50091
147 0.651785714 74.03709
148 0.656250000 34.35907
149 0.660714286 69.89873
150 0.665178571 67.50091
151 0.669642857 74.03709
152 0.674107143 34.35907
153 0.678571429 69.89873
154 0.683035714 67.50091
155 0.687500000 74.03709
156 0.691964286 34.35907
157 0.696428571 69.89873
158 0.700892857 67.50091
159 0.705357143 74.03709
160 0.709821429 34.35907
161 0.714285714 69.89873
162 0.718750000 67.50091
163 0.723214286 74.03709
164 0.727678571 34.35907
165 0.732142857 69.89873
166 0.736607143 67.50091
167 0.741071429 74.03709
168 0.745535714 34.35907
169 0.750000000 69.89873
170 0.754464286 67.50091
171 0.758928571 74.03709
172 0.763392857 34.35907
173 0.767857143 69.89873
174 0.772321429 67.50091
175 0.776785714 74.03709
176 0.781250000 34.35907
177 0.785714286 69.89873
178 0.790178571 67.50091
179 0.794642857 74.03709
180 0.799107143 34.35907
181 0.803571429 69.89873
182 0.808035714 67.50091
183 0.812500000 74.03709
184 0.816964286 34.35907
185 0.821428571 69.89873
186 0.825892857 67.50091
187 0.830357143 74.03709
188 0.834821429 34.35907
189 0.839285714 69.89873
190 0.843750000 67.50091
191 0.848214286 74.03709
192 0.852678571 34.35907
193 0.857142857 69.89873
194 0.861607143 67.50091
195 0.866071429 74.03709
196 0.870535714 34.35907
197 0.875000000 69.89873
198 0.879464286 67.50091
199 0.883928571 74.03709
200 0.888392857 34.35907
201 0.892857143 69.89873
202 0.897321429 67.50091
203 0.901785714 74.03709
204 0.906250000 34.35907
205 0.910714286 69.89873
206 0.915178571 67.50091
207 0.919642857 74.03709
208 0.924107143 34.35907
209 0.928571429 69.89873
210 0.933035714 67.50091
211 0.937500000 74.03709
212 0.941964286 34.35907
213 0.946428571 69.89873
214 0.950892857 67.50091
215 0.955357143 74.03709
216 0.959821429 34.35907
217 0.964285714 69.89873
218 0.968750000 67.50091
219 0.973214286 74.03709
220 0.977678571 34.35907
221 0.982142857 69.89873
222 0.986607143 67.50091
223 0.991071429 74.03709
224 0.995535714 34.35907
225 1.000000000 69.89873
> # Alternative code
> m1 <- lm(x ~ classifier, data = foo2)
> m2 <- lm(x ~ poly(classifier, 2), data = foo2)
Error in x - xbar : non-numeric argument to binary operator
In addition: Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
> grid %>% add_predictions(m1)
              x     pred
1   0.000000000 67.50091
2   0.004464286 74.03709
3   0.008928571 34.35907
4   0.013392857 69.89873
5   0.017857143 46.23833
6   0.022321429 67.50091
7   0.026785714 74.03709
8   0.031250000 34.35907
9   0.035714286 69.89873
10  0.040178571 46.23833
11  0.044642857 67.50091
12  0.049107143 74.03709
13  0.053571429 34.35907
14  0.058035714 69.89873
15  0.062500000 46.23833
16  0.066964286 67.50091
17  0.071428571 74.03709
18  0.075892857 34.35907
19  0.080357143 69.89873
20  0.084821429 46.23833
21  0.089285714 67.50091
22  0.093750000 74.03709
23  0.098214286 34.35907
24  0.102678571 69.89873
25  0.107142857 46.23833
26  0.111607143 67.50091
27  0.116071429 74.03709
28  0.120535714 34.35907
29  0.125000000 69.89873
30  0.129464286 46.23833
31  0.133928571 67.50091
32  0.138392857 74.03709
33  0.142857143 34.35907
34  0.147321429 69.89873
35  0.151785714 67.50091
36  0.156250000 74.03709
37  0.160714286 34.35907
38  0.165178571 69.89873
39  0.169642857 67.50091
40  0.174107143 74.03709
41  0.178571429 34.35907
42  0.183035714 69.89873
43  0.187500000 67.50091
44  0.191964286 74.03709
45  0.196428571 34.35907
46  0.200892857 69.89873
47  0.205357143 67.50091
48  0.209821429 74.03709
49  0.214285714 34.35907
50  0.218750000 69.89873
51  0.223214286 67.50091
52  0.227678571 74.03709
53  0.232142857 34.35907
54  0.236607143 69.89873
55  0.241071429 67.50091
56  0.245535714 74.03709
57  0.250000000 34.35907
58  0.254464286 69.89873
59  0.258928571 67.50091
60  0.263392857 74.03709
61  0.267857143 34.35907
62  0.272321429 69.89873
63  0.276785714 67.50091
64  0.281250000 74.03709
65  0.285714286 34.35907
66  0.290178571 69.89873
67  0.294642857 67.50091
68  0.299107143 74.03709
69  0.303571429 34.35907
70  0.308035714 69.89873
71  0.312500000 67.50091
72  0.316964286 74.03709
73  0.321428571 34.35907
74  0.325892857 69.89873
75  0.330357143 67.50091
76  0.334821429 74.03709
77  0.339285714 34.35907
78  0.343750000 69.89873
79  0.348214286 67.50091
80  0.352678571 74.03709
81  0.357142857 34.35907
82  0.361607143 69.89873
83  0.366071429 67.50091
84  0.370535714 74.03709
85  0.375000000 34.35907
86  0.379464286 69.89873
87  0.383928571 67.50091
88  0.388392857 74.03709
89  0.392857143 34.35907
90  0.397321429 69.89873
91  0.401785714 67.50091
92  0.406250000 74.03709
93  0.410714286 34.35907
94  0.415178571 69.89873
95  0.419642857 67.50091
96  0.424107143 74.03709
97  0.428571429 34.35907
98  0.433035714 69.89873
99  0.437500000 67.50091
100 0.441964286 74.03709
101 0.446428571 34.35907
102 0.450892857 69.89873
103 0.455357143 69.89873
104 0.459821429 67.50091
105 0.464285714 74.03709
106 0.468750000 67.50091
107 0.473214286 74.03709
108 0.477678571 34.35907
109 0.482142857 69.89873
110 0.486607143 67.50091
111 0.491071429 74.03709
112 0.495535714 34.35907
113 0.500000000 69.89873
114 0.504464286 67.50091
115 0.508928571 74.03709
116 0.513392857 34.35907
117 0.517857143 69.89873
118 0.522321429 67.50091
119 0.526785714 74.03709
120 0.531250000 34.35907
121 0.535714286 69.89873
122 0.540178571 67.50091
123 0.544642857 74.03709
124 0.549107143 34.35907
125 0.553571429 69.89873
126 0.558035714 67.50091
127 0.562500000 74.03709
128 0.566964286 34.35907
129 0.571428571 69.89873
130 0.575892857 67.50091
131 0.580357143 74.03709
132 0.584821429 34.35907
133 0.589285714 69.89873
134 0.593750000 67.50091
135 0.598214286 74.03709
136 0.602678571 34.35907
137 0.607142857 69.89873
138 0.611607143 67.50091
139 0.616071429 74.03709
140 0.620535714 34.35907
141 0.625000000 69.89873
142 0.629464286 67.50091
143 0.633928571 74.03709
144 0.638392857 34.35907
145 0.642857143 69.89873
146 0.647321429 67.50091
147 0.651785714 74.03709
148 0.656250000 34.35907
149 0.660714286 69.89873
150 0.665178571 67.50091
151 0.669642857 74.03709
152 0.674107143 34.35907
153 0.678571429 69.89873
154 0.683035714 67.50091
155 0.687500000 74.03709
156 0.691964286 34.35907
157 0.696428571 69.89873
158 0.700892857 67.50091
159 0.705357143 74.03709
160 0.709821429 34.35907
161 0.714285714 69.89873
162 0.718750000 67.50091
163 0.723214286 74.03709
164 0.727678571 34.35907
165 0.732142857 69.89873
166 0.736607143 67.50091
167 0.741071429 74.03709
168 0.745535714 34.35907
169 0.750000000 69.89873
170 0.754464286 67.50091
171 0.758928571 74.03709
172 0.763392857 34.35907
173 0.767857143 69.89873
174 0.772321429 67.50091
175 0.776785714 74.03709
176 0.781250000 34.35907
177 0.785714286 69.89873
178 0.790178571 67.50091
179 0.794642857 74.03709
180 0.799107143 34.35907
181 0.803571429 69.89873
182 0.808035714 67.50091
183 0.812500000 74.03709
184 0.816964286 34.35907
185 0.821428571 69.89873
186 0.825892857 67.50091
187 0.830357143 74.03709
188 0.834821429 34.35907
189 0.839285714 69.89873
190 0.843750000 67.50091
191 0.848214286 74.03709
192 0.852678571 34.35907
193 0.857142857 69.89873
194 0.861607143 67.50091
195 0.866071429 74.03709
196 0.870535714 34.35907
197 0.875000000 69.89873
198 0.879464286 67.50091
199 0.883928571 74.03709
200 0.888392857 34.35907
201 0.892857143 69.89873
202 0.897321429 67.50091
203 0.901785714 74.03709
204 0.906250000 34.35907
205 0.910714286 69.89873
206 0.915178571 67.50091
207 0.919642857 74.03709
208 0.924107143 34.35907
209 0.928571429 69.89873
210 0.933035714 67.50091
211 0.937500000 74.03709
212 0.941964286 34.35907
213 0.946428571 69.89873
214 0.950892857 67.50091
215 0.955357143 74.03709
216 0.959821429 34.35907
217 0.964285714 69.89873
218 0.968750000 67.50091
219 0.973214286 74.03709
220 0.977678571 34.35907
221 0.982142857 69.89873
222 0.986607143 67.50091
223 0.991071429 74.03709
224 0.995535714 34.35907
225 1.000000000 69.89873
> m2 <- lm(x ~ poly(classifier, 2), data = foo2)
Error in x - xbar : non-numeric argument to binary operator
In addition: Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
> grid %>% gather_predictions(m1, m2)
Error in eval_tidy(xs[[i]], unique_output) : object 'm2' not found
> m2 <- lm(y ~ poly(x, 2), data = foo2)
> m2 <- lm(y ~ poly(x, 2), data = foo2)
> classifier1 <- filter(foo2, classifier == "Naive Bayes")
Error in `filter()`:
! Problem while computing `..1 =
  classifier == "Naive Bayes"`.
x Input `..1` must be of size 1, not size
  225.
Run `rlang::last_error()` to see where the error occurred.
> classifier1 %>% 
+   ggplot(aes(x, classifier)) + 
+   geom_line() + 
+   ggtitle("Full data = ")
Error in ggplot(., aes(x, classifier)) : object 'classifier1' not found
> foo2 <- filter(foo2, classifier == "Naive Bayes")
Error in `filter()`:
! Problem while computing `..1 =
  classifier == "Naive Bayes"`.
x Input `..1` must be of size 1, not size
  225.
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>% 
+   ggplot(aes(x, classifier)) + 
+   geom_line() + 
+   ggtitle("Full data = ")
Error in `check_aesthetics()`:
! Aesthetics must be either length 1 or the same as the data (1): x and y
Run `rlang::last_error()` to see where the error occurred.
> foo2 <- filter(foo2, classifier == "Naive Bayes")
Error in `filter()`:
! Problem while computing `..1 = classifier == "Naive Bayes"`.
x Input `..1` must be of size 1, not size 225.
Run `rlang::last_error()` to see where the error occurred.
> foo2 %>% 
+   ggplot(aes(x, classifier)) + 
+   geom_line() + 
+   ggtitle("Full data = ")
Error in `check_aesthetics()`:
! Aesthetics must be either length 1 or the same as the data (1): x and y
Run `rlang::last_error()` to see where the error occurred.
> 